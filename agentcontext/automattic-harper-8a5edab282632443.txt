Directory structure:
└── automattic-harper/
    ├── README.md
    ├── ARCHITECTURE.md
    ├── biome.json
    ├── Cargo.toml
    ├── COMPARISON.md
    ├── CONTRIBUTING.md
    ├── demo.md
    ├── docker-compose.dev.yml
    ├── docker-compose.yml
    ├── Dockerfile
    ├── flake.lock
    ├── flake.nix
    ├── justfile
    ├── LICENSE
    ├── package.json
    ├── pnpm-workspace.yaml
    ├── rust-toolchain.toml
    ├── rustfmt.toml
    ├── .dockerignore
    ├── .editorconfig
    ├── .envrc
    ├── .node-version
    ├── .npmrc
    ├── fuzz/
    │   ├── README.md
    │   ├── Cargo.toml
    │   └── fuzz_targets/
    │       ├── fuzz_harper_comment.rs
    │       ├── fuzz_harper_core_markdown.rs
    │       ├── fuzz_harper_html.rs
    │       ├── fuzz_harper_literate_haskell.rs
    │       └── fuzz_harper_typst.rs
    ├── harper-asciidoc/
    │   ├── Cargo.toml
    │   ├── src/
    │   │   └── lib.rs
    │   └── tests/
    │       ├── asciidoc_tests.rs
    │       └── test_sources/
    │           ├── basic.adoc
    │           ├── comment.adoc
    │           ├── comprehensive.adoc
    │           └── table.adoc
    ├── harper-brill/
    │   ├── Cargo.toml
    │   └── src/
    │       └── lib.rs
    ├── harper-cli/
    │   ├── README.md
    │   ├── Cargo.toml
    │   └── src/
    │       ├── annotate.rs
    │       ├── input.rs
    │       ├── lint.rs
    │       ├── main.rs
    │       └── input/
    │           ├── multi_input.rs
    │           └── single_input.rs
    ├── harper-comments/
    │   ├── README.md
    │   ├── Cargo.toml
    │   ├── src/
    │   │   ├── comment_parser.rs
    │   │   ├── lib.rs
    │   │   ├── masker.rs
    │   │   └── comment_parsers/
    │   │       ├── go.rs
    │   │       ├── javadoc.rs
    │   │       ├── jsdoc.rs
    │   │       ├── lua.rs
    │   │       ├── mod.rs
    │   │       ├── solidity.rs
    │   │       └── unit.rs
    │   └── tests/
    │       ├── language_support.rs
    │       └── language_support_sources/
    │           ├── basic.clj
    │           ├── basic_kotlin.kt
    │           ├── clean.lua
    │           ├── clean.rs
    │           ├── clean.sol
    │           ├── common.mill
    │           ├── dirty.lua
    │           ├── empty.js
    │           ├── eof.rs
    │           ├── ignore_comments.c
    │           ├── ignore_comments.rs
    │           ├── ignore_comments.sol
    │           ├── ignore_shebang_1.sh
    │           ├── ignore_shebang_2.sh
    │           ├── ignore_shebang_3.sh
    │           ├── ignore_shebang_4.sh
    │           ├── issue_1097.lua
    │           ├── issue_132.rs
    │           ├── issue_229.c
    │           ├── issue_229.cs
    │           ├── issue_229.js
    │           ├── issue_96.lua
    │           ├── issue_96.rb
    │           ├── javadoc_clean_simple.java
    │           ├── javadoc_complex.java
    │           ├── jsdoc.ts
    │           ├── laravel_app.php
    │           ├── merged_lines.ts
    │           ├── multiline_comments.cpp
    │           ├── multiline_comments.sol
    │           └── multiline_comments.ts
    ├── harper-core/
    │   ├── README.md
    │   ├── annotations.json
    │   ├── build.rs
    │   ├── Cargo.toml
    │   ├── clippy.toml
    │   ├── irregular_nouns.json
    │   ├── irregular_verbs.json
    │   ├── proper_noun_rules.json
    │   ├── benches/
    │   │   ├── essay.md
    │   │   └── parse_essay.rs
    │   ├── src/
    │   │   ├── case.rs
    │   │   ├── char_ext.rs
    │   │   ├── char_string.rs
    │   │   ├── currency.rs
    │   │   ├── dict_word_metadata_orthography.rs
    │   │   ├── document.rs
    │   │   ├── edit_distance.rs
    │   │   ├── fat_token.rs
    │   │   ├── irregular_nouns.rs
    │   │   ├── irregular_verbs.rs
    │   │   ├── language_detection.rs
    │   │   ├── lib.rs
    │   │   ├── number.rs
    │   │   ├── punctuation.rs
    │   │   ├── render_markdown.rs
    │   │   ├── span.rs
    │   │   ├── sync.rs
    │   │   ├── thesaurus_helper.rs
    │   │   ├── title_case.rs
    │   │   ├── token.rs
    │   │   ├── token_kind.rs
    │   │   ├── token_string_ext.rs
    │   │   ├── vec_ext.rs
    │   │   ├── expr/
    │   │   │   ├── all.rs
    │   │   │   ├── anchor_end.rs
    │   │   │   ├── anchor_start.rs
    │   │   │   ├── duration_expr.rs
    │   │   │   ├── expr_map.rs
    │   │   │   ├── filter.rs
    │   │   │   ├── first_match_of.rs
    │   │   │   ├── fixed_phrase.rs
    │   │   │   ├── longest_match_of.rs
    │   │   │   ├── mergeable_words.rs
    │   │   │   ├── mod.rs
    │   │   │   ├── optional.rs
    │   │   │   ├── reflexive_pronoun.rs
    │   │   │   ├── repeating.rs
    │   │   │   ├── sequence_expr.rs
    │   │   │   ├── similar_to_phrase.rs
    │   │   │   ├── space_or_hyphen.rs
    │   │   │   ├── spelled_number_expr.rs
    │   │   │   ├── step.rs
    │   │   │   ├── time_unit_expr.rs
    │   │   │   ├── unless_step.rs
    │   │   │   └── word_expr_group.rs
    │   │   ├── ignored_lints/
    │   │   │   ├── lint_context.rs
    │   │   │   └── mod.rs
    │   │   ├── lexing/
    │   │   │   ├── email_address.rs
    │   │   │   ├── hostname.rs
    │   │   │   ├── mod.rs
    │   │   │   └── url.rs
    │   │   ├── linting/
    │   │   │   ├── a_part.rs
    │   │   │   ├── a_while.rs
    │   │   │   ├── addicting.rs
    │   │   │   ├── adjective_double_degree.rs
    │   │   │   ├── adjective_of_a.rs
    │   │   │   ├── after_later.rs
    │   │   │   ├── all_intents_and_purposes.rs
    │   │   │   ├── allow_to.rs
    │   │   │   ├── am_in_the_morning.rs
    │   │   │   ├── amounts_for.rs
    │   │   │   ├── an_a.rs
    │   │   │   ├── and_in.rs
    │   │   │   ├── and_the_like.rs
    │   │   │   ├── another_thing_coming.rs
    │   │   │   ├── another_think_coming.rs
    │   │   │   ├── apart_from.rs
    │   │   │   ├── ask_no_preposition.rs
    │   │   │   ├── avoid_curses.rs
    │   │   │   ├── back_in_the_day.rs
    │   │   │   ├── be_allowed.rs
    │   │   │   ├── behind_the_scenes.rs
    │   │   │   ├── best_of_all_time.rs
    │   │   │   ├── boring_words.rs
    │   │   │   ├── bought.rs
    │   │   │   ├── brand_brandish.rs
    │   │   │   ├── call_them.rs
    │   │   │   ├── cant.rs
    │   │   │   ├── capitalize_personal_pronouns.rs
    │   │   │   ├── cautionary_tale.rs
    │   │   │   ├── change_tack.rs
    │   │   │   ├── chock_full.rs
    │   │   │   ├── closed_compounds.rs
    │   │   │   ├── comma_fixes.rs
    │   │   │   ├── compound_subject_i.rs
    │   │   │   ├── confident.rs
    │   │   │   ├── correct_number_suffix.rs
    │   │   │   ├── criteria_phenomena.rs
    │   │   │   ├── cure_for.rs
    │   │   │   ├── currency_placement.rs
    │   │   │   ├── dashes.rs
    │   │   │   ├── despite_it_is.rs
    │   │   │   ├── despite_of.rs
    │   │   │   ├── determiner_without_noun.rs
    │   │   │   ├── didnt.rs
    │   │   │   ├── discourse_markers.rs
    │   │   │   ├── disjoint_prefixes.rs
    │   │   │   ├── dot_initialisms.rs
    │   │   │   ├── double_click.rs
    │   │   │   ├── double_modal.rs
    │   │   │   ├── ellipsis_length.rs
    │   │   │   ├── else_possessive.rs
    │   │   │   ├── ever_every.rs
    │   │   │   ├── everyday.rs
    │   │   │   ├── expand_memory_shorthands.rs
    │   │   │   ├── expand_time_shorthands.rs
    │   │   │   ├── expr_linter.rs
    │   │   │   ├── far_be_it.rs
    │   │   │   ├── fascinated_by.rs
    │   │   │   ├── feel_fell.rs
    │   │   │   ├── few_units_of_time_ago.rs
    │   │   │   ├── filler_words.rs
    │   │   │   ├── find_fine.rs
    │   │   │   ├── first_aid_kit.rs
    │   │   │   ├── flesh_out_vs_full_fledged.rs
    │   │   │   ├── for_noun.rs
    │   │   │   ├── free_predicate.rs
    │   │   │   ├── friend_of_me.rs
    │   │   │   ├── go_so_far_as_to.rs
    │   │   │   ├── good_at.rs
    │   │   │   ├── handful.rs
    │   │   │   ├── have_pronoun.rs
    │   │   │   ├── have_take_a_look.rs
    │   │   │   ├── hedging.rs
    │   │   │   ├── hello_greeting.rs
    │   │   │   ├── hereby.rs
    │   │   │   ├── hope_youre.rs
    │   │   │   ├── how_to.rs
    │   │   │   ├── hyphenate_number_day.rs
    │   │   │   ├── i_am_agreement.rs
    │   │   │   ├── if_wouldve.rs
    │   │   │   ├── in_on_the_cards.rs
    │   │   │   ├── inflected_verb_after_to.rs
    │   │   │   ├── initialism_linter.rs
    │   │   │   ├── initialisms.rs
    │   │   │   ├── interested_in.rs
    │   │   │   ├── it_is.rs
    │   │   │   ├── it_looks_like_that.rs
    │   │   │   ├── it_would_be.rs
    │   │   │   ├── its_possessive.rs
    │   │   │   ├── jealous_of.rs
    │   │   │   ├── johns_hopkins.rs
    │   │   │   ├── left_right_hand.rs
    │   │   │   ├── less_worse.rs
    │   │   │   ├── let_to_do.rs
    │   │   │   ├── likewise.rs
    │   │   │   ├── lint.rs
    │   │   │   ├── lint_group.rs
    │   │   │   ├── lint_kind.rs
    │   │   │   ├── long_sentences.rs
    │   │   │   ├── looking_forward_to.rs
    │   │   │   ├── map_phrase_linter.rs
    │   │   │   ├── map_phrase_set_linter.rs
    │   │   │   ├── merge_linters.rs
    │   │   │   ├── merge_words.rs
    │   │   │   ├── missing_preposition.rs
    │   │   │   ├── missing_space.rs
    │   │   │   ├── missing_to.rs
    │   │   │   ├── misspell.rs
    │   │   │   ├── mixed_bag.rs
    │   │   │   ├── mod.rs
    │   │   │   ├── modal_be_adjective.rs
    │   │   │   ├── modal_of.rs
    │   │   │   ├── modal_seem.rs
    │   │   │   ├── months.rs
    │   │   │   ├── more_adjective.rs
    │   │   │   ├── more_better.rs
    │   │   │   ├── most_number.rs
    │   │   │   ├── most_of_the_times.rs
    │   │   │   ├── multiple_sequential_pronouns.rs
    │   │   │   ├── nail_on_the_head.rs
    │   │   │   ├── need_to_noun.rs
    │   │   │   ├── no_french_spaces.rs
    │   │   │   ├── no_match_for.rs
    │   │   │   ├── no_oxford_comma.rs
    │   │   │   ├── nobody.rs
    │   │   │   ├── nominal_wants.rs
    │   │   │   ├── nor_modal_pronoun.rs
    │   │   │   ├── number_suffix_capitalization.rs
    │   │   │   ├── obsess_preposition.rs
    │   │   │   ├── of_course.rs
    │   │   │   ├── oldest_in_the_book.rs
    │   │   │   ├── on_floor.rs
    │   │   │   ├── once_or_twice.rs
    │   │   │   ├── one_and_the_same.rs
    │   │   │   ├── one_of_the_singular.rs
    │   │   │   ├── open_compounds.rs
    │   │   │   ├── open_the_light.rs
    │   │   │   ├── orthographic_consistency.rs
    │   │   │   ├── ought_to_be.rs
    │   │   │   ├── out_of_date.rs
    │   │   │   ├── oxford_comma.rs
    │   │   │   ├── oxymorons.rs
    │   │   │   ├── phrasal_verb_as_compound_noun.rs
    │   │   │   ├── pique_interest.rs
    │   │   │   ├── plural_wrong_word_of_phrase.rs
    │   │   │   ├── possessive_noun.rs
    │   │   │   ├── possessive_your.rs
    │   │   │   ├── progressive_needs_be.rs
    │   │   │   ├── pronoun_are.rs
    │   │   │   ├── pronoun_inflection_be.rs
    │   │   │   ├── pronoun_knew.rs
    │   │   │   ├── pronoun_verb_agreement.rs
    │   │   │   ├── proper_noun_capitalization_linters.rs
    │   │   │   ├── quantifier_needs_of.rs
    │   │   │   ├── quantifier_numeral_conflict.rs
    │   │   │   ├── quite_quiet.rs
    │   │   │   ├── quote_spacing.rs
    │   │   │   ├── redundant_acronyms.rs
    │   │   │   ├── redundant_additive_adverbs.rs
    │   │   │   ├── regionalisms.rs
    │   │   │   ├── repeated_words.rs
    │   │   │   ├── respond.rs
    │   │   │   ├── right_click.rs
    │   │   │   ├── roller_skated.rs
    │   │   │   ├── safe_to_save.rs
    │   │   │   ├── save_to_safe.rs
    │   │   │   ├── semicolon_apostrophe.rs
    │   │   │   ├── sentence_capitalization.rs
    │   │   │   ├── shoot_oneself_in_the_foot.rs
    │   │   │   ├── simple_past_to_past_participle.rs
    │   │   │   ├── since_duration.rs
    │   │   │   ├── single_be.rs
    │   │   │   ├── some_without_article.rs
    │   │   │   ├── something_is.rs
    │   │   │   ├── somewhat_something.rs
    │   │   │   ├── soon_to_be.rs
    │   │   │   ├── sought_after.rs
    │   │   │   ├── spaces.rs
    │   │   │   ├── spell_check.rs
    │   │   │   ├── spelled_numbers.rs
    │   │   │   ├── split_words.rs
    │   │   │   ├── subject_pronoun.rs
    │   │   │   ├── suggestion.rs
    │   │   │   ├── take_a_look_to.rs
    │   │   │   ├── take_medicine.rs
    │   │   │   ├── take_serious.rs
    │   │   │   ├── that_than.rs
    │   │   │   ├── that_which.rs
    │   │   │   ├── the_how_why.rs
    │   │   │   ├── the_my.rs
    │   │   │   ├── the_proper_noun_possessive.rs
    │   │   │   ├── then_than.rs
    │   │   │   ├── theres.rs
    │   │   │   ├── theses_these.rs
    │   │   │   ├── thing_think.rs
    │   │   │   ├── this_type_of_thing.rs
    │   │   │   ├── though_thought.rs
    │   │   │   ├── throw_away.rs
    │   │   │   ├── throw_rubbish.rs
    │   │   │   ├── to_adverb.rs
    │   │   │   ├── touristic.rs
    │   │   │   ├── transposed_space.rs
    │   │   │   ├── try_ones_hand_at.rs
    │   │   │   ├── unclosed_quotes.rs
    │   │   │   ├── update_place_names.rs
    │   │   │   ├── use_title_case.rs
    │   │   │   ├── verb_to_adjective.rs
    │   │   │   ├── very_unique.rs
    │   │   │   ├── vice_versa.rs
    │   │   │   ├── was_aloud.rs
    │   │   │   ├── way_too_adjective.rs
    │   │   │   ├── well_educated.rs
    │   │   │   ├── whereas.rs
    │   │   │   ├── whom_subject_of_verb.rs
    │   │   │   ├── widely_accepted.rs
    │   │   │   ├── win_prize.rs
    │   │   │   ├── wish_could.rs
    │   │   │   ├── wordpress_dotcom.rs
    │   │   │   ├── would_never_have.rs
    │   │   │   ├── compound_nouns/
    │   │   │   │   ├── compound_noun_after_det_adj.rs
    │   │   │   │   ├── compound_noun_after_possessive.rs
    │   │   │   │   ├── compound_noun_before_aux_verb.rs
    │   │   │   │   └── mod.rs
    │   │   │   ├── hop_hope/
    │   │   │   │   ├── mod.rs
    │   │   │   │   ├── to_hop.rs
    │   │   │   │   └── to_hope.rs
    │   │   │   ├── its_contraction/
    │   │   │   │   ├── general.rs
    │   │   │   │   ├── mod.rs
    │   │   │   │   └── proper_noun.rs
    │   │   │   ├── lets_confusion/
    │   │   │   │   ├── let_us_redundancy.rs
    │   │   │   │   ├── mod.rs
    │   │   │   │   └── no_contraction_with_verb.rs
    │   │   │   ├── mass_nouns/
    │   │   │   │   ├── mass_plurals.rs
    │   │   │   │   ├── mod.rs
    │   │   │   │   └── noun_countability.rs
    │   │   │   ├── noun_verb_confusion/
    │   │   │   │   ├── mod.rs
    │   │   │   │   ├── verb_instead_of_noun.rs
    │   │   │   │   ├── effect_affect/
    │   │   │   │   │   ├── affect_to_effect.rs
    │   │   │   │   │   ├── effect_to_affect.rs
    │   │   │   │   │   └── mod.rs
    │   │   │   │   └── noun_instead_of_verb/
    │   │   │   │       ├── general.rs
    │   │   │   │       └── mod.rs
    │   │   │   ├── phrase_set_corrections/
    │   │   │   │   └── mod.rs
    │   │   │   ├── pronoun_contraction/
    │   │   │   │   ├── avoid_contraction.rs
    │   │   │   │   ├── mod.rs
    │   │   │   │   └── should_contract.rs
    │   │   │   ├── to_two_too/
    │   │   │   │   ├── mod.rs
    │   │   │   │   ├── to_too_adjective_end.rs
    │   │   │   │   ├── to_too_adjective_punct.rs
    │   │   │   │   ├── to_too_adjverb_ed_punct.rs
    │   │   │   │   ├── to_too_adverb.rs
    │   │   │   │   ├── to_too_chunk_start_comma.rs
    │   │   │   │   ├── to_too_degree_words.rs
    │   │   │   │   ├── to_too_eos.rs
    │   │   │   │   ├── to_too_pronoun_end.rs
    │   │   │   │   └── too_to.rs
    │   │   │   ├── vicious_loop/
    │   │   │   │   └── mod.rs
    │   │   │   └── weir_rules/
    │   │   │       ├── ACoupleMore.weir
    │   │   │       ├── AdNauseam.weir
    │   │   │       ├── AfterAll.weir
    │   │   │       ├── AfterAWhile.weir
    │   │   │       ├── AheadAnd.weir
    │   │   │       ├── AllOfASudden.weir
    │   │   │       ├── Alongside.weir
    │   │   │       ├── ALongTime.weir
    │   │   │       ├── AlzheimersDisease.weir
    │   │   │       ├── AnAnother.weir
    │   │   │       ├── AnotherAn.weir
    │   │   │       ├── AnotherOnes.weir
    │   │   │       ├── AnotherThings.weir
    │   │   │       ├── AOkHyphen.weir
    │   │   │       ├── AsFarBackAs.weir
    │   │   │       ├── AsFollows.weir
    │   │   │       ├── AsIfThough.weir
    │   │   │       ├── AsItHappens.weir
    │   │   │       ├── AsLongAs.weir
    │   │   │       ├── AsOfCurrently.weir
    │   │   │       ├── AsOfLately.weir
    │   │   │       ├── AsOpposedTo.weir
    │   │   │       ├── AtFaceValue.weir
    │   │   │       ├── AtTheEndOfTheDay.weir
    │   │   │       ├── AvoidAndAlso.weir
    │   │   │       ├── BadRap.weir
    │   │   │       ├── BanTogether.weir
    │   │   │       ├── BareInMind.weir
    │   │   │       ├── BatedBreath.weir
    │   │   │       ├── BeckAndCall.weir
    │   │   │       ├── BeenThere.weir
    │   │   │       ├── Beforehand.weir
    │   │   │       ├── BesideThePoint.weir
    │   │   │       ├── BestRegards.weir
    │   │   │       ├── BetterOffWith.weir
    │   │   │       ├── BewareOf.weir
    │   │   │       ├── BlanketStatement.weir
    │   │   │       ├── Brutality.weir
    │   │   │       ├── BuiltIn.weir
    │   │   │       ├── ByAccident.weir
    │   │   │       ├── CanBeSeen.weir
    │   │   │       ├── CaseInPoint.weir
    │   │   │       ├── CaseSensitive.weir
    │   │   │       ├── CondenseAllThe.weir
    │   │   │       ├── CoursingThroughVeins.weir
    │   │   │       ├── Cybersec.weir
    │   │   │       ├── DampSquib.weir
    │   │   │       ├── DayAndAge.weir
    │   │   │       ├── DegreesKelvin.weir
    │   │   │       ├── DegreesKelvinSymbol.weir
    │   │   │       ├── DoIAdjective.weir
    │   │   │       ├── DoNotWant.weir
    │   │   │       ├── DontCan.weir
    │   │   │       ├── DoToDueTo.weir
    │   │   │       ├── DoubleNegative.weir
    │   │   │       ├── EachAndEveryOne.weir
    │   │   │       ├── EggYolk.weir
    │   │   │       ├── EludedTo.weir
    │   │   │       ├── EnMasse.weir
    │   │   │       ├── EnRoute.weir
    │   │   │       ├── EverPresent.weir
    │   │   │       ├── EverSince.weir
    │   │   │       ├── EveryOnceAndAgain.weir
    │   │   │       ├── EveryTime.weir
    │   │   │       ├── Excellent.weir
    │   │   │       ├── ExpandBecause.weir
    │   │   │       ├── ExpandForward.weir
    │   │   │       ├── ExpandMinimum.weir
    │   │   │       ├── ExpandPrevious.weir
    │   │   │       ├── ExpandWith.weir
    │   │   │       ├── ExpandWithout.weir
    │   │   │       ├── FaceFirst.weir
    │   │   │       ├── FairBit.weir
    │   │   │       ├── FarAndFewBetween.weir
    │   │   │       ├── FastPaste.weir
    │   │   │       ├── FatalOutcome.weir
    │   │   │       ├── FetalPosition.weir
    │   │   │       ├── ForALongTime.weir
    │   │   │       ├── ForAWhile.weir
    │   │   │       ├── FreeRein.weir
    │   │   │       ├── Freezing.weir
    │   │   │       ├── FromTheGetGo.weir
    │   │   │       ├── GildedAge.weir
    │   │   │       ├── GoingTo.weir
    │   │   │       ├── GuineaBissau.weir
    │   │   │       ├── HadOf.weir
    │   │   │       ├── HalfAnHour.weir
    │   │   │       ├── Haphazard.weir
    │   │   │       ├── HeartToHeard.weir
    │   │   │       ├── HeDos.weir
    │   │   │       ├── HowMach.weir
    │   │   │       ├── HumanBeings.weir
    │   │   │       ├── HumanLife.weir
    │   │   │       ├── HungerPang.weir
    │   │   │       ├── IAm.weir
    │   │   │       ├── IDo.weir
    │   │   │       ├── InAnyWay.weir
    │   │   │       ├── InAWhile.weir
    │   │   │       ├── Initiatively.weir
    │   │   │       ├── InLieuOf.weir
    │   │   │       ├── InNeedOf.weir
    │   │   │       ├── InOfItself.weir
    │   │   │       ├── InOneFellSwoop.weir
    │   │   │       ├── Insensitive.weir
    │   │   │       ├── InsteadOf.weir
    │   │   │       ├── Insurmountable.weir
    │   │   │       ├── Intact.weir
    │   │   │       ├── InThe.weir
    │   │   │       ├── IsKnownFor.weir
    │   │   │       ├── ItCan.weir
    │   │   │       ├── IveGotTo.weir
    │   │   │       ├── JawDropping.weir
    │   │   │       ├── JustDeserts.weir
    │   │   │       ├── KindOf.weir
    │   │   │       ├── KindRegards.weir
    │   │   │       ├── LastButNotLeast.weir
    │   │   │       ├── LastDitch.weir
    │   │   │       ├── LastNight.weir
    │   │   │       ├── LaughOfAt.weir
    │   │   │       ├── LeaveToFor.weir
    │   │   │       ├── LetAlone.weir
    │   │   │       ├── LikeAsIf.weir
    │   │   │       ├── LikeThePlague.weir
    │   │   │       ├── LinesOfCode.weir
    │   │   │       ├── LooksLikes.weir
    │   │   │       ├── LowHangingFruit.weir
    │   │   │       ├── ManagerialReins.weir
    │   │   │       ├── mod.rs
    │   │   │       ├── Monumentous.weir
    │   │   │       ├── MyHouse.weir
    │   │   │       ├── NeedHelp.weir
    │   │   │       ├── NerveRacking.weir
    │   │   │       ├── NotIn.weir
    │   │   │       ├── NotTo.weir
    │   │   │       ├── OfCourse.weir
    │   │   │       ├── OffTheCuff.weir
    │   │   │       ├── OldWivesTale.weir
    │   │   │       ├── OnceInAWhile.weir
    │   │   │       ├── OnSecondThought.weir
    │   │   │       ├── OnTheSpurOfTheMoment.weir
    │   │   │       ├── OnTopOf.weir
    │   │   │       ├── PartsOfSpeech.weir
    │   │   │       ├── PasswordProtectedHyphen.weir
    │   │   │       ├── PeaceOfMind.weir
    │   │   │       ├── PedalToTheMetal.weir
    │   │   │       ├── PerSe.weir
    │   │   │       ├── PointsOfView.weir
    │   │   │       ├── PortAuPrince.weir
    │   │   │       ├── PortoNovo.weir
    │   │   │       ├── PrayingMantis.weir
    │   │   │       ├── QuiteMany.weir
    │   │   │       ├── RainbowColoredHyphen.weir
    │   │   │       ├── RallyToReally.weir
    │   │   │       ├── RapidFire.weir
    │   │   │       ├── RealTrouper.weir
    │   │   │       ├── RedundantIIRC.weir
    │   │   │       ├── RedundantPretty.weir
    │   │   │       ├── RedundantThat.weir
    │   │   │       ├── RifeWith.weir
    │   │   │       ├── RoadMap.weir
    │   │   │       ├── RulesOfThumb.weir
    │   │   │       ├── SameAs.weir
    │   │   │       ├── ScantilyClad.weir
    │   │   │       ├── SendAnEmailTo.weir
    │   │   │       ├── SimpleGrammatical.weir
    │   │   │       ├── SneakingSuspicion.weir
    │   │   │       ├── SomebodyElses.weir
    │   │   │       ├── SomeOfThe.weir
    │   │   │       ├── SoonerOrLater.weir
    │   │   │       ├── SpecialAttention.weir
    │   │   │       ├── Starving.weir
    │   │   │       ├── StateOfTheArt.weir
    │   │   │       ├── StatuteOfLimitations.weir
    │   │   │       ├── SufficeItToSay.weir
    │   │   │       ├── SupposedTo.weir
    │   │   │       ├── TakeItPersonally.weir
    │   │   │       ├── ThanksALot.weir
    │   │   │       ├── ThatChallenged.weir
    │   │   │       ├── ThatThis.weir
    │   │   │       ├── The.weir
    │   │   │       ├── TheAnother.weir
    │   │   │       ├── TheirToThere.weir
    │   │   │       ├── TheirToTheyre.weir
    │   │   │       ├── ThereToTheir.weir
    │   │   │       ├── TheyreToTheir.weir
    │   │   │       ├── ThoughtProcess.weir
    │   │   │       ├── TickingTimeClock.weir
    │   │   │       ├── ToDoHyphen.weir
    │   │   │       ├── ToGreatLengths.weir
    │   │   │       ├── ToLoseTooLoose.weir
    │   │   │       ├── TongueInCheek.weir
    │   │   │       ├── ToTheMannerBorn.weir
    │   │   │       ├── Towards.weir
    │   │   │       ├── ToWorryAbout.weir
    │   │   │       ├── TrialAndError.weir
    │   │   │       ├── TrueToWord.weir
    │   │   │       ├── TurnItOff.weir
    │   │   │       ├── Unless.weir
    │   │   │       ├── VeryLess.weir
    │   │   │       ├── WantBe.weir
    │   │   │       ├── WaveFunction.weir
    │   │   │       ├── WellBeing.weir
    │   │   │       ├── WellKept.weir
    │   │   │       ├── WhetYourAppetite.weir
    │   │   │       ├── WillContain.weir
    │   │   │       ├── WithoutOut.weir
    │   │   │       ├── WorstCaseScenario.weir
    │   │   │       ├── WroughtIron.weir
    │   │   │       ├── YeaToYeah.weir
    │   │   │       └── YehToYeah.weir
    │   │   ├── mask/
    │   │   │   └── mod.rs
    │   │   ├── parsers/
    │   │   │   ├── collapse_identifiers.rs
    │   │   │   ├── isolate_english.rs
    │   │   │   ├── markdown.rs
    │   │   │   ├── mask.rs
    │   │   │   ├── mod.rs
    │   │   │   ├── oops_all_headings.rs
    │   │   │   ├── org_mode.rs
    │   │   │   └── plain_english.rs
    │   │   ├── patterns/
    │   │   │   ├── any_pattern.rs
    │   │   │   ├── derived_from.rs
    │   │   │   ├── implies_quantity.rs
    │   │   │   ├── indefinite_article.rs
    │   │   │   ├── inflection_of_be.rs
    │   │   │   ├── invert.rs
    │   │   │   ├── mod.rs
    │   │   │   ├── modal_verb.rs
    │   │   │   ├── nominal_phrase.rs
    │   │   │   ├── prepositional_preceder.rs
    │   │   │   ├── upos_set.rs
    │   │   │   ├── whitespace_pattern.rs
    │   │   │   ├── within_edit_distance.rs
    │   │   │   ├── word.rs
    │   │   │   └── word_set.rs
    │   │   ├── spell/
    │   │   │   ├── dictionary.rs
    │   │   │   ├── fst_dictionary.rs
    │   │   │   ├── merged_dictionary.rs
    │   │   │   ├── mod.rs
    │   │   │   ├── mutable_dictionary.rs
    │   │   │   ├── trie_dictionary.rs
    │   │   │   ├── word_id.rs
    │   │   │   ├── word_map.rs
    │   │   │   └── rune/
    │   │   │       ├── affix_replacement.rs
    │   │   │       ├── attribute_list.rs
    │   │   │       ├── error.rs
    │   │   │       ├── expansion.rs
    │   │   │       ├── matcher.rs
    │   │   │       ├── mod.rs
    │   │   │       └── word_list.rs
    │   │   └── weir/
    │   │       ├── ast.rs
    │   │       ├── error.rs
    │   │       ├── mod.rs
    │   │       ├── optimize.rs
    │   │       └── parsing/
    │   │           ├── expr.rs
    │   │           ├── mod.rs
    │   │           └── stmt.rs
    │   └── tests/
    │       ├── linters.rs
    │       ├── pos_tags.rs
    │       ├── run_tests.rs
    │       ├── snapshot.rs
    │       ├── test_sources/
    │       │   ├── amazon_hostname.md
    │       │   ├── chinese_lorem_ipsum.md
    │       │   ├── hex_basic_clean.md
    │       │   ├── hex_basic_dirty.md
    │       │   ├── index.org
    │       │   ├── issue_109.md
    │       │   ├── issue_109_ext.md
    │       │   ├── issue_118.md
    │       │   ├── issue_1581.md
    │       │   ├── issue_159.md
    │       │   ├── issue_1873.md
    │       │   ├── issue_195.md
    │       │   ├── issue_1988.md
    │       │   ├── issue_2054.md
    │       │   ├── issue_2054_clean.md
    │       │   ├── issue_2151.md
    │       │   ├── issue_2233.md
    │       │   ├── issue_2240.md
    │       │   ├── issue_2246.md
    │       │   ├── issue_267.md
    │       │   ├── issue_358.md
    │       │   ├── lots_of_latin.md
    │       │   ├── lukas_homework.md
    │       │   ├── misc_closed_compound_clean.md
    │       │   ├── obsidian_links.md
    │       │   ├── pr_452.md
    │       │   ├── pr_504.md
    │       │   ├── proper_noun_capitalization.md
    │       │   ├── statist_localist.md
    │       │   ├── title_case_clean.md
    │       │   ├── title_case_errors.md
    │       │   ├── whack_bullets.md
    │       │   └── yogurt_british_clean.md
    │       └── text/
    │           ├── Computer science.md
    │           ├── Difficult sentences.md
    │           ├── Part-of-speech tagging.md
    │           ├── Spell.md
    │           ├── Spell.US.md
    │           ├── Swear.md
    │           ├── The Constitution of the United States.md
    │           ├── this and that.md
    │           ├── linters/
    │           │   ├── Computer science.snap.yml
    │           │   ├── Difficult sentences.snap.yml
    │           │   ├── Part-of-speech tagging.snap.yml
    │           │   ├── Spell.snap.yml
    │           │   ├── Spell.US.snap.yml
    │           │   ├── Swear.snap.yml
    │           │   └── this and that.snap.yml
    │           └── tagged/
    │               ├── Difficult sentences.md
    │               ├── Part-of-speech tagging.md
    │               ├── Spell.md
    │               ├── Spell.US.md
    │               ├── Swear.md
    │               └── this and that.md
    ├── harper-html/
    │   ├── Cargo.toml
    │   ├── src/
    │   │   └── lib.rs
    │   └── tests/
    │       ├── run_tests.rs
    │       └── test_sources/
    │           ├── issue_156.html
    │           ├── issue_541.html
    │           └── run_on.html
    ├── harper-ink/
    │   ├── Cargo.toml
    │   ├── src/
    │   │   └── lib.rs
    │   └── tests/
    │       ├── run_tests.rs
    │       └── test_sources/
    │           ├── bad.ink
    │           └── good.ink
    ├── harper-jjdescription/
    │   ├── Cargo.toml
    │   ├── src/
    │   │   └── lib.rs
    │   └── tests/
    │       ├── run_tests.rs
    │       └── test_sources/
    │           ├── complex_verbose_description.txt
    │           ├── conventional_description.txt
    │           └── simple_description.txt
    ├── harper-literate-haskell/
    │   ├── Cargo.toml
    │   ├── src/
    │   │   ├── lib.rs
    │   │   └── masker.rs
    │   └── tests/
    │       ├── run_tests.rs
    │       └── test_sources/
    │           ├── bird_format.lhs
    │           ├── latex_format.lhs
    │           └── mixed_format.lhs
    ├── harper-ls/
    │   ├── README.md
    │   ├── Cargo.toml
    │   └── src/
    │       ├── backend.rs
    │       ├── config.rs
    │       ├── diagnostics.rs
    │       ├── dictionary_io.rs
    │       ├── document_state.rs
    │       ├── git_commit_parser.rs
    │       ├── ignored_lints_io.rs
    │       ├── io_utils.rs
    │       ├── main.rs
    │       └── pos_conv.rs
    ├── harper-pos-utils/
    │   ├── Cargo.toml
    │   └── src/
    │       ├── conllu_utils.rs
    │       ├── lib.rs
    │       ├── patch_criteria.rs
    │       ├── upos.rs
    │       ├── word_counter.rs
    │       ├── chunker/
    │       │   ├── burn_chunker.rs
    │       │   ├── cached_chunker.rs
    │       │   ├── mod.rs
    │       │   ├── np_extraction.rs
    │       │   ├── upos_freq_dict.rs
    │       │   └── brill_chunker/
    │       │       ├── mod.rs
    │       │       └── patch.rs
    │       └── tagger/
    │           ├── error_counter.rs
    │           ├── freq_dict.rs
    │           ├── freq_dict_builder.rs
    │           ├── mod.rs
    │           └── brill_tagger/
    │               ├── mod.rs
    │               └── patch.rs
    ├── harper-python/
    │   ├── Cargo.toml
    │   ├── src/
    │   │   └── lib.rs
    │   └── tests/
    │       ├── run_tests.rs
    │       └── test_sources/
    │           ├── comments.py
    │           ├── docstrings.py
    │           └── field_docstrings.py
    ├── harper-stats/
    │   ├── README.md
    │   ├── Cargo.toml
    │   └── src/
    │       ├── lib.rs
    │       ├── record.rs
    │       └── summary.rs
    ├── harper-thesaurus/
    │   ├── build.rs
    │   ├── Cargo.toml
    │   ├── clippy.toml
    │   └── src/
    │       ├── lib.rs
    │       └── thesaurus.rs
    ├── harper-tree-sitter/
    │   ├── Cargo.toml
    │   └── src/
    │       └── lib.rs
    ├── harper-typst/
    │   ├── Cargo.toml
    │   ├── src/
    │   │   ├── lib.rs
    │   │   ├── offset_cursor.rs
    │   │   └── typst_translator.rs
    │   └── tests/
    │       ├── run_tests.rs
    │       ├── tests.rs
    │       └── test_sources/
    │           ├── complex_document.typ
    │           ├── complex_document_with_spelling_mistakes.typ
    │           ├── contractions.typ
    │           ├── function_with_ignorable_args.typ
    │           ├── issue_1926.typ
    │           ├── issue_399.typ
    │           └── simplified_document.typ
    ├── harper-wasm/
    │   ├── README.md
    │   ├── Cargo.toml
    │   └── src/
    │       └── lib.rs
    ├── packages/
    │   ├── chrome-plugin/
    │   │   ├── app.css
    │   │   ├── CHANGELOG.md
    │   │   ├── LICENSE
    │   │   ├── options.html
    │   │   ├── package.json
    │   │   ├── playwright.config.ts
    │   │   ├── popup.html
    │   │   ├── sidepanel.html
    │   │   ├── tsconfig.json
    │   │   ├── tsconfig.node.json
    │   │   ├── vite.config.ts
    │   │   ├── .editorconfig
    │   │   ├── .npmignore
    │   │   ├── src/
    │   │   │   ├── generateGreeting.ts
    │   │   │   ├── global.d.ts
    │   │   │   ├── isWordPress.ts
    │   │   │   ├── manifest.ts
    │   │   │   ├── PopupState.ts
    │   │   │   ├── protocol.ts
    │   │   │   ├── ProtocolClient.ts
    │   │   │   ├── theme.ts
    │   │   │   ├── zip.js
    │   │   │   ├── background/
    │   │   │   │   ├── detectDialect.ts
    │   │   │   │   └── index.ts
    │   │   │   ├── contentScript/
    │   │   │   │   └── index.ts
    │   │   │   ├── options/
    │   │   │   │   ├── index.ts
    │   │   │   │   └── Options.svelte
    │   │   │   └── popup/
    │   │   │       ├── index.ts
    │   │   │       ├── Main.svelte
    │   │   │       ├── Onboarding.svelte
    │   │   │       ├── Popup.svelte
    │   │   │       └── ReportProblematicLint.svelte
    │   │   └── tests/
    │   │       ├── draft.spec.ts
    │   │       ├── fixtures.ts
    │   │       ├── github.spec.ts
    │   │       ├── hn.spec.ts
    │   │       ├── lexical.spec.ts
    │   │       ├── lexical_webcomponent.spec.ts
    │   │       ├── lint-kinds.spec.ts
    │   │       ├── nested_elements.spec.ts
    │   │       ├── prosemirror.spec.ts
    │   │       ├── quill.spec.ts
    │   │       ├── review_banner.spec.ts
    │   │       ├── simple_inputs_disabled.spec.ts
    │   │       ├── simple_textarea.spec.ts
    │   │       ├── slate.spec.ts
    │   │       ├── testUtils.ts
    │   │       └── pages/
    │   │           ├── lexical_webcomponent.html
    │   │           ├── nested_elements.html
    │   │           ├── simple_inputs_disabled.html
    │   │           └── simple_textarea.html
    │   ├── components/
    │   │   ├── package.json
    │   │   ├── svelte.config.js
    │   │   ├── tsconfig.json
    │   │   ├── vite.config.ts
    │   │   ├── .npmrc
    │   │   └── src/
    │   │       ├── app.d.ts
    │   │       ├── app.html
    │   │       ├── lib/
    │   │       │   ├── Button.svelte
    │   │       │   ├── Card.svelte
    │   │       │   ├── Collapsible.svelte
    │   │       │   ├── index.ts
    │   │       │   ├── Input.svelte
    │   │       │   ├── Link.svelte
    │   │       │   ├── Select.svelte
    │   │       │   ├── styles.css
    │   │       │   └── Textarea.svelte
    │   │       └── routes/
    │   │           ├── +layout.svelte
    │   │           ├── +page.svelte
    │   │           └── layout.css
    │   ├── harper.js/
    │   │   ├── README.md
    │   │   ├── api-extractor.json
    │   │   ├── docs.sh
    │   │   ├── package.json
    │   │   ├── renderPage.js
    │   │   ├── tsconfig.json
    │   │   ├── vite.config.ts
    │   │   ├── examples/
    │   │   │   ├── commonjs-simple/
    │   │   │   │   ├── README.md
    │   │   │   │   ├── index.js
    │   │   │   │   └── package.json
    │   │   │   └── raw-web/
    │   │   │       ├── README.md
    │   │   │       └── index.html
    │   │   └── src/
    │   │       ├── binary.ts
    │   │       ├── Linter.bench.ts
    │   │       ├── Linter.test.ts
    │   │       ├── Linter.ts
    │   │       ├── LocalLinter.ts
    │   │       ├── main.ts
    │   │       ├── Serializer.test.ts
    │   │       ├── Serializer.ts
    │   │       ├── Summary.ts
    │   │       ├── utils.ts
    │   │       └── WorkerLinter/
    │   │           ├── index.ts
    │   │           ├── shims.ts
    │   │           └── worker.ts
    │   ├── lint-framework/
    │   │   ├── README.md
    │   │   ├── package.json
    │   │   ├── tsconfig.json
    │   │   ├── vite.config.ts
    │   │   └── src/
    │   │       ├── index.ts
    │   │       ├── assets/
    │   │       │   ├── bookDownSvg.ts
    │   │       │   └── hints.json
    │   │       └── lint/
    │   │           ├── Box.ts
    │   │           ├── computeLintBoxes.ts
    │   │           ├── domUtils.ts
    │   │           ├── editorUtils.ts
    │   │           ├── Highlights.ts
    │   │           ├── LintFramework.ts
    │   │           ├── lintKindColor.ts
    │   │           ├── PopupHandler.ts
    │   │           ├── RenderBox.ts
    │   │           ├── SourceElement.ts
    │   │           ├── SuggestionBox.ts
    │   │           ├── TextFieldRange.ts
    │   │           ├── unpackLint.ts
    │   │           └── utils.ts
    │   ├── obsidian-plugin/
    │   │   ├── README.md
    │   │   ├── package.json
    │   │   ├── vite.config.ts
    │   │   └── src/
    │   │       ├── HarperSettingTab.ts
    │   │       ├── index.ts
    │   │       ├── lint.ts
    │   │       ├── State.test.ts
    │   │       ├── State.ts
    │   │       ├── textUtils.test.ts
    │   │       └── textUtils.ts
    │   ├── vscode-plugin/
    │   │   ├── README.md
    │   │   ├── development-guide.md
    │   │   ├── esbuild.cjs
    │   │   ├── tsconfig.json
    │   │   ├── .vscodeignore
    │   │   ├── media/
    │   │   │   └── harper.woff
    │   │   └── src/
    │   │       ├── extension.ts
    │   │       └── tests/
    │   │           ├── runTests.ts
    │   │           ├── fixtures/
    │   │           │   ├── integration.md
    │   │           │   └── languages/
    │   │           │       ├── c.c
    │   │           │       ├── CMakeLists.txt
    │   │           │       ├── cpp.cpp
    │   │           │       ├── cpp.h
    │   │           │       ├── csharp.cs
    │   │           │       ├── dart.dart
    │   │           │       ├── git-commit
    │   │           │       ├── go.go
    │   │           │       ├── haskell.hs
    │   │           │       ├── html.html
    │   │           │       ├── java.java
    │   │           │       ├── javascript.js
    │   │           │       ├── javascriptreact.jsx
    │   │           │       ├── literate-haskell.lhs
    │   │           │       ├── lua.lua
    │   │           │       ├── nix.nix
    │   │           │       ├── php.php
    │   │           │       ├── plaintext
    │   │           │       ├── plaintext.txt
    │   │           │       ├── python.py
    │   │           │       ├── ruby.rb
    │   │           │       ├── rust.rs
    │   │           │       ├── shellscript
    │   │           │       ├── shellscript.bash
    │   │           │       ├── shellscript.sh
    │   │           │       ├── solidity.sol
    │   │           │       ├── swift.swift
    │   │           │       ├── toml.toml
    │   │           │       ├── typescript.ts
    │   │           │       ├── typescriptreact.tsx
    │   │           │       └── typst.typ
    │   │           └── suite/
    │   │               ├── helper.ts
    │   │               ├── index.ts
    │   │               ├── integration.test.ts
    │   │               └── languages.test.ts
    │   ├── web/
    │   │   ├── README.md
    │   │   ├── demo_wp_blueprint.json
    │   │   ├── drizzle.config.ts
    │   │   ├── package.json
    │   │   ├── svelte.config.js
    │   │   ├── tailwind.config.js
    │   │   ├── tsconfig.json
    │   │   ├── vite.config.ts
    │   │   ├── .dockerignore
    │   │   ├── drizzle/
    │   │   │   ├── 0000_cute_zuras.sql
    │   │   │   ├── 0001_blushing_corsair.sql
    │   │   │   ├── 0002_blushing_chameleon.sql
    │   │   │   └── meta/
    │   │   │       ├── 0000_snapshot.json
    │   │   │       ├── 0001_snapshot.json
    │   │   │       ├── 0002_snapshot.json
    │   │   │       └── _journal.json
    │   │   ├── src/
    │   │   │   ├── app.css
    │   │   │   ├── app.d.ts
    │   │   │   ├── app.html
    │   │   │   ├── hooks.server.ts
    │   │   │   ├── lib/
    │   │   │   │   ├── GitHubClient.ts
    │   │   │   │   ├── components/
    │   │   │   │   │   ├── AutomatticLogo.svelte
    │   │   │   │   │   ├── ChromeLogo.svelte
    │   │   │   │   │   ├── CodeLogo.svelte
    │   │   │   │   │   ├── DefaultNeovimConfig.svelte
    │   │   │   │   │   ├── EdgeLogo.svelte
    │   │   │   │   │   ├── Editor.svelte
    │   │   │   │   │   ├── EmacsLogo.svelte
    │   │   │   │   │   ├── FirefoxLogo.svelte
    │   │   │   │   │   ├── GitHubLogo.svelte
    │   │   │   │   │   ├── Graph.svelte
    │   │   │   │   │   ├── GutterCenter.svelte
    │   │   │   │   │   ├── HelixLogo.svelte
    │   │   │   │   │   ├── Isolate.svelte
    │   │   │   │   │   ├── LazyEditor.svelte
    │   │   │   │   │   ├── LintCard.svelte
    │   │   │   │   │   ├── LintKindChart.svelte
    │   │   │   │   │   ├── LintSidebar.svelte
    │   │   │   │   │   ├── Logo.svelte
    │   │   │   │   │   ├── NeovimLogo.svelte
    │   │   │   │   │   ├── ObsidianLogo.svelte
    │   │   │   │   │   ├── Section.svelte
    │   │   │   │   │   ├── SublimeLogo.svelte
    │   │   │   │   │   ├── Testimonial.svelte
    │   │   │   │   │   ├── TestimonialCollection.svelte
    │   │   │   │   │   ├── WordPressLogo.svelte
    │   │   │   │   │   └── ZedLogo.svelte
    │   │   │   │   └── db/
    │   │   │   │       ├── index.ts
    │   │   │   │       ├── schema.ts
    │   │   │   │       └── models/
    │   │   │   │           ├── ProblematicLints.ts
    │   │   │   │           └── UninstallFeedback.ts
    │   │   │   └── routes/
    │   │   │       ├── +layout.svelte
    │   │   │       ├── +page.svelte
    │   │   │       ├── api/
    │   │   │       │   ├── problematic-lints/
    │   │   │       │   │   └── +server.ts
    │   │   │       │   └── uninstall-feedback/
    │   │   │       │       └── +server.ts
    │   │   │       ├── cache-healthcheck/
    │   │   │       │   └── +server.ts
    │   │   │       ├── docs/
    │   │   │       │   ├── about/
    │   │   │       │   │   ├── +page.md
    │   │   │       │   │   └── +page.ts
    │   │   │       │   ├── contributors/
    │   │   │       │   │   ├── architecture/
    │   │   │       │   │   │   └── +page.md
    │   │   │       │   │   ├── author-a-rule/
    │   │   │       │   │   │   └── +page.md
    │   │   │       │   │   ├── brill/
    │   │   │       │   │   │   └── +page.md
    │   │   │       │   │   ├── chrome-extension/
    │   │   │       │   │   │   └── +page.md
    │   │   │       │   │   ├── committing/
    │   │   │       │   │   │   └── +page.md
    │   │   │       │   │   ├── dictionary/
    │   │   │       │   │   │   └── +page.md
    │   │   │       │   │   ├── environment/
    │   │   │       │   │   │   └── +page.md
    │   │   │       │   │   ├── faq/
    │   │   │       │   │   │   └── +page.md
    │   │   │       │   │   ├── introduction/
    │   │   │       │   │   │   └── +page.md
    │   │   │       │   │   ├── local-stats/
    │   │   │       │   │   │   └── +page.md
    │   │   │       │   │   ├── obsidian/
    │   │   │       │   │   │   └── +page.md
    │   │   │       │   │   ├── review/
    │   │   │       │   │   │   └── +page.md
    │   │   │       │   │   ├── tests/
    │   │   │       │   │   │   └── +page.md
    │   │   │       │   │   ├── visual-studio-code/
    │   │   │       │   │   │   └── +page.md
    │   │   │       │   │   └── wordpress/
    │   │   │       │   │       └── +page.md
    │   │   │       │   ├── harperjs/
    │   │   │       │   │   ├── CDN/
    │   │   │       │   │   │   ├── +page.md
    │   │   │       │   │   │   └── example/
    │   │   │       │   │   │       └── +server.ts
    │   │   │       │   │   ├── configurerules/
    │   │   │       │   │   │   └── +page.md
    │   │   │       │   │   ├── introduction/
    │   │   │       │   │   │   └── +page.md
    │   │   │       │   │   ├── linting/
    │   │   │       │   │   │   └── +page.md
    │   │   │       │   │   ├── node/
    │   │   │       │   │   │   └── +page.md
    │   │   │       │   │   └── spans/
    │   │   │       │   │       └── +page.md
    │   │   │       │   ├── integrations/
    │   │   │       │   │   ├── chrome-extension/
    │   │   │       │   │   │   └── +page.md
    │   │   │       │   │   ├── emacs/
    │   │   │       │   │   │   └── +page.md
    │   │   │       │   │   ├── firefox-extension/
    │   │   │       │   │   │   └── +page.md
    │   │   │       │   │   ├── helix/
    │   │   │       │   │   │   └── +page.md
    │   │   │       │   │   ├── language-server/
    │   │   │       │   │   │   └── +page.md
    │   │   │       │   │   ├── neovim/
    │   │   │       │   │   │   └── +page.md
    │   │   │       │   │   ├── obsidian/
    │   │   │       │   │   │   └── +page.md
    │   │   │       │   │   ├── sublime-text/
    │   │   │       │   │   │   └── +page.md
    │   │   │       │   │   ├── visual-studio-code/
    │   │   │       │   │   │   └── +page.md
    │   │   │       │   │   ├── wordpress/
    │   │   │       │   │   │   └── +page.md
    │   │   │       │   │   └── zed/
    │   │   │       │   │       └── +page.md
    │   │   │       │   ├── rules/
    │   │   │       │   │   └── +page.svelte
    │   │   │       │   └── weir/
    │   │   │       │       └── +page.md
    │   │   │       ├── editor/
    │   │   │       │   ├── +page.svelte
    │   │   │       │   └── +page.ts
    │   │   │       ├── install-browser-extension/
    │   │   │       │   └── +page.svelte
    │   │   │       ├── languagedetection/
    │   │   │       │   └── +page.svelte
    │   │   │       ├── latestversion/
    │   │   │       │   └── +server.ts
    │   │   │       ├── presentation/
    │   │   │       │   └── +page.svelte
    │   │   │       ├── report-problematic-lint/
    │   │   │       │   └── +page.svelte
    │   │   │       ├── request-browser-support/
    │   │   │       │   └── +page.svelte
    │   │   │       ├── stats/
    │   │   │       │   └── +page.svelte
    │   │   │       ├── titlecase/
    │   │   │       │   └── +page.svelte
    │   │   │       ├── uninstall-browser-extension/
    │   │   │       │   └── +page.svelte
    │   │   │       └── wpdemo/
    │   │   │           └── +page.server.ts
    │   │   └── static/
    │   │       ├── browserconfig.xml
    │   │       ├── site.webmanifest
    │   │       └── images/
    │   │           ├── obsidian_screenshot.webp
    │   │           └── vscode_harper_path.webp
    │   └── wordpress-plugin/
    │       ├── README.md
    │       ├── harper.php
    │       ├── package.json
    │       ├── .editorconfig
    │       └── src/
    │           └── harper/
    │               ├── block.json
    │               ├── Box.ts
    │               ├── DataBlock.ts
    │               ├── DialectSelectRow.tsx
    │               ├── domUtils.ts
    │               ├── Highlighter.tsx
    │               ├── index.css
    │               ├── index.tsx
    │               ├── LinterProvider.tsx
    │               ├── LintList.tsx
    │               ├── LintListItem.tsx
    │               ├── LintSettingList.tsx
    │               ├── LintSettingRow.tsx
    │               ├── lintUtils.ts
    │               ├── Logo.jsx
    │               ├── RichText.ts
    │               ├── SidebarControl.tsx
    │               ├── SidebarTabContainer.tsx
    │               ├── SuggestionControl.tsx
    │               ├── useDialect.ts
    │               ├── useIgnoredLintState.ts
    │               ├── useLintBoxes.ts
    │               ├── useLintConfig.ts
    │               ├── usePersonalDictionary.ts
    │               └── useToggle.ts
    └── .github/
        ├── dependabot.yml
        ├── pull_request_template.md
        ├── ISSUE_TEMPLATE/
        │   ├── bug_report.md
        │   ├── report-false-positive.md
        │   ├── report-grammatical-error.md
        │   └── suggest-a-feature.md
        └── workflows/
            ├── binaries.yml
            ├── build_web.yml
            ├── chrome_plugin.yml
            ├── just_checks.yml
            ├── stale.yml
            ├── vscode_plugin.yml
            └── wp_plugin.yml

================================================
FILE: README.md
================================================
<div id="header" align="center">
    <img src="logo.svg" width="400px" />
    <h1>Harper</h1>
</div>

[![Harper Binaries](https://github.com/automattic/harper/actions/workflows/binaries.yml/badge.svg)](https://github.com/automattic/harper/actions/workflows/binaries.yml)
[![Website](https://github.com/automattic/harper/actions/workflows/build_web.yml/badge.svg)](https://github.com/automattic/harper/actions/workflows/build_web.yml)
[![Checks](https://github.com/automattic/harper/actions/workflows/just_checks.yml/badge.svg)](https://github.com/automattic/harper/actions/workflows/just_checks.yml)
[![Crates.io](https://img.shields.io/crates/v/harper-ls)](https://crates.io/crates/harper-ls)
![NPM Version](https://img.shields.io/npm/v/harper.js)
![Downloads](https://img.shields.io/github/downloads/automattic/harper/total?label=Binary+Downloads)
![Obsidian Plugin Downloads](https://img.shields.io/github/downloads/automattic/harper-obsidian-plugin/total?label=Obsidian+Plugin+Downloads)

Harper is an English grammar checker designed to be _just right._
I created it after years of dealing with the shortcomings of the competition.

Grammarly was too expensive and too overbearing.
Its suggestions lacked context, and were often just plain _wrong_.
Not to mention: it's a privacy nightmare.
Everything you write with Grammarly is sent to their servers.
Their privacy policy claims they don't sell the data, but that doesn't mean they don't use it to train large language models and god knows what else.
Not only that, but the round-trip-time of the network request makes revising your work all the more tedious.

LanguageTool is great, if you have gigabytes of RAM to spare and are willing to download the ~16GB n-gram dataset.
Besides the memory requirements, I found LanguageTool too slow: it would take several seconds to lint even a moderate-size document.

That's why I created Harper: it is the grammar checker that fits my needs.
Not only does it take milliseconds to lint a document, take less than 1/50th of LanguageTool's memory footprint,
but it is also completely private.

Harper is even small enough to load via [WebAssembly.](https://writewithharper.com)

## Language Support

Harper currently only supports English, but the core is extensible to support other languages, so we welcome contributions that allow for other language support.

## Performance Issues

We consider long lint times bugs.
If you encounter any significant performance issues, please create an issue on the topic.

If you find a fix to any performance issue, we would appreciate the contribution.
Just please make sure to read [our contribution guidelines first.](https://github.com/automattic/harper/blob/master/CONTRIBUTING.md)

## Links

- [Frequently Asked Questions](https://writewithharper.com/#faqs)
- [Obsidian Documentation](https://writewithharper.com/docs/integrations/obsidian)
- [`harper-ls` Documentation](https://writewithharper.com/docs/integrations/language-server)
- Supported Editors' Documentation
  - [Visual Studio Code](https://writewithharper.com/docs/integrations/visual-studio-code)
  - [Neovim](https://writewithharper.com/docs/integrations/neovim)
  - [Helix](https://writewithharper.com/docs/integrations/helix)
  - [Emacs](https://writewithharper.com/docs/integrations/emacs)
  - [Zed](https://writewithharper.com/docs/integrations/zed)
- [`harper.js` Documentation](https://writewithharper.com/docs/harperjs/introduction)
- [Official Discord Server](https://discord.com/invite/JBqcAaKrzQ)

## Huge Thanks

This project would not be possible without the hard work from those who [contribute](https://writewithharper.com/docs/contributors/introduction).

<a href="https://github.com/automattic/harper/graphs/contributors">
  <img src="https://contrib.rocks/image?repo=automattic/harper" />
</a>

Harper's logo was designed by [Lukas Werner](https://lukaswerner.com/).



================================================
FILE: ARCHITECTURE.md
================================================
# Harper's Architecture

This document has been moved to the [online documentation](https://writewithharper.com/docs/contributors/architecture).



================================================
FILE: biome.json
================================================
{
	"$schema": "https://biomejs.dev/schemas/2.3.3/schema.json",
	"vcs": {
		"enabled": true,
		"clientKind": "git",
		"useIgnoreFile": true
	},
	"files": {
		"ignoreUnknown": true,
		"includes": [
			"**/packages/**/*",
			"**/*.json",
			"!**/test-results",
			"!**/node_modules",
			"!**/mariadb_data",
			"!**/dist",
			"!**/target",
			"!**/build",
			"!**/temp",
			"!**/*.zip",
			"!**/*.rs",
			"!**/harper-wasm/pkg",
			"!**/.vscode-test",
			"!**/.svelte-kit",
			"!**/.sveltepress",
			"!**/packages/obsidian-plugin/main.js",
			"!**/pnpm-lock.yaml",
			"!**/package-lock.json",
			"!**/playwright-report",
			"!**/yarn.lock"
		]
	},
	"css": {
		"parser": {
			"tailwindDirectives": true
		}
	},
	"formatter": {
		"enabled": true,
		"lineWidth": 100,
		"indentStyle": "tab",
		"useEditorconfig": true
	},
	"assist": {
		"actions": {
			"source": {
				"organizeImports": "on"
			}
		}
	},
	"linter": {
		"enabled": true,
		"rules": {
			"recommended": true,
			"suspicious": {
				"noExplicitAny": "off",
				"noArrayIndexKey": "off",
				"noLabelVar": "warn",
				"noDoubleEquals": "off"
			},
			"a11y": {
				"noSvgWithoutTitle": "off",
				"useGenericFontNames": "warn"
			},
			"correctness": {
				"useExhaustiveDependencies": "off",
				"noUnusedVariables": "off"
			},
			"style": {
				"noParameterAssign": "off",
				"noNonNullAssertion": "off",
				"noUselessElse": "off",
				"useNodejsImportProtocol": "off",
				"useAsConstAssertion": "error",
				"useDefaultParameterLast": "error",
				"useEnumInitializers": "error",
				"useSelfClosingElements": "error",
				"useSingleVarDeclarator": "error",
				"noUnusedTemplateLiteral": "error",
				"useNumberNamespace": "error",
				"noInferrableTypes": "error"
			},
			"complexity": {
				"noForEach": "off",
				"noStaticOnlyClass": "off",
				"noThisInStatic": "off",
				"noArguments": "off",
				"noUselessFragments": "off"
			}
		}
	},
	"javascript": {
		"formatter": {
			"quoteStyle": "single"
		}
	},
	"overrides": [
		{
			"includes": ["**/*.svelte", "**/*.astro", "**/*.vue"],
			"linter": {
				"rules": {
					"correctness": {
						"noUnusedImports": "off"
					},
					"style": {
						"useConst": "off",
						"useImportType": "off"
					}
				}
			}
		}
	]
}



================================================
FILE: Cargo.toml
================================================
[workspace]
members = ["harper-cli", "harper-core", "harper-ls", "harper-comments", "harper-wasm", "harper-tree-sitter", "harper-html", "harper-literate-haskell", "harper-typst", "harper-stats", "harper-pos-utils", "harper-brill", "harper-ink", "harper-python", "harper-jjdescription", "harper-thesaurus", "harper-asciidoc", "fuzz"]
resolver = "2"

[profile.test]
opt-level = 3

[profile.release]
opt-level = 3
# Stripping binaries triggers a bug in `wasm-opt`.
# Disable it for now.
# strip = true

# Release profile with debug info.
# Useful for debugging and profiling.
[profile.release-debug]
inherits = "release"
debug = 2



================================================
FILE: COMPARISON.md
================================================
# Comparison to Other Grammar Checkers

|              | Suggestion Time | License                  | LSP Support                                                                                          | Ruleset                                                                                   | Multi-Lingual/Multi-Dialect |
| ------------ | --------------- | ------------------------ | ---------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------- | --------------------------- |
| Harper       | 10ms            | Apache-2.0               | ✅                                                                                                   | [Custom](https://github.com/automattic/harper/tree/master/harper-core/src/linting)     | ❌                          |
| LanguageTool | 650ms           | LGPL-2.1                 | 🟨 Through [ltex-ls](https://github.com/valentjn/ltex-ls)                                            | [Custom](https://community.languagetool.org/rule/list?lang=en) + N-Gram Based + LLM Based | 🟨 Not simultaneously       |
| hunspell     |                 | LGPL/GPL/MPL tri-license | ❌                                                                                                   | hunspell/MySpell                                                                          | 🟨 Not simultaneously       |
| Grammarly    | 4000ms          | Proprietary              | 🟨 Through [grammarly-language-server](https://github.com/emacs-grammarly/grammarly-language-server) | Proprietary                                                                               | ❌                          |



================================================
FILE: CONTRIBUTING.md
================================================
# Contributing

This page has been moved to [the main documentation](https://writewithharper.com/docs/contributors/introduction).



================================================
FILE: demo.md
================================================
There are some cases where the the standard grammar
checkers don't cut it. That;s where Harper comes in handy.

Harper is an language checker for developers. It can detect
improper capitalization and misspellled words,
as well as a number of other issues.
Like if you break up words you shoul dn't.
Harper can be an lifesaver when writing technical documents, 
emails or other formal forms of communication.

Harper works everywhere, even when you're not online. Since your data
never leaves your device, you don't ned too worry aout us
selling it or using it to train large language models.

The best part: Harper can give you feedback instantly.
For most documents, Harper can serve up suggestions in
under 10 ms, faster that Grammarly.



================================================
FILE: docker-compose.dev.yml
================================================
# This Docker compose file is for development of the Harper website and web services.
# You do not need it to use Harper.

services:
  db:
    image: mariadb:lts
    restart: always
    environment:
      MARIADB_ROOT_PASSWORD: password
      MARIADB_DATABASE: harper
      MARIADB_USER: devuser
      MARIADB_PASSWORD: password
    ports:
      - "3306:3306"
    volumes:
      - ./mariadb_data:/var/lib/mysql
    healthcheck:
      test: ["CMD", "mariadb-admin", "ping", "-h", "localhost"]
      interval: 5s
      timeout: 5s
      retries: 10



================================================
FILE: docker-compose.yml
================================================
# This Docker compose file is for development of the Harper website and web services.
# You do not need it to use Harper.

services:
  site:
    build:
      dockerfile: Dockerfile
    restart: always
    ports:
      - "3000:3000"
    environment:
      - ORIGIN=http://localhost:3000
      - DATABASE_URL=mysql://devuser:password@db:3306/harper
    depends_on:
      db:
        condition: service_healthy
  db:
    image: mariadb:lts
    restart: always
    environment:
      MARIADB_ROOT_PASSWORD: password
      MARIADB_DATABASE: harper
      MARIADB_USER: devuser
      MARIADB_PASSWORD: password
    ports:
      - "3306:3306"
    volumes:
      - ./mariadb_data:/var/lib/mysql
    healthcheck:
      test: ["CMD", "mariadb-admin", "ping", "-h", "localhost"]
      interval: 5s
      timeout: 5s
      retries: 10



================================================
FILE: Dockerfile
================================================
# This Dockerfile is for the Harper website and web services.
# You do not need it to use Harper.

ARG NODE_VERSION=24

FROM rust:latest AS wasm-build
RUN rustup toolchain install
RUN apt-get update -y && apt-get install clang -y

RUN mkdir -p /usr/build/
WORKDIR /usr/build/

RUN cargo install wasm-pack

COPY . .

WORKDIR /usr/build/harper-wasm
RUN wasm-pack build --target web
RUN cargo clean

FROM node:${NODE_VERSION} AS node-build

RUN apt-get update && apt-get install git parallel -y
RUN corepack enable

RUN mkdir -p /usr/build/
WORKDIR /usr/build/

COPY . .
COPY --from=wasm-build /usr/build/harper-wasm/pkg /usr/build/harper-wasm/pkg

RUN pnpm install --engine-strict=false --shamefully-hoist

WORKDIR /usr/build/packages/components
RUN pnpm install --engine-strict=false --shamefully-hoist
RUN pnpm build

WORKDIR /usr/build/packages/harper.js

RUN pnpm build && ./docs.sh

WORKDIR /usr/build/packages/lint-framework
RUN pnpm build

WORKDIR /usr/build/packages/web
RUN pnpm install --engine-strict=false --shamefully-hoist
RUN pnpm build

FROM node:${NODE_VERSION}

COPY --from=node-build /usr/build/node_modules /usr/build/packages/web/node_modules
COPY --from=node-build /usr/build/packages/web/build /usr/build/packages/web/build
COPY ./packages/web/drizzle /usr/build/packages/web/build/drizzle
COPY --from=node-build /usr/build/packages/web/package.json /usr/build/packages/web/package.json

WORKDIR /usr/build/packages/web/build

ENV HOST=0.0.0.0
ENV PORT=3000

ENTRYPOINT ["node", "index"]



================================================
FILE: flake.lock
================================================
{
  "nodes": {
    "nixpkgs": {
      "locked": {
        "lastModified": 1761236834,
        "narHash": "sha256-+pthv6hrL5VLW2UqPdISGuLiUZ6SnAXdd2DdUE+fV2Q=",
        "owner": "NixOS",
        "repo": "nixpkgs",
        "rev": "d5faa84122bc0a1fd5d378492efce4e289f8eac1",
        "type": "github"
      },
      "original": {
        "id": "nixpkgs",
        "type": "indirect"
      }
    },
    "root": {
      "inputs": {
        "nixpkgs": "nixpkgs",
        "utils": "utils"
      }
    },
    "systems": {
      "locked": {
        "lastModified": 1681028828,
        "narHash": "sha256-Vy1rq5AaRuLzOxct8nz4T6wlgyUR7zLU309k9mBC768=",
        "owner": "nix-systems",
        "repo": "default",
        "rev": "da67096a3b9bf56a91d16901293e51ba5b49a27e",
        "type": "github"
      },
      "original": {
        "owner": "nix-systems",
        "repo": "default",
        "type": "github"
      }
    },
    "utils": {
      "inputs": {
        "systems": "systems"
      },
      "locked": {
        "lastModified": 1731533236,
        "narHash": "sha256-l0KFg5HjrsfsO/JpG+r7fRrqm12kzFHyUHqHCVpMMbI=",
        "owner": "numtide",
        "repo": "flake-utils",
        "rev": "11707dc2f618dd54ca8739b309ec4fc024de578b",
        "type": "github"
      },
      "original": {
        "owner": "numtide",
        "repo": "flake-utils",
        "type": "github"
      }
    }
  },
  "root": "root",
  "version": 7
}



================================================
FILE: flake.nix
================================================
{
  inputs = {
    utils.url = "github:numtide/flake-utils";
  };
  outputs =
    {
      self,
      nixpkgs,
      utils,
    }:
    utils.lib.eachDefaultSystem (
      system:
      let
        pkgs = import nixpkgs {
          inherit system;
        };
      in
      {
        devShell =
          with pkgs;
          mkShell {
            buildInputs = [
              just
              bash
              parallel
              rustup
              gcc
              pnpm
              nodejs
              wasm-pack
              zip
              wasm-bindgen-cli_0_2_100
            ];

            shellHook = ''
              echo "
                                                                   YSOKGECAACDFIMRVZ               
                                                                YQHAAAAABDFFDBAAAAABU              
                                                              WKAAAFNTWZ      ZWTQNNY              
                         ZTPMIFDCAAAAAEJPUZ                 ZKAADOX                                
                      ZTJBAAABFHJMMMMLFAAAAGRZ             YFAAKZ                                  
                     XDAAELSW          ZVQIAADQZ           QAAL                                    
                     ZPNW                  VIAACOZ          VTZ                                    
                          YPLIGDBBDFIKPY     VIABX                   YOKIFDABDGILPY                
                        TJAAABEILLIFCAAAJT     WW                 ZSIAAACFIMLHEBAABKU              
                      UEAADNW        XNEAADT                     SDAAEOX        WMDAAEV            
                 YTTTNAACT              UDAAM                  ZLAAEV              TCAAOTTTY       
                WBAAAAAFX                YGAAM                 KAAHY                XEAAAAACX      
                YAAAAACZ                  ZEAAJMMMMMMIGIMMMMMMIAAFZ                  YBAAAAAZ      
                YAAAAAK                    JAAAAAAAAAAAAAAAAAAAAAL                    IAAAAAZ      
                 TNDAAT                    TAAAAAAAAAAAAAAAAAAAAAV                    RAAENU       
                   KAAM                    NAAGTTTTTTRORTTTTTTFAAP                    KAAM         
                   UAAC                    EAAU               RAAF                   ZBAAW         
                    NAAHX                XIAAM                 KAAJY                WGAAO          
                     OAABNX            XOBAAM                  ZLAACOY            XMAAAP           
                      UEAAAGQVY    ZVQHAAAET                     SDAAAHRVZ    YVPGAAAFV            
                        VNDAAAABEFBAAAADMV                         UMCAAAABFEBAAAAENW              
                           VRPMKHHJMORV                               UROMJHHKMPRW
              "
            '';
          };
      }
    );
}



================================================
FILE: justfile
================================================
# Format entire project
format:
  cargo fmt  
  pnpm format

# Build the shared component library
build-components:
  #!/usr/bin/env bash
  set -eo pipefail

  cd "{{justfile_directory()}}/packages/components"
  pnpm install --engine-strict=false
  pnpm build

# Build the WebAssembly module
build-wasm:
  #!/usr/bin/env bash
  cd "{{justfile_directory()}}/harper-wasm"
  if [ "${DISABLE_WASM_OPT:-0}" -eq 1 ]; then
    wasm-pack build --target web --no-opt
  else
    wasm-pack build --target web
  fi

# Build `harper.js` with all size optimizations available.
build-harperjs: build-wasm 
  #!/usr/bin/env bash
  set -eo pipefail

  # Removes a duplicate copy of the WASM binary if Vite is left to its devices.
  perl -pi -e 's/new URL\(.*\)/new URL()/g' "{{justfile_directory()}}/harper-wasm/pkg/harper_wasm.js"

  cd "{{justfile_directory()}}/packages/harper.js"
  pnpm install
  pnpm build

  # Generate API reference
  ./docs.sh

# Build the browser lint framework module
build-lint-framework: build-harperjs
  #!/usr/bin/env bash
  set -eo pipefail

  cd "{{justfile_directory()}}/packages/lint-framework"
  pnpm install
  pnpm build

test-harperjs: build-harperjs
  #!/usr/bin/env bash
  set -eo pipefail

  pnpm install
  cd "{{justfile_directory()}}/packages/harper.js"
  pnpm playwright install
  pnpm test

  # Test runnable examples
  cd "{{justfile_directory()}}/packages/harper.js/examples/commonjs-simple"
  pnpm start

test-obsidian: build-obsidian
  #!/usr/bin/env bash
  set -eo pipefail

  pnpm install
  cd "{{justfile_directory()}}/packages/obsidian-plugin"
  pnpm playwright install
  pnpm test

dev-wp: build-harperjs
  #!/usr/bin/env bash

  set -eo pipefail

  cd "{{justfile_directory()}}/packages/wordpress-plugin"
  pnpm install
  pnpm wp-now start &
  pnpm start 

# Build the WordPress plugin
build-wp: build-harperjs
  #!/usr/bin/env bash
  set -eo pipefail

  cd "{{justfile_directory()}}/packages/wordpress-plugin"
  pnpm install
  pnpm build
  pnpm plugin-zip

# Compile the website's dependencies and start a development server. Note that if you make changes to `harper-wasm`, you will have to re-run this command.
dev-web: build-harperjs build-lint-framework build-components
  #!/usr/bin/env bash
  set -eo pipefail

  cd "{{justfile_directory()}}/packages/web"
  pnpm install
  pnpm dev

# Build the Harper website.
build-web: build-harperjs build-lint-framework build-components
  #!/usr/bin/env bash
  set -eo pipefail
  
  cd "{{justfile_directory()}}/packages/web"
  pnpm install
  pnpm build

# Build the Harper Obsidian plugin.
build-obsidian: build-harperjs
  #!/usr/bin/env bash
  set -eo pipefail
  
  cd "{{justfile_directory()}}/packages/obsidian-plugin"

  pnpm install
  pnpm build

  zip harper-obsidian-plugin.zip manifest.json main.js

# Build the Chrome extension.
build-chrome-plugin: build-harperjs build-lint-framework build-components
  #!/usr/bin/env bash
  set -eo pipefail
  
  cd "{{justfile_directory()}}/packages/chrome-plugin"

  pnpm install 
  pnpm zip-for-chrome

# Start a development server for the Chrome extension.
dev-chrome-plugin: build-harperjs build-lint-framework build-components
  #!/usr/bin/env bash
  set -eo pipefail
  
  cd "{{justfile_directory()}}/packages/chrome-plugin"

  pnpm install 
  pnpm dev

# Build the Firefox extension.
build-firefox-plugin: build-harperjs build-lint-framework build-components
  #!/usr/bin/env bash
  set -eo pipefail
  
  cd "{{justfile_directory()}}/packages/chrome-plugin"

  pnpm install 
  pnpm zip-for-firefox

test-chrome-plugin: build-chrome-plugin
  #!/usr/bin/env bash
  set -eo pipefail

  pnpm install
  cd "{{justfile_directory()}}/packages/chrome-plugin"
  pnpm playwright install

  # For environments without displays like CI servers or containers
  if [[ "$(uname)" == "Linux" ]] && [[ -z "$DISPLAY" ]]; then
    xvfb-run --auto-servernum pnpm test --project chromium
  else
    pnpm test --project chromium
  fi

test-firefox-plugin: build-firefox-plugin
  #!/usr/bin/env bash
  set -eo pipefail

  pnpm install
  cd "{{justfile_directory()}}/packages/chrome-plugin"
  pnpm playwright install
  # For environments without displays like CI servers or containers
  if [[ "$(uname)" == "Linux" ]] && [[ -z "$DISPLAY" ]]; then
    xvfb-run --auto-servernum pnpm test --project firefox
  else
    pnpm test --project firefox 
  fi


# Run VSCode plugin unit and integration tests.
test-vscode:
  #!/usr/bin/env bash
  set -eo pipefail

  ext_dir="{{justfile_directory()}}/packages/vscode-plugin"
  bin_dir="${ext_dir}/bin"

  if ! [[ -d "$bin_dir" ]]; then
    mkdir "$bin_dir"
  fi

  echo Building binaries
  cargo build --release -q

  cp "{{justfile_directory()}}/target/release/harper-ls"* "$bin_dir"

  cd "$ext_dir"

  pnpm install
  # For environments without displays like CI servers or containers
  if [[ "$(uname)" == "Linux" ]] && [[ -z "$DISPLAY" ]]; then
    xvfb-run --auto-servernum pnpm test
  else
    pnpm test
  fi

  # Over time, VSCode test versions take up space that can be hard to track down
  if [[ -d .vscode-test ]]; then
    all_versions=$(ls -1 .vscode-test | grep "^vscode-" | sort -V)
    latest_version=$(echo "$all_versions" | tail -n 1)
    old_versions=$(echo "$all_versions" | sed '$d')  # Delete last line instead
    if [[ -n "$old_versions" ]]; then
      count=$(echo "$old_versions" | wc -l)
      echo "$old_versions" | xargs -I {} rm -rf .vscode-test/{}
      echo "✓ Deleted $count old VSCode versions, keeping $latest_version"
    else
      echo "✓ No old versions to clean (keeping $latest_version)"
    fi
  fi

# Build and package the Visual Studio Code extension.
# If `target` is passed, it is assumed that `harper-ls` has been compiled beforehand and is in `packages/vscode-plugin/bin`. This is used in CI.
package-vscode target="":
  #!/usr/bin/env bash
  set -eo pipefail

  ext_dir="{{justfile_directory()}}/packages/vscode-plugin"
  bin_dir="${ext_dir}/bin"

  cp LICENSE "$ext_dir"

  if [[ -z "{{target}}" ]]; then
    echo Building binaries
    cargo build --release -q

    if ! [[ -d "$bin_dir" ]]; then
      mkdir "$bin_dir"
    fi

    cp "{{justfile_directory()}}/target/release/harper-ls"* "$bin_dir"
  fi

  cd "$ext_dir"

  pnpm install
  if [[ -n "{{target}}" ]]; then
    pnpm package --target {{target}}
  else
    pnpm package
  fi

update-vscode-linters:
  #!/usr/bin/env bash
  set -eo pipefail

  linters=$(
    cargo run --bin harper-cli -- config |
      jq 'with_entries(.key |= "harper.linters." + . |
        .value |= {
          "scope": "resource",
          "type": "boolean",
          "default": .default_value,
          "description": .description
        }
      )'
  )

  cd "{{justfile_directory()}}/packages/vscode-plugin"

  manifest_without_linters=$(
    jq 'walk(
      if type == "object" then
        with_entries(select(.key | startswith("harper.linters") | not))
      end
    )' package.json
  )

  jq --argjson linters "$linters" \
    '.contributes.configuration.properties += $linters' <<< \
    "$manifest_without_linters" > \
    package.json
  just format

# Run Rust formatting and linting.
check-rust: auditdictionary
  #!/usr/bin/env bash
  set -eo pipefail

  cargo fmt -- --check
  cargo clippy -- -Dwarnings -D clippy::dbg_macro -D clippy::needless_raw_string_hashes

  cargo hack check --each-feature

# Perform format and type checking.
check: check-rust check-js build-web

check-js: build-harperjs build-lint-framework build-components
  #!/usr/bin/env bash
  set -eo pipefail

  pnpm install
  pnpm check

  # Needed because Svelte has special linters
  cd "{{justfile_directory()}}/packages/web"
  pnpm check

# Populate build caches and install necessary local tooling (tools callable via `pnpm run <tool>`).
setup: build-harperjs test-harperjs test-vscode build-web build-wp build-obsidian build-chrome-plugin

# Perform full format and type checking, build all projects and run all tests. Run this before pushing your code.
precommit: check test build-harperjs build-obsidian build-web build-wp build-firefox-plugin build-chrome-plugin 
  #!/usr/bin/env bash
  set -eo pipefail

  echo Building binaries
  cargo build --all-targets -q

# Install `harper-cli` and `harper-ls` to your machine via `cargo`
install:
  cargo install --path harper-ls --locked 
  cargo install --path harper-cli --locked 

# Run `harper-cli` on the Harper repository
dogfood:
  #!/usr/bin/env bash
  cargo build --release
  for file in `fd -e rs`
  do
    echo Linting $file
    ./target/release/harper-cli lint $file
  done

test-rust:
  echo Running all Rust tests
  cargo test -q

# Test everything.
test: test-rust test-harperjs test-vscode test-obsidian test-chrome-plugin test-firefox-plugin

# Use `harper-cli` to parse a provided file and print out the resulting tokens.
parse file:
  cargo run --bin harper-cli -- parse {{file}}

# Lint provided inputs using Harper and print the results.
# The inputs can be files, directories, or a string on the command line.
# If no inputs are provided, lint stdin.
lint *inputs:
  cargo run --bin harper-cli -- lint {{inputs}}

# Show the spans of the parsed tokens overlapped in the provided file.
spans file:
  cargo run --bin harper-cli -- spans {{file}}

# Add a noun to Harper's curated dictionary.
addnoun noun:
  #!/usr/bin/env bash
  DICT_FILE=./harper-core/dictionary.dict 

  cat $DICT_FILE | grep "^{{noun}}/"

  if [ $? -eq 0 ]
  then
    echo "That noun may already be in the dictionary."
    exit 0
  fi

  # 'g': possessive -'s suffix for both common and proper nouns
  flags='g'

  # If the first letter is uppercase, treat it as a proper noun
  if [[ "{{noun}}" =~ ^[A-Z] ]]; then
    # 'O': proper noun, usually no plural
    flags+='O'
  else
    # 'N': (common) singular noun, 'S': plural -(e)s
    flags+='NS'
  fi

  # Echo the noun with its flags to the dictionary file
  [[ -s $DICT_FILE && -n $(tail -c1 "$DICT_FILE") ]] && echo >> "$DICT_FILE"
  echo "{{noun}}/$flags" >> "$DICT_FILE"

# Search Harper's curated dictionary for a specific word
searchdictfor word:
  #!/usr/bin/env bash
  if command -v rg > /dev/null; then
    cargo run --bin harper-cli -- words | rg {{word}}
  else
    cargo run --bin harper-cli -- words | grep {{word}}
  fi

# Find words in the user's `harper-ls/dictionary.txt` for words already in the curated dictionary.
userdictoverlap:
  #!/usr/bin/env bash
  USER_DICT_FILE="$HOME/.config/harper-ls/dictionary.txt"

  while read -r line; do
    just searchdictfor $line 2> /dev/null
  done < $USER_DICT_FILE

# Get the metadata associated with one or more words in Harper's dictionary as JSON.
getmetadata *words:
  cargo run --bin harper-cli -- metadata {{words}}
getmetadata-brief *words:
  cargo run --bin harper-cli -- metadata --brief {{words}}
# Get all the forms of a word using the affixes.
getforms word:
  cargo run --bin harper-cli -- forms {{word}}
# Get a random sample of words from Harper's dictionary and list all forms of each.
sampleforms count:
  #!/usr/bin/env bash
  set -eo pipefail
  DICT_FILE=./harper-core/dictionary.dict 
  # USER_DICT_FILE="$HOME/.config/harper-ls/dictionary.txt"

  if [ "{{count}}" -eq 0 ]; then
    exit 0
  fi

  total_lines=$(wc -l < $DICT_FILE)
  
  # Cross-platform random line selection
  if command -v shuf >/dev/null 2>&1; then
    words=$(shuf -n "{{count}}" "$DICT_FILE")
  elif command -v jot >/dev/null 2>&1; then
    words=$(jot -r "{{count}}" 1 "$total_lines" | while read -r line_num; do \
      sed -n "$line_num"p "$DICT_FILE"; \
    done)
  else
    echo "Error: Neither 'shuf' nor 'jot' found. Cannot generate random words." >&2
    exit 1
  fi
  
  cargo run --bin harper-cli -- forms $words

bump-versions: update-vscode-linters
  #!/usr/bin/env bash
  set -eo pipefail

  cargo ws version --no-git-push --no-git-tag --force '*'

  HARPER_VERSION=$(tq --raw --file harper-core/Cargo.toml .package.version)

  cd "{{justfile_directory()}}/packages/harper.js"

  cat package.json | jq ".version = \"$HARPER_VERSION\"" > package.json.edited
  mv package.json.edited package.json

  cd "{{justfile_directory()}}/packages/vscode-plugin"

  cat package.json | jq ".version = \"$HARPER_VERSION\"" > package.json.edited
  mv package.json.edited package.json

  cd "{{justfile_directory()}}/packages/chrome-plugin"

  cat package.json | jq ".version = \"$HARPER_VERSION\"" > package.json.edited
  mv package.json.edited package.json

  cd "{{justfile_directory()}}/packages/obsidian-plugin"

  cat package.json | jq ".version = \"$HARPER_VERSION\"" > package.json.edited
  mv package.json.edited package.json

  just format

  lazygit

# Enter an infinite loop of property testing until a bug is found.
fuzz:
  #!/usr/bin/env bash
  
  while true
  do
      QUICKCHECK_TESTS=100000 cargo test
      if [[ x$? != x0 ]] ; then
          exit $?
      fi
  done

registerlinter module name:
  #!/usr/bin/env bash

  D="{{justfile_directory()}}/harper-core/src/linting"

  sed -i "/pub use an_a::AnA;/a pub use {{module}}::{{name}};" "$D/mod.rs"
  sed -i "/use super::an_a::AnA;/a use super::{{module}}::{{name}};" "$D/lint_group.rs"
  sed -i "/insert_expr_rule!(ChockFull, true);/a \ \ \ \ insert_struct_rule!({{name}}, true);" "$D/lint_group.rs"
  just format

# Print annotations and their descriptions from annotations.json
alias printaffixes := printannotations
alias getannotations := printannotations
alias listannotations := printannotations
alias showannotations := printannotations

printannotations:
  #! /usr/bin/env node
  const affixesData = require('{{justfile_directory()}}/harper-core/annotations.json');
  const allEntries = {
    ...affixesData.affixes || {},
    ...affixesData.properties || {}
  };
  
  // Calculate the maximum description length for alignment
  const entries = Object.entries(allEntries);
  const maxDescLength = entries.reduce((max, [flag, fields]) => {
    const description = fields['#'] || '';
    const lineLength = flag.length + 2 + description.length; // flag + ': ' + description
    return Math.max(max, lineLength);
  }, 0);
  
  entries.sort((a, b) => a[0].localeCompare(b[0])).forEach(([flag, fields]) => {
    const description = fields['#'] || '';
    const comment = fields['//'] || null;
    if (description) {
      const line = `${flag}: ${description}`;
      const padding = ' '.repeat(Math.max(1, maxDescLength - line.length + 2));
      console.log(line + (comment ? `${padding}// ${comment}` : ''));
    }
  });
  
  console.log('Available letters for new flags:', [...Array.from({length: 26}, (_, i) => 
    [String.fromCharCode(65 + i), String.fromCharCode(97 + i)]
  ).flat()].filter(letter => !Object.keys(allEntries).includes(letter)).sort().join(' '));
  console.log('Available digits for new flags:', [...Array.from({length: 10}, (_, i) => 
    String(i)
  )].filter(digit => !Object.keys(allEntries).includes(digit)).sort().join(' '));
  console.log('Available symbols for new flags:',
    [...Array.from('!"#$%&\'()*+,-./:;<=>?@\[\\\]\^_`{|}~')]
  .filter(symbol => !Object.keys(allEntries).includes(symbol)).sort().join(' '));
  console.log('Available Latin-1 characters for new flags:'); 
  [...Array.from({length: 256-160}, (_, i) => String.fromCharCode(160 + i))]
    .filter(char => !Object.keys(allEntries).includes(char) && char.charCodeAt(0) !== 160 && char.charCodeAt(0) !== 173)
    .sort()
    .join(' ')
    .match(/.{1,64}/g)
    .forEach(line => console.log('  ' + line));
    
# Get the most recent changes to the curated dictionary. Includes an optional argument to specify the number of commits to look back. Defaults to 1.
newest-dict-changes *numCommits:
  #! /usr/bin/env node

  const { exec } = require('child_process');

  const DICT_FILE = 'harper-core/dictionary.dict';

  const [RST, BOLD, DIM, ITAL, NORM] = [0, 1, 2, 3, 22].map(c => `\x1b[${c}m`);
  const [RED, GRN, YLW, BLU, MGN, CYN, WHT] = [1, 2, 3, 4, 5, 6, 7].map(c => `\x1b[${30+c}m`);

  const argv = [...process.argv];

  const [showHashes, showDiff] = ["--show-hashes", "--show-diff"].map(flag => argv.includes(flag) && argv.splice(argv.indexOf(flag), 1));

  // uncomment first line to use in justfile, comment out second line to use standalone
  const numCommits = "{{numCommits}}" || 1;
  // const numCommits = argv[2] || 1;

  // Command to get the last commit hash that modified the specified file
  const hashCommand = `git log --no-merges -n ${numCommits} --format="%H" -- ${DICT_FILE}`;
  console.log(`${MGN}${BOLD}GET HASHES${NORM}: ${hashCommand}${RST}`);

  // Execute the command to get the hash
  exec(hashCommand, (error, hashString, stderr) => {
    if (error) return console.error(`Error executing command: ${error.message}`);
    if (stderr) return console.error(`stderr: ${stderr}`);

    // avoid empty last line
    const longHashes = hashString.trim().split('\n');
    if (showHashes) console.log(longHashes.length, longHashes);

    if (longHashes.length < 1) {
      console.error('No hash(es) returned. Exiting.');
      process.exit(1);
    }

    // keep the last line and second last if there's more than one hash
    const [hash2, hash1] = longHashes.slice(-2).map((h) => h.substring(0, 7));

    // Command to get the word-level diff using the retrieved hash, using either one or two hashes
    const hashes = longHashes.length == 1 ? `${hash2}` : `${hash1} ${hash2}`;
    const diffCommand = `git diff --word-diff --no-color --unified=0 ${hashes} -- ${DICT_FILE}`;
    console.log(`${MGN}${BOLD}GET DIFF${NORM}: ${diffCommand}${RST}`);

    // Execute the diff command with a large buffer to avoid failing to handle large diffs such as:
    // git diff --word-diff --no-color --unified=0 0761702 baeb08e -- harper-core/dictionary.dict
    exec(diffCommand, { maxBuffer: 2048 * 1024 }, (diffError, diffString, diffStderr) => {
      if (diffError) {
        console.error(`Error executing diff command: ${diffError.message}`);
        return;
      }
      if (diffStderr) return console.error(`stderr: ${diffStderr}`);

      if (showDiff) console.log(`DIFFSTART\n${diffString}\nDIFFEND`);

      // uncomment first line to use in justfile, comment out second line to use standalone
      const affixes = require('{{justfile_directory()}}/harper-core/annotations.json').affixes;
      // const affixes = require('./harper-core/annotations.json').affixes;

      diffString.split("\n").forEach(line => {
        const match = line.match(/^(?:\[-(.*?)-\])?(?:\{\+(.*?)\+\})?$/);
        if (match) {
          let [, before, after] = match;

          if (before && after) {
            // An entry changed
            const [[oldword, oldaff], [newword, newaff]] = [before, after].map(e => e.split('/'));
            if (oldword === newword) {
              if (oldaff !== newaff) {
                const [oldRest, newRest] = [oldaff, newaff].map(aff => aff ? `${DIM}/${aff}${RST}`: '');
                console.log(`${BOLD}${CYN}CHG${RST} # ${oldword}${oldRest} -> ${newRest}`);
                const [oldNorm, newNorm] = [oldaff, newaff].map(a => a ? a.split(''): [])
                                                           .map(a => new Set(a))
                                                           .map(a => Array.from(a))
                                                           .map(a => a.sort());
                const removed = oldNorm.filter(o => !newNorm.includes(o));
                const added = newNorm.filter(n => !oldNorm.includes(n));
                const [addStr, remStr] = [added, removed]
                  .map(a => a.map(a => `    ${BOLD}${ITAL}${a}${RST} -> ${ (affixes[a] && affixes[a]['#']) || '???' }`)
                             .join('\n')
                  );
                if (removed.length > 0) console.log(`${RED}  ${BOLD}REMOVED${RST}:\n${remStr}`);
                if (added.length > 0) console.log(`${GRN}  ${BOLD}ADDED${RST}:\n${addStr}`);
              } else {
                // should never happen
                console.log(`${YLW} ?NO AFFIX CHG? '${oldaff}' -> '${newaff}'${RST}`);
              }
            } else {
              // The word changed rather than its affixes
              console.log(`${YLW}  ${BOLD}CHANGED${RST} ${RED}${oldword}${RST} -> ${GRN}${newword}${RST}`);
            }
          } else if (before || after) {
            // An entry was added or removed
            const [entry, symbol, action, colour] = before ? [before, "-", 'DEL', RED] : [after, "+", 'ADD', GRN];
            const [word, affix] = entry.split('/');
            console.log(`${colour}${BOLD}${action}${RST} ${symbol} ${word}${ affix ? `${DIM}/${affix}` : '' }${RST}`);
          }
        }
      });
    });
  });

# Print the input string or file with nominal phrases highlighted. These are generated using Harper's chunker.
getnps text:
  cargo run --bin harper-cli -- nominal-phrases "{{text}}"

# Suggest annotations for a potential new property annotation
suggestannotation input:
  #! /usr/bin/env node
  const affixesData = require('{{justfile_directory()}}/harper-core/annotations.json');
  const allEntries = {
    ...affixesData.affixes || {},
    ...affixesData.properties || {}
  };
  
  // Get all used flags
  const usedFlags = new Set(Object.keys(allEntries));
  
  // Process input string and check both cases
  const input = '{{input}}';
  const normalizedInput = input.replace(/\s/g, '');
  const uniqueChars = [...new Set(normalizedInput.toUpperCase() + normalizedInput.toLowerCase())];
  
  console.log(`Checking input: "${input}"\n${'='.repeat(50)}`);
  
  // Check each character in input
  const availableChars = [...new Set(uniqueChars)]
    .filter(char => !usedFlags.has(char));
  
  if (availableChars.length > 0) {
    console.log(`These characters of "${input}" are available to use for new annotations:`);
    availableChars.forEach(char => console.log(`  '${char}' (${char.charCodeAt(0)})`));
  } else {
    const inputChars = new Set(normalizedInput.toLowerCase() + normalizedInput.toUpperCase());
    const renamable = Object.entries(allEntries)
      .filter(([flag, entry]) => entry.rename_ok && inputChars.has(flag))
      .sort((a, b) => a[0].localeCompare(b[0]));
    
    if (renamable.length > 0) {
      console.log(`None of the characters of "${input}" are available to use for new annotations, but these ones are OK to be moved to make way for new annotations:`);
      renamable.forEach(([flag, entry]) => {
        console.log(`  '${flag}': ${entry['#'] || 'No description'}${entry['//'] ? ` (${entry['//']})` : ''}`);
      });
    } else {
      console.log(`None of the characters of "${input}" are available to use for new annotations, and none of them are OK to be moved to make way for new annotations.`);
    }
  }

# Audit the curated dictionary for any issues.
alias auditdict := auditdictionary

auditdictionary DIR="harper-core":
  cargo run --bin harper-cli -- audit-dictionary {{DIR}}

runsnapshots:
  #!/usr/bin/env bash
  set -eo pipefail

  cd harper-core
  cargo test -- test_pos_tagger test_most_lints



================================================
FILE: LICENSE
================================================
                                 Apache License
                           Version 2.0, January 2004
                        http://www.apache.org/licenses/

   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION

   1. Definitions.

      "License" shall mean the terms and conditions for use, reproduction,
      and distribution as defined by Sections 1 through 9 of this document.

      "Licensor" shall mean the copyright owner or entity authorized by
      the copyright owner that is granting the License.

      "Legal Entity" shall mean the union of the acting entity and all
      other entities that control, are controlled by, or are under common
      control with that entity. For the purposes of this definition,
      "control" means (i) the power, direct or indirect, to cause the
      direction or management of such entity, whether by contract or
      otherwise, or (ii) ownership of fifty percent (50%) or more of the
      outstanding shares, or (iii) beneficial ownership of such entity.

      "You" (or "Your") shall mean an individual or Legal Entity
      exercising permissions granted by this License.

      "Source" form shall mean the preferred form for making modifications,
      including but not limited to software source code, documentation
      source, and configuration files.

      "Object" form shall mean any form resulting from mechanical
      transformation or translation of a Source form, including but
      not limited to compiled object code, generated documentation,
      and conversions to other media types.

      "Work" shall mean the work of authorship, whether in Source or
      Object form, made available under the License, as indicated by a
      copyright notice that is included in or attached to the work
      (an example is provided in the Appendix below).

      "Derivative Works" shall mean any work, whether in Source or Object
      form, that is based on (or derived from) the Work and for which the
      editorial revisions, annotations, elaborations, or other modifications
      represent, as a whole, an original work of authorship. For the purposes
      of this License, Derivative Works shall not include works that remain
      separable from, or merely link (or bind by name) to the interfaces of,
      the Work and Derivative Works thereof.

      "Contribution" shall mean any work of authorship, including
      the original version of the Work and any modifications or additions
      to that Work or Derivative Works thereof, that is intentionally
      submitted to Licensor for inclusion in the Work by the copyright owner
      or by an individual or Legal Entity authorized to submit on behalf of
      the copyright owner. For the purposes of this definition, "submitted"
      means any form of electronic, verbal, or written communication sent
      to the Licensor or its representatives, including but not limited to
      communication on electronic mailing lists, source code control systems,
      and issue tracking systems that are managed by, or on behalf of, the
      Licensor for the purpose of discussing and improving the Work, but
      excluding communication that is conspicuously marked or otherwise
      designated in writing by the copyright owner as "Not a Contribution."

      "Contributor" shall mean Licensor and any individual or Legal Entity
      on behalf of whom a Contribution has been received by Licensor and
      subsequently incorporated within the Work.

   2. Grant of Copyright License. Subject to the terms and conditions of
      this License, each Contributor hereby grants to You a perpetual,
      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
      copyright license to reproduce, prepare Derivative Works of,
      publicly display, publicly perform, sublicense, and distribute the
      Work and such Derivative Works in Source or Object form.

   3. Grant of Patent License. Subject to the terms and conditions of
      this License, each Contributor hereby grants to You a perpetual,
      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
      (except as stated in this section) patent license to make, have made,
      use, offer to sell, sell, import, and otherwise transfer the Work,
      where such license applies only to those patent claims licensable
      by such Contributor that are necessarily infringed by their
      Contribution(s) alone or by combination of their Contribution(s)
      with the Work to which such Contribution(s) was submitted. If You
      institute patent litigation against any entity (including a
      cross-claim or counterclaim in a lawsuit) alleging that the Work
      or a Contribution incorporated within the Work constitutes direct
      or contributory patent infringement, then any patent licenses
      granted to You under this License for that Work shall terminate
      as of the date such litigation is filed.

   4. Redistribution. You may reproduce and distribute copies of the
      Work or Derivative Works thereof in any medium, with or without
      modifications, and in Source or Object form, provided that You
      meet the following conditions:

      (a) You must give any other recipients of the Work or
          Derivative Works a copy of this License; and

      (b) You must cause any modified files to carry prominent notices
          stating that You changed the files; and

      (c) You must retain, in the Source form of any Derivative Works
          that You distribute, all copyright, patent, trademark, and
          attribution notices from the Source form of the Work,
          excluding those notices that do not pertain to any part of
          the Derivative Works; and

      (d) If the Work includes a "NOTICE" text file as part of its
          distribution, then any Derivative Works that You distribute must
          include a readable copy of the attribution notices contained
          within such NOTICE file, excluding those notices that do not
          pertain to any part of the Derivative Works, in at least one
          of the following places: within a NOTICE text file distributed
          as part of the Derivative Works; within the Source form or
          documentation, if provided along with the Derivative Works; or,
          within a display generated by the Derivative Works, if and
          wherever such third-party notices normally appear. The contents
          of the NOTICE file are for informational purposes only and
          do not modify the License. You may add Your own attribution
          notices within Derivative Works that You distribute, alongside
          or as an addendum to the NOTICE text from the Work, provided
          that such additional attribution notices cannot be construed
          as modifying the License.

      You may add Your own copyright statement to Your modifications and
      may provide additional or different license terms and conditions
      for use, reproduction, or distribution of Your modifications, or
      for any such Derivative Works as a whole, provided Your use,
      reproduction, and distribution of the Work otherwise complies with
      the conditions stated in this License.

   5. Submission of Contributions. Unless You explicitly state otherwise,
      any Contribution intentionally submitted for inclusion in the Work
      by You to the Licensor shall be under the terms and conditions of
      this License, without any additional terms or conditions.
      Notwithstanding the above, nothing herein shall supersede or modify
      the terms of any separate license agreement you may have executed
      with Licensor regarding such Contributions.

   6. Trademarks. This License does not grant permission to use the trade
      names, trademarks, service marks, or product names of the Licensor,
      except as required for reasonable and customary use in describing the
      origin of the Work and reproducing the content of the NOTICE file.

   7. Disclaimer of Warranty. Unless required by applicable law or
      agreed to in writing, Licensor provides the Work (and each
      Contributor provides its Contributions) on an "AS IS" BASIS,
      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
      implied, including, without limitation, any warranties or conditions
      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
      PARTICULAR PURPOSE. You are solely responsible for determining the
      appropriateness of using or redistributing the Work and assume any
      risks associated with Your exercise of permissions under this License.

   8. Limitation of Liability. In no event and under no legal theory,
      whether in tort (including negligence), contract, or otherwise,
      unless required by applicable law (such as deliberate and grossly
      negligent acts) or agreed to in writing, shall any Contributor be
      liable to You for damages, including any direct, indirect, special,
      incidental, or consequential damages of any character arising as a
      result of this License or out of the use or inability to use the
      Work (including but not limited to damages for loss of goodwill,
      work stoppage, computer failure or malfunction, or any and all
      other commercial damages or losses), even if such Contributor
      has been advised of the possibility of such damages.

   9. Accepting Warranty or Additional Liability. While redistributing
      the Work or Derivative Works thereof, You may choose to offer,
      and charge a fee for, acceptance of support, warranty, indemnity,
      or other liability obligations and/or rights consistent with this
      License. However, in accepting such obligations, You may act only
      on Your own behalf and on Your sole responsibility, not on behalf
      of any other Contributor, and only if You agree to indemnify,
      defend, and hold each Contributor harmless for any liability
      incurred by, or claims asserted against, such Contributor by reason
      of your accepting any such warranty or additional liability.

   END OF TERMS AND CONDITIONS

   APPENDIX: How to apply the Apache License to your work.

      To apply the Apache License to your work, attach the following
      boilerplate notice, with the fields enclosed by brackets "[]"
      replaced with your own identifying information. (Don't include
      the brackets!)  The text should be enclosed in the appropriate
      comment syntax for the file format. We also recommend that a
      file or class name and description of purpose be included on the
      same "printed page" as the copyright notice for easier
      identification within third-party archives.

   Copyright 2024 Elijah Potter

   Licensed under the Apache License, Version 2.0 (the "License");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.



================================================
FILE: package.json
================================================
{
	"private": true,
	"scripts": {
		"check-dependency-version-consistency": "check-dependency-version-consistency",
		"check": "biome check --diagnostic-level=error",
		"format": "biome check --write ."
	},
	"engines": {
		"node": ">=22",
		"pnpm": "^10.6.3"
	},
	"devDependencies": {
		"@babel/runtime": "catalog:",
		"@biomejs/biome": "2.3.3",
		"check-dependency-version-consistency": "^5.0.0",
		"typescript": "catalog:"
	},
	"packageManager": "pnpm@10.10.0+sha512.d615db246fe70f25dcfea6d8d73dee782ce23e2245e3c4f6f888249fb568149318637dca73c2c5c8ef2a4ca0d5657fb9567188bfab47f566d1ee6ce987815c39"
}



================================================
FILE: pnpm-workspace.yaml
================================================
packages:
  - packages/*
  - harper-wasm/pkg
  - packages/harper.js/examples/*
catalog:
  typescript: ^5.9.3
  tslib: ^2.8.1
  "@types/node": ^22.13.10
  "@babel/runtime": ^7.26.10
onlyBuiltDependencies:
  - "@biomejs/biome"
  - "@parcel/watcher"
  - "@swc/core"
  - "@vscode/vsce-sign"
  - core-js
  - core-js-pure
  - esbuild
  - keytar
  - msw
  - svelte-preprocess
  - "@tailwindcss/oxide"



================================================
FILE: rust-toolchain.toml
================================================
[toolchain]
channel = "stable"
targets = ["wasm32-unknown-unknown"]



================================================
FILE: rustfmt.toml
================================================
newline_style = "Unix"
use_field_init_shorthand = true
reorder_imports = true



================================================
FILE: .dockerignore
================================================
target
build
*.pdf
node_modules



================================================
FILE: .editorconfig
================================================
root = true

[*]
end_of_line = lf



================================================
FILE: .envrc
================================================
use flake



================================================
FILE: .node-version
================================================
lts/*


================================================
FILE: .npmrc
================================================
registry=https://registry.npmjs.org



================================================
FILE: fuzz/README.md
================================================
# cargo-fuzz targets

## Setup

Follow the rust-fuzz [setup guide](https://rust-fuzz.github.io/book/cargo-fuzz/setup.html).
You need a nightly toolchain and the cargo-fuzz plugin.

Simple installation steps:

- `rustup install nightly`
- `cargo install cargo-fuzz`

## Adding a new fuzzing target

To add a new target, run `cargo fuzz add $TARGET_NAME`

## Doing a fuzzing run

If possible, prefill the `fuzz/corpus/$TARGET_NAME` directory with appropriate examples to speed up fuzzing.
The fuzzer should be coverage aware, so providing a well formed input document to fuzzing targets only expecting a string as input can speed things up a lot.

Then, run `cargo +nightly fuzz run $TARGET_NAME -- -timeout=$TIMEOUT`

The timeout flag accepts a timeout in seconds, after which a long-running test case will be aborted.
This should be set to a low number to quickly report endless loops / deep recursion in parsers.

The normal fuzzing run will continue until a crash is found.

Alternatively, if you want to run all the fuzzing targets at once: `cargo +nightly fuzz list | parallel -j0 cargo +nightly fuzz run {} -- -timeout=$TIMEOUT`

## Minifying a test case

Once the fuzzer finds a crash, we probably want to minify the result.
This can be done with `CARGO_PROFILE_RELEASE_LTO=false cargo +nightly fuzz tmin $TARGET $TEST_CASE_PATH`



================================================
FILE: fuzz/Cargo.toml
================================================
[package]
name = "fuzz"
version = "0.0.0"
publish = false
edition = "2024"

[package.metadata]
cargo-fuzz = true

[dependencies]
libfuzzer-sys = "0.4"

harper-core = { path = "../harper-core" }
harper-typst = { path = "../harper-typst" }
harper-literate-haskell = { path = "../harper-literate-haskell" }
harper-html = { path = "../harper-html" }
harper-comments = { path = "../harper-comments" }

[[bin]]
name = "fuzz_harper_typst"
path = "fuzz_targets/fuzz_harper_typst.rs"
test = false
doc = false
bench = false

[[bin]]
name = "fuzz_harper_literate_haskell"
path = "fuzz_targets/fuzz_harper_literate_haskell.rs"
test = false
doc = false
bench = false

[[bin]]
name = "fuzz_harper_html"
path = "fuzz_targets/fuzz_harper_html.rs"
test = false
doc = false
bench = false

[[bin]]
name = "fuzz_harper_comment"
path = "fuzz_targets/fuzz_harper_comment.rs"
test = false
doc = false
bench = false

[[bin]]
name = "fuzz_harper_core_markdown"
path = "fuzz_targets/fuzz_harper_core_markdown.rs"
test = false
doc = false
bench = false



================================================
FILE: fuzz/fuzz_targets/fuzz_harper_comment.rs
================================================
#![no_main]

use harper_core::parsers::{MarkdownOptions, StrParser};
use libfuzzer_sys::arbitrary::{Arbitrary, Result, Unstructured};
use libfuzzer_sys::fuzz_target;

#[derive(Debug)]
struct Language(String);

const LANGUAGES: [&str; 32] = [
    "cmake",
    "cpp",
    "csharp",
    "c",
    "dart",
    "go",
    "haskell",
    "javascriptreact",
    "javascript",
    "java",
    "kotlin",
    "lua",
    "nix",
    "php",
    "python",
    "ruby",
    "rust",
    "scala",
    "shellscript",
    "solidity",
    "swift",
    "toml",
    "typescriptreact",
    "typescript",
    "clojure",
    "go",
    "lua",
    "java",
    "javascriptreact",
    "typescript",
    "typescriptreact",
    "solidity",
];

impl<'a> Arbitrary<'a> for Language {
    fn arbitrary(u: &mut Unstructured<'a>) -> Result<Self> {
        let &lang = u.choose(&LANGUAGES)?;
        Ok(Language(lang.to_owned()))
    }
}

#[derive(Debug)]
struct Input {
    language: Language,
    text: String,
}

impl<'a> Arbitrary<'a> for Input {
    fn arbitrary(u: &mut Unstructured<'a>) -> Result<Self> {
        let (language, text) = Arbitrary::arbitrary(u)?;
        Ok(Input { language, text })
    }

    fn arbitrary_take_rest(u: Unstructured<'a>) -> Result<Self> {
        let (language, text) = Arbitrary::arbitrary_take_rest(u)?;
        Ok(Input { language, text })
    }
}

fuzz_target!(|data: Input| {
    let opts = MarkdownOptions::default();
    let parser = harper_comments::CommentParser::new_from_language_id(&data.language.0, opts);
    if let Some(parser) = parser {
        let _res = parser.parse_str(&data.text);
    }
});



================================================
FILE: fuzz/fuzz_targets/fuzz_harper_core_markdown.rs
================================================
#![no_main]

use harper_core::parsers::{Markdown, MarkdownOptions, StrParser};
use libfuzzer_sys::fuzz_target;

fuzz_target!(|data: &str| {
    let opts = MarkdownOptions::default();
    let parser = Markdown::new(opts);
    let _res = parser.parse_str(data);
});



================================================
FILE: fuzz/fuzz_targets/fuzz_harper_html.rs
================================================
#![no_main]

use harper_core::parsers::StrParser;
use libfuzzer_sys::fuzz_target;

fuzz_target!(|data: &str| {
    let parser = harper_html::HtmlParser::default();
    let _res = parser.parse_str(data);
});



================================================
FILE: fuzz/fuzz_targets/fuzz_harper_literate_haskell.rs
================================================
#![no_main]

// use harper_core::parsers::StrParser;
use libfuzzer_sys::fuzz_target;

fuzz_target!(|_data: &str| {
    // TODO: figure out how to create a literate haskell parser
    // let _res = typst.parse_str(&data);
});



================================================
FILE: fuzz/fuzz_targets/fuzz_harper_typst.rs
================================================
#![no_main]

use harper_core::parsers::StrParser;
use libfuzzer_sys::fuzz_target;

fuzz_target!(|data: &str| {
    let typst = harper_typst::Typst;
    let _res = typst.parse_str(data);
});



================================================
FILE: harper-asciidoc/Cargo.toml
================================================
[package]
name = "harper-asciidoc"
version = "1.5.1"
edition = "2024"
description = "The language checker for developers."
license = "Apache-2.0"
repository = "https://github.com/automattic/harper"

[dependencies]
harper-core = { path = "../harper-core", version = "1.0.0" }
harper-tree-sitter = { path = "../harper-tree-sitter", version = "1.0.0" }
tree-sitter-asciidoc = "0.6.0"
tree-sitter = "0.25.10"

[dev-dependencies]
paste = "1.0.15"



================================================
FILE: harper-asciidoc/src/lib.rs
================================================
use harper_core::parsers::{self, Parser, PlainEnglish};
use harper_core::{Token, TokenKind};
use harper_tree_sitter::TreeSitterMasker;
use tree_sitter::Node;

pub struct AsciidocParser {
    inner: parsers::Mask<TreeSitterMasker, PlainEnglish>,
}

impl AsciidocParser {
    fn node_condition(n: &Node) -> bool {
        matches!(
            n.kind(),
            "line" | "body" | "table_cell_content" | "author" | "ident_block_line"
        )
    }
}

impl Default for AsciidocParser {
    fn default() -> Self {
        Self {
            inner: parsers::Mask::new(
                TreeSitterMasker::new(tree_sitter_asciidoc::language(), Self::node_condition),
                PlainEnglish,
            ),
        }
    }
}

impl Parser for AsciidocParser {
    fn parse(&self, source: &[char]) -> Vec<Token> {
        let mut tokens = self.inner.parse(source);

        for token in &mut tokens {
            if let TokenKind::Space(v) = &mut token.kind {
                *v = (*v).clamp(0, 1);
            }
        }

        tokens
    }
}



================================================
FILE: harper-asciidoc/tests/asciidoc_tests.rs
================================================
use harper_asciidoc::AsciidocParser;
use harper_core::linting::{LintGroup, Linter};
use harper_core::spell::FstDictionary;
use harper_core::{Dialect, Document};

/// Creates a unit test checking Asciidoc source code parsing.
macro_rules! create_test {
    ($filename:ident.$ext:ident, $correct_expected:expr) => {
        paste::paste! {
            #[test]
            fn [<lints_$ext _ $filename _correctly>](){
                 let source = include_str!(
                    concat!(
                        "./test_sources/",
                        concat!(
                        stringify!($filename), ".", stringify!($ext))
                    )
                 );

                 let parser = AsciidocParser::default();
                 let dict = FstDictionary::curated();
                 let document = Document::new(&source, &parser, &dict);

                 let mut linter = LintGroup::new_curated(dict, Dialect::American);
                 let lints = linter.lint(&document);

                 dbg!(&lints);
                 assert_eq!(lints.len(), $correct_expected);

                 // Make sure that all generated tokens span real characters
                 for token in document.tokens(){
                     assert!(token.span.try_get_content(document.get_source()).is_some());
                 }
            }
        }
    };
}

create_test!(basic.adoc, 2);
create_test!(table.adoc, 1);
create_test!(comment.adoc, 2);
create_test!(comprehensive.adoc, 13);



================================================
FILE: harper-asciidoc/tests/test_sources/basic.adoc
================================================
= This is a titlle

This is a basic paragraph with a typo here: mstakes.



================================================
FILE: harper-asciidoc/tests/test_sources/comment.adoc
================================================
// This is a comment with a typo: spelll
// Another line of comment.



================================================
FILE: harper-asciidoc/tests/test_sources/comprehensive.adoc
================================================
= Document Title
Author Name <author@example.com>
:revdate: 2026-01-01
:custom-attr: Value with typpo.

This is a paragraph with a deliberate typpo.

== Section Titlre

* List item with errorr
* Another item

.Block Titlle
[NOTE]
====
Admonition with mistacke.
====

|===
| Header with errorr | Header 2

| Cell with typpo | Cell 1.2
|===

// Comment with mistacke.

////
Block comment with errorr.
////

Indented block:
    This has a typpo too.

Term with errorr::
    Definition with mistacke.



================================================
FILE: harper-asciidoc/tests/test_sources/table.adoc
================================================
|===
| Cell 1 | Cell 2 with typo: errorr
|===



================================================
FILE: harper-brill/Cargo.toml
================================================
[package]
name = "harper-brill"
version = "1.5.1"
edition = "2024"
description = "The language checker for developers."
license = "Apache-2.0"
repository = "https://github.com/automattic/harper"

[dependencies]
harper-pos-utils = { path = "../harper-pos-utils/", version = "1.0.0" }
serde_json = "1.0.149"

[build-dependencies]
serde_json = "1.0.149"



================================================
FILE: harper-brill/src/lib.rs
================================================
use std::num::NonZero;
use std::rc::Rc;
use std::sync::{Arc, LazyLock};

pub use harper_pos_utils::{
    BrillChunker, BrillTagger, BurnChunkerCpu, CachedChunker, Chunker, FreqDict, Tagger, UPOS,
};

const BRILL_TAGGER_SOURCE: &str = include_str!("../trained_tagger_model.json");

static BRILL_TAGGER: LazyLock<Arc<BrillTagger<FreqDict>>> =
    LazyLock::new(|| Arc::new(uncached_brill_tagger()));

fn uncached_brill_tagger() -> BrillTagger<FreqDict> {
    serde_json::from_str(BRILL_TAGGER_SOURCE).unwrap()
}

/// Get a copy of a shared, lazily-initialized [`BrillTagger`]. There will be only one instance
/// per-process.
pub fn brill_tagger() -> Arc<BrillTagger<FreqDict>> {
    (*BRILL_TAGGER).clone()
}

const BRILL_CHUNKER_SOURCE: &str = include_str!("../trained_chunker_model.json");

static BRILL_CHUNKER: LazyLock<Arc<BrillChunker>> =
    LazyLock::new(|| Arc::new(uncached_brill_chunker()));

fn uncached_brill_chunker() -> BrillChunker {
    serde_json::from_str(BRILL_CHUNKER_SOURCE).unwrap()
}

/// Get a copy of a shared, lazily-initialized [`BrillChunker`]. There will be only one instance
/// per-process.
pub fn brill_chunker() -> Arc<BrillChunker> {
    (*BRILL_CHUNKER).clone()
}

const BURN_CHUNKER_VOCAB: &[u8; 627993] = include_bytes!("../finished_chunker/vocab.json");
const BURN_CHUNKER_BIN: &[u8; 806312] = include_bytes!("../finished_chunker/model.mpk");

thread_local! {
    static BURN_CHUNKER: Rc<CachedChunker<BurnChunkerCpu>> =  Rc::new(uncached_burn_chunker());
}

fn uncached_burn_chunker() -> CachedChunker<BurnChunkerCpu> {
    CachedChunker::new(
        BurnChunkerCpu::load_from_bytes_cpu(BURN_CHUNKER_BIN, BURN_CHUNKER_VOCAB, 6, 0.3),
        NonZero::new(10000).unwrap(),
    )
}

/// Get a copy of a shared, lazily-initialized [`BurnChunkerCpu`]. There will be only one instance
/// per-process. Since neural net inference is extremely expensive, this chunker is memoized as
/// well.
pub fn burn_chunker() -> Rc<CachedChunker<BurnChunkerCpu>> {
    (BURN_CHUNKER).with(|c| c.clone())
}



================================================
FILE: harper-cli/README.md
================================================
# `harper-cli`

## What?

`harper-cli` is a small, experimental frontend for Harper.
It can be used in any situation where you might need to check a large number of files automatically (like in continuous integration).

Right now it is quite feature barren, mainly because an external use-case has not been defined yet.
If you have any thoughts, feel free to reach out.

## Possible Future Features

- On-disk caching
- Custom dictionaries (maybe use the same ones as `harper-ls`?)
- Machine-readable output



================================================
FILE: harper-cli/Cargo.toml
================================================
[package]
name = "harper-cli"
version = "0.1.0"
edition = "2024"
publish = false
repository = "https://github.com/automattic/harper"

[dependencies]
anyhow = "1.0.100"
ariadne = "0.6.0"
clap = { version = "4.5.54", features = ["derive", "std", "string"], default-features = false }
harper-stats = { path = "../harper-stats", version = "1.0.0" }
dirs = "6.0.0"
harper-literate-haskell = { path = "../harper-literate-haskell", version = "1.0.0" }
harper-python = { path = "../harper-python", version = "1.0.0" }
harper-asciidoc = { path = "../harper-asciidoc", version = "1.0.0" }
harper-core = { path = "../harper-core", version = "1.0.0" }
harper-pos-utils = { path = "../harper-pos-utils", version = "1.0.0", features = [] }
harper-comments = { path = "../harper-comments", version = "1.0.0" }
harper-typst = { path = "../harper-typst", version = "1.0.0" }
hashbrown = "0.16.1"
rayon = "1.11.0"
serde = { version = "1.0.228", features = ["derive"] }
serde_json = "1.0.149"
strum = "0.27.2"
strum_macros = "0.27.2"
harper-ink = { version = "1.0.0", path = "../harper-ink" }
enum_dispatch = "0.3.13"

[features]
default = []
training = ["harper-pos-utils/training"]



================================================
FILE: harper-cli/src/annotate.rs
================================================
use std::{borrow::Cow, ops::Range};

use ariadne::{Color, Label, Report, ReportKind};
use clap::ValueEnum;
use harper_core::{Document, Span, TokenKind, TokenStringExt};
use strum::IntoEnumIterator;

/// Represents an annotation.
pub(super) struct Annotation {
    /// The range the annotation covers in the source. For instance, this might be a single word.
    span: Span<char>,
    /// The message displayed by the annotation.
    annotation_text: String,
    /// The color of the annotation.
    color: Color,
}
impl Annotation {
    /// Converts the annotation into an [`ariadne::Label`].
    #[must_use]
    pub(super) fn into_label(
        self,
        input_identifier: &str,
    ) -> Label<(&str, std::ops::Range<usize>)> {
        Label::new((input_identifier, self.span.into()))
            .with_message(self.annotation_text)
            .with_color(self.color)
    }

    /// Gets an iterator of annotation `Label` from the given document.
    ///
    /// This is similar to [`Self::iter_from_document`], but this additionally converts
    /// the [`Annotation`] into [`ariadne::Label`] for convenience.
    pub(super) fn iter_labels_from_document<'inpt_id>(
        annotation_type: AnnotationType,
        document: &Document,
        input_identifier: &'inpt_id str,
    ) -> impl Iterator<Item = Label<(&'inpt_id str, std::ops::Range<usize>)>> {
        Self::iter_from_document(annotation_type, document)
            .map(|annotation| annotation.into_label(input_identifier))
    }

    /// Gets an iterator of [`Annotation`] for a given document. The annotations will be based on
    /// `annotation_type`.
    fn iter_from_document(
        annotation_type: AnnotationType,
        document: &Document,
    ) -> Box<dyn Iterator<Item = Self> + '_> {
        match annotation_type {
            AnnotationType::Upos => Box::new({
                document.tokens().filter_map(|token| {
                    let span = token.span;
                    if let TokenKind::Word(Some(metadata)) = &token.kind {
                        // Only annotate words (with dict word metadata) for `AnnotationType::Upos`.
                        let pos_tag = metadata.pos_tag;
                        Some(Self {
                            span,
                            annotation_text: pos_tag
                                .map_or("NONE".to_owned(), |upos| upos.to_string()),
                            color: pos_tag.map_or(Color::Red, get_color_for_enum_variant),
                        })
                    } else {
                        // Not a word, or a word with no metadata.
                        None
                    }
                })
            }),
            AnnotationType::Chunks => Box::new(
                document
                    .iter_chunks()
                    .zip(RandomColorIter::new())
                    .enumerate()
                    .map(|(i, (chunk, color))| Self {
                        span: chunk.span().unwrap(),
                        annotation_text: i.to_string(),
                        color,
                    }),
            ),
        }
    }
}

/// Represents how the tokens should be annotated.
#[derive(Debug, Clone, Copy, ValueEnum)]
pub(super) enum AnnotationType {
    /// UPOS (part of speech)
    Upos,
    Chunks,
}
impl AnnotationType {
    /// Build a [`Report`] from the provided [`Document`], `input_identifier`, and `report_title`.
    pub(super) fn build_report<'input_id>(
        &self,
        doc: &Document,
        input_identifier: &'input_id str,
        report_title: &'input_id str,
    ) -> Report<'input_id, (&'input_id str, Range<usize>)> {
        Report::build(
            ReportKind::Custom(report_title, Color::Blue),
            (input_identifier, 0..0),
        )
        .with_labels(Annotation::iter_labels_from_document(
            *self,
            doc,
            input_identifier,
        ))
        .finish()
    }

    /// The title that should be used for the printed output.
    pub(super) fn get_title(&self) -> &'static str {
        match self {
            AnnotationType::Upos => "UPOS Tags",
            AnnotationType::Chunks => "Chunks",
        }
    }

    /// The title that should be used for the printed output, with added tags.
    ///
    /// The tags are used to provide additional information about the output.
    pub(super) fn get_title_with_tags(&self, tags: &[&str]) -> Cow<'static, str> {
        if tags.is_empty() {
            self.get_title().into()
        } else {
            let tags = tags.join(", ");
            (self.get_title().to_owned() + &format!(" ({tags})")).into()
        }
    }
}

/// An infinite iterator that produces random colors. This uses a fixed seed, so all instances of
/// this iterator will produce colors in the same order.
struct RandomColorIter {
    color_gen: ariadne::ColorGenerator,
}
impl RandomColorIter {
    fn new() -> Self {
        Self {
            // Using a lower than default `min_brightness` to hopefully create more distinguishable colors.
            color_gen: ariadne::ColorGenerator::from_state([31715, 3528, 21854], 0.2),
        }
    }
}
impl Iterator for RandomColorIter {
    type Item = Color;
    fn next(&mut self) -> Option<Self::Item> {
        Some(self.color_gen.next())
    }
}

/// Gets a random `Color` for an enum variant.
///
/// A given enum variant's color is consistent, meaning it will not change throughout multiple
/// calls of this function or multiple runs of the application.
#[must_use]
fn get_color_for_enum_variant<T: IntoEnumIterator + PartialEq>(variant_to_color: T) -> Color {
    get_color_for_index(
        T::iter()
            .position(|variant| variant == variant_to_color)
            .unwrap(),
    )
}

/// Gets the nth random `Color` for a numeric index.
///
/// A given index's color is consistent, meaning it will not change throughout multiple calls of
/// this function or multiple runs of the application.
#[must_use]
fn get_color_for_index(idx_to_color: usize) -> Color {
    RandomColorIter::new().nth(idx_to_color).unwrap()
}



================================================
FILE: harper-cli/src/input.rs
================================================
use std::borrow::Cow;

use enum_dispatch::enum_dispatch;
use strum_macros::EnumTryAs;

pub mod single_input;
use single_input::SingleInput;

pub mod multi_input;
use multi_input::MultiInput;

/// The general trait implemented by all input types.
#[enum_dispatch]
pub(crate) trait InputTrait {
    /// Gets a human-readable identifier for the input. For example, this can be a filename, or
    /// simply the string `"<input>"`.
    fn get_identifier(&self) -> Cow<'_, str>;
}

/// Represents an input/source passed via the command line. For example, this can be a file,
/// a directory, or text passed via the command line directly.
#[enum_dispatch(InputTrait)]
#[derive(Clone, EnumTryAs)]
pub(crate) enum AnyInput {
    /// An input of a single source. For instance, a specific file, or input from standard input.
    Single(SingleInput),
    /// An input of multiple sources. For instance, a path to a directory.
    Multi(MultiInput),
}

// This allows this type to be directly used with clap as an argument.
// https://docs.rs/clap/latest/clap/macro.value_parser.html
impl From<String> for AnyInput {
    /// Converts the given string into an `Input` by trying to detect the input type.
    fn from(input_string: String) -> Self {
        if let Ok(multi_input) = MultiInput::try_parse_string(&input_string) {
            Self::Multi(multi_input)
        } else {
            Self::Single(SingleInput::parse_string(&input_string))
        }
    }
}

// This allows this type to be directly used with clap as an argument.
// It can be used in place of AnyInput if the command should only accept single-inputs
// (e.g. a file).
impl From<String> for SingleInput {
    fn from(input_string: String) -> Self {
        SingleInput::parse_string(&input_string)
    }
}

// This allows this type to be directly used with clap as an argument.
// It can be used in place of AnyInput if the command should only accept multi-inputs,
// (e.g. directories).
impl From<String> for MultiInput {
    fn from(input_string: String) -> Self {
        MultiInput::try_parse_string(&input_string).unwrap()
    }
}



================================================
FILE: harper-cli/src/lint.rs
================================================
use std::borrow::Cow;
use std::collections::BTreeMap;
use std::path::{Component, Path, PathBuf};
use std::sync::Arc;
use std::{fs, process};

use ariadne::{Color, Fmt, Label, Report, ReportKind, Source};
use hashbrown::HashMap;
use rayon::prelude::*;

use harper_core::{
    linting::{Lint, LintGroup, LintGroupConfig, LintKind},
    parsers::MarkdownOptions,
    spell::{Dictionary, MergedDictionary, MutableDictionary},
    {Dialect, DictWordMetadata, Document, Token, TokenKind, remove_overlaps_map},
};

use crate::input::{
    AnyInput, InputTrait,
    multi_input::MultiInput,
    single_input::{SingleInput, SingleInputTrait, StdinInput},
};

/// Sync version of harper-ls/src/dictionary_io@load_dict
fn load_dict(path: &Path) -> anyhow::Result<MutableDictionary> {
    let str = fs::read_to_string(path)?;

    let mut dict = MutableDictionary::new();
    dict.extend_words(
        str.lines()
            .map(|l| (l.chars().collect::<Vec<_>>(), DictWordMetadata::default())),
    );

    Ok(dict)
}

/// Path version of harper-ls/src/dictionary_io@file_dict_name
fn file_dict_name(path: &Path) -> PathBuf {
    let mut rewritten = String::new();

    for seg in path.components() {
        if !matches!(seg, Component::RootDir) {
            rewritten.push_str(&seg.as_os_str().to_string_lossy());
            rewritten.push('%');
        }
    }

    rewritten.into()
}

pub struct LintOptions {
    pub count: bool,
    pub ignore: Option<Vec<String>>,
    pub only: Option<Vec<String>>,
    pub keep_overlapping_lints: bool,
    pub dialect: Dialect,
}
enum ReportStyle {
    FullAriadneLintReport,
    BriefCountsOnlyLintReport,
}

struct InputInfo<'a> {
    parent_input_id: &'a str,
    input: &'a AnyInput,
}

struct InputJob {
    batch_mode: bool,
    parent_input_id: String,
    input: AnyInput,
}

impl InputInfo<'_> {
    fn format_path(&self) -> String {
        let child = self.input.get_identifier();
        if self.parent_input_id.is_empty() {
            child.into_owned()
        } else {
            format!("\x1b[33m{}/\x1b[0m{}", self.parent_input_id, child)
        }
    }
}

pub fn lint(
    markdown_options: MarkdownOptions,
    curated_dictionary: Arc<dyn Dictionary>,
    mut inputs: Vec<AnyInput>,
    mut lint_options: LintOptions,
    user_dict_path: PathBuf,
    // TODO workspace_dict_path?
    file_dict_path: PathBuf,
) -> anyhow::Result<()> {
    let LintOptions {
        count,
        ref mut ignore,
        ref mut only,
        dialect,
        ..
    } = lint_options;

    // Zero or more inputs, default to stdin if not provided
    if inputs.is_empty() {
        inputs.push(SingleInput::from(StdinInput).into());
    }

    // Filter out any rules from ignore/only lists that don't exist in the current config
    // Uses a cached config to avoid expensive linter initialization
    let config = LintGroupConfig::new_curated();

    if let Some(only) = only {
        only.retain(|rule| {
            if !config.has_rule(rule) {
                eprintln!("Warning: Cannot enable unknown rule '{}'.", rule);
                return false;
            }
            true
        });
    }

    if let Some(ignore) = ignore {
        ignore.retain(|rule| {
            if !config.has_rule(rule) {
                eprintln!("Warning: Cannot disable unknown rule '{}'.", rule);
                return false;
            }
            true
        });
    }

    // Create merged dictionary with base dictionary
    let mut curated_plus_user_dict = MergedDictionary::new();
    curated_plus_user_dict.add_dictionary(Arc::new(curated_dictionary));

    let user_dict_msg = match load_dict(&user_dict_path) {
        Ok(user_dict) => {
            curated_plus_user_dict.add_dictionary(Arc::new(user_dict));
            "Using"
        }
        Err(_) => "There is no",
    };
    println!(
        "Note: {user_dict_msg} user dictionary at {}",
        user_dict_path.display()
    );

    // The lint stats for all files
    let mut all_lint_kinds: HashMap<LintKind, usize> = HashMap::new();
    let mut all_rules: HashMap<String, usize> = HashMap::new();
    let mut all_lint_kind_rule_pairs: HashMap<(LintKind, String), usize> = HashMap::new();
    let mut all_spellos: HashMap<String, usize> = HashMap::new();

    // Convert the 'count' flag into a ReportStyle enum
    let report_mode = match count {
        true => ReportStyle::BriefCountsOnlyLintReport,
        false => ReportStyle::FullAriadneLintReport,
    };

    let mut input_jobs = Vec::new();
    for user_input in inputs {
        if let Some(dir_input) = user_input
            .try_as_multi_ref()
            .and_then(MultiInput::try_as_dir_ref)
        {
            let mut file_entries: Vec<_> = dir_input.iter_files()?.collect();

            file_entries.sort_by(|a, b| a.path().file_name().cmp(&b.path().file_name()));

            for entry in file_entries.into_iter().map(SingleInput::from) {
                input_jobs.push(InputJob {
                    batch_mode: true,
                    parent_input_id: user_input.get_identifier().to_string(),
                    input: entry.into(),
                });
            }
        } else {
            input_jobs.push(InputJob {
                batch_mode: false,
                parent_input_id: String::new(),
                input: user_input.clone(),
            });
        }
    }

    let per_input_results = {
        let run_job = |job: InputJob| {
            let InputJob {
                batch_mode,
                parent_input_id,
                input,
            } = job;
            lint_one_input(
                // Common properties of harper-cli
                markdown_options,
                &curated_plus_user_dict,
                // Passed from the user for the `lint` subcommand
                &report_mode,
                &lint_options,
                &file_dict_path,
                // Are we linting multiple inputs inside a directory?
                batch_mode,
                // The current input to be linted
                InputInfo {
                    parent_input_id: parent_input_id.as_str(),
                    input: &input,
                },
            )
        };

        if input_jobs.len() > 1 {
            input_jobs.into_par_iter().map(run_job).collect::<Vec<_>>()
        } else {
            input_jobs.into_iter().map(run_job).collect::<Vec<_>>()
        }
    };

    for lint_results in per_input_results {
        // Update the global stats
        for (kind, count) in lint_results.0 {
            *all_lint_kinds.entry(kind).or_insert(0) += count;
        }
        for (rule, count) in lint_results.1 {
            *all_rules.entry(rule).or_insert(0) += count;
        }
        for ((kind, rule), count) in lint_results.2 {
            *all_lint_kind_rule_pairs.entry((kind, rule)).or_insert(0) += count;
        }
        for (word, count) in lint_results.3 {
            *all_spellos.entry(word).or_insert(0) += count;
        }
    }

    final_report(
        dialect,
        true,
        all_lint_kinds,
        all_rules,
        all_lint_kind_rule_pairs,
        all_spellos,
    );

    process::exit(1);
}

type LintKindCount = HashMap<LintKind, usize>;
type LintRuleCount = HashMap<String, usize>;
type LintKindRulePairCount = HashMap<(LintKind, String), usize>;
type SpelloCount = HashMap<String, usize>;

struct FullInputInfo<'a> {
    input: InputInfo<'a>,
    doc: Document,
    source: Cow<'a, str>,
}

fn lint_one_input(
    // Common properties of harper-cli
    markdown_options: MarkdownOptions,
    curated_plus_user_dict: &MergedDictionary,
    report_mode: &ReportStyle,
    // Options passed from the user specific to the `lint` subcommand
    lint_options: &LintOptions,
    file_dict_path: &Path,
    // Are we linting multiple inputs?
    batch_mode: bool,
    // For the current input
    current: InputInfo,
) -> (
    LintKindCount,
    LintRuleCount,
    LintKindRulePairCount,
    SpelloCount,
) {
    let LintOptions {
        count: _,
        ignore,
        only,
        keep_overlapping_lints,
        dialect,
    } = lint_options;

    let mut lint_kinds: HashMap<LintKind, usize> = HashMap::new();
    let mut lint_rules: HashMap<String, usize> = HashMap::new();
    let mut lint_kind_rule_pairs: HashMap<(LintKind, String), usize> = HashMap::new();
    let mut spellos: HashMap<String, usize> = HashMap::new();

    if let Some(single_input) = current.input.try_as_single_ref() {
        // Create a new merged dictionary for this input.
        let mut merged_dictionary = curated_plus_user_dict.clone();

        // If processing a file, try to load its per-file dictionary
        if let Some(file) = single_input.try_as_file_ref() {
            let dict_path = file_dict_path.join(file_dict_name(file.path()));
            if let Ok(file_dictionary) = load_dict(&dict_path) {
                merged_dictionary.add_dictionary(Arc::new(file_dictionary));
                println!(
                    "{}: Note: Using per-file dictionary: {}",
                    current.format_path(),
                    dict_path.display()
                );
            }
        }

        match single_input.load(markdown_options, &merged_dictionary) {
            Err(err) => eprintln!("{}", err),
            Ok((doc, source)) => {
                // Create the Lint Group from which we will lint this input, using the combined dictionary and the specified dialect
                let mut lint_group = LintGroup::new_curated(merged_dictionary.into(), *dialect);

                // Turn specified rules on or off
                configure_lint_group(&mut lint_group, only, ignore);

                // Run the linter, getting back a map of rule name -> lints
                let mut named_lints = lint_group.organized_lints(&doc);

                // Lint counts, for brief reporting
                let lint_count_before = named_lints.values().map(|v| v.len()).sum::<usize>();
                if !keep_overlapping_lints {
                    remove_overlaps_map(&mut named_lints);
                }
                let lint_count_after = named_lints.values().map(|v| v.len()).sum::<usize>();

                // Extract the lint kinds and rules etc. for reporting
                (lint_kinds, lint_rules) = count_lint_kinds_and_rules(&named_lints);
                lint_kind_rule_pairs = collect_lint_kind_rule_pairs(&named_lints);
                spellos = collect_spellos(&named_lints, doc.get_source());

                single_input_report(
                    &FullInputInfo {
                        input: InputInfo {
                            parent_input_id: current.parent_input_id,
                            input: current.input,
                        },
                        doc,
                        source,
                    },
                    // Linting results of this input
                    &named_lints,
                    (lint_count_before, lint_count_after),
                    &lint_kinds,
                    &lint_rules,
                    // Reporting arguments
                    batch_mode,
                    report_mode,
                );
            }
        }
    }

    (lint_kinds, lint_rules, lint_kind_rule_pairs, spellos)
}

fn configure_lint_group(
    lint_group: &mut LintGroup,
    only: &Option<Vec<String>>,
    ignore: &Option<Vec<String>>,
) {
    if let Some(rules) = only {
        lint_group.set_all_rules_to(Some(false));
        rules
            .iter()
            .for_each(|rule| lint_group.config.set_rule_enabled(rule, true));
    }

    if let Some(rules) = ignore {
        rules
            .iter()
            .for_each(|rule| lint_group.config.set_rule_enabled(rule, false));
    }
}

fn count_lint_kinds_and_rules(
    named_lints: &BTreeMap<String, Vec<Lint>>,
) -> (HashMap<LintKind, usize>, HashMap<String, usize>) {
    let mut kinds = HashMap::new();
    let mut rules = HashMap::new();

    for (rule_name, lints) in named_lints {
        lints
            .iter()
            .for_each(|lint| *kinds.entry(lint.lint_kind).or_insert(0) += 1);

        if !lints.is_empty() {
            *rules.entry(rule_name.to_string()).or_insert(0) += lints.len();
        }
    }

    (kinds, rules)
}

fn collect_lint_kind_rule_pairs(
    named_lints: &BTreeMap<String, Vec<Lint>>,
) -> HashMap<(LintKind, String), usize> {
    let mut pairs = HashMap::new();

    for (rule_name, lints) in named_lints {
        for lint in lints {
            pairs
                .entry((lint.lint_kind, rule_name.to_string()))
                .and_modify(|count| *count += 1)
                .or_insert(1);
        }
    }

    pairs
}

fn collect_spellos(
    named_lints: &BTreeMap<String, Vec<Lint>>,
    source: &[char],
) -> HashMap<String, usize> {
    named_lints
        .get("SpellCheck")
        .into_iter()
        .flatten()
        .map(|lint| lint.span.get_content_string(source))
        .fold(HashMap::new(), |mut acc, spello| {
            *acc.entry(spello).or_insert(0) += 1;
            acc
        })
}

fn single_input_report(
    // Properties of the current input
    input_info: &FullInputInfo,
    // Linting results of this input
    named_lints: &BTreeMap<String, Vec<Lint>>,
    lint_count: (usize, usize),
    lint_kinds: &HashMap<LintKind, usize>,
    lint_rules: &HashMap<String, usize>,
    // Reporting parameters
    batch_mode: bool, // If true, we are processing multiple files, which affects how we report
    report_mode: &ReportStyle,
) {
    let FullInputInfo { input, doc, source } = input_info;
    let (lint_count_before, lint_count_after) = lint_count;
    // The Ariadne report works poorly for files with very long lines, so suppress it unless only processing one file
    const MAX_LINE_LEN: usize = 150;

    let mut report_mode = report_mode;
    let longest = find_longest_doc_line(doc.get_tokens());

    if batch_mode
        && longest > MAX_LINE_LEN
        && matches!(report_mode, ReportStyle::FullAriadneLintReport)
    {
        report_mode = &ReportStyle::BriefCountsOnlyLintReport;
        println!(
            "{}: Longest line: {longest} exceeds max line length: {MAX_LINE_LEN}",
            input.format_path()
        );
    }

    // Report the number of lints no matter what report mode we are in
    println!(
        "{}: {}",
        input.format_path(),
        match (lint_count_before, lint_count_after) {
            (0, _) => "No lints found".to_string(),
            (before, after) if before != after =>
                format!("{before} lints before overlap removal, {after} after"),
            (before, _) => format!("{before} lints"),
        }
    );

    // If we are in Ariadne mode, print the report
    if matches!(report_mode, ReportStyle::FullAriadneLintReport) {
        let primary_color = Color::Magenta;

        let input_identifier = input.input.get_identifier();

        if lint_count_after != 0 {
            let mut report_builder = Report::build(ReportKind::Advice, (&input_identifier, 0..0));

            for (rule_name, lints) in named_lints {
                for lint in lints {
                    let (r, g, b) = rgb_for_lint_kind(Some(&lint.lint_kind));
                    report_builder = report_builder.with_label(
                        Label::new((&input_identifier, lint.span.into()))
                            .with_message(format!(
                                "{} {}: {}",
                                format_args!("[{}::{}]", lint.lint_kind, rule_name)
                                    .fg(ariadne::Color::Rgb(r, g, b)),
                                format_args!("(pri {})", lint.priority).fg(ariadne::Color::Rgb(
                                    (r as f32 * 0.66) as u8,
                                    (g as f32 * 0.66) as u8,
                                    (b as f32 * 0.66) as u8
                                )),
                                lint.message
                            ))
                            .with_color(primary_color),
                    );
                }
            }

            let report = report_builder.finish();
            report.print((&input_identifier, Source::from(source))).ok();
        }
    }

    // Print the more detailed counts for the lint kinds and then for the rules
    if !lint_kinds.is_empty() {
        let mut lint_kinds_vec: Vec<_> = lint_kinds.iter().collect();
        lint_kinds_vec.sort_by_key(|(lk, count)| (std::cmp::Reverse(**count), lk.to_string()));

        let lk_vec: Vec<(Option<String>, String)> = lint_kinds_vec
            .into_iter()
            .map(|(lk, c)| {
                let (r, g, b) = rgb_for_lint_kind(Some(lk));
                (
                    Some(format!("\x1b[38;2;{r};{g};{b}m")),
                    format!("[{lk}: {c}]"),
                )
            })
            .collect();

        println!("lint kinds:");
        print_formatted_items(lk_vec);
    }

    if !lint_rules.is_empty() {
        let mut rules_vec: Vec<_> = lint_rules.iter().collect();
        rules_vec.sort_by_key(|(rn, count)| (std::cmp::Reverse(**count), rn.to_string()));

        let r_vec: Vec<(Option<String>, String)> = rules_vec
            .into_iter()
            .map(|(rn, c)| (None, format!("<{rn}: {c}>")))
            .collect();

        println!("rules:");
        print_formatted_items(r_vec);
    }
}

fn find_longest_doc_line(toks: &[Token]) -> usize {
    let mut longest_len_chars = 0;
    let mut curr_len_chars = 0;
    let mut current_line_start_tok_idx = 0;

    for (idx, tok) in toks.iter().enumerate() {
        if matches!(tok.kind, TokenKind::Newline(_))
            || matches!(tok.kind, TokenKind::ParagraphBreak)
        {
            if curr_len_chars > longest_len_chars {
                longest_len_chars = curr_len_chars;
            }
            curr_len_chars = 0;
            current_line_start_tok_idx = idx + 1;
        } else if matches!(tok.kind, TokenKind::Unlintable) {
            // TODO would be more accurate to scan for \n in the tok.span.get_content(src)
        } else {
            curr_len_chars += tok.span.len();
        }
    }

    if curr_len_chars > longest_len_chars
        && !toks.is_empty()
        && current_line_start_tok_idx < toks.len()
    {
        longest_len_chars = curr_len_chars;
    }

    longest_len_chars
}

fn final_report(
    dialect: Dialect,
    batch_mode: bool,
    all_lint_kinds: HashMap<LintKind, usize>,
    all_rules: HashMap<String, usize>,
    all_lint_kind_rule_pairs: HashMap<(LintKind, String), usize>,
    all_spellos: HashMap<String, usize>,
) {
    // The stats summary of all inputs that we only do when there are multiple inputs.
    if batch_mode {
        let mut all_files_lint_kind_counts_vec: Vec<(LintKind, _)> =
            all_lint_kinds.into_iter().collect();
        all_files_lint_kind_counts_vec
            .sort_by_key(|(lk, count)| (std::cmp::Reverse(*count), lk.to_string()));

        let lint_kind_counts: Vec<(Option<String>, String)> = all_files_lint_kind_counts_vec
            .into_iter()
            .map(|(lint_kind, c)| {
                let (r, g, b) = rgb_for_lint_kind(Some(&lint_kind));
                (
                    Some(format!("\x1b[38;2;{r};{g};{b}m")),
                    format!("[{lint_kind}: {c}]"),
                )
            })
            .collect();

        if !lint_kind_counts.is_empty() {
            println!("All files lint kinds:");
            print_formatted_items(lint_kind_counts);
        }

        let mut all_files_rule_name_counts_vec: Vec<_> = all_rules.into_iter().collect();
        all_files_rule_name_counts_vec
            .sort_by_key(|(rule_name, count)| (std::cmp::Reverse(*count), rule_name.to_string()));

        let rule_name_counts: Vec<(Option<String>, String)> = all_files_rule_name_counts_vec
            .into_iter()
            .map(|(rule_name, count)| (None, format!("({rule_name}: {count})")))
            .collect();

        if !rule_name_counts.is_empty() {
            println!("All files rule names:");
            print_formatted_items(rule_name_counts);
        }
    }

    // The stats summary of all pairs of lint kind + rule name, whether there is only one input or multiple.
    let mut lint_kind_rule_pairs: Vec<_> = all_lint_kind_rule_pairs.into_iter().collect();
    lint_kind_rule_pairs.sort_by(|a, b| {
        let (a, b) = ((&a.0, &a.1), (&b.0, &b.1));
        b.1.cmp(a.1)
            .then_with(|| a.0.0.to_string().cmp(&b.0.0.to_string()))
            .then_with(|| a.0.1.cmp(&b.0.1))
    });

    // Format them using their colours
    let formatted_lint_kind_rule_pairs: Vec<(Option<String>, String)> = lint_kind_rule_pairs
        .into_iter()
        .map(|ele| {
            let (r, g, b) = rgb_for_lint_kind(Some(&ele.0.0));
            let ansi_prefix = format!("\x1b[38;2;{r};{g};{b}m");
            (
                Some(ansi_prefix),
                format!("«« {} {}·{} »»", ele.1, ele.0.0, ele.0.1),
            )
        })
        .collect();

    if !formatted_lint_kind_rule_pairs.is_empty() {
        // Print them with line wrapping
        print_formatted_items(formatted_lint_kind_rule_pairs);
    }

    if !all_spellos.is_empty() {
        // Group by lowercase spelling while preserving original case and counts
        let mut grouped: HashMap<String, Vec<(String, usize)>> = HashMap::new();
        for (spelling, count) in all_spellos {
            grouped
                .entry(spelling.to_lowercase())
                .or_default()
                .push((spelling, count));
        }

        // Create a vector of (lowercase_spelling, variants, total_count)
        let mut grouped_vec: Vec<_> = grouped
            .into_iter()
            .map(|(lower, variants)| {
                let total: usize = variants.iter().map(|(_, c)| c).sum();
                (lower, variants, total)
            })
            .collect();

        // Sort by total count (descending), then by lowercase spelling
        grouped_vec.sort_by(|a, b| b.2.cmp(&a.2).then_with(|| a.0.cmp(&b.0)));

        // Flatten the variants back out, but keep track of the group index for coloring
        let spelling_vec: Vec<(Option<String>, String)> = grouped_vec
            .into_iter()
            .enumerate()
            .flat_map(|(i, (_, variants, _))| {
                // Sort variants by count (descending) then by original spelling
                let mut variants = variants;
                variants.sort_by(|a, b| b.1.cmp(&a.1).then_with(|| a.0.cmp(&b.0)));

                // Choose colour based on group index (rotating through three colours)
                let (r, g, b) = match i % 3 {
                    0 => (180, 90, 150), // Magenta
                    1 => (90, 180, 90),  // Green
                    _ => (90, 150, 180), // Cyan
                };
                let color = format!("\x1b[38;2;{};{};{}m", r, g, b);

                variants
                    .into_iter()
                    .map(move |(spelling, c)| (Some(color.clone()), format!("(“{spelling}”: {c})")))
            })
            .collect();

        println!("All files Spelling::SpellCheck (For dialect: {})", dialect);
        print_formatted_items(spelling_vec);
    }
}

// Note: This must be kept synchronized with:
// packages/lint-framework/src/lint/lintKindColor.ts
// packages/web/src/lib/lintKindColor.ts
// This can be removed when issue #1991 is resolved.
fn lint_kind_to_rgb() -> &'static [(LintKind, (u8, u8, u8))] {
    &[
        (LintKind::Agreement, (0x22, 0x8B, 0x22)),
        (LintKind::BoundaryError, (0x8B, 0x45, 0x13)),
        (LintKind::Capitalization, (0x54, 0x0D, 0x6E)),
        (LintKind::Eggcorn, (0xFF, 0x8C, 0x00)),
        (LintKind::Enhancement, (0x0E, 0xAD, 0x69)),
        (LintKind::Formatting, (0x7D, 0x3C, 0x98)),
        (LintKind::Grammar, (0x9B, 0x59, 0xB6)),
        (LintKind::Malapropism, (0xC7, 0x15, 0x85)),
        (LintKind::Miscellaneous, (0x3B, 0xCE, 0xAC)),
        (LintKind::Nonstandard, (0x00, 0x8B, 0x8B)),
        (LintKind::Punctuation, (0xD4, 0x85, 0x0F)),
        (LintKind::Readability, (0x2E, 0x8B, 0x57)),
        (LintKind::Redundancy, (0x46, 0x82, 0xB4)),
        (LintKind::Regionalism, (0xC0, 0x61, 0xCB)),
        (LintKind::Repetition, (0x00, 0xA6, 0x7C)),
        (LintKind::Spelling, (0xEE, 0x42, 0x66)),
        (LintKind::Style, (0xFF, 0xD2, 0x3F)),
        (LintKind::Typo, (0xFF, 0x6B, 0x35)),
        (LintKind::Usage, (0x1E, 0x90, 0xFF)),
        (LintKind::WordChoice, (0x22, 0x8B, 0x22)),
    ]
}

fn rgb_for_lint_kind(olk: Option<&LintKind>) -> (u8, u8, u8) {
    olk.and_then(|lk| {
        lint_kind_to_rgb()
            .iter()
            .find(|(k, _)| k == lk)
            .map(|(_, color)| *color)
    })
    .unwrap_or((0, 0, 0))
}

fn print_formatted_items(items: impl IntoIterator<Item = (Option<String>, String)>) {
    let mut first_on_line = true;
    let mut len_so_far = 0;

    for (ansi, text) in items {
        let text_len = text.len();

        let mut len_to_add = !first_on_line as usize + text_len;

        let mut before = "";
        if len_so_far + len_to_add > 120 {
            before = "\n";
            len_to_add -= 1; // no space before the first item
            len_so_far = 0;
        } else if !first_on_line {
            before = " ";
        }

        let (set, reset): (&str, &str) = if let Some(prefix) = ansi.as_ref() {
            (prefix, "\x1b[0m")
        } else {
            ("", "")
        };
        print!("{}{}{}{}", before, set, text, reset);
        len_so_far += len_to_add;
        first_on_line = false;
    }
    println!();
}



================================================
FILE: harper-cli/src/main.rs
================================================
#![doc = include_str!("../README.md")]

use harper_core::spell::{Dictionary, FstDictionary, MutableDictionary, WordId};
use hashbrown::HashMap;
use std::collections::BTreeMap;
use std::fs::File;
use std::io::BufReader;
use std::path::PathBuf;
// use std::sync::Arc;
use std::{fs, process};

use anyhow::anyhow;
use ariadne::{Color, Label, Report, ReportKind, Source};
use clap::Parser;
use dirs::{config_dir, data_local_dir};
use harper_core::linting::LintGroup;
use harper_core::parsers::{IsolateEnglish, MarkdownOptions};
use harper_core::weir::WeirLinter;
use harper_core::{
    CharStringExt, Dialect, DictWordMetadata, OrthFlags, Span, TokenKind, TokenStringExt,
};
#[cfg(feature = "training")]
use harper_pos_utils::{BrillChunker, BrillTagger, BurnChunkerCpu};

use harper_stats::Stats;
use serde::Serialize;
use serde_json::Value;

mod input;
use input::{
    AnyInput, InputTrait,
    single_input::{SingleInput, SingleInputOptionExt, SingleInputTrait},
};

mod annotate;
use annotate::AnnotationType;

mod lint;
use crate::lint::lint;
use lint::LintOptions;

/// A debugging tool for the Harper grammar checker.
#[derive(Parser)]
#[command(version, about)]
enum Args {
    /// Lint provided documents.
    Lint {
        /// The text or file you wish to grammar check. If not provided, it will be read from
        /// standard input.
        inputs: Vec<AnyInput>,
        /// Whether to merely print out the number of errors encountered,
        /// without further details.
        #[arg(short, long)]
        count: bool,
        /// Restrict linting to only a specific set of rules.
        /// If omitted, `harper-cli` will run every rule.
        #[arg(long, value_delimiter = ',')]
        ignore: Option<Vec<String>>,
        /// Restrict linting to only a specific set of rules.
        /// If omitted, `harper-cli` will run every rule.
        #[arg(long, value_delimiter = ',')]
        only: Option<Vec<String>>,
        /// Overlapping lints are removed by default. This option disables that behavior.
        #[arg(short = 'o', long)]
        keep_overlapping_lints: bool,
        /// Specify the dialect.
        #[arg(short, long, default_value = Dialect::American.to_string())]
        dialect: Dialect,
        /// Path to the user dictionary.
        #[arg(short, long, default_value = config_dir().unwrap().join("harper-ls/dictionary.txt").into_os_string())]
        user_dict_path: PathBuf,
        /// Path to the directory for file-local dictionaries.
        #[arg(short, long, default_value = data_local_dir().unwrap().join("harper-ls/file_dictionaries/").into_os_string())]
        file_dict_path: PathBuf,
    },
    /// Parse a provided document and print the detected symbols.
    Parse {
        /// The text or file you wish to parse. If not provided, it will be read from standard
        /// input.
        input: Option<SingleInput>,
    },
    /// Parse a provided document and show the spans of the detected tokens.
    Spans {
        /// The file or text for which you wish to display the spans. If not provided, it will be
        /// read from standard input.
        input: Option<SingleInput>,
        /// Include newlines in the output
        #[arg(short, long)]
        include_newlines: bool,
    },
    /// Parse and annotate a provided document.
    Annotate {
        /// The text or file you wish to parse. If not provided, it will be read from standard
        /// input.
        input: Option<SingleInput>,
        /// How the document should be annotated.
        #[arg(short, long, value_enum, default_value_t = AnnotationType::Upos)]
        annotation_type: AnnotationType,
        /// Attempt to detect and ignore non-English spans of text.
        #[arg(short, long)]
        isolate_english: bool,
    },
    /// Get the metadata associated with one or more words.
    Metadata {
        words: Vec<String>,
        /// Only show the part-of-speech flags and emojis, not the full JSON
        #[arg(short, long)]
        brief: bool,
    },
    /// Get all the forms of a word using the affixes.
    Forms { line: String },
    /// Emit a decompressed, line-separated list of the words in Harper's dictionary.
    Words,
    /// Summarize a lint record
    SummarizeLintRecord { file: PathBuf },
    /// Print the default config with descriptions.
    Config,
    /// Print a list of all the words in a document, sorted by frequency.
    MineWords {
        /// The document to mine words from.
        input: Option<SingleInput>,
    },
    #[cfg(feature = "training")]
    TrainBrillTagger {
        #[arg(short, long, default_value = "1.0")]
        candidate_selection_chance: f32,
        /// The path to write the final JSON model file to.
        output: PathBuf,
        /// The number of epochs (and patch rules) to train.
        epochs: usize,
        /// Path to a `.conllu` dataset to train on.
        #[arg(num_args = 1..)]
        datasets: Vec<PathBuf>,
    },
    #[cfg(feature = "training")]
    TrainBrillChunker {
        #[arg(short, long, default_value = "1.0")]
        candidate_selection_chance: f32,
        /// The path to write the final JSON model file to.
        output: PathBuf,
        /// The number of epochs (and patch rules) to train.
        epochs: usize,
        /// Path to a `.conllu` dataset to train on.
        #[arg(num_args = 1..)]
        datasets: Vec<PathBuf>,
    },
    #[cfg(feature = "training")]
    TrainBurnChunker {
        #[arg(short, long)]
        lr: f64,
        // The number of embedding dimensions
        #[arg(long)]
        dim: usize,
        /// The path to write the final  model file to.
        #[arg(short, long)]
        output: PathBuf,
        /// The number of epochs to train.
        #[arg(short, long)]
        epochs: usize,
        /// The dropout probability
        #[arg(long)]
        dropout: f32,
        #[arg(short, long)]
        test_file: PathBuf,
        #[arg(num_args = 1..)]
        datasets: Vec<PathBuf>,
    },
    /// Print harper-core version.
    CoreVersion,
    /// Rename a flag in the dictionary and affixes.
    RenameFlag {
        /// The old flag.
        old: String,
        /// The new flag.
        new: String,
        /// The directory containing the dictionary and affixes.
        dir: PathBuf,
    },
    /// Audit the `dictionary.dict` file.
    AuditDictionary {
        /// The directory containing the dictionary and affixes.
        dir: PathBuf,
    },
    /// Emit a decompressed, line-separated list of the compounds in Harper's dictionary.
    /// As long as there's either an open or hyphenated spelling.
    Compounds,
    /// Emit a decompressed, line-separated list of the words in Harper's dictionary
    /// which occur in more than one lettercase variant.    
    CaseVariants,
    /// Emit a list of each noun phrase contained within the input
    NominalPhrases {
        /// The text or file to analyze. If not provided, it will be read from standard input.
        input: Option<SingleInput>,
    },
    /// Run the tests contained within a Weir file.
    Test {
        /// The location of the Weir file to test
        input: PathBuf,
    },
}

fn main() -> anyhow::Result<()> {
    let args = Args::parse();
    let markdown_options = MarkdownOptions::default();
    let curated_dictionary = FstDictionary::curated();

    match args {
        Args::Lint {
            inputs,
            count,
            ignore,
            only,
            keep_overlapping_lints,
            dialect,
            user_dict_path,
            // TODO workspace_dict_path?
            file_dict_path,
        } => {
            lint(
                markdown_options,
                curated_dictionary,
                inputs,
                LintOptions {
                    count,
                    ignore,
                    only,
                    keep_overlapping_lints,
                    dialect,
                },
                user_dict_path,
                // TODO workspace_dict_path?
                file_dict_path,
            )
        }
        Args::Parse { input } => {
            // Try to read from standard input if `input` was not provided.
            let input = input.unwrap_or_read_from_stdin();

            // Load the file/text.
            let (doc, _) = input.load(markdown_options, &curated_dictionary)?;

            for token in doc.tokens() {
                let json = serde_json::to_string(&token)?;
                println!("{json}");
            }

            Ok(())
        }
        Args::Spans {
            input,
            include_newlines,
        } => {
            // Try to read from standard input if `input` was not provided.
            let input = input.unwrap_or_read_from_stdin();

            // Load the file/text.
            let (doc, source) = input.load(markdown_options, &curated_dictionary)?;

            let primary_color = Color::Blue;
            let secondary_color = Color::Magenta;
            let unlintable_color = Color::Red;
            let input_identifier = input.get_identifier();

            let mut report_builder = Report::build(
                ReportKind::Custom("Spans", primary_color),
                (&input_identifier, 0..0),
            );
            let mut color = primary_color;

            for token in doc.tokens().filter(|t| {
                include_newlines
                    || !matches!(t.kind, TokenKind::Newline(_) | TokenKind::ParagraphBreak)
            }) {
                report_builder = report_builder.with_label(
                    Label::new((&input_identifier, token.span.into()))
                        .with_message(format!("[{}, {})", token.span.start, token.span.end))
                        .with_color(if matches!(token.kind, TokenKind::Unlintable) {
                            unlintable_color
                        } else {
                            color
                        }),
                );

                // Alternate colors so spans are clear
                color = if color == primary_color {
                    secondary_color
                } else {
                    primary_color
                };
            }

            let report = report_builder.finish();
            report.print((&input_identifier, Source::from(source)))?;

            Ok(())
        }
        Args::Annotate {
            input,
            annotation_type,
            isolate_english,
        } => {
            // Try to read from standard input if `input` was not provided.
            let input = input.unwrap_or_read_from_stdin();

            let parser = if isolate_english {
                Box::new(IsolateEnglish::new(
                    input.get_parser(markdown_options),
                    &curated_dictionary,
                ))
            } else {
                input.get_parser(markdown_options)
            };

            // Load the file/text.
            let (doc, source) = input.load_with_parser(&parser, &curated_dictionary)?;

            let input_identifier = input.get_identifier();

            annotation_type
                .build_report(
                    &doc,
                    &input_identifier,
                    &annotation_type.get_title_with_tags(if isolate_english {
                        &["Isolate english"]
                    } else {
                        &[]
                    }),
                )
                .print((&*input_identifier, Source::from(source)))?;

            Ok(())
        }
        Args::Words => {
            let mut word_str = String::new();

            for word in curated_dictionary.words_iter() {
                word_str.clear();
                word_str.extend(word);

                println!("{word_str:?}");
            }

            Ok(())
        }
        Args::Metadata { words, brief } => {
            type PosPredicate = fn(&DictWordMetadata) -> bool;

            const POS: &[(&str, PosPredicate)] = &[
                ("N📦", |m| m.is_noun() && !m.is_proper_noun()),
                ("O📛", DictWordMetadata::is_proper_noun),
                ("V🏃", DictWordMetadata::is_verb),
                ("J🌈", DictWordMetadata::is_adjective),
                ("R🤷", DictWordMetadata::is_adverb),
                ("C🔗", DictWordMetadata::is_conjunction),
                ("D👉", DictWordMetadata::is_determiner),
                ("P📥", |m| m.preposition),
                ("I👤", DictWordMetadata::is_pronoun),
            ];

            for word in words {
                let meta = curated_dictionary.get_word_metadata_str(&word);
                let (flags, emojis) = meta.as_ref().map_or_else(
                    || (String::new(), String::new()),
                    |md| {
                        POS.iter()
                            .filter(|&(_, pred)| pred(md))
                            .map(|(syms, _)| {
                                let mut ch = syms.chars();
                                (ch.next().unwrap(), ch.next().unwrap())
                            })
                            .unzip()
                    },
                );

                let json = brief.then(String::new).unwrap_or_else(|| {
                    format!("\n{}", serde_json::to_string_pretty(&meta).unwrap())
                });
                println!("{}: {} {}{}", word, flags, emojis, json);
            }
            Ok(())
        }
        Args::SummarizeLintRecord { file } => {
            let file = File::open(file)?;
            let mut reader = BufReader::new(file);
            let stats = Stats::read(&mut reader)?;

            let summary = stats.summarize();
            println!("{summary}");

            Ok(())
        }
        Args::Forms { line } => {
            let (word, annot) = line_to_parts(&line);

            let curated_word_list = include_str!("../../harper-core/dictionary.dict");
            let dict_lines = curated_word_list.split('\n');

            let mut entry_in_dict = None;

            // Check if the word is contained in the list.
            for dict_line in dict_lines {
                let (dict_word, dict_annot) = line_to_parts(dict_line);

                if dict_word == word {
                    entry_in_dict = Some((dict_word, dict_annot));
                    break;
                }
            }

            let summary = match &entry_in_dict {
                Some((dict_word, dict_annot)) => {
                    let mut status_summary = if dict_annot.is_empty() {
                        format!("'{dict_word}' is already in the dictionary but not annotated.")
                    } else {
                        format!(
                            "'{dict_word}' is already in the dictionary with annotation `{dict_annot}`."
                        )
                    };

                    if !annot.is_empty() {
                        if annot.as_str() != dict_annot.as_str() {
                            status_summary
                                .push_str("\n  Your annotations differ from the dictionary.\n");
                        } else {
                            status_summary
                                .push_str("\n  Your annotations are the same as the dictionary.\n");
                        }
                    }

                    status_summary
                }
                None => format!("'{word}' is not in the dictionary yet."),
            };

            println!("{summary}");

            if let Some((dict_word, dict_annot)) = &entry_in_dict {
                println!("Old, from the dictionary:");
                print_word_derivations(dict_word, dict_annot, &FstDictionary::curated());
            };

            if !annot.is_empty() {
                let rune_words = format!("1\n{line}");
                let dict = MutableDictionary::from_rune_files(
                    &rune_words,
                    include_str!("../../harper-core/annotations.json"),
                )?;

                println!("New, from you:");
                print_word_derivations(&word, &annot, &dict);
            }

            Ok(())
        }
        Args::Config => {
            #[derive(Serialize)]
            struct Config {
                default_value: bool,
                description: String,
            }

            let linter = LintGroup::new_curated(curated_dictionary, Dialect::American);

            let default_config: HashMap<String, bool> =
                serde_json::from_str(&serde_json::to_string(&linter.config).unwrap()).unwrap();

            // Use `BTreeMap` so output is sorted by keys.
            let mut configs = BTreeMap::new();
            for (key, desc) in linter.all_descriptions() {
                configs.insert(
                    key.to_owned(),
                    Config {
                        default_value: default_config[key],
                        description: desc.to_owned(),
                    },
                );
            }

            println!("{}", serde_json::to_string_pretty(&configs).unwrap());

            Ok(())
        }
        Args::MineWords { input } => {
            let input = input.unwrap_or_read_from_stdin();
            let (doc, _source) = input.load(MarkdownOptions::default(), &curated_dictionary)?;

            let mut words = HashMap::new();

            for word in doc.iter_words() {
                let chars = doc.get_span_content(&word.span);

                words
                    .entry(chars.to_lower())
                    .and_modify(|v| *v += 1)
                    .or_insert(1);
            }

            let mut words_ordered: Vec<(String, usize)> = words
                .into_iter()
                .map(|(key, value)| (key.to_string(), value))
                .collect();

            words_ordered.sort_by_key(|v| v.1);

            for (word, _) in words_ordered {
                println!("{word}");
            }

            Ok(())
        }
        Args::CoreVersion => {
            println!("harper-core v{}", harper_core::core_version());
            Ok(())
        }
        #[cfg(feature = "training")]
        Args::TrainBrillTagger {
            datasets: dataset,
            epochs,
            output,
            candidate_selection_chance,
        } => {
            let tagger = BrillTagger::train(&dataset, epochs, candidate_selection_chance);
            fs::write(output, serde_json::to_string_pretty(&tagger)?)?;

            Ok(())
        }
        #[cfg(feature = "training")]
        Args::TrainBrillChunker {
            datasets,
            epochs,
            output,
            candidate_selection_chance,
        } => {
            let chunker = BrillChunker::train(&datasets, epochs, candidate_selection_chance);
            fs::write(output, serde_json::to_string_pretty(&chunker)?)?;
            Ok(())
        }
        #[cfg(feature = "training")]
        Args::TrainBurnChunker {
            datasets,
            test_file,
            epochs,
            dropout,
            output,
            lr,
            dim: embed_dim,
        } => {
            let chunker =
                BurnChunkerCpu::train_cpu(&datasets, &test_file, embed_dim, dropout, epochs, lr);
            chunker.save_to(output);

            Ok(())
        }
        Args::RenameFlag { old, new, dir } => {
            let dict_path = dir.join("dictionary.dict");
            let affixes_path = dir.join("annotations.json");

            // Validate old and new flags are exactly one Unicode code point (Rust char)
            // And not characters used for the dictionary format
            const BAD_CHARS: [char; 3] = ['/', '#', ' '];

            // Then use it like this:
            if old.chars().count() != 1 || BAD_CHARS.iter().any(|&c| old.contains(c)) {
                return Err(anyhow!(
                    "Flags must be one Unicode code point, not / or # or space. Old flag '{old}' is {}",
                    old.chars().count()
                ));
            }
            if new.chars().count() != 1 || BAD_CHARS.iter().any(|&c| new.contains(c)) {
                return Err(anyhow!(
                    "Flags must be one Unicode code point, not / or # or space. New flag '{new}' is {}",
                    new.chars().count()
                ));
            }

            // Load and parse affixes
            let affixes_string = fs::read_to_string(&affixes_path)
                .map_err(|e| anyhow!("Failed to read annotations.json: {e}"))?;

            let affixes_json: Value = serde_json::from_str(&affixes_string)
                .map_err(|e| anyhow!("Failed to parse annotations.json: {e}"))?;

            // Get the nested "affixes" object
            let affixes_obj = &affixes_json
                .get("affixes")
                .and_then(Value::as_object)
                .ok_or_else(|| anyhow!("annotations.json does not contain 'affixes' object"))?;

            let properties_obj = &affixes_json
                .get("properties")
                .and_then(Value::as_object)
                .ok_or_else(|| anyhow!("annotations.json does not contain 'properties' object"))?;

            // Validate old flag exists and get its description
            let old_entry = affixes_obj
                .get(&old)
                .or_else(|| properties_obj.get(&old))
                .ok_or_else(|| anyhow!("Flag '{old}' not found in annotations.json"))?;

            let description = old_entry
                .get("#")
                .and_then(Value::as_str)
                .unwrap_or("(no description)");

            println!("Renaming flag '{old}' ({description})");

            // Validate new flag doesn't exist
            if let Some(new_entry) = affixes_obj.get(&new).or_else(|| properties_obj.get(&new)) {
                let new_desc = new_entry
                    .get("#")
                    .and_then(Value::as_str)
                    .unwrap_or("(no description)");
                return Err(anyhow!(
                    "Cannot rename to '{new}': flag already exists and is used for: {new_desc}"
                ));
            }

            // Create backups
            let backup_dict = format!("{}.bak", dict_path.display());
            let backup_affixes = format!("{}.bak", affixes_path.display());
            fs::copy(&dict_path, &backup_dict)
                .map_err(|e| anyhow!("Failed to create dictionary backup: {e}"))?;
            fs::copy(&affixes_path, &backup_affixes)
                .map_err(|e| anyhow!("Failed to create affixes backup: {e}"))?;

            // Update dictionary with proper comment and whitespace handling
            let dict_content = fs::read_to_string(&dict_path)
                .map_err(|e| anyhow!("Failed to read dictionary: {e}"))?;

            let updated_dict = dict_content
                .lines()
                .map(|line| {
                    if line.is_empty() || line.starts_with('#') {
                        return line.to_string();
                    }

                    let hash_pos = line.find('#').unwrap_or(line.len());
                    let (entry_part, comment_part) = line.split_at(hash_pos);

                    let slash_pos = entry_part.find('/').unwrap_or(entry_part.len());
                    let (lexeme, annotation) = entry_part.split_at(slash_pos);

                    format!(
                        "{}{}{}",
                        lexeme,
                        annotation.replace(&old, &new),
                        comment_part
                    )
                })
                .collect::<Vec<_>>()
                .join("\n");

            // Update affixes (text-based replacement with context awareness)
            let updated_affixes_string =
                affixes_string.replace(&format!("\"{}\":", &old), &format!("\"{}\":", &new));

            // Verify that the updated affixes string is valid JSON
            serde_json::from_str::<Value>(&updated_affixes_string)
                .map_err(|e| anyhow!("Failed to parse updated annotations.json: {e}"))?;

            // Write changes
            fs::write(&dict_path, updated_dict)
                .map_err(|e| anyhow!("Failed to write updated dictionary: {e}"))?;
            fs::write(&affixes_path, updated_affixes_string)
                .map_err(|e| anyhow!("Failed to write updated affixes: {e}"))?;

            println!("Successfully renamed flag '{old}' to '{new}'");
            println!("  Description: {description}");
            println!("  Backups created at:\n    {backup_dict}\n    {backup_affixes}");

            Ok(())
        }
        Args::AuditDictionary { dir } => {
            let annotations_path = dir.join("annotations.json");
            let annotations_content = fs::read_to_string(&annotations_path)
                .map_err(|e| anyhow!("Failed to read annotations: {e}"))?;
            let annotations_json: Value = serde_json::from_str(&annotations_content)
                .map_err(|e| anyhow!("Failed to parse annotations.json: {e}"))?;

            let annotations = annotations_json
                .as_object()
                .ok_or_else(|| anyhow!("annotations.json is not an object"))?;

            let (affixes, properties) = ["affixes", "properties"]
                .iter()
                .map(|key| {
                    annotations
                        .get(*key)
                        .and_then(Value::as_object)
                        .ok_or_else(|| {
                            anyhow!("Missing or invalid '{key}' key in annotations.json")
                        })
                })
                .collect::<Result<Vec<_>, _>>()
                .map(|v| (v[0], v[1]))?;

            let all_keys = affixes.keys().chain(properties.keys()).collect::<Vec<_>>();

            let mut annotation_flag_count: HashMap<char, u32> = all_keys
                .iter()
                .filter_map(|key| key.chars().next()) // Get first char of each key
                .map(|c| (c, 0))
                .collect();

            // let mut duplicate_flag_total = 0;
            let mut duplicate_flags = std::collections::HashMap::new();
            let mut unknown_flags = std::collections::HashMap::new();
            let mut unused_flag_total = 0;

            let dict_path = dir.join("dictionary.dict");
            let dict_content = fs::read_to_string(&dict_path)
                .map_err(|e| anyhow!("Failed to read dictionary: {e}"))?;

            for (line_num, line) in dict_content.lines().enumerate() {
                if line.is_empty()
                    || line.starts_with('#')
                    || line.chars().all(|c| c.is_ascii_digit())
                {
                    continue;
                }

                let (entry_part, _comment_part) =
                    line.split_once('#').map_or((line, ""), |(e, c)| (e, c));

                if let Some((lexeme, rest)) = entry_part.split_once('/') {
                    let (annotation, _whitespace) = match rest.split_once([' ', '\t']) {
                        Some((a, _)) => (a, &rest[a.len()..]),
                        None => (rest, ""),
                    };

                    let mut seen_flags = hashbrown::HashSet::new();

                    for flag in annotation.chars() {
                        if !seen_flags.insert(flag) {
                            eprintln!(
                                "Warning: Line {}: Duplicate annotation flag '{}' in entry: {}/{}",
                                line_num + 1,
                                flag,
                                lexeme,
                                annotation
                            );
                            // duplicate_flag_total += 1;
                            *duplicate_flags.entry(flag).or_insert(0) += 1;
                        }
                        if !annotation_flag_count.contains_key(&flag) {
                            eprintln!(
                                "Warning: Line {}: Unknown annotation flag '{}' in entry: {}/{}",
                                line_num + 1,
                                flag,
                                lexeme,
                                annotation
                            );
                            *unknown_flags.entry(flag).or_insert(0) += 1;
                        } else {
                            *annotation_flag_count.get_mut(&flag).unwrap() += 1;
                        }
                    }
                }
            }

            for (flag, count) in annotation_flag_count {
                if count == 0 {
                    eprintln!("Warning: Unused annotation flag '{}'", flag);
                    unused_flag_total += 1;
                }
            }

            let duplicate_flag_total = duplicate_flags.values().sum::<usize>();
            let unknown_flag_total = unknown_flags.values().sum::<usize>();

            if duplicate_flag_total > 0 || unknown_flag_total > 0 || unused_flag_total > 0 {
                eprintln!("\nAudit found issues:");
                if duplicate_flag_total > 0 {
                    eprintln!(
                        "  - {} duplicate flags found in {} entries",
                        duplicate_flags.len(),
                        duplicate_flag_total
                    );
                }
                if !unknown_flags.is_empty() {
                    let total_unknown = unknown_flags.values().sum::<usize>();
                    eprintln!(
                        "  - {} unknown flags found in {} entries",
                        unknown_flags.len(),
                        total_unknown
                    );
                }
                if unused_flag_total > 0 {
                    eprintln!("  - {} unused flags found", unused_flag_total);
                }
                std::process::exit(1);
            }

            Ok(())
        }
        Args::Compounds => {
            let mut compound_map: HashMap<String, Vec<String>> = HashMap::new();

            // First pass: process open and hyphenated compounds
            for word in curated_dictionary.words_iter() {
                if !word.contains(&' ') && !word.contains(&'-') {
                    continue;
                }

                let normalized_key: String = word
                    .iter()
                    .filter(|&&c| c != ' ' && c != '-')
                    .collect::<String>()
                    .to_lowercase();

                let word_str = word.iter().collect::<String>();
                compound_map
                    .entry(normalized_key)
                    .or_default()
                    .push(word_str);
            }

            // Second pass: process closed compounds
            for word in curated_dictionary.words_iter() {
                if word.contains(&' ') || word.contains(&'-') {
                    continue;
                }

                let normalized_key: String = word.iter().collect::<String>().to_lowercase();
                if let Some(variants) = compound_map.get_mut(&normalized_key) {
                    variants.push(word.iter().collect());
                }
            }

            // Process and print results
            let mut results: Vec<_> = compound_map
                .into_iter()
                .filter(|(_, v)| v.len() > 1)
                .collect();
            results.sort_by_key(|(k, _)| k.clone());

            // Instead of moving `results` into the for loop, iterate over a reference to it
            for (normalized, originals) in &results {
                println!("\nVariants for '{normalized}':");
                for original in originals {
                    println!("  - {original}");
                }
            }

            println!("\nFound {} compound word groups", results.len());
            Ok(())
        }
        Args::CaseVariants => {
            let case_bitmask = OrthFlags::LOWERCASE
                | OrthFlags::TITLECASE
                | OrthFlags::ALLCAPS
                | OrthFlags::LOWER_CAMEL
                | OrthFlags::UPPER_CAMEL;
            let mut processed_words = HashMap::new();
            let mut longest_word = 0;
            for word in curated_dictionary.words_iter() {
                if let Some(metadata) = curated_dictionary.get_word_metadata(word) {
                    let orth = metadata.orth_info;
                    let bits = orth.bits() & case_bitmask.bits();

                    if bits.count_ones() > 1 {
                        longest_word = longest_word.max(word.len());
                        // Mask out all bits except the case-related ones before printing
                        processed_words.insert(
                            word.to_string(),
                            OrthFlags::from_bits_truncate(orth.bits() & case_bitmask.bits()),
                        );
                    }
                }
            }
            let mut processed_words: Vec<_> = processed_words.into_iter().collect();
            processed_words.sort_by_key(|(word, _)| word.clone());
            let longest_num = (processed_words.len() - 1).to_string().len();
            for (i, (word, orth)) in processed_words.iter().enumerate() {
                println!("{i:>longest_num$} {word:<longest_word$} : {orth:?}");
            }
            Ok(())
        }
        Args::NominalPhrases { input } => {
            // Get input from either file or direct text
            let (doc, _) = input
                .unwrap_or_read_from_stdin()
                .load(MarkdownOptions::default(), &curated_dictionary)?;

            let phrases: Vec<_> = doc
                .iter_nominal_phrases()
                .map(|toks| {
                    (
                        toks.first().unwrap().span.start,
                        toks.last().unwrap().span.end,
                    )
                })
                .collect();

            let mut last_end = 0;

            for (start, end) in phrases {
                // Plain text between nominal phrases
                if start > last_end {
                    let span = Span::new(last_end, start);
                    let txt = doc.get_span_content_str(&span);
                    if !txt.trim().is_empty() {
                        print!("{}", txt);
                    }
                }

                // Highlighted nominal phrase
                let span = Span::new(start, end);
                let txt = doc.get_span_content_str(&span);

                print!("\x1b[33m{}\x1b[0m", txt);

                last_end = end;
            }

            // Plain text after the last nominal phrase, if any
            let doc_len = doc.get_full_content().len();
            if last_end < doc_len {
                let span = Span::new(last_end, doc_len);
                let txt = doc.get_span_content_str(&span);
                if !txt.trim().is_empty() {
                    print!("{}", txt);
                }
            }

            println!();

            Ok(())
        }
        Args::Test { input } => {
            let weir_file = fs::read_to_string(input)?;
            let mut linter = WeirLinter::new(&weir_file)?;

            let failing_tests = linter.run_tests();

            if failing_tests.is_empty() {
                eprintln!("All tests pass!");
                Ok(())
            } else {
                eprintln!("{:?}", failing_tests);
                process::exit(1);
            }
        }
    }
}

/// Split a dictionary line into its word and annotation segments
fn line_to_parts(line: &str) -> (String, String) {
    if let Some((word, annot)) = line.split_once('/') {
        (word.to_owned(), annot.to_string())
    } else {
        (line.to_owned(), String::new())
    }
}

fn print_word_derivations(word: &str, annot: &str, dictionary: &impl Dictionary) {
    println!("{word}/{annot}");

    let id = WordId::from_word_str(word);

    let children = dictionary
        .words_iter()
        .filter(|e| dictionary.get_word_metadata(e).unwrap().derived_from == Some(id));

    println!(" - {word}");

    for child in children {
        let child_str: String = child.iter().collect();
        println!(" - {child_str}");
    }
}



================================================
FILE: harper-cli/src/input/multi_input.rs
================================================
use std::{borrow::Cow, path::PathBuf};

use enum_dispatch::enum_dispatch;
use strum_macros::EnumTryAs;

use crate::input::single_input::{FileInput, SingleInput};

use super::InputTrait;

#[enum_dispatch]
pub(crate) trait MultiInputTrait: InputTrait {
    /// Get an iterator of [`SingleInput`] from this `MultiInput`.
    ///
    /// For instance, if this is a directory input, the returned inputs might correspond to the
    /// files inside that directory.
    #[allow(dead_code)]
    fn iter_inputs(&self) -> anyhow::Result<impl Iterator<Item = SingleInput>>;
}

#[derive(Clone, EnumTryAs)]
#[enum_dispatch(MultiInputTrait, InputTrait)]
pub(crate) enum MultiInput {
    /// A directory.
    Dir(DirInput),
}
impl MultiInput {
    /// Try to parse a `MultiInput` from the provided string. This might fail if the provided
    /// string cannot be parsed as a supported `MultiInput`.
    pub(crate) fn try_parse_string(input_string: &str) -> anyhow::Result<Self> {
        let metadata = std::fs::metadata(input_string);
        if metadata?.is_dir() {
            // Input is a valid directory path.
            Ok(Self::Dir(DirInput {
                path: input_string.into(),
            }))
        } else {
            anyhow::bail!(
                "Unsupported input '{}' for {}",
                input_string,
                std::any::type_name::<Self>()
            )
        }
    }
}

/// A directory.
#[derive(Clone)]
pub(crate) struct DirInput {
    /// The path pointing to the directory.
    path: PathBuf,
}
impl DirInput {
    /// An iterator of the files inside the directory, as [`FileInput`].
    pub(crate) fn iter_files(&self) -> anyhow::Result<impl Iterator<Item = FileInput>> {
        Ok(std::fs::read_dir(&self.path)?.filter_map(|dir_entry| {
            if let Ok(dir_entry) = dir_entry
                && let Ok(file) = FileInput::try_from_path(&dir_entry.path())
            {
                Some(file)
            } else {
                None
            }
        }))
    }
}
impl MultiInputTrait for DirInput {
    fn iter_inputs(&self) -> anyhow::Result<impl Iterator<Item = SingleInput>> {
        Ok(self.iter_files()?.map(|file| file.into()))
    }
}
impl InputTrait for DirInput {
    fn get_identifier(&self) -> Cow<'_, str> {
        self.path
            .file_name()
            .map_or(Cow::from("<dir>"), |dir_name| dir_name.to_string_lossy())
    }
}



================================================
FILE: harper-cli/src/input/single_input.rs
================================================
use std::path::Path;
use std::{borrow::Cow, io::Read, path::PathBuf};

use enum_dispatch::enum_dispatch;
use strum_macros::EnumTryAs;

use harper_asciidoc::AsciidocParser;
use harper_comments::CommentParser;
use harper_core::parsers::{Markdown, OrgMode, Parser};
use harper_core::spell::Dictionary;
use harper_core::{
    Document,
    parsers::{MarkdownOptions, PlainEnglish},
};
use harper_ink::InkParser;
use harper_literate_haskell::LiterateHaskellParser;
use harper_python::PythonParser;

use super::InputTrait;

/// An input of a single source. This would not include a directory for instance, which may have
/// multiple (file) sources.
#[enum_dispatch]
pub(crate) trait SingleInputTrait: InputTrait {
    /// Loads the contained file/string into a conventional format. Returns a `Result` containing
    /// a tuple of a `Document` and its corresponding source text as a string.
    fn load(
        &self,
        markdown_options: MarkdownOptions,
        dictionary: &dyn Dictionary,
    ) -> anyhow::Result<(Document, Cow<'_, str>)> {
        self.load_with_parser(&self.get_parser(markdown_options), dictionary)
    }

    /// Loads the contained file/string into a conventional format using the provided
    /// parser. Returns a `Result` containing a tuple of a `Document` and its corresponding source
    /// text as a string.
    fn load_with_parser(
        &self,
        parser: &dyn Parser,
        dictionary: &dyn Dictionary,
    ) -> anyhow::Result<(Document, Cow<'_, str>)> {
        let text = self.get_content()?;
        Ok((Document::new(&text, &parser, &dictionary), text))
    }

    /// The parser that should be used to parse this input.
    fn get_parser(&self, _markdown_options: MarkdownOptions) -> Box<dyn Parser> {
        Box::new(PlainEnglish)
    }

    /// Get/load the raw content of this input.
    fn get_content(&self) -> anyhow::Result<Cow<'_, str>>;
}

#[derive(Clone, EnumTryAs)]
#[enum_dispatch(SingleInputTrait, InputTrait)]
pub(crate) enum SingleInput {
    /// Read from a file.
    File(FileInput),
    /// Direct text input via the command line.
    Text(TextInput),
    /// Read from standard input.
    Stdin(StdinInput),
}
impl SingleInput {
    /// Parse a string into a [`SingleInput`], trying to automatically detect the input
    /// type based on its contents.
    ///
    /// For instance, an `input_string` that corresponds to a valid filepath will be parsed as
    /// a [`SingleInput::File`].
    pub(crate) fn parse_string(input_string: &str) -> Self {
        if let Ok(file) = FileInput::try_from_path(Path::new(input_string)) {
            // Input is a valid filepath.
            Self::File(file)
        } else {
            // Input is not a valid filepath, we assume it's intended to be a string.
            Self::Text(TextInput {
                text: input_string.to_owned(),
            })
        }
    }
}

pub trait SingleInputOptionExt {
    /// Returns the contained [`Some`] value if some, otherwise returns [`SingleInput::Stdin`].
    fn unwrap_or_read_from_stdin(self) -> SingleInput;
}
impl SingleInputOptionExt for Option<SingleInput> {
    fn unwrap_or_read_from_stdin(self) -> SingleInput {
        self.unwrap_or_else(|| StdinInput.into())
    }
}

/// File (path) input.
#[derive(Clone)]
pub(crate) struct FileInput {
    path: PathBuf,
}
impl FileInput {
    /// The path of the file.
    pub(crate) fn path(&self) -> &PathBuf {
        &self.path
    }

    /// Try to create a `FileInput` from the given path. If the path does not point to a valid
    /// file, this will fail.
    pub(crate) fn try_from_path(path: &Path) -> anyhow::Result<Self> {
        let metadata = std::fs::metadata(path);
        if metadata?.is_file() {
            Ok(Self::from_path_unchecked(path))
        } else {
            anyhow::bail!(
                "Failed to parse '{}' as {}",
                path.to_string_lossy(),
                std::any::type_name::<Self>()
            )
        }
    }

    /// Create a file input from the given path, without checking if that path points to a valid
    /// file.
    pub(crate) fn from_path_unchecked(path: &Path) -> Self {
        Self {
            path: path.to_owned(),
        }
    }
}
impl SingleInputTrait for FileInput {
    /// Read content from the file.
    fn get_content(&self) -> anyhow::Result<Cow<'_, str>> {
        Ok(std::fs::read_to_string(&self.path)?.into())
    }

    /// Detect the parser that should be used for the given file.
    fn get_parser(&self, _markdown_options: MarkdownOptions) -> Box<dyn Parser> {
        match self.path.extension().map(|ext| ext.to_str().unwrap()) {
            Some("md" | "markdown" | "mkd" | "mdwn" | "mdown" | "mdtxt" | "mdtext") => {
                Box::new(Markdown::default())
            }
            Some("ink") => Box::new(InkParser::default()),
            Some("lhs") => Box::new(LiterateHaskellParser::new_markdown(
                MarkdownOptions::default(),
            )),
            Some("org") => Box::new(OrgMode),
            Some("typ") => Box::new(harper_typst::Typst),
            Some("py") | Some("pyi") => Box::new(PythonParser::default()),
            Some("adoc") | Some("asciidoc") => Box::new(AsciidocParser::default()),
            Some("txt") => Box::new(PlainEnglish),
            _ => {
                if let Some(comment_parser) =
                    CommentParser::new_from_filename(&self.path, _markdown_options)
                {
                    Box::new(comment_parser)
                } else {
                    eprintln!(
                        "{}: Warning: Could not detect language ID; falling back to PlainEnglish parser.",
                        self.get_identifier()
                    );
                    Box::new(PlainEnglish)
                }
            }
        }
    }
}
impl InputTrait for FileInput {
    fn get_identifier(&self) -> Cow<'_, str> {
        self.path
            .file_name()
            .map_or(Cow::from("<file>"), |file_name| file_name.to_string_lossy())
    }
}

/// Direct text input via the command line.
#[derive(Clone)]
pub(crate) struct TextInput {
    text: String,
}
impl SingleInputTrait for TextInput {
    fn get_content(&self) -> anyhow::Result<Cow<'_, str>> {
        Ok(Cow::from(&self.text))
    }
}
impl InputTrait for TextInput {
    fn get_identifier(&self) -> Cow<'_, str> {
        Cow::from("<text>")
    }
}

/// Standard input (stdin).
#[derive(Clone)]
pub(crate) struct StdinInput;
impl SingleInputTrait for StdinInput {
    fn get_content(&self) -> anyhow::Result<Cow<'_, str>> {
        let mut buf = String::new();
        std::io::stdin().lock().read_to_string(&mut buf)?;
        Ok(Cow::from(buf))
    }
}
impl InputTrait for StdinInput {
    fn get_identifier(&self) -> Cow<'_, str> {
        Cow::from("<stdin>")
    }
}



================================================
FILE: harper-comments/README.md
================================================
# `harper-comments`

This crate holds a number of functions, but it is primarily a wrapper around `tree-sitter` that allows Harper to locate the comments of a wide variety of programming languages.
It also has purpose-built parsers for the structured comments of a number of languages, including Go.
These additional parsers are available through the `CommentParser` and are enabled automatically through there.



================================================
FILE: harper-comments/Cargo.toml
================================================
[package]
name = "harper-comments"
version = "1.5.1"
edition = "2024"
description = "The language checker for developers."
license = "Apache-2.0"
readme = "README.md"
repository = "https://github.com/automattic/harper"

[dependencies]
harper-core = { path = "../harper-core", version = "1.0.0" }
harper-html = { path = "../harper-html", version = "1.0.0" }
harper-tree-sitter = { path = "../harper-tree-sitter", version = "1.0.0" }
itertools = "0.14.0"
tree-sitter = "0.25.10"
tree-sitter-bash = "0.25.1"
tree-sitter-c = "0.24.1"
tree-sitter-cmake = "0.7.1"
tree-sitter-cpp = "0.23.4"
tree-sitter-c-sharp = "0.23.1"
tree-sitter-go = "0.25.0"
tree-sitter-haskell = "0.23.1"
tree-sitter-java = "0.23.5"
tree-sitter-javascript = "0.25.0"
tree-sitter-kotlin-ng = "1.1.0"
tree-sitter-lua = "0.4.1"
tree-sitter-nix = "0.3.0"
tree-sitter-php = "0.24.2"
tree-sitter-ruby = "0.23.1"
tree-sitter-rust = "0.24.0"
tree-sitter-scala = "0.24.0"
tree-sitter-solidity = "1.2.13"
tree-sitter-swift = "0.7.1"
tree-sitter-toml-ng = "0.7.0"
tree-sitter-typescript = "0.23.2"
harper-tree-sitter-dart = "0.0.5"
tree-sitter-clojure = "0.1.0"

[dev-dependencies]
paste = "1.0.15"



================================================
FILE: harper-comments/src/comment_parser.rs
================================================
use std::path::Path;

use crate::comment_parsers;
use comment_parsers::{Go, JavaDoc, JsDoc, Lua, Solidity, Unit};
use harper_core::Token;
use harper_core::parsers::{self, MarkdownOptions, Parser};
use harper_core::spell::MutableDictionary;
use tree_sitter::Node;

use crate::masker::CommentMasker;

pub struct CommentParser {
    inner: parsers::Mask<CommentMasker, Box<dyn Parser>>,
}

impl CommentParser {
    pub fn create_ident_dict(&self, source: &[char]) -> Option<MutableDictionary> {
        self.inner.masker.create_ident_dict(source)
    }

    pub fn new_from_language_id(
        language_id: &str,
        markdown_options: MarkdownOptions,
    ) -> Option<Self> {
        let language = match language_id {
            "c" => tree_sitter_c::LANGUAGE,
            "clojure" => tree_sitter_clojure::LANGUAGE,
            "cmake" => tree_sitter_cmake::LANGUAGE,
            "cpp" => tree_sitter_cpp::LANGUAGE,
            "csharp" => tree_sitter_c_sharp::LANGUAGE,
            "dart" => harper_tree_sitter_dart::LANGUAGE,
            "go" => tree_sitter_go::LANGUAGE,
            "haskell" => tree_sitter_haskell::LANGUAGE,
            "daml" => tree_sitter_haskell::LANGUAGE,
            "java" => tree_sitter_java::LANGUAGE,
            "javascript" => tree_sitter_javascript::LANGUAGE,
            "javascriptreact" => tree_sitter_typescript::LANGUAGE_TSX,
            "kotlin" => tree_sitter_kotlin_ng::LANGUAGE,
            "lua" => tree_sitter_lua::LANGUAGE,
            "nix" => tree_sitter_nix::LANGUAGE,
            "php" => tree_sitter_php::LANGUAGE_PHP,
            "ruby" => tree_sitter_ruby::LANGUAGE,
            "rust" => tree_sitter_rust::LANGUAGE,
            "scala" => tree_sitter_scala::LANGUAGE,
            "shellscript" => tree_sitter_bash::LANGUAGE,
            "solidity" => tree_sitter_solidity::LANGUAGE,
            "swift" => tree_sitter_swift::LANGUAGE,
            "toml" => tree_sitter_toml_ng::LANGUAGE,
            "typescript" => tree_sitter_typescript::LANGUAGE_TYPESCRIPT,
            "typescriptreact" => tree_sitter_typescript::LANGUAGE_TSX,
            _ => return None,
        };

        let comment_parser: Box<dyn Parser> = match language_id {
            "go" => Box::new(Go::new_markdown(markdown_options)),
            "java" => Box::new(JavaDoc::default()),
            "javascript" | "javascriptreact" | "typescript" | "typescriptreact" => {
                Box::new(JsDoc::new_markdown(markdown_options))
            }
            "lua" => Box::new(Lua::new_markdown(markdown_options)),
            "solidity" => Box::new(Solidity::new_markdown(markdown_options)),
            _ => Box::new(Unit::new_markdown(markdown_options)),
        };

        Some(Self {
            inner: parsers::Mask::new(
                CommentMasker::new(language.into(), Self::node_condition),
                comment_parser,
            ),
        })
    }

    /// Infer the programming language from a provided filename.
    pub fn new_from_filename(filename: &Path, markdown_options: MarkdownOptions) -> Option<Self> {
        Self::new_from_language_id(Self::filename_to_filetype(filename)?, markdown_options)
    }

    /// Convert a provided path to a corresponding Language Server Protocol file
    /// type.
    ///
    /// Note to contributors: try to keep this in sync with
    /// [`Self::new_from_language_id`]
    fn filename_to_filetype(path: &Path) -> Option<&'static str> {
        Some(match path.extension()?.to_str()? {
            "c" => "c",
            "bb" | "cljc" | "cljd" | "clj" | "cljs" => "clojure",
            "cmake" => "cmake",
            "cpp" | "h" => "cpp",
            "cs" => "csharp",
            "dart" => "dart",
            "go" => "go",
            "hs" => "haskell",
            "daml" => "daml",
            "java" => "java",
            "js" => "javascript",
            "jsx" => "javascriptreact",
            "kt" | "kts" => "kotlin",
            "lua" => "lua",
            "nix" => "nix",
            "php" => "php",
            "rb" => "ruby",
            "rs" => "rust",
            "sbt" | "sc" | "scala" | "mill" => "scala",
            "bash" | "sh" => "shellscript",
            "sol" => "solidity",
            "swift" => "swift",
            "toml" => "toml",
            "ts" => "typescript",
            "tsx" => "typescriptreact",
            _ => return None,
        })
    }

    fn node_condition(n: &Node) -> bool {
        n.kind().contains("comment")
    }
}

impl Parser for CommentParser {
    fn parse(&self, source: &[char]) -> Vec<Token> {
        self.inner.parse(source)
    }
}

#[cfg(test)]
mod tests {
    use super::CommentParser;
    use harper_core::parsers::{MarkdownOptions, StrParser};

    #[test]
    fn hang() {
        use std::sync::mpsc::channel;
        use std::thread;
        use std::time::Duration;

        let (tx, rx) = channel::<()>();

        let handle = thread::spawn(move || {
            let opts = MarkdownOptions::default();
            let parser = CommentParser::new_from_language_id("java", opts).unwrap();
            let _res = parser.parse_str("//{@j");
            tx.send(()).expect("send failed");
        });

        rx.recv_timeout(Duration::from_secs(10)).expect("timed out");
        handle.join().expect("failed to join");
    }
}



================================================
FILE: harper-comments/src/lib.rs
================================================
#![doc = include_str!("../README.md")]

mod comment_parser;
mod comment_parsers;
mod masker;
pub use comment_parser::CommentParser;



================================================
FILE: harper-comments/src/masker.rs
================================================
use harper_core::Masker;
use harper_core::spell::MutableDictionary;
use harper_tree_sitter::TreeSitterMasker;

pub struct CommentMasker {
    inner: TreeSitterMasker,
    ignore_condition: Box<dyn Fn(&String) -> bool + Send + Sync>,
}

impl CommentMasker {
    pub fn create_ident_dict(&self, source: &[char]) -> Option<MutableDictionary> {
        self.inner.create_ident_dict(source)
    }

    pub fn new(
        language: tree_sitter::Language,
        ts_node_condition: fn(&tree_sitter::Node) -> bool,
    ) -> Self {
        Self::new_with_ignore_condition(
            language,
            ts_node_condition,
            Box::new(|text| {
                text.contains("spellchecker:ignore")
                    || text.contains("spellchecker: ignore")
                    || text.contains("spell-checker:ignore")
                    || text.contains("spell-checker: ignore")
                    || text.contains("spellcheck:ignore")
                    || text.contains("spellcheck: ignore")
                    || text.contains("harper:ignore")
                    || text.contains("harper: ignore")
                    || text.starts_with("#!")
            }),
        )
    }

    pub fn new_with_ignore_condition(
        language: tree_sitter::Language,
        ts_node_condition: fn(&tree_sitter::Node) -> bool,
        ignore_condition: Box<dyn Fn(&String) -> bool + Send + Sync>,
    ) -> Self {
        Self {
            inner: TreeSitterMasker::new(language, ts_node_condition),
            ignore_condition,
        }
    }
}

impl Masker for CommentMasker {
    fn create_mask(&self, source: &[char]) -> harper_core::Mask {
        self.inner
            .create_mask(source)
            .iter_allowed(source)
            .map(|(span, chars)| (span, chars.iter().collect::<String>()))
            .filter(|(_, text)| !(self.ignore_condition)(text))
            .map(|(span, _)| span)
            .collect()
    }
}



================================================
FILE: harper-comments/src/comment_parsers/go.rs
================================================
use harper_core::Lrc;
use harper_core::Token;
use harper_core::parsers::{Markdown, MarkdownOptions, Parser};

use super::without_initiators;

#[derive(Clone)]
pub struct Go {
    inner: Lrc<dyn Parser>,
}

impl Go {
    pub fn new(parser: Lrc<dyn Parser>) -> Self {
        Self { inner: parser }
    }

    pub fn new_markdown(markdown_options: MarkdownOptions) -> Self {
        Self::new(Lrc::new(Markdown::new(markdown_options)))
    }
}

impl Parser for Go {
    fn parse(&self, source: &[char]) -> Vec<Token> {
        let mut actual = without_initiators(source);
        let mut actual_source = actual.get_content(source);

        if matches!(actual_source, ['g', 'o', ':', ..]) {
            let Some(terminator) = source.iter().position(|c| *c == '\n') else {
                return Vec::new();
            };

            actual.start += terminator;

            let Some(new_source) = actual.try_get_content(actual_source) else {
                return Vec::new();
            };

            actual_source = new_source
        }

        let mut new_tokens = self.inner.parse(actual_source);

        new_tokens
            .iter_mut()
            .for_each(|t| t.span.push_by(actual.start));

        new_tokens
    }
}



================================================
FILE: harper-comments/src/comment_parsers/javadoc.rs
================================================
use std::collections::VecDeque;

use harper_core::parsers::Parser;
use harper_core::{Punctuation, Token, TokenKind, VecExt};
use harper_html::HtmlParser;

use super::without_initiators;

#[derive(Default)]
pub struct JavaDoc {
    html_parser: HtmlParser,
}

impl Parser for JavaDoc {
    fn parse(&self, source: &[char]) -> Vec<Token> {
        let actual = without_initiators(source);
        let actual_source = actual.get_content(source);

        let mut tokens = self.html_parser.parse(actual_source);

        // We need to remove leading spaces and stars from the block of tokens.
        let mut remove_these: VecDeque<usize> = VecDeque::new();

        let mut cursor = 0;

        while cursor < tokens.len() {
            let maybe_newline = &tokens[cursor];

            if let TokenKind::Newline(_) = maybe_newline.kind {
                cursor += 1;

                loop {
                    if cursor >= tokens.len() {
                        break;
                    }

                    let maybe_removable = &tokens[cursor];

                    if matches!(
                        maybe_removable.kind,
                        TokenKind::Punctuation(Punctuation::Star) | TokenKind::Space(_)
                    ) {
                        remove_these.push_back(cursor);
                        cursor += 1;
                    } else {
                        break;
                    }
                }
            } else {
                cursor += 1;
            }
        }

        tokens.remove_indices(remove_these);

        for token in tokens.iter_mut() {
            token.span.push_by(actual.start);
        }

        super::jsdoc::mark_inline_tags(&mut tokens);

        // Mark @tags as unlintable
        for i in 3..tokens.len() {
            let a = &tokens[i - 3];
            let b = &tokens[i - 2];
            let c = &tokens[i - 1];
            let d = &tokens[i];

            if a.kind.is_at() && b.kind.is_word() && c.kind.is_space() && d.kind.is_word() {
                tokens[i - 3].kind = TokenKind::Unlintable;
                tokens[i - 2].kind = TokenKind::Unlintable;
                tokens[i - 1].kind = TokenKind::Unlintable;
                tokens[i].kind = TokenKind::Unlintable;
            }
        }

        tokens
    }
}



================================================
FILE: harper-comments/src/comment_parsers/jsdoc.rs
================================================
use harper_core::Lrc;
use harper_core::parsers::{Markdown, MarkdownOptions, Parser};
use harper_core::{Punctuation, Span, Token, TokenKind};
use itertools::Itertools;

use super::without_initiators;

#[derive(Clone)]
pub struct JsDoc {
    inner: Lrc<dyn Parser>,
}

impl JsDoc {
    pub fn new(parser: Lrc<dyn Parser>) -> Self {
        Self { inner: parser }
    }

    pub fn new_markdown(markdown_options: MarkdownOptions) -> Self {
        Self::new(Lrc::new(Markdown::new(markdown_options)))
    }
}

impl Parser for JsDoc {
    fn parse(&self, source: &[char]) -> Vec<Token> {
        let mut tokens = Vec::new();

        let mut chars_traversed = 0;

        for line in source.split(|c| *c == '\n') {
            let mut new_tokens = parse_line(line, self.inner.clone());

            if chars_traversed + line.len() < source.len() {
                new_tokens.push(Token::new(
                    Span::new_with_len(line.len(), 1),
                    harper_core::TokenKind::Newline(1),
                ));
            }

            new_tokens
                .iter_mut()
                .for_each(|t| t.span.push_by(chars_traversed));

            chars_traversed += line.len() + 1;
            tokens.append(&mut new_tokens);
        }

        tokens
    }
}

fn parse_line(source: &[char], parser: Lrc<dyn Parser>) -> Vec<Token> {
    let actual_line = without_initiators(source);

    if actual_line.is_empty() {
        return vec![];
    }

    let source_line = actual_line.get_content(source);

    let mut new_tokens = parser.parse(source_line);

    // Handle inline tags
    mark_inline_tags(&mut new_tokens);

    // Handle the block tag, if it exists on the current line.
    if let Some(tag_start) = new_tokens.iter().tuple_windows().position(|(a, b)| {
        matches!(
            (a, b),
            (
                Token {
                    kind: TokenKind::Punctuation(Punctuation::At),
                    ..
                },
                Token {
                    kind: TokenKind::Word(..),
                    ..
                }
            )
        )
    }) {
        for token in &mut new_tokens[tag_start..] {
            token.kind = TokenKind::Unlintable;
        }
    }

    for token in new_tokens.iter_mut() {
        token.span.push_by(actual_line.start);
    }

    new_tokens
}

/// Locate all inline tags (i.e. `{@tag ..}`) and mark them as unlintable
pub(super) fn mark_inline_tags(tokens: &mut [Token]) {
    let mut cursor = 0;

    loop {
        if cursor >= tokens.len() {
            break;
        }

        if let Some(new_cursor) = &tokens[cursor..]
            .iter()
            .position(|t| t.kind == TokenKind::Punctuation(Punctuation::OpenCurly))
            .map(|i| i + cursor)
        {
            cursor = *new_cursor;
        } else {
            break;
        }

        if let Some(p) = parse_inline_tag(&tokens[cursor..]) {
            for tok in &mut tokens[cursor..cursor + p] {
                tok.kind = TokenKind::Unlintable;
            }

            cursor += p;
            continue;
        }
        cursor += 1;
    }
}

/// Checks if the provided token slice begins with an inline tag, returning its
/// end if so.
fn parse_inline_tag(tokens: &[Token]) -> Option<usize> {
    if !matches!(
        tokens,
        [
            Token {
                kind: TokenKind::Punctuation(Punctuation::OpenCurly),
                ..
            },
            Token {
                kind: TokenKind::Punctuation(Punctuation::At),
                ..
            },
            Token {
                kind: TokenKind::Word(..),
                ..
            },
            ..,
        ]
    ) {
        return None;
    }

    if tokens.len() <= 3 {
        return None;
    }

    let mut cursor = 3;

    while cursor < tokens.len()
        && !matches!(
            tokens.get(cursor),
            Some(Token {
                kind: TokenKind::Punctuation(Punctuation::CloseCurly),
                ..
            })
        )
    {
        cursor += 1;
    }

    Some(cursor + 1)
}

#[cfg(test)]
mod tests {
    use harper_core::{Document, Punctuation, TokenKind, parsers::MarkdownOptions};

    use crate::CommentParser;

    #[test]
    fn escapes_loop() {
        let source = "/** This should _not_cause an infinite loop: {@ */";
        let parser =
            CommentParser::new_from_language_id("javascript", MarkdownOptions::default()).unwrap();
        Document::new_curated(source, &parser);
    }

    #[test]
    fn handles_inline_link() {
        let source = "/** See {@link MyClass} and [MyClass's foo property]{@link MyClass#foo}. */";
        let parser =
            CommentParser::new_from_language_id("javascript", MarkdownOptions::default()).unwrap();
        let document = Document::new_curated(source, &parser);

        assert!(matches!(
            document
                .tokens()
                .map(|t| t.kind.clone())
                .collect::<Vec<_>>()
                .as_slice(),
            &[
                TokenKind::Word(..),
                TokenKind::Space(1),
                TokenKind::Unlintable,
                TokenKind::Unlintable,
                TokenKind::Unlintable,
                TokenKind::Unlintable,
                TokenKind::Unlintable,
                TokenKind::Unlintable,
                TokenKind::Space(1),
                TokenKind::Word(..),
                TokenKind::Space(1),
                TokenKind::Punctuation(Punctuation::OpenSquare),
                TokenKind::Word(..),
                TokenKind::Space(1),
                TokenKind::Word(..),
                TokenKind::Space(1),
                TokenKind::Word(..),
                TokenKind::Punctuation(Punctuation::CloseSquare),
                TokenKind::Unlintable,
                TokenKind::Unlintable,
                TokenKind::Unlintable,
                TokenKind::Unlintable,
                TokenKind::Unlintable,
                TokenKind::Unlintable,
                TokenKind::Unlintable,
                TokenKind::Unlintable,
                TokenKind::Punctuation(Punctuation::Period),
            ]
        ));
    }

    #[test]
    fn handles_class() {
        let source = "/** @class Circle representing a circle. */";
        let parser =
            CommentParser::new_from_language_id("javascript", MarkdownOptions::default()).unwrap();
        let document = Document::new_curated(source, &parser);

        assert!(
            document.tokens().all(|t| t.kind.is_unlintable()
                || t.kind.is_newline()
                || t.kind.is_paragraph_break())
        );
    }
}



================================================
FILE: harper-comments/src/comment_parsers/lua.rs
================================================
use harper_core::Lrc;
use harper_core::Span;
use harper_core::Token;
use harper_core::parsers::{Markdown, MarkdownOptions, Parser};

use super::without_initiators;

#[derive(Clone)]
pub struct Lua {
    inner: Lrc<dyn Parser>,
}

impl Lua {
    pub fn new(parser: Lrc<dyn Parser>) -> Self {
        Self { inner: parser }
    }

    pub fn new_markdown(markdown_options: MarkdownOptions) -> Self {
        Self::new(Lrc::new(Markdown::new(markdown_options)))
    }
}

impl Parser for Lua {
    fn parse(&self, source: &[char]) -> Vec<Token> {
        let mut tokens = Vec::new();

        let mut chars_traversed = 0;

        for line in source.split(|c| *c == '\n') {
            if starts_with_prefix(line) {
                tokens.push(Token::new(
                    Span::new_with_len(chars_traversed, 0),
                    harper_core::TokenKind::Newline(2),
                ));
                chars_traversed += line.len() + 1;
                continue;
            }

            let mut new_tokens = parse_line(line, self.inner.clone());

            if chars_traversed + line.len() < source.len() {
                new_tokens.push(Token::new(
                    Span::new_with_len(line.len(), 1),
                    harper_core::TokenKind::Newline(1),
                ));
            }

            new_tokens
                .iter_mut()
                .for_each(|t| t.span.push_by(chars_traversed));

            chars_traversed += line.len() + 1;
            tokens.append(&mut new_tokens);
        }

        tokens
    }
}

fn starts_with_prefix(source: &[char]) -> bool {
    let actual = without_initiators(source);
    let actual_chars = actual.get_content(source);

    matches!(actual_chars, ['@', ..])
}

fn parse_line(source: &[char], parser: Lrc<dyn Parser>) -> Vec<Token> {
    let actual = without_initiators(source);

    if actual.is_empty() {
        return Vec::new();
    }

    let source = actual.get_content(source);

    let mut new_tokens = parser.parse(source);

    new_tokens
        .iter_mut()
        .for_each(|t| t.span.push_by(actual.start));

    new_tokens
}



================================================
FILE: harper-comments/src/comment_parsers/mod.rs
================================================
mod go;
mod javadoc;
mod jsdoc;
mod lua;
mod solidity;
mod unit;

pub use go::Go;
use harper_core::Span;
pub use javadoc::JavaDoc;
pub use jsdoc::JsDoc;
pub use lua::Lua;
pub use solidity::Solidity;
pub use unit::Unit;

/// Get the span of a tree-sitter-produced comment that doesn't include the
/// comment openers and closers.
fn without_initiators(source: &[char]) -> Span<char> {
    // Skip over the comment start characters
    let actual_start = source
        .iter()
        .position(|c| !is_comment_character(*c) && !c.is_whitespace())
        .unwrap_or(source.len());

    // Chop off the end
    let actual_end = source.len()
        - source
            .iter()
            .rev()
            .position(|c| !is_comment_character(*c) && !c.is_whitespace())
            .unwrap_or(0);

    Span::new(actual_start, actual_end)
}

fn is_comment_character(c: char) -> bool {
    matches!(c, '#' | '-' | '/' | '*' | '!')
}

#[cfg(test)]
mod tests {
    use super::without_initiators;

    #[test]
    fn cleans_empty_comment() {
        let source: Vec<_> = "///".chars().collect();
        assert_eq!(without_initiators(&source).len(), 0);
    }

    #[test]
    fn cleans_empty_comment_with_whitespace() {
        let source: Vec<_> = "///   ".chars().collect();
        assert_eq!(without_initiators(&source).len(), 0);
    }
}



================================================
FILE: harper-comments/src/comment_parsers/solidity.rs
================================================
use harper_core::Lrc;
use harper_core::Span;
use harper_core::Token;
use harper_core::parsers::{MarkdownOptions, Parser};

use super::jsdoc::JsDoc;
use super::without_initiators;

#[derive(Clone)]
pub struct Solidity {
    inner: Lrc<dyn Parser>,
}

impl Solidity {
    pub fn new(parser: Lrc<dyn Parser>) -> Self {
        Self { inner: parser }
    }

    pub fn new_markdown(markdown_options: MarkdownOptions) -> Self {
        Self::new(Lrc::new(JsDoc::new_markdown(markdown_options)))
    }
}

impl Parser for Solidity {
    fn parse(&self, source: &[char]) -> Vec<Token> {
        let mut tokens = Vec::new();

        let mut chars_traversed = 0;

        for line in source.split(|c| *c == '\n') {
            let mut new_tokens = parse_line(line, self.inner.clone());

            if chars_traversed + line.len() < source.len() {
                new_tokens.push(Token::new(
                    Span::new_with_len(line.len(), 1),
                    harper_core::TokenKind::Newline(1),
                ));
            }

            new_tokens
                .iter_mut()
                .for_each(|t| t.span.push_by(chars_traversed));

            chars_traversed += line.len() + 1;
            tokens.append(&mut new_tokens);
        }

        tokens
    }
}

fn parse_line(source: &[char], parser: Lrc<dyn Parser>) -> Vec<Token> {
    let mut actual = without_initiators(source);
    if actual.is_empty() {
        return Vec::new();
    }
    let mut actual_source = actual.get_content(source);

    // ignore the special SPDX-License-Identifier comment
    if actual_source.starts_with(&['S', 'P', 'D', 'X', '-']) {
        let Some(terminator) = source.iter().position(|c| *c == '\n') else {
            return Vec::new();
        };

        actual.start += terminator;

        let Some(new_source) = actual.try_get_content(actual_source) else {
            return Vec::new();
        };

        actual_source = new_source
    }

    let mut new_tokens = parser.parse(actual_source);

    new_tokens
        .iter_mut()
        .for_each(|t| t.span.push_by(actual.start));

    new_tokens
}



================================================
FILE: harper-comments/src/comment_parsers/unit.rs
================================================
use harper_core::Lrc;
use harper_core::parsers::{Markdown, MarkdownOptions, Parser};
use harper_core::{Span, Token};

use super::without_initiators;

/// A comment parser that strips starting `/` and `*` characters.
///
/// It is meant to cover _most_ cases in _most_ programming languages.
///
/// It assumes it is being provided a single line of comment at a time,
/// including the comment initiation characters.
#[derive(Clone)]
pub struct Unit {
    inner: Lrc<dyn Parser>,
}

impl Unit {
    pub fn new(parser: Lrc<dyn Parser>) -> Self {
        Self { inner: parser }
    }

    pub fn new_markdown(markdown_options: MarkdownOptions) -> Self {
        Self::new(Lrc::new(Markdown::new(markdown_options)))
    }
}

impl Parser for Unit {
    fn parse(&self, source: &[char]) -> Vec<Token> {
        let mut tokens = Vec::new();

        let mut chars_traversed = 0;
        let mut in_code_fence = false;

        for line in source.split(|c| *c == '\n') {
            if line_is_code_fence(line) {
                in_code_fence = !in_code_fence;
            }

            if in_code_fence {
                chars_traversed += line.len() + 1;
                continue;
            }

            let mut new_tokens = parse_line(line, self.inner.clone());

            if chars_traversed + line.len() < source.len() {
                new_tokens.push(Token::new(
                    Span::new_with_len(line.len(), 1),
                    harper_core::TokenKind::Newline(1),
                ));
            }

            new_tokens
                .iter_mut()
                .for_each(|t| t.span.push_by(chars_traversed));

            chars_traversed += line.len() + 1;
            tokens.append(&mut new_tokens);
        }

        tokens
    }
}

fn parse_line(source: &[char], parser: Lrc<dyn Parser>) -> Vec<Token> {
    let actual = without_initiators(source);

    if actual.is_empty() {
        return Vec::new();
    }

    let source = actual.get_content(source);

    let mut new_tokens = parser.parse(source);

    new_tokens
        .iter_mut()
        .for_each(|t| t.span.push_by(actual.start));

    new_tokens
}

fn line_is_code_fence(source: &[char]) -> bool {
    let actual = without_initiators(source);
    let actual_chars = actual.get_content(source);

    matches!(actual_chars, ['`', '`', '`', ..])
}



================================================
FILE: harper-comments/tests/language_support.rs
================================================
use std::path::Path;

use harper_comments::CommentParser;
use harper_core::linting::{LintGroup, Linter};
use harper_core::parsers::MarkdownOptions;
use harper_core::spell::FstDictionary;
use harper_core::{Dialect, Document};

/// Creates a unit test checking that the linting of a source file in
/// `language_support_sources` produces the expected number of lints.
macro_rules! create_test {
    ($filename:ident.$ext:ident, $correct_expected:expr) => {
        paste::paste! {
            #[test]
            fn [<lints_$ext _ $filename _correctly>](){
                 let filename = concat!(stringify!($filename), ".", stringify!($ext));
                 let source = include_str!(
                    concat!(
                        "./language_support_sources/",
                        concat!(
                        stringify!($filename), ".", stringify!($ext))
                    )
                 );

                 let parser = CommentParser::new_from_filename(Path::new(filename), MarkdownOptions::default()).unwrap();
                 let dict = FstDictionary::curated();
                 let document = Document::new(&source, &parser, &dict);

                 let mut linter = LintGroup::new_curated(dict, Dialect::American);
                 let lints = linter.lint(&document);

                 dbg!(&lints);
                 assert_eq!(lints.len(), $correct_expected);

                 // Make sure that all generated tokens span real characters
                 for token in document.tokens(){
                     assert!(token.span.try_get_content(document.get_source()).is_some());
                 }
            }
        }
    };
}

create_test!(multiline_comments.cpp, 4);
create_test!(multiline_comments.ts, 4);
create_test!(multiline_comments.sol, 4);
create_test!(clean.lua, 0);
create_test!(dirty.lua, 1);
create_test!(clean.rs, 0);
create_test!(clean.sol, 0);
create_test!(jsdoc.ts, 4);
create_test!(issue_96.lua, 0);
create_test!(merged_lines.ts, 1);
create_test!(javadoc_clean_simple.java, 0);
create_test!(javadoc_complex.java, 5);
create_test!(issue_132.rs, 1);
create_test!(laravel_app.php, 2);
create_test!(ignore_shebang_1.sh, 0);
create_test!(ignore_shebang_2.sh, 0);
create_test!(ignore_shebang_3.sh, 0);
create_test!(ignore_shebang_4.sh, 1);
create_test!(common.mill, 1);
create_test!(basic_kotlin.kt, 0);
create_test!(issue_1097.lua, 0);
create_test!(basic.clj, 12);

// Checks that some comments are masked out
create_test!(ignore_comments.rs, 1);
create_test!(ignore_comments.c, 1);
create_test!(ignore_comments.sol, 1);

// These are to make sure nothing crashes.
create_test!(empty.js, 0);
create_test!(issue_229.js, 0);
create_test!(issue_229.c, 0);
create_test!(issue_229.cs, 0);
create_test!(eof.rs, 0);



================================================
FILE: harper-comments/tests/language_support_sources/basic.clj
================================================
(ns clean
  "It is actually possible to document a ns.
  It's a nice place to describe the purpose of the namespace and maybe even
  the overall conventions used. Note how _not_ indenting the docstring makes
  it easier for tooling to display it correctly.")

;;;; Section Comment/Heading

;;; Foo...
;;; Bar...
;;; Baz...

;; good
(defn foo
  "This funtion doesn't do much."
  []
  nil)

;; bad
(defn bar
  ^{:doc "This function doesn't do much."}
  []
  nil)

;; good
(defn qzuf-number
  "Computes the [Qzuf number](https://wikipedia.org/qzuf) of the `coll`.
  Supported options in `opts`:

  | key           | description |
  | --------------|-------------|
  | `:finite-uni?`| Assume finite universe; default: `false`
  | `:complex?`   | If OK to return a [complex number](https://en.wikipedia.org/wiki/Complex_number); default: `false`
  | `:timeout`    | Throw an exception if the computation doesn't finish within `:timeout` milliseconds; default: `nil`

  Example:
  ```clojure
  (when (neg? (qzuf-number [1 2 3] {:finite-uni? true}))
    (throw (RuntimeException. \"Error in the Universe!\")))
  ```"
  [coll opts]
  nil)

(defprotocol MyProtocol
  "MyProtocol docstring"
  (foo [this x y z]
    "foo docstring")
  (bar [this]
    "bar docstring"))

;; good
(defn some-fun
  []
  ;; FIXME: This has crashed occasionally since v1.2.3. It may
  ;;        be related to the BarBazUtil upgrade. (xz 13-1-31)
  #_(baz))

;;;; Frob Grovel

;;; This section of code has some important implications:
;;;   1. Foo.
;;;   2. Bar.
;;;   3. Baz.

(defn fnord [zarquon]
  ;; If zob, then veeblefitz.
  (quux zot
        mumble             ; Zibblefrotz.
        frotz))

(defn foo [x]
  x ; I'm a line/code fragment comment.
  )

;;; I'm a top-level comment.
;;; I live outside any definition.

(defn foo [])

(def ^{:deprecated "0.5"} foo
  "Use `bar` instead."
  42)



================================================
FILE: harper-comments/tests/language_support_sources/basic_kotlin.kt
================================================
// *************************************************************************************************
//  A diminutive but fully-formed demonstration of idiomatic Kotlin.
//
//  1. Defines a sealed algebraic hierarchy to represent the discrete states of a task
//     transmogrifying through a rudimentary scheduler.
//  2. Employs a type-safe builder DSL to assemble a cohort of Task objects succinctly.
//  3. Utilizes coroutines and the structured-concurrency discipline to execute tasks
//     concomitantly while preserving deterministic shutdown semantics.
// *************************************************************************************************

// ---------- Domain model -------------------------------------------------------------------------

/** Immutable value holder representing a unit of executable labor. */
data class Task(
    val id: Int,
    val description: String,
    val action: suspend () -> Unit,
)

/** Exhaustive taxonomy of execution outcomes; the `sealed` modifier ensures compiler‐enforced totality. */
sealed interface TaskResult {
    /** Successful completion carrying an optional payload. */
    data class Success(val id: Int, val elapsedMillis: Long) : TaskResult
    /** Recoverable misadventure accompanied by the causal `Throwable`. */
    data class Failure(val id: Int, val cause: Throwable) : TaskResult
    /** Voluntary cessation initiated by the caller before execution. */
    data class Cancelled(val id: Int) : TaskResult
}

// ---------- DSL for declarative task construction -----------------------------------------------

/** Fluent builder furnishing a terse, expressive syntax for batch task definition. */
@DslMarker
annotation class TaskDsl

@TaskDsl
class TaskBatchBuilder {
    private val tasks = mutableListOf<Task>()

    /** Registers a new task whose body is expressed as a suspending lambda. */
    fun task(description: String, block: suspend () -> Unit) {
        tasks += Task(tasks.size + 1, description, block)
    }

    internal fun build(): List<Task> = tasks.toList()
}

/** Conveniences the client with type inference and inline lambda to craft a task batch. */
fun taskBatch(init: TaskBatchBuilder.() -> Unit): List<Task> =
    TaskBatchBuilder().apply(init).build()

// ---------- Scheduler implementation -------------------------------------------------------------

import kotlinx.coroutines.*
import kotlin.system.*

/** Executes all tasks concurrently, returning a conglomerate of `TaskResult` artifacts. */
suspend fun runTasks(tasks: List<Task>): List<TaskResult> = coroutineScope {
    val startEpoch = System.currentTimeMillis()

    // Launch each task within its own child coroutine; Deferred encapsulates the eventual result.
    val futures: List<Deferred<TaskResult>> = tasks.map { task ->
        async {
            val elapsed = measureTimeMillis {
                try {
                    task.action()
                } catch (t: CancellationException) {
                    // Propagate structured-concurrency cancellation upward; annotate as `Cancelled`.
                    return@async TaskResult.Cancelled(task.id)
                } catch (t: Throwable) {
                    // Swallow domain-level exception, encapsulate in Failure result.
                    return@async TaskResult.Failure(task.id, t)
                }
            }
            // If the lambda returns normally, the endeavor is deemed triumphant.
            TaskResult.Success(task.id, elapsed)
        }
    }

    // Await completion of the entire cohort, preserving result order by task identifier.
    futures.awaitAll().sortedBy { result ->
        when (result) {
            is TaskResult.Success   -> result.id
            is TaskResult.Failure   -> result.id
            is TaskResult.Cancelled -> result.id
        }
    }
}

// ---------- Demonstration entry-point ------------------------------------------------------------

fun main() = runBlocking {
    // Compose an eclectic suite of tasks via the DSL.
    val tasks = taskBatch {
        task("Inconsequential delay") {
            delay(250)
            println("Task A executed on thread ${Thread.currentThread().name}")
        }
        task("Spurious exception") {
            delay(100)
            error("Intentional kaboom")
        }
        task("CPU-bound Fibonacci") {
            val n = 25
            val fib = generateSequence(0 to 1) { it.second to it.first + it.second }
                .take(n + 1).last().first
            println("fib($n) = $fib")
        }
    }

    println("Launching ${tasks.size} tasks concurrently…\n")

    // Drive the scheduler and acquire the final ledger.
    val ledger = runTasks(tasks)

    // Expository epilogue.
    println("\n────────── Execution Ledger ──────────")
    ledger.forEach { result ->
        when (result) {
            is TaskResult.Success ->
                println("✔︎ Task ${result.id} succeeded in ${result.elapsedMillis} ms")
            is TaskResult.Failure ->
                println("✘ Task ${result.id} failed with ${result.cause::class.simpleName}: ${result.cause.message}")
            is TaskResult.Cancelled ->
                println("⚑ Task ${result.id} was cancelled before commencement")
        }
    }
}



================================================
FILE: harper-comments/tests/language_support_sources/clean.lua
================================================
---@meta

---@alias MyCustomType integer

---Calculate a value using [my custom type](lua://MyCustomType)
---@param x MyCustomType
function calculate(x) end



================================================
FILE: harper-comments/tests/language_support_sources/clean.rs
================================================
/// This is an example Rust file that should produce no Harper lints.

struct TestStruct {}

impl TestStruct {
    /// This is a test function.
    /// It has a [link](https://example.com) embedded inside
    fn test_function() {}

    /// This is another test function.
    /// It has another [link](https://example.com) embedded inside
    fn test_function() {}

    /// This is some gibberish to try to trigger a lint for sentences that continue for too long
    ///
    /// This is some gibberish to try to trigger a lint for sentences that continue for too long
    ///
    /// This is some gibberish to try to trigger a lint for sentences that continue for too long
    /// 
    /// This is some gibberish to try to trigger a lint for sentences that continue for too long
    ///
    /// This is some gibberish to try to trigger a lint for sentences that continue for too long
}




================================================
FILE: harper-comments/tests/language_support_sources/clean.sol
================================================
// SPDX-License-Identifier: UNLICENSED
pragma solidity ^0.8.20;

/// This is an example Solidity file that should produce no Harper lints.
contract TestContract {
    /// This is a test function.
    /// It has a [link](https://example.com) embedded inside
    function testFunction() external {}

    /**
     * @notice This is another test function.
     * @dev It has another [link](https://example.com) embedded inside
     * @param p This is a parameter
     */
    function testFunction2(uint256 p) external {}

    // This is some gibberish to try to trigger a lint for sentences that continue for too long
    //
    // This is some gibberish to try to trigger a lint for sentences that continue for too long
    //
    // This is some gibberish to try to trigger a lint for sentences that continue for too long
    //
    // This is some gibberish to try to trigger a lint for sentences that continue for too long
    //
    // This is some gibberish to try to trigger a lint for sentences that continue for too long
}



================================================
FILE: harper-comments/tests/language_support_sources/common.mill
================================================
import mill._, scalalib._

object hello extends ScalaModule {
  def scalaVersion = "2.13.8"

  // Define third-party dependencies
  def ivyDeps = Agg(
    ivy"com.lihaoyi::scalatags:0.9.4",  // for HTML generation
    ivy"com.lihaoyi::mainargs:0.6.2"     // for CLI argument parsing
  )

  // Define an test submodule using a test framework.
  object test extends ScalaTests {
    def testFramework = "utest.runner.Framework"
    def ivyDeps = Agg(
      ivy"com.lihaoyi::utest:0.7.10"
    )
  }
}



================================================
FILE: harper-comments/tests/language_support_sources/dirty.lua
================================================
---@meta

---@alias MyCustomType integer

---Calculate a value using [my custom type](lua://MyCustomType)
---
--- This calcumalates stuff
---@param x MyCustomType
function calculate(x) end



================================================
FILE: harper-comments/tests/language_support_sources/empty.js
================================================
// This is an empty file, apart from this comment.



================================================
FILE: harper-comments/tests/language_support_sources/eof.rs
================================================
fn main() {}
// This is a test to ensure Harper doesn't crash on comments at the end of files.



================================================
FILE: harper-comments/tests/language_support_sources/ignore_comments.c
================================================
// This comment is spellcheckd
int main() {
  // spellchecker:ignore Thear be code in here
}



================================================
FILE: harper-comments/tests/language_support_sources/ignore_comments.rs
================================================
/// spellcheck:ignore splling error
/// This applies to the entire comment block
#[derive(Debug)]
/// Ths comment block is checked
pub struct Testing {
    // spellchecker: ignore ths struct isnt done yt
}



================================================
FILE: harper-comments/tests/language_support_sources/ignore_comments.sol
================================================
// SPDX-License-Identifier: UNLICENSED
pragma solidity ^0.8.20;

/// spellcheck:ignore splling error
/// Ths applies to the entire comment block
contract Testing {
    // spellchecker: ignore ths contrat isnt done yt
    uint256 internal foo;

    /// Ths comment block is checked
    function test() external {}
}



================================================
FILE: harper-comments/tests/language_support_sources/ignore_shebang_1.sh
================================================
#!/bin/sh
# This is a test to make sure that we don't lint shebang lines.



================================================
FILE: harper-comments/tests/language_support_sources/ignore_shebang_2.sh
================================================
#! /usr/bin/env sh
# This is a test to make sure that we don't lint shebang lines.



================================================
FILE: harper-comments/tests/language_support_sources/ignore_shebang_3.sh
================================================
#!/usr/bin/python3
# This is a test to make sure that we don't lint shebang lines.



================================================
FILE: harper-comments/tests/language_support_sources/ignore_shebang_4.sh
================================================
#/bin/sh
# This is a test to make sure that we don't ignore invalid shebang lines.



================================================
FILE: harper-comments/tests/language_support_sources/issue_1097.lua
================================================
---Starting with something capitalized, but without dot at the end
---@type table<string, string>
local f = {} -- ending with a dot.



================================================
FILE: harper-comments/tests/language_support_sources/issue_132.rs
================================================
/// ```
/// println!("Test");
/// ```
///
/// This shoud get checked.
fn main() {
    println!("Hello, world!");
}



================================================
FILE: harper-comments/tests/language_support_sources/issue_229.c
================================================
// 


================================================
FILE: harper-comments/tests/language_support_sources/issue_229.cs
================================================
// 


================================================
FILE: harper-comments/tests/language_support_sources/issue_229.js
================================================
// 


================================================
FILE: harper-comments/tests/language_support_sources/issue_96.lua
================================================
-- Below, we have a situation where the line terminates and should end the sentence.

local alphabet = {
  [1] = "a",  -- This is a test
  [2] = "b",  -- This is a test
  [3] = "c",  -- This is a test
  [4] = "d",  -- This is a test
  [5] = "e",  -- This is a test
  [6] = "f",  -- This is a test
  [7] = "g",  -- This is a test
  [8] = "h",  -- This is a test
  [9] = "i",  -- This is a test
  [10] = "j", -- This is a test
  [11] = "k", -- This is a test
}



================================================
FILE: harper-comments/tests/language_support_sources/issue_96.rb
================================================
# Below, we have a situation where the line terminates and should end the sentence.

alphabet = [
 "a",  # This is a test
 "b",  # This is a test
 "c",  # This is a test
 "d",  # This is a test
 "e",  # This is a test
 "f",  # This is a test
 "g",  # This is a test
 "h",  # This is a test
 "i",  # This is a test
 "j",  # This is a test
 "k",  # This is a test
]



================================================
FILE: harper-comments/tests/language_support_sources/javadoc_clean_simple.java
================================================
class TestClass {

  /**
   * This is a JavaDoc without any of the fancy frills that come with it.
   */
  public static void main(String[] args) {
    System.out.println("Hello world.");
  }
}



================================================
FILE: harper-comments/tests/language_support_sources/javadoc_complex.java
================================================
class TestClass {
  /**
   * This is a JavaDoc with <i>many</i> of the fancy frills that come with it.
   *
   * <p>
   * Notably, the allowed use of HTML inline to <i>format</i> the text.
   * </p>
   *
   * Also, the allowed use of the various metadata tags we can attach to methods
   * and classes.
   *
   * @param args these are the arguents passed to the program from the command
   *             lin.
   */
  public static void main(String[] args) {
    greet("world");
  }

  /**
   * This doc has a link in it: {@link this sould b ignor} but not tis
   *
   * @param name this is anoher test.
   */
  public static void greet(String name) {
    System.out.println("Hello " + name + ".");
  }
}



================================================
FILE: harper-comments/tests/language_support_sources/jsdoc.ts
================================================
/** This is a doc comment.
  * Since there are no keywords it _sould_ be checked. */
function test(){}

/** This is also a doc comment.
  * @class this sould be unchecked. */
class Clazz { }

/** Here is another example: {@link this sould also b unchecked}. But this _sould_ be.*/

/** However, tis should be checked, while {@link tis should not} */

/**
 * The following examples should be ignored by Harper.
 *
 * @param {string} n - ignor
 * @param {string} [o] - ignor
 * @param {string} [d=DefaultValue] - ignor
 * @return {string} ignor
 *
 * This should not be ignor
 */

function foo(n, o, d) {
  return n
}



================================================
FILE: harper-comments/tests/language_support_sources/laravel_app.php
================================================
<?php

return [

    /*
    |--------------------------------------------------------------------------
    | Application Name
    |--------------------------------------------------------------------------
    |
    | This value is the name of your application, which will be used when the
    | framework needs to place the application's name in a notification or
    | other UI elements where an application name needs to be displayed.
    |
    */

    'name' => env('APP_NAME', 'Laravel'),

    /*
    |--------------------------------------------------------------------------
    | Application Environment
    |--------------------------------------------------------------------------
    |
    | This value determines the "environment" your application is currently
    | running in. This may determine how you prefer to configure various
    | services the application utilizes. Set this in your ".env" file.
    |
    */

    'env' => env('APP_ENV', 'production'),

    /*
    |--------------------------------------------------------------------------
    | Application Debug Mode
    |--------------------------------------------------------------------------
    |
    | When your application is in debug mode, detailed error messages with
    | stacktraces will be shown on every error that occurs within your
    | application. If disabled, a simple generic error page is shown.
    |
    */

    'debug' => (bool) env('APP_DEBUG', false),

    /*
    |--------------------------------------------------------------------------
    | Application URL
    |--------------------------------------------------------------------------
    |
    | This URL is used by the console to properly generate URLs when using
    | the Artisan command line tool. You should set this to the root of
    | the application so that it's available within Artisan commands.
    |
    */

    'url' => env('APP_URL', 'http://localhost'),

    /*
    |--------------------------------------------------------------------------
    | Application Timezone
    |--------------------------------------------------------------------------
    |
    | Here you may specify the default timezone for your application, which
    | will be used by the PHP date and date-time functions. The timezone
    | is set to "UTC" by default as it is suitable for most use cases.
    |
    */

    'timezone' => env('APP_TIMEZONE', 'UTC'),

    /*
    |--------------------------------------------------------------------------
    | Application Locale Configuration
    |--------------------------------------------------------------------------
    |
    | The application locale determines the default locale that will be used
    | by Laravel's translation / localization methods. This option can be
    | set to any locale for which you plan to have translation strings.
    |
    */

    'locale' => env('APP_LOCALE', 'en'),

    'fallback_locale' => env('APP_FALLBACK_LOCALE', 'en'),

    'faker_locale' => env('APP_FAKER_LOCALE', 'en_US'),

    /*
    |--------------------------------------------------------------------------
    | Encryption Key
    |--------------------------------------------------------------------------
    |
    | This key is utilized by Laravel's encryption services and should be set
    | to a random, 32 character string to ensure that all encrypted values
    | are secure. You should do this prior to deploying the application.
    |
    */

    'cipher' => 'AES-256-CBC',

    'key' => env('APP_KEY'),

    'previous_keys' => [
        ...array_filter(
            explode(',', env('APP_PREVIOUS_KEYS', ''))
        ),
    ],

    /*
    |--------------------------------------------------------------------------
    | Maintenance Mode Driver
    |--------------------------------------------------------------------------
    |
    | These configuration options determine the driver used to determine and
    | manage Laravel's "maintenance mode" status. The "cache" driver will
    | allow maintenance mode to be controlled across multiple machines.
    |
    | Supported drivers: "file", "cache"
    |
    */

    'maintenance' => [
        'driver' => env('APP_MAINTENANCE_DRIVER', 'file'),
        'store' => env('APP_MAINTENANCE_STORE', 'database'),
    ],

];



================================================
FILE: harper-comments/tests/language_support_sources/merged_lines.ts
================================================
// This is a test to make sure we don't split up paragraphs on newlines.
// This should be the same sentence,
// this should be the same sentence,
// this should be the same sentence,
// this should be the same sentence,
// this should be the same sentence,
// this should be the same sentence,
// this should be the same sentence,
// this should be the same sentence,
//
// And this should be a new sentence.



================================================
FILE: harper-comments/tests/language_support_sources/multiline_comments.cpp
================================================
/// This is an example of an problematic comment.
/// It should produce one error.
int test() {}

/***
 * This is an example of a possible error:
 * these subsequent lines should not be considered a new sentence and should
 * produce no errors.
 */
int arbitrary() {}

/// Let's aadd a cuple spelling errors for good measure.



================================================
FILE: harper-comments/tests/language_support_sources/multiline_comments.sol
================================================
// SPDX-License-Identifier: UNLICENSED
pragma solidity ^0.8.20;

/// This is an example of an problematic comment.
/// It should produce one error.
contract Test {}

/**
 * This is an example of a possible error:
 * these subsequent lines should not be considered a new sentence and should
 * produce no errors.
 */
library FooBar {}

/// Let's aadd a cuple spelling errors for good measure.



================================================
FILE: harper-comments/tests/language_support_sources/multiline_comments.ts
================================================
// This is an example of an problematic comment
// It should produce one error
function test() {}

/***
 * This is an example of a possible error:
 * these subsequent lines should not be considered a new sentence and should
 * produce no errors.
 */
function arbitrary() {}

// Let's aadd a cuple spelling errors for good measure.




================================================
FILE: harper-core/README.md
================================================
# `harper-core`

`harper-core` is the fundamental engine behind [Harper](https://writewithharper.com), the private grammar checker.

`harper-core` is [available on `crates.io`](https://crates.io/crates/harper-core) to enable Rust engineers to integrate high-quality grammar checking directly into their apps and workflows.
Feel free to use `harper-core` in your projects.
If you run into problems with the code, open an issue or, even better, create a pull request.
We are also happy to chat with you on [Discord](https://discord.com/invite/JBqcAaKrzQ).

[The documentation for `harper-core` is available online.](https://docs.rs/harper-core/latest/harper_core/)

If you would prefer to run Harper from inside a JavaScript runtime, [we have a package for that as well.](https://www.npmjs.com/package/harper.js)

## Example

Here's what a full end-to-end linting pipeline could look like using `harper-core`.

```rust
use harper_core::linting::{LintGroup, Linter};
use harper_core::parsers::PlainEnglish;
use harper_core::spell::FstDictionary;
use harper_core::{Dialect, Document};

let text = "This is an test.";
let parser = PlainEnglish;

let document = Document::new_curated(text, &parser);

let dict = FstDictionary::curated();
let mut linter = LintGroup::new_curated(dict, Dialect::American);

let lints = linter.lint(&document);

for lint in lints {
    println!("{:?}", lint);
}
```

## Features

`concurrent`: Whether to use thread-safe primitives (`Arc` vs `Rc`). Disabled by default.
It is not recommended unless you need thread-safely (i.e. you want to use something like `tokio`).

## Other Relevant Packages

- [`harper-ls`](https://crates.io/crates/harper-ls)
- [`harper-tree-sitter`](https://crates.io/crates/harper-tree-sitter)



================================================
FILE: harper-core/annotations.json
================================================
{
	"affixes": {
		"K": {
			"#": "'pro-' prefix",
			"kind": "prefix",
			"cross_product": true,
			"replacements": [
				{
					"remove": "",
					"add": "pro",
					"condition": "."
				}
			],
			"target": [],
			"base_metadata": {},
			"rename_ok": true
		},
		"L": {
			"#": "'-ment' suffix",
			"kind": "suffix",
			"cross_product": true,
			"replacements": [
				{
					"remove": "",
					"add": "ment",
					"condition": "."
				}
			],
			"target": [],
			"base_metadata": {},
			"rename_ok": true
		},
		"E": {
			"#": "'dis-' prefix",
			"kind": "prefix",
			"cross_product": true,
			"replacements": [
				{
					"remove": "",
					"add": "dis",
					"condition": "."
				}
			],
			"target": [],
			"base_metadata": {},
			"rename_ok": true
		},
		"Y": {
			"#": "'-ly' suffix",
			"kind": "suffix",
			"cross_product": true,
			"replacements": [
				{
					"remove": "",
					"add": "ly",
					"condition": "."
				}
			],
			"target": [
				{
					"metadata": {
						"adverb": {
							"is_manner": true
						}
					}
				}
			],
			"base_metadata": {
				"adjective": {}
			}
		},
		"U": {
			"#": "'un-' prefix",
			"kind": "prefix",
			"cross_product": true,
			"replacements": [
				{
					"remove": "",
					"add": "un",
					"condition": "."
				}
			],
			"target": [],
			"base_metadata": {}
		},
		"H": {
			"#": "'-ieth' suffix",
			"kind": "suffix",
			"cross_product": false,
			"replacements": [
				{
					"remove": "y",
					"add": "ieth",
					"condition": "y"
				},
				{
					"remove": "",
					"add": "th",
					"condition": "[^y]"
				}
			],
			"target": [],
			"base_metadata": {}
		},
		"^": {
			"#": "'-(i)est' superlative suffix",
			"//": "mnemonic: the topmost is the best. see also 'u' which marks a superlative form",
			"kind": "suffix",
			"cross_product": false,
			"replacements": [
				{
					"remove": "",
					"add": "st",
					"condition": "e"
				},
				{
					"remove": "y",
					"add": "iest",
					"condition": "[^aeiou]y"
				},
				{
					"remove": "",
					"add": "est",
					"condition": "[aeiou]y"
				},
				{
					"remove": "",
					"add": "est",
					"condition": "[^ey]"
				}
			],
			"target": [
				{
					"if_base": {
						"adjective": {}
					},
					"metadata": {
						"adjective": {
							"degree": "Superlative"
						}
					}
				}
			],
			"base_metadata": {}
		},
		">": {
			"#": "'-(i)er' comparative suffix; agent suffix. see also 'c' which marks a comparative form",
			"//": "mnemonic: greater than is better; singular of 'Z'",
			"kind": "suffix",
			"cross_product": true,
			"replacements": [
				{
					"remove": "",
					"add": "r",
					"condition": "e"
				},
				{
					"remove": "y",
					"add": "ier",
					"condition": "[^aeiou]y"
				},
				{
					"remove": "",
					"add": "er",
					"condition": "[aeiou]y"
				},
				{
					"remove": "",
					"add": "er",
					"condition": "[^ey]"
				}
			],
			"target": [
				{
					"if_base": {
						"adjective": {}
					},
					"metadata": {
						"adjective": {
							"degree": "Comparative"
						}
					}
				},
				{
					"if_base": {
						"verb": {}
					},
					"metadata": {
						"noun": {
							"//": "TODO: agent noun: run -> runner"
						}
					}
				}
			],
			"base_metadata": {}
		},
		"e": {
			"#": "'de-' prefix",
			"kind": "prefix",
			"cross_product": true,
			"replacements": [
				{
					"remove": "",
					"add": "de",
					"condition": "."
				}
			],
			"target": [],
			"base_metadata": {}
		},
		"v": {
			"#": "'-ive' suffix",
			"kind": "suffix",
			"cross_product": false,
			"replacements": [
				{
					"remove": "e",
					"add": "ive",
					"condition": "e"
				},
				{
					"remove": "",
					"add": "ive",
					"condition": "[^e]"
				}
			],
			"target": [],
			"base_metadata": {}
		},
		"n": {
			"#": "nominalization suffixes: -ion, -ication, -en",
			"kind": "suffix",
			"cross_product": true,
			"replacements": [
				{
					"remove": "e",
					"add": "ion",
					"condition": "e"
				},
				{
					"remove": "y",
					"add": "ication",
					"condition": "y"
				},
				{
					"remove": "",
					"add": "en",
					"condition": "[^ey]"
				}
			],
			"target": [],
			"base_metadata": {}
		},
		"r": {
			"#": "'re-' prefix",
			"kind": "prefix",
			"cross_product": true,
			"replacements": [
				{
					"remove": "",
					"add": "re",
					"condition": "."
				}
			],
			"target": [],
			"base_metadata": {}
		},
		"Z": {
			"#": "'-(i)(e)rs' suffix",
			"//": "plural of '>' agent noun suffix '-(i)(e)r'",
			"kind": "suffix",
			"cross_product": true,
			"replacements": [
				{
					"remove": "",
					"add": "rs",
					"condition": "e"
				},
				{
					"remove": "y",
					"add": "iers",
					"condition": "[^aeiou]y"
				},
				{
					"remove": "",
					"add": "ers",
					"condition": "[aeiou]y"
				},
				{
					"remove": "",
					"add": "ers",
					"condition": "[^ey]"
				}
			],
			"target": [],
			"base_metadata": {},
			"rename_ok": true
		},
		"p": {
			"#": "'-(i)ness' suffix",
			"kind": "suffix",
			"cross_product": true,
			"replacements": [
				{
					"remove": "y",
					"add": "iness",
					"condition": "[^aeiou]y"
				},
				{
					"remove": "",
					"add": "ness",
					"condition": "[aeiou]y"
				},
				{
					"remove": "",
					"add": "ness",
					"condition": "[^y]"
				}
			],
			"target": [],
			"base_metadata": {},
			"rename_ok": true
		},
		"g": {
			"#": "-'s possessive suffix; contraction of 'has' and 'is",
			"//": "mnemonic: 'genitive' is a similar concept to 'possessive'",
			"kind": "suffix",
			"cross_product": true,
			"replacements": [
				{
					"remove": "",
					"add": "'s",
					"condition": "."
				}
			],
			"target": [
				{
					"metadata": {
						"noun": {
							"is_possessive": true
						}
					}
				}
			],
			"base_metadata": {
				"noun": {}
			}
		},
		"W": {
			"#": "'con-' prefix",
			"kind": "prefix",
			"cross_product": true,
			"replacements": [
				{
					"remove": "",
					"add": "con",
					"condition": "."
				}
			],
			"target": [],
			"base_metadata": {},
			"rename_ok": true
		},
		"B": {
			"#": "'-able' suffix",
			"kind": "suffix",
			"cross_product": true,
			"replacements": [
				{
					"remove": "",
					"add": "able",
					"condition": "[^aeiou]"
				},
				{
					"remove": "",
					"add": "able",
					"condition": "ee"
				},
				{
					"remove": "e",
					"add": "able",
					"condition": "[^aeiou]e"
				}
			],
			"target": [
				{
					"if_base": {
						"verb": {}
					},
					"metadata": {
						"adjective": {
							"degree": "Positive"
						}
					}
				}
			],
			"base_metadata": {}
		},
		"S": {
			"#": "'-(i)(e)s' plural suffix",
			"kind": "suffix",
			"cross_product": true,
			"replacements": [
				{
					"remove": "y",
					"add": "ies",
					"condition": "[^aeiou]y"
				},
				{
					"remove": "",
					"add": "s",
					"condition": "[aeiou]y"
				},
				{
					"remove": "",
					"add": "es",
					"condition": "[sxzh]"
				},
				{
					"remove": "",
					"add": "s",
					"condition": "[^sxzhy]"
				}
			],
			"target": [
				{
					"if_base": {
						"noun": {}
					},
					"metadata": {
						"noun": {
							"is_plural": true
						}
					}
				},
				{
					"if_base": {
						"verb": {}
					},
					"metadata": {
						"verb": {
							"verb_form": "THIRD_PERSON_SINGULAR"
						}
					}
				}
			],
			"base_metadata": {}
		},
		"d": {
			"#": "'-(e)d' suffix; verb past",
			"kind": "suffix",
			"cross_product": true,
			"replacements": [
				{
					"remove": "",
					"add": "d",
					"condition": "e"
				},
				{
					"remove": "y",
					"add": "ied",
					"condition": "[^aeiou]y"
				},
				{
					"remove": "",
					"add": "ed",
					"condition": "[^ey]"
				},
				{
					"remove": "",
					"add": "ed",
					"condition": "[aeiou]y"
				}
			],
			"target": [
				{
					"metadata": {
						"adjective": {
							"degree": "Positive"
						}
					}
				},
				{
					"if_base": {
						"verb": {}
					},
					"metadata": {
						"verb": {
							"verb_form": "PAST"
						}
					}
				}
			],
			"base_metadata": {}
		},
		"G": {
			"#": "'-ing' suffix",
			"kind": "suffix",
			"cross_product": true,
			"replacements": [
				{
					"remove": "e",
					"add": "ing",
					"condition": "e"
				},
				{
					"remove": "",
					"add": "ing",
					"condition": "[^e]"
				}
			],
			"target": [
				{
					"metadata": {
						"verb": {
							"verb_form": "PROGRESSIVE"
						},
						"noun": {
							"is_mass": true
						},
						"adjective": {}
					}
				}
			],
			"base_metadata": {}
		},
		"Q": {
			"#": "'-ally' suffix",
			"kind": "suffix",
			"cross_product": true,
			"replacements": [
				{
					"remove": "",
					"add": "ally",
					"condition": "."
				}
			],
			"target": [
				{
					"metadata": {
						"adverb": {}
					}
				}
			],
			"base_metadata": {},
			"rename_ok": true
		},
		"f": {
			"#": "'-ful' suffix",
			"kind": "suffix",
			"cross_product": true,
			"replacements": [
				{
					"remove": "",
					"add": "ful",
					"condition": "."
				}
			],
			"target": [],
			"base_metadata": {}
		},
		"i": {
			"#": "'in-' prefix",
			"kind": "prefix",
			"cross_product": true,
			"replacements": [
				{
					"remove": "",
					"add": "in",
					"condition": "."
				}
			],
			"target": [],
			"base_metadata": {}
		},
		"X": {
			"#": "'-ions', '-ications', '-ens' suffixes",
			"kind": "suffix",
			"cross_product": true,
			"replacements": [
				{
					"remove": "e",
					"add": "ions",
					"condition": "e"
				},
				{
					"remove": "y",
					"add": "ications",
					"condition": "y"
				},
				{
					"remove": "",
					"add": "ens",
					"condition": "[^ey]"
				}
			],
			"target": [],
			"base_metadata": {},
			"rename_ok": true
		},
		"z": {
			"#": "'-ings' suffix",
			"kind": "suffix",
			"cross_product": true,
			"replacements": [
				{
					"remove": "e",
					"add": "ings",
					"condition": "e"
				},
				{
					"remove": "",
					"add": "ings",
					"condition": "[^e]"
				}
			],
			"target": [],
			"base_metadata": {},
			"rename_ok": true
		}
	},
	"properties": {
		"N": {
			"#": "noun property",
			"metadata": {
				"noun": {}
			}
		},
		"O": {
			"#": "proper noun property",
			"propagate": true,
			"metadata": {
				"noun": {
					"is_proper": true
				}
			}
		},
		"l": {
			"#": "linking verb property",
			"//": "see also A: auxiliary verb property",
			"metadata": {
				"verb": {
					"is_linking": true
				}
			}
		},
		"V": {
			"#": "verb property",
			"metadata": {
				"verb": {}
			}
		},
		"j": {
			"#": "verb past property",
			"metadata": {
				"verb": {
					"verb_form": "PAST"
				}
			}
		},
		"J": {
			"#": "adjective property",
			"metadata": {
				"adjective": {}
			}
		},
		"x": {
			"#": "swear word property",
			"//": "'xxx' used to be a placeholder for swear words",
			"propagate": true,
			"metadata": {
				"swear": true
			}
		},
		"C": {
			"#": "conjunction property",
			"metadata": {
				"conjunction": {}
			}
		},
		"I": {
			"#": "pronoun property",
			"metadata": {
				"pronoun": {}
			}
		},
		"0": {
			"#": "singular noun property",
			"//": "mnemonic: the closest digit to single '1' that's not used for grammatical person",
			"metadata": {
				"noun": {
					"is_singular": true
				}
			}
		},
		"9": {
			"#": "plural noun property",
			"//": "mnemonic: the biggest, most plural digit",
			"metadata": {
				"noun": {
					"is_plural": true
				}
			}
		},
		"~": {
			"#": "common word property",
			"metadata": {
				"common": true
			},
			"rename_ok": true
		},
		"P": {
			"#": "preposition property",
			"metadata": {
				"preposition": true
			}
		},
		"D": {
			"#": "determiner property",
			"metadata": {
				"determiner": {}
			}
		},
		"q": {
			"#": "quantifier property",
			"metadata": {
				"determiner": {
					"is_quantifier": true
				}
			}
		},
		"R": {
			"#": "adverb property",
			"metadata": {
				"adverb": {}
			}
		},
		"s": {
			"#": "subject case property",
			"metadata": {
				"pronoun": {
					"is_subject": true
				}
			}
		},
		"o": {
			"#": "object case property",
			"metadata": {
				"pronoun": {
					"is_object": true
				}
			}
		},
		"1": {
			"#": "first-person property",
			"metadata": {
				"pronoun": {
					"person": "First"
				}
			}
		},
		"2": {
			"#": "second-person property",
			"metadata": {
				"pronoun": {
					"person": "Second"
				}
			}
		},
		"3": {
			"#": "third-person property",
			"metadata": {
				"pronoun": {
					"person": "Third"
				}
			}
		},
		"c": {
			"#": "comparative property",
			"//": "see also '>' which derives a comparative form",
			"metadata": {
				"adjective": {
					"degree": "Comparative"
				}
			}
		},
		"u": {
			"#": "superlative property",
			"//": "see also '^' which derives a superlative form",
			"metadata": {
				"adjective": {
					"degree": "Superlative"
				}
			}
		},
		"*": {
			"#": "singular third-person subject pronoun property",
			"//": "so we can do verb agreement",
			"metadata": {
				"pronoun": {
					"is_singular": true,
					"person": "Third"
				}
			}
		},
		".": {
			"#": "singular pronoun property",
			"//": "mnemonic: one dot",
			"metadata": {
				"pronoun": {
					"is_singular": true
				}
			}
		},
		":": {
			"#": "plural pronoun property",
			"//": "mnemonic: multiple dots",
			"metadata": {
				"pronoun": {
					"is_plural": true
				}
			}
		},
		"A": {
			"#": "auxiliary verb property",
			"//": "see also l: linking verb property",
			"metadata": {
				"verb": {
					"is_auxiliary": true
				}
			}
		},
		"<": {
			"#": "American property",
			"propagate": true,
			"metadata": {
				"dialects": "AMERICAN"
			},
			"rename_ok": true
		},
		"!": {
			"#": "GB property",
			"propagate": true,
			"metadata": {
				"dialects": "BRITISH"
			},
			"rename_ok": true
		},
		"@": {
			"#": "CA property",
			"//": "mnemonic: at symbol resembles an 'a' inside a 'C'",
			"propagate": true,
			"metadata": {
				"dialects": "CANADIAN"
			}
		},
		"_": {
			"#": "AU property",
			"//": "mnemonic: down under",
			"propagate": true,
			"metadata": {
				"dialects": "AUSTRALIAN"
			}
		},
		"₹": {
			"#": "IN property",
			"//": "mnemonic: rupee symbol",
			"propagate": true,
			"metadata": {
				"dialects": "INDIAN"
			}
		},
		"F": {
			"#": "reflexive property",
			"metadata": {
				"pronoun": {
					"is_reflexive": true
				}
			}
		},
		"M": {
			"#": "demonstrative determiner property",
			"metadata": {
				"determiner": {
					"is_demonstrative": true
				}
			}
		},
		"5": {
			"#": "possessive determiner property",
			"//": "mnemonic: 5 looks like an 's'",
			"metadata": {
				"determiner": {
					"is_possessive": true
				}
			}
		},
		"a": {
			"#": "personal pronoun property",
			"//": "'personal' means 'grammatical person', not 'human'",
			"metadata": {
				"pronoun": {
					"is_personal": true
				}
			}
		},
		"m": {
			"#": "mass noun (only) property",
			"metadata": {
				"noun": {
					"is_mass": true
				}
			}
		},
		"w": {
			"#": "mass + countable noun property",
			"metadata": {
				"noun": {
					"is_countable": true,
					"is_mass": true
				}
			}
		},
		"b": {
			"#": "verb lemma form property",
			"//": "mnemonic: 'b' for 'base form'",
			"metadata": {
				"verb": {
					"verb_form": "LEMMA"
				}
			}
		},
		"t": {
			"#": "verb preterite / simple past form property",
			"metadata": {
				"verb": {
					"verb_form": "PRETERITE"
				}
			}
		},
		"T": {
			"#": "verb past participle form property",
			"metadata": {
				"verb": {
					"verb_form": "PAST_PARTICIPLE"
				}
			}
		},
		"6": {
			"#": "verb progressive form property",
			"//": "mnemonic: '6' looks like 'g' in 'ing'",
			"metadata": {
				"verb": {
					"verb_form": "PROGRESSIVE"
				}
			}
		},
		"h": {
			"#": "verb third person singular present form property",
			"metadata": {
				"verb": {
					"verb_form": "THIRD_PERSON_SINGULAR"
				}
			}
		},
		"y": {
			"#": "adverb of manner property",
			"//": "mnemonic: 'y' looks like 'ly'",
			"metadata": {
				"adverb": {
					"is_manner": true
				}
			}
		},
		"8": {
			"#": "adverb of frequency property",
			"//": "mnemonic: '8' looks like '♾️'",
			"metadata": {
				"adverb": {
					"is_frequency": true
				}
			}
		},
		"%": {
			"#": "adverb of degree property",
			"//": "mnemonic: '%' reminds of '°'",
			"metadata": {
				"adverb": {
					"is_degree": true
				}
			}
		},
		"♂": {
			"#": "masculine property",
			"metadata": {
				"//": "not yet implemented"
			}
		},
		"♀": {
			"#": "feminine property",
			"metadata": {
				"//": "not yet implemented"
			}
		},
		"ª": {
			"#": "animate property",
			"metadata": {
				"//": "not yet implemented"
			}
		},
		"(": {
			"#": "prefix property",
			"metadata": {
				"affix": {
					"is_prefix": true
				}
			}
		},
		"/": {
			"#": "phrasal verb property",
			"metadata": {
				"verb": {
					"is_phrasal": true
				}
			}
		}
	}
}



================================================
FILE: harper-core/build.rs
================================================
use std::{env, fs, path::PathBuf};

fn main() {
    let manifest_dir = PathBuf::from(env::var("CARGO_MANIFEST_DIR").unwrap());
    let weir_rule_dir = manifest_dir.join("./src/linting/weir_rules");
    let out_dir = PathBuf::from(env::var("OUT_DIR").unwrap());
    let dest = out_dir.join("weir_rules_generated_list.rs");

    let mut files: Vec<PathBuf> = fs::read_dir(&weir_rule_dir)
        .unwrap()
        .filter_map(Result::ok)
        .filter(|e| e.file_type().unwrap().is_file())
        .map(|e| e.path().to_path_buf())
        .collect();

    files.sort();

    let mut code = String::new();

    code.push_str("generate_boilerplate!{[");

    for file in files {
        if file
            .file_name()
            .unwrap()
            .to_string_lossy()
            .ends_with(".weir")
        {
            code.push_str(&format!(
                "{},\n",
                file.file_stem().unwrap().to_str().unwrap()
            ));
        }
    }

    code.push_str("]}");

    fs::write(&dest, code).unwrap();

    println!("cargo:rerun-if-changed={}", weir_rule_dir.display());
    println!("cargo:rerun-if-changed=build.rs");
    println!("cargo:rustc-env=WEIR_RULE_DIR={}", weir_rule_dir.display());
    println!("cargo:rustc-env=WEIR_RULE_LIST={}", dest.display());
}



================================================
FILE: harper-core/Cargo.toml
================================================
[package]
name = "harper-core"
version = "1.5.1"
edition = "2024"
description = "The language checker for developers."
license = "Apache-2.0"
readme = "README.md"
repository = "https://github.com/automattic/harper"

[dependencies]
blanket = "0.4.0"
fst = "0.4.7"
hashbrown = { version = "0.16.1", features = ["serde"] }
is-macro = "0.3.6"
itertools = "0.14.0"
ordered-float = { version = "5.1.0", features = ["serde"] }
paste = "1.0.14"
pulldown-cmark = "0.13.0"
serde = { version = "1.0.228", features = ["derive"] }
serde_json = "1.0.149"
smallvec = { version = "1.15.1", features = ["serde"] }
thiserror = "2.0.18"
unicode-blocks = "0.1.9"
unicode-script = "0.5.8"
unicode-width = "0.2.2"
levenshtein_automata = { version = "0.2.1", features = ["fst_automaton"] }
cached = "0.56.0"
lru = "0.16.3"
foldhash = "0.2.0"
strum_macros = "0.27.2"
strum = "0.27.2"
ammonia = "4.1.2"
harper-brill = { path = "../harper-brill", version = "1.0.0" }
harper-thesaurus = { path = "../harper-thesaurus", version = "1.4.1", optional = true }
bitflags = { version = "2.10.0", features = ["serde"] }
trie-rs = "0.4.2"

[dev-dependencies]
criterion = { version = "0.8.1", default-features = false }
rand = "0.8.5"
quickcheck = "1.0.3"
quickcheck_macros = "1.1.0"
once_cell = "1.21.3"
rayon = "1.11.0"

[[bench]]
name = "parse_essay"
harness = false

[features]
default = ["thesaurus"]
concurrent = []
thesaurus = ["dep:harper-thesaurus"]



================================================
FILE: harper-core/clippy.toml
================================================
disallowed-types = ["std::collections::HashMap", "std::collections::HashSet"]



================================================
FILE: harper-core/irregular_nouns.json
================================================
[
	"// comments can appear in the line before an entry",
	"// or in place of an entry",
	["child", "children"],
	["foot", "feet"],
	["goose", "geese"],
	["man", "men"],
	["mouse", "mice"],
	["ox", "oxen"],
	["person", "people"],
	["seraph", "seraphim"],
	["woman", "women"],
	["addendum", "addenda"],
	["aircraft", "aircraft"],
	["aircraftman", "aircraftmen"],
	["aircraftwoman", "aircraftwomen"],
	["airman", "airmen"],
	["alderman", "aldermen"],
	["alga", "algae"],
	["alveolus", "alveoli"],
	["anchorman", "anchormen"],
	["anchorwoman", "anchorwomen"],
	["atrium", "atria"],
	["axis", "axes"],
	["bacillus", "bacilli"],
	["bacterium", "bacteria"],
	["bandsman", "bandsmen"],
	["bargeman", "bargemen"],
	["bellman", "bellmen"],
	["biceps", "biceps"],
	["boatman", "boatmen"],
	["bronchus", "bronchi"],
	["businesswoman", "businesswomen"],
	["cactus", "cacti"],
	["cameraperson", "camerapeople"],
	["candelabrum", "candelabra"],
	["catharsis", "catharses"],
	["chairman", "chairmen"],
	["chairwoman", "chairwomen"],
	["churchwoman", "churchwomen"],
	["clansman", "clansmen"],
	["clanswoman", "clanswomen"],
	["committeeman", "committeemen"],
	["committeewoman", "committeewomen"],
	["continuum", "continua"],
	["corpus", "corpora"],
	["craftsman", "craftsmen"],
	["craftswoman", "craftswomen"],
	["crisis", "crises"],
	["cyclops", "cyclopes"],
	["datum", "data"],
	["diaeresis", "diaereses"],
	["diagnosis", "diagnoses"],
	["dominatrix", "dominatrices"],
	["draughtsman", "draughtsmen"],
	["draughtswoman", "draughtswomen"],
	["effluvium", "effluvia"],
	["emphasis", "emphases"],
	["esophagus", "esophagi"],
	["extremum", "extrema"],
	["fish", "fish"],
	["footman", "footmen"],
	["formula", "formulae"],
	["forum", "fora"],
	["freeman", "freemen"],
	["frontiersman", "frontiersmen"],
	["frontierswoman", "frontierswomen"],
	["garbageman", "garbagemen"],
	["genesis", "geneses"],
	["genie", "genii"],
	["genius", "genii"],
	["genus", "genera"],
	["glissando", "glissandi"],
	["graffito", "graffiti"],
	["grandchild", "grandchildren"],
	["handyman", "handymen"],
	["hitman", "hitmen"],
	["houseman", "housemen"],
	["iceman", "icemen"],
	["ilium", "ilia"],
	["index", "indices"],
	["intermezzo", "intermezzi"],
	["journeyman", "journeymen"],
	["labium", "labia"],
	["lamina", "laminae"],
	["laundrywoman", "laundrywomen"],
	["laywoman", "laywomen"],
	["linesman", "linesmen"],
	["lira", " lire"],
	["longshoreman", "longshoremen"],
	["louse", "lice"],
	["madman", "madmen"],
	["mailman", "mailmen"],
	["memorandum", "memoranda"],
	["metathesis", "metatheses"],
	["minimum", "minima"],
	["mitosis", "mitoses"],
	["motorman", "motormen"],
	["muscleman", "musclemen"],
	["nemesis", "nemeses"],
	["nightwatchman", "nightwatchmen"],
	["oarsman", "oarsmen"],
	["oarswoman", "oarswomen"],
	["oasis", "oases"],
	["ombudsman", "ombudsmen"],
	["optimum", "optima"],
	["palazzo", "palazzi"],
	["papyrus", "papyri"],
	["parenthesis", "parentheses"],
	["patina", "patinae"],
	["patrolman", "patrolmen"],
	["pericardium", "pericardia"],
	["periphrasis", "periphrases"],
	["pharynx", "pharynges"],
	["phenomenon", "phenomena"],
	["plainclothesman", "plainclothesmen"],
	["pneumococcus", "pneumococci"],
	["pressman", "pressmen"],
	["prosthesis", "protheses"],
	["quantum", "quanta"],
	["radius", "radii"],
	["radix", "radices"],
	["repairman", "repairmen"],
	["salesman", "salesmen"],
	["saleswoman", "saleswomen"],
	["sandman", "sandmen"],
	["schema", "schemata"],
	["sheep", "sheep"],
	["shoreman", "shoremen"],
	["signore", "signori"],
	["simulacrum", "simulacra"],
	["solarium", "solaria"],
	["spokesman", "spokesmen"],
	["spokesperson", "spokespeople"],
	["spokeswoman", "spokeswomen"],
	["statesman", "statesmen"],
	["stateswoman", "stateswomen"],
	["steersman", "steersmen"],
	["stratum", "strata"],
	["streptococcus", "streptococci"],
	["succubus", "succubi"],
	["symbiosis", "symbioses"],
	["tarsus", "tarsi"],
	["taxon", "taxa"],
	["testatrix", "testatrices"],
	["testis", "testes"],
	["thesis", "theses"],
	["thrombosis", "thromboses"],
	["tooth", "teeth"],
	["townsman", "townsmen"],
	["townswoman", "townswomen"],
	["tradesman", "tradesmen"],
	["tradeswoman", "tradeswomen"],
	["uterus", "uteri"],
	["vertebra", "vertebrae"],
	["vertex", "vertices"],
	["vivarium", "vivaria"],
	["washerwoman", "washerwomen"],
	["woodlouse", "woodlice"],
	["workingwoman", "workingwomen"],
	["workman", "workmen"]
]



================================================
FILE: harper-core/irregular_verbs.json
================================================
[
	"// comments can appear in the line before an entry",
	"// or in place of an entry",
	["arise", "arose", "arisen"],
	["awake", "awoke", "awoken"],
	"// be/am/are/is -- was/were -- been",
	["bear", "bore", "born"],
	["become", "became", "become"],
	["begin", "began", "begun"],
	["bend", "bent", "bent"],
	["bet", "bet", "bet"],
	["bid", "bade", "bidden"],
	["bind", "bound", "bound"],
	["bite", "bit", "bitten"],
	["bleed", "bled", "bled"],
	["blow", "blew", "blown"],
	["break", "broke", "broken"],
	["breed", "bred", "bred"],
	["bring", "brought", "brought"],
	["build", "built", "built"],
	["burst", "burst", "burst"],
	["buy", "bought", "bought"],
	["catch", "caught", "caught"],
	["choose", "chose", "chosen"],
	["come", "came", "come"],
	["cost", "cost", "cost"],
	["cut", "cut", "cut"],
	["dive", "dove", "dove"],
	["do", "did", "done"],
	["drink", "drank", "drunk"],
	["drive", "drove", "driven"],
	["eat", "ate", "eaten"],
	["fall", "fell", "fallen"],
	["feed", "fed", "fed"],
	["feel", "felt", "felt"],
	["fight", "fought", "fought"],
	["find", "found", "found"],
	["fly", "flew", "flown"],
	["forget", "forgot", "forgotten"],
	["forgo", "forwent", "forgone"],
	["freeze", "froze", "frozen"],
	"// get -- got -- gotten",
	["get", "got", "got"],
	["give", "gave", "given"],
	["go", "went", "gone"],
	["grow", "grew", "grown"],
	["have", "had", "had"],
	["hear", "heard", "heard"],
	["hit", "hit", "hit"],
	["hold", "held", "held"],
	["hurt", "hurt", "hurt"],
	["input", "input", "input"],
	["keep", "kept", "kept"],
	["kneel", "knelt", "knelt"],
	["know", "knew", "known"],
	"// lay -- laid -- lain",
	["lay", "laid", "laid"],
	["lead", "led", "led"],
	["leave", "left", "left"],
	["lend", "lent", "lent"],
	["let", "let", "let"],
	["lie", "lay", "lain"],
	["light", "lit", "lit"],
	["lose", "lost", "lost"],
	["make", "made", "made"],
	["mean", "meant", "meant"],
	["meet", "met", "met"],
	["mistake", "mistook", "mistaken"],
	["output", "output", "output"],
	["overtake", "overtook", "overtaken"],
	["overthrow", "overthrew", "overthrown"],
	["overwrite", "overwrote", "overwritten"],
	["partake", "partook", "partaken"],
	["pay", "paid", "paid"],
	["put", "put", "put"],
	["read", "read", "read"],
	["redo", "redid", "redone"],
	["remake", "remade", "remade"],
	["reread", "reread", "reread"],
	["reset", "reset", "reset"],
	["ride", "rode", "ridden"],
	["ring", "rang", "rung"],
	["rise", "rose", "risen"],
	["run", "ran", "run"],
	["see", "saw", "seen"],
	["sell", "sold", "sold"],
	["send", "sent", "sent"],
	["set", "set", "set"],
	["shake", "shook", "shaken"],
	["shed", "shed", "shed"],
	["shine", "shone", "shone"],
	["shoe", "shod", "shod"],
	["shoot", "shot", "shot"],
	["show", "showed", "shown"],
	["shrink", "shrank", "shrunk"],
	["shut", "shut", "shut"],
	["sing", "sang", "sung"],
	"// sink -- sank -- sunken??",
	["sink", "sank", "sunk"],
	["sit", "sat", "sat"],
	["slay", "slew", "slain"],
	["sleep", "slept", "slept"],
	["slide", "slid", "slid"],
	["slit", "slit", "slit"],
	"// sneak -- sneaked/snuck -- sneaked/snuck",
	["speak", "spoke", "spoken"],
	["spend", "spent", "spent"],
	["spin", "spun", "spun"],
	["spit", "spat", "spat"],
	["split", "split", "split"],
	["spread", "spread", "spread"],
	["spring", "sprang", "sprung"],
	["stand", "stood", "stood"],
	["steal", "stole", "stolen"],
	["stick", "stuck", "stuck"],
	["sting", "stung", "stung"],
	["stink", "stank", "stunk"],
	["stride", "strode", "stridden"],
	["strike", "struck", "stricken"],
	["string", "strung", "strung"],
	["sew", "sewed", "sewn"],
	["swear", "swore", "sworn"],
	["sweep", "swept", "swept"],
	["swell", "swelled", "swollen"],
	["swim", "swam", "swum"],
	["swing", "swung", "swung"],
	["take", "took", "taken"],
	["teach", "taught", "taught"],
	["tear", "tore", "torn"],
	["think", "thought", "thought"],
	["throw", "threw", "thrown"],
	["tread", "trod", "trodden"],
	["undo", "undid", "undone"],
	["wake", "woke", "woken"],
	["wear", "wore", "worn"],
	["weave", "wove", "woven"],
	["weep", "wept", "wept"],
	"// wet -- wetted -- wetted",
	["wet", "wet", "wet"],
	["win", "won", "won"],
	["wind", "wound", "wound"],
	["write", "wrote", "written"]
]



================================================
FILE: harper-core/proper_noun_rules.json
================================================
{
	"Americas": {
		"canonical": ["South America", "North America", "Central America"],
		"description": "When referring to North, Central, and South America, make sure to treat them as a proper noun."
	},
	"Australia": {
		"canonical": [
			"Australian Capital Territory",
			"New South Wales",
			"Northern Territory",
			"South Australia",
			"Western Australia",
			"Alice Springs",
			"Gold Coast",
			"Sunshine Coast"
		],
		"description": "When referring to states, territories, and cities in Australia, make sure to treat them as a proper noun."
	},
	"OceansAndSeas": {
		"canonical": [
			"Atlantic Ocean",
			"Pacific Ocean",
			"Indian Ocean",
			"Southern Ocean",
			"Arctic Ocean",
			"Mediterranean Sea",
			"Caribbean Sea",
			"Baltic Sea",
			"Red Sea",
			"Black Sea",
			"Caspian Sea",
			"Coral Sea",
			"Bering Sea",
			"North Sea",
			"South China Sea"
		],
		"description": "When referring to the world's oceans and seas, ensure they are treated as proper nouns."
	},
	"Canada": {
		"canonical": [
			"British Columbia",
			"New Brunswick",
			"Northwest Territories",
			"Nova Scotia",
			"Prince Edward Island",
			"Quebec City"
		],
		"description": "When referring to provinces, territories, and cities in Canada, make sure to treat them as a proper noun."
	},
	"Laos": {
		"canonical": ["La Mam", "Luang Namtha", "Luang Prabang", "Xam Neua"],
		"description": "When referring to provinces and cities in Laos, make sure to treat them as a proper noun."
	},
	"Malaysia": {
		"canonical": [
			"Alor Setar",
			"George Town",
			"Johor Bahru",
			"Kota Bahru",
			"Kota Kinabalu",
			"Kuala Lumpur",
			"Kuala Terengganu",
			"Negeri Sembilan",
			"Shah Alam"
		],
		"description": "When referring to the states of Malaysia and their capitals, make sure to treat them as a proper noun."
	},
	"Countries": {
		"canonical": [
			"Equatorial Guinea",
			"Papua New Guinea",
			"Cayman Islands",
			"Falkland Islands",
			"Marshall Islands",
			"Solomon Islands",
			"British Virgin Islands",
			"United States Virgin Islands",
			"Northern Mariana Islands",
			"New Caledonia",
			"New Zealand",
			"Northern Cyprus",
			"Northern Ireland",
			"Central African Republic",
			"Czech Republic",
			"Dominican Republic",
			"Saint Helena",
			"Saint Lucia",
			"Saint Martin",
			"South Africa",
			"South Ossetia",
			"South Sudan",
			"American Samoa",
			"Antigua and Barbuda",
			"Bosnia and Herzegovina",
			"Burkina Faso",
			"Cape Verde",
			"Costa Rica",
			"Democratic Republic of the Congo",
			"East Timor",
			"El Salvador",
			"French Polynesia",
			"Guinea-Bissau",
			"Isle of Man",
			"Ivory Coast",
			"North Macedonia",
			"Puerto Rico",
			"São Tomé and Príncipe",
			"Saudi Arabia",
			"Sierra Leone",
			"Sint Maarten",
			"Sri Lanka",
			"Trinidad and Tobago",
			"Western Sahara"
		],
		"description": "When referring to Countries, make sure to treat it as a proper noun."
	},
	"NationalCapitals": {
		"canonical": [
			"Abu Dhabi",
			"Addis Ababa",
			"Andorra la Vella",
			"Bandar Seri Begawan",
			"Belize City",
			"Buenos Aires",
			"Cape Town",
			"Dar es Salaam",
			"Diego Garcia",
			"George Town",
			"Guatemala City",
			"Ho Chi Minh City",
			"Kuwait City",
			"La Paz",
			"Mexico City",
			"New Delhi",
			"Pago Pago",
			"Panama City",
			"Phnom Penh",
			"Port-au-Prince",
			"Port Louis",
			"Port Moresby",
			"Port of Spain",
			"Port Vila",
			"Porto-Novo",
			"Saint Kitts and Nevis",
			"Saint Pierre and Miquelon",
			"Saint Vincent and the Grenadines",
			"San José",
			"San Juan",
			"San Marino",
			"San Salvador",
			"Santo Domingo",
			"São Tomé",
			"The Bahamas",
			"The Hague",
			"Vatican City"
		],
		"description": "When referring to national capitals, make sure to treat it as a proper noun."
	},
	"ChineseCommunistParty": {
		"canonical": ["Chinese Communist Party"],
		"description": "When referring to the political party, make sure to treat them as a proper noun."
	},
	"UnitedOrganizations": {
		"canonical": [
			"United Nations",
			"United States",
			"United Kingdom",
			"United Airlines",
			"United Arab Emirates"
		],
		"description": "When referring to national or international organizations, make sure to treat them as a proper noun."
	},
	"Holidays": {
		"canonical": [
			"Absolution Day",
			"Admission Day",
			"Alaska Day",
			"Anzac Day",
			"Arbor Day",
			"Armistice Day",
			"Ascension Day",
			"Australia Day",
			"Bastille Day",
			"Boxing Day",
			"Canada Day",
			"Christmas Day",
			"Columbus Day",
			"Commonwealth Day",
			"Darwin Day",
			"Discovery Day",
			"Dominion Day",
			"Earth Day",
			"Easter Day",
			"Election Day",
			"Emancipation Day",
			"Empire Day",
			"Father's Day",
			"Flag Day",
			"Freedom Day",
			"Galentine's Day",
			"Groundhog Day",
			"Halloween",
			"Independence Day",
			"Jamhuri Day",
			"Jubilee Day",
			"Kamehameha Day",
			"Kenyatta Day",
			"Labor Day",
			"Labour Day",
			"Madaraka Day",
			"Mashujaa Day",
			"May Day",
			"Memorial Day",
			"Merdeka Day",
			"Mother's Day",
			"National Freedom Day",
			"New Year's Day",
			"Patrick's Day",
			"Presidents' Day",
			"Remembrance Day",
			"Republic Day",
			"Rizal Day",
			"Thanksgiving Day",
			"Ulster Day",
			"Valentine's Day",
			"Veterans Day",
			"Victoria Day",
			"Victory Day",
			"Waitangi Day",
			"Wattle Day",
			"Year's Day",
			"Youth Day",
			"Black Friday",
			"Cyber Monday"
		],
		"description": "When referring to holidays, make sure to treat them as a proper noun."
	},
	"Koreas": {
		"canonical": ["South Korea", "North Korea"],
		"description": "When referring to the nations, make sure to treat them as a proper noun."
	},
	"AmazonNames": {
		"canonical": [
			"Amazon Shopping",
			"Amazon Web Services",
			"Amazon Lambda",
			"Amazon RDS",
			"Amazon DynamoDB",
			"Amazon SageMaker",
			"Amazon Rekognition",
			"Amazon CloudFront",
			"Amazon ECS",
			"Amazon EKS",
			"Amazon CloudWatch",
			"Amazon IAM",
			"Amazon Prime",
			"Amazon Kindle"
		],
		"description": "When referring to the various products of Amazon.com, make sure to treat them as a proper noun."
	},
	"GoogleNames": {
		"canonical": [
			"Google Search",
			"Google Cloud",
			"Google Maps",
			"Google Docs",
			"Google Sheets",
			"Google Slides",
			"Google Drive",
			"Google Meet",
			"Google Gmail",
			"Google Calendar",
			"Google Chrome",
			"Google ChromeOS",
			"Google Android",
			"Google Play",
			"Google Bard",
			"Google Gemini",
			"Google YouTube",
			"Google Photos",
			"Google Analytics",
			"Google AdSense",
			"Google Pixel",
			"Google Nest",
			"Google Workspace",
			"Chrome Web Store",
			"Google Chrome Web Store"
		],
		"description": "When referring to Google products and services, make sure to treat them as proper nouns."
	},
	"AzureNames": {
		"canonical": [
			"Azure DevOps",
			"Azure Functions",
			"Azure Cosmos DB",
			"Azure SQL Database",
			"Azure Kubernetes Service",
			"Azure Virtual Machines",
			"Azure Monitor",
			"Azure Storage",
			"Azure Active Directory",
			"Azure App Service",
			"Azure Key Vault",
			"Azure Cognitive Services",
			"Azure Service Bus",
			"Azure Event Hub"
		],
		"description": "When referring to Azure cloud services, make sure to treat them as proper nouns."
	},
	"MicrosoftNames": {
		"canonical": [
			"Microsoft Bing",
			"Microsoft Dynamics",
			"Microsoft Edge",
			"Microsoft Excel",
			"Microsoft Office",
			"Microsoft OneDrive",
			"Microsoft Outlook",
			"Microsoft PowerPoint",
			"Microsoft SharePoint",
			"Microsoft Surface",
			"Microsoft Teams",
			"Microsoft Visual Studio",
			"Microsoft Windows",
			"Microsoft Word",
			"Microsoft Xbox",
			"VS Code"
		],
		"description": "When referring to Microsoft products and services, make sure to treat them as proper nouns."
	},
	"AppleNames": {
		"canonical": [
			"Apple iPhone",
			"Apple iPad",
			"Apple iMac",
			"Apple MacBook",
			"Apple Watch",
			"Apple TV",
			"Apple Music",
			"Apple Arcade",
			"Apple iCloud",
			"Apple Safari",
			"Apple HomeKit",
			"Apple CarPlay",
			"Apple MacBook Pro",
			"Apple MacBook Air",
			"Apple Mac Pro",
			"Apple Mac Mini",
			"Apple AirPods",
			"Apple AirPods Pro",
			"Apple AirPods Max",
			"Apple Vision Pro"
		],
		"description": "When referring to Apple products and services, make sure to treat them as proper nouns."
	},
	"MetaNames": {
		"canonical": [
			"Meta Oculus",
			"Meta Portals",
			"Meta Quest",
			"Meta Gaming",
			"Meta Horizon",
			"Meta Reality Labs"
		],
		"description": "When referring to Meta products and services, make sure to treat them as proper nouns."
	},
	"JetpackNames": {
		"canonical": [
			"Jetpack VaultPress Backup",
			"Jetpack VaultPress",
			"Jetpack Scan",
			"Jetpack Akismet Anti-spam",
			"Jetpack Stats",
			"Jetpack Social",
			"Jetpack Blaze",
			"Jetpack AI Assistant",
			"Jetpack Site Search",
			"Jetpack Boost",
			"Jetpack VideoPress",
			"Jetpack For Agencies",
			"Jetpack CRM"
		],
		"description": "Ensure proper capitalization of Jetpack-related terms."
	},
	"TumblrNames": {
		"canonical": [
			"Tumblr Blaze",
			"Tumblr Pro",
			"Tumblr Live",
			"Tumblr Ads",
			"Tumblr Communities",
			"Tumblr Shop",
			"Tumblr Dashboard"
		],
		"description": "Ensure proper capitalization of Tumblr-related terms."
	},
	"PocketCastsNames": {
		"canonical": ["Pocket Casts", "Pocket Casts Plus"],
		"description": "Ensure proper capitalization of Pocket Casts and Pocket Casts Plus as brand names."
	},
	"DayOneNames": {
		"canonical": ["Day One", "Day One Premium"],
		"description": "Ensure proper capitalization of Day One and Day One Premium as brand names."
	},
	"USUniversities": {
		"canonical": [
			"Harvard University",
			"Stanford University",
			"Massachusetts Institute of Technology",
			"California Institute of Technology",
			"Princeton University",
			"Yale University",
			"Columbia University",
			"University of Chicago",
			"University of Pennsylvania",
			"Johns Hopkins University",
			"Duke University",
			"Northwestern University",
			"University of California",
			"University of Michigan",
			"University of Virginia",
			"University of North Carolina",
			"University of Wisconsin",
			"University of Texas",
			"University of Florida",
			"University of Washington",
			"University of Southern California",
			"New York University",
			"Cornell University",
			"Brown University",
			"Dartmouth College",
			"Carnegie Mellon University",
			"Georgetown University",
			"Rice University",
			"Vanderbilt University",
			"Washington University",
			"Emory University",
			"University of Notre Dame",
			"Boston University",
			"Boston College",
			"University of Miami",
			"University of Illinois",
			"Ohio State University",
			"Pennsylvania State University",
			"Purdue University",
			"Texas A&M University",
			"Georgia Institute of Technology",
			"University of Minnesota",
			"Michigan State University",
			"Indiana University",
			"University of Colorado",
			"University of Arizona",
			"University of Pittsburgh",
			"University of Maryland",
			"Rutgers University",
			"University of Rochester",
			"University of Connecticut",
			"University of Georgia",
			"University of Iowa",
			"University of Kansas",
			"University of Kentucky",
			"University of Missouri",
			"University of Nebraska",
			"University of Tennessee",
			"University of Utah",
			"University of Oklahoma",
			"University of Oregon",
			"University of South Carolina",
			"University of Alabama",
			"University of Central Florida",
			"University of Houston",
			"University of Delaware",
			"University of Mississippi",
			"University of Arkansas",
			"Florida State University",
			"Arizona State University",
			"Colorado State University",
			"North Carolina State University",
			"Iowa State University",
			"Kansas State University",
			"Louisiana State University",
			"Oregon State University",
			"South Carolina State University",
			"Virginia Tech",
			"Auburn University",
			"Temple University",
			"University of Massachusetts",
			"Baylor University",
			"Southern Methodist University",
			"Wake Forest University",
			"George Washington University",
			"American University",
			"Villanova University",
			"Marquette University",
			"Pepperdine University",
			"Loyola Marymount University",
			"Santa Clara University",
			"Fordham University",
			"DePaul University",
			"Syracuse University",
			"Rensselaer Polytechnic Institute",
			"Stevens Institute of Technology",
			"Illinois Institute of Technology",
			"Clark University",
			"Tufts University",
			"Brandeis University",
			"Case Western Reserve University",
			"Drexel University",
			"Lehigh University",
			"Howard University",
			"Spelman College",
			"Morehouse College",
			"Hampton University",
			"Xavier University of Louisiana",
			"Tuskegee University",
			"Florida A&M University",
			"Colorado School of Mines"
		],
		"description": "Ensure proper capitalization of major universities in the United States."
	},
	"NotablePlaces": {
		"canonical": [
			"Big Sur",
			"Bretton Woods",
			"Coney Island",
			"Darien Gap",
			"Des Moines",
			"El Paso",
			"Hong Kong",
			"Las Palmas",
			"Las Vegas",
			"Los Angeles",
			"New York",
			"New York City",
			"Niagara Falls",
			"Novi Sad",
			"Panama Canal",
			"Rio de Janeiro",
			"San Francisco"
		],
		"description": "Ensure proper capitalization of notable places that are significant regional centers, travel destinations, or have international importance."
	},
	"ProperNouns": {
		"canonical": ["Bhagavad Gita", "Gilded Age", "Pax Americana"],
		"description": "Ensure proper capitalization of proper nouns."
	},
	"CompaniesProductsAndTrademarks": {
		"canonical": ["Stack Exchange", "Stack Overflow"],
		"description": "Ensure proper capitalization of companies, products, and trademarks."
	}
}



================================================
FILE: harper-core/benches/essay.md
================================================
The question of why we do anything at all is one of those profound, irritatingly unanswerable riddles that philosophers and late-night overthinkers have wrestled with for centuries. If we take a purely biological perspective, we do things to survive, to propagate the species, to eat, drink, and stave off the cold. But that answer is profoundly unsatisfying because it ignores the sheer peculiarity of human behavior. Why do we build cathedrals, write novels, or argue endlessly on the internet about whether a hot dog is a sandwich? What compels someone to paint a canvas or compose a symphony when neither is necessary for survival? 

The siplest answer is that we are creatures of pattern and meaning, constantly searching for order in chaos. Take language, for instance—our ceaseless need to name, categorize, and label everything around us, as if pinning a word to an object somehow grants us mastery over it. This extends even to the grammar of our thoughts. The way we construct sentences, form arguments, and recognize the structure of a well-crafted joke reveals something fundamental about our cognition. A joke, after all, is just a bait-and-switch for the brain, an elegant dance of expectations and subversions. Similarly, the way we tell stories, build relationships, and pass on knowledge relies on our ability to perceive and manipulate patterns, making communication a fundamental pillar of human experience.

But where des that leave us in the grander scheme of things? Humans have an insatiable need to create, even in the face of an indifferent universe. The pyramids were built by civilizations that no longer exist, their original intentions obscured by the shifting sands of history. And yet, there they stand, testaments to some long-forgotten ambition. We are driven to leave something behind, whether it be a physical monument, a digital footprint, or simply a story whispered from one generation to the next. Even now, we etch our thoughts into the collective consciousness of humanity through books, blogs, tweets, and videos, trying to make some mark that will outlive us, even if just for a moment.

Speaking of stories, fiction is perhaps the most peculiar human invention of all. Other animals communicate, solve problems, even display emotions—but they do not tell each other elaborate lies for entertainment. Fiction allows us to live infinite lives, to explore the what-ifs of existence without ever leaving our chair. And yet, fiction is paradoxically one of the best ways to understand reality. If you want to grasp the true horrors of war, a history book will tell you the facts, but a novel will make you feel them. Our brains, those ancient, pattern-seeking machines, respond more to narratives than to raw data. This is why memoirs and personal accounts carry such emotional weight, why a well-told anecdote can shape political movements, and why some of the most effective leaders in history were, above all, masterful storytellers.

This is why histry, for all its pretense of objectivity, is really just a collection of competing narratives. Every empire, every ideology, every revolution is shaped by the stories people choose to tell about them. A civilization may fall not because of military defeat but because its foundational myth loses its grip on the collective imagination. Think about the fall of Rome—not a singular event but a slow unraveling, a loss of confidence in the structures that once held everything together. Perhaps all civilizations eventually reach this point, where the grand story that justified their existence is no longer compelling enough to sustain them. Perhaps the same is true for individuals as well, where personal reinvention is not merely an option but an inevitability.

But then again, collapse is just another word for transformation. New stories take root in the ashes of the old. The medieval world gave way to the Renaissance because someone, somewhere, decided that maybe the past was worth revisiting. This is how ideas work: they lie dormant until the right moment, waiting for someone to rediscover them. You see this in science, in philosophy, in technology. The invention of the printing press wasn’t just a mechanical breakthrough—it was a revolution in the way ideas could spread, a prototype for the internet centuries before its time. The cyclical nature of innovation means that old ideas often become new again, reinterpreted through different lenses as human society evolves.

And the internet, of couse, is its own beast entirely. A swirling, chaotic cauldron of human thought, filled with brilliance and stupidity in equal measure. We are more connected than ever before, and yet lonelier than ever, drowning in a sea of information without a clear way to separate signal from noise. What does it mean to be truly informed in an era where every piece of knowledge is instantly available but where misinformation spreads just as quickly? The ancient Greeks worried about the written word weakening our memory; what would they think of a world where no one remembers anything because Google is always a click away? What would they make of a world where artificial intelligence now plays a role in shaping narratives, in predicting trends, in subtly altering the way we perceive reality itself?

Perhaps the next great hman challenge is not discovering new information but learning how to curate it—how to distinguish the meaningful from the meaningless. The ability to think critically, to recognize bias, to resist the lure of easy, comfortable falsehoods—these may become the most valuable skills of the future. But even as we wrestle with these challenges, we will still find time to argue about trivial things. Are video games art? Is pineapple on pizza a culinary abomination or a stroke of genius? These questions, absurd as they may seem, are part of what makes us human. We care about things that don’t matter because, in a way, they do matter. They give us something to latch onto, something to discuss, something to shape the narrative of our lives around. These seemingly frivolous debates become markers of cultural identity, of generational shifts, of the ever-changing nature of taste and perception.

And so, we continue. Building, arguing, dreaming, and storytelling. Not because we have to, but because, for some reason, we can’t seem to stop. And maybe that’s the most human thing of all. Maybe the true mark of being human is not merely the ability to think, but the compulsion to share those thoughts with others, to seek meaning in the vast expanse of uncertainty, to create narratives that outlive us, if only for a fleeting moment in time.

The nature of progress is one of the most fascinating and contentious debates in human history. Is progress an inevitable force, a gradual accumulation of knowledge and refinement of ideas, or is it a chaotic series of fits and starts, a process governed as much by accident and serendipity as by deliberate effort? The answer, as with most things, is probably boh.

Consider the way technological advancements unfold. The wheel, fire, writing, the printing press, the steam engine, electricity, the internet—these milestones are often presented as stepping stones on a linear path toward a more advanced civilization. And yet, history is littered with examples of knowledge lost, rediscovered, or arriving before its time. The Antikythera Mechanism, a sophisticated analog computer from ancient Greece, was forgotten for centuries before we had machines of similar complexity. The steam engine existed in rudimentary form in Hellenistic Alexandria, but it would take over a thousand years for the Industrial Revolution to harness its true potential.

This pattern of innovation, stagnation, and rediscovery suggests that human progress is not a smooth arc but a jagged line. Ideas often arrive before society is ready for them, only to be shelved until conditions align for their widespread adoption. The internet, for example, could have theoretically existed decades earlier had the right economic and political structures been in place. Similarly, artificial intelligence was theorized long before computational power made it feasible.

But what drives progress? Some argue that necessity is the mother of invention, that crises and hardships push humanity to innovate. War, for instance, has been a catalyst for numerous technological breakthroughs, from radar to nclear energy to modern computing. Others argue that curiosity and creativity, independent of immediate needs, are the true engines of discovery. The Renaissance was not born out of desperation but out of an insatiable hunger for knowledge and artistic expression.

Economic structures also play a crucial role. Capitalism, with its relentless drive for efficiency and profit, has undoubtedly accelerated technological progress. But it has also created perverse incentives—planned obsolescence, environmental degradation, and the prioritization of profit over long-term sustainability. Would a different system, one not beholden to market forces, produce a different kind of progress? Could we achieve breakthroughs in medicine, energy, or space travel faster if research were not so often dictated by financial viability?

Culture, too, influences how progress unfolds. Some societies embrace innovation and risk, while others are more conservative, preferring stability over disruption. The spread of ideas often depends on networks of communication and openness to external influences. China, for example, was the world's most advanced civilization for centuries, yet political isolation slowed its technological dominance. Conversely, Europe's patchwork of competing states fostered a dynamic intellectual environment where ideas could cross borders, merge, and evolve.

There is also the question of unintended consequences. Every major technological leap comes with unforeseen effects. The printing press democratized knowledge but also spread misinformation and propaganda. The industrial revolution improved living standards but also led to mass pollution and worker exploitation. The internet has connected billions but has also given rise to surveillance, misinformation, and algorithmic manipulation. Are we progressing toward a better world, or are we merely exchanging one set of problems for another?

Looking to the future, the acceleration of artificial intelligence, biotechnology, and space eploration presents us with ethical and existential dilemmas unlike any faced before. Will AI surpass human intelligence in a way that is beneficial or catastrophic? Will genetic modification lead to the eradication of disease or the rise of designer babies and genetic inequality? Will humanity colonize space, or will we become trapped in the gravity of our own short-term thinking?

Ultimately, progress is a double-edged sword. It is neither inherently good nor bad, but it is relentless. We push forward because we can, because curiosity compels us, because the alternative—stagnation—is untenable. The challenge is not merely to advance but to do so wisely, ensuring that our creations serve us rather than enslave us. In that sense, progress is not just about technology, but about wisdom—the wisdom to recognize the costs, to weigh the trade-offs, and to steer our collective trajectory toward a future that is not just more advanced, but more humane.




================================================
FILE: harper-core/benches/parse_essay.rs
================================================
use criterion::{Criterion, criterion_group, criterion_main};
use harper_core::linting::{LintGroup, Linter};
use harper_core::spell::FstDictionary;
use harper_core::{Dialect, Document};
use std::hint::black_box;

static ESSAY: &str = include_str!("./essay.md");

fn parse_essay(c: &mut Criterion) {
    c.bench_function("parse_essay", |b| {
        b.iter(|| Document::new_markdown_default_curated(black_box(ESSAY)));
    });
}

fn lint_essay(c: &mut Criterion) {
    let dictionary = FstDictionary::curated();
    let mut lint_set = LintGroup::new_curated(dictionary, Dialect::American);
    let document = Document::new_markdown_default_curated(black_box(ESSAY));

    c.bench_function("lint_essay", |b| {
        b.iter(|| lint_set.lint(&document));
    });
}

fn lint_essay_uncached(c: &mut Criterion) {
    c.bench_function("lint_essay_uncached", |b| {
        b.iter(|| {
            let dictionary = FstDictionary::curated();
            let mut lint_set = LintGroup::new_curated(dictionary.clone(), Dialect::American);
            let document = Document::new_markdown_default(black_box(ESSAY), &dictionary);
            lint_set.lint(&document)
        })
    });
}

pub fn criterion_benchmark(c: &mut Criterion) {
    parse_essay(c);
    lint_essay(c);
    lint_essay_uncached(c);
}

criterion_group!(benches, criterion_benchmark);
criterion_main!(benches);



================================================
FILE: harper-core/src/case.rs
================================================
use std::borrow::Borrow;

use smallvec::SmallVec;

use crate::{CharString, char_string::CHAR_STRING_INLINE_SIZE};

/// Apply the casing of `template` to `target`.
///
/// If `template` is shorter than `target`, the casing of the last character of `template` will be reused for
/// the rest of the string.
///
/// If `template` is empty, all characters will be lowercased.
#[must_use]
pub fn copy_casing(
    template: impl IntoIterator<Item = impl Borrow<char>>,
    target: impl IntoIterator<Item = impl Borrow<char>>,
) -> CharString {
    target
        .into_iter()
        .scan(
            (template.into_iter().get_casing(), Case::Lower),
            |(template, prev_case), c| {
                // Skip non-alphabetic characters in `target` without advancing `template`.
                if c.borrow().is_alphabetic()
                    && let Some(template_case) = template.next()
                {
                    *prev_case = template_case;
                };
                Some(prev_case.apply_to(*c.borrow()))
            },
        )
        .flatten()
        .collect()
}

/// Represents the casing of a character.
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum Case {
    Upper,
    Lower,
}

impl Case {
    /// Apply the casing to a provided character.
    ///
    /// This essentially calls [`char::to_uppercase()`] or [`char::to_lowercase()`] depending on
    /// the state of `self`. Similarly to those functions, it returns an iterator of the resulting
    /// character(s).
    pub fn apply_to(&self, char: char) -> impl Iterator<Item = char> + use<> {
        match self {
            Self::Upper => char.to_uppercase().collect::<SmallVec<[char; 2]>>(),
            Self::Lower => char.to_lowercase().collect::<SmallVec<[char; 2]>>(),
        }
        .into_iter()
    }
}

impl TryFrom<char> for Case {
    type Error = ();

    /// Try to get the casing from the given character.
    ///
    /// This fails if the character is neither uppercase nor lowercase.
    fn try_from(value: char) -> Result<Self, Self::Error> {
        if value.is_uppercase() {
            Ok(Self::Upper)
        } else if value.is_lowercase() {
            Ok(Self::Lower)
        } else {
            Err(())
        }
    }
}

// TODO: maybe move this functionality to CharStringExt if and when CharStringExt can be
// generalized to work with char iterators.
pub trait CaseIterExt {
    fn get_casing(self) -> impl Iterator<Item = Case>;
    fn get_casing_unfiltered(self) -> SmallVec<[Option<Case>; CHAR_STRING_INLINE_SIZE]>;
}
impl<I: IntoIterator<Item = T>, T: Borrow<char>> CaseIterExt for I {
    /// Get an iterator of [`Case`] from a collection of characters. Note that this will not
    /// include cases for characters that are neither uppercase nor lowercase.
    fn get_casing(self) -> impl Iterator<Item = Case> {
        self.into_iter()
            .filter_map(|char| (*char.borrow()).try_into().ok())
    }

    /// Get casing for the provided string. Unlike [`Self::get_casing`], the output will always
    /// be the same length as the input string. If a character is neither uppercase nor lowercase,
    /// its corresponding case will be `None`.
    fn get_casing_unfiltered(self) -> SmallVec<[Option<Case>; CHAR_STRING_INLINE_SIZE]> {
        self.into_iter()
            .map(|c| Case::try_from(*c.borrow()).ok())
            .collect()
    }
}



================================================
FILE: harper-core/src/char_ext.rs
================================================
use unicode_script::{Script, UnicodeScript};
use unicode_width::UnicodeWidthChar;

use crate::Punctuation;

mod private {
    pub trait Sealed {}

    impl Sealed for char {}
}

pub trait CharExt: private::Sealed {
    fn is_cjk(&self) -> bool;
    /// Whether a character can be a component of an English word.
    fn is_english_lingual(&self) -> bool;
    fn is_emoji(&self) -> bool;
    fn is_punctuation(&self) -> bool;
    /// Whether the character is an (English) vowel.
    ///
    /// Checks whether the character is in the set (A, E, I, O, U); case-insensitive.
    fn is_vowel(&self) -> bool;
    fn normalized(&self) -> Self;
}

impl CharExt for char {
    fn is_english_lingual(&self) -> bool {
        !self.is_whitespace()
            && !self.is_numeric()
            && !self.is_emoji()
            && matches!(self.width(), Some(1..))
            && !self.is_punctuation()
            && self.is_alphabetic()
            && !self.is_cjk()
            && self.script() == Script::Latin
    }

    fn normalized(&self) -> Self {
        match self {
            '\u{2018}' | '\u{2019}' | '\u{02BC}' | '\u{FF07}' => '\'',
            '\u{201C}' | '\u{201D}' | '\u{FF02}' => '"',
            '\u{2013}' | '\u{2014}' | '\u{2212}' | '\u{FF0D}' => '-',
            _ => *self,
        }
    }

    fn is_emoji(&self) -> bool {
        let Some(block) = unicode_blocks::find_unicode_block(*self) else {
            return false;
        };

        let blocks = [
            unicode_blocks::SPECIALS,
            unicode_blocks::EMOTICONS,
            unicode_blocks::MISCELLANEOUS_SYMBOLS,
            unicode_blocks::VARIATION_SELECTORS,
            unicode_blocks::SUPPLEMENTAL_SYMBOLS_AND_PICTOGRAPHS,
        ];

        blocks.contains(&block)
    }

    fn is_cjk(&self) -> bool {
        let Some(block) = unicode_blocks::find_unicode_block(*self) else {
            return false;
        };

        let blocks = [
            unicode_blocks::CJK_UNIFIED_IDEOGRAPHS,
            unicode_blocks::CJK_UNIFIED_IDEOGRAPHS_EXTENSION_A,
            unicode_blocks::CJK_UNIFIED_IDEOGRAPHS_EXTENSION_B,
            unicode_blocks::CJK_UNIFIED_IDEOGRAPHS_EXTENSION_C,
            unicode_blocks::CJK_UNIFIED_IDEOGRAPHS_EXTENSION_D,
            unicode_blocks::CJK_UNIFIED_IDEOGRAPHS_EXTENSION_E,
            unicode_blocks::CJK_UNIFIED_IDEOGRAPHS_EXTENSION_F,
            unicode_blocks::CJK_UNIFIED_IDEOGRAPHS_EXTENSION_G,
            unicode_blocks::CJK_UNIFIED_IDEOGRAPHS_EXTENSION_H,
            unicode_blocks::CJK_UNIFIED_IDEOGRAPHS_EXTENSION_I,
            unicode_blocks::HANGUL_JAMO,
            unicode_blocks::HANGUL_SYLLABLES,
            unicode_blocks::HANGUL_JAMO_EXTENDED_A,
            unicode_blocks::HANGUL_JAMO_EXTENDED_B,
            unicode_blocks::HANGUL_COMPATIBILITY_JAMO,
            unicode_blocks::CJK_SYMBOLS_AND_PUNCTUATION,
            unicode_blocks::CJK_STROKES,
            unicode_blocks::CJK_COMPATIBILITY,
            unicode_blocks::CJK_COMPATIBILITY_FORMS,
            unicode_blocks::CJK_COMPATIBILITY_IDEOGRAPHS,
            unicode_blocks::CJK_COMPATIBILITY_IDEOGRAPHS_SUPPLEMENT,
            unicode_blocks::CJK_RADICALS_SUPPLEMENT,
            unicode_blocks::ENCLOSED_CJK_LETTERS_AND_MONTHS,
            unicode_blocks::HIRAGANA,
        ];

        blocks.contains(&block)
    }

    fn is_punctuation(&self) -> bool {
        Punctuation::from_char(*self).is_some()
    }

    fn is_vowel(&self) -> bool {
        matches!(self.to_ascii_lowercase(), 'a' | 'e' | 'i' | 'o' | 'u')
    }
}

#[cfg(test)]
mod tests {
    use super::CharExt;

    #[test]
    fn cjk_is_not_english_lingual() {
        assert!(!'世'.is_english_lingual())
    }
}



================================================
FILE: harper-core/src/char_string.rs
================================================
use crate::char_ext::CharExt;
use std::borrow::Cow;

use smallvec::SmallVec;

// TODO: remove this when `SmallVec` allows retrieving this value in a const context.
pub(crate) const CHAR_STRING_INLINE_SIZE: usize = 16;

/// A char sequence that improves cache locality.
/// Most English words are fewer than 12 characters.
pub type CharString = SmallVec<[char; CHAR_STRING_INLINE_SIZE]>;

mod private {
    pub trait Sealed {}

    impl Sealed for [char] {}
}

/// Extensions to character sequences that make them easier to wrangle.
pub trait CharStringExt: private::Sealed {
    /// Convert all characters to lowercase, returning a new owned vector if any changes were made.
    fn to_lower(&'_ self) -> Cow<'_, [char]>;

    /// Normalize the character sequence according to the dictionary's standard character set.
    fn normalized(&'_ self) -> Cow<'_, [char]>;

    /// Convert the character sequence to a String.
    fn to_string(&self) -> String;

    /// Case-insensitive comparison with a character slice, assuming the right-hand side is lowercase ASCII.
    /// Only normalizes the left side to lowercase and avoids allocations.
    fn eq_ignore_ascii_case_chars(&self, other: &[char]) -> bool;

    /// Case-insensitive comparison with a string slice, assuming the right-hand side is lowercase ASCII.
    /// Only normalizes the left side to lowercase and avoids allocations.
    fn eq_ignore_ascii_case_str(&self, other: &str) -> bool;

    /// Case-insensitive comparison with any of a list of string slices, assuming the right-hand side is lowercase ASCII.
    /// Only normalizes the left side to lowercase and avoids allocations.
    fn eq_any_ignore_ascii_case_str(&self, others: &[&str]) -> bool;

    /// Case-insensitive comparison with any of a list of character slices, assuming the right-hand side is lowercase ASCII.
    /// Only normalizes the left side to lowercase and avoids allocations.
    fn eq_any_ignore_ascii_case_chars(&self, others: &[&[char]]) -> bool;

    /// Case-insensitive check if the string starts with the given ASCII prefix.
    /// The prefix is assumed to be lowercase.
    fn starts_with_ignore_ascii_case_str(&self, prefix: &str) -> bool;

    /// Case-insensitive check if the string starts with any of the given ASCII prefixes.
    /// The prefixes are assumed to be lowercase.
    fn starts_with_any_ignore_ascii_case_str(&self, prefixes: &[&str]) -> bool;

    /// Case-insensitive check if the string ends with the given ASCII suffix.
    /// The suffix is assumed to be lowercase.
    fn ends_with_ignore_ascii_case_chars(&self, suffix: &[char]) -> bool;

    /// Case-insensitive check if the string ends with the given ASCII suffix.
    /// The suffix is assumed to be lowercase.
    fn ends_with_ignore_ascii_case_str(&self, suffix: &str) -> bool;

    /// Case-insensitive check if the string ends with any of the given ASCII suffixes.
    /// The suffixes are assumed to be lowercase.
    fn ends_with_any_ignore_ascii_case_chars(&self, suffixes: &[&[char]]) -> bool;

    /// Check if the string contains any vowels
    fn contains_vowel(&self) -> bool;
}

impl CharStringExt for [char] {
    fn to_lower(&'_ self) -> Cow<'_, [char]> {
        if self.iter().all(|c| c.is_lowercase()) {
            return Cow::Borrowed(self);
        }

        let mut out = CharString::with_capacity(self.len());

        out.extend(self.iter().flat_map(|v| v.to_lowercase()));

        Cow::Owned(out.to_vec())
    }

    fn to_string(&self) -> String {
        self.iter().collect()
    }

    /// Convert a given character sequence to the standard character set
    /// the dictionary is in.
    fn normalized(&'_ self) -> Cow<'_, [char]> {
        if self.as_ref().iter().any(|c| c.normalized() != *c) {
            Cow::Owned(
                self.as_ref()
                    .iter()
                    .copied()
                    .map(|c| c.normalized())
                    .collect(),
            )
        } else {
            Cow::Borrowed(self)
        }
    }

    fn eq_ignore_ascii_case_str(&self, other: &str) -> bool {
        let mut chit = self.iter();
        let mut strit = other.chars();

        loop {
            let (c, s) = (chit.next(), strit.next());
            match (c, s) {
                (Some(c), Some(s)) => {
                    if c.to_ascii_lowercase() != s {
                        return false;
                    }
                }
                (None, None) => return true,
                _ => return false,
            }
        }
    }

    fn eq_ignore_ascii_case_chars(&self, other: &[char]) -> bool {
        self.len() == other.len()
            && self
                .iter()
                .zip(other.iter())
                .all(|(a, b)| a.to_ascii_lowercase() == *b)
    }

    fn eq_any_ignore_ascii_case_str(&self, others: &[&str]) -> bool {
        others.iter().any(|str| self.eq_ignore_ascii_case_str(str))
    }

    fn eq_any_ignore_ascii_case_chars(&self, others: &[&[char]]) -> bool {
        others
            .iter()
            .any(|chars| self.eq_ignore_ascii_case_chars(chars))
    }

    fn starts_with_ignore_ascii_case_str(&self, prefix: &str) -> bool {
        let prefix_len = prefix.chars().count();
        if self.len() < prefix_len {
            return false;
        }
        self.iter()
            .take(prefix_len)
            .zip(prefix.chars())
            .all(|(a, b)| a.to_ascii_lowercase() == b)
    }

    fn starts_with_any_ignore_ascii_case_str(&self, prefixes: &[&str]) -> bool {
        prefixes
            .iter()
            .any(|prefix| self.starts_with_ignore_ascii_case_str(prefix))
    }

    fn ends_with_ignore_ascii_case_str(&self, suffix: &str) -> bool {
        let suffix_len = suffix.chars().count();
        if self.len() < suffix_len {
            return false;
        }
        self.iter()
            .rev()
            .take(suffix_len)
            .rev()
            .zip(suffix.chars())
            .all(|(a, b)| a.to_ascii_lowercase() == b)
    }

    fn ends_with_ignore_ascii_case_chars(&self, suffix: &[char]) -> bool {
        let suffix_len = suffix.len();
        if self.len() < suffix_len {
            return false;
        }
        self.iter()
            .rev()
            .take(suffix_len)
            .rev()
            .zip(suffix.iter())
            .all(|(a, b)| a.to_ascii_lowercase() == *b)
    }

    fn ends_with_any_ignore_ascii_case_chars(&self, suffixes: &[&[char]]) -> bool {
        suffixes
            .iter()
            .any(|suffix| self.ends_with_ignore_ascii_case_chars(suffix))
    }

    fn contains_vowel(&self) -> bool {
        self.iter().any(|c| c.is_vowel())
    }
}

macro_rules! char_string {
    ($string:literal) => {{
        use crate::char_string::CharString;

        $string.chars().collect::<CharString>()
    }};
}

pub(crate) use char_string;

#[cfg(test)]
mod tests {
    use super::CharStringExt;

    #[test]
    fn eq_ignore_ascii_case_chars_matches_lowercase() {
        assert!(['H', 'e', 'l', 'l', 'o'].eq_ignore_ascii_case_chars(&['h', 'e', 'l', 'l', 'o']));
    }

    #[test]
    fn eq_ignore_ascii_case_chars_does_not_match_different_word() {
        assert!(!['H', 'e', 'l', 'l', 'o'].eq_ignore_ascii_case_chars(&['w', 'o', 'r', 'l', 'd']));
    }

    #[test]
    fn eq_ignore_ascii_case_str_matches_lowercase() {
        assert!(['H', 'e', 'l', 'l', 'o'].eq_ignore_ascii_case_str("hello"));
    }

    #[test]
    fn eq_ignore_ascii_case_str_does_not_match_different_word() {
        assert!(!['H', 'e', 'l', 'l', 'o'].eq_ignore_ascii_case_str("world"));
    }

    #[test]
    fn ends_with_ignore_ascii_case_chars_matches_suffix() {
        assert!(['H', 'e', 'l', 'l', 'o'].ends_with_ignore_ascii_case_chars(&['l', 'o']));
    }

    #[test]
    fn ends_with_ignore_ascii_case_chars_does_not_match_different_suffix() {
        assert!(
            !['H', 'e', 'l', 'l', 'o']
                .ends_with_ignore_ascii_case_chars(&['w', 'o', 'r', 'l', 'd'])
        );
    }

    #[test]
    fn ends_with_ignore_ascii_case_str_matches_suffix() {
        assert!(['H', 'e', 'l', 'l', 'o'].ends_with_ignore_ascii_case_str("lo"));
    }

    #[test]
    fn ends_with_ignore_ascii_case_str_does_not_match_different_suffix() {
        assert!(!['H', 'e', 'l', 'l', 'o'].ends_with_ignore_ascii_case_str("world"));
    }

    #[test]
    fn differs_only_by_length_1() {
        assert!(!['b', 'b'].eq_ignore_ascii_case_str("b"));
    }

    #[test]
    fn differs_only_by_length_2() {
        assert!(!['c'].eq_ignore_ascii_case_str("cc"));
    }
}



================================================
FILE: harper-core/src/currency.rs
================================================
use is_macro::Is;
use serde::{Deserialize, Serialize};

use crate::Number;

/// A national or international currency
#[derive(Debug, Is, Clone, Copy, Serialize, Deserialize, PartialEq, Eq, PartialOrd, Hash)]
pub enum Currency {
    // $
    Dollar,
    // ¢
    Cent,
    // €
    Euro,
    // ₽
    Ruble,
    // ₺
    Lira,
    // £
    Pound,
    // ¥
    Yen,
    // ฿
    Baht,
    // ₩
    Won,
    // ₭,
    Kip,
    // ₹
    Rupee,
}

impl Currency {
    pub fn from_char(c: char) -> Option<Self> {
        let cur = match c {
            '$' => Self::Dollar,
            '¢' => Self::Cent,
            '€' => Self::Euro,
            '₽' => Self::Ruble,
            '₺' => Self::Lira,
            '£' => Self::Pound,
            '¥' => Self::Yen,
            '฿' => Self::Baht,
            '₩' => Self::Won,
            '₭' => Self::Kip,
            '₹' => Self::Rupee,
            _ => return None,
        };

        Some(cur)
    }

    pub fn to_char(&self) -> char {
        match self {
            Self::Dollar => '$',
            Self::Cent => '¢',
            Self::Euro => '€',
            Self::Ruble => '₽',
            Self::Lira => '₺',
            Self::Pound => '£',
            Self::Yen => '¥',
            Self::Baht => '฿',
            Self::Won => '₩',
            Self::Kip => '₭',
            Self::Rupee => '₹',
        }
    }

    /// Format an amount of the specific currency.
    pub fn format_amount(&self, amount: &Number) -> String {
        let c = self.to_char();

        let amount = amount.to_string();

        match self {
            Currency::Dollar => format!("{c}{amount}"),
            Currency::Cent => format!("{amount}{c}"),
            Currency::Euro => format!("{c}{amount}"),
            Currency::Ruble => format!("{amount} {c}"),
            Currency::Lira => format!("{amount} {c}"),
            Currency::Pound => format!("{c}{amount}"),
            Currency::Yen => format!("{c} {amount}"),
            Currency::Baht => format!("{amount} {c}"),
            Currency::Won => format!("{c} {amount}"),
            Currency::Kip => format!("{c}{amount}"),
            Currency::Rupee => format!("{c}{amount}"),
        }
    }
}



================================================
FILE: harper-core/src/dict_word_metadata_orthography.rs
================================================
use crate::CharStringExt;
use crate::char_ext::CharExt;
use serde::{Deserialize, Serialize};

/// Orthography information.
pub enum Orthography {
    /// Every char that is a letter is lowercase.
    Lowercase = 1 << 0,
    /// First char is uppercase, the rest is lowercase (but multi-word?)
    Titlecase = 1 << 1,
    /// Every char that is a letter is uppercase (including single-letter uppercase)
    AllCaps = 1 << 2,
    /// Starts with a lowercase letter but also contains uppercase letters.
    LowerCamel = 1 << 3,
    /// Starts with an uppercase letter but also contains lowercase letters. (Superset of Titlecase.)
    UpperCamel = 1 << 4,
    /// Contains at least one space.
    Multiword = 1 << 5,
    /// Contains at least one hyphen.
    Hyphenated = 1 << 6,
    /// Contains an apostrophe, so it's a possessive or a contraction.
    Apostrophe = 1 << 7,
    /// Could be Roman numerals.
    RomanNumerals = 1 << 8,
}

/// The underlying type used for OrthographyFlags.
/// At the time of writing, this is currently a `u8`. If we want to define more than 8 orthographic
/// properties in the future, we will need to switch this to a larger type.
type OrthographyFlagsUnderlyingType = u16;

bitflags::bitflags! {
    /// A collection of bit flags used to represent orthographic properties of a word.
    ///
    /// This is generally used to allow a word (or similar) to be tagged with multiple orthographic
    /// properties.
    #[derive(Clone, Copy, Debug, Deserialize, Eq, Hash, PartialEq, PartialOrd, Serialize)]
    pub struct OrthFlags: OrthographyFlagsUnderlyingType {
        const LOWERCASE = Orthography::Lowercase as OrthographyFlagsUnderlyingType;
        const TITLECASE = Orthography::Titlecase as OrthographyFlagsUnderlyingType;
        const ALLCAPS = Orthography::AllCaps as OrthographyFlagsUnderlyingType;
        const LOWER_CAMEL = Orthography::LowerCamel as OrthographyFlagsUnderlyingType;
        const UPPER_CAMEL = Orthography::UpperCamel as OrthographyFlagsUnderlyingType;
        const MULTIWORD = Orthography::Multiword as OrthographyFlagsUnderlyingType;
        const HYPHENATED = Orthography::Hyphenated as OrthographyFlagsUnderlyingType;
        const APOSTROPHE = Orthography::Apostrophe as OrthographyFlagsUnderlyingType;
        const ROMAN_NUMERALS = Orthography::RomanNumerals as OrthographyFlagsUnderlyingType;
    }
}
impl Default for OrthFlags {
    fn default() -> Self {
        Self::empty()
    }
}

impl OrthFlags {
    /// Construct orthography flags for a given sequence of letters.
    pub fn from_letters(letters: &[char]) -> Self {
        let mut ortho_flags = Self::default();
        let mut all_lower = true;
        let mut all_upper = true;
        let mut first_is_upper = false;
        let mut first_is_lower = false;
        let mut saw_upper_after_first = false;
        let mut saw_lower_after_first = false;
        let mut is_first_char = true;
        let mut upper_to_lower = false;
        let mut lower_to_upper = false;
        let letter_count = letters.iter().filter(|c| c.is_english_lingual()).count();

        for &c in letters {
            if c == ' ' {
                ortho_flags |= Self::MULTIWORD;
                continue;
            }

            if c == '-' {
                ortho_flags |= Self::HYPHENATED;
                continue;
            }

            if c.normalized() == '\'' {
                ortho_flags |= Self::APOSTROPHE;
                continue;
            }

            if !c.is_english_lingual() {
                continue;
            }

            if c.is_lowercase() {
                all_upper = false;
                if is_first_char {
                    first_is_lower = true;
                } else {
                    saw_lower_after_first = true;
                    if upper_to_lower {
                        lower_to_upper = true;
                    }
                    upper_to_lower = true;
                }
            } else if c.is_uppercase() {
                all_lower = false;
                if is_first_char {
                    first_is_upper = true;
                } else {
                    saw_upper_after_first = true;
                    if lower_to_upper {
                        upper_to_lower = true;
                    }
                    lower_to_upper = true;
                }
            } else {
                first_is_upper = false;
                first_is_lower = false;
                upper_to_lower = false;
                lower_to_upper = false;
            }
            is_first_char = false;
        }

        if letter_count > 0 {
            if all_lower {
                ortho_flags |= Self::LOWERCASE;
            }
            if all_upper {
                ortho_flags |= Self::ALLCAPS;
            }
            if letter_count > 1 && first_is_upper && !saw_upper_after_first {
                ortho_flags |= Self::TITLECASE;
            }
            if first_is_lower && saw_upper_after_first {
                ortho_flags |= Self::LOWER_CAMEL;
            }
            if first_is_upper && saw_lower_after_first && saw_upper_after_first {
                ortho_flags |= Self::UPPER_CAMEL;
            }
        }

        if looks_like_roman_numerals(letters) && is_really_roman_numerals(&letters.to_lower()) {
            ortho_flags |= Self::ROMAN_NUMERALS;
        }

        ortho_flags
    }
}

fn looks_like_roman_numerals(word: &[char]) -> bool {
    let mut is_roman = false;
    let first_char_upper;

    if let Some((&first, rest)) = word.split_first()
        && "mdclxvi".contains(first.to_ascii_lowercase())
    {
        first_char_upper = first.is_uppercase();

        for &c in rest {
            if !"mdclxvi".contains(c.to_ascii_lowercase()) || c.is_uppercase() != first_char_upper {
                return false;
            }
        }
        is_roman = true;
    }
    is_roman
}

fn is_really_roman_numerals(word: &[char]) -> bool {
    let s: String = word.iter().collect();
    let mut chars = s.chars().peekable();

    let mut m_count = 0;
    while m_count < 4 && chars.peek() == Some(&'m') {
        chars.next();
        m_count += 1;
    }

    if !check_roman_group(&mut chars, 'c', 'd', 'm') {
        return false;
    }

    if !check_roman_group(&mut chars, 'x', 'l', 'c') {
        return false;
    }

    if !check_roman_group(&mut chars, 'i', 'v', 'x') {
        return false;
    }

    if chars.next().is_some() {
        return false;
    }

    true
}

fn check_roman_group<I: Iterator<Item = char>>(
    chars: &mut std::iter::Peekable<I>,
    one: char,
    five: char,
    ten: char,
) -> bool {
    match chars.peek() {
        Some(&c) if c == one => {
            chars.next();
            match chars.peek() {
                Some(&next) if next == ten || next == five => {
                    chars.next();
                    true
                }
                _ => {
                    let mut count = 0;
                    while count < 2 && chars.peek() == Some(&one) {
                        chars.next();
                        count += 1;
                    }
                    true
                }
            }
        }
        Some(&c) if c == five => {
            chars.next();
            let mut count = 0;
            while count < 3 && chars.peek() == Some(&one) {
                chars.next();
                count += 1;
            }
            true
        }
        _ => true,
    }
}

#[cfg(test)]
mod tests {
    use crate::CharString;
    use crate::dict_word_metadata::tests::md;
    use crate::dict_word_metadata_orthography::OrthFlags;

    fn orth_flags(s: &str) -> OrthFlags {
        let letters: CharString = s.chars().collect();
        OrthFlags::from_letters(&letters)
    }

    #[test]
    fn test_lowercase_flags() {
        let flags = orth_flags("hello");
        assert!(flags.contains(OrthFlags::LOWERCASE));
        assert!(!flags.contains(OrthFlags::TITLECASE));
        assert!(!flags.contains(OrthFlags::ALLCAPS));
        assert!(!flags.contains(OrthFlags::LOWER_CAMEL));
        assert!(!flags.contains(OrthFlags::UPPER_CAMEL));

        let flags = orth_flags("hello123");
        assert!(flags.contains(OrthFlags::LOWERCASE));
    }

    #[test]
    fn test_titlecase_flags() {
        let flags = orth_flags("Hello");
        assert!(!flags.contains(OrthFlags::LOWERCASE));
        assert!(flags.contains(OrthFlags::TITLECASE));
        assert!(!flags.contains(OrthFlags::ALLCAPS));
        assert!(!flags.contains(OrthFlags::LOWER_CAMEL));
        assert!(!flags.contains(OrthFlags::UPPER_CAMEL));

        assert!(orth_flags("World").contains(OrthFlags::TITLECASE));
        assert!(orth_flags("Something").contains(OrthFlags::TITLECASE));
        assert!(!orth_flags("McDonald").contains(OrthFlags::TITLECASE));
        assert!(!orth_flags("O'Reilly").contains(OrthFlags::TITLECASE));
        assert!(!orth_flags("A").contains(OrthFlags::TITLECASE));
    }

    #[test]
    fn test_allcaps_flags() {
        let flags = orth_flags("HELLO");
        assert!(!flags.contains(OrthFlags::LOWERCASE));
        assert!(!flags.contains(OrthFlags::TITLECASE));
        assert!(flags.contains(OrthFlags::ALLCAPS));
        assert!(!flags.contains(OrthFlags::LOWER_CAMEL));
        assert!(!flags.contains(OrthFlags::UPPER_CAMEL));

        assert!(orth_flags("NASA").contains(OrthFlags::ALLCAPS));
        assert!(orth_flags("I").contains(OrthFlags::ALLCAPS));
    }

    #[test]
    fn test_lower_camel_flags() {
        let flags = orth_flags("helloWorld");
        assert!(!flags.contains(OrthFlags::LOWERCASE));
        assert!(!flags.contains(OrthFlags::TITLECASE));
        assert!(!flags.contains(OrthFlags::ALLCAPS));
        assert!(flags.contains(OrthFlags::LOWER_CAMEL));
        assert!(!flags.contains(OrthFlags::UPPER_CAMEL));

        assert!(orth_flags("getHTTPResponse").contains(OrthFlags::LOWER_CAMEL));
        assert!(orth_flags("eBay").contains(OrthFlags::LOWER_CAMEL));
        assert!(!orth_flags("hello").contains(OrthFlags::LOWER_CAMEL));
        assert!(!orth_flags("HelloWorld").contains(OrthFlags::LOWER_CAMEL));
    }

    #[test]
    fn test_upper_camel_flags() {
        let flags = orth_flags("HelloWorld");
        assert!(!flags.contains(OrthFlags::LOWERCASE));
        assert!(!flags.contains(OrthFlags::TITLECASE));
        assert!(!flags.contains(OrthFlags::ALLCAPS));
        assert!(!flags.contains(OrthFlags::LOWER_CAMEL));
        assert!(flags.contains(OrthFlags::UPPER_CAMEL));

        assert!(orth_flags("HttpRequest").contains(OrthFlags::UPPER_CAMEL));
        assert!(orth_flags("McDonald").contains(OrthFlags::UPPER_CAMEL));
        assert!(orth_flags("O'Reilly").contains(OrthFlags::UPPER_CAMEL));
        assert!(orth_flags("XMLHttpRequest").contains(OrthFlags::UPPER_CAMEL));
        assert!(!orth_flags("Hello").contains(OrthFlags::UPPER_CAMEL));
        assert!(!orth_flags("NASA").contains(OrthFlags::UPPER_CAMEL));
        assert!(!orth_flags("Hi").contains(OrthFlags::UPPER_CAMEL));
    }

    #[test]
    fn test_roman_numeral_flags() {
        assert!(orth_flags("MCMXCIV").contains(OrthFlags::ROMAN_NUMERALS));
        assert!(orth_flags("mdccclxxi").contains(OrthFlags::ROMAN_NUMERALS));
        assert!(orth_flags("MMXXI").contains(OrthFlags::ROMAN_NUMERALS));
        assert!(orth_flags("mcmxciv").contains(OrthFlags::ROMAN_NUMERALS));
        assert!(orth_flags("MCMXCIV").contains(OrthFlags::ROMAN_NUMERALS));
        assert!(orth_flags("MMI").contains(OrthFlags::ROMAN_NUMERALS));
        assert!(orth_flags("MMXXV").contains(OrthFlags::ROMAN_NUMERALS));
    }

    #[test]
    fn test_single_roman_numeral_flags() {
        assert!(orth_flags("i").contains(OrthFlags::ROMAN_NUMERALS));
    }

    #[test]
    fn empty_string_is_not_roman_numeral() {
        assert!(!orth_flags("").contains(OrthFlags::ROMAN_NUMERALS));
    }

    #[test]
    fn dont_allow_mixed_case_roman_numerals() {
        assert!(!orth_flags("MCMlxxxVIII").contains(OrthFlags::ROMAN_NUMERALS));
    }

    #[test]
    fn dont_allow_looks_like_but_isnt_roman_numeral() {
        assert!(!orth_flags("mdxlivx").contains(OrthFlags::ROMAN_NUMERALS));
        assert!(!orth_flags("XIXIVV").contains(OrthFlags::ROMAN_NUMERALS));
    }

    #[test]
    fn australia_lexeme_is_titlecase_even_when_word_is_lowercase() {
        assert!(md("australia").orth_info.contains(OrthFlags::TITLECASE));
    }

    #[test]
    fn australia_lexeme_is_titlecase_even_when_word_is_all_caps() {
        assert!(md("AUSTRALIA").orth_info.contains(OrthFlags::TITLECASE));
    }

    #[test]
    fn australia_lexeme_is_titlecase_even_when_word_is_mixed_case() {
        assert!(md("AuStrAlIA").orth_info.contains(OrthFlags::TITLECASE));
    }

    #[test]
    fn db_and_kw_symbols_are_lower_camel_case() {
        // dB, kW
        assert!(md("db").orth_info.contains(OrthFlags::LOWER_CAMEL));
    }

    #[test]
    fn am_is_lowercase_and_titlecase_and_all_caps() {
        // am, Am, AM
        let metadata = md("am");
        assert!(metadata.orth_info.contains(OrthFlags::LOWERCASE));
        assert!(metadata.orth_info.contains(OrthFlags::TITLECASE));
        assert!(metadata.orth_info.contains(OrthFlags::ALLCAPS));
    }

    #[test]
    fn reading_is_both_lowercase_and_titlecase() {
        // Reading is a town in England
        let metadata = md("reading");
        assert!(metadata.orth_info.contains(OrthFlags::LOWERCASE));
        assert!(metadata.orth_info.contains(OrthFlags::TITLECASE));
    }

    #[test]
    fn ebay_and_esim_are_lower_camel() {
        // eBay eSIM
        let md1 = md("ebay");
        assert!(md1.orth_info.contains(OrthFlags::LOWER_CAMEL));
        let md2 = md("esim");
        assert!(md2.orth_info.contains(OrthFlags::LOWER_CAMEL));
    }
}



================================================
FILE: harper-core/src/document.rs
================================================
use std::cmp::Ordering;
use std::collections::VecDeque;
use std::fmt::Display;

use harper_brill::{Chunker, Tagger, brill_tagger, burn_chunker};
use itertools::Itertools;
use paste::paste;

use crate::expr::{Expr, ExprExt, FirstMatchOf, Repeating, SequenceExpr};
use crate::parsers::{Markdown, MarkdownOptions, Parser, PlainEnglish};
use crate::patterns::WordSet;
use crate::punctuation::Punctuation;
use crate::spell::{Dictionary, FstDictionary};
use crate::vec_ext::VecExt;
use crate::{CharStringExt, FatStringToken, FatToken, Lrc, Token, TokenKind, TokenStringExt};
use crate::{OrdinalSuffix, Span};

/// A document containing some amount of lexed and parsed English text.
#[derive(Debug, Clone)]
pub struct Document {
    source: Lrc<Vec<char>>,
    tokens: Vec<Token>,
}

impl Default for Document {
    fn default() -> Self {
        Self::new("", &PlainEnglish, &FstDictionary::curated())
    }
}

impl Document {
    /// Locate all the tokens that intersect a provided span.
    ///
    /// Desperately needs optimization.
    pub fn token_indices_intersecting(&self, span: Span<char>) -> Vec<usize> {
        self.tokens()
            .enumerate()
            .filter_map(|(idx, tok)| tok.span.overlaps_with(span).then_some(idx))
            .collect()
    }

    /// Locate all the tokens that intersect a provided span and convert them to [`FatToken`]s.
    ///
    /// Desperately needs optimization.
    pub fn fat_tokens_intersecting(&self, span: Span<char>) -> Vec<FatToken> {
        let indices = self.token_indices_intersecting(span);

        indices
            .into_iter()
            .map(|i| self.tokens[i].to_fat(&self.source))
            .collect()
    }

    /// Lexes and parses text to produce a document using a provided language
    /// parser and dictionary.
    pub fn new(text: &str, parser: &impl Parser, dictionary: &impl Dictionary) -> Self {
        let source: Vec<_> = text.chars().collect();

        Self::new_from_vec(Lrc::new(source), parser, dictionary)
    }

    /// Lexes and parses text to produce a document using a provided language
    /// parser and the included curated dictionary.
    pub fn new_curated(text: &str, parser: &impl Parser) -> Self {
        let source: Vec<_> = text.chars().collect();

        Self::new_from_vec(Lrc::new(source), parser, &FstDictionary::curated())
    }

    /// Lexes and parses text to produce a document using a provided language
    /// parser and dictionary.
    pub fn new_from_vec(
        source: Lrc<Vec<char>>,
        parser: &impl Parser,
        dictionary: &impl Dictionary,
    ) -> Self {
        let tokens = parser.parse(&source);

        let mut document = Self { source, tokens };
        document.parse(dictionary);

        document
    }

    /// Parse text to produce a document using the built-in [`PlainEnglish`]
    /// parser and curated dictionary.
    pub fn new_plain_english_curated(text: &str) -> Self {
        Self::new(text, &PlainEnglish, &FstDictionary::curated())
    }

    /// Create a new document simply by tokenizing the provided input and applying fix-ups. The
    /// contained words will not contain any metadata.
    ///
    /// This avoids running potentially expensive metadata generation code, so this is more
    /// efficient if you don't need that information.
    pub(crate) fn new_basic_tokenize(text: &str, parser: &impl Parser) -> Self {
        let source = Lrc::new(text.chars().collect_vec());
        let tokens = parser.parse(&source);
        let mut document = Self { source, tokens };
        document.apply_fixups();
        document
    }

    /// Parse text to produce a document using the built-in [`PlainEnglish`]
    /// parser and a provided dictionary.
    pub fn new_plain_english(text: &str, dictionary: &impl Dictionary) -> Self {
        Self::new(text, &PlainEnglish, dictionary)
    }

    /// Parse text to produce a document using the built-in [`Markdown`] parser
    /// and curated dictionary.
    pub fn new_markdown_curated(text: &str, markdown_options: MarkdownOptions) -> Self {
        Self::new(
            text,
            &Markdown::new(markdown_options),
            &FstDictionary::curated(),
        )
    }

    /// Parse text to produce a document using the built-in [`Markdown`] parser
    /// and curated dictionary with the default Markdown configuration.
    pub fn new_markdown_default_curated(text: &str) -> Self {
        Self::new_markdown_curated(text, MarkdownOptions::default())
    }

    /// Parse text to produce a document using the built-in [`PlainEnglish`]
    /// parser and the curated dictionary.
    pub fn new_markdown(
        text: &str,
        markdown_options: MarkdownOptions,
        dictionary: &impl Dictionary,
    ) -> Self {
        Self::new(text, &Markdown::new(markdown_options), dictionary)
    }

    /// Parse text to produce a document using the built-in [`PlainEnglish`]
    /// parser and the curated dictionary with the default Markdown configuration.
    pub fn new_markdown_default(text: &str, dictionary: &impl Dictionary) -> Self {
        Self::new_markdown(text, MarkdownOptions::default(), dictionary)
    }

    fn apply_fixups(&mut self) {
        self.condense_spaces();
        self.condense_newlines();
        self.newlines_to_breaks();
        self.condense_dotted_initialisms();
        self.condense_number_suffixes();
        self.condense_ellipsis();
        self.condense_latin();
        self.condense_filename_extensions();
        self.condense_tldr();
        self.condense_ampersand_pairs();
        self.condense_slash_pairs();
        self.match_quotes();
    }

    /// Re-parse important language constructs.
    ///
    /// Should be run after every change to the underlying [`Self::source`].
    fn parse(&mut self, dictionary: &impl Dictionary) {
        self.apply_fixups();

        let chunker = burn_chunker();
        let tagger = brill_tagger();

        for sent in self.tokens.iter_sentences_mut() {
            let token_strings: Vec<_> = sent
                .iter()
                .filter(|t| !t.kind.is_whitespace())
                .map(|t| t.span.get_content_string(&self.source))
                .collect();

            let token_tags = tagger.tag_sentence(&token_strings);
            let np_flags = chunker.chunk_sentence(&token_strings, &token_tags);

            let mut i = 0;

            // Annotate DictWord metadata
            for token in sent.iter_mut() {
                if let TokenKind::Word(meta) = &mut token.kind {
                    let word_source = token.span.get_content(&self.source);
                    let mut found_meta = dictionary
                        .get_word_metadata(word_source)
                        .map(|c| c.into_owned());

                    if let Some(inner) = &mut found_meta {
                        inner.pos_tag = token_tags[i].or_else(|| inner.infer_pos_tag());
                        inner.np_member = Some(np_flags[i]);
                    }

                    *meta = found_meta;
                    i += 1;
                } else if !token.kind.is_whitespace() {
                    i += 1;
                }
            }
        }
    }

    /// Convert all sets of newlines greater than 2 to paragraph breaks.
    fn newlines_to_breaks(&mut self) {
        for token in &mut self.tokens {
            if let TokenKind::Newline(n) = token.kind
                && n >= 2
            {
                token.kind = TokenKind::ParagraphBreak;
            }
        }
    }

    /// Given a list of indices, this function removes the subsequent
    /// `stretch_len - 1` elements after each index.
    ///
    /// Will extend token spans to include removed elements.
    /// Assumes condensed tokens are contiguous in source text.
    fn condense_indices(&mut self, indices: &[usize], stretch_len: usize) {
        // Update spans
        for idx in indices {
            let end_tok = self.tokens[idx + stretch_len - 1].clone();
            let start_tok = &mut self.tokens[*idx];

            start_tok.span.end = end_tok.span.end;
        }

        // Trim
        let old = self.tokens.clone();
        self.tokens.clear();

        // Keep first chunk.
        self.tokens
            .extend_from_slice(&old[0..indices.first().copied().unwrap_or(indices.len())]);

        let mut iter = indices.iter().peekable();

        while let (Some(a_idx), b) = (iter.next(), iter.peek()) {
            self.tokens.push(old[*a_idx].clone());

            if let Some(b_idx) = b {
                self.tokens
                    .extend_from_slice(&old[a_idx + stretch_len..**b_idx]);
            }
        }

        // Keep last chunk.
        self.tokens.extend_from_slice(
            &old[indices
                .last()
                .map(|v| v + stretch_len)
                .unwrap_or(indices.len())..],
        );
    }

    pub fn get_token_at_char_index(&self, char_index: usize) -> Option<&Token> {
        let index = self
            .tokens
            .binary_search_by(|t| {
                if t.span.overlaps_with(Span::new_with_len(char_index, 1)) {
                    Ordering::Equal
                } else {
                    t.span.start.cmp(&char_index)
                }
            })
            .ok()?;

        Some(&self.tokens[index])
    }

    /// Defensively attempt to grab a specific token.
    pub fn get_token(&self, index: usize) -> Option<&Token> {
        self.tokens.get(index)
    }

    /// Get a token at a signed offset from a base index, or None if out of bounds.
    pub fn get_token_offset(&self, base: usize, offset: isize) -> Option<&Token> {
        match base.checked_add_signed(offset) {
            None => None,
            Some(idx) => self.get_token(idx),
        }
    }

    /// Get an iterator over all the tokens contained in the document.
    pub fn tokens(&self) -> impl Iterator<Item = &Token> + '_ {
        self.tokens.iter()
    }

    pub fn iter_nominal_phrases(&self) -> impl Iterator<Item = &[Token]> {
        fn is_np_member(t: &Token) -> bool {
            t.kind
                .as_word()
                .and_then(|x| x.as_ref())
                .and_then(|w| w.np_member)
                .unwrap_or(false)
        }

        fn trim(slice: &[Token]) -> &[Token] {
            let mut start = 0;
            let mut end = slice.len();
            while start < end && slice[start].kind.is_whitespace() {
                start += 1;
            }
            while end > start && slice[end - 1].kind.is_whitespace() {
                end -= 1;
            }
            &slice[start..end]
        }

        self.tokens
            .as_slice()
            .split(|t| !(is_np_member(t) || t.kind.is_whitespace()))
            .filter_map(|s| {
                let s = trim(s);
                if s.iter().any(is_np_member) {
                    Some(s)
                } else {
                    None
                }
            })
    }

    /// Get an iterator over all the tokens contained in the document.
    pub fn fat_tokens(&self) -> impl Iterator<Item = FatToken> + '_ {
        self.tokens().map(|token| token.to_fat(&self.source))
    }

    /// Get the next or previous word token relative to a base index, if separated by whitespace.
    /// Returns None if the next/previous token is not a word or does not exist.
    pub fn get_next_word_from_offset(&self, base: usize, offset: isize) -> Option<&Token> {
        // Look for whitespace at the expected offset
        if !self.get_token_offset(base, offset)?.kind.is_whitespace() {
            return None;
        }
        // Now look beyond the whitespace for a word token
        let word_token = self.get_token_offset(base, offset + offset.signum());
        let word_token = word_token?;
        word_token.kind.is_word().then_some(word_token)
    }

    /// Get an iterator over all the tokens contained in the document.
    pub fn fat_string_tokens(&self) -> impl Iterator<Item = FatStringToken> + '_ {
        self.fat_tokens().map(|t| t.into())
    }

    pub fn get_span_content(&self, span: &Span<char>) -> &[char] {
        span.get_content(&self.source)
    }

    pub fn get_span_content_str(&self, span: &Span<char>) -> String {
        String::from_iter(self.get_span_content(span))
    }

    pub fn get_full_string(&self) -> String {
        self.get_span_content_str(&Span::new(0, self.source.len()))
    }

    pub fn get_full_content(&self) -> &[char] {
        &self.source
    }

    pub fn get_source(&self) -> &[char] {
        &self.source
    }

    pub fn get_tokens(&self) -> &[Token] {
        &self.tokens
    }

    /// Searches for quotation marks and fills the
    /// [`Punctuation::Quote::twin_loc`] field. This is on a best-effort
    /// basis.
    ///
    /// Current algorithm is based on https://leancrew.com/all-this/2025/03/a-mac-smart-quote-curiosity
    fn match_quotes(&mut self) {
        let mut pg_indices: Vec<_> = vec![0];
        pg_indices.extend(self.iter_paragraph_break_indices());
        pg_indices.push(self.tokens.len());

        // Avoid allocation in loop
        let mut quote_indices = Vec::new();
        let mut open_quote_indices = Vec::new();

        for (start, end) in pg_indices.into_iter().tuple_windows() {
            let pg = &mut self.tokens[start..end];

            quote_indices.clear();
            quote_indices.extend(pg.iter_quote_indices());
            open_quote_indices.clear();

            // Find open quotes first.
            for quote in &quote_indices {
                let is_open = *quote == 0
                    || pg[0..*quote].iter_word_likes().next().is_none()
                    || pg[quote - 1].kind.is_whitespace()
                    || matches!(
                        pg[quote - 1].kind.as_punctuation(),
                        Some(Punctuation::LessThan)
                            | Some(Punctuation::OpenRound)
                            | Some(Punctuation::OpenSquare)
                            | Some(Punctuation::OpenCurly)
                            | Some(Punctuation::Apostrophe)
                    );

                if is_open {
                    open_quote_indices.push(*quote);
                }
            }

            while let Some(open_idx) = open_quote_indices.pop() {
                let Some(close_idx) = pg[open_idx + 1..].iter_quote_indices().next() else {
                    continue;
                };

                if pg[close_idx + open_idx + 1]
                    .kind
                    .as_quote()
                    .unwrap()
                    .twin_loc
                    .is_some()
                {
                    continue;
                }

                pg[open_idx].kind.as_mut_quote().unwrap().twin_loc =
                    Some(close_idx + open_idx + start + 1);
                pg[close_idx + open_idx + 1]
                    .kind
                    .as_mut_quote()
                    .unwrap()
                    .twin_loc = Some(open_idx + start);
            }
        }
    }

    /// Searches for number suffixes and condenses them down into single tokens
    fn condense_number_suffixes(&mut self) {
        if self.tokens.len() < 2 {
            return;
        }

        let mut replace_starts = Vec::new();

        for idx in 0..self.tokens.len() - 1 {
            let b = &self.tokens[idx + 1];
            let a = &self.tokens[idx];

            // TODO: Allow spaces between `a` and `b`

            if let (TokenKind::Number(..), TokenKind::Word(..)) = (&a.kind, &b.kind)
                && let Some(found_suffix) =
                    OrdinalSuffix::from_chars(self.get_span_content(&b.span))
            {
                self.tokens[idx].kind.as_mut_number().unwrap().suffix = Some(found_suffix);
                replace_starts.push(idx);
            }
        }

        self.condense_indices(&replace_starts, 2);
    }

    /// Searches for multiple sequential space tokens and condenses them down
    /// into one.
    fn condense_spaces(&mut self) {
        let mut cursor = 0;
        let copy = self.tokens.clone();

        let mut remove_these = VecDeque::new();

        while cursor < self.tokens.len() {
            // Locate a stretch of one or more newline tokens.
            let start_tok = &mut self.tokens[cursor];

            if let TokenKind::Space(start_count) = &mut start_tok.kind {
                loop {
                    cursor += 1;

                    if cursor >= copy.len() {
                        break;
                    }

                    let child_tok = &copy[cursor];

                    // Only condense adjacent spans
                    if start_tok.span.end != child_tok.span.start {
                        break;
                    }

                    if let TokenKind::Space(n) = child_tok.kind {
                        *start_count += n;
                        start_tok.span.end = child_tok.span.end;
                        remove_these.push_back(cursor);
                        cursor += 1;
                    } else {
                        break;
                    };
                }
            }

            cursor += 1;
        }

        self.tokens.remove_indices(remove_these);
    }

    thread_local! {
        static LATIN_EXPR: Lrc<FirstMatchOf> = Document::uncached_latin_expr();
    }

    fn uncached_latin_expr() -> Lrc<FirstMatchOf> {
        Lrc::new(FirstMatchOf::new(vec![
            Box::new(
                SequenceExpr::default()
                    .then(WordSet::new(&["etc", "vs"]))
                    .then_period(),
            ),
            Box::new(
                SequenceExpr::aco("et")
                    .then_whitespace()
                    .t_aco("al")
                    .then_period(),
            ),
        ]))
    }

    /// Assumes that the first matched token is the canonical one to be condensed into.
    /// Takes a callback that can be used to retroactively edit the canonical token afterwards.
    fn condense_expr<F>(&mut self, expr: &impl Expr, edit: F)
    where
        F: Fn(&mut Token),
    {
        let matches = expr.iter_matches_in_doc(self).collect::<Vec<_>>();

        let mut remove_indices = VecDeque::with_capacity(matches.len());

        for m in matches {
            remove_indices.extend(m.start + 1..m.end);
            self.tokens[m.start].span = self.tokens[m.into_iter()].span().unwrap();
            edit(&mut self.tokens[m.start]);
        }

        self.tokens.remove_indices(remove_indices);
    }

    fn condense_latin(&mut self) {
        self.condense_expr(&Self::LATIN_EXPR.with(|v| v.clone()), |_| {})
    }

    /// Searches for multiple sequential newline tokens and condenses them down
    /// into one.
    fn condense_newlines(&mut self) {
        let mut cursor = 0;
        let copy = self.tokens.clone();

        let mut remove_these = VecDeque::new();

        while cursor < self.tokens.len() {
            // Locate a stretch of one or more newline tokens.
            let start_tok = &mut self.tokens[cursor];

            if let TokenKind::Newline(start_count) = &mut start_tok.kind {
                loop {
                    cursor += 1;

                    if cursor >= copy.len() {
                        break;
                    }

                    let child_tok = &copy[cursor];
                    if let TokenKind::Newline(n) = child_tok.kind {
                        *start_count += n;
                        start_tok.span.end = child_tok.span.end;
                        remove_these.push_back(cursor);
                        cursor += 1;
                    } else {
                        break;
                    };
                }
            }

            cursor += 1;
        }

        self.tokens.remove_indices(remove_these);
    }

    /// Condenses words like "i.e.", "e.g." and "N.S.A." down to single words
    /// using a state machine.
    fn condense_dotted_initialisms(&mut self) {
        if self.tokens.len() < 2 {
            return;
        }

        let mut to_remove = VecDeque::new();

        let mut cursor = 1;

        let mut initialism_start = None;

        loop {
            let a = &self.tokens[cursor - 1];
            let b = &self.tokens[cursor];

            let is_initialism_chunk = a.kind.is_word() && a.span.len() == 1 && b.kind.is_period();

            if is_initialism_chunk {
                if initialism_start.is_none() {
                    initialism_start = Some(cursor - 1);
                } else {
                    to_remove.push_back(cursor - 1);
                }

                to_remove.push_back(cursor);
                cursor += 1;
            } else {
                if let Some(start) = initialism_start {
                    let end = self.tokens[cursor - 2].span.end;
                    let start_tok: &mut Token = &mut self.tokens[start];
                    start_tok.span.end = end;
                }

                initialism_start = None;
            }

            cursor += 1;

            if cursor >= self.tokens.len() - 1 {
                break;
            }
        }

        self.tokens.remove_indices(to_remove);
    }

    /// Condenses likely filename extensions down to single tokens.
    fn condense_filename_extensions(&mut self) {
        if self.tokens.len() < 2 {
            return;
        }

        let mut to_remove = VecDeque::new();

        let mut cursor = 1;

        let mut ext_start = None;

        loop {
            // left context, dot, extension, right context
            let l = self.get_token_offset(cursor, -2);
            let d = &self.tokens[cursor - 1];
            let x = &self.tokens[cursor];
            let r = self.get_token_offset(cursor, 1);

            let is_ext_chunk = d.kind.is_period()
                && x.kind.is_word()
                && x.span.len() <= 3
                && ((l.is_none_or(|t| t.kind.is_whitespace())
                    && r.is_none_or(|t| t.kind.is_whitespace()))
                    || (l.is_some_and(|t| t.kind.is_open_round())
                        && r.is_some_and(|t| t.kind.is_close_round())))
                && {
                    let ext_chars = x.span.get_content(&self.source);
                    ext_chars.iter().all(|c| c.is_ascii_lowercase())
                        || ext_chars.iter().all(|c| c.is_ascii_uppercase())
                };

            if is_ext_chunk {
                if ext_start.is_none() {
                    ext_start = Some(cursor - 1);
                    self.tokens[cursor - 1].kind = TokenKind::Unlintable;
                } else {
                    to_remove.push_back(cursor - 1);
                }

                to_remove.push_back(cursor);
                cursor += 1;
            } else {
                if let Some(start) = ext_start {
                    let end = self.tokens[cursor - 2].span.end;
                    let start_tok: &mut Token = &mut self.tokens[start];
                    start_tok.span.end = end;
                }

                ext_start = None;
            }

            cursor += 1;

            if cursor >= self.tokens.len() {
                break;
            }
        }

        self.tokens.remove_indices(to_remove);
    }

    /// Condenses "tl;dr" down to a single word token.
    fn condense_tldr(&mut self) {
        if self.tokens.len() < 3 {
            return;
        }

        let mut to_remove = VecDeque::new();
        let mut cursor = 2;

        loop {
            let tl = &self.tokens[cursor - 2];
            let simicolon = &self.tokens[cursor - 1];
            let dr = &self.tokens[cursor];

            let is_tldr_chunk = tl.kind.is_word()
                && tl.span.len() == 2
                && tl
                    .span
                    .get_content(&self.source)
                    .eq_ignore_ascii_case_chars(&['t', 'l'])
                && simicolon.kind.is_semicolon()
                && dr.kind.is_word()
                && dr.span.len() >= 2
                && dr.span.len() <= 3
                && dr
                    .span
                    .get_content(&self.source)
                    .eq_any_ignore_ascii_case_chars(&[&['d', 'r'], &['d', 'r', 's']]);

            if is_tldr_chunk {
                // Update the first token to be the full "tl;dr" as a word
                self.tokens[cursor - 2].span = Span::new(
                    self.tokens[cursor - 2].span.start,
                    self.tokens[cursor].span.end,
                );

                // Mark the semicolon and "dr" tokens for removal
                to_remove.push_back(cursor - 1);
                to_remove.push_back(cursor);
            }

            // Skip ahead since we've processed these tokens
            cursor += 1;

            if cursor >= self.tokens.len() {
                break;
            }
        }

        // Remove the marked tokens in reverse order to maintain correct indices
        self.tokens.remove_indices(to_remove);
    }

    /// Allows condensing of delimited pairs of tokens into a single token.
    ///
    /// # Arguments
    ///
    /// * `is_delimiter` - A function that returns `true` if the token is a delimiter.
    /// * `valid_pairs` - A slice of tuples representing the valid pairs of tokens to condense.
    ///
    fn condense_delimited_pairs<F>(&mut self, is_delimiter: F, valid_pairs: &[(char, char)])
    where
        F: Fn(&TokenKind) -> bool,
    {
        if self.tokens.len() < 3 {
            return;
        }

        let mut to_remove = VecDeque::new();
        let mut cursor = 2;

        loop {
            let l1 = &self.tokens[cursor - 2];
            let delim = &self.tokens[cursor - 1];
            let l2 = &self.tokens[cursor];

            let is_delimited_chunk = l1.kind.is_word()
                && l1.span.len() == 1
                && is_delimiter(&delim.kind)
                && l2.kind.is_word()
                && l2.span.len() == 1;

            if is_delimited_chunk {
                let (l1, l2) = (
                    l1.span.get_content(&self.source).first(),
                    l2.span.get_content(&self.source).first(),
                );

                let is_valid_pair = match (l1, l2) {
                    (Some(l1), Some(l2)) => {
                        let pair = (l1.to_ascii_lowercase(), l2.to_ascii_lowercase());
                        valid_pairs.contains(&pair)
                    }
                    _ => false,
                };

                if is_valid_pair {
                    self.tokens[cursor - 2].span = Span::new(
                        self.tokens[cursor - 2].span.start,
                        self.tokens[cursor].span.end,
                    );
                    to_remove.push_back(cursor - 1);
                    to_remove.push_back(cursor);
                }
            }

            cursor += 1;
            if cursor >= self.tokens.len() {
                break;
            }
        }

        self.tokens.remove_indices(to_remove);
    }

    // Condenses "ampersand pairs" such as "R&D" or "Q&A" into single tokens.
    fn condense_ampersand_pairs(&mut self) {
        self.condense_delimited_pairs(
            |kind| kind.is_ampersand(),
            &[
                ('b', 'b'), // bed & breakfast
                ('b', 'w'), // black & white
                ('g', 't'), // gin & tonic
                ('k', 'r'), // Kernighan & Ritchie
                ('q', 'a'), // question & answer
                ('r', 'b'), // rhythm & blues
                ('r', 'd'), // research & development
                ('r', 'r'), // rest & relaxation
                ('s', 'p'), // Standard & Poor's
            ],
        );
    }

    // Condenses "slash pairs" such as "I/O" into single tokens.
    fn condense_slash_pairs(&mut self) {
        self.condense_delimited_pairs(
            |kind| kind.is_slash(),
            &[
                ('a', 'c'), // aircon; alternating current
                ('b', 'w'), // black and white
                ('c', 'o'), // care of
                ('d', 'c'), // direct current
                ('d', 'l'), // download
                ('i', 'o'), // input/output
                ('j', 'k'), // just kidding
                ('n', 'a'), // not applicable
                ('r', 'c'), // radio control
                ('s', 'n'), // serial number
                ('y', 'n'), // yes/no
                ('y', 'o'), // years old
            ],
        );
    }

    fn uncached_ellipsis_pattern() -> Lrc<Repeating> {
        let period = SequenceExpr::default().then_period();
        Lrc::new(Repeating::new(Box::new(period), 2))
    }

    thread_local! {
        static ELLIPSIS_EXPR: Lrc<Repeating> = Document::uncached_ellipsis_pattern();
    }

    fn condense_ellipsis(&mut self) {
        let expr = Self::ELLIPSIS_EXPR.with(|v| v.clone());
        self.condense_expr(&expr, |tok| {
            tok.kind = TokenKind::Punctuation(Punctuation::Ellipsis)
        });
    }
}

/// Creates functions necessary to implement [`TokenStringExt]` on a document.
macro_rules! create_fns_on_doc {
    ($thing:ident) => {
        paste! {
            fn [< first_ $thing >](&self) -> Option<&Token> {
                self.tokens.[< first_ $thing >]()
            }

            fn [< last_ $thing >](&self) -> Option<&Token> {
                self.tokens.[< last_ $thing >]()
            }

            fn [< last_ $thing _index>](&self) -> Option<usize> {
                self.tokens.[< last_ $thing _index >]()
            }

            fn [<iter_ $thing _indices>](&self) -> impl DoubleEndedIterator<Item = usize> + '_ {
                self.tokens.[< iter_ $thing _indices >]()
            }

            fn [<iter_ $thing s>](&self) -> impl Iterator<Item = &Token> + '_ {
                self.tokens.[< iter_ $thing s >]()
            }
        }
    };
}

impl TokenStringExt for Document {
    create_fns_on_doc!(adjective);
    create_fns_on_doc!(apostrophe);
    create_fns_on_doc!(at);
    create_fns_on_doc!(chunk_terminator);
    create_fns_on_doc!(comma);
    create_fns_on_doc!(conjunction);
    create_fns_on_doc!(currency);
    create_fns_on_doc!(ellipsis);
    create_fns_on_doc!(hostname);
    create_fns_on_doc!(likely_homograph);
    create_fns_on_doc!(noun);
    create_fns_on_doc!(number);
    create_fns_on_doc!(paragraph_break);
    create_fns_on_doc!(pipe);
    create_fns_on_doc!(preposition);
    create_fns_on_doc!(punctuation);
    create_fns_on_doc!(quote);
    create_fns_on_doc!(sentence_terminator);
    create_fns_on_doc!(space);
    create_fns_on_doc!(unlintable);
    create_fns_on_doc!(verb);
    create_fns_on_doc!(word);
    create_fns_on_doc!(word_like);
    create_fns_on_doc!(heading_start);

    fn first_sentence_word(&self) -> Option<&Token> {
        self.tokens.first_sentence_word()
    }

    fn first_non_whitespace(&self) -> Option<&Token> {
        self.tokens.first_non_whitespace()
    }

    fn span(&self) -> Option<Span<char>> {
        self.tokens.span()
    }

    fn iter_linking_verb_indices(&self) -> impl Iterator<Item = usize> + '_ {
        self.tokens.iter_linking_verb_indices()
    }

    fn iter_linking_verbs(&self) -> impl Iterator<Item = &Token> + '_ {
        self.tokens.iter_linking_verbs()
    }

    fn iter_chunks(&self) -> impl Iterator<Item = &'_ [Token]> + '_ {
        self.tokens.iter_chunks()
    }

    fn iter_paragraphs(&self) -> impl Iterator<Item = &'_ [Token]> + '_ {
        self.tokens.iter_paragraphs()
    }

    fn iter_headings(&self) -> impl Iterator<Item = &'_ [Token]> + '_ {
        self.tokens.iter_headings()
    }

    fn iter_sentences(&self) -> impl Iterator<Item = &'_ [Token]> + '_ {
        self.tokens.iter_sentences()
    }

    fn iter_sentences_mut(&mut self) -> impl Iterator<Item = &'_ mut [Token]> + '_ {
        self.tokens.iter_sentences_mut()
    }
}

impl Display for Document {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        for token in &self.tokens {
            write!(f, "{}", self.get_span_content_str(&token.span))?;
        }

        Ok(())
    }
}

#[cfg(test)]
mod tests {
    use itertools::Itertools;

    use super::Document;
    use crate::TokenStringExt;
    use crate::{Span, parsers::MarkdownOptions};

    fn assert_condensed_contractions(text: &str, final_tok_count: usize) {
        let document = Document::new_plain_english_curated(text);

        assert_eq!(document.tokens.len(), final_tok_count);

        let document = Document::new_markdown_curated(text, MarkdownOptions::default());

        assert_eq!(document.tokens.len(), final_tok_count);
    }

    #[test]
    fn simple_contraction() {
        assert_condensed_contractions("isn't", 1);
    }

    #[test]
    fn simple_contraction2() {
        assert_condensed_contractions("wasn't", 1);
    }

    #[test]
    fn simple_contraction3() {
        assert_condensed_contractions("There's", 1);
    }

    #[test]
    fn simple_contraction4() {
        assert_condensed_contractions("doesn't", 1);
    }

    #[test]
    fn medium_contraction() {
        assert_condensed_contractions("isn't wasn't", 3);
    }

    #[test]
    fn medium_contraction2() {
        assert_condensed_contractions("There's no way", 5);
    }

    #[test]
    fn selects_token_at_char_index() {
        let text = "There were three little pigs. They built three little homes.";
        let document = Document::new_plain_english_curated(text);

        let got = document.get_token_at_char_index(19).unwrap();

        assert!(got.kind.is_word());
        assert_eq!(got.span, Span::new(17, 23));
    }

    fn assert_token_count(source: &str, count: usize) {
        let document = Document::new_plain_english_curated(source);

        dbg!(document.tokens().map(|t| t.kind.clone()).collect_vec());
        assert_eq!(document.tokens.len(), count);
    }

    #[test]
    fn condenses_number_suffixes() {
        assert_token_count("1st", 1);
        assert_token_count("This is the 2nd test", 9);
        assert_token_count("This is the 3rd test", 9);
        assert_token_count(
            "It works even with weird capitalization like this: 600nD",
            18,
        );
    }

    #[test]
    fn condenses_ie() {
        assert_token_count("There is a thing (i.e. that one)", 15);
        assert_token_count("We are trying to condense \"i.e.\"", 13);
        assert_token_count(r#"Condenses words like "i.e.", "e.g." and "N.S.A.""#, 20);
    }

    #[test]
    fn condenses_eg() {
        assert_token_count("We are trying to condense \"e.g.\"", 13);
        assert_token_count(r#"Condenses words like "i.e.", "e.g." and "N.S.A.""#, 20);
    }

    #[test]
    fn condenses_nsa() {
        assert_token_count(r#"Condenses words like "i.e.", "e.g." and "N.S.A.""#, 20);
    }

    #[test]
    fn parses_ellipsis() {
        assert_token_count("...", 1);
    }

    #[test]
    fn parses_long_ellipsis() {
        assert_token_count(".....", 1);
    }

    #[test]
    fn parses_short_ellipsis() {
        assert_token_count("..", 1);
    }

    #[test]
    fn selects_token_at_offset() {
        let doc = Document::new_plain_english_curated("Foo bar baz");

        let tok = doc.get_token_offset(1, -1).unwrap();

        assert_eq!(tok.span, Span::new(0, 3));
    }

    #[test]
    fn cant_select_token_before_start() {
        let doc = Document::new_plain_english_curated("Foo bar baz");

        let tok = doc.get_token_offset(0, -1);

        assert!(tok.is_none());
    }

    #[test]
    fn select_next_word_pos_offset() {
        let doc = Document::new_plain_english_curated("Foo bar baz");

        let bar = doc.get_next_word_from_offset(0, 1).unwrap();
        let bar = doc.get_span_content(&bar.span);
        assert_eq!(bar, ['b', 'a', 'r']);
    }

    #[test]
    fn select_next_word_neg_offset() {
        let doc = Document::new_plain_english_curated("Foo bar baz");

        let bar = doc.get_next_word_from_offset(2, -1).unwrap();
        let bar = doc.get_span_content(&bar.span);
        assert_eq!(bar, ['F', 'o', 'o']);
    }

    #[test]
    fn cant_select_next_word_not_from_whitespace() {
        let doc = Document::new_plain_english_curated("Foo bar baz");

        let tok = doc.get_next_word_from_offset(0, 2);

        assert!(tok.is_none());
    }

    #[test]
    fn cant_select_next_word_before_start() {
        let doc = Document::new_plain_english_curated("Foo bar baz");

        let tok = doc.get_next_word_from_offset(0, -1);

        assert!(tok.is_none());
    }

    #[test]
    fn cant_select_next_word_with_punctuation_instead_of_whitespace() {
        let doc = Document::new_plain_english_curated("Foo, bar, baz");

        let tok = doc.get_next_word_from_offset(0, 1);

        assert!(tok.is_none());
    }

    #[test]
    fn cant_select_next_word_with_punctuation_after_whitespace() {
        let doc = Document::new_plain_english_curated("Foo \"bar\", baz");

        let tok = doc.get_next_word_from_offset(0, 1);

        assert!(tok.is_none());
    }

    #[test]
    fn condenses_filename_extensions() {
        let doc = Document::new_plain_english_curated(".c and .exe and .js");
        assert!(doc.tokens[0].kind.is_unlintable());
        assert!(doc.tokens[4].kind.is_unlintable());
        assert!(doc.tokens[8].kind.is_unlintable());
    }

    #[test]
    fn condense_filename_extension_ok_at_start_and_end() {
        let doc = Document::new_plain_english_curated(".c and .EXE");
        assert!(doc.tokens.len() == 5);
        assert!(doc.tokens[0].kind.is_unlintable());
        assert!(doc.tokens[4].kind.is_unlintable());
    }

    #[test]
    fn doesnt_condense_filename_extensions_with_mixed_case() {
        let doc = Document::new_plain_english_curated(".c and .Exe");
        assert!(doc.tokens.len() == 6);
        assert!(doc.tokens[0].kind.is_unlintable());
        assert!(doc.tokens[4].kind.is_punctuation());
        assert!(doc.tokens[5].kind.is_word());
    }

    #[test]
    fn doesnt_condense_filename_extensions_with_non_letters() {
        let doc = Document::new_plain_english_curated(".COM and .C0M");
        assert!(doc.tokens.len() == 6);
        assert!(doc.tokens[0].kind.is_unlintable());
        assert!(doc.tokens[4].kind.is_punctuation());
        assert!(doc.tokens[5].kind.is_word());
    }

    #[test]
    fn doesnt_condense_filename_extensions_longer_than_three() {
        let doc = Document::new_plain_english_curated(".dll and .dlls");
        assert!(doc.tokens.len() == 6);
        assert!(doc.tokens[0].kind.is_unlintable());
        assert!(doc.tokens[4].kind.is_punctuation());
        assert!(doc.tokens[5].kind.is_word());
    }

    #[test]
    fn condense_filename_extension_in_parens() {
        let doc = Document::new_plain_english_curated(
            "true for the manual installation when trying to run the executable(.exe) after a manual download",
        );
        assert!(doc.tokens.len() > 23);
        assert!(doc.tokens[21].kind.is_open_round());
        assert!(doc.tokens[22].kind.is_unlintable());
        assert!(doc.tokens[23].kind.is_close_round());
    }

    #[test]
    fn condense_tldr_uppercase() {
        let doc = Document::new_plain_english_curated("TL;DR");
        assert!(doc.tokens.len() == 1);
        assert!(doc.tokens[0].kind.is_word());
        assert!(doc.tokens[0].span.len() == 5);
    }

    #[test]
    fn condense_tldr_lowercase() {
        let doc = Document::new_plain_english_curated("tl;dr");
        assert!(doc.tokens.len() == 1);
        assert!(doc.tokens[0].kind.is_word());
    }

    #[test]
    fn condense_tldr_mixed_case_1() {
        let doc = Document::new_plain_english_curated("tl;DR");
        assert!(doc.tokens.len() == 1);
        assert!(doc.tokens[0].kind.is_word());
    }

    #[test]
    fn condense_tldr_mixed_case_2() {
        let doc = Document::new_plain_english_curated("TL;Dr");
        assert!(doc.tokens.len() == 1);
        assert!(doc.tokens[0].kind.is_word());
    }

    #[test]
    fn condense_tldr_pural() {
        let doc = Document::new_plain_english_curated(
            "managing the flow between components to produce relevant TL;DRs of current news articles",
        );
        // no token is a punctuation token - only words with whitespace between
        assert!(
            doc.tokens
                .iter()
                .all(|t| t.kind.is_word() || t.kind.is_whitespace())
        );
        // one of the word tokens contains a ';' character
        let tldrs = doc
            .tokens
            .iter()
            .filter(|t| t.span.get_content(&doc.source).contains(&';'))
            .collect_vec();
        assert!(tldrs.len() == 1);
        assert!(tldrs[0].span.get_content_string(&doc.source) == "TL;DRs");
    }

    #[test]
    fn condense_r_and_d_caps() {
        let doc = Document::new_plain_english_curated("R&D");
        assert!(doc.tokens.len() == 1);
        assert!(doc.tokens[0].kind.is_word());
    }

    #[test]
    fn condense_r_and_d_mixed_case() {
        let doc = Document::new_plain_english_curated("R&d");
        assert!(doc.tokens.len() == 1);
        assert!(doc.tokens[0].kind.is_word());
    }

    #[test]
    fn condense_r_and_d_lowercase() {
        let doc = Document::new_plain_english_curated("r&d");
        assert!(doc.tokens.len() == 1);
        assert!(doc.tokens[0].kind.is_word());
    }

    #[test]
    fn dont_condense_r_and_d_with_spaces() {
        let doc = Document::new_plain_english_curated("R & D");
        assert!(doc.tokens.len() == 5);
        assert!(doc.tokens[0].kind.is_word());
        assert!(doc.tokens[1].kind.is_whitespace());
        assert!(doc.tokens[2].kind.is_ampersand());
        assert!(doc.tokens[3].kind.is_whitespace());
        assert!(doc.tokens[4].kind.is_word());
    }

    #[test]
    fn condense_q_and_a() {
        let doc =
            Document::new_plain_english_curated("A Q&A platform software for teams at any scales.");
        assert!(doc.tokens.len() >= 3);
        assert!(doc.tokens[2].kind.is_word());
        assert!(doc.tokens[2].span.get_content_string(&doc.source) == "Q&A");
    }

    #[test]
    fn dont_allow_mixed_r_and_d_with_q_and_a() {
        let doc = Document::new_plain_english_curated("R&A or Q&D");
        assert!(doc.tokens.len() == 9);
        assert!(doc.tokens[1].kind.is_ampersand() || doc.tokens[7].kind.is_ampersand());
    }

    #[test]
    fn condense_io() {
        let doc = Document::new_plain_english_curated("I/O");
        assert!(doc.tokens.len() == 1);
        assert!(doc.tokens[0].kind.is_word());
    }

    #[test]
    fn finds_unmatched_quotes_in_document() {
        let raw = r#"
This is a paragraph with a single word "quoted."

This is a second paragraph with no quotes.

This is a third paragraph with a single erroneous "quote.

This is a final paragraph with a weird "quote and a not-weird "quote".
            "#;

        let doc = Document::new_markdown_default_curated(raw);

        let quote_twins: Vec<_> = doc
            .iter_quotes()
            .map(|t| t.kind.as_quote().unwrap().twin_loc)
            .collect();

        assert_eq!(
            quote_twins,
            vec![Some(19), Some(16), None, None, Some(89), Some(87)]
        )
    }

    #[test]
    fn issue_1901() {
        let raw = r#"
"A quoted line"
"A quote without a closing mark
"Another quoted lined"
"The last quoted line"
            "#;

        let doc = Document::new_markdown_default_curated(raw);

        let quote_twins: Vec<_> = doc
            .iter_quotes()
            .map(|t| t.kind.as_quote().unwrap().twin_loc)
            .collect();

        assert_eq!(
            quote_twins,
            vec![
                Some(6),
                Some(0),
                None,
                Some(27),
                Some(21),
                Some(37),
                Some(29)
            ]
        )
    }
}



================================================
FILE: harper-core/src/edit_distance.rs
================================================
// Computes the Levenshtein edit distance between two patterns.
// This is accomplished via a memory-optimized Wagner-Fischer algorithm
//
// This variant avoids allocation if you already have buffers.
#[inline]
pub fn edit_distance_min_alloc(
    source: &[char],
    target: &[char],
    previous_row: &mut Vec<u8>,
    current_row: &mut Vec<u8>,
) -> u8 {
    if cfg!(debug_assertions) {
        assert!(source.len() <= 255 && target.len() <= 255);
    }

    let row_width = source.len();
    let col_height = target.len();

    previous_row.clear();
    previous_row.extend(0u8..=row_width as u8);
    // Alright if not zeroed, since we overwrite it anyway.
    current_row.resize(row_width + 1, 0);

    for j in 1..=col_height {
        current_row[0] = j as u8;

        for i in 1..=row_width {
            let cost = if source[i - 1] == target[j - 1] { 0 } else { 1 };

            current_row[i] = (previous_row[i] + 1)
                .min(current_row[i - 1] + 1)
                .min(previous_row[i - 1] + cost);
        }

        std::mem::swap(previous_row, current_row);
    }

    previous_row[row_width]
}

pub fn edit_distance(source: &[char], target: &[char]) -> u8 {
    edit_distance_min_alloc(source, target, &mut Vec::new(), &mut Vec::new())
}

#[cfg(test)]
mod tests {
    use super::edit_distance;

    fn assert_edit_dist(source: &str, target: &str, expected: u8) {
        let source: Vec<_> = source.chars().collect();
        let target: Vec<_> = target.chars().collect();

        let dist = edit_distance(&source, &target);
        assert_eq!(dist, expected)
    }

    #[test]
    fn simple_edit_distance_1() {
        assert_edit_dist("kitten", "sitting", 3)
    }

    #[test]
    fn simple_edit_distance_2() {
        assert_edit_dist("saturday", "sunday", 3)
    }

    #[test]
    fn one_edit_distance() {
        let source: Vec<_> = "hello".chars().collect();
        let target: Vec<_> = "hellos".chars().collect();
        assert_eq!(edit_distance(&source, &target), 1);

        let target: Vec<_> = "hell".chars().collect();
        assert_eq!(edit_distance(&source, &target), 1);

        let target: Vec<_> = "hell".chars().collect();
        assert_eq!(edit_distance(&source, &target), 1);

        let target: Vec<_> = "hvllo".chars().collect();
        assert_eq!(edit_distance(&source, &target), 1);

        let target: Vec<_> = "Hello".chars().collect();
        assert_eq!(edit_distance(&source, &target), 1);
    }

    #[test]
    fn zero_edit_distance() {
        let source: Vec<_> = "hello".chars().collect();
        let target: Vec<_> = "hello".chars().collect();
        assert_eq!(edit_distance(&source, &target), 0);
    }
}



================================================
FILE: harper-core/src/fat_token.rs
================================================
use serde::{Deserialize, Serialize};

use crate::{CharStringExt, TokenKind};

/// A [`Token`](crate::Token) that holds its content as a fat [`Vec<char>`] rather than as a
/// [`Span`](crate::Span).
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, PartialOrd, Hash, Eq)]
pub struct FatToken {
    pub content: Vec<char>,
    pub kind: TokenKind,
}

impl From<FatStringToken> for FatToken {
    fn from(value: FatStringToken) -> Self {
        Self {
            content: value.content.chars().collect(),
            kind: value.kind,
        }
    }
}

/// Similar to a [`FatToken`], but uses a [`String`] as the underlying store.
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, PartialOrd, Hash, Eq)]
pub struct FatStringToken {
    pub content: String,
    pub kind: TokenKind,
}

impl From<FatToken> for FatStringToken {
    fn from(value: FatToken) -> Self {
        Self {
            content: value.content.to_string(),
            kind: value.kind,
        }
    }
}



================================================
FILE: harper-core/src/irregular_nouns.rs
================================================
use serde::Deserialize;
use std::sync::{Arc, LazyLock};

type Noun = (String, String);

#[derive(Debug, Deserialize)]
pub struct IrregularNouns {
    nouns: Vec<Noun>,
}

/// The uncached function that is used to produce the original copy of the
/// irregular noun table.
fn uncached_inner_new() -> Arc<IrregularNouns> {
    IrregularNouns::from_json_file(include_str!("../irregular_nouns.json"))
        .map(Arc::new)
        .unwrap_or_else(|e| panic!("Failed to load irregular noun table: {}", e))
}

static NOUNS: LazyLock<Arc<IrregularNouns>> = LazyLock::new(uncached_inner_new);

impl IrregularNouns {
    pub fn new() -> Self {
        Self { nouns: vec![] }
    }

    pub fn from_json_file(json: &str) -> Result<Self, serde_json::Error> {
        // Deserialize into Vec<serde_json::Value> to handle mixed types
        let values: Vec<serde_json::Value> =
            serde_json::from_str(json).expect("Failed to parse irregular nouns JSON");

        let mut nouns = Vec::new();

        for value in values {
            match value {
                serde_json::Value::Array(arr) if arr.len() == 2 => {
                    // Handle array of 2 strings
                    if let (Some(singular), Some(plural)) = (arr[0].as_str(), arr[1].as_str()) {
                        nouns.push((singular.to_string(), plural.to_string()));
                    }
                }
                // Strings are used for comments to guide contributors editing the file
                serde_json::Value::String(_) => {}
                _ => {}
            }
        }

        Ok(Self { nouns })
    }

    pub fn curated() -> Arc<Self> {
        (*NOUNS).clone()
    }

    pub fn get_plural_for_singular(&self, singular: &str) -> Option<&str> {
        self.nouns
            .iter()
            .find(|(sg, _)| sg.eq_ignore_ascii_case(singular))
            .map(|(_, pl)| pl.as_str())
    }

    pub fn get_singular_for_plural(&self, plural: &str) -> Option<&str> {
        self.nouns
            .iter()
            .find(|(_, pl)| pl.eq_ignore_ascii_case(plural))
            .map(|(sg, _)| sg.as_str())
    }
}

impl Default for IrregularNouns {
    fn default() -> Self {
        Self::new()
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn can_find_irregular_plural_for_singular_lowercase() {
        assert_eq!(
            IrregularNouns::curated().get_plural_for_singular("man"),
            Some("men")
        );
    }

    #[test]
    fn can_find_irregular_plural_for_singular_uppercase() {
        assert_eq!(
            IrregularNouns::curated().get_plural_for_singular("WOMAN"),
            Some("women")
        );
    }

    #[test]
    fn can_find_singular_for_irregular_plural() {
        assert_eq!(
            IrregularNouns::curated().get_singular_for_plural("children"),
            Some("child")
        );
    }

    #[test]
    fn cant_find_regular_plural() {
        assert_eq!(
            IrregularNouns::curated().get_plural_for_singular("car"),
            None
        );
    }

    #[test]
    fn cant_find_non_noun() {
        assert_eq!(
            IrregularNouns::curated().get_plural_for_singular("the"),
            None
        );
    }
}



================================================
FILE: harper-core/src/irregular_verbs.rs
================================================
use serde::Deserialize;
use std::sync::{Arc, LazyLock};

type Verb = (String, String, String);

#[derive(Debug, Deserialize)]
pub struct IrregularVerbs {
    verbs: Vec<Verb>,
}

/// The uncached function that is used to produce the original copy of the
/// irregular verb table.
fn uncached_inner_new() -> Arc<IrregularVerbs> {
    IrregularVerbs::from_json_file(include_str!("../irregular_verbs.json"))
        .map(Arc::new)
        .unwrap_or_else(|e| panic!("Failed to load irregular verb table: {}", e))
}

static VERBS: LazyLock<Arc<IrregularVerbs>> = LazyLock::new(uncached_inner_new);

impl IrregularVerbs {
    pub fn new() -> Self {
        Self { verbs: vec![] }
    }

    pub fn from_json_file(json: &str) -> Result<Self, serde_json::Error> {
        // Deserialize into Vec<serde_json::Value> to handle mixed types
        let values: Vec<serde_json::Value> =
            serde_json::from_str(json).expect("Failed to parse irregular verbs JSON");

        let mut verbs = Vec::new();

        for value in values {
            match value {
                serde_json::Value::Array(arr) if arr.len() == 3 => {
                    // Handle array of 3 strings
                    if let (Some(lemma), Some(preterite), Some(past_participle)) =
                        (arr[0].as_str(), arr[1].as_str(), arr[2].as_str())
                    {
                        verbs.push((
                            lemma.to_string(),
                            preterite.to_string(),
                            past_participle.to_string(),
                        ));
                    }
                }
                // Strings are used for comments to guide contributors editing the file
                serde_json::Value::String(_) => {}
                _ => {}
            }
        }

        Ok(Self { verbs })
    }

    pub fn curated() -> Arc<Self> {
        (*VERBS).clone()
    }

    pub fn get_past_participle_for_preterite(&self, preterite: &str) -> Option<&str> {
        self.verbs
            .iter()
            .find(|(_, pt, _)| pt.eq_ignore_ascii_case(preterite))
            .map(|(_, _, pp)| pp.as_str())
    }
}

impl Default for IrregularVerbs {
    fn default() -> Self {
        Self::new()
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn can_find_irregular_past_participle_for_preterite_lowercase() {
        assert_eq!(
            IrregularVerbs::curated().get_past_participle_for_preterite("arose"),
            Some("arisen")
        );
    }

    #[test]
    fn can_find_irregular_past_participle_for_preterite_uppercase() {
        assert_eq!(
            IrregularVerbs::curated().get_past_participle_for_preterite("WENT"),
            Some("gone")
        );
    }

    #[test]
    fn can_find_irregular_past_participle_same_as_past_tense() {
        assert_eq!(
            IrregularVerbs::curated().get_past_participle_for_preterite("taught"),
            Some("taught")
        );
    }

    #[test]
    fn cant_find_regular_past_participle() {
        assert_eq!(
            IrregularVerbs::curated().get_past_participle_for_preterite("walked"),
            None
        );
    }

    #[test]
    fn cant_find_non_verb() {
        assert_eq!(
            IrregularVerbs::curated().get_past_participle_for_preterite("the"),
            None
        );
    }
}



================================================
FILE: harper-core/src/language_detection.rs
================================================
//! This module implements rudimentary, dictionary-based English language detection.

use crate::spell::Dictionary;
use crate::{Document, Token, TokenKind};

/// Check if the contents of the document are likely intended to represent
/// English.
pub fn is_doc_likely_english(doc: &Document, dict: &impl Dictionary) -> bool {
    is_likely_english(doc.get_tokens(), doc.get_source(), dict)
}

/// Check if given tokens are likely intended to represent English.
pub fn is_likely_english(toks: &[Token], source: &[char], dict: &impl Dictionary) -> bool {
    let mut total_words = 0;
    let mut valid_words = 0;
    let mut punctuation = 0;
    let mut unlintable = 0;

    for token in toks {
        match token.kind {
            TokenKind::Word(_) => {
                total_words += 1;

                let word_content = token.span.get_content(source);
                if dict.contains_word(word_content) {
                    valid_words += 1;
                }
            }
            TokenKind::Punctuation(_) => punctuation += 1,
            TokenKind::Unlintable => unlintable += 1,
            _ => (),
        }
    }

    if total_words <= 7 && total_words - valid_words > 0 {
        return false;
    }

    if unlintable > valid_words {
        return false;
    }

    if (punctuation as f32 * 1.25) > valid_words as f32 {
        return false;
    }

    if (valid_words as f64 / total_words as f64) < 0.7 {
        return false;
    }

    true
}

#[cfg(test)]
mod tests {
    use super::is_doc_likely_english;
    use crate::Document;
    use crate::spell::FstDictionary;

    fn assert_not_english(source: &'static str) {
        let dict = FstDictionary::curated();
        let doc = Document::new_plain_english(source, &dict);
        let is_likely_english = is_doc_likely_english(&doc, &dict);
        dbg!(source);
        assert!(!is_likely_english);
    }

    fn assert_english(source: &'static str) {
        let dict = FstDictionary::curated();
        let doc = Document::new_plain_english(source, &dict);
        let is_likely_english = is_doc_likely_english(&doc, &dict);
        dbg!(source);
        assert!(is_likely_english);
    }

    #[test]
    fn detects_spanish() {
        assert_not_english("Esto es español. Harper no debería marcarlo como inglés.");
    }

    #[test]
    fn detects_french() {
        assert_not_english(
            "C'est du français. Il ne devrait pas être marqué comme anglais par Harper.",
        );
    }

    #[test]
    fn detects_shebang() {
        assert_not_english("#! /bin/bash");
        assert_not_english("#! /usr/bin/fish");
    }

    #[test]
    fn detects_short_english() {
        assert_english("This is English!");
    }

    #[test]
    fn detects_english() {
        assert_english("This is perfectly valid English, evn if it has a cople typos.")
    }

    #[test]
    fn detects_expressive_english() {
        assert_english("Look above! That is real English! So is this: bippity bop!")
    }

    /// Useful for detecting commented-out code.
    #[test]
    fn detects_python_fib() {
        assert_not_english(
            r"
def fibIter(n):
    if n < 2:
        return n
    fibPrev = 1
    fib = 1
    for _ in range(2, n):
        fibPrev, fib = fib, fib + fibPrev
    return fib
        ",
        );
    }

    #[test]
    fn mixed_french_english_park() {
        assert_not_english("Je voudrais promener au the park a huit heures with ma voisine");
    }

    #[test]
    fn mixed_french_english_drunk() {
        assert_not_english("Je ne suis pas drunk, je suis only ivre by you");
    }

    #[test]
    fn mixed_french_english_dress() {
        assert_not_english(
            "Je buy une robe nouveau chaque Tuesday, mais aujourd'hui, je don't have temps",
        );
    }

    #[test]
    fn english_motto() {
        assert_english("I have a simple motto in life");
    }
}



================================================
FILE: harper-core/src/lib.rs
================================================
#![doc = include_str!("../README.md")]
#![allow(dead_code)]

mod case;
mod char_ext;
mod char_string;
mod currency;
mod dict_word_metadata;
mod dict_word_metadata_orthography;
mod document;
mod edit_distance;
pub mod expr;
mod fat_token;
mod ignored_lints;
mod irregular_nouns;
mod irregular_verbs;
pub mod language_detection;
mod lexing;
pub mod linting;
mod mask;
mod number;
pub mod parsers;
pub mod patterns;
mod punctuation;
mod render_markdown;
mod span;
pub mod spell;
mod sync;
mod thesaurus_helper;
mod title_case;
mod token;
mod token_kind;
mod token_string_ext;
mod vec_ext;
pub mod weir;

use render_markdown::render_markdown;
use std::collections::{BTreeMap, VecDeque};

pub use case::{Case, CaseIterExt};
pub use char_string::{CharString, CharStringExt};
pub use currency::Currency;
pub use dict_word_metadata::{
    AdverbData, ConjunctionData, Degree, DeterminerData, Dialect, DialectFlags, DictWordMetadata,
    NounData, PronounData, VerbData, VerbForm, VerbFormFlags,
};
pub use dict_word_metadata_orthography::{OrthFlags, Orthography};
pub use document::Document;
pub use fat_token::{FatStringToken, FatToken};
pub use ignored_lints::{IgnoredLints, LintContext};
pub use irregular_nouns::IrregularNouns;
pub use irregular_verbs::IrregularVerbs;
use linting::Lint;
pub use mask::{Mask, Masker};
pub use number::{Number, OrdinalSuffix};
pub use punctuation::{Punctuation, Quote};
pub use span::Span;
pub use sync::{LSend, Lrc};
pub use title_case::{make_title_case, make_title_case_str};
pub use token::Token;
pub use token_kind::TokenKind;
pub use token_string_ext::TokenStringExt;
pub use vec_ext::VecExt;

/// Return `harper-core` version
pub fn core_version() -> &'static str {
    env!("CARGO_PKG_VERSION")
}

/// A utility function that removes overlapping lints in a vector,
/// keeping the more important ones.
///
/// Note: this function will change the ordering of the lints.
pub fn remove_overlaps(lints: &mut Vec<Lint>) {
    if lints.len() < 2 {
        return;
    }

    let mut remove_indices = VecDeque::new();
    lints.sort_by_key(|l| (l.span.start, !0 - l.span.end));

    let mut cur = 0;

    for (i, lint) in lints.iter().enumerate() {
        if lint.span.start < cur {
            remove_indices.push_back(i);
            continue;
        }
        cur = lint.span.end;
    }

    lints.remove_indices(remove_indices);
}

/// Remove overlapping lints from a map keyed by rule name, similar to [`remove_overlaps`].
///
/// The map is treated as if all contained lints were in a single flat collection, ensuring the
/// same lint would be kept regardless of whether it originated from `lint` or `organized_lints`.
pub fn remove_overlaps_map<K: Ord>(lint_map: &mut BTreeMap<K, Vec<Lint>>) {
    let total: usize = lint_map.values().map(Vec::len).sum();
    if total < 2 {
        return;
    }

    struct IndexedSpan {
        rule_idx: usize,
        lint_idx: usize,
        start: usize,
        end: usize,
    }

    let mut removal_flags: Vec<Vec<bool>> = lint_map
        .values()
        .map(|lints| vec![false; lints.len()])
        .collect();

    let mut spans = Vec::with_capacity(total);
    for (rule_idx, (_, lints)) in lint_map.iter().enumerate() {
        for (lint_idx, lint) in lints.iter().enumerate() {
            spans.push(IndexedSpan {
                rule_idx,
                lint_idx,
                start: lint.span.start,
                end: lint.span.end,
            });
        }
    }

    spans.sort_by_key(|span| (span.start, usize::MAX - span.end));

    let mut cur = 0;
    for span in spans {
        if span.start < cur {
            removal_flags[span.rule_idx][span.lint_idx] = true;
        } else {
            cur = span.end;
        }
    }

    for (rule_idx, (_, lints)) in lint_map.iter_mut().enumerate() {
        if removal_flags[rule_idx].iter().all(|flag| !*flag) {
            continue;
        }

        let mut idx = 0;
        lints.retain(|_| {
            let remove = removal_flags[rule_idx][idx];
            idx += 1;
            !remove
        });
    }
}

#[cfg(test)]
mod tests {
    use crate::spell::FstDictionary;
    use crate::{
        Dialect, Document,
        linting::{LintGroup, Linter},
        remove_overlaps,
    };

    #[test]
    fn keeps_space_lint() {
        let doc = Document::new_plain_english_curated("Ths  tet");

        let mut linter = LintGroup::new_curated(FstDictionary::curated(), Dialect::American);

        let mut lints = linter.lint(&doc);

        dbg!(&lints);
        remove_overlaps(&mut lints);
        dbg!(&lints);

        assert_eq!(lints.len(), 3);
    }
}



================================================
FILE: harper-core/src/number.rs
================================================
use std::fmt::Display;

use is_macro::Is;
use itertools::Itertools;
use ordered_float::OrderedFloat;
use serde::{Deserialize, Serialize};

/// Represents a written number.
#[derive(Debug, Serialize, Deserialize, Clone, Copy, Default, PartialEq, Eq, Hash, PartialOrd)]
pub struct Number {
    /// The actual value of the number
    pub value: OrderedFloat<f64>,
    /// Whether it contains a suffix (like the 1__st__ element).
    pub suffix: Option<OrdinalSuffix>,
    /// What base it is in (hex v.s. decimal, for example).
    pub radix: u32,
    /// The level of precision the number is formatted with.
    pub precision: usize,
}

impl Display for Number {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        if self.radix == 16 {
            write!(f, "0x{:X}", self.value.0 as u64)?;
        } else {
            write!(f, "{:.*}", self.precision, self.value.0)?;
        }

        if let Some(suffix) = self.suffix {
            for c in suffix.to_chars() {
                write!(f, "{c}")?;
            }
        }

        Ok(())
    }
}

#[derive(
    Debug, Serialize, Deserialize, Default, PartialEq, PartialOrd, Clone, Copy, Is, Hash, Eq,
)]
pub enum OrdinalSuffix {
    #[default]
    Th,
    St,
    Nd,
    Rd,
}

impl OrdinalSuffix {
    pub fn correct_suffix_for(number: impl Into<f64>) -> Option<Self> {
        let number = number.into();

        if number < 0.0 || number - number.floor() > f64::EPSILON || number > u64::MAX as f64 {
            return None;
        }

        let integer = number as u64;

        if let 11..=13 = integer % 100 {
            return Some(Self::Th);
        };

        Some(match integer % 10 {
            0 | 4..=9 => Self::Th,
            1 => Self::St,
            2 => Self::Nd,
            3 => Self::Rd,
            _ => unreachable!(),
        })
    }

    pub const fn to_chars(self) -> &'static [char] {
        match self {
            OrdinalSuffix::Th => &['t', 'h'],
            OrdinalSuffix::St => &['s', 't'],
            OrdinalSuffix::Nd => &['n', 'd'],
            OrdinalSuffix::Rd => &['r', 'd'],
        }
    }

    /// Check the characters in a buffer to see if it matches a number suffix.
    pub fn from_chars(chars: &[char]) -> Option<Self> {
        let lower_chars: [char; 2] = chars.iter().map(char::to_ascii_lowercase).collect_array()?;

        match lower_chars {
            ['t', 'h'] => Some(OrdinalSuffix::Th),
            ['s', 't'] => Some(OrdinalSuffix::St),
            ['n', 'd'] => Some(OrdinalSuffix::Nd),
            ['r', 'd'] => Some(OrdinalSuffix::Rd),
            _ => None,
        }
    }
}

#[cfg(test)]
mod tests {
    use itertools::Itertools;
    use ordered_float::OrderedFloat;

    use crate::OrdinalSuffix;

    use super::Number;

    #[test]
    fn hex_fifteen() {
        assert_eq!(
            Number {
                value: OrderedFloat(15.0),
                suffix: None,
                radix: 16,
                precision: 0
            }
            .to_string(),
            "0xF"
        )
    }

    #[test]
    fn decimal_fifteen() {
        assert_eq!(
            Number {
                value: OrderedFloat(15.0),
                suffix: None,
                radix: 10,
                precision: 0
            }
            .to_string(),
            "15"
        )
    }

    #[test]
    fn decimal_fifteen_suffix() {
        assert_eq!(
            Number {
                value: OrderedFloat(15.0),
                suffix: Some(OrdinalSuffix::Th),
                radix: 10,
                precision: 0
            }
            .to_string(),
            "15th"
        )
    }

    #[test]
    fn decimal_fifteen_and_a_half() {
        assert_eq!(
            Number {
                value: OrderedFloat(15.5),
                suffix: None,
                radix: 10,
                precision: 2
            }
            .to_string(),
            "15.50"
        )
    }

    #[test]
    fn issue_1051() {
        let word = "story".chars().collect_vec();
        assert_eq!(None, OrdinalSuffix::from_chars(&word));
    }
}



================================================
FILE: harper-core/src/punctuation.rs
================================================
use is_macro::Is;
use serde::{Deserialize, Serialize};

use crate::Currency;

#[derive(
    Debug, Is, Clone, Copy, Serialize, Deserialize, PartialEq, Eq, PartialOrd, Default, Hash,
)]
#[serde(tag = "kind")]
pub enum Punctuation {
    /// `°`
    Degree,
    /// `…`
    Ellipsis,
    /// `–`
    EnDash,
    /// `—`
    EmDash,
    /// `&`
    Ampersand,
    /// `.`
    #[default]
    Period,
    /// `!`
    Bang,
    /// `?`
    Question,
    /// `:`
    Colon,
    /// ``;``
    Semicolon,
    /// `"`
    Quote(Quote),
    /// `,`
    Comma,
    /// `-`
    Hyphen,
    /// `[`
    OpenSquare,
    /// `]`
    CloseSquare,
    /// `(`
    OpenRound,
    /// `)`
    CloseRound,
    /// `{`
    OpenCurly,
    /// `}`
    CloseCurly,
    /// `"`
    Hash,
    /// `'`
    Apostrophe,
    /// `%`
    Percent,
    /// `/`
    ForwardSlash,
    /// `\`
    Backslash,
    /// `<`
    LessThan,
    /// `>`
    GreaterThan,
    /// `=`
    Equal,
    /// `*`
    Star,
    /// `~`
    Tilde,
    /// `@`
    At,
    /// `^`
    Caret,
    /// `+`
    Plus,
    Currency(Currency),
    /// `|`
    Pipe,
    /// `_`
    Underscore,
}

impl Punctuation {
    pub fn from_char(c: char) -> Option<Punctuation> {
        let punct = match c {
            '@' => Punctuation::At,
            '~' => Punctuation::Tilde,
            '°' => Punctuation::Degree,
            '=' => Punctuation::Equal,
            '<' => Punctuation::LessThan,
            '>' => Punctuation::GreaterThan,
            '/' => Punctuation::ForwardSlash,
            '\\' => Punctuation::Backslash,
            '%' => Punctuation::Percent,
            '’' => Punctuation::Apostrophe,
            '\'' => Punctuation::Apostrophe,
            '.' => Punctuation::Period,
            '!' => Punctuation::Bang,
            '?' => Punctuation::Question,
            ':' => Punctuation::Colon,
            ';' => Punctuation::Semicolon,
            ',' => Punctuation::Comma,
            '、' => Punctuation::Comma,
            '，' => Punctuation::Comma,
            '-' => Punctuation::Hyphen,
            '[' => Punctuation::OpenSquare,
            ']' => Punctuation::CloseSquare,
            '{' => Punctuation::OpenCurly,
            '}' => Punctuation::CloseCurly,
            '(' => Punctuation::OpenRound,
            ')' => Punctuation::CloseRound,
            '#' => Punctuation::Hash,
            '*' => Punctuation::Star,
            '&' => Punctuation::Ampersand,
            '–' => Punctuation::EnDash,
            '—' => Punctuation::EmDash,
            '…' => Punctuation::Ellipsis,
            '^' => Punctuation::Caret,
            '+' => Punctuation::Plus,
            '|' => Punctuation::Pipe,
            '_' => Punctuation::Underscore,
            _ => Punctuation::Currency(Currency::from_char(c)?),
        };

        Some(punct)
    }
}

#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize, PartialOrd, Hash)]
pub struct Quote {
    /// The location of the matching quote, if it exists.
    pub twin_loc: Option<usize>,
}



================================================
FILE: harper-core/src/render_markdown.rs
================================================
use ammonia::clean;
use pulldown_cmark::{Options, Parser, html};

/// The standard Markdown rendering function for the crate.
/// Do not call `pulldown_cmark` directly. Use this.
pub fn render_markdown(markdown: &str) -> String {
    let parser = Parser::new_ext(markdown, Options::all());
    let mut html = String::new();
    html::push_html(&mut html, parser);
    clean(&html)
}



================================================
FILE: harper-core/src/span.rs
================================================
use std::{fmt::Display, marker::PhantomData, ops::Range};

use serde::{Deserialize, Serialize};

use crate::Token;

/// A window in a `T` sequence.
///
/// Note that the range covered by a [`Span`] is end-exclusive, meaning that the end index is not
/// included in the range covered by the [`Span`]. If you're familiar with the Rust range syntax,
/// you could say the span covers the equivalent of `start..end`, *not* `start..=end`.
///
/// For a [`Span`] to be correct, its end index must be greater than or equal to its start
/// index. Creating or using a [`Span`] which does not follow this rule may lead to unexpected
/// behavior or panics.
///
/// Although specific to `harper.js`, [this page may clear up any questions you have](https://writewithharper.com/docs/harperjs/spans).
#[derive(Debug, Serialize, Deserialize, Default, PartialEq, Eq)]
pub struct Span<T> {
    /// The start index of the span.
    pub start: usize,
    /// The end index of the span.
    ///
    /// Note that [`Span`] represents an exclusive range. This means that a `Span::new(0, 5)` will
    /// cover the values `0, 1, 2, 3, 4`; it will not cover the `5`.
    pub end: usize,
    #[serde(skip)]
    span_type: PhantomData<T>,
}

impl<T> Span<T> {
    /// A [`Span`] with a start and end index of 0.
    pub const ZERO: Self = Self::empty(0);

    /// Creates a new [`Span`] with the provided start and end indices.
    ///
    /// # Panics
    ///
    /// This will panic if `start` is greater than `end`.
    pub fn new(start: usize, end: usize) -> Self {
        if start > end {
            panic!("{start} > {end}");
        }
        Self {
            start,
            end,
            span_type: PhantomData,
        }
    }

    /// Creates a new [`Span`] from the provided start position and length.
    pub fn new_with_len(start: usize, len: usize) -> Self {
        Self {
            start,
            end: start + len,
            span_type: PhantomData,
        }
    }

    /// Creates a new empty [`Span`] with the provided position.
    pub const fn empty(pos: usize) -> Self {
        Self {
            start: pos,
            end: pos,
            span_type: PhantomData,
        }
    }

    /// The length of the [`Span`].
    pub fn len(&self) -> usize {
        self.end - self.start
    }

    /// Checks whether the [`Span`] is empty.
    ///
    /// A [`Span`] is considered empty if it has a length of 0.
    pub fn is_empty(&self) -> bool {
        self.len() == 0
    }

    /// Checks whether `idx` is within the range of the span.
    pub fn contains(&self, idx: usize) -> bool {
        self.start <= idx && idx < self.end
    }

    /// Checks whether this span's range overlaps with `other`.
    pub fn overlaps_with(&self, other: Self) -> bool {
        (self.start < other.end) && (other.start < self.end)
    }

    /// Get the associated content. Will return [`None`] if the span is non-empty and any aspect is
    /// invalid.
    pub fn try_get_content<'a>(&self, source: &'a [T]) -> Option<&'a [T]> {
        if self.is_empty() {
            Some(&source[0..0])
        } else {
            source.get(self.start..self.end)
        }
    }

    /// Expand the span by either modifying [`Self::start`] or [`Self::end`] to include the target
    /// index.
    ///
    /// Does nothing if the span already includes the target.
    pub fn expand_to_include(&mut self, target: usize) {
        if target < self.start {
            self.start = target;
        } else if target >= self.end {
            self.end = target + 1;
        }
    }

    /// Get the associated content. Will panic if any aspect is invalid.
    pub fn get_content<'a>(&self, source: &'a [T]) -> &'a [T] {
        match self.try_get_content(source) {
            Some(v) => v,
            None => panic!("Failed to get content for span."),
        }
    }

    /// Set the span's length.
    pub fn set_len(&mut self, length: usize) {
        self.end = self.start + length;
    }

    /// Returns a copy of this [`Span`] with a new length.
    pub fn with_len(&self, length: usize) -> Self {
        let mut cloned = *self;
        cloned.set_len(length);
        cloned
    }

    /// Add an amount to both [`Self::start`] and [`Self::end`]
    pub fn push_by(&mut self, by: usize) {
        self.start += by;
        self.end += by;
    }

    /// Subtract an amount from both [`Self::start`] and [`Self::end`]
    pub fn pull_by(&mut self, by: usize) {
        self.start -= by;
        self.end -= by;
    }

    /// Add an amount to a copy of both [`Self::start`] and [`Self::end`]
    pub fn pushed_by(&self, by: usize) -> Self {
        let mut clone = *self;
        clone.start += by;
        clone.end += by;
        clone
    }

    /// Subtract an amount to a copy of both [`Self::start`] and [`Self::end`]
    pub fn pulled_by(&self, by: usize) -> Option<Self> {
        if by > self.start {
            return None;
        }

        let mut clone = *self;
        clone.start -= by;
        clone.end -= by;
        Some(clone)
    }
}

/// Additional functions for types that implement [`std::fmt::Debug`] and [`Display`].
impl<T: Display + std::fmt::Debug> Span<T> {
    /// Gets the content of this [`Span<T>`] as a [`String`].
    pub fn get_content_string(&self, source: &[T]) -> String {
        if let Some(content) = self.try_get_content(source) {
            content.iter().map(|t| t.to_string()).collect()
        } else {
            panic!("Could not get position {self:?} within \"{source:?}\"")
        }
    }
}

/// Functionality specific to [`Token`] spans.
impl Span<Token> {
    /// Converts the [`Span<Token>`] into a [`Span<char>`].
    ///
    /// This requires knowing the character spans of the tokens covered by this
    /// [`Span<Token>`]. Because of this, a reference to the source token sequence used to create
    /// this span is required.
    pub fn to_char_span(&self, source_document_tokens: &[Token]) -> Span<char> {
        if self.is_empty() {
            Span::ZERO
        } else {
            let target_tokens = &source_document_tokens[self.start..self.end];
            Span::new(
                target_tokens.first().unwrap().span.start,
                target_tokens.last().unwrap().span.end,
            )
        }
    }
}

impl<T> From<Range<usize>> for Span<T> {
    /// Reinterprets the provided [`std::ops::Range`] as a [`Span`].
    fn from(value: Range<usize>) -> Self {
        Self::new(value.start, value.end)
    }
}

impl<T> From<Span<T>> for Range<usize> {
    /// Converts the [`Span`] to an [`std::ops::Range`].
    fn from(value: Span<T>) -> Self {
        value.start..value.end
    }
}

impl<T> IntoIterator for Span<T> {
    type Item = usize;

    type IntoIter = Range<usize>;

    /// Converts the [`Span`] into an iterator that yields the indices covered by its range.
    ///
    /// Note that [`Span`] is half-open, meaning that the value [`Self::end`] will not be yielded
    /// by this iterator: it will stop at the index immediately preceding [`Self::end`].
    fn into_iter(self) -> Self::IntoIter {
        self.start..self.end
    }
}

impl<T> Clone for Span<T> {
    // Note: manual implementation so we don't unnecessarily require `T` to impl `Clone`.
    fn clone(&self) -> Self {
        *self
    }
}
impl<T> Copy for Span<T> {}

#[cfg(test)]
mod tests {
    use crate::{
        Document,
        expr::{ExprExt, SequenceExpr},
    };

    use super::Span;

    type UntypedSpan = Span<()>;

    #[test]
    fn overlaps() {
        assert!(UntypedSpan::new(0, 5).overlaps_with(UntypedSpan::new(3, 6)));
        assert!(UntypedSpan::new(0, 5).overlaps_with(UntypedSpan::new(2, 3)));
        assert!(UntypedSpan::new(0, 5).overlaps_with(UntypedSpan::new(4, 5)));
        assert!(UntypedSpan::new(0, 5).overlaps_with(UntypedSpan::new(4, 4)));

        assert!(!UntypedSpan::new(0, 3).overlaps_with(UntypedSpan::new(3, 5)));
    }

    #[test]
    fn expands_properly() {
        let mut span = UntypedSpan::new(2, 2);

        span.expand_to_include(1);
        assert_eq!(span, UntypedSpan::new(1, 2));

        span.expand_to_include(2);
        assert_eq!(span, UntypedSpan::new(1, 3));
    }

    #[test]
    fn to_char_span_converts_correctly() {
        let doc = Document::new_plain_english_curated("Hello world!");

        // Empty span.
        let token_span = Span::ZERO;
        let converted = token_span.to_char_span(doc.get_tokens());
        assert!(converted.is_empty());

        // Span from `Expr`.
        let token_span = SequenceExpr::default()
            .then_any_word()
            .t_ws()
            .then_any_word()
            .iter_matches_in_doc(&doc)
            .next()
            .unwrap();
        let converted = token_span.to_char_span(doc.get_tokens());
        assert_eq!(
            converted.get_content_string(doc.get_source()),
            "Hello world"
        );
    }
}



================================================
FILE: harper-core/src/sync.rs
================================================
#[cfg(not(feature = "concurrent"))]
pub use std::rc::Rc as Lrc;
#[cfg(feature = "concurrent")]
pub use std::sync::Arc as Lrc;

#[cfg(not(feature = "concurrent"))]
pub trait LSend {}

#[cfg(not(feature = "concurrent"))]
impl<T: ?Sized> LSend for T {}

#[cfg(feature = "concurrent")]
pub trait LSend: Send + Sync {}

#[cfg(feature = "concurrent")]
impl<T: Send + Sync + ?Sized> LSend for T {}



================================================
FILE: harper-core/src/thesaurus_helper.rs
================================================
use crate::{
    TokenKind,
    linting::{Suggestion, SuggestionCollectionExt},
};

#[cfg(feature = "thesaurus")]
use crate::spell::{Dictionary, FstDictionary};

/// Gets synonyms for a provided word.
///
/// If the `thesaurus` feature is not enabled, will always return [`None`].
#[allow(unreachable_code)]
pub fn get_synonyms(_word: &str) -> Option<Vec<&str>> {
    #[cfg(feature = "thesaurus")]
    {
        return harper_thesaurus::thesaurus().get_synonyms(_word);
    }
    None
}

/// Gets synonyms for a provided word, sorted by the following means:
/// - The level of difference between the provided token and that of the synonym.
/// - How often the synonym is used.
///
/// If the `thesaurus` feature is not enabled, will always return [`None`].
#[allow(unreachable_code)]
pub fn get_synonyms_sorted(_word: &str, _token: &TokenKind) -> Option<Vec<&'static str>> {
    #[cfg(feature = "thesaurus")]
    {
        // Sorting by frequency.
        let mut syns = harper_thesaurus::thesaurus().get_synonyms_freq_sorted(_word)?;

        // Sorting by TokenKind difference.
        if let Some(Some(word_meta)) = _token.as_word() {
            let dict = FstDictionary::curated();
            syns.sort_by_key(|syn| {
                if let Some(syn_meta) = dict.get_word_metadata_str(syn) {
                    word_meta.difference(&syn_meta)
                } else {
                    u32::MAX
                }
            });
        }

        return Some(syns);
    }
    None
}

/// Helper method to provide synonym replacement suggestions for the provided word.
///
/// The output is sorted as in [`get_synonyms_sorted()`], which attempts to place more relevant
/// results first.
///
/// If the `thesaurus` feature isn't enabled or the word cannot be found in the thesaurus, will
/// return an empty iterator.
pub fn get_synonym_replacement_suggestions(
    word: &str,
    token: &TokenKind,
) -> impl Iterator<Item = Suggestion> {
    get_synonyms_sorted(word, token)
        .unwrap_or_default()
        .to_replace_suggestions(word.chars())
}



================================================
FILE: harper-core/src/title_case.rs
================================================
use std::borrow::Cow;
use std::sync::LazyLock;

use crate::Lrc;
use crate::Token;
use crate::TokenKind;
use hashbrown::HashSet;

use crate::Punctuation;
use crate::spell::Dictionary;
use crate::{CharStringExt, Document, TokenStringExt, parsers::Parser};

/// A helper function for [`make_title_case`] that uses Strings instead of char buffers.
pub fn make_title_case_str(source: &str, parser: &impl Parser, dict: &impl Dictionary) -> String {
    let source: Vec<char> = source.chars().collect();

    make_title_case_chars(Lrc::new(source), parser, dict).to_string()
}

// Make a given string [title case](https://en.wikipedia.org/wiki/Title_case) following the Chicago Manual of Style.
pub fn make_title_case_chars(
    source: Lrc<Vec<char>>,
    parser: &impl Parser,
    dict: &impl Dictionary,
) -> Vec<char> {
    let document = Document::new_from_vec(source.clone(), parser, dict);

    make_title_case(document.get_tokens(), source.as_slice(), dict)
}

pub fn try_make_title_case(
    toks: &[Token],
    source: &[char],
    dict: &impl Dictionary,
) -> Option<Vec<char>> {
    if toks.is_empty() {
        return None;
    }

    let start_index = toks.first().unwrap().span.start;
    let relevant_text = toks.span().unwrap().get_content(source);

    let mut word_likes = toks.iter_word_like_indices().enumerate().peekable();

    let mut output = None;
    let mut previous_word_index = 0;

    // Checks if the output if the provided char is different from the source. If so, it will
    // set the output. The goal here is to avoid allocating if no edits must be made.
    let mut set_output_char = |idx: usize, new_char: char| {
        if output
            .as_ref()
            .is_some_and(|o: &Vec<char>| o[idx] != new_char)
            || relevant_text[idx] != new_char
        {
            if output.is_none() {
                output = Some(relevant_text.to_vec())
            }

            let Some(mutable) = &mut output else {
                panic!("We just set output to `Some`. This should be impossible.");
            };

            mutable[idx] = new_char;
        }
    };

    while let Some((index, word_idx)) = word_likes.next() {
        let word = &toks[word_idx];

        if let Some(Some(metadata)) = word.kind.as_word()
            && metadata.is_proper_noun()
        {
            // Replace it with the dictionary entry verbatim.
            let orig_text = word.span.get_content(source);

            if let Some(correct_caps) = dict.get_correct_capitalization_of(orig_text) {
                // It should match the dictionary verbatim
                for (i, c) in correct_caps.iter().enumerate() {
                    if c.is_alphabetic() {
                        set_output_char(word.span.start - start_index + i, *c);
                    }
                }
            }
        };

        // Capitalize the first word following a colon to match Chicago style.
        let is_after_colon = toks[previous_word_index..word_idx]
            .iter()
            .any(|tok| matches!(tok.kind, TokenKind::Punctuation(Punctuation::Colon)));

        let should_capitalize = is_after_colon
            || should_capitalize_token(word, source)
            || index == 0
            || word_likes.peek().is_none();

        if should_capitalize {
            set_output_char(
                word.span.start - start_index,
                relevant_text[word.span.start - start_index].to_ascii_uppercase(),
            );
        } else {
            // The whole word should be lowercase.
            for i in word.span {
                set_output_char(
                    i - start_index,
                    relevant_text[i - start_index].to_ascii_lowercase(),
                );
            }
        }

        previous_word_index = word_idx
    }

    if let Some(output) = &output
        && output.as_slice() == relevant_text
    {
        return None;
    }

    output
}

pub fn make_title_case(toks: &[Token], source: &[char], dict: &impl Dictionary) -> Vec<char> {
    try_make_title_case(toks, source, dict)
        .unwrap_or_else(|| toks.span().unwrap_or_default().get_content(source).to_vec())
}

/// Determines whether a token should be capitalized.
/// Is not responsible for capitalization requirements that are dependent on token position.
fn should_capitalize_token(tok: &Token, source: &[char]) -> bool {
    match &tok.kind {
        TokenKind::Word(Some(metadata)) => {
            // Only specific conjunctions are not capitalized.
            static SPECIAL_CONJUNCTIONS: LazyLock<HashSet<Vec<char>>> = LazyLock::new(|| {
                ["and", "but", "for", "or", "nor", "as"]
                    .iter()
                    .map(|v| v.chars().collect())
                    .collect()
            });
            static SPECIAL_ARTICLES: LazyLock<HashSet<Vec<char>>> = LazyLock::new(|| {
                ["a", "an", "the"]
                    .iter()
                    .map(|v| v.chars().collect())
                    .collect()
            });

            let chars = tok.span.get_content(source);
            let chars_lower = chars.to_lower();

            let metadata = Cow::Borrowed(metadata);

            let is_short_preposition = metadata.preposition && tok.span.len() <= 4;

            if chars_lower.as_ref() == ['a', 'l', 'l'] {
                return true;
            }

            !is_short_preposition
                && !metadata.is_non_possessive_determiner()
                && !SPECIAL_CONJUNCTIONS.contains(chars_lower.as_ref())
                && !SPECIAL_ARTICLES.contains(chars_lower.as_ref())
        }
        _ => true,
    }
}

#[cfg(test)]
mod tests {
    use quickcheck::TestResult;
    use quickcheck_macros::quickcheck;

    use super::make_title_case_str;
    use crate::parsers::{Markdown, PlainEnglish};
    use crate::spell::FstDictionary;

    #[test]
    fn normal() {
        assert_eq!(
            make_title_case_str("this is a test", &PlainEnglish, &FstDictionary::curated()),
            "This Is a Test"
        )
    }

    #[test]
    fn complex() {
        assert_eq!(
            make_title_case_str(
                "the first and last words should be capitalized, even if it is \"the\"",
                &PlainEnglish,
                &FstDictionary::curated()
            ),
            "The First and Last Words Should Be Capitalized, Even If It Is \"The\""
        )
    }

    /// Check that "about" remains uppercase
    #[test]
    fn about_uppercase_with_numbers() {
        assert_eq!(
            make_title_case_str("0 about 0", &PlainEnglish, &FstDictionary::curated()),
            "0 About 0"
        )
    }

    #[test]
    fn pipe_does_not_cause_crash() {
        assert_eq!(
            make_title_case_str("|", &Markdown::default(), &FstDictionary::curated()),
            "|"
        )
    }

    #[test]
    fn a_paragraph_does_not_cause_crash() {
        assert_eq!(
            make_title_case_str("A\n", &Markdown::default(), &FstDictionary::curated()),
            "A"
        )
    }

    #[test]
    fn tab_a_becomes_upcase() {
        assert_eq!(
            make_title_case_str("\ta", &PlainEnglish, &FstDictionary::curated()),
            "\tA"
        )
    }

    #[test]
    fn fixes_video_press() {
        assert_eq!(
            make_title_case_str("videopress", &PlainEnglish, &FstDictionary::curated()),
            "VideoPress"
        )
    }

    #[quickcheck]
    fn a_stays_lowercase(prefix: String, postfix: String) -> TestResult {
        // There must be words other than the `a`.
        if prefix.chars().any(|c| !c.is_ascii_alphanumeric())
            || prefix.is_empty()
            || postfix.chars().any(|c| !c.is_ascii_alphanumeric())
            || postfix.is_empty()
        {
            return TestResult::discard();
        }

        let title_case: Vec<_> = make_title_case_str(
            &format!("{prefix} a {postfix}"),
            &Markdown::default(),
            &FstDictionary::curated(),
        )
        .chars()
        .collect();

        TestResult::from_bool(title_case[prefix.chars().count() + 1] == 'a')
    }

    #[quickcheck]
    fn about_becomes_uppercase(prefix: String, postfix: String) -> TestResult {
        // There must be words other than the `a`.
        if prefix.chars().any(|c| !c.is_ascii_alphanumeric())
            || prefix.is_empty()
            || postfix.chars().any(|c| !c.is_ascii_alphanumeric())
            || postfix.is_empty()
        {
            return TestResult::discard();
        }

        let title_case: Vec<_> = make_title_case_str(
            &format!("{prefix} about {postfix}"),
            &Markdown::default(),
            &FstDictionary::curated(),
        )
        .chars()
        .collect();

        TestResult::from_bool(title_case[prefix.chars().count() + 1] == 'A')
    }

    #[quickcheck]
    fn first_word_is_upcase(text: String) -> TestResult {
        let title_case: Vec<_> =
            make_title_case_str(&text, &PlainEnglish, &FstDictionary::curated())
                .chars()
                .collect();

        if let Some(first) = title_case.first() {
            if first.is_ascii_alphabetic() {
                TestResult::from_bool(first.is_ascii_uppercase())
            } else {
                TestResult::discard()
            }
        } else {
            TestResult::discard()
        }
    }

    #[test]
    fn united_states() {
        assert_eq!(
            make_title_case_str("united states", &PlainEnglish, &FstDictionary::curated()),
            "United States"
        )
    }

    #[test]
    fn keeps_decimal() {
        assert_eq!(
            make_title_case_str(
                "harper turns 1.0 today",
                &PlainEnglish,
                &FstDictionary::curated()
            ),
            "Harper Turns 1.0 Today"
        )
    }

    #[test]
    fn fixes_odd_capitalized_proper_nouns() {
        assert_eq!(
            make_title_case_str(
                "i spoke at wordcamp u.s. in 2025",
                &PlainEnglish,
                &FstDictionary::curated()
            ),
            "I Spoke at WordCamp U.S. in 2025",
        );
    }

    #[test]
    fn fixes_your_correctly() {
        assert_eq!(
            make_title_case_str(
                "it is not your friend",
                &PlainEnglish,
                &FstDictionary::curated()
            ),
            "It Is Not Your Friend",
        );
    }

    #[test]
    fn handles_old_man_and_the_sea() {
        assert_eq!(
            make_title_case_str(
                "the old man and the sea",
                &PlainEnglish,
                &FstDictionary::curated()
            ),
            "The Old Man and the Sea",
        );
    }

    #[test]
    fn handles_great_story_with_subtitle() {
        assert_eq!(
            make_title_case_str(
                "the great story: a tale of two cities",
                &PlainEnglish,
                &FstDictionary::curated()
            ),
            "The Great Story: A Tale of Two Cities",
        );
    }

    #[test]
    fn handles_lantern_and_moths() {
        assert_eq!(
            make_title_case_str(
                "lantern flickered; moths began their worship",
                &PlainEnglish,
                &FstDictionary::curated()
            ),
            "Lantern Flickered; Moths Began Their Worship",
        );
    }

    #[test]
    fn handles_static_with_ghosts() {
        assert_eq!(
            make_title_case_str(
                "static filled the room with ghosts",
                &PlainEnglish,
                &FstDictionary::curated()
            ),
            "Static Filled the Room with Ghosts",
        );
    }

    #[test]
    fn handles_glass_trembled_before_thunder() {
        assert_eq!(
            make_title_case_str(
                "glass trembled before thunder arrived.",
                &PlainEnglish,
                &FstDictionary::curated()
            ),
            "Glass Trembled Before Thunder Arrived.",
        );
    }

    #[test]
    fn handles_hepatitis_b_shots() {
        assert_eq!(
            make_title_case_str(
                "an end to hepatitis b shots for all newborns",
                &PlainEnglish,
                &FstDictionary::curated()
            ),
            "An End to Hepatitis B Shots for All Newborns",
        );
    }

    #[test]
    fn handles_trump_approval_rating() {
        assert_eq!(
            make_title_case_str(
                "trump's approval rating dips as views of his handling of the economy sour",
                &PlainEnglish,
                &FstDictionary::curated()
            ),
            "Trump's Approval Rating Dips as Views of His Handling of the Economy Sour",
        );
    }

    #[test]
    fn handles_last_door() {
        assert_eq!(
            make_title_case_str("the last door", &PlainEnglish, &FstDictionary::curated()),
            "The Last Door",
        );
    }

    #[test]
    fn handles_midnight_river() {
        assert_eq!(
            make_title_case_str("midnight river", &PlainEnglish, &FstDictionary::curated()),
            "Midnight River",
        );
    }

    #[test]
    fn handles_a_quiet_room() {
        assert_eq!(
            make_title_case_str("a quiet room", &PlainEnglish, &FstDictionary::curated()),
            "A Quiet Room",
        );
    }

    #[test]
    fn handles_broken_map() {
        assert_eq!(
            make_title_case_str("broken map", &PlainEnglish, &FstDictionary::curated()),
            "Broken Map",
        );
    }

    #[test]
    fn handles_fire_in_autumn() {
        assert_eq!(
            make_title_case_str("fire in autumn", &PlainEnglish, &FstDictionary::curated()),
            "Fire in Autumn",
        );
    }

    #[test]
    fn handles_hidden_path() {
        assert_eq!(
            make_title_case_str("the hidden path", &PlainEnglish, &FstDictionary::curated()),
            "The Hidden Path",
        );
    }

    #[test]
    fn handles_under_blue_skies() {
        assert_eq!(
            make_title_case_str("under blue skies", &PlainEnglish, &FstDictionary::curated()),
            "Under Blue Skies",
        );
    }

    #[test]
    fn handles_lost_and_found() {
        assert_eq!(
            make_title_case_str("lost and found", &PlainEnglish, &FstDictionary::curated()),
            "Lost and Found",
        );
    }

    #[test]
    fn handles_silent_watcher() {
        assert_eq!(
            make_title_case_str(
                "the silent watcher",
                &PlainEnglish,
                &FstDictionary::curated()
            ),
            "The Silent Watcher",
        );
    }

    #[test]
    fn handles_winter_road() {
        assert_eq!(
            make_title_case_str("winter road", &PlainEnglish, &FstDictionary::curated()),
            "Winter Road",
        );
    }

    #[test]
    fn maintains_same_apostrophe_type() {
        assert_eq!(
            make_title_case_str(
                "Alice’s Adventures in Wonderland",
                &PlainEnglish,
                &FstDictionary::curated()
            ),
            "Alice’s Adventures in Wonderland",
        );
    }
}



================================================
FILE: harper-core/src/token.rs
================================================
use serde::{Deserialize, Serialize};

use crate::{FatToken, Span, TokenKind};

/// Represents a semantic, parsed component of a [`Document`](crate::Document).
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Default)]
pub struct Token {
    /// The characters the token represents.
    pub span: Span<char>,
    /// The parsed value.
    pub kind: TokenKind,
}

impl Token {
    pub fn new(span: Span<char>, kind: TokenKind) -> Self {
        Self { span, kind }
    }

    /// Convert to an allocated [`FatToken`].
    pub fn to_fat(&self, source: &[char]) -> FatToken {
        let content = self.span.get_content(source).to_vec();

        FatToken {
            content,
            kind: self.kind.clone(),
        }
    }
}

#[cfg(test)]
mod tests {
    use crate::{
        TokenStringExt,
        parsers::{Parser, PlainEnglish},
    };

    #[test]
    fn parses_sentences_correctly() {
        let text = "There were three little pigs. They built three little homes.";
        let chars: Vec<char> = text.chars().collect();
        let toks = PlainEnglish.parse(&chars);

        let mut sentence_strs = vec![];

        for sentence in toks.iter_sentences() {
            if let Some(span) = sentence.span() {
                sentence_strs.push(span.get_content_string(&chars));
            }
        }

        assert_eq!(
            sentence_strs,
            vec![
                "There were three little pigs.",
                " They built three little homes."
            ]
        )
    }
}



================================================
FILE: harper-core/src/token_kind.rs
================================================
use harper_brill::UPOS;
use is_macro::Is;
use serde::{Deserialize, Serialize};

use crate::{
    DictWordMetadata, Number, Punctuation, Quote, TokenKind::Word, dict_word_metadata::Person,
};

/// Generate wrapper code to pass a function call to the inner [`DictWordMetadata`],  
/// if the token is indeed a word, while also emitting method-level documentation.
macro_rules! delegate_to_metadata {
    ($($method:ident),* $(,)?) => {
        $(
            #[doc = concat!(
                "Delegates to [`DictWordMetadata::",
                stringify!($method),
                "`] when this token is a word.\n\n",
                "Returns `false` if the token is not a word."
            )]
            pub fn $method(&self) -> bool {
                let Word(Some(metadata)) = self else {
                    return false;
                };
                metadata.$method()
            }
        )*
    };
}

/// The parsed value of a [`Token`](crate::Token).
/// Has a variety of queries available.
/// If there is a query missing, it may be easy to implement by just calling the
/// `delegate_to_metadata` macro.
#[derive(Debug, Is, Clone, Serialize, Deserialize, Default, PartialOrd, Hash, Eq, PartialEq)]
#[serde(tag = "kind", content = "value")]
pub enum TokenKind {
    /// `None` if the word does not exist in the dictionary.
    Word(Option<DictWordMetadata>),
    Punctuation(Punctuation),
    Decade,
    Number(Number),
    /// A sequence of " " spaces.
    Space(usize),
    /// A sequence of "\n" newlines
    Newline(usize),
    EmailAddress,
    Url,
    Hostname,
    /// A special token used for things like inline code blocks that should be
    /// ignored by all linters.
    #[default]
    Unlintable,
    ParagraphBreak,
    Regexish,
    HeadingStart,
}

impl TokenKind {
    // DictWord metadata delegation methods grouped by part of speech
    delegate_to_metadata! {
        // Nominal methods (nouns and pronouns)
        is_nominal,
        is_noun,
        is_pronoun,
        is_proper_noun,
        is_singular_nominal,
        is_plural_nominal,
        is_possessive_nominal,
        is_non_plural_nominal,
        is_singular_noun,
        is_plural_noun,
        is_non_plural_noun,
        is_non_possessive_noun,
        is_countable_noun,
        is_non_countable_noun,
        is_mass_noun,
        is_mass_noun_only,
        is_non_mass_noun,
        is_singular_pronoun,
        is_plural_pronoun,
        is_non_plural_pronoun,
        is_reflexive_pronoun,
        is_personal_pronoun,
        is_first_person_singular_pronoun,
        is_first_person_plural_pronoun,
        is_second_person_pronoun,
        is_third_person_pronoun,
        is_third_person_singular_pronoun,
        is_third_person_plural_pronoun,
        is_subject_pronoun,
        is_object_pronoun,
        is_possessive_noun,
        // Note: possessive pronouns are: mine, ours, yours, his, hers, its, theirs
        is_possessive_pronoun,

        // Verb methods
        is_verb,
        is_auxiliary_verb,
        is_linking_verb,
        is_verb_lemma,
        is_verb_past_form,
        is_verb_simple_past_form,
        is_verb_past_participle_form,
        is_verb_progressive_form,
        is_verb_third_person_singular_present_form,

        // Adjective methods
        is_adjective,
        is_comparative_adjective,
        is_superlative_adjective,
        is_positive_adjective,

        // Adverb methods
        is_adverb,
        is_manner_adverb,
        is_frequency_adverb,
        is_degree_adverb,

        // Determiner methods
        is_determiner,
        is_demonstrative_determiner,
        is_possessive_determiner,
        is_quantifier,
        is_non_quantifier_determiner,
        is_non_demonstrative_determiner,

        // Conjunction methods
        is_conjunction,

        // Generic word methods
        is_swear,
        is_likely_homograph,

        // Orthography methods
        is_lowercase,
        is_titlecase,
        is_allcaps,
        is_lower_camel,
        is_upper_camel,
        is_apostrophized,

        is_roman_numerals
    }

    pub fn get_pronoun_person(&self) -> Option<Person> {
        let Word(Some(metadata)) = self else {
            return None;
        };
        metadata.get_person()
    }

    // DictWord metadata delegation methods not generated by macro
    pub fn is_preposition(&self) -> bool {
        let Word(Some(metadata)) = self else {
            return false;
        };
        metadata.preposition
    }

    // Generic word is-methods

    pub fn is_common_word(&self) -> bool {
        let Word(Some(metadata)) = self else {
            return true;
        };
        metadata.common
    }

    /// Checks whether the token is a member of a nominal phrase.
    pub fn is_np_member(&self) -> bool {
        let Word(Some(metadata)) = self else {
            return false;
        };
        metadata.np_member.unwrap_or(false)
    }

    /// Checks whether a word token is out-of-vocabulary (not found in the dictionary).
    ///
    /// Returns `true` if the token is a word that was not found in the dictionary,
    /// `false` if the token is a word found in the dictionary or is not a word token.
    pub fn is_oov(&self) -> bool {
        matches!(self, TokenKind::Word(None))
    }

    // Number is-methods

    pub fn is_cardinal_number(&self) -> bool {
        matches!(self, TokenKind::Number(Number { suffix: None, .. }))
    }

    pub fn is_ordinal_number(&self) -> bool {
        matches!(
            self,
            TokenKind::Number(Number {
                suffix: Some(_),
                ..
            })
        )
    }

    // Punctuation and symbol is-methods

    pub fn is_open_square(&self) -> bool {
        matches!(self, TokenKind::Punctuation(Punctuation::OpenSquare))
    }

    pub fn is_close_square(&self) -> bool {
        matches!(self, TokenKind::Punctuation(Punctuation::CloseSquare))
    }

    pub fn is_less_than(&self) -> bool {
        matches!(self, TokenKind::Punctuation(Punctuation::LessThan))
    }

    pub fn is_greater_than(&self) -> bool {
        matches!(self, TokenKind::Punctuation(Punctuation::GreaterThan))
    }

    pub fn is_open_round(&self) -> bool {
        matches!(self, TokenKind::Punctuation(Punctuation::OpenRound))
    }

    pub fn is_close_round(&self) -> bool {
        matches!(self, TokenKind::Punctuation(Punctuation::CloseRound))
    }

    pub fn is_pipe(&self) -> bool {
        matches!(self, TokenKind::Punctuation(Punctuation::Pipe))
    }

    pub fn is_currency(&self) -> bool {
        matches!(self, TokenKind::Punctuation(Punctuation::Currency(..)))
    }

    pub fn is_ellipsis(&self) -> bool {
        matches!(self, TokenKind::Punctuation(Punctuation::Ellipsis))
    }

    pub fn is_hyphen(&self) -> bool {
        matches!(self, TokenKind::Punctuation(Punctuation::Hyphen))
    }

    pub fn is_quote(&self) -> bool {
        matches!(self, TokenKind::Punctuation(Punctuation::Quote(_)))
    }

    pub fn is_apostrophe(&self) -> bool {
        matches!(self, TokenKind::Punctuation(Punctuation::Apostrophe))
    }

    pub fn is_period(&self) -> bool {
        matches!(self, TokenKind::Punctuation(Punctuation::Period))
    }

    pub fn is_at(&self) -> bool {
        matches!(self, TokenKind::Punctuation(Punctuation::At))
    }

    pub fn is_comma(&self) -> bool {
        matches!(self, TokenKind::Punctuation(Punctuation::Comma))
    }

    pub fn is_semicolon(&self) -> bool {
        matches!(self, TokenKind::Punctuation(Punctuation::Semicolon))
    }

    pub fn is_ampersand(&self) -> bool {
        matches!(self, TokenKind::Punctuation(Punctuation::Ampersand))
    }

    pub fn is_slash(&self) -> bool {
        matches!(self, TokenKind::Punctuation(Punctuation::ForwardSlash))
    }

    // Miscellaneous is-methods

    /// Checks whether a token is word-like--meaning it is more complex than punctuation and can
    /// hold semantic meaning in the way a word does.
    pub fn is_word_like(&self) -> bool {
        matches!(
            self,
            TokenKind::Word(..)
                | TokenKind::EmailAddress
                | TokenKind::Hostname
                | TokenKind::Decade
                | TokenKind::Number(..)
        )
    }

    pub(crate) fn is_chunk_terminator(&self) -> bool {
        if self.is_sentence_terminator() {
            return true;
        }

        match self {
            TokenKind::Punctuation(punct) => {
                matches!(
                    punct,
                    Punctuation::Comma | Punctuation::Quote { .. } | Punctuation::Colon
                )
            }
            _ => false,
        }
    }

    pub fn is_sentence_terminator(&self) -> bool {
        match self {
            TokenKind::Punctuation(punct) => [
                Punctuation::Period,
                Punctuation::Bang,
                Punctuation::Question,
            ]
            .contains(punct),
            TokenKind::ParagraphBreak => true,
            _ => false,
        }
    }

    /// Used by `crate::parsers::CollapseIdentifiers`
    /// TODO: Separate this into two functions and add OR functionality to
    /// pattern matching
    pub fn is_case_separator(&self) -> bool {
        matches!(self, TokenKind::Punctuation(Punctuation::Underscore))
            || matches!(self, TokenKind::Punctuation(Punctuation::Hyphen))
    }

    /// Checks whether the token is whitespace.
    pub fn is_whitespace(&self) -> bool {
        matches!(self, TokenKind::Space(_) | TokenKind::Newline(_))
    }

    pub fn is_upos(&self, upos: UPOS) -> bool {
        let Some(Some(meta)) = self.as_word() else {
            return false;
        };

        meta.pos_tag == Some(upos)
    }

    // Miscellaneous non-is methods

    /// Checks that `self` is the same enum variant as `other`, regardless of
    /// whether the inner metadata is also equal.
    pub fn matches_variant_of(&self, other: &Self) -> bool {
        self.with_default_data() == other.with_default_data()
    }

    /// Produces a copy of `self` with any inner data replaced with its default
    /// value. Useful for making comparisons on just the variant of the
    /// enum.
    pub fn with_default_data(&self) -> Self {
        match self {
            TokenKind::Word(_) => TokenKind::Word(Default::default()),
            TokenKind::Punctuation(_) => TokenKind::Punctuation(Default::default()),
            TokenKind::Number(..) => TokenKind::Number(Default::default()),
            TokenKind::Space(_) => TokenKind::Space(Default::default()),
            TokenKind::Newline(_) => TokenKind::Newline(Default::default()),
            _ => self.clone(),
        }
    }

    /// Construct a [`TokenKind::Word`] with no metadata.
    pub fn blank_word() -> Self {
        Self::Word(None)
    }

    // Punctuation and symbol non-is methods

    pub fn as_mut_quote(&mut self) -> Option<&mut Quote> {
        self.as_mut_punctuation()?.as_mut_quote()
    }

    pub fn as_quote(&self) -> Option<&Quote> {
        self.as_punctuation()?.as_quote()
    }
}

#[cfg(test)]
mod tests {
    use crate::Document;

    #[test]
    fn car_is_singular_noun() {
        let doc = Document::new_plain_english_curated("car");
        let tk = &doc.tokens().next().unwrap().kind;
        assert!(tk.is_singular_noun());
    }

    #[test]
    fn traffic_is_mass_noun_only() {
        let doc = Document::new_plain_english_curated("traffic");
        let tk = &doc.tokens().next().unwrap().kind;
        assert!(tk.is_mass_noun_only());
    }

    #[test]
    fn equipment_is_mass_noun() {
        let doc = Document::new_plain_english_curated("equipment");
        let tk = &doc.tokens().next().unwrap().kind;
        assert!(tk.is_mass_noun());
    }

    #[test]
    fn equipment_is_non_countable_noun() {
        let doc = Document::new_plain_english_curated("equipment");
        let tk = &doc.tokens().next().unwrap().kind;
        assert!(tk.is_non_countable_noun());
    }

    #[test]
    fn equipment_isnt_countable_noun() {
        let doc = Document::new_plain_english_curated("equipment");
        let tk = &doc.tokens().next().unwrap().kind;
        assert!(!tk.is_countable_noun());
    }

    #[test]
    fn oov_word_is_oov() {
        let doc = Document::new_plain_english_curated("nonexistentword");
        let tk = &doc.tokens().next().unwrap().kind;
        assert!(tk.is_oov());
    }

    #[test]
    fn known_word_is_not_oov() {
        let doc = Document::new_plain_english_curated("car");
        let tk = &doc.tokens().next().unwrap().kind;
        assert!(!tk.is_oov());
    }

    #[test]
    fn non_word_tokens_are_not_oov() {
        let doc = Document::new_plain_english_curated("Hello, world!");
        let tokens: Vec<_> = doc.tokens().collect();

        // Comma should not be OOV
        assert!(!tokens[1].kind.is_oov());
        // Exclamation mark should not be OOV
        assert!(!tokens[3].kind.is_oov());
    }
}



================================================
FILE: harper-core/src/token_string_ext.rs
================================================
use crate::{Span, Token};
use itertools::Itertools;
use paste::paste;

macro_rules! create_decl_for {
    ($thing:ident) => {
        paste! {
            fn [< first_ $thing >](&self) -> Option<&Token>;

            fn [< last_ $thing >](&self) -> Option<&Token>;

            fn [< last_ $thing _index >](&self) -> Option<usize>;

            fn [<iter_ $thing _indices>](&self) -> impl DoubleEndedIterator<Item = usize> + '_;

            fn [<iter_ $thing s>](&self) -> impl Iterator<Item = &Token> + '_;
        }
    };
}

macro_rules! create_fns_for {
    ($thing:ident) => {
        paste! {
            fn [< first_ $thing >](&self) -> Option<&Token> {
                self.iter().find(|v| v.kind.[<is_ $thing>]())
            }

            fn [< last_ $thing >](&self) -> Option<&Token> {
                self.iter().rev().find(|v| v.kind.[<is_ $thing>]())
            }

            fn [< last_ $thing _index >](&self) -> Option<usize> {
                self.iter().rev().position(|v| v.kind.[<is_ $thing>]()).map(|i| self.len() - i - 1)
            }

            fn [<iter_ $thing _indices>](&self) -> impl DoubleEndedIterator<Item = usize> + '_ {
                self.iter()
                    .enumerate()
                    .filter(|(_, t)| t.kind.[<is_ $thing>]())
                    .map(|(i, _)| i)
            }

            fn [<iter_ $thing s>](&self) -> impl Iterator<Item = &Token> + '_ {
                self.[<iter_ $thing _indices>]().map(|i| &self[i])
            }
        }
    };
}

mod private {
    use crate::{Document, Token};

    pub trait Sealed {}

    impl Sealed for [Token] {}

    impl Sealed for Document {}
}

/// Extension methods for [`Token`] sequences that make them easier to wrangle and query.
pub trait TokenStringExt: private::Sealed {
    fn first_sentence_word(&self) -> Option<&Token>;
    fn first_non_whitespace(&self) -> Option<&Token>;
    /// Grab the span that represents the beginning of the first element and the
    /// end of the last element.
    fn span(&self) -> Option<Span<char>>;

    create_decl_for!(adjective);
    create_decl_for!(apostrophe);
    create_decl_for!(at);
    create_decl_for!(comma);
    create_decl_for!(conjunction);
    create_decl_for!(chunk_terminator);
    create_decl_for!(currency);
    create_decl_for!(ellipsis);
    create_decl_for!(hostname);
    create_decl_for!(likely_homograph);
    create_decl_for!(number);
    create_decl_for!(noun);
    create_decl_for!(paragraph_break);
    create_decl_for!(pipe);
    create_decl_for!(preposition);
    create_decl_for!(punctuation);
    create_decl_for!(quote);
    create_decl_for!(sentence_terminator);
    create_decl_for!(space);
    create_decl_for!(unlintable);
    create_decl_for!(verb);
    create_decl_for!(word);
    create_decl_for!(word_like);
    create_decl_for!(heading_start);

    /// Get a reference to a token by index, with negative numbers counting from the end.
    ///
    /// # Examples
    /// ```
    /// # use harper_core::{Token, TokenStringExt, parsers::{Parser, PlainEnglish}};
    /// # fn main() {
    /// let source = "The cat sat on the mat.".chars().collect::<Vec<_>>();
    /// let tokens = PlainEnglish.parse(&source);
    /// assert_eq!(tokens.get_rel(0).unwrap().span.get_content_string(&source), "The");
    /// assert_eq!(tokens.get_rel(1).unwrap().kind.is_whitespace(), true);
    /// assert_eq!(tokens.get_rel(-1).unwrap().kind.is_punctuation(), true);
    /// assert_eq!(tokens.get_rel(-2).unwrap().span.get_content_string(&source), "mat");
    /// # }
    /// ```
    ///
    /// # Returns
    ///
    /// * `Some(&Token)` - If the index is in bounds
    /// * `None` - If the index is out of bounds
    fn get_rel(&self, index: isize) -> Option<&Token>
    where
        Self: AsRef<[Token]>,
    {
        let slice = self.as_ref();
        let len = slice.len() as isize;

        if index >= len || -index > len {
            return None;
        }

        let idx = if index >= 0 { index } else { len + index } as usize;

        slice.get(idx)
    }

    /// Get a slice of tokens using relative indices.
    ///
    /// # Examples
    /// ```
    /// # use harper_core::{Token, TokenStringExt, parsers::{Parser, PlainEnglish}};
    /// # fn main() {
    /// let source = "The cat sat on the mat.".chars().collect::<Vec<_>>();
    /// let tokens = PlainEnglish.parse(&source);
    /// assert_eq!(tokens.get_rel_slice(0, 2).unwrap().span().unwrap().get_content_string(&source), "The cat");
    /// assert_eq!(tokens.get_rel_slice(-3, -1).unwrap().span().unwrap().get_content_string(&source), " mat.");
    /// # }
    /// ```
    fn get_rel_slice(&self, rel_start: isize, inclusive_end: isize) -> Option<&[Token]>
    where
        Self: AsRef<[Token]>,
    {
        let slice = self.as_ref();
        let len = slice.len() as isize;

        // Convert relative indices to absolute indices
        let start_idx = if rel_start >= 0 {
            rel_start
        } else {
            len + rel_start
        } as usize;

        let end_idx_plus_one = if inclusive_end >= 0 {
            inclusive_end + 1 // +1 to make end exclusive
        } else {
            len + inclusive_end + 1
        } as usize;

        // Check bounds
        if start_idx >= slice.len()
            || end_idx_plus_one > slice.len()
            || start_idx >= end_idx_plus_one
        {
            return None;
        }

        Some(&slice[start_idx..end_idx_plus_one])
    }

    fn iter_linking_verb_indices(&self) -> impl Iterator<Item = usize> + '_;
    fn iter_linking_verbs(&self) -> impl Iterator<Item = &Token> + '_;

    /// Iterate over chunks.
    ///
    /// For example, the following sentence contains two chunks separated by a
    /// comma:
    ///
    /// ```text
    /// Here is an example, it is short.
    /// ```
    fn iter_chunks(&self) -> impl Iterator<Item = &'_ [Token]> + '_;

    /// Get an iterator over token slices that represent the individual
    /// paragraphs in a document.
    fn iter_paragraphs(&self) -> impl Iterator<Item = &'_ [Token]> + '_;

    /// Get an iterator over token slices that represent headings.
    ///
    /// A heading begins with a [`TokenKind::HeadingStart`](crate::TokenKind::HeadingStart) token and ends with
    /// the next [`TokenKind::ParagraphBreak`](crate::TokenKind::ParagraphBreak).
    fn iter_headings(&self) -> impl Iterator<Item = &'_ [Token]> + '_;

    /// Get an iterator over token slices that represent the individual
    /// sentences in a document.
    fn iter_sentences(&self) -> impl Iterator<Item = &'_ [Token]> + '_;

    /// Get an iterator over mutable token slices that represent the individual
    /// sentences in a document.
    fn iter_sentences_mut(&mut self) -> impl Iterator<Item = &'_ mut [Token]> + '_;
}

impl TokenStringExt for [Token] {
    create_fns_for!(adjective);
    create_fns_for!(apostrophe);
    create_fns_for!(at);
    create_fns_for!(chunk_terminator);
    create_fns_for!(comma);
    create_fns_for!(conjunction);
    create_fns_for!(currency);
    create_fns_for!(ellipsis);
    create_fns_for!(hostname);
    create_fns_for!(likely_homograph);
    create_fns_for!(noun);
    create_fns_for!(number);
    create_fns_for!(paragraph_break);
    create_fns_for!(pipe);
    create_fns_for!(preposition);
    create_fns_for!(punctuation);
    create_fns_for!(quote);
    create_fns_for!(sentence_terminator);
    create_fns_for!(space);
    create_fns_for!(unlintable);
    create_fns_for!(verb);
    create_fns_for!(word_like);
    create_fns_for!(word);
    create_fns_for!(heading_start);

    fn first_non_whitespace(&self) -> Option<&Token> {
        self.iter().find(|t| !t.kind.is_whitespace())
    }

    fn first_sentence_word(&self) -> Option<&Token> {
        let (w_idx, word) = self.iter().find_position(|v| v.kind.is_word())?;

        let Some(u_idx) = self.iter().position(|v| v.kind.is_unlintable()) else {
            return Some(word);
        };

        if w_idx < u_idx { Some(word) } else { None }
    }

    fn span(&self) -> Option<Span<char>> {
        let min_max = self
            .iter()
            .flat_map(|v| [v.span.start, v.span.end].into_iter())
            .minmax();

        match min_max {
            itertools::MinMaxResult::NoElements => None,
            itertools::MinMaxResult::OneElement(min) => Some(Span::new(min, min)),
            itertools::MinMaxResult::MinMax(min, max) => Some(Span::new(min, max)),
        }
    }

    fn iter_linking_verb_indices(&self) -> impl Iterator<Item = usize> + '_ {
        self.iter_word_indices().filter(|idx| {
            let word = &self[*idx];
            let Some(Some(meta)) = word.kind.as_word() else {
                return false;
            };

            meta.is_linking_verb()
        })
    }

    fn iter_linking_verbs(&self) -> impl Iterator<Item = &Token> + '_ {
        self.iter_linking_verb_indices().map(|idx| &self[idx])
    }

    fn iter_chunks(&self) -> impl Iterator<Item = &'_ [Token]> + '_ {
        self.split_inclusive(|tok| tok.kind.is_chunk_terminator())
    }

    fn iter_paragraphs(&self) -> impl Iterator<Item = &'_ [Token]> + '_ {
        self.split_inclusive(|tok| tok.kind.is_paragraph_break())
    }

    fn iter_headings(&self) -> impl Iterator<Item = &'_ [Token]> + '_ {
        self.iter_heading_start_indices().map(|start| {
            let end = self[start..]
                .iter()
                .position(|t| t.kind.is_paragraph_break())
                .unwrap_or(self[start..].len() - 1);

            &self[start..=start + end]
        })
    }

    fn iter_sentences(&self) -> impl Iterator<Item = &'_ [Token]> + '_ {
        self.split_inclusive(|token| token.kind.is_sentence_terminator())
    }

    fn iter_sentences_mut(&mut self) -> impl Iterator<Item = &mut [Token]> + '_ {
        struct SentIter<'a> {
            rem: &'a mut [Token],
        }

        impl<'a> Iterator for SentIter<'a> {
            type Item = &'a mut [Token];

            fn next(&mut self) -> Option<Self::Item> {
                if self.rem.is_empty() {
                    return None;
                }
                let split = self
                    .rem
                    .iter()
                    .position(|t| t.kind.is_sentence_terminator())
                    .map(|i| i + 1)
                    .unwrap_or(self.rem.len());
                let tmp = core::mem::take(&mut self.rem);
                let (sent, rest) = tmp.split_at_mut(split);
                self.rem = rest;
                Some(sent)
            }
        }

        SentIter { rem: self }
    }
}



================================================
FILE: harper-core/src/vec_ext.rs
================================================
use std::collections::VecDeque;

mod private {
    pub trait Sealed {}

    impl<T> Sealed for Vec<T> {}
}

/// Extensions on top of [`Vec`] that make certain common operations easier.
pub trait VecExt: private::Sealed {
    /// Removes a list of indices from a Vector.
    /// Assumes that the provided indices are already in sorted order.
    fn remove_indices(&mut self, to_remove: VecDeque<usize>);
}

impl<T> VecExt for Vec<T> {
    fn remove_indices(&mut self, mut to_remove: VecDeque<usize>) {
        let mut i = 0;

        let mut next_remove = to_remove.pop_front();

        self.retain(|_| {
            let keep = if let Some(next_remove) = next_remove {
                i != next_remove
            } else {
                true
            };

            if !keep {
                next_remove = to_remove.pop_front();
            }

            i += 1;
            keep
        });
    }
}

#[cfg(test)]
mod tests {
    use std::collections::VecDeque;

    use crate::vec_ext::VecExt;

    #[test]
    fn removes_requested_indices() {
        let mut data: Vec<i32> = (0..10).collect();
        let remove: VecDeque<usize> = vec![1, 4, 6].into_iter().collect();

        data.remove_indices(remove);

        assert_eq!(data, vec![0, 2, 3, 5, 7, 8, 9])
    }
}



================================================
FILE: harper-core/src/expr/all.rs
================================================
use crate::{Span, Token, expr::Expr};

/// An [`Expr`] that matches against tokens if and only if all of its children do.
/// This can be useful for situations where you have multiple expressions that represent a grammatical
/// error, but you need _all_ of them to match to be certain.
///
/// It will return the position of the farthest window.
#[derive(Default)]
pub struct All {
    children: Vec<Box<dyn Expr>>,
}

impl All {
    pub fn new(children: Vec<Box<dyn Expr>>) -> Self {
        Self { children }
    }

    pub fn add(&mut self, e: impl Expr + 'static) {
        self.children.push(Box::new(e));
    }
}

impl Expr for All {
    fn run(&self, cursor: usize, tokens: &[Token], source: &[char]) -> Option<Span<Token>> {
        let mut longest: Option<Span<Token>> = None;

        for expr in self.children.iter() {
            let window = expr.run(cursor, tokens, source)?;

            if let Some(longest_window) = longest {
                if window.len() > longest_window.len() {
                    longest = Some(window);
                }
            } else {
                longest = Some(window);
            }
        }

        longest
    }
}



================================================
FILE: harper-core/src/expr/anchor_end.rs
================================================
use crate::Token;

use super::Step;

/// A [`Step`] which will match only if the cursor is over the last non-whitespace character in stream.
/// It will return that token.
///
/// For example, if you built `SequenceExpr::default().t_aco("word").then(AnchorEnd)` and ran it on `This is a word`, the resulting `Span` would only cover the final word token.
pub struct AnchorEnd;

impl Step for AnchorEnd {
    fn step(&self, tokens: &[Token], cursor: usize, _source: &[char]) -> Option<isize> {
        if tokens
            .iter()
            .enumerate()
            .rev()
            .filter(|(_, t)| !t.kind.is_whitespace())
            .map(|(i, _)| i)
            .next()
            == Some(cursor)
        {
            Some(0)
        } else {
            None
        }
    }
}

#[cfg(test)]
mod tests {
    use crate::expr::ExprExt;
    use crate::{Document, Span};

    use super::AnchorEnd;

    #[test]
    fn matches_period() {
        let document = Document::new_markdown_default_curated("This is a test.");
        let matches: Vec<_> = AnchorEnd.iter_matches_in_doc(&document).collect();

        assert_eq!(matches, vec![Span::new(7, 7)])
    }

    #[test]
    fn does_not_match_empty() {
        let document = Document::new_markdown_default_curated("");
        let matches: Vec<_> = AnchorEnd.iter_matches_in_doc(&document).collect();

        assert_eq!(matches, vec![])
    }
}



================================================
FILE: harper-core/src/expr/anchor_start.rs
================================================
use crate::{Token, TokenStringExt};

use super::Step;

/// A [`Step`] which will match only if the cursor is over the first word-like of a token stream.
/// It will return that token.
pub struct AnchorStart;

impl Step for AnchorStart {
    fn step(&self, tokens: &[Token], cursor: usize, _source: &[char]) -> Option<isize> {
        if tokens.iter_word_like_indices().next() == Some(cursor) {
            Some(0)
        } else {
            None
        }
    }
}

#[cfg(test)]
mod tests {
    use crate::expr::ExprExt;
    use crate::{Document, Span};

    use super::AnchorStart;

    #[test]
    fn matches_first_word() {
        let document = Document::new_markdown_default_curated("This is a test.");
        let matches: Vec<_> = AnchorStart.iter_matches_in_doc(&document).collect();

        assert_eq!(matches, vec![Span::new(0, 0)])
    }

    #[test]
    fn does_not_match_empty() {
        let document = Document::new_markdown_default_curated("");
        let matches: Vec<_> = AnchorStart.iter_matches_in_doc(&document).collect();

        assert_eq!(matches, vec![])
    }
}



================================================
FILE: harper-core/src/expr/duration_expr.rs
================================================
use crate::patterns::{IndefiniteArticle, WordSet};
use crate::{Span, Token};

use super::{Expr, SequenceExpr, SpelledNumberExpr};

#[derive(Default)]
pub struct DurationExpr;

impl Expr for DurationExpr {
    fn run(&self, cursor: usize, tokens: &[Token], source: &[char]) -> Option<Span<Token>> {
        if tokens.is_empty() {
            return None;
        }

        let units = WordSet::new(&[
            "minute", "minutes", "hour", "hours", "day", "days", "week", "weeks", "month",
            "months", "year", "years",
        ]);

        let expr = SequenceExpr::default()
            .then_longest_of(vec![
                Box::new(SpelledNumberExpr),
                Box::new(SequenceExpr::default().then_number()),
                Box::new(IndefiniteArticle::default()),
            ])
            .then_whitespace()
            .then(units);

        expr.run(cursor, tokens, source)
    }
}

#[cfg(test)]
pub mod tests {
    use super::DurationExpr;
    use crate::Document;
    use crate::expr::ExprExt;
    use crate::linting::tests::SpanVecExt;

    #[test]
    fn detect_10_days() {
        let doc = Document::new_markdown_default_curated("Is 10 days a long time?");
        let matches = DurationExpr.iter_matches_in_doc(&doc).collect::<Vec<_>>();
        assert_eq!(matches.to_strings(&doc), vec!["10 days"]);
    }

    #[test]
    fn detect_ten_days() {
        let doc = Document::new_markdown_default_curated("I think ten days is a long time.");
        let matches = DurationExpr.iter_matches_in_doc(&doc).collect::<Vec<_>>();
        assert_eq!(matches.to_strings(&doc), vec!["ten days"]);
    }
}



================================================
FILE: harper-core/src/expr/expr_map.rs
================================================
use crate::LSend;
use crate::Span;
use crate::Token;

use super::Expr;

/// A map from an [`Expr`] to arbitrary data.
///
/// It has been a common pattern for rule authors to build a list of expressions that match a
/// grammatical error.
/// Then, depending on which expression was matched, a suggestion is chosen from another list.
///
/// The [`ExprMap`] unifies these two lists into one.
///
/// When used as a [`Expr`] in and of itself, it simply iterates through
/// all contained expressions, returning the first match found.
/// You should not assume this search is deterministic.
pub struct ExprMap<T>
where
    T: LSend,
{
    rows: Vec<Row<T>>,
}

struct Row<T>
where
    T: LSend,
{
    pub key: Box<dyn Expr>,
    pub element: T,
}

impl<T> Default for ExprMap<T>
where
    T: LSend,
{
    fn default() -> Self {
        Self {
            rows: Default::default(),
        }
    }
}

impl<T> ExprMap<T>
where
    T: LSend,
{
    pub fn insert(&mut self, expr: impl Expr + 'static, value: T) {
        self.rows.push(Row {
            key: Box::new(expr),
            element: value,
        });
    }

    /// Look up the corresponding value for the given map.
    pub fn lookup(&self, cursor: usize, tokens: &[Token], source: &[char]) -> Option<&T> {
        for row in &self.rows {
            let len = row.key.run(cursor, tokens, source);

            if len.is_some() {
                return Some(&row.element);
            }
        }

        None
    }
}

impl<T> Expr for ExprMap<T>
where
    T: LSend,
{
    fn run(&self, cursor: usize, tokens: &[Token], source: &[char]) -> Option<Span<Token>> {
        self.rows
            .iter()
            .filter_map(|row| row.key.run(cursor, tokens, source))
            .next()
    }
}



================================================
FILE: harper-core/src/expr/filter.rs
================================================
use crate::{Span, Token};

use super::Expr;

/// An expression that wraps other expressions to build a filter-line pipeline.
///
/// For example, let's say you wanted to build an expression that matches the spaces between two
/// specific words.
/// To do this, you could start with expression A that detects the pattern `<WORD> <WORD>`. That is,
/// a word, followed by a space, followed by a second word. You could then build Expression B, that
/// simply matches the space. By combining these using a filter, you end up building an expression
/// that matches expression A first, then narrows the result further to only match the resulting
/// space.
///
/// ``` rust
/// use harper_core::patterns::WhitespacePattern;
/// use harper_core::expr::{SequenceExpr, Filter, ExprExt};
/// use harper_core::{Span, Document};
///
/// let a = SequenceExpr::aco("chock").t_ws().t_aco("full");
/// let b = WhitespacePattern;
///
/// let filter = Filter::new(vec![Box::new(a), Box::new(b)]);
/// let doc = Document::new_markdown_default_curated("This test is chock full of insights.");
///
/// let matches: Vec<_> = filter.iter_matches_in_doc(&doc).collect();
/// assert_eq!(vec![Span::new(7, 8)], matches)
/// ```
pub struct Filter {
    steps: Vec<Box<dyn Expr>>,
}

impl Filter {
    pub fn new(steps: Vec<Box<dyn Expr>>) -> Self {
        Self { steps }
    }
}

impl Expr for Filter {
    fn run(&self, cursor: usize, tokens: &[Token], source: &[char]) -> Option<Span<Token>> {
        let mut result = self.steps.first()?.run(cursor, tokens, source)?;

        for step in self.steps.iter().skip(1) {
            let mut found = false;

            for i in 0..result.len() {
                let step_res = step.run(i, result.get_content(tokens), source);

                if let Some(step) = step_res {
                    result = step.pushed_by(result.start);
                    found = true;
                    break;
                }
            }

            if !found {
                return None;
            }
        }

        Some(result)
    }
}



================================================
FILE: harper-core/src/expr/first_match_of.rs
================================================
use super::Expr;
use crate::{Span, Token};

/// A naive expr collection that naively iterates through a list of patterns,
/// returning the first one that matches.
///
/// Compare to [`LongestMatchOf`](super::LongestMatchOf), which returns the longest match.
#[derive(Default)]
pub struct FirstMatchOf {
    exprs: Vec<Box<dyn Expr>>,
}

impl FirstMatchOf {
    pub fn new(exprs: Vec<Box<dyn Expr>>) -> Self {
        Self { exprs }
    }

    pub fn add(&mut self, expr: impl Expr + 'static) {
        self.exprs.push(Box::new(expr));
    }

    pub fn add_boxed(&mut self, expr: Box<dyn Expr>) {
        self.exprs.push(Box::new(expr));
    }
}

impl Expr for FirstMatchOf {
    fn run(&self, cursor: usize, tokens: &[Token], source: &[char]) -> Option<Span<Token>> {
        self.exprs
            .iter()
            .find_map(|p| p.run(cursor, tokens, source))
    }
}



================================================
FILE: harper-core/src/expr/fixed_phrase.rs
================================================
use crate::parsers::PlainEnglish;
use crate::patterns::Word;
use crate::{Document, Span, Token, TokenKind};

use super::{Expr, SequenceExpr};

/// Matches a fixed sequence of tokens as they appear in the input.
/// Case-insensitive for words but maintains exact matching for other token types.
///
/// # Example
///
/// ```rust
/// use harper_core::expr::{FixedPhrase, Expr};
/// use harper_core::Document;
///
/// let doc = Document::new_plain_english_curated("Hello, world!");
/// let phrase = FixedPhrase::from_phrase("Hello, world!");
/// assert!(phrase.run(0, doc.get_tokens(), doc.get_source()).is_some());
/// ```
pub struct FixedPhrase {
    inner: SequenceExpr,
}

impl FixedPhrase {
    /// Creates a [`FixedPhrase`] from a plaintext string.
    /// Uses plain English tokenization rules.
    pub fn from_phrase(text: &str) -> Self {
        let document = Document::new_basic_tokenize(text, &PlainEnglish);
        Self::from_document(&document)
    }

    /// Creates a [`FixedPhrase`] from a pre-tokenized document.
    /// Allows custom tokenization by creating a `Document` first.
    pub fn from_document(doc: &Document) -> Self {
        let mut phrase = SequenceExpr::default();

        for token in doc.fat_tokens() {
            match token.kind {
                TokenKind::Word(_lexeme_metadata) => {
                    phrase = phrase.then(Word::from_chars(token.content.as_slice()));
                }
                TokenKind::Space(_) => {
                    phrase = phrase.then_whitespace();
                }
                TokenKind::Punctuation(p) => {
                    phrase = phrase
                        .then_kind_where(move |kind| kind.as_punctuation().cloned() == Some(p));
                }
                TokenKind::ParagraphBreak => {
                    phrase = phrase.then_whitespace();
                }
                TokenKind::Number(_) => phrase = phrase.then_kind_where(|kind| kind.is_number()),
                _ => panic!("Fell out of expected document formats."),
            }
        }

        Self { inner: phrase }
    }
}

impl Expr for FixedPhrase {
    fn run(&self, cursor: usize, tokens: &[Token], source: &[char]) -> Option<Span<Token>> {
        self.inner.run(cursor, tokens, source)
    }
}

#[cfg(test)]
mod tests {
    use super::FixedPhrase;
    use crate::expr::Expr;
    use crate::{Document, Span};

    #[test]
    fn test_not_case_sensitive() {
        let doc_lower = Document::new_plain_english_curated("hello world");
        let doc_upper = Document::new_plain_english_curated("HELLO WORLD");
        let doc_title = Document::new_plain_english_curated("Hello World");
        let phrase = FixedPhrase::from_document(&doc_lower);
        assert_eq!(
            phrase.run(0, doc_lower.get_tokens(), doc_title.get_source()),
            Some(Span::new(0, 3))
        );
        assert_eq!(
            phrase.run(0, doc_lower.get_tokens(), doc_upper.get_source()),
            Some(Span::new(0, 3))
        );
        assert_eq!(
            phrase.run(0, doc_title.get_tokens(), doc_lower.get_source()),
            Some(Span::new(0, 3))
        );
        assert_eq!(
            phrase.run(0, doc_title.get_tokens(), doc_upper.get_source()),
            Some(Span::new(0, 3))
        );
        assert_eq!(
            phrase.run(0, doc_upper.get_tokens(), doc_lower.get_source()),
            Some(Span::new(0, 3))
        );
        assert_eq!(
            phrase.run(0, doc_upper.get_tokens(), doc_title.get_source()),
            Some(Span::new(0, 3))
        );
    }
}



================================================
FILE: harper-core/src/expr/longest_match_of.rs
================================================
use crate::{Span, Token, expr::Expr};

/// An [`Expr`] that returns the farthest offset of the longest match in a list of expressions.
#[derive(Default)]
pub struct LongestMatchOf {
    exprs: Vec<Box<dyn Expr>>,
}

impl LongestMatchOf {
    pub fn new(exprs: Vec<Box<dyn Expr>>) -> Self {
        Self { exprs }
    }

    pub fn add(&mut self, expr: impl Expr + 'static) {
        self.exprs.push(Box::new(expr));
    }
}

impl Expr for LongestMatchOf {
    fn run(&self, cursor: usize, tokens: &[Token], source: &[char]) -> Option<Span<Token>> {
        let mut longest: Option<Span<Token>> = None;

        for expr in self.exprs.iter() {
            let Some(window) = expr.run(cursor, tokens, source) else {
                continue;
            };

            if let Some(longest_window) = longest {
                if window.len() > longest_window.len() {
                    longest = Some(window);
                }
            } else {
                longest = Some(window);
            }
        }

        longest
    }
}



================================================
FILE: harper-core/src/expr/mergeable_words.rs
================================================
use std::sync::Arc;

use super::{Expr, SequenceExpr, SpaceOrHyphen};
use crate::spell::{Dictionary, FstDictionary};
use crate::{CharString, DictWordMetadata, Span, Token};

type PredicateFn =
    dyn Fn(Option<&DictWordMetadata>, Option<&DictWordMetadata>) -> bool + Send + Sync;

/// An [`Expr`] that identifies adjacent words that could potentially be merged into a single word.
///
/// This checks if two adjacent words could form a valid compound word, but first verifies
/// that the two words aren't already a valid entry in the dictionary (like "straight away").
pub struct MergeableWords {
    inner: SequenceExpr,
    dict: Arc<FstDictionary>,
    predicate: Box<PredicateFn>,
}

impl MergeableWords {
    pub fn new(
        predicate: impl Fn(Option<&DictWordMetadata>, Option<&DictWordMetadata>) -> bool
        + Send
        + Sync
        + 'static,
    ) -> Self {
        Self {
            inner: SequenceExpr::default()
                .then_any_word()
                .then(SpaceOrHyphen)
                .then_any_word(),
            dict: FstDictionary::curated(),
            predicate: Box::new(predicate),
        }
    }

    /// Get the merged word from the dictionary if these words can be merged.
    /// Returns None if the words should remain separate (according to the predicate).
    pub fn get_merged_word(
        &self,
        word_a: &Token,
        word_b: &Token,
        source: &[char],
    ) -> Option<CharString> {
        let a_chars: CharString = word_a.span.get_content(source).into();
        let b_chars: CharString = word_b.span.get_content(source).into();

        // First check if the open compound exists in the dictionary
        let mut compound = a_chars.clone();
        compound.push(' ');
        compound.extend_from_slice(&b_chars);
        let meta_open = self.dict.get_word_metadata(&compound);

        // Then check if the closed compound exists in the dictionary
        compound.remove(a_chars.len());
        let meta_closed = self.dict.get_word_metadata(&compound);

        if (self.predicate)(meta_closed.as_deref(), meta_open.as_deref()) {
            return Some(compound);
        }

        None
    }
}

impl Expr for MergeableWords {
    fn run(&self, cursor: usize, tokens: &[Token], source: &[char]) -> Option<Span<Token>> {
        let inner_match = self.inner.run(cursor, tokens, source)?;

        if inner_match.len() != 3 {
            return None;
        }

        if self
            .get_merged_word(&tokens[cursor], &tokens[cursor + 2], source)
            .is_some()
        {
            return Some(inner_match);
        }

        None
    }
}

#[cfg(test)]
mod tests {
    use super::MergeableWords;
    use crate::{DictWordMetadata, Document};

    fn predicate(
        meta_closed: Option<&DictWordMetadata>,
        meta_open: Option<&DictWordMetadata>,
    ) -> bool {
        meta_open.is_none() && meta_closed.is_some_and(|m| m.is_noun() && !m.is_proper_noun())
    }

    #[test]
    fn merges_open_compound_not_in_dict() {
        // note book is not in the dictionary, but notebook is
        let doc = Document::new_plain_english_curated("note book");
        let a = doc.tokens().next().unwrap();
        let b = doc.tokens().nth(2).unwrap();

        let merged = MergeableWords::new(predicate).get_merged_word(a, b, doc.get_source());

        assert_eq!(merged, Some("notebook".chars().collect()));
    }

    #[test]
    fn does_not_merge_open_compound_in_dict() {
        // straight away is in the dictionary, and straightaway is
        let doc = Document::new_plain_english_curated("straight away");
        let a = doc.tokens().next().unwrap();
        let b = doc.tokens().nth(2).unwrap();

        let merged = MergeableWords::new(predicate).get_merged_word(a, b, doc.get_source());

        assert_eq!(merged, None);
    }

    #[test]
    fn does_not_merge_invalid_compound() {
        // neither quick for nor quickfox are in the dictionary
        let doc = Document::new_plain_english_curated("quick fox");
        let a = doc.tokens().next().unwrap();
        let b = doc.tokens().nth(2).unwrap();

        let merged = MergeableWords::new(predicate).get_merged_word(a, b, doc.get_source());

        assert_eq!(merged, None);
    }

    #[test]
    fn merges_open_compound() {
        // Dictionary has "frontline" but not "front line"
        let doc = Document::new_plain_english_curated("front line");
        let a = doc.tokens().next().unwrap();
        let b = doc.tokens().nth(2).unwrap();

        let merged = MergeableWords::new(predicate).get_merged_word(a, b, doc.get_source());

        assert_eq!(merged, Some("frontline".chars().collect()));
    }

    #[test]
    fn merges_hyphenated_compound() {
        // Doesn't check for "front-line" in the dictionary but matches it and "frontline" is in the dictionary
        let doc = Document::new_plain_english_curated("front-line");
        let a = doc.tokens().next().unwrap();
        let b = doc.tokens().nth(2).unwrap();

        let merged = MergeableWords::new(predicate).get_merged_word(a, b, doc.get_source());

        assert_eq!(merged, Some("frontline".chars().collect()));
    }
}



================================================
FILE: harper-core/src/expr/mod.rs
================================================
//! An `Expr` is a declarative way to express whether a certain set of tokens fulfill a criteria.
//!
//! For example, if we want to look for the word "that" followed by an adjective, we could build an
//! expression to do so.
//!
//! The actual searching is done by another system (usually a part of the [lint framework](crate::linting::ExprLinter)).
//! It iterates through a document, checking if each index matches the criteria.
//!
//! When supplied a specific position in a token stream, the technical job of an `Expr` is to determine the window of tokens (including the cursor itself) that fulfills whatever criteria the author desires.
//!
//! The goal of the `Expr` initiative is to make rules easier to _read_ as well as to write.
//! Gone are the days of trying to manually parse the logic of another man's Rust code.
//!
//! See also: [`SequenceExpr`].

mod all;
mod anchor_end;
mod anchor_start;
mod duration_expr;
mod expr_map;
mod filter;
mod first_match_of;
mod fixed_phrase;
mod longest_match_of;
mod mergeable_words;
mod optional;
mod reflexive_pronoun;
mod repeating;
mod sequence_expr;
mod similar_to_phrase;
mod space_or_hyphen;
mod spelled_number_expr;
mod step;
mod time_unit_expr;
mod unless_step;
mod word_expr_group;

#[cfg(not(feature = "concurrent"))]
use std::rc::Rc;
use std::sync::Arc;

pub use all::All;
pub use anchor_end::AnchorEnd;
pub use anchor_start::AnchorStart;
pub use duration_expr::DurationExpr;
pub use expr_map::ExprMap;
pub use filter::Filter;
pub use first_match_of::FirstMatchOf;
pub use fixed_phrase::FixedPhrase;
pub use longest_match_of::LongestMatchOf;
pub use mergeable_words::MergeableWords;
pub use optional::Optional;
pub use reflexive_pronoun::ReflexivePronoun;
pub use repeating::Repeating;
pub use sequence_expr::SequenceExpr;
pub use similar_to_phrase::SimilarToPhrase;
pub use space_or_hyphen::SpaceOrHyphen;
pub use spelled_number_expr::SpelledNumberExpr;
pub use step::Step;
pub use time_unit_expr::TimeUnitExpr;
pub use unless_step::UnlessStep;
pub use word_expr_group::WordExprGroup;

use crate::{Document, LSend, Span, Token};

pub trait Expr: LSend {
    fn run(&self, cursor: usize, tokens: &[Token], source: &[char]) -> Option<Span<Token>>;
}

impl<S> Expr for S
where
    S: Step + ?Sized,
{
    fn run(&self, cursor: usize, tokens: &[Token], source: &[char]) -> Option<Span<Token>> {
        self.step(tokens, cursor, source).map(|s| {
            if s >= 0 {
                Span::new_with_len(cursor, s as usize)
            } else {
                Span::new(add(cursor, s).unwrap(), cursor)
            }
        })
    }
}

impl<E> Expr for Arc<E>
where
    E: Expr,
{
    fn run(&self, cursor: usize, tokens: &[Token], source: &[char]) -> Option<Span<Token>> {
        self.as_ref().run(cursor, tokens, source)
    }
}

impl Expr for Box<dyn Expr> {
    fn run(&self, cursor: usize, tokens: &[Token], source: &[char]) -> Option<Span<Token>> {
        self.as_ref().run(cursor, tokens, source)
    }
}

#[cfg(not(feature = "concurrent"))]
impl<E> Expr for Rc<E>
where
    E: Expr,
{
    fn run(&self, cursor: usize, tokens: &[Token], source: &[char]) -> Option<Span<Token>> {
        self.as_ref().run(cursor, tokens, source)
    }
}

fn add(u: usize, i: isize) -> Option<usize> {
    if i.is_negative() {
        u.checked_sub(i.wrapping_abs() as u32 as usize)
    } else {
        u.checked_add(i as usize)
    }
}

pub trait ExprExt {
    /// Iterate over all matches of this expression in the document, automatically filtering out
    /// overlapping matches, preferring the first.
    fn iter_matches<'a>(
        &'a self,
        tokens: &'a [Token],
        source: &'a [char],
    ) -> Box<dyn Iterator<Item = Span<Token>> + 'a>;

    fn iter_matches_in_doc<'a>(
        &'a self,
        doc: &'a Document,
    ) -> Box<dyn Iterator<Item = Span<Token>> + 'a>;
}

impl<E: ?Sized> ExprExt for E
where
    E: Expr,
{
    fn iter_matches<'a>(
        &'a self,
        tokens: &'a [Token],
        source: &'a [char],
    ) -> Box<dyn Iterator<Item = Span<Token>> + 'a> {
        let mut last_end = 0usize;

        Box::new((0..tokens.len()).filter_map(move |i| {
            let span = self.run(i, tokens, source)?;
            if span.start >= last_end {
                last_end = span.end;
                Some(span)
            } else {
                None
            }
        }))
    }

    fn iter_matches_in_doc<'a>(
        &'a self,
        doc: &'a Document,
    ) -> Box<dyn Iterator<Item = Span<Token>> + 'a> {
        Box::new(self.iter_matches(doc.get_tokens(), doc.get_source()))
    }
}

pub trait OwnedExprExt {
    fn or(self, other: impl Expr + 'static) -> FirstMatchOf;
    fn and(self, other: impl Expr + 'static) -> All;
    fn and_not(self, other: impl Expr + 'static) -> All;
    fn or_longest(self, other: impl Expr + 'static) -> LongestMatchOf;
}

impl<E> OwnedExprExt for E
where
    E: Expr + 'static,
{
    /// Returns an expression that matches either the current one or the expression contained in `other`.
    fn or(self, other: impl Expr + 'static) -> FirstMatchOf {
        FirstMatchOf::new(vec![Box::new(self), Box::new(other)])
    }

    /// Returns an expression that matches only if both the current one and the expression contained in `other` do.
    fn and(self, other: impl Expr + 'static) -> All {
        All::new(vec![Box::new(self), Box::new(other)])
    }

    /// Returns an expression that matches only if the current one matches and the expression contained in `other` does not.
    fn and_not(self, other: impl Expr + 'static) -> All {
        self.and(UnlessStep::new(other, |_tok: &Token, _src: &[char]| true))
    }

    /// Returns an expression that matches the longest of the current one or the expression contained in `other`.
    ///
    /// If you don't need the longest match, prefer using the short-circuiting [`Self::or()`] instead.
    fn or_longest(self, other: impl Expr + 'static) -> LongestMatchOf {
        LongestMatchOf::new(vec![Box::new(self), Box::new(other)])
    }
}



================================================
FILE: harper-core/src/expr/optional.rs
================================================
use crate::{Span, Token};

use super::Expr;

/// An optional expression.
/// Forces the optional expression to always return Some by transmuting `None` into
/// `Some(cursor..cursor)`.
pub struct Optional {
    inner: Box<dyn Expr>,
}

impl Optional {
    pub fn new(inner: impl Expr + 'static) -> Self {
        Self {
            inner: Box::new(inner),
        }
    }
}

impl Expr for Optional {
    fn run(&self, cursor: usize, tokens: &[Token], source: &[char]) -> Option<Span<Token>> {
        let res = self.inner.run(cursor, tokens, source);

        if res.is_none() {
            Some(Span::new_with_len(cursor, 0))
        } else {
            res
        }
    }
}



================================================
FILE: harper-core/src/expr/reflexive_pronoun.rs
================================================
use crate::{
    Span, Token,
    expr::{Expr, FirstMatchOf},
    patterns::WordSet,
};

// These are considered ungrammatical, or are at least not in `dictionary.dict` but are commonly used anyway.
// The tests below check if this changes so we can update this `Expr`
const BAD_REFLEXIVE_PRONOUNS: &[&str] = &[
    "hisself",
    "oneselves",
    "theirself",
    "theirselves",
    "themself",
];

/// Matches reflexive pronouns with configurable strictness.
///
/// By default, only matches standard English reflexive pronouns. Use `with_common_errors()` to include
/// frequently encountered non-standard forms like "hisself" or "theirself".
pub struct ReflexivePronoun {
    include_common_errors: bool,
}

impl Default for ReflexivePronoun {
    fn default() -> Self {
        Self::standard()
    }
}

impl ReflexivePronoun {
    /// Creates a matcher for standard English reflexive pronouns.
    ///
    /// Matches only the correct forms: "myself", "yourself", "himself", "herself", "itself",
    /// "ourselves", "yourselves", and "themselves".
    pub fn standard() -> Self {
        Self {
            include_common_errors: false,
        }
    }

    /// Creates a matcher that includes non-standard but commonly used reflexive pronouns.
    ///
    /// In addition to standard forms, matches common errors like "hisself", "theirself",
    /// and other non-standard forms that are frequently seen in user-generated content.
    pub fn with_common_errors() -> Self {
        Self {
            include_common_errors: true,
        }
    }
}

impl Expr for ReflexivePronoun {
    fn run(&self, cursor: usize, tokens: &[Token], source: &[char]) -> Option<Span<Token>> {
        let good_pronouns = |token: &Token, _: &[char]| token.kind.is_reflexive_pronoun();
        let mut expr = FirstMatchOf::new(vec![Box::new(good_pronouns)]);
        if self.include_common_errors {
            expr.add(WordSet::new(BAD_REFLEXIVE_PRONOUNS));
        }
        expr.run(cursor, tokens, source)
    }
}

#[cfg(test)]
mod tests {
    use crate::{
        Document, TokenKind,
        expr::{ExprExt, ReflexivePronoun, reflexive_pronoun::BAD_REFLEXIVE_PRONOUNS},
    };

    // These are considered grammatically correct, or are at least in `dictionary.dict`.
    // The tests below check if this changes so we can update this `Expr`
    const GOOD_REFLEXIVE_PRONOUNS: &[&str] = &[
        "herself",
        "himself",
        "itself",
        "myself",
        "oneself",
        "ourself",
        "ourselves",
        "themselves",
        "thyself",
        "yourself",
        "yourselves",
    ];

    fn test_pronoun(word: &str) {
        let doc = Document::new_plain_english_curated(word);
        let token = doc.tokens().next().expect("No tokens in document");

        let is_good_pron = GOOD_REFLEXIVE_PRONOUNS.contains(&word);
        let is_bad_pron = BAD_REFLEXIVE_PRONOUNS.contains(&word);

        match (is_good_pron, is_bad_pron, &token.kind) {
            (true, false, TokenKind::Word(Some(md))) => {
                assert!(md.is_pronoun());
                assert!(md.is_reflexive_pronoun());
            }
            (true, false, TokenKind::Word(None)) => {
                panic!("Widely accepted pronoun '{word}' has gone missing from the dictionary!")
            }
            (false, true, TokenKind::Word(Some(_))) => panic!(
                "Unaccepted pronoun '{word}' that's used in bad English is now in the dictionary!"
            ),
            (false, true, TokenKind::Word(None)) => {}
            (false, false, TokenKind::Word(Some(_))) => panic!(
                "non-pronoun '{word}' is made up just for testing but is now in the dictionary!"
            ),
            (false, false, TokenKind::Word(None)) => {}
            (true, true, _) => panic!("'{word}' is in both good and bad lists"),
            _ => panic!("'{word}' doesn't match any expected case"),
        }
    }

    #[test]
    fn test_good_reflexive_pronouns() {
        for word in GOOD_REFLEXIVE_PRONOUNS {
            test_pronoun(word);
        }
    }

    #[test]
    fn test_bad_reflexive_pronouns() {
        for word in BAD_REFLEXIVE_PRONOUNS {
            test_pronoun(word);
        }
    }

    // It's expected that nobody uses these words even in bad English.
    #[test]
    fn test_non_pronouns() {
        test_pronoun("myselves");
        test_pronoun("weselves");
        test_pronoun("usself");
        test_pronoun("usselves");
    }

    #[test]
    fn ensure_standard_ctor_includes_myself() {
        let doc =
            Document::new_plain_english_curated("If you want something done, do it yourself.");
        let rp = ReflexivePronoun::standard();
        let matches = rp.iter_matches_in_doc(&doc);
        assert_eq!(matches.count(), 1);
    }

    #[test]
    fn ensure_default_ctor_includes_myself() {
        let doc = Document::new_plain_english_curated(
            "I wanted a reflexive pronoun module, so I wrote one myself.",
        );
        let rp = ReflexivePronoun::default();
        let matches = rp.iter_matches_in_doc(&doc);
        assert_eq!(matches.count(), 1);
    }

    #[test]
    fn ensure_with_common_errors_includes_hisself() {
        let doc = Document::new_plain_english_curated("He teached hisself English.");
        let rp = ReflexivePronoun::with_common_errors();
        let matches = rp.iter_matches_in_doc(&doc);
        assert_eq!(matches.count(), 1);
    }

    #[test]
    fn ensure_standard_ctor_excludes_hisself() {
        let doc = Document::new_plain_english_curated("Was he pleased with hisself?");
        let rp = ReflexivePronoun::standard();
        let matches = rp.iter_matches_in_doc(&doc);
        assert_eq!(matches.count(), 0);
    }

    #[test]
    fn ensure_default_ctor_excludes_theirself() {
        let doc = Document::new_plain_english_curated("They look at theirself in the mirror.");
        let rp = ReflexivePronoun::default();
        let matches = rp.iter_matches_in_doc(&doc);
        assert_eq!(matches.count(), 0);
    }
}



================================================
FILE: harper-core/src/expr/repeating.rs
================================================
use super::Expr;
use crate::{Span, Token};

/// An expression that will match one or more repetitions of the same expression.
///
/// Somewhat reminiscent of the `+*` operator in Regex.
pub struct Repeating {
    inner: Box<dyn Expr>,
    required_repetitions: usize,
}

impl Repeating {
    pub fn new(expr: Box<dyn Expr>, required_repetitions: usize) -> Self {
        Self {
            inner: expr,
            required_repetitions,
        }
    }
}

impl Expr for Repeating {
    fn run(&self, mut cursor: usize, tokens: &[Token], source: &[char]) -> Option<Span<Token>> {
        let mut window = Span::new_with_len(cursor, 0);
        let mut repetition = 0;

        loop {
            let res = self.inner.run(cursor, tokens, source);

            if let Some(res) = res {
                window.expand_to_include(res.start);
                window.expand_to_include(res.end - 1);

                if res.start < cursor {
                    cursor = res.start;
                } else {
                    cursor = res.end;
                }

                if res.is_empty() {
                    return Some(window);
                }

                repetition += 1;
            } else if repetition >= self.required_repetitions {
                return Some(window);
            } else {
                return None;
            }
        }
    }
}

#[cfg(test)]
mod tests {

    use super::Repeating;
    use crate::expr::{ExprExt, SequenceExpr};
    use crate::patterns::AnyPattern;
    use crate::{Document, Span};

    #[test]
    fn matches_anything() {
        let doc = Document::new_plain_english_curated(
            "This matcher will match the entirety of any document!",
        );
        let pat = Repeating::new(Box::new(SequenceExpr::from(AnyPattern)), 0);

        assert_eq!(
            pat.iter_matches(doc.get_tokens(), doc.get_source()).next(),
            Some(Span::new(0, doc.get_tokens().len()))
        )
    }

    #[test]
    fn does_not_match_short() {
        let doc = Document::new_plain_english_curated("No match");
        let pat = Repeating::new(Box::new(SequenceExpr::from(AnyPattern)), 4);

        assert_eq!(
            pat.iter_matches(doc.get_tokens(), doc.get_source()).next(),
            None
        )
    }
}



================================================
FILE: harper-core/src/expr/sequence_expr.rs
================================================
use paste::paste;

use crate::{
    CharStringExt, Lrc, Span, Token, TokenKind,
    expr::{FirstMatchOf, FixedPhrase, LongestMatchOf},
    patterns::{AnyPattern, IndefiniteArticle, WhitespacePattern, Word, WordSet},
};

use super::{Expr, Optional, OwnedExprExt, Repeating, Step, UnlessStep};

#[derive(Default)]
pub struct SequenceExpr {
    exprs: Vec<Box<dyn Expr>>,
}

/// Generate a `then_*` method from an available `is_*` function on [`TokenKind`].
macro_rules! gen_then_from_is {
    ($quality:ident) => {
        paste! {
            #[doc = concat!("Adds a step matching a token where [`TokenKind::is_", stringify!($quality), "()`] returns true.")]
            pub fn [< then_$quality >] (self) -> Self{
                self.then_kind_where(|kind| {
                    kind.[< is_$quality >]()
                })
            }

            #[doc = concat!("Adds an optional step matching a token where [`TokenKind::is_", stringify!($quality), "()`] returns true.")]
            pub fn [< then_optional_$quality >] (self) -> Self{
                self.then_optional(|tok: &Token, _source: &[char]| {
                    tok.kind.[< is_$quality >]()
                })
            }

            #[doc = concat!("Adds a step matching one or more consecutive tokens where [`TokenKind::is_", stringify!($quality), "()`] returns true.")]
            pub fn [< then_one_or_more_$quality s >] (self) -> Self{
                self.then_one_or_more(Box::new(|tok: &Token, _source: &[char]| {
                    tok.kind.[< is_$quality >]()
                }))
            }

            #[doc = concat!("Adds a step matching a token where [`TokenKind::is_", stringify!($quality), "()`] returns false.")]
            pub fn [< then_anything_but_$quality >] (self) -> Self{
                self.then_kind_where(|kind| {
                    !kind.[< is_$quality >]()
                })
            }
        }
    };
}

impl Expr for SequenceExpr {
    /// Run the expression starting at an index, returning the total matched window.
    ///
    /// If any step returns `None`, the entire expression does as well.
    fn run(&self, mut cursor: usize, tokens: &[Token], source: &[char]) -> Option<Span<Token>> {
        let mut window = Span::new_with_len(cursor, 0);

        for cur_expr in &self.exprs {
            let out = cur_expr.run(cursor, tokens, source)?;

            // Only expand the window if the match actually covers some tokens
            if out.end > out.start {
                window.expand_to_include(out.start);
                window.expand_to_include(out.end.checked_sub(1).unwrap_or(out.start));
            }

            // Only advance cursor if we actually matched something
            if out.end > cursor {
                cursor = out.end;
            } else if out.start < cursor {
                cursor = out.start;
            }
            // If both start and end are equal to cursor, don't move the cursor
        }

        Some(window)
    }
}

impl SequenceExpr {
    // Constructor methods

    // Match an [expression](Expr).
    pub fn with(expr: impl Expr + 'static) -> Self {
        Self::default().then(expr)
    }

    // Single token methods

    /// Construct a new sequence with an [`AnyPattern`] at the beginning of the operation list.
    pub fn anything() -> Self {
        Self::default().then_anything()
    }

    // Single word token methods

    /// Construct a new sequence with a [`Word`] at the beginning of the operation list.
    pub fn any_capitalization_of(word: &'static str) -> Self {
        Self::default().then_any_capitalization_of(word)
    }

    /// Shorthand for [`Self::any_capitalization_of`].
    pub fn aco(word: &'static str) -> Self {
        Self::any_capitalization_of(word)
    }

    /// Match any word from the given set of words, case-insensitive.
    pub fn word_set(words: &'static [&'static str]) -> Self {
        Self::default().then_word_set(words)
    }

    /// Match any word.
    pub fn any_word() -> Self {
        Self::default().then_any_word()
    }

    // Expressions of more than one token

    /// Optionally match an expression.
    pub fn optional(expr: impl Expr + 'static) -> Self {
        Self::default().then_optional(expr)
    }

    /// Match a fixed phrase.
    pub fn fixed_phrase(phrase: &'static str) -> Self {
        Self::default().then_fixed_phrase(phrase)
    }

    // Multiple expressions

    /// Match the first of multiple expressions.
    pub fn any_of(exprs: Vec<Box<dyn Expr>>) -> Self {
        Self::default().then_any_of(exprs)
    }

    /// Will be accepted unless the condition matches.
    pub fn unless(condition: impl Expr + 'static) -> Self {
        Self::default().then_unless(condition)
    }

    // Builder methods

    /// Push an [expression](Expr) to the operation list.
    pub fn then(mut self, expr: impl Expr + 'static) -> Self {
        self.exprs.push(Box::new(expr));
        self
    }

    /// Push an already-boxed [expression](Expr) to the operation list.
    pub fn then_boxed(mut self, expr: Box<dyn Expr>) -> Self {
        self.exprs.push(expr);
        self
    }

    /// Pushes an expression that could move the cursor to the sequence, but does not require it.
    pub fn then_optional(mut self, expr: impl Expr + 'static) -> Self {
        self.exprs.push(Box::new(Optional::new(expr)));
        self
    }

    /// Pushes an expression that will match any of the provided expressions.
    ///
    /// If more than one of the provided expressions match, this function provides no guarantee
    /// as to which match will end up being used. If you need to get the longest of multiple
    /// matches, use [`Self::then_longest_of()`] instead.
    pub fn then_any_of(mut self, exprs: Vec<Box<dyn Expr>>) -> Self {
        self.exprs.push(Box::new(FirstMatchOf::new(exprs)));
        self
    }

    /// Pushes an expression that will match the longest of the provided expressions.
    ///
    /// If you don't need the longest match, prefer using the short-circuiting
    /// [`Self::then_any_of()`] instead.
    pub fn then_longest_of(mut self, exprs: Vec<Box<dyn Expr>>) -> Self {
        self.exprs.push(Box::new(LongestMatchOf::new(exprs)));
        self
    }

    /// Appends the steps in `other` onto the end of `self`.
    /// This is more efficient than [`Self::then`] because it avoids pointer redirection.
    pub fn then_seq(mut self, mut other: Self) -> Self {
        self.exprs.append(&mut other.exprs);
        self
    }

    /// Pushes an expression that will match any word from the given set of words, case-insensitive.
    pub fn then_word_set(self, words: &'static [&'static str]) -> Self {
        self.then(WordSet::new(words))
    }

    /// Shorthand for [`Self::then_word_set`].
    pub fn t_set(self, words: &'static [&'static str]) -> Self {
        self.then_word_set(words)
    }

    /// Match against one or more whitespace tokens.
    pub fn then_whitespace(self) -> Self {
        self.then(WhitespacePattern)
    }

    /// Shorthand for [`Self::then_whitespace`].
    pub fn t_ws(self) -> Self {
        self.then_whitespace()
    }

    /// Match against one or more whitespace tokens.
    pub fn then_whitespace_or_hyphen(self) -> Self {
        self.then(WhitespacePattern.or(|tok: &Token, _: &[char]| tok.kind.is_hyphen()))
    }

    /// Shorthand for [`Self::then_whitespace_or_hyphen`].
    pub fn t_ws_h(self) -> Self {
        self.then_whitespace_or_hyphen()
    }

    pub fn then_one_or_more(self, expr: impl Expr + 'static) -> Self {
        self.then(Repeating::new(Box::new(expr), 1))
    }

    pub fn then_one_or_more_spaced(self, expr: impl Expr + 'static) -> Self {
        let expr = Lrc::new(expr);
        self.then(
            SequenceExpr::default()
                .then(expr.clone())
                .then(Repeating::new(
                    Box::new(SequenceExpr::default().t_ws().then(expr)),
                    0,
                )),
        )
    }

    /// Create a new condition that will step one token forward if met.
    /// If the condition is _not_ met, the whole expression returns `None`.
    ///
    /// This can be used to build out exceptions to other rules.
    ///
    /// See [`UnlessStep`] for more info.
    pub fn then_unless(self, condition: impl Expr + 'static) -> Self {
        self.then(UnlessStep::new(condition, |_tok: &Token, _src: &[char]| {
            true
        }))
    }

    /// Match any single token.
    ///
    /// See [`AnyPattern`] for more info.
    pub fn then_anything(self) -> Self {
        self.then(AnyPattern)
    }

    /// Match any single token.
    ///
    /// Shorthand for [`Self::then_anything`].
    pub fn t_any(self) -> Self {
        self.then_anything()
    }

    // Word matching methods

    /// Matches any word.
    pub fn then_any_word(self) -> Self {
        self.then_kind_where(|kind| kind.is_word())
    }

    /// Match examples of `word` that have any capitalization.
    pub fn then_any_capitalization_of(self, word: &'static str) -> Self {
        self.then(Word::new(word))
    }

    /// Shorthand for [`Self::then_any_capitalization_of`].
    pub fn t_aco(self, word: &'static str) -> Self {
        self.then_any_capitalization_of(word)
    }

    /// Match examples of `word` case-sensitively.
    pub fn then_exact_word(self, word: &'static str) -> Self {
        self.then(Word::new_exact(word))
    }

    /// Match a fixed phrase.
    pub fn then_fixed_phrase(self, phrase: &'static str) -> Self {
        self.then(FixedPhrase::from_phrase(phrase))
    }

    /// Match any word except the ones in `words`.
    pub fn then_word_except(self, words: &'static [&'static str]) -> Self {
        self.then(move |tok: &Token, src: &[char]| {
            !tok.kind.is_word()
                || !words
                    .iter()
                    .any(|&word| tok.span.get_content(src).eq_ignore_ascii_case_str(word))
        })
    }

    // Token kind/predicate matching methods

    // One kind

    /// Matches any token whose `Kind` exactly matches.
    pub fn then_kind(self, kind: TokenKind) -> Self {
        self.then_kind_where(move |k| kind == *k)
    }

    /// Matches a token where the provided closure returns true for the token's kind.
    pub fn then_kind_where<F>(mut self, predicate: F) -> Self
    where
        F: Fn(&TokenKind) -> bool + Send + Sync + 'static,
    {
        self.exprs
            .push(Box::new(move |tok: &Token, _source: &[char]| {
                predicate(&tok.kind)
            }));
        self
    }

    /// Match a token of a given kind which is not in the list of words.
    pub fn then_kind_except<F>(self, pred_is: F, ex: &'static [&'static str]) -> Self
    where
        F: Fn(&TokenKind) -> bool + Send + Sync + 'static,
    {
        self.then(move |tok: &Token, src: &[char]| {
            pred_is(&tok.kind)
                && !ex
                    .iter()
                    .any(|&word| tok.span.get_content(src).eq_ignore_ascii_case_str(word))
        })
    }

    // Two kinds

    /// Match a token where both token kind predicates return true.
    /// For instance, a word that can be both noun and verb.
    pub fn then_kind_both<F1, F2>(self, pred_is_1: F1, pred_is_2: F2) -> Self
    where
        F1: Fn(&TokenKind) -> bool + Send + Sync + 'static,
        F2: Fn(&TokenKind) -> bool + Send + Sync + 'static,
    {
        self.then_kind_where(move |k| pred_is_1(k) && pred_is_2(k))
    }

    /// Match a token where either of the two token kind predicates returns true.
    /// For instance, an adjective or an adverb.
    pub fn then_kind_either<F1, F2>(self, pred_is_1: F1, pred_is_2: F2) -> Self
    where
        F1: Fn(&TokenKind) -> bool + Send + Sync + 'static,
        F2: Fn(&TokenKind) -> bool + Send + Sync + 'static,
    {
        self.then_kind_where(move |k| pred_is_1(k) || pred_is_2(k))
    }

    /// Match a token where neither of the two token kind predicates returns true.
    /// For instance, a word that can't be a verb or a noun.
    pub fn then_kind_neither<F1, F2>(self, pred_isnt_1: F1, pred_isnt_2: F2) -> Self
    where
        F1: Fn(&TokenKind) -> bool + Send + Sync + 'static,
        F2: Fn(&TokenKind) -> bool + Send + Sync + 'static,
    {
        self.then_kind_where(move |k| !pred_isnt_1(k) && !pred_isnt_2(k))
    }

    /// Match a token where the first token kind predicate returns true and the second returns false.
    /// For instance, a word that can be a noun but cannot be a verb.
    pub fn then_kind_is_but_is_not<F1, F2>(self, pred_is: F1, pred_not: F2) -> Self
    where
        F1: Fn(&TokenKind) -> bool + Send + Sync + 'static,
        F2: Fn(&TokenKind) -> bool + Send + Sync + 'static,
    {
        self.then_kind_where(move |k| pred_is(k) && !pred_not(k))
    }

    /// Match a token where the first token kind predicate returns true and the second returns false,
    /// and the token is not in the list of exceptions.
    pub fn then_kind_is_but_is_not_except<F1, F2>(
        self,
        pred_is: F1,
        pred_not: F2,
        ex: &'static [&'static str],
    ) -> Self
    where
        F1: Fn(&TokenKind) -> bool + Send + Sync + 'static,
        F2: Fn(&TokenKind) -> bool + Send + Sync + 'static,
    {
        self.then(move |tok: &Token, src: &[char]| {
            pred_is(&tok.kind)
                && !pred_not(&tok.kind)
                && !ex
                    .iter()
                    .any(|&word| tok.span.get_content(src).eq_ignore_ascii_case_str(word))
        })
    }

    /// Match a token where the first token kind predicate returns true and all of the second return false.
    /// For instance, a word that can be a verb but not a noun or an adjective.
    pub fn then_kind_is_but_isnt_any_of<F1, F2>(
        self,
        pred_is: F1,
        preds_isnt: &'static [F2],
    ) -> Self
    where
        F1: Fn(&TokenKind) -> bool + Send + Sync + 'static,
        F2: Fn(&TokenKind) -> bool + Send + Sync + 'static,
    {
        self.then_kind_where(move |k| pred_is(k) && !preds_isnt.iter().any(|pred| pred(k)))
    }

    /// Match a token where the first token kind predicate returns true and all of the second return false,
    /// and the token is not in the list of exceptions.
    /// For instance, an adjective that isn't also a verb or adverb or the word "likely".
    pub fn then_kind_is_but_isnt_any_of_except<F1, F2>(
        self,
        pred_is: F1,
        preds_isnt: &'static [F2],
        ex: &'static [&'static str],
    ) -> Self
    where
        F1: Fn(&TokenKind) -> bool + Send + Sync + 'static,
        F2: Fn(&TokenKind) -> bool + Send + Sync + 'static,
    {
        self.then(move |tok: &Token, src: &[char]| {
            pred_is(&tok.kind)
                && !preds_isnt.iter().any(|pred| pred(&tok.kind))
                && !ex
                    .iter()
                    .any(|&word| tok.span.get_content(src).eq_ignore_ascii_case_str(word))
        })
    }

    // More than two kinds

    /// Match a token where both of the first two token kind predicates return true,
    /// and the third returns false.
    /// For instance, a word that must be both noun and verb, but not adjective.
    pub fn then_kind_both_but_not<F1, F2, F3>(
        self,
        (pred_is_1, pred_is_2): (F1, F2),
        pred_not: F3,
    ) -> Self
    where
        F1: Fn(&TokenKind) -> bool + Send + Sync + 'static,
        F2: Fn(&TokenKind) -> bool + Send + Sync + 'static,
        F3: Fn(&TokenKind) -> bool + Send + Sync + 'static,
    {
        self.then_kind_where(move |k| pred_is_1(k) && pred_is_2(k) && !pred_not(k))
    }

    /// Match a token where any of the token kind predicates returns true.
    /// Like `then_kind_either` but for more than two predicates.
    pub fn then_kind_any<F>(self, preds_is: &'static [F]) -> Self
    where
        F: Fn(&TokenKind) -> bool + Send + Sync + 'static,
    {
        self.then_kind_where(move |k| preds_is.iter().any(|pred| pred(k)))
    }

    /// Match a token where none of the token kind predicates returns true.
    /// Like `then_kind_neither` but for more than two predicates.
    pub fn then_kind_none_of<F>(self, preds_isnt: &'static [F]) -> Self
    where
        F: Fn(&TokenKind) -> bool + Send + Sync + 'static,
    {
        self.then_kind_where(move |k| preds_isnt.iter().all(|pred| !pred(k)))
    }

    /// Match a token where any of the token kind predicates returns true,
    /// and the word is not in the list of exceptions.
    pub fn then_kind_any_except<F>(
        self,
        preds_is: &'static [F],
        ex: &'static [&'static str],
    ) -> Self
    where
        F: Fn(&TokenKind) -> bool + Send + Sync + 'static,
    {
        self.then(move |tok: &Token, src: &[char]| {
            preds_is.iter().any(|pred| pred(&tok.kind))
                && !ex
                    .iter()
                    .any(|&word| tok.span.get_content(src).eq_ignore_ascii_case_str(word))
        })
    }

    /// Match a token where any of the token kind predicates returns true,
    /// or the token is in the list of words.
    pub fn then_kind_any_or_words<F>(
        self,
        preds: &'static [F],
        words: &'static [&'static str],
    ) -> Self
    where
        F: Fn(&TokenKind) -> bool + Send + Sync + 'static,
    {
        self.then(move |tok: &Token, src: &[char]| {
            preds.iter().any(|pred| pred(&tok.kind))
                || words
                    .iter()
                    .any(|&word| tok.span.get_content(src).eq_ignore_ascii_case_str(word))
        })
    }

    /// Match a token where any of the first token kind predicates returns true,
    /// the second returns false, and the token is not in the list of exceptions.    
    pub fn then_kind_any_but_not_except<F1, F2>(
        self,
        preds_is: &'static [F1],
        pred_not: F2,
        ex: &'static [&'static str],
    ) -> Self
    where
        F1: Fn(&TokenKind) -> bool + Send + Sync + 'static,
        F2: Fn(&TokenKind) -> bool + Send + Sync + 'static,
    {
        self.then(move |tok: &Token, src: &[char]| {
            preds_is.iter().any(|pred| pred(&tok.kind))
                && !pred_not(&tok.kind)
                && !ex
                    .iter()
                    .any(|&word| tok.span.get_content(src).eq_ignore_ascii_case_str(word))
        })
    }

    // Word property matching methods

    // Out-of-vocabulary word. (Words not in the dictionary)
    gen_then_from_is!(oov);
    gen_then_from_is!(swear);

    // Part-of-speech matching methods

    // Nominals (nouns and pronouns)

    gen_then_from_is!(nominal);
    gen_then_from_is!(plural_nominal);
    gen_then_from_is!(non_plural_nominal);
    gen_then_from_is!(possessive_nominal);

    // Nouns

    gen_then_from_is!(noun);
    gen_then_from_is!(proper_noun);
    gen_then_from_is!(plural_noun);
    gen_then_from_is!(singular_noun);
    gen_then_from_is!(mass_noun_only);

    // Pronouns

    gen_then_from_is!(pronoun);
    gen_then_from_is!(personal_pronoun);
    gen_then_from_is!(first_person_singular_pronoun);
    gen_then_from_is!(first_person_plural_pronoun);
    gen_then_from_is!(second_person_pronoun);
    gen_then_from_is!(third_person_pronoun);
    gen_then_from_is!(third_person_singular_pronoun);
    gen_then_from_is!(third_person_plural_pronoun);
    gen_then_from_is!(subject_pronoun);
    gen_then_from_is!(object_pronoun);

    // Verbs

    gen_then_from_is!(verb);
    gen_then_from_is!(auxiliary_verb);
    gen_then_from_is!(linking_verb);
    gen_then_from_is!(verb_lemma);
    gen_then_from_is!(verb_simple_past_form);
    gen_then_from_is!(verb_past_participle_form);
    gen_then_from_is!(verb_progressive_form);
    gen_then_from_is!(verb_third_person_singular_present_form);

    // Adjectives

    gen_then_from_is!(adjective);
    gen_then_from_is!(positive_adjective);
    gen_then_from_is!(comparative_adjective);
    gen_then_from_is!(superlative_adjective);

    // Adverbs

    gen_then_from_is!(adverb);
    gen_then_from_is!(frequency_adverb);
    gen_then_from_is!(degree_adverb);

    // Determiners

    gen_then_from_is!(determiner);
    gen_then_from_is!(demonstrative_determiner);
    gen_then_from_is!(possessive_determiner);
    gen_then_from_is!(quantifier);
    gen_then_from_is!(non_quantifier_determiner);
    gen_then_from_is!(non_demonstrative_determiner);

    /// Push an [`IndefiniteArticle`] to the end of the operation list.
    pub fn then_indefinite_article(self) -> Self {
        self.then(IndefiniteArticle::default())
    }

    // Other parts of speech

    gen_then_from_is!(conjunction);
    gen_then_from_is!(preposition);

    // Numbers

    gen_then_from_is!(number);
    gen_then_from_is!(cardinal_number);
    gen_then_from_is!(ordinal_number);

    // Punctuation

    gen_then_from_is!(punctuation);
    gen_then_from_is!(apostrophe);
    gen_then_from_is!(comma);
    gen_then_from_is!(hyphen);
    gen_then_from_is!(period);
    gen_then_from_is!(semicolon);
    gen_then_from_is!(quote);

    // Other

    gen_then_from_is!(case_separator);
    gen_then_from_is!(likely_homograph);
    gen_then_from_is!(sentence_terminator);
}

impl<S> From<S> for SequenceExpr
where
    S: Step + 'static,
{
    fn from(step: S) -> Self {
        Self {
            exprs: vec![Box::new(step)],
        }
    }
}

#[cfg(test)]
mod tests {
    use crate::{
        Document, TokenKind,
        expr::{ExprExt, SequenceExpr},
        linting::tests::SpanVecExt,
    };

    #[test]
    fn test_kind_both() {
        let noun_and_verb =
            SequenceExpr::default().then_kind_both(TokenKind::is_noun, TokenKind::is_verb);
        let doc = Document::new_plain_english_curated("Use a good example.");
        let matches = noun_and_verb.iter_matches_in_doc(&doc).collect::<Vec<_>>();
        assert_eq!(matches.to_strings(&doc), vec!["Use", "good", "example"]);
    }

    #[test]
    fn test_adjective_or_determiner() {
        let expr = SequenceExpr::default()
            .then_kind_either(TokenKind::is_adjective, TokenKind::is_determiner);
        let doc = Document::new_plain_english_curated("Use a good example.");
        let matches = expr.iter_matches_in_doc(&doc).collect::<Vec<_>>();
        assert_eq!(matches.to_strings(&doc), vec!["a", "good"]);
    }

    #[test]
    fn test_noun_but_not_adjective() {
        let expr = SequenceExpr::default()
            .then_kind_is_but_is_not(TokenKind::is_noun, TokenKind::is_adjective);
        let doc = Document::new_plain_english_curated("Use a good example.");
        let matches = expr.iter_matches_in_doc(&doc).collect::<Vec<_>>();
        assert_eq!(matches.to_strings(&doc), vec!["Use", "example"]);
    }
}



================================================
FILE: harper-core/src/expr/similar_to_phrase.rs
================================================
use crate::patterns::{WithinEditDistance, Word};
use crate::{Document, Span, Token, TokenKind};

use super::{Expr, SequenceExpr};

pub struct SimilarToPhrase {
    phrase: SequenceExpr,
    fuzzy_phrase: SequenceExpr,
}

impl SimilarToPhrase {
    /// Create an error-tolerant SequenceExpr that looks for phrases similar to (but not the same as) that contained
    /// in the provided text.
    ///
    /// This is an expensive operation, so try to only do it at startup and in tests.
    ///
    /// It will panic if your document is too complex, so only run this with curated phrases.
    pub fn from_phrase(text: &str, max_edit_dist: u8) -> Self {
        let document = Document::new_plain_english_curated(text);

        Self::from_doc(&document, max_edit_dist)
    }

    /// Create an error-tolerant SequenceExpr that looks for phrases similar to (but not the same as) that contained
    /// in the provided document.
    ///
    /// This is an expensive operation, so try to only do it at startup and in tests.
    ///
    /// It will panic if your document contains certain token types, so only run this with curated phrases.
    pub fn from_doc(document: &Document, max_edit_dist: u8) -> Self {
        let mut phrase = SequenceExpr::default();
        let mut fuzzy_phrase = SequenceExpr::default();

        for token in document.fat_tokens() {
            match token.kind {
                TokenKind::Word(_lexeme_metadata) => {
                    phrase = phrase.then(Word::from_chars(token.content.as_slice()));
                    fuzzy_phrase = fuzzy_phrase
                        .then(WithinEditDistance::new(token.content.into(), max_edit_dist));
                }
                TokenKind::Space(_) => {
                    fuzzy_phrase = fuzzy_phrase.then_whitespace();
                    phrase = phrase.then_whitespace();
                }
                TokenKind::ParagraphBreak => {
                    fuzzy_phrase = fuzzy_phrase.then_whitespace();
                    phrase = phrase.then_whitespace();
                }
                _ => panic!("Fell out of expected document formats."),
            }
        }

        Self {
            phrase,
            fuzzy_phrase,
        }
    }
}

impl Expr for SimilarToPhrase {
    fn run(&self, cursor: usize, tokens: &[Token], source: &[char]) -> Option<Span<Token>> {
        if self.phrase.run(cursor, tokens, source).is_some() {
            return None;
        }
        self.fuzzy_phrase.run(cursor, tokens, source)
    }
}



================================================
FILE: harper-core/src/expr/space_or_hyphen.rs
================================================
use crate::expr::FirstMatchOf;
use crate::patterns::WhitespacePattern;
use crate::{Span, Token};

use super::Expr;

/// Matches either a space or a hyphen, useful for matching compound words.
#[derive(Default)]
pub struct SpaceOrHyphen;

impl Expr for SpaceOrHyphen {
    fn run(&self, cursor: usize, tokens: &[Token], source: &[char]) -> Option<Span<Token>> {
        FirstMatchOf::new(vec![
            Box::new(WhitespacePattern),
            Box::new(|tok: &Token, _source: &[char]| tok.kind.is_hyphen()),
        ])
        .run(cursor, tokens, source)
    }
}



================================================
FILE: harper-core/src/expr/spelled_number_expr.rs
================================================
use crate::expr::LongestMatchOf;
use crate::patterns::{WhitespacePattern, WordSet};
use crate::{Span, Token};

use super::{Expr, SequenceExpr};

/// Matches spelled-out numbers from one to ninety-nine
#[derive(Default)]
pub struct SpelledNumberExpr;

impl Expr for SpelledNumberExpr {
    fn run(&self, cursor: usize, tokens: &[Token], source: &[char]) -> Option<Span<Token>> {
        if tokens.is_empty() {
            return None;
        }

        // The numbers that can be in the 2nd position of a compound number.
        // A subset of the standalone numbers since we can't say "twenty zero" or "twenty eleven"
        // "Zero" and "ten" don't belong: twenty-one ✅ twenty-zero ❌ twenty-ten ❌
        let units = &[
            "one", "two", "three", "four", "five", "six", "seven", "eight", "nine",
        ];

        // These can't make a compound with `tens` but they can stand alone
        let teens = &[
            "ten",
            "eleven",
            "twelve",
            "thirteen",
            "fourteen",
            "fifteen",
            "sixteen",
            "seventeen",
            "eighteen",
            "nineteen",
        ];

        // These can make a compound with the part_2 standalones above.
        // "Ten" and "hundred" don't belong: twenty-one ✅ ten-one ❌ hundred-one ❌
        let tens = &[
            "twenty", "thirty", "forty", "fifty", "sixty", "seventy", "eighty", "ninety",
        ];

        let single_words = WordSet::new(
            &units
                .iter()
                .chain(teens.iter())
                .chain(tens.iter())
                .copied()
                .chain(std::iter::once("zero"))
                .collect::<Vec<&str>>(),
        );

        let tens_units_compounds = SequenceExpr::default()
            .then(WordSet::new(tens))
            .then_any_of(vec![
                Box::new(|t: &Token, _s: &[char]| t.kind.is_hyphen()),
                Box::new(WhitespacePattern),
            ])
            .then(WordSet::new(units));

        let expr =
            LongestMatchOf::new(vec![Box::new(single_words), Box::new(tens_units_compounds)]);

        expr.run(cursor, tokens, source)
    }
}

#[cfg(test)]
mod tests {
    use super::SpelledNumberExpr;
    use crate::Document;
    use crate::expr::ExprExt;
    use crate::linting::tests::SpanVecExt;

    #[test]
    fn matches_single_digit() {
        let doc = Document::new_markdown_default_curated("one two three");
        let matches = SpelledNumberExpr.iter_matches_in_doc(&doc);
        assert_eq!(matches.count(), 3);
    }

    #[test]
    fn matches_teens() {
        let doc = Document::new_markdown_default_curated("ten eleven twelve");
        let matches = SpelledNumberExpr.iter_matches_in_doc(&doc);
        assert_eq!(matches.count(), 3);
    }

    #[test]
    fn matches_tens() {
        let doc = Document::new_markdown_default_curated("twenty thirty forty");
        let matches = SpelledNumberExpr.iter_matches_in_doc(&doc);
        assert_eq!(matches.count(), 3);
    }

    #[test]
    fn matches_compound_numbers() {
        let doc = Document::new_markdown_default_curated("twenty-one thirty-two");
        let matches = SpelledNumberExpr
            .iter_matches_in_doc(&doc)
            .collect::<Vec<_>>();

        // Debug output
        println!("Found {} matches:", matches.len());
        for m in &matches {
            let text: String = doc.get_tokens()[m.start..m.end]
                .iter()
                .map(|t| doc.get_span_content_str(&t.span))
                .collect();
            println!("- '{text}' (span: {m:?})");
        }

        assert_eq!(matches.len(), 2);
    }

    #[test]
    fn deep_thought() {
        let doc = Document::new_markdown_default_curated(
            "the answer to the ultimate question of life, the universe, and everything is forty-two",
        );
        let matches = SpelledNumberExpr
            .iter_matches_in_doc(&doc)
            .collect::<Vec<_>>();

        dbg!(&matches);
        dbg!(matches.to_strings(&doc));

        assert_eq!(matches.to_strings(&doc), vec!["forty-two"]);
    }

    #[test]
    fn jacksons() {
        let doc = Document::new_markdown_default_curated(
            "A, B, C It's easy as one, two, three. Or simple as Do-Re-Mi",
        );
        let matches = SpelledNumberExpr
            .iter_matches_in_doc(&doc)
            .collect::<Vec<_>>();

        assert_eq!(matches.to_strings(&doc), vec!["one", "two", "three"]);
    }

    #[test]
    fn orwell() {
        let doc = Document::new_markdown_default_curated("Nineteen Eighty-Four");
        let matches = SpelledNumberExpr
            .iter_matches_in_doc(&doc)
            .collect::<Vec<_>>();

        assert_eq!(matches.to_strings(&doc), vec!["Nineteen", "Eighty-Four"]);
    }

    #[test]
    fn get_smart() {
        let doc = Document::new_markdown_default_curated(
            "Maxwell Smart was Agent Eighty-Six, but who was Agent Ninety-Nine?",
        );
        let matches = SpelledNumberExpr
            .iter_matches_in_doc(&doc)
            .collect::<Vec<_>>();

        assert_eq!(matches.to_strings(&doc), vec!["Eighty-Six", "Ninety-Nine"]);
    }

    #[test]
    fn hyphens_or_spaces() {
        let doc = Document::new_markdown_default_curated(
            "twenty-one, thirty two, forty-three, fifty four, sixty-five, seventy six, eighty-seven, ninety eight",
        );
        let matches = SpelledNumberExpr
            .iter_matches_in_doc(&doc)
            .collect::<Vec<_>>();

        assert_eq!(
            matches.to_strings(&doc),
            vec![
                "twenty-one",
                "thirty two",
                "forty-three",
                "fifty four",
                "sixty-five",
                "seventy six",
                "eighty-seven",
                "ninety eight",
            ]
        );
    }

    #[test]
    fn waiting_since() {
        let doc = Document::new_markdown_default_curated("I have been waiting since two hours.");
        let matches = SpelledNumberExpr
            .iter_matches_in_doc(&doc)
            .collect::<Vec<_>>();

        assert_eq!(matches.to_strings(&doc), vec!["two"]);
    }
}



================================================
FILE: harper-core/src/expr/step.rs
================================================
use crate::{LSend, Token, patterns::Pattern};

/// An atomic step within a larger expression.
///
/// Its principle job is to identify (if any) the next position of the cursor.
/// When cursor is moved, all tokens between the current cursor and the target position will be
/// added to the match group.
pub trait Step: LSend {
    fn step(&self, tokens: &[Token], cursor: usize, source: &[char]) -> Option<isize>;
}

impl<P> Step for P
where
    P: Pattern,
{
    fn step(&self, tokens: &[Token], cursor: usize, source: &[char]) -> Option<isize> {
        self.matches(&tokens[cursor..], source).map(|i| i as isize)
    }
}



================================================
FILE: harper-core/src/expr/time_unit_expr.rs
================================================
use crate::expr::LongestMatchOf;
use crate::patterns::WordSet;
use crate::{Span, Token};

use super::Expr;

/// Matches a time unit.
///
/// Matches standard units from microsecond to decade.
/// Matches other 'units' such as moment, night, weekend.
/// Matches singular and plural forms.
/// Matches possessive forms (which are also common misspellings for the plurals).
/// Matches abbreviations.
#[derive(Default)]
pub struct TimeUnitExpr;

impl Expr for TimeUnitExpr {
    fn run(&self, cursor: usize, tokens: &[Token], source: &[char]) -> Option<Span<Token>> {
        if tokens.is_empty() {
            return None;
        }

        let units_definite_singular = WordSet::new(&[
            "microsecond",
            "millisecond",
            "second",
            "minute",
            "hour",
            "day",
            "week",
            "month",
            "year",
            "decade",
        ]);

        let units_definite_plural = WordSet::new(&[
            "microseconds",
            "milliseconds",
            "seconds",
            "minutes",
            "hours",
            "days",
            "weeks",
            "months",
            "years",
            "decades",
        ]);

        let units_definite_apos = WordSet::new(&[
            "microsecond's",
            "millisecond's",
            "second's",
            "minute's",
            "hour's",
            "day's",
            "week's",
            "month's",
            "year's",
            "decade's",
        ]);

        // ms
        let units_definite_abbrev = WordSet::new(&["ms"]);

        let units_other_singular = WordSet::new(&["moment", "night", "weekend"]);
        let units_other_plural = WordSet::new(&["moments", "nights", "weekends"]);
        let units_other_apos = WordSet::new(&["moment's", "night's", "weekend's"]);

        let units = LongestMatchOf::new(vec![
            Box::new(units_definite_singular),
            Box::new(units_definite_plural),
            Box::new(units_other_singular),
            Box::new(units_other_plural),
            Box::new(units_definite_abbrev),
            Box::new(units_definite_apos),
            Box::new(units_other_apos),
        ]);

        units.run(cursor, tokens, source)
    }
}



================================================
FILE: harper-core/src/expr/unless_step.rs
================================================
use crate::{Token, expr::Expr};

use super::Step;

/// Provides the ability to use an expression as a condition.
/// If the condition does __not match__, it will return the result of the provided step.
pub struct UnlessStep<E: Expr, S: Step> {
    condition: E,
    step: S,
}

impl<E, S> UnlessStep<E, S>
where
    E: Expr,
    S: Step,
{
    pub fn new(condition: E, step: S) -> Self {
        Self { condition, step }
    }
}

impl<E: Expr, S: Step> Step for UnlessStep<E, S> {
    fn step(&self, tokens: &[Token], cursor: usize, source: &[char]) -> Option<isize> {
        if self.condition.run(cursor, tokens, source).is_none() {
            self.step.step(tokens, cursor, source)
        } else {
            None
        }
    }
}



================================================
FILE: harper-core/src/expr/word_expr_group.rs
================================================
use hashbrown::HashMap;

use super::first_match_of::FirstMatchOf;
use super::{Expr, SequenceExpr};
use crate::{CharString, Span, Token};

/// An expression collection to look for expressions that start with a specific
/// word.
///
/// The benefit of using this struct over other methods increases for larger collections.
#[derive(Default)]
pub struct WordExprGroup<E>
where
    E: Expr,
{
    exprs: HashMap<CharString, E>,
}

impl WordExprGroup<FirstMatchOf> {
    pub fn add(&mut self, word: &str, expr: impl Expr + 'static) {
        let chars = word.chars().collect();

        if let Some(group) = self.exprs.get_mut(&chars) {
            group.add(expr);
        } else {
            let mut group = FirstMatchOf::default();
            group.add(expr);
            self.exprs.insert(chars, group);
        }
    }

    /// Add a pattern that matches just a word on its own, without anything else required to match.
    pub fn add_word(&mut self, word: &'static str) {
        self.add(word, SequenceExpr::default().then_exact_word(word));
    }
}

impl<E> Expr for WordExprGroup<E>
where
    E: Expr,
{
    fn run(&self, cursor: usize, tokens: &[Token], source: &[char]) -> Option<Span<Token>> {
        let first = tokens.get(cursor)?;
        if !first.kind.is_word() {
            return None;
        }

        let word_chars = first.span.get_content(source);
        let inner_pattern = self.exprs.get(word_chars)?;

        inner_pattern.run(cursor, tokens, source)
    }
}



================================================
FILE: harper-core/src/ignored_lints/lint_context.rs
================================================
use std::hash::{DefaultHasher, Hash, Hasher};

use serde::{Deserialize, Serialize};

use crate::{
    Document, FatToken,
    linting::{Lint, LintKind, Suggestion},
};

/// A location-agnostic structure that attempts to captures the context and content that a [`Lint`]
/// occurred.
#[derive(Debug, Hash, Serialize, Deserialize)]
pub struct LintContext {
    pub lint_kind: LintKind,
    pub suggestions: Vec<Suggestion>,
    pub message: String,
    pub priority: u8,
    pub tokens: Vec<FatToken>,
}

impl LintContext {
    pub fn from_lint(lint: &Lint, document: &Document) -> Self {
        let Lint {
            lint_kind,
            suggestions,
            message,
            priority,
            ..
        } = lint.clone();

        let problem_tokens = document.token_indices_intersecting(lint.span);
        let prequel_tokens = lint
            .span
            .with_len(2)
            .pulled_by(2)
            .map(|v| document.token_indices_intersecting(v))
            .unwrap_or_default();
        let sequel_tokens = document.token_indices_intersecting(lint.span.with_len(2).pushed_by(2));

        let tokens = prequel_tokens
            .into_iter()
            .chain(problem_tokens)
            .chain(sequel_tokens)
            .flat_map(|idx| document.get_token(idx))
            .map(|t| t.to_fat(document.get_source()))
            .collect();

        Self {
            lint_kind,
            suggestions,
            message,
            priority,
            tokens,
        }
    }

    pub fn default_hash(&self) -> u64 {
        let mut hasher = DefaultHasher::default();
        self.hash(&mut hasher);

        hasher.finish()
    }
}



================================================
FILE: harper-core/src/ignored_lints/mod.rs
================================================
mod lint_context;

use hashbrown::HashSet;
pub use lint_context::LintContext;
use serde::{Deserialize, Serialize};

use crate::{Document, linting::Lint};

/// A structure that keeps track of lints that have been ignored by users.
///
/// To use this structure, apply [`Self::remove_ignored`] on the output of a
/// [`Linter`](crate::linting::Linter).
#[derive(Debug, Default, Serialize, Deserialize)]
pub struct IgnoredLints {
    context_hashes: HashSet<u64>,
}

impl IgnoredLints {
    pub fn new() -> Self {
        Self::default()
    }

    /// Move entries from another instance to this one.
    pub fn append(&mut self, other: Self) {
        self.context_hashes.extend(other.context_hashes)
    }

    /// Add a lint to the list.
    pub fn ignore_lint(&mut self, lint: &Lint, document: &Document) {
        let context = LintContext::from_lint(lint, document);
        let context_hash = context.default_hash();

        self.ignore_hash(context_hash);
    }

    /// Add a context hash to the list of ignored lints.
    pub fn ignore_hash(&mut self, hash: u64) {
        self.context_hashes.insert(hash);
    }

    pub fn is_ignored(&self, lint: &Lint, document: &Document) -> bool {
        let context = LintContext::from_lint(lint, document);
        let hash = context.default_hash();

        self.context_hashes.contains(&hash)
    }

    /// Remove ignored Lints from a [`Vec`].
    pub fn remove_ignored(&self, lints: &mut Vec<Lint>, document: &Document) {
        if self.context_hashes.is_empty() {
            return;
        }

        lints.retain(|lint| !self.is_ignored(lint, document));
    }
}

#[cfg(test)]
mod tests {
    use quickcheck::TestResult;
    use quickcheck_macros::quickcheck;

    use super::IgnoredLints;
    use crate::spell::FstDictionary;
    use crate::{
        Dialect, Document,
        linting::{LintGroup, Linter},
    };

    #[quickcheck]
    fn can_ignore_all(text: String) -> bool {
        let document = Document::new_markdown_default_curated(&text);

        let mut lints =
            LintGroup::new_curated(FstDictionary::curated(), Dialect::American).lint(&document);

        let mut ignored = IgnoredLints::new();

        for lint in &lints {
            ignored.ignore_lint(lint, &document);
        }

        ignored.remove_ignored(&mut lints, &document);
        lints.is_empty()
    }

    #[quickcheck]
    fn can_ignore_first(text: String) -> TestResult {
        let document = Document::new_markdown_default_curated(&text);

        let mut lints =
            LintGroup::new_curated(FstDictionary::curated(), Dialect::American).lint(&document);

        let Some(first) = lints.first().cloned() else {
            return TestResult::discard();
        };

        let mut ignored = IgnoredLints::new();
        ignored.ignore_lint(&first, &document);

        ignored.remove_ignored(&mut lints, &document);

        TestResult::from_bool(!lints.contains(&first))
    }

    // Check that ignoring the nth lint found in source text actually removes it (and no others).
    fn assert_ignore_lint_reduction(source: &str, nth_lint: usize) {
        let document = Document::new_markdown_default_curated(source);

        let mut lints =
            LintGroup::new_curated(FstDictionary::curated(), Dialect::American).lint(&document);

        let nth = lints.get(nth_lint).cloned().unwrap_or_else(|| {
            panic!("If ignoring the lint at {nth_lint}, make sure there are enough problems.")
        });

        let mut ignored = IgnoredLints::new();
        ignored.ignore_lint(&nth, &document);

        let prev_count = lints.len();

        ignored.remove_ignored(&mut lints, &document);

        assert_eq!(prev_count, lints.len() + 1);
        assert!(!lints.contains(&nth));
    }

    #[test]
    fn an_a() {
        let source = "There is an problem in this text. Here is an second one.";

        assert_ignore_lint_reduction(source, 0);
        assert_ignore_lint_reduction(source, 1);
    }

    #[test]
    fn spelling() {
        let source = "There is a problm in this text. Here is a scond one.";

        assert_ignore_lint_reduction(source, 0);
        assert_ignore_lint_reduction(source, 1);
    }
}



================================================
FILE: harper-core/src/lexing/email_address.rs
================================================
use itertools::Itertools;

use super::FoundToken;
use super::hostname::lex_hostname;
use crate::TokenKind;

pub fn lex_email_address(source: &[char]) -> Option<FoundToken> {
    // Location of the @ sign
    let (at_loc, _) = source.iter().enumerate().rev().find(|(_, c)| **c == '@')?;

    let local_part = &source[0..at_loc];

    if !validate_local_part(local_part) {
        return None;
    }

    let domain_part_len = lex_hostname(&source[at_loc + 1..])?;

    if domain_part_len == 0 {
        return None;
    }

    Some(FoundToken {
        next_index: at_loc + 1 + domain_part_len,
        token: TokenKind::EmailAddress,
    })
}

/// Check to see if a given slice is a valid local part of an email address.
fn validate_local_part(mut local_part: &[char]) -> bool {
    if local_part.len() > 64 || local_part.is_empty() {
        return false;
    }

    let is_quoted =
        local_part.first().cloned() == Some('"') && local_part.last().cloned() == Some('"');

    if is_quoted && local_part.len() < 2 {
        return false;
    }

    if is_quoted {
        local_part = &local_part[1..local_part.len() - 1];
    }

    if !is_quoted {
        if !local_part.iter().cloned().all(valid_unquoted_character) {
            return false;
        }

        if local_part.first().cloned().unwrap() == '.' || local_part.last().cloned().unwrap() == '.'
        {
            return false;
        }

        for (c, n) in local_part.iter().tuple_windows() {
            if *c == '.' && *n == '.' {
                return false;
            }
        }
    } else {
        let mut iter = local_part.iter().cloned();

        while let Some(c) = iter.next() {
            if c == '\\' {
                iter.next();
                continue;
            }

            let also_valid = ['(', ')', ',', ':', ';', '<', '>', '@', '[', ']', ' '];

            if !valid_unquoted_character(c) && !also_valid.contains(&c) {
                return false;
            }
        }
    }

    true
}

/// Check if a given character is valid in an unquoted local part of an address
fn valid_unquoted_character(c: char) -> bool {
    if matches!(c,
        'A'..='Z' |
        'a'..='z' |
        '0'..='9'
    ) {
        return true;
    }

    if c > '\u{007F}' {
        return true;
    }

    let others = [
        '!', '#', '$', '%', '&', '\'', '*', '+', '-', '/', '=', '?', '^', '_', '`', '{', '|', '}',
        '~', '.',
    ];

    if others.contains(&c) {
        return true;
    }

    false
}

#[cfg(test)]
mod tests {
    use rand::Rng;

    use super::super::hostname::tests::example_domain_parts;
    use super::{lex_email_address, validate_local_part};

    fn example_local_parts() -> impl Iterator<Item = Vec<char>> {
        [
            r"simple",
            r"very.common",
            r"x",
            r"long.email-address-with-hyphens",
            r"user.name+tag+sorting",
            r"name/surname",
            r"admin",
            r"example",
            r#"" ""#,
            r#""john..doe""#,
            r"mailhost!username",
            r#""very.(),:;<>[]\".VERY.\"very@\\ \"very\".unusual""#,
            r"user%example.com",
            r"user-",
            r"postmaster",
            r"postmaster",
            r"_test",
        ]
        .into_iter()
        .map(|s| s.chars().collect())
    }

    #[test]
    fn example_local_parts_pass_validation() {
        for local in example_local_parts() {
            dbg!(local.iter().collect::<String>());
            assert!(validate_local_part(&local));
        }
    }

    #[test]
    fn test_many_example_email_addresses() {
        for local in example_local_parts() {
            for mut domain in example_domain_parts() {
                // Generate email address
                let mut address = local.clone();
                address.push('@');
                address.append(&mut domain);

                dbg!(address.iter().collect::<String>());
                let found = lex_email_address(&address).unwrap();
                assert_eq!(found.next_index, address.len());
            }
        }
    }

    #[test]
    fn does_not_allow_empty_domain() {
        for local in example_local_parts() {
            // Generate invalid email address
            let mut address = local.clone();
            address.push('@');
            address.push(' ');

            assert!(lex_email_address(&address).is_none());
        }
    }

    /// Tests that the email parser will not throw a panic under some random
    /// situations.
    #[test]
    fn survives_random_chars() {
        let mut rng = rand::thread_rng();

        let mut buf = [' '; 128];

        for _ in 0..1 << 16 {
            rng.try_fill(&mut buf).unwrap();

            lex_email_address(&buf);
        }
    }
}



================================================
FILE: harper-core/src/lexing/hostname.rs
================================================
use crate::TokenKind;

use super::FoundToken;

/// Lex a hostname token.
pub fn lex_hostname_token(source: &[char]) -> Option<FoundToken> {
    let len = lex_hostname(source)?;

    // Might be word, just skip it.
    if len <= 1 {
        return None;
    }

    if !source.get(1..len - 1)?.contains(&'.') {
        return None;
    }

    if source.get(len - 1) == Some(&'.') {
        return None;
    }

    // For the sake of semantics and downstream grammar checking.
    if !ends_with_common_tld(&source[0..len]) {
        return None;
    }

    Some(FoundToken {
        next_index: len,
        token: TokenKind::Hostname,
    })
}

pub fn lex_hostname(source: &[char]) -> Option<usize> {
    let mut passed_chars = 0;

    // The beginning has different requirements from the rest of the hostname.
    let first = source.first()?;

    if !matches!(first,  'A'..='Z' |  'a'..='z' | '0'..='9' ) {
        return None;
    }

    for label in source.split(|c| *c == '.') {
        for c in label {
            passed_chars += 1;
            if !matches!(c,  'A'..='Z' |  'a'..='z' | '0'..='9' | '-') {
                return Some(passed_chars - 1);
            }
        }

        passed_chars += 1;
    }

    if passed_chars == 0 {
        None
    } else {
        Some(passed_chars - 1)
    }
}

const COMMON_TLDS: &[&[char]] = &[
    &['c', 'o', 'm'],
    &['n', 'e', 't'],
    &['o', 'r', 'g'],
    &['e', 'd', 'u'],
    &['g', 'o', 'v'],
    &['m', 'i', 'l'],
    &['t', 'x', 't'],
    &['i', 'o'],
    &['c', 'o'],
    &['u', 's'],
    &['u', 'k'],
    &['d', 'e'],
    &['c', 'a'],
    &['a', 'u'],
    &['j', 'p'],
];

fn ends_with_common_tld(input: &[char]) -> bool {
    for tld in COMMON_TLDS {
        let n = tld.len();
        if input.len() >= n && &input[input.len() - n..] == *tld {
            return true;
        }
    }
    false
}

#[cfg(test)]
pub mod tests {
    use super::lex_hostname;

    pub fn example_domain_parts() -> impl Iterator<Item = Vec<char>> {
        [
            r"example.com",
            r"example.com",
            r"example.com",
            r"and.subdomains.example.com",
            r"example.com",
            r"example.com",
            r"example",
            r"s.example",
            r"example.org",
            r"example.org",
            r"example.org",
            r"strange.example.com",
            r"example.org",
            r"example.org",
        ]
        .into_iter()
        .map(|s| s.chars().collect())
    }

    #[test]
    fn can_parse_example_hostnames() {
        for domain in example_domain_parts() {
            dbg!(domain.iter().collect::<String>());
            assert_eq!(lex_hostname(&domain), Some(domain.len()));
        }
    }

    #[test]
    fn hyphen_cannot_open_hostname() {
        let host: Vec<_> = "-something.com".chars().collect();
        assert!(lex_hostname(&host).is_none())
    }
}



================================================
FILE: harper-core/src/lexing/mod.rs
================================================
mod email_address;
mod hostname;
mod url;

use hostname::lex_hostname_token;
use ordered_float::OrderedFloat;
use url::lex_url;

use self::email_address::lex_email_address;
use crate::char_ext::CharExt;
use crate::punctuation::{Punctuation, Quote};
use crate::{Number, TokenKind};

#[derive(Debug, Eq, PartialEq)]
pub struct FoundToken {
    /// The index of the character __after__ the lexed token
    pub next_index: usize,
    /// Token lexed
    pub token: TokenKind,
}

pub fn lex_weir_token(source: &[char]) -> Option<FoundToken> {
    let lexers = [
        lex_punctuation,
        lex_tabs,
        lex_spaces,
        lex_newlines,
        lex_plural_digit, // Before lex_number, which would match the initial digit
        lex_hex_number,   // Before lex_number, which would match the initial 0
        lex_long_decade,  // Before lex_number, which would match the digits up to the -s
        lex_number,
        lex_url,
        lex_email_address,
        lex_hostname_token,
        lex_word,
        lex_catch,
    ];

    for lexer in lexers {
        if let Some(f) = lexer(source) {
            return Some(f);
        }
    }

    None
}

pub fn lex_english_token(source: &[char]) -> Option<FoundToken> {
    let lexers = [
        lex_regexish,
        lex_punctuation,
        lex_tabs,
        lex_spaces,
        lex_newlines,
        lex_plural_digit, // Before lex_number, which would match the initial digit
        lex_hex_number,   // Before lex_number, which would match the initial 0
        lex_long_decade,  // Before lex_number, which would match the digits up to the -s
        lex_number,
        lex_url,
        lex_email_address,
        lex_hostname_token,
        lex_word,
        lex_catch,
    ];

    for lexer in lexers {
        if let Some(f) = lexer(source) {
            return Some(f);
        }
    }

    None
}

fn lex_word(source: &[char]) -> Option<FoundToken> {
    let is_tack = |c: char| lex_punctuation(&[c]).is_some_and(|t| t.token.is_apostrophe());

    let mut end = source
        .iter()
        .position(|c| !c.is_english_lingual() && !c.is_ascii_digit() && !is_tack(*c))
        .unwrap_or(source.len());

    while end >= 1 && is_tack(source[end - 1]) {
        end -= 1;
    }

    if end == 0 {
        None
    } else {
        Some(FoundToken {
            next_index: end,
            token: TokenKind::Word(None),
        })
    }
}

fn lex_number(source: &[char]) -> Option<FoundToken> {
    if source.is_empty() {
        return None;
    }

    if !source[0].is_numeric() {
        return None;
    }

    let end = source
        .iter()
        .enumerate()
        .rev()
        .find_map(|(i, v)| v.is_ascii_digit().then_some(i))?;

    let mut s: String = source[0..end + 1].iter().collect();

    // Find the longest possible valid number
    while !s.is_empty() {
        if let Ok(n) = s.parse::<f64>() {
            let precision = s.chars().rev().position(|c| c == '.').unwrap_or_default();

            if !s.ends_with('.') {
                return Some(FoundToken {
                    token: TokenKind::Number(Number {
                        value: n.into(),
                        suffix: None,
                        radix: 10,
                        precision,
                    }),
                    next_index: s.len(),
                });
            }
        }

        s.pop();
    }

    None
}

// Often in comments we mention partial- or pseudo- regexes. Here's an example from Ghidra:
// ([a-z0-9]+ only) - We previously flagged just the z0 in the middle of it.
fn lex_regexish(src: &[char]) -> Option<FoundToken> {
    let l = src.len();
    let mut i = 0;

    if i >= l || src[i] != '[' {
        return None;
    }
    i += 1;

    loop {
        if i >= l || !src[i].is_alphanumeric() {
            return None;
        }
        i += 1;
        if i < l && src[i] == '-' {
            i += 1;
            if i >= l || !src[i].is_alphanumeric() {
                return None;
            }
            i += 1;
        }

        if i >= l || src[i] != ']' {
            continue;
        }
        break;
    }

    Some(FoundToken {
        token: TokenKind::Regexish,
        next_index: i + 1,
    })
}

fn lex_hex_number(source: &[char]) -> Option<FoundToken> {
    // < 3 to avoid accepting 0x alone
    if source.len() < 3 || source[0] != '0' || source[1] != 'x' || !source[2].is_ascii_hexdigit() {
        return None;
    }

    let mut i = 2;
    let len = source.len();

    while i < len {
        let next = source[i];

        if !next.is_ascii_hexdigit() {
            if !next.is_alphanumeric() {
                break;
            } else {
                return None;
            }
        }

        i += 1;
    }

    let s: String = source[2..i].iter().collect();

    // Should always succeed unless the logic above is broken
    if let Ok(n) = u64::from_str_radix(&s, 16) {
        return Some(FoundToken {
            token: TokenKind::Number(Number {
                value: OrderedFloat(n as f64),
                suffix: None,
                radix: 16,
                precision: 0,
            }),
            next_index: s.len() + 2,
        });
    }

    None
}

fn lex_long_decade(source: &[char]) -> Option<FoundToken> {
    // lex 4-digit decades in their plural such as: 1980s 1990s 2000s 2020s
    if source.len() < 5 {
        return None;
    }
    if source[0] != '1' && source[0] != '2' {
        return None;
    }
    if !source[1].is_ascii_digit() {
        return None;
    }
    if !source[2].is_ascii_digit() {
        return None;
    }
    if source[3] != '0' {
        return None;
    }
    if source[4] != 's' {
        return None;
    }

    Some(FoundToken {
        token: TokenKind::Decade,
        next_index: 5,
    })
}

fn lex_plural_digit(src: &[char]) -> Option<FoundToken> {
    // Issue #774
    let l = src.len();
    let mut i = 0;

    if src.is_empty() || !src[i].is_ascii_alphanumeric() {
        return None;
    }
    i += 1;

    if l > i && src[i] == '\'' {
        i += 1;
    }

    if l > i && src[i] == 's' {
        i += 1;

        if l == i || !src[i].is_ascii_alphanumeric() {
            return Some(FoundToken {
                token: TokenKind::Word(None),
                next_index: i,
            });
        }
    }
    None
}

fn lex_newlines(source: &[char]) -> Option<FoundToken> {
    let count = source.iter().take_while(|c| **c == '\n').count();

    if count > 0 {
        Some(FoundToken {
            token: TokenKind::Newline(count),
            next_index: count,
        })
    } else {
        None
    }
}

fn lex_tabs(source: &[char]) -> Option<FoundToken> {
    let count = source.iter().take_while(|c| **c == '\t').count();

    if count > 0 {
        Some(FoundToken {
            token: TokenKind::Space(count * 2),
            next_index: count,
        })
    } else {
        None
    }
}

fn lex_spaces(source: &[char]) -> Option<FoundToken> {
    let count = source.iter().take_while(|c| **c == ' ').count();

    if count > 0 {
        Some(FoundToken {
            token: TokenKind::Space(count),
            next_index: count,
        })
    } else {
        None
    }
}

fn lex_punctuation(source: &[char]) -> Option<FoundToken> {
    if let Some(found) = lex_quote(source) {
        return Some(found);
    }

    let c = source.first()?;
    let punct = Punctuation::from_char(*c)?;

    Some(FoundToken {
        next_index: 1,
        token: TokenKind::Punctuation(punct),
    })
}

fn lex_quote(source: &[char]) -> Option<FoundToken> {
    let c = *source.first()?;

    if c == '\"' || c == '“' || c == '”' {
        Some(FoundToken {
            next_index: 1,
            token: TokenKind::Punctuation(Punctuation::Quote(Quote { twin_loc: None })),
        })
    } else {
        None
    }
}

/// Covers cases not covered by the other lints.
fn lex_catch(_source: &[char]) -> Option<FoundToken> {
    Some(FoundToken {
        next_index: 1,
        token: TokenKind::Unlintable,
    })
}

#[cfg(test)]
mod tests {
    use crate::Punctuation;
    use crate::char_string::char_string;
    use crate::lexing::lex_plural_digit;

    use super::lex_english_token;
    use super::lex_hex_number;
    use super::lex_long_decade;
    use super::lex_number;
    use super::lex_word;
    use super::{FoundToken, TokenKind};

    // test various kinds of number
    #[test]
    fn lexes_0() {
        let source: Vec<_> = "0".chars().collect();
        assert!(matches!(
            lex_number(&source),
            Some(FoundToken {
                token: TokenKind::Number(_),
                ..
            })
        ));
    }

    #[test]
    fn lexes_0_point_0() {
        let source: Vec<_> = "0.0".chars().collect();
        assert!(matches!(
            lex_number(&source),
            Some(FoundToken {
                token: TokenKind::Number(_),
                ..
            })
        ));
    }

    #[test]
    fn lexes_00() {
        let source: Vec<_> = "00".chars().collect();
        assert!(matches!(
            lex_number(&source),
            Some(FoundToken {
                token: TokenKind::Number(_),
                ..
            })
        ));
    }

    #[ignore = "Negative numbers are not yet supported"]
    fn lexes_negative_1() {
        let source: Vec<_> = "-1".chars().collect();
        assert!(matches!(
            lex_number(&source),
            Some(FoundToken {
                token: TokenKind::Number(_),
                ..
            })
        ));
    }

    #[ignore = "Positive numbers with a leading + are not supported"]
    fn lexes_positive_1() {
        let source: Vec<_> = "+1".chars().collect();
        assert!(matches!(
            lex_number(&source),
            Some(FoundToken {
                token: TokenKind::Number(_),
                ..
            })
        ));
    }

    #[test]
    fn lexes_pi() {
        let source: Vec<_> = "3.1415926535897932384626433832795028841971693993751058209749445923078164062862089986280348253421170679".chars().collect();
        assert!(matches!(
            lex_number(&source),
            Some(FoundToken {
                token: TokenKind::Number(_),
                ..
            })
        ));
    }

    #[test]
    fn lexes_speed_of_light() {
        let source: Vec<_> = "3.00e8".chars().collect();
        assert!(matches!(
            lex_number(&source),
            Some(FoundToken {
                token: TokenKind::Number(_),
                ..
            })
        ));
    }

    #[test]
    fn doesnt_lex_cjk_numeral() {
        let source: Vec<_> = "二".chars().collect();
        assert!(lex_number(&source).is_none());
    }

    #[test]
    fn doesnt_lex_thai_digit() {
        let source: Vec<_> = "๑".chars().collect();
        assert!(lex_number(&source).is_none());
    }

    #[test]
    fn lexes_cjk_as_unlintable() {
        let source: Vec<_> = "世".chars().collect();
        assert!(lex_word(&source).is_none());
    }

    #[test]
    fn lexes_youtube_as_hostname() {
        let source: Vec<_> = "youtube.com".chars().collect();
        assert_eq!(
            lex_english_token(&source),
            Some(FoundToken {
                token: TokenKind::Hostname,
                next_index: source.len()
            })
        );
    }

    #[test]
    fn doesnt_lex_regex_mini_range() {
        let source: Vec<_> = "[]".chars().collect();
        assert!(!matches!(
            lex_english_token(&source),
            Some(FoundToken {
                token: TokenKind::Regexish,
                next_index: 2
            })
        ))
    }

    #[test]
    fn lexes_regex_one_letter() {
        let source: Vec<_> = "[a]".chars().collect();
        assert_eq!(
            lex_english_token(&source),
            Some(FoundToken {
                token: TokenKind::Regexish,
                next_index: 3
            })
        );
    }

    #[test]
    fn lexes_regex_two_letters() {
        let source: Vec<_> = "[az]".chars().collect();
        assert_eq!(
            lex_english_token(&source),
            Some(FoundToken {
                token: TokenKind::Regexish,
                next_index: 4
            })
        );
    }

    #[test]
    fn lexes_regex_digits() {
        let source: Vec<_> = "[123]".chars().collect();
        assert_eq!(
            lex_english_token(&source),
            Some(FoundToken {
                token: TokenKind::Regexish,
                next_index: 5
            })
        );
    }

    #[test]
    fn lexes_regex_two_alphanumeric() {
        let source: Vec<_> = "[a0b1c2]".chars().collect();
        assert_eq!(
            lex_english_token(&source),
            Some(FoundToken {
                token: TokenKind::Regexish,
                next_index: 8
            })
        );
    }

    #[test]
    fn lexes_regex_one_range() {
        let source: Vec<_> = "[a-z]".chars().collect();
        assert_eq!(
            lex_english_token(&source),
            Some(FoundToken {
                token: TokenKind::Regexish,
                next_index: 5
            })
        );
    }

    #[test]
    fn lexes_regex_letter_plus_range() {
        let source: Vec<_> = "[ax-z]".chars().collect();
        assert_eq!(
            lex_english_token(&source),
            Some(FoundToken {
                token: TokenKind::Regexish,
                next_index: 6
            })
        );
    }

    #[test]
    fn lexes_regex_range_plus_letter() {
        let source: Vec<_> = "[a-cz]".chars().collect();
        assert_eq!(
            lex_english_token(&source),
            Some(FoundToken {
                token: TokenKind::Regexish,
                next_index: 6
            })
        );
    }

    #[test]
    fn lexes_regex_two_ranges() {
        let source: Vec<_> = "[a-cx-z]".chars().collect();
        assert_eq!(
            lex_english_token(&source),
            Some(FoundToken {
                token: TokenKind::Regexish,
                next_index: 8
            })
        );
    }

    #[test]
    fn doesnt_lex_regex_broken_two_ranges() {
        // You can't end a range and start a range with a single letter
        let source: Vec<_> = "[a-x-z]".chars().collect();
        assert_eq!(
            lex_english_token(&source),
            Some(FoundToken {
                token: TokenKind::Punctuation(Punctuation::OpenSquare),
                next_index: 1
            })
        );
    }

    #[test]
    fn doesnt_lex_regex_hyphen_at_start() {
        let source: Vec<_> = "[a-]".chars().collect();
        assert!(!matches!(
            lex_english_token(&source),
            Some(FoundToken {
                token: TokenKind::Regexish,
                ..
            })
        ));
    }

    #[test]
    fn doesnt_lex_regex_hyphen_at_end() {
        let source: Vec<_> = "[-z]".chars().collect();
        assert!(!matches!(
            lex_english_token(&source),
            Some(FoundToken {
                token: TokenKind::Regexish,
                ..
            })
        ));
    }

    #[test]
    fn lexes_good_hex_numeric() {
        let source: Vec<_> = "0x0".chars().collect();
        assert!(matches!(
            lex_hex_number(&source),
            Some(FoundToken {
                token: TokenKind::Number(_),
                ..
            })
        ));
    }

    #[test]
    fn lexes_good_hex_lowercase() {
        let source: Vec<_> = "0xa".chars().collect();
        assert!(matches!(
            lex_hex_number(&source),
            Some(FoundToken {
                token: TokenKind::Number(_),
                ..
            })
        ));
    }

    #[test]
    fn lexes_good_hex_uppercase() {
        let source: Vec<_> = "0xF".chars().collect();
        assert!(matches!(
            lex_hex_number(&source),
            Some(FoundToken {
                token: TokenKind::Number(_),
                ..
            })
        ));
    }

    #[test]
    fn lexes_good_hex_mixed_case() {
        let source: Vec<_> = "0xaF".chars().collect();
        assert!(matches!(
            lex_hex_number(&source),
            Some(FoundToken {
                token: TokenKind::Number(_),
                ..
            })
        ));
    }

    #[test]
    fn lexes_good_hex_lowercase_long() {
        let source: Vec<_> = "0x0123456789abcdef".chars().collect();
        assert!(matches!(
            lex_hex_number(&source),
            Some(FoundToken {
                token: TokenKind::Number(_),
                ..
            })
        ));
    }

    #[test]
    fn lexes_good_hex_uppercase_long() {
        let source: Vec<_> = "0x0123456789ABCDEF".chars().collect();
        assert!(matches!(
            lex_hex_number(&source),
            Some(FoundToken {
                token: TokenKind::Number(_),
                ..
            })
        ));
    }

    #[test]
    fn does_not_lex_prefix_only() {
        let source: Vec<_> = "0x".chars().collect();
        assert!(lex_hex_number(&source).is_none());
    }

    #[test]
    fn does_not_lex_bad_alphabetic() {
        let source: Vec<_> = "0xg".chars().collect();
        assert!(lex_hex_number(&source).is_none());
    }

    #[test]
    fn does_not_lex_bad_after_good() {
        let source: Vec<_> = "0x123g".chars().collect();
        assert!(lex_hex_number(&source).is_none());
    }

    #[test]
    fn does_not_lex_uppercase_prefix() {
        let source: Vec<_> = "0Xf00d".chars().collect();
        assert!(lex_hex_number(&source).is_none());
    }

    #[test]
    fn lexes_0s() {
        let source: Vec<_> = "0s".chars().collect();
        assert!(matches!(
            // lex_token(&source),
            lex_plural_digit(&source),
            Some(FoundToken {
                token: TokenKind::Word(_),
                ..
            })
        ));
    }

    #[test]
    fn lexes_1_apostrophe_s() {
        let source: Vec<_> = "1's".chars().collect();
        assert!(matches!(
            // lex_token(&source),
            lex_plural_digit(&source),
            Some(FoundToken {
                token: TokenKind::Word(_),
                ..
            })
        ));
    }

    #[test]
    fn lexes_0s_and_1s() {
        let source: Vec<_> = "0s and 1s".chars().collect();
        assert!(matches!(
            // lex_token(&source),
            lex_plural_digit(&source),
            Some(FoundToken {
                token: TokenKind::Word(_),
                ..
            })
        ));
    }

    #[test]
    fn lexes_1s_and_0s_apostrophes() {
        let source: Vec<_> = "1's and 0's".chars().collect();
        assert!(matches!(
            // lex_token(&source),
            lex_plural_digit(&source),
            Some(FoundToken {
                token: TokenKind::Word(_),
                ..
            })
        ));
    }

    #[test]
    fn doesnt_lex_0s_joined_letter() {
        let source: Vec<_> = "0ss".chars().collect();
        assert!(lex_plural_digit(&source).is_none());
    }

    #[test]
    fn doesnt_lex_1s_apostrophe_joined_number() {
        let source: Vec<_> = "1's1".chars().collect();
        assert!(lex_plural_digit(&source).is_none());
    }

    #[test]
    fn lexes_20c_decade() {
        let source: Vec<_> = "1980s".chars().collect();
        assert!(matches!(
            lex_long_decade(&source),
            Some(FoundToken {
                token: TokenKind::Decade,
                ..
            })
        ));
    }

    #[test]
    fn lexes_21c_decade() {
        let source: Vec<_> = "2020s".chars().collect();
        assert!(matches!(
            lex_long_decade(&source),
            Some(FoundToken {
                token: TokenKind::Decade,
                ..
            })
        ));
    }

    #[test]
    fn lexes_ancient_decade() {
        let source: Vec<_> = "1010s".chars().collect();
        assert!(matches!(
            lex_long_decade(&source),
            Some(FoundToken {
                token: TokenKind::Decade,
                ..
            })
        ));
    }

    #[test]
    fn lexes_word_before_decade() {
        let source: Vec<_> = "late 1980s".chars().collect();
        assert!(matches!(
            lex_english_token(&source),
            Some(FoundToken {
                token: TokenKind::Word(_),
                ..
            })
        ));
    }

    #[test]
    fn lexes_word_after_decade() {
        let source: Vec<_> = "1980s and".chars().collect();
        assert!(matches!(
            lex_english_token(&source),
            Some(FoundToken {
                token: TokenKind::Decade,
                ..
            })
        ));
    }

    #[test]
    fn doesnt_lex_far_future_decade() {
        let source: Vec<_> = "3190s".chars().collect();
        assert!(lex_long_decade(&source).is_none());
    }

    #[test]
    fn doesnt_lex_too_ancient_decade() {
        let source: Vec<_> = "100s".chars().collect();
        assert!(lex_long_decade(&source).is_none());
    }

    #[test]
    fn doesnt_lex_0_prefixed_decade() {
        let source: Vec<_> = "0100s".chars().collect();
        assert!(lex_long_decade(&source).is_none());
    }

    #[test]
    fn doesnt_lex_uppercase_decade() {
        let source: Vec<_> = "2000S".chars().collect();
        assert!(lex_long_decade(&source).is_none());
    }

    #[test]
    fn doesnt_lex_overlong_decade() {
        let source: Vec<_> = "20000s".chars().collect();
        assert!(lex_long_decade(&source).is_none());
    }

    #[test]
    fn doesnt_lex_apostrophe_long_decade() {
        let source: Vec<_> = "2020's".chars().collect();
        assert!(lex_long_decade(&source).is_none());
    }

    #[test]
    fn doesnt_lex_bad_apostrophe_short_decade() {
        let source: Vec<_> = "80's".chars().collect();
        assert!(lex_long_decade(&source).is_none());
    }

    #[test]
    fn doesnt_lex_good_apostrophe_short_decade() {
        let source: Vec<_> = "'90s".chars().collect();
        assert!(lex_long_decade(&source).is_none());
    }

    #[test]
    fn accepts_sentence_with_decade() {
        let sentence: Vec<_> = "To the early 1990s there were a lot of Movies where the bad guys were former Russian intelligence agents.".chars().collect();
        let expected_tokens = [
            TokenKind::Word(None),
            TokenKind::Space(1),
            TokenKind::Word(None),
            TokenKind::Space(1),
            TokenKind::Word(None),
            TokenKind::Space(1),
            TokenKind::Decade,
        ];

        let mut next_index = 0;

        for expected_token in expected_tokens.iter() {
            if next_index >= sentence.len() {
                break; // Exit if we've processed the entire source
            }

            let token = lex_english_token(&sentence[next_index..]).expect("Failed to lex token");
            assert_eq!(token.token, *expected_token);
            next_index += token.next_index;
        }
    }

    #[test]
    fn rejects_sentence_with_number() {
        let sentence: Vec<_> = "To the early 1990s there were a lot of Movies where the bad guys were former Russian intelligence agents.".chars().collect();
        let expected_tokens = [
            TokenKind::Word(None),
            TokenKind::Space(1),
            TokenKind::Word(None),
            TokenKind::Space(1),
            TokenKind::Word(None),
            TokenKind::Space(1),
            TokenKind::Number(Default::default()),
        ];

        let mut next_index = 0;

        for (i, expected_token) in expected_tokens.iter().enumerate() {
            if next_index >= sentence.len() {
                break; // Exit if we've processed the entire source
            }

            let token = lex_english_token(&sentence[next_index..]).expect("Failed to lex token");

            if i < 6 {
                assert_eq!(token.token, *expected_token);
            } else {
                assert_ne!(token.token, *expected_token);
            }

            next_index += token.next_index;
        }
    }

    #[test]
    fn issue_1010() {
        let source = char_string!("3.");

        let tok = lex_number(&source).unwrap();
        assert_eq!(tok.next_index, 1);
    }

    #[test]
    fn lexes_full_number() {
        let source = char_string!("3.0");

        let tok = lex_number(&source).unwrap();
        assert_eq!(tok.next_index, 3);
    }
}



================================================
FILE: harper-core/src/lexing/url.rs
================================================
/// This module implements parsing of URIs.
/// See RFC 1738 for more information.
use super::{FoundToken, hostname::lex_hostname};
use crate::TokenKind;

pub fn lex_url(source: &[char]) -> Option<FoundToken> {
    let sep = source.iter().position(|c| *c == ':')?;

    if !validate_scheme(&source[0..sep]) {
        return None;
    }

    let url_end = lex_ip_schemepart(&source[sep + 1..])?;

    Some(FoundToken {
        next_index: url_end + sep + 1,
        token: TokenKind::Url,
    })
}

/// Checks whether a given char string is a valid "scheme" part of a URI.
fn validate_scheme(source: &[char]) -> bool {
    source.iter().all(|c: &char| valid_scheme_char(*c))
}

fn lex_ip_schemepart(source: &[char]) -> Option<usize> {
    if !matches!(source, ['/', '/', ..]) {
        return None;
    }

    let rest = &source[2..];

    let login_end = lex_login(rest).unwrap_or(0);

    let mut cursor = login_end;

    // Parse endpoint path
    while cursor != rest.len() {
        if rest[cursor] != '/' {
            break;
        }

        cursor += 1;

        let next_idx = lex_xchar_string(&rest[cursor..]);

        if next_idx == 0 {
            break;
        }

        cursor += next_idx;
    }

    Some(cursor + 2)
}

fn lex_login(source: &[char]) -> Option<usize> {
    let hostport_start = if let Some(cred_end) = source.iter().position(|c| *c == '@') {
        if let Some(pass_beg) = source[0..cred_end].iter().position(|c| *c == ':')
            && !is_uchar_plus_string(&source[pass_beg + 1..cred_end])
        {
            return None;
        }

        // Check username
        if !is_uchar_plus_string(&source[0..cred_end]) {
            return None;
        }

        cred_end + 1
    } else {
        0
    };

    let hostport_source = &source[hostport_start..];

    let hostport_end = lex_hostport(hostport_source)?;

    Some(hostport_start + hostport_end)
}

fn lex_hostport(source: &[char]) -> Option<usize> {
    let hostname_end = lex_hostname(source)?;

    if source.get(hostname_end) == Some(&':') {
        Some(
            source
                .iter()
                .enumerate()
                .find(|(_, c)| !{
                    let c = **c;
                    c.is_ascii_digit()
                })
                .map(|(i, _)| i)
                .unwrap_or(source.len()),
        )
    } else {
        Some(hostname_end)
    }
}

fn valid_scheme_char(c: char) -> bool {
    c.is_ascii_alphabetic() || c.is_ascii_digit() || matches!(c, '.' | '-' | '+')
}

fn is_reserved(c: char) -> bool {
    matches!(c, ';' | '/' | '?' | ':' | '@' | '&' | '=' | '#')
}

fn is_safe(c: char) -> bool {
    matches!(c, '$' | '-' | '_' | '.' | '+')
}

fn is_extra(c: char) -> bool {
    matches!(c, '!' | '*' | '\'' | '(' | ')' | ',')
}

fn is_unreserved(c: char) -> bool {
    c.is_ascii_alphabetic() || c.is_ascii_digit() || is_safe(c) || is_extra(c)
}

fn is_hex(c: char) -> bool {
    c.is_ascii_hexdigit()
}

/// Lex an escaped hex code, returning the subsequent index
fn lex_escaped(source: &[char]) -> Option<usize> {
    if source.len() < 3 {
        return None;
    }

    if source[0] == '%' && is_hex(source[1]) && is_hex(source[2]) {
        Some(3)
    } else {
        None
    }
}

fn lex_xchar_string(source: &[char]) -> usize {
    let mut cursor = 0;

    while cursor != source.len() {
        let Some(next) = lex_xchar(&source[cursor..]) else {
            break;
        };

        cursor += next;
    }

    cursor
}

fn is_xchar_string(source: &[char]) -> bool {
    lex_xchar_string(source) == source.len()
}

/// Used for passwords and usernames
fn is_uchar_plus_string(source: &[char]) -> bool {
    let mut cursor = 0;

    while cursor != source.len() {
        if matches!(source[cursor], ';' | '?' | '&' | '=') {
            cursor += 1;
            continue;
        }

        let Some(next) = lex_uchar(&source[cursor..]) else {
            return false;
        };

        cursor += next;
    }

    true
}

fn lex_xchar(source: &[char]) -> Option<usize> {
    if is_reserved(source[0]) {
        return Some(1);
    }

    lex_uchar(source)
}

fn lex_uchar(source: &[char]) -> Option<usize> {
    if is_unreserved(source[0]) {
        return Some(1);
    }

    lex_escaped(source)
}

#[cfg(test)]
mod tests {
    use rand::Rng;

    use super::lex_url;

    fn assert_consumes_full(url: &str) {
        assert_consumes_part(url, url.len());
    }

    fn assert_consumes_part(url: &str, len: usize) {
        let url = url.chars().collect::<Vec<_>>();

        assert_eq!(lex_url(&url).unwrap().next_index, len);
    }

    #[test]
    fn consumes_google() {
        assert_consumes_full("https://google.com")
    }

    #[test]
    fn consumes_wikipedia() {
        assert_consumes_full("https://wikipedia.com")
    }

    #[test]
    fn consumes_youtube() {
        assert_consumes_full("https://youtube.com")
    }

    #[test]
    fn consumes_youtube_not_garbage() {
        assert_consumes_part("https://youtube.com aklsjdha", 19);
    }

    #[test]
    fn consumes_with_path() {
        assert_consumes_full("https://elijahpotter.dev/articles/quantifying_hope_on_a_global_scale")
    }

    #[test]
    fn consumes_issue_142() {
        assert_consumes_full("https://github.com/nodesource/distributions#debinstall")
    }

    /// Tests that the URL parser will not throw a panic under some random
    /// situations.
    #[test]
    fn survives_random_chars() {
        let mut rng = rand::thread_rng();

        let mut buf = [' '; 128];

        for _ in 0..1 << 16 {
            rng.try_fill(&mut buf).unwrap();

            lex_url(&buf);
        }
    }
}



================================================
FILE: harper-core/src/linting/a_part.rs
================================================
use crate::expr::Expr;
use crate::expr::FirstMatchOf;
use crate::expr::FixedPhrase;
use crate::linting::expr_linter::Chunk;
use crate::{
    Token, TokenStringExt,
    linting::{ExprLinter, Lint, LintKind, Suggestion},
};

pub struct APart {
    expr: Box<dyn Expr>,
}

impl Default for APart {
    fn default() -> Self {
        let pattern = FirstMatchOf::new(vec![
            Box::new(FixedPhrase::from_phrase("a part from")),
            Box::new(FixedPhrase::from_phrase("apart of")),
            Box::new(FixedPhrase::from_phrase("fall a part")),
            Box::new(FixedPhrase::from_phrase("far a part")),
        ]);

        Self {
            expr: Box::new(pattern),
        }
    }
}

impl ExprLinter for APart {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], source: &[char]) -> Option<Lint> {
        let span = matched_tokens.span()?;
        let text: String = span.get_content(source).iter().collect();
        let text_lower = text.to_lowercase();

        let (suggestions, message) = match text_lower.as_str() {
            // Not always a mistake:
            // I ordered a part from an online store
            "a part from" => (
                vec![
                    Suggestion::ReplaceWith("apart from".chars().collect()),
                    Suggestion::ReplaceWith("a part of".chars().collect()),
                ],
                "If you mean 'except for', use 'apart from'. If you mean 'a piece belonging to', use 'a part of'. Keep it this way if referring to the origin of a piece.",
            ),
            "apart of" => (
                vec![
                    Suggestion::ReplaceWith("a part of".chars().collect()),
                    Suggestion::ReplaceWith("apart from".chars().collect()),
                ],
                "Did you mean 'a part of' (a piece belonging to) or 'apart from' (except for)?",
            ),
            // Not necessarily always a mistake:
            // How would you detect how far a part is from another part?
            // Any one else amazed with how far a part will travel if you accidentally drop a little model piece?
            // ... how far a part of the value of the relevant step is attributable to the overseas part of the tax ...
            //
            // If the previous word before "far" is "how" or "so", it's still ambiguous
            // But could the next word after "part" help us understand if it's a mistake?
            "far a part" => (
                vec![Suggestion::ReplaceWith("far apart".chars().collect())],
                "If you mean 'separated by a distance', use 'far apart'. If referring to the distance of a piece, keep it this way.",
            ),
            "fall a part" => (
                vec![Suggestion::ReplaceWith("fall apart".chars().collect())],
                "'Fall apart' meaning 'collapse into pieces' or 'stop functioning' is written as two words.",
            ),
            _ => return None,
        };

        Some(Lint {
            span,
            lint_kind: LintKind::WordChoice,
            suggestions,
            message: message.to_owned(),
            priority: 50,
        })
    }

    fn description(&self) -> &'static str {
        "Finds and corrects common mistakes between 'a part' and 'apart'"
    }
}

#[cfg(test)]
mod tests {
    use super::APart;
    use crate::linting::tests::{assert_lint_count, assert_top3_suggestion_result};

    #[test]
    fn allow_normal_use_of_a_part() {
        assert_lint_count(
            "That's not the whole truth, it's just a part.",
            APart::default(),
            0,
        );
    }

    #[test]
    fn allow_normal_use_of_apart() {
        assert_lint_count("You shouldn't have taken it apart.", APart::default(), 0);
    }

    #[test]
    fn allow_normal_use_of_a_part_of() {
        assert_lint_count("The elbow is a part of the arm.", APart::default(), 0);
    }

    #[test]
    fn allow_normal_use_of_apart_from() {
        assert_lint_count("Apart from one error, the code works.", APart::default(), 0);
    }

    #[test]
    fn allow_normal_us_of_fall_apart() {
        assert_lint_count("The roof fell apart.", APart::default(), 0);
    }

    #[test]
    fn allow_normal_use_of_far_apart() {
        assert_lint_count("Okinawa and Hokkaido are far apart.", APart::default(), 0);
    }

    #[test]
    fn corrects_a_part_from_to_apart_from_format() {
        assert_top3_suggestion_result(
            "Is it correct that the output file seems to be the same of the input file a part from the format (input: jpg, output: png)?",
            APart::default(),
            "Is it correct that the output file seems to be the same of the input file apart from the format (input: jpg, output: png)?",
        );
    }

    #[test]
    fn corrects_a_part_from_to_apart_from_english() {
        assert_top3_suggestion_result(
            "Do you know there are more languages out there a part from English right?",
            APart::default(),
            "Do you know there are more languages out there apart from English right?",
        )
    }

    #[test]
    fn corrects_a_part_from_to_a_part_of() {
        assert_top3_suggestion_result(
            "An easy tool to generate backdoor with msfvenom (a part from metasploit framework).",
            APart::default(),
            "An easy tool to generate backdoor with msfvenom (a part of metasploit framework).",
        )
    }

    #[test]
    fn corrects_apart_of_to_apart_from_cflinuxfs() {
        assert_top3_suggestion_result(
            "Doesn't work with any stacks apart of cflinuxfs2 and cflinuxfs3",
            APart::default(),
            "Doesn't work with any stacks apart from cflinuxfs2 and cflinuxfs3",
        )
    }

    #[test]
    fn corrects_apart_of_to_apart_from_using() {
        assert_top3_suggestion_result(
            "apart of using filter, i can't find it in the documentation",
            APart::default(),
            "apart from using filter, i can't find it in the documentation",
        )
    }

    #[test]
    fn corrects_apart_of_to_a_part_of_openai() {
        assert_top3_suggestion_result(
            "export 'Usage' class as apart of openai.types",
            APart::default(),
            "export 'Usage' class as a part of openai.types",
        )
    }

    #[test]
    fn corrects_apart_of_to_a_part_of_formly() {
        assert_top3_suggestion_result(
            "FormlyDatepickerTypeComponent is not listed as apart of the Formly Public API",
            APart::default(),
            "FormlyDatepickerTypeComponent is not listed as a part of the Formly Public API",
        )
    }

    #[test]
    fn corrects_far_a_part() {
        assert_top3_suggestion_result(
            "That leaves you only the other hand on the keyboard and you don't want the keys to be that far a part.",
            APart::default(),
            "That leaves you only the other hand on the keyboard and you don't want the keys to be that far apart.",
        )
    }

    #[test]
    fn corrects_so_far_a_part_from_being_taken() {
        assert_top3_suggestion_result(
            "I can't see in the code what is done really with this session_timeout so far a part from being taken from the conf if defined there or setup ...",
            APart::default(),
            "I can't see in the code what is done really with this session_timeout so far apart from being taken from the conf if defined there or setup ...",
        )
    }

    #[test]
    fn corrects_so_far_a_part_from_version_upgrade() {
        assert_top3_suggestion_result(
            "Any workaround so far a part from the version upgrade?",
            APart::default(),
            "Any workaround so far apart from the version upgrade?",
        )
    }

    #[test]
    fn corrects_fall_a_part() {
        assert_top3_suggestion_result(
            "When I set up a script I set up card priority based on my frontline but sometimes a servant dies which sometimes causes things to fall a part.",
            APart::default(),
            "When I set up a script I set up card priority based on my frontline but sometimes a servant dies which sometimes causes things to fall apart.",
        )
    }

    // Sentences from GitHub I can't understand so can't suggest a fix

    // Use Reanimated to create Animated Map Components and provide as **a part from** library.
    // I'm trying to add tokens to the bucket **apart of** the time so this can help to have distributed rate-limiting so that
    // Slice **apart of** slice apart breaks after slightest change to sliced model
    // Docker image running as different user **apart of** multiple groups
    // Diamond Checker is a cookie checker **apart of** the DIamond Software
    // fetchParent() doesn't work properly with foreign key referencing just a part from a composed primary key
}



================================================
FILE: harper-core/src/linting/a_while.rs
================================================
use std::sync::Arc;

use harper_brill::UPOS;

use crate::char_string::char_string;
use crate::expr::{Expr, ExprMap, SequenceExpr};
use crate::patterns::UPOSSet;
use crate::{CharString, Token, TokenStringExt};

use super::expr_linter::Chunk;
use super::{ExprLinter, Lint, LintKind, Suggestion};

pub struct AWhile {
    expr: Box<dyn Expr>,
    map: Arc<ExprMap<(CharString, &'static str)>>,
}

impl Default for AWhile {
    fn default() -> Self {
        let mut map = ExprMap::default();

        let a = SequenceExpr::default()
            .then(UPOSSet::new(&[UPOS::VERB]))
            .t_ws()
            .t_aco("a")
            .t_ws()
            .t_aco("while");

        map.insert(
            a,
            (
                char_string!("awhile"),
                "Use the single word `awhile` when it follows a verb.",
            ),
        );

        let b = SequenceExpr::default()
            .then_unless(UPOSSet::new(&[UPOS::VERB]))
            .t_ws()
            .t_aco("awhile");

        map.insert(
            b,
            (
                char_string!("a while"),
                "When not used after a verb, spell this duration as `a while`.",
            ),
        );

        let map = Arc::new(map);

        Self {
            expr: Box::new(map.clone()),
            map,
        }
    }
}

impl ExprLinter for AWhile {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], source: &[char]) -> Option<Lint> {
        let &(ref suggestion, message) = self.map.lookup(0, matched_tokens, source)?;
        let span = matched_tokens[2..].span()?;
        let suggestion =
            Suggestion::replace_with_match_case(suggestion.to_vec(), span.get_content(source));

        Some(Lint {
            span,
            lint_kind: LintKind::Typo,
            suggestions: vec![suggestion],
            message: message.to_owned(),
            ..Default::default()
        })
    }

    fn description(&self) -> &'static str {
        "Enforces `awhile` after verbs and `a while` everywhere else."
    }
}

#[cfg(test)]
mod tests {
    use crate::linting::tests::{assert_no_lints, assert_suggestion_result};

    use super::AWhile;

    #[test]
    fn allow_issue_2144() {
        assert_no_lints(
            "After thinking awhile, I decided to foo a bar.",
            AWhile::default(),
        );
        assert_no_lints(
            "After thinking for a while, I decided to foo a bar.",
            AWhile::default(),
        );
    }

    #[test]
    fn fix_issue_2144() {
        assert_suggestion_result(
            "After thinking a while, I decided to foo a bar.",
            AWhile::default(),
            "After thinking awhile, I decided to foo a bar.",
        );
    }

    #[test]
    fn correct_in_quite_a_while() {
        assert_suggestion_result(
            "I haven't seen him in quite awhile.",
            AWhile::default(),
            "I haven't seen him in quite a while.",
        );
    }

    #[test]
    fn correct_in_a_while() {
        assert_suggestion_result(
            "I haven't checked in awhile.",
            AWhile::default(),
            "I haven't checked in a while.",
        );
    }

    #[test]
    fn correct_for_awhile() {
        assert_suggestion_result(
            "Video Element Error: MEDA_ERR_DECODE when chrome is left open for awhile",
            AWhile::default(),
            "Video Element Error: MEDA_ERR_DECODE when chrome is left open for a while",
        );
    }

    #[test]
    fn correct_after_awhile() {
        assert_suggestion_result(
            "Links on portal stop working after awhile, requiring page refresh.",
            AWhile::default(),
            "Links on portal stop working after a while, requiring page refresh.",
        );
    }
}



================================================
FILE: harper-core/src/linting/addicting.rs
================================================
use crate::linting::expr_linter::Chunk;
use crate::{
    Token,
    expr::{All, AnchorEnd, Expr, FirstMatchOf, LongestMatchOf, ReflexivePronoun, SequenceExpr},
    linting::{ExprLinter, Lint, LintKind, Suggestion},
};

pub struct Addicting {
    expr: Box<dyn Expr>,
}

impl Default for Addicting {
    fn default() -> Self {
        Self {
            expr: Box::new(LongestMatchOf::new(vec![
                // matches `addicting` without anything after
                Box::new(SequenceExpr::aco("addicting").then(AnchorEnd)),
                // matches `addicting` <ws> [ any word but not a reflexive pronoun or object pronoun ]
                Box::new(
                    SequenceExpr::aco("addicting")
                        .then_whitespace()
                        .then(All::new(vec![
                            // positive - any word
                            Box::new(SequenceExpr::any_word()),
                            // negative - reflexive pronoun or object pronoun
                            Box::new(SequenceExpr::unless(FirstMatchOf::new(vec![
                                Box::new(ReflexivePronoun::with_common_errors()),
                                Box::new(SequenceExpr::default().then_object_pronoun()),
                            ]))),
                        ])),
                ),
            ])),
        }
    }
}

impl ExprLinter for Addicting {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, toks: &[Token], src: &[char]) -> Option<Lint> {
        let tok = toks.first()?;

        Some(Lint {
            span: tok.span,
            lint_kind: LintKind::Style,
            suggestions: vec![Suggestion::replace_with_match_case(
                "addictive".chars().collect(),
                tok.span.get_content(src),
            )],
            message: "When used as an adjective, `addictive` is the traditional and more f form."
                .to_owned(),
            ..Default::default()
        })
    }

    fn description(&self) -> &str {
        "Replaces `addicting` with `addictive` when used as an adjective."
    }
}

#[cfg(test)]
mod tests {
    use super::Addicting;
    use crate::linting::tests::{assert_lint_count, assert_no_lints, assert_suggestion_result};

    #[test]
    fn fix_addicting() {
        assert_suggestion_result(
            "It is addicting like heroin.",
            Addicting::default(),
            "It is addictive like heroin.",
        );
    }

    #[test]
    fn dont_flag_addicting_object_pronoun() {
        assert_lint_count("It is addicting me.", Addicting::default(), 0);
    }

    #[test]
    fn dont_flag_addicting_reflexive_pronoun() {
        assert_lint_count("He is addicting himself.", Addicting::default(), 0);
    }

    #[test]
    fn fix_yet_highly_addicting() {
        assert_suggestion_result(
            "The objective of the game is simple yet highly addicting, you start out with the four basic elements.",
            Addicting::default(),
            "The objective of the game is simple yet highly addictive, you start out with the four basic elements.",
        );
    }

    #[test]
    fn dont_flag_addicting_them_on() {
        assert_no_lints(
            "Helping humans on their daily tasks instead of addicting them on social networks of all sorts.",
            Addicting::default(),
        );
    }

    #[test]
    #[ignore = "False positive since `myself` is not an object pronoun in this construction"]
    fn fix_find_things_addicting_myself() {
        assert_suggestion_result(
            "Yeah, I find taking the functional approach for these kinds of problems rather addicting myself :)",
            Addicting::default(),
            "Yeah, I find taking the functional approach for these kinds of problems rather addictive myself :)",
        );
    }

    #[test]
    fn dont_fix_coerced_into_addicting_themselves() {
        assert_no_lints(
            "The British, in another display of gunboat diplomacy, coerced countless innocent people into addicting themselves to opium.",
            Addicting::default(),
        );
    }
}



================================================
FILE: harper-core/src/linting/adjective_double_degree.rs
================================================
use crate::linting::expr_linter::Chunk;
use crate::{
    CharStringExt, Token, TokenStringExt,
    expr::{Expr, SequenceExpr},
    linting::{ExprLinter, Lint, LintKind, Suggestion},
};

pub struct AdjectiveDoubleDegree {
    expr: Box<dyn Expr>,
}

impl Default for AdjectiveDoubleDegree {
    fn default() -> Self {
        Self {
            expr: Box::new(
                SequenceExpr::word_set(&["more", "most"])
                    .t_ws()
                    .then_kind_where(|kind| {
                        kind.is_comparative_adjective() || kind.is_superlative_adjective()
                    }),
            ),
        }
    }
}

impl ExprLinter for AdjectiveDoubleDegree {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, toks: &[Token], src: &[char]) -> Option<Lint> {
        let phrase_span = toks.span()?;
        let phrase_chars = phrase_span.get_content(src);

        let adj_chars = toks.last()?.span.get_content(src);

        let (lint_kind, message, suggestions) = match (
            &toks.first()?.span.get_content(src).to_lower().as_ref(),
            toks.last()?.kind.is_comparative_adjective(),
            toks.last()?.kind.is_superlative_adjective(),
        ) {
            (['m', 'o', 'r', 'e'], true, false) => (
                LintKind::Redundancy,
                "Using `more` and the comparative form of the adjective together is redundant."
                    .to_string(),
                vec![Suggestion::replace_with_match_case(
                    adj_chars.to_vec(),
                    phrase_chars,
                )],
            ),
            (['m', 'o', 's', 't'], false, true) => (
                LintKind::Redundancy,
                "Using `most` and the superlative form of the adjective together is redundant."
                    .to_string(),
                vec![Suggestion::replace_with_match_case(
                    adj_chars.to_vec(),
                    phrase_chars,
                )],
            ),
            _ => {
                let other_adj_degree = match adj_chars {
                    &['b', 'e', 't', 't', 'e', 'r'] => vec!['b', 'e', 's', 't'],
                    &['b', 'e', 's', 't'] => vec!['b', 'e', 't', 't', 'e', 'r'],
                    &['w', 'o', 'r', 's', 'e'] => vec!['w', 'o', 'r', 's', 't'],
                    &['w', 'o', 'r', 's', 't'] => vec!['w', 'o', 'r', 's', 'e'],
                    adj_chars if adj_chars.ends_with(&['r']) => {
                        let len = adj_chars.len() + 1;
                        let mut other = vec!['\0'; len];
                        other[..len - 2].copy_from_slice(&adj_chars[..len - 2]);
                        other[len - 2] = 's';
                        other[len - 1] = 't';
                        other
                    }
                    adj_chars if adj_chars.ends_with(&['s', 't']) => {
                        let len = adj_chars.len() - 1;
                        let mut other = vec!['\0'; len];
                        other[..len - 1].copy_from_slice(&adj_chars[..len - 1]);
                        other[len - 1] = 'r';
                        other
                    }
                    _ => return None,
                };

                (
                    LintKind::WordChoice,
                    "The degree of the adverb conflicts with the degree of the adjective."
                        .to_string(),
                    vec![
                        Suggestion::replace_with_match_case(adj_chars.to_vec(), phrase_chars),
                        Suggestion::replace_with_match_case(other_adj_degree, phrase_chars),
                    ],
                )
            }
        };

        Some(Lint {
            span: phrase_span,
            lint_kind,
            message,
            suggestions,
            priority: 126,
        })
    }

    fn description(&self) -> &'static str {
        "Finds adjectives that are used as double degrees (e.g. `more prettier`)."
    }
}

#[cfg(test)]
mod tests {
    use super::AdjectiveDoubleDegree;
    use crate::linting::tests::{assert_good_and_bad_suggestions, assert_suggestion_result};

    #[test]
    fn fix_double_regular_superlative() {
        assert_suggestion_result(
            "The most easiest to use, self-service open BI reporting and BI dashboard and BI monitor screen platform.",
            AdjectiveDoubleDegree::default(),
            "The easiest to use, self-service open BI reporting and BI dashboard and BI monitor screen platform.",
        );
    }

    #[test]
    fn fix_double_regular_comparative() {
        assert_suggestion_result(
            "how can make docx gennerate more faster?",
            AdjectiveDoubleDegree::default(),
            "how can make docx gennerate faster?",
        );
    }

    #[test]
    fn fix_double_irregular_comparative() {
        assert_suggestion_result(
            "Find alternative product name more better than age .",
            AdjectiveDoubleDegree::default(),
            "Find alternative product name better than age .",
        );
    }

    #[test]
    fn fix_double_irregular_superlative() {
        assert_suggestion_result(
            "how can i get a most best quality file",
            AdjectiveDoubleDegree::default(),
            "how can i get a best quality file",
        );
    }

    #[test]
    fn conflicting_moster_offers_two_suggestions() {
        assert_good_and_bad_suggestions(
            "application which students to learn most faster in efficient way.",
            AdjectiveDoubleDegree::default(),
            &[
                "application which students to learn faster in efficient way.",
                "application which students to learn fastest in efficient way.",
            ],
            &[],
        );
    }

    #[test]
    fn conflicting_morest_offers_two_suggestions() {
        assert_good_and_bad_suggestions(
            "I suggest migrating to vite that more flexible and more fastest.",
            AdjectiveDoubleDegree::default(),
            &[
                "I suggest migrating to vite that more flexible and faster.",
                "I suggest migrating to vite that more flexible and fastest.",
            ],
            &[],
        );
    }

    #[test]
    fn conflicting_most_better_offers_two_suggestions() {
        assert_good_and_bad_suggestions(
            "But first logo is most better for me.",
            AdjectiveDoubleDegree::default(),
            &[
                "But first logo is better for me.",
                "But first logo is best for me.",
            ],
            &[],
        );
    }

    #[test]
    fn conflicting_most_worse_offers_two_suggestions() {
        assert_good_and_bad_suggestions(
            "We also see the need of a generic solution built-in in Pimcore, but currently it's probably the most worse time to implement a new solution.",
            AdjectiveDoubleDegree::default(),
            &[
                // TODO: special-case after "the" since that implies a superlative
                "We also see the need of a generic solution built-in in Pimcore, but currently it's probably the worse time to implement a new solution.",
                "We also see the need of a generic solution built-in in Pimcore, but currently it's probably the worst time to implement a new solution.",
            ],
            &[],
        );
    }
}



================================================
FILE: harper-core/src/linting/adjective_of_a.rs
================================================
use super::{Lint, LintKind, Linter, Suggestion};
use crate::{Document, Span, TokenStringExt};

/// Detect sequences of words of the form "adjective of a".
#[derive(Debug, Clone, Copy, Default)]
pub struct AdjectiveOfA;

const ADJECTIVE_WHITELIST: &[&str] = &["bad", "big", "good", "large", "long", "vague"];

const CONTEXT_WORDS: &[&str] = &[
    "as", "how", // but "how much of a"
    "that", "this", "too",
];

const ADJECTIVE_BLACKLIST: &[&str] = &["much", "part"];

fn has_context_word(document: &Document, adj_idx: usize) -> bool {
    if adj_idx < 2 {
        // Need at least 2 tokens before the adjective (word + space)
        return false;
    }

    // Get the token before the adjective (should be a space)
    if let Some(space_token) = document.get_token(adj_idx - 1) {
        if !space_token.kind.is_whitespace() {
            return false;
        }

        // Get the token before the space (should be our context word)
        if let Some(word_token) = document.get_token(adj_idx - 2) {
            if !word_token.kind.is_word() {
                return false;
            }

            let word = document.get_span_content_str(&word_token.span);

            return CONTEXT_WORDS.iter().any(|&w| w.eq_ignore_ascii_case(&word));
        }
    }

    false
}

fn is_good_adjective(word: &str) -> bool {
    ADJECTIVE_WHITELIST
        .iter()
        .any(|&adj| word.eq_ignore_ascii_case(adj))
}

fn is_bad_adjective(word: &str) -> bool {
    ADJECTIVE_BLACKLIST
        .iter()
        .any(|&adj| word.eq_ignore_ascii_case(adj))
}

impl Linter for AdjectiveOfA {
    fn lint(&mut self, document: &Document) -> Vec<Lint> {
        let mut lints = Vec::new();

        for i in document.iter_adjective_indices() {
            let adjective = document.get_token(i).unwrap();
            let space_1 = document.get_token(i + 1);
            let word_of = document.get_token(i + 2);
            let space_2 = document.get_token(i + 3);
            let a_or_an = document.get_token(i + 4);
            let adj_str = document
                .get_span_content_str(&adjective.span)
                .to_lowercase();

            // Only flag adjectives known to use this construction
            // Unless we have a clearer context
            if !is_good_adjective(&adj_str) && !has_context_word(document, i) {
                continue;
            }
            // Some adjectives still create false positives even with the extra context
            if is_bad_adjective(&adj_str) {
                continue;
            }

            // Rule out comparatives and superlatives.

            // Pros:
            // "for the better of a day"
            // "might not be the best of a given run"
            // "Which brings me to my best of a bad situation."
            //
            // Cons:
            // "see if you can give us a little better of an answer"
            // "hopefully it won't be too much worse of a problem"
            // "seems far worse of a result to me"
            if adj_str.ends_with("er") || adj_str.ends_with("st") {
                continue;
            }
            // Rule out present participles (e.g. "beginning of a")
            // The -ing form of a verb acts as an adjective called a present participle
            // and also acts as a noun called a gerund.
            if adj_str.ends_with("ing") && (adjective.kind.is_noun() || adjective.kind.is_verb()) {
                continue;
            }

            if space_1.is_none() || word_of.is_none() || space_2.is_none() || a_or_an.is_none() {
                continue;
            }
            let space_1 = space_1.unwrap();
            if !space_1.kind.is_whitespace() {
                continue;
            }
            let word_of = word_of.unwrap();
            if !word_of.kind.is_word() {
                continue;
            }
            let word_of = document.get_span_content_str(&word_of.span).to_lowercase();
            if word_of != "of" {
                continue;
            }
            let space_2 = space_2.unwrap();
            if !space_2.kind.is_whitespace() {
                continue;
            }
            let a_or_an = a_or_an.unwrap();
            if !a_or_an.kind.is_word() {
                continue;
            }
            let a_or_an_str = document.get_span_content_str(&a_or_an.span).to_lowercase();
            if a_or_an_str != "a" && a_or_an_str != "an" {
                continue;
            }

            // Whitespace may differ, add the other replacement if so
            let mut sugg_1 = Vec::new();
            sugg_1.extend_from_slice(document.get_span_content(&adjective.span));
            sugg_1.extend_from_slice(document.get_span_content(&space_1.span));
            sugg_1.extend_from_slice(document.get_span_content(&a_or_an.span));

            let mut sugg_2 = Vec::new();
            sugg_2.extend_from_slice(document.get_span_content(&adjective.span));
            sugg_2.extend_from_slice(document.get_span_content(&space_2.span));
            sugg_2.extend_from_slice(document.get_span_content(&a_or_an.span));

            let mut suggestions = vec![Suggestion::ReplaceWith(sugg_1.clone())];
            if sugg_1 != sugg_2 {
                suggestions.push(Suggestion::ReplaceWith(sugg_2));
            }

            lints.push(Lint {
                span: Span::new(adjective.span.start, a_or_an.span.end),
                lint_kind: LintKind::Style,
                suggestions,
                message: "The word `of` is not needed here.".to_string(),
                priority: 63,
            });
        }

        lints
    }

    fn description(&self) -> &str {
        "This rule looks for sequences of words of the form `adjective of a`."
    }
}

#[cfg(test)]
mod tests {
    use super::AdjectiveOfA;
    use crate::linting::tests::{assert_lint_count, assert_suggestion_result};

    #[test]
    fn correct_large_of_a() {
        assert_suggestion_result(
            "Yeah I'm using as large of a batch size as I can on this machine",
            AdjectiveOfA,
            "Yeah I'm using as large a batch size as I can on this machine",
        )
    }

    #[test]
    fn correct_bad_of_an() {
        assert_suggestion_result(
            "- If forking is really that bad of an option, let's first decide where to put this.",
            AdjectiveOfA,
            "- If forking is really that bad an option, let's first decide where to put this.",
        );
    }

    #[test]
    fn dont_flag_comparative() {
        assert_lint_count(
            "I only worked with custom composer installers for the better of a day, so please excuse me if I missed a thing.",
            AdjectiveOfA,
            0,
        );
    }

    #[test]
    fn dont_flag_superlative() {
        assert_lint_count(
            "I am trying to use composites to visualize the worst of a set of metrics.",
            AdjectiveOfA,
            0,
        );
    }

    #[test]
    fn dont_flag_kind() {
        // Adjective as in "a kind person" vs noun as in "A kind of person"
        assert_lint_count(
            "Log.txt file automatic creation in PWD is kind of an anti-feature",
            AdjectiveOfA,
            0,
        );
    }

    #[test]
    fn dont_flag_part() {
        // Can be an adjective in e.g. "He is just part owner"
        assert_lint_count(
            "cannot delete a food that is no longer part of a recipe",
            AdjectiveOfA,
            0,
        );
    }

    #[test]
    fn dont_flag_much() {
        // "much of" is correct idiomatic usage
        assert_lint_count(
            "How much of a performance impact when switching from rails to rails-api ?",
            AdjectiveOfA,
            0,
        );
    }

    #[test]
    fn dont_flag_part_uppercase() {
        // Can be an adjective in e.g. "Part man, part machine"
        assert_lint_count(
            "Quarkus Extension as Part of a Project inside a Monorepo?",
            AdjectiveOfA,
            0,
        );
    }

    #[test]
    fn dont_flag_all_of() {
        // "all of" is correct idiomatic usage
        assert_lint_count(
            "This repository is deprecated. All of its content and history has been moved.",
            AdjectiveOfA,
            0,
        );
    }

    #[test]
    fn dont_flag_inside() {
        // "inside of" is idiomatic usage
        assert_lint_count(
            "Michael and Brock sat inside of a diner in Brandon",
            AdjectiveOfA,
            0,
        );
    }

    #[test]
    fn dont_flag_out() {
        // "out of" is correct idiomatic usage
        assert_lint_count(
            "not only would he potentially be out of a job and back to sort of poverty",
            AdjectiveOfA,
            0,
        );
    }

    #[test]
    fn dont_flag_full() {
        // "full of" is correct idiomatic usage
        assert_lint_count(
            "fortunately I happen to have this Tupperware full of an unceremoniously disassembled LED Mac Mini",
            AdjectiveOfA,
            0,
        );
    }

    #[test]
    fn dont_flag_something() {
        // Can be a noun in e.g. "a certain something"
        assert_lint_count(
            "Well its popularity seems to be taking something of a dip right now.",
            AdjectiveOfA,
            0,
        );
    }

    #[test]
    fn dont_flag_short() {
        // Can be a noun in e.g. "use a multimeter to find the short"
        assert_lint_count(
            "I found one Youtube short of an indonesian girl.",
            AdjectiveOfA,
            0,
        )
    }

    #[test]
    fn dont_flag_bottom() {
        // Can be an adjective in e.g. "bottom bunk"
        assert_lint_count(
            "When leaves are just like coming out individually from the bottom of a fruit.",
            AdjectiveOfA,
            0,
        )
    }

    #[test]
    fn dont_flag_left() {
        // Can be an adjective in e.g. "left hand"
        assert_lint_count("and what is left of a 12vt coil", AdjectiveOfA, 0)
    }

    #[test]
    fn dont_flag_full_uppercase() {
        assert_lint_count("Full of a bunch varnish like we get.", AdjectiveOfA, 0);
    }

    #[test]
    fn dont_flag_head() {
        // Can be an adjective in e.g. "the head cook"
        assert_lint_count(
            "You need to get out if you're the head of an education department and you're not using AI",
            AdjectiveOfA,
            0,
        );
    }

    #[test]
    fn dont_flag_middle() {
        // Can be an adjective in e.g. "middle child"
        assert_lint_count(
            "just to get to that part in the middle of a blizzard",
            AdjectiveOfA,
            0,
        );
    }

    #[test]
    fn dont_flag_chance() {
        // Can be an adjective in e.g. "a chance encounter"
        assert_lint_count(
            "products that you overpay for because there are subtle details in the terms and conditions that reduce the size or chance of a payout.",
            AdjectiveOfA,
            0,
        );
    }

    #[test]
    fn dont_flag_potential() {
        // Can be an adjective in e.g. "a potential candidate"
        assert_lint_count(
            "People that are happy to accept it for the potential of a reward.",
            AdjectiveOfA,
            0,
        );
    }

    #[test]
    fn dont_flag_sound() {
        // Can be an adjective in e.g. "sound advice"
        assert_lint_count("the sound of an approaching Krampus", AdjectiveOfA, 0);
    }

    #[test]
    fn dont_flag_rid() {
        // I removed the `5` flag from `rid` in `dictionary.dict`
        // because dictionaries say the sense is archaic.
        assert_lint_count("I need to get rid of a problem", AdjectiveOfA, 0);
    }

    #[test]
    fn dont_flag_precision() {
        // Can be an adjective in e.g. "a precision instrument"
        assert_lint_count(
            "a man whose crew cut has the precision of a targeted drone strike",
            AdjectiveOfA,
            0,
        );
    }

    #[test]
    fn dont_flag_back() {
        // Can be an adjective in e.g. "back door"
        assert_lint_count(
            "a man whose crew cut has the back of a targeted drone strike",
            AdjectiveOfA,
            0,
        );
    }

    #[test]
    fn dont_flag_emblematic() {
        // "emblematic of" is correct idiomatic usage
        assert_lint_count(
            "... situation was emblematic of a publication that ...",
            AdjectiveOfA,
            0,
        );
    }

    #[test]
    fn dont_flag_half() {
        // Can be an adjective in e.g. "half man, half machine"
        assert_lint_count("And now I only have half of a CyberTruck", AdjectiveOfA, 0);
    }

    #[test]
    fn dont_flag_bit() {
        // Technically also an adj as in "that guy's bit - he'll turn into a zombie"
        assert_lint_count("we ran into a bit of an issue", AdjectiveOfA, 0);
    }

    #[test]
    fn dont_flag_dream() {
        // Can be an adjective in e.g. "we built our dream house"
        assert_lint_count("When the dream of a united Europe began", AdjectiveOfA, 0);
    }

    #[test]
    fn dont_flag_beginning() {
        // Present participles have properties of adjectives, nouns, and verbs
        assert_lint_count("That's the beginning of a conversation.", AdjectiveOfA, 0);
    }

    #[test]
    fn dont_flag_side() {
        // Can be an adjective in e.g. "via a side door"
        assert_lint_count(
            "it hit the barrier on the side of a highway",
            AdjectiveOfA,
            0,
        );
    }

    #[test]
    fn dont_flag_derivative() {
        // Adj: "a derivative story", Noun: "stocks and derivatives"
        assert_lint_count(
            "Techniques for evaluating the *partial derivative of a function",
            AdjectiveOfA,
            0,
        )
    }

    #[test]
    fn dont_flag_equivalent() {
        assert_lint_count(
            "Rust's equivalent of a switch statement is a match expression",
            AdjectiveOfA,
            0,
        );
    }

    #[test]
    fn dont_flag_up() {
        assert_lint_count(
            "Yeah gas is made up of a bunch of teenytiny particles all moving around.",
            AdjectiveOfA,
            0,
        );
    }

    #[test]
    fn dont_flag_eighth() {
        assert_lint_count(
            "It's about an eighth of an inch or whatever",
            AdjectiveOfA,
            0,
        );
    }

    #[test]
    fn dont_flag_shy() {
        assert_lint_count(
            "... or just shy of a third of the country's total trade deficit.",
            AdjectiveOfA,
            0,
        );
    }

    #[test]
    fn dont_flag_fun() {
        assert_lint_count(
            "Remember that $4,000 Hermes horse bag I was making fun of a little while ago.",
            AdjectiveOfA,
            0,
        );
    }

    #[test]
    fn dont_flag_off() {
        // Can be an adjective in e.g. "The TV is off".
        // This should be in a different lint that handles based on/off/off of.
        assert_lint_count(
            "can't identify a person based off of an IP from 10 years ago",
            AdjectiveOfA,
            0,
        );
    }

    #[test]
    fn dont_flag_borderline_of() {
        assert_lint_count(
            "it's very very on the borderline of a rock pop ballad",
            AdjectiveOfA,
            0,
        );
    }

    #[test]
    fn dont_flag_light() {
        assert_lint_count("The light of a star.", AdjectiveOfA, 0);
    }

    #[test]
    fn dont_flag_multiple() {
        assert_lint_count(
            "The image needs to be a multiple of a certain size.",
            AdjectiveOfA,
            0,
        );
    }

    #[test]
    fn dont_flag_red() {
        assert_lint_count("The red of a drop of blood.", AdjectiveOfA, 0);
    }

    #[test]
    fn dont_flag_top() {
        assert_lint_count("The top of a hill.", AdjectiveOfA, 0);
    }

    #[test]
    fn dont_flag_slack() {
        assert_lint_count(
            "They've been picking up the slack of a federal government mostly dominated by whatever this is.",
            AdjectiveOfA,
            0,
        );
    }

    #[test]
    fn dont_flag_illustrative() {
        assert_lint_count(
            "Yet, the fact that they clearly give a one-sided account of most of their case studies is illustrative of a bias.",
            AdjectiveOfA,
            0,
        );
    }

    #[test]
    fn dont_flag_perspective() {
        assert_lint_count(
            "I always assess software by looking at it from the perspective of a new user.",
            AdjectiveOfA,
            0,
        );
    }

    #[test]
    fn correct_too_large_of_a() {
        assert_suggestion_result(
            "Warn users if setting too large of a session object",
            AdjectiveOfA,
            "Warn users if setting too large a session object",
        )
    }

    #[test]
    fn correct_too_long_of_a() {
        assert_suggestion_result(
            "An Org Role with Too Long of a Name Hides Delete Option",
            AdjectiveOfA,
            "An Org Role with Too Long a Name Hides Delete Option",
        )
    }

    #[test]
    fn correct_too_big_of_a() {
        assert_suggestion_result(
            "StepButton has too big of a space to click",
            AdjectiveOfA,
            "StepButton has too big a space to click",
        )
    }

    #[test]
    fn correct_too_vague_of_a() {
        assert_suggestion_result(
            "\"No Speech provider is registered.\" is too vague of an error",
            AdjectiveOfA,
            "\"No Speech provider is registered.\" is too vague an error",
        )
    }

    #[test]
    fn correct_too_dumb_of_a() {
        assert_suggestion_result(
            "Hopefully this isn't too dumb of a question.",
            AdjectiveOfA,
            "Hopefully this isn't too dumb a question.",
        )
    }

    #[test]
    fn correct_how_important_of_a() {
        assert_suggestion_result(
            "This should tell us how important of a use case that is and how often writing a type literal in a case is deliberate.",
            AdjectiveOfA,
            "This should tell us how important a use case that is and how often writing a type literal in a case is deliberate.",
        )
    }

    #[test]
    fn correct_that_rare_of_an() {
        assert_suggestion_result(
            "so making changes isn't that rare of an occurrence for me.",
            AdjectiveOfA,
            "so making changes isn't that rare an occurrence for me.",
        )
    }

    #[test]
    fn correct_as_important_of_a() {
        assert_suggestion_result(
            "Might be nice to have it draggable from other places as well, but not as important of a bug anymore.",
            AdjectiveOfA,
            "Might be nice to have it draggable from other places as well, but not as important a bug anymore.",
        )
    }

    #[test]
    fn correct_too_short_of_a() {
        assert_suggestion_result(
            "I login infrequently as well and 6 months is too short of a time.",
            AdjectiveOfA,
            "I login infrequently as well and 6 months is too short a time.",
        )
    }

    #[test]
    fn correct_that_common_of_a() {
        assert_suggestion_result(
            "that common of a name for a cluster role its hard to rule out",
            AdjectiveOfA,
            "that common a name for a cluster role its hard to rule out",
        )
    }

    #[test]
    fn correct_as_great_of_an() {
        assert_suggestion_result(
            "the w factor into the u factor to as great of an extent as possible.",
            AdjectiveOfA,
            "the w factor into the u factor to as great an extent as possible.",
        )
    }

    #[test]
    fn correct_too_uncommon_of_a() {
        assert_suggestion_result(
            "but this is probably too uncommon of a practice to be the default",
            AdjectiveOfA,
            "but this is probably too uncommon a practice to be the default",
        )
    }
}



================================================
FILE: harper-core/src/linting/after_later.rs
================================================
use crate::Token;
use crate::expr::{DurationExpr, Expr, SequenceExpr};
use crate::linting::expr_linter::Chunk;
use crate::linting::{ExprLinter, Lint, LintKind, Suggestion};
use crate::token_string_ext::TokenStringExt;

pub struct AfterLater {
    expr: Box<dyn Expr>,
}

impl Default for AfterLater {
    fn default() -> Self {
        Self {
            expr: Box::new(
                SequenceExpr::aco("after")
                    .t_ws()
                    .then_optional(
                        SequenceExpr::word_set(&[
                            "about",
                            "almost",
                            "approximately",
                            "around",
                            "circa",
                            "exactly",
                            "just",
                            "maybe",
                            "nearly",
                            "only",
                            "perhaps",
                            "precisely",
                            "probably",
                            "roughly",
                        ])
                        .t_ws(),
                    )
                    .then(DurationExpr)
                    .t_ws()
                    .t_aco("later"),
            ),
        }
    }
}

impl ExprLinter for AfterLater {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, toks: &[Token], src: &[char]) -> Option<Lint> {
        let without_after: Vec<char> = toks[2..].span()?.get_content(src).to_vec();
        let without_later: Vec<char> = toks[..toks.len() - 2].span()?.get_content(src).to_vec();

        let template_chars = toks.span()?.get_content(src);

        Some(Lint {
            span: toks.span()?,
            lint_kind: LintKind::Redundancy,
            message: "Don't use `later` following `after [a period of time]`".to_string(),
            suggestions: vec![
                Suggestion::replace_with_match_case(without_after, template_chars),
                Suggestion::replace_with_match_case(without_later, template_chars),
            ],
            ..Default::default()
        })
    }

    fn description(&self) -> &str {
        "Checks for the word `later` following `after [a period of time]`."
    }
}

#[cfg(test)]
mod tests {
    use super::AfterLater;
    use crate::linting::tests::assert_top3_suggestion_result;

    #[test]
    fn after_90_days_later() {
        assert_top3_suggestion_result(
            "Try to rename your organization after 90 days later because of GitHub official documentation it said.",
            AfterLater::default(),
            "Try to rename your organization after 90 days because of GitHub official documentation it said.",
        );
    }

    #[test]
    fn after_about_30_minutes_later() {
        assert_top3_suggestion_result(
            "It plays like 1 minute of the song and then stops, and after about 30 minutes later, the bot disconnects an throws DisTubeError",
            AfterLater::default(),
            "It plays like 1 minute of the song and then stops, and about 30 minutes later, the bot disconnects an throws DisTubeError",
        );
    }

    #[test]
    fn after_14_days_later() {
        assert_top3_suggestion_result(
            "After 14 days later, the cache expired.",
            AfterLater::default(),
            "After 14 days, the cache expired.",
        );
    }

    #[test]
    fn after_exactly_5_minutes_later() {
        assert_top3_suggestion_result(
            "After exactly 5 minutes later, they try again and the cluster is formed then.",
            AfterLater::default(),
            "Exactly 5 minutes later, they try again and the cluster is formed then.",
        );
    }

    #[test]
    fn after_22_years_later_1() {
        assert_top3_suggestion_result(
            "Completed YR campaign for 2nd time after 22 years later.",
            AfterLater::default(),
            "Completed YR campaign for 2nd time after 22 years.",
        );
    }

    #[test]
    fn after_almost_2_years_later() {
        assert_top3_suggestion_result(
            "This buyer contacted me after almost 2 years later.",
            AfterLater::default(),
            "This buyer contacted me almost 2 years later.",
        );
    }

    #[test]
    fn after_2_years_later() {
        assert_top3_suggestion_result(
            "Is Jedi Survivor better now after 2 years later?",
            AfterLater::default(),
            "Is Jedi Survivor better now after 2 years?",
        );
    }

    #[test]
    fn after_a_year_later() {
        assert_top3_suggestion_result(
            "Even after a year later, I don’t know how to get my self-love back.",
            AfterLater::default(),
            "Even a year later, I don’t know how to get my self-love back.",
        );
    }

    #[test]
    fn after_22_years_later_2() {
        assert_top3_suggestion_result(
            "After 22 years later, my top 1 game was Zeroed",
            AfterLater::default(),
            "After 22 years, my top 1 game was Zeroed",
        );
    }
}



================================================
FILE: harper-core/src/linting/all_intents_and_purposes.rs
================================================
use crate::Token;
use crate::char_string::CharStringExt;
use crate::expr::{Expr, SequenceExpr};
use crate::linting::expr_linter::Chunk;
use crate::linting::{ExprLinter, Lint, LintKind, Suggestion};
use crate::token_string_ext::TokenStringExt;

pub struct AllIntentsAndPurposes {
    expr: Box<dyn Expr>,
}

impl Default for AllIntentsAndPurposes {
    fn default() -> Self {
        Self {
            expr: Box::new(
                SequenceExpr::default()
                    .then_preposition() // Only "for" or "to" are OK
                    .t_ws()
                    .t_aco("all")
                    .t_ws()
                    .then_any_of(vec![
                        Box::new(
                            SequenceExpr::word_set(&[
                                "intents", // Correct, as long as it follows "for" or "to"
                                "extents", "intense", // Incorrect, no matter the preposition
                            ])
                            .t_ws()
                            .t_aco("and"),
                        ),
                        Box::new(SequenceExpr::word_set(&[
                            "intended",
                            "intense",
                            "intensive",
                            "intrinsic",
                        ])),
                    ])
                    .t_ws()
                    .t_aco("purposes"),
            ),
        }
    }
}

impl ExprLinter for AllIntentsAndPurposes {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, toks: &[Token], src: &[char]) -> Option<Lint> {
        let whole_span = toks.span()?;
        let whole_str = whole_span.get_content_string(src);

        // "for" is first since "to" is listed as a UK variant in some dictionaries
        const LEGIT: [&str; 2] = [
            "for all intents and purposes",
            "to all intents and purposes",
        ];

        if LEGIT.iter().any(|s| s.eq_ignore_ascii_case(&whole_str)) {
            return None;
        }

        let prep_text = toks.first().unwrap().span.get_content(src);

        let mut suggs = LEGIT.to_vec();

        // Suggest "to" first if the text uses "to", otherwise "for" first
        if prep_text.eq_ignore_ascii_case_chars(&['t', 'o']) {
            suggs.swap(0, 1);
        }

        let suggs = suggs
            .into_iter()
            .map(|s| Suggestion::replace_with_match_case_str(s, whole_span.get_content(src)))
            .collect::<Vec<_>>();

        let message = format!(
            "The correct form is '{} all intents and purposes'.",
            prep_text.iter().collect::<String>().to_ascii_lowercase()
        );

        Some(Lint {
            span: whole_span,
            lint_kind: LintKind::Nonstandard,
            suggestions: suggs,
            message,
            priority: 50,
        })
    }

    fn description(&self) -> &'static str {
        "Finds and corrects common wrong forms of the phrase 'for all intents and purposes' / 'to all intents and purposes'."
    }
}

#[cfg(test)]
mod tests {
    use super::AllIntentsAndPurposes;
    use crate::linting::tests::{assert_no_lints, assert_suggestion_result};

    // Adjectives without "and"

    #[test]
    fn fix_for_intended() {
        assert_suggestion_result(
            "The details tag should be treated like a div for all intended purposes, but unsure where in the selection logic",
            AllIntentsAndPurposes::default(),
            "The details tag should be treated like a div for all intents and purposes, but unsure where in the selection logic",
        );
    }

    #[test]
    fn fix_for_intense() {
        assert_suggestion_result(
            "For all intense purposes, I thought your code was really well written",
            AllIntentsAndPurposes::default(),
            "For all intents and purposes, I thought your code was really well written",
        );
    }

    #[test]
    fn fix_for_intensive() {
        assert_suggestion_result(
            "MultiNode could be for all intensive purposes, the same as Node sans the way it creates the command line arguments for the process.",
            AllIntentsAndPurposes::default(),
            "MultiNode could be for all intents and purposes, the same as Node sans the way it creates the command line arguments for the process.",
        );
    }

    #[test]
    fn fix_for_intrinsic_purposes() {
        assert_suggestion_result(
            "For all intrinsic purposes I think you are wrong.",
            AllIntentsAndPurposes::default(),
            "For all intents and purposes I think you are wrong.",
        );
    }

    #[test]
    fn fix_in_intense_purposes() {
        assert_suggestion_result(
            "the solution has some rules than in all intense purposes is not necessarily database driven",
            AllIntentsAndPurposes::default(),
            "the solution has some rules than for all intents and purposes is not necessarily database driven",
        );
    }

    #[test]
    fn fix_to_intensive_purposes() {
        assert_suggestion_result(
            "To all intensive purposes, for the consumer, a view is a table",
            AllIntentsAndPurposes::default(),
            "To all intents and purposes, for the consumer, a view is a table",
        );
    }

    // Nouns with "and"

    #[test]
    fn fix_at_intents_and() {
        assert_suggestion_result(
            "can be thought of, at all intents and purposes, as a controlled cache",
            AllIntentsAndPurposes::default(),
            "can be thought of, for all intents and purposes, as a controlled cache",
        );
    }

    #[test]
    fn fix_by_intents_and() {
        assert_suggestion_result(
            "so by all intents and purposes one is not nested into another",
            AllIntentsAndPurposes::default(),
            "so for all intents and purposes one is not nested into another",
        );
    }

    #[test]
    fn fix_for_extents_and() {
        assert_suggestion_result(
            "#include, for all extents and purposes (if you take the preprocessor out) just copies the file",
            AllIntentsAndPurposes::default(),
            "#include, for all intents and purposes (if you take the preprocessor out) just copies the file",
        );
    }

    #[test]
    fn dont_flag_for_intents_and() {
        assert_no_lints(
            "with the previous previous setting still present and for all intents and purposes seems enabled",
            AllIntentsAndPurposes::default(),
        );
    }

    #[test]
    fn fix_from_intents_and() {
        assert_suggestion_result(
            "act as a full archive node from all intents and purposes",
            AllIntentsAndPurposes::default(),
            "act as a full archive node for all intents and purposes",
        );
    }

    #[test]
    fn fix_in_intents_and() {
        assert_suggestion_result(
            "I posted #20493 asking about, in all intents and purposes, deno info",
            AllIntentsAndPurposes::default(),
            "I posted #20493 asking about, for all intents and purposes, deno info",
        );
    }

    #[test]
    fn fix_on_intents_and() {
        assert_suggestion_result(
            "It depends on all intents and purposes what you want to do.",
            AllIntentsAndPurposes::default(),
            "It depends for all intents and purposes what you want to do.",
        );
    }

    #[test]
    fn fix_through_intents_and() {
        assert_suggestion_result(
            "While, I know through all intents and purposes it is an ugly url to look at",
            AllIntentsAndPurposes::default(),
            "While, I know for all intents and purposes it is an ugly url to look at",
        );
    }

    #[test]
    fn fix_to_extents_and() {
        assert_suggestion_result(
            "and they were trying to find out how that would also affect the the personnel to all extents and purposes.",
            AllIntentsAndPurposes::default(),
            "and they were trying to find out how that would also affect the the personnel to all intents and purposes.",
        );
    }

    #[test]
    fn dont_flag_to_intents_and() {
        assert_no_lints(
            "and they were trying to find out how that would also affect the the personnel to all intents and purposes.",
            AllIntentsAndPurposes::default(),
        );
    }

    #[test]
    fn fix_with_intents_and() {
        assert_suggestion_result(
            "With all intents and purposes the array should be As String since all values I'll be dealing with will be strings.",
            AllIntentsAndPurposes::default(),
            "For all intents and purposes the array should be As String since all values I'll be dealing with will be strings.",
        );
    }

    // Adjectives with "and"!

    #[test]
    fn fix_by_intensive_purposes() {
        assert_suggestion_result(
            "By all intensive purposes this should be working",
            AllIntentsAndPurposes::default(),
            "For all intents and purposes this should be working",
        );
    }

    #[test]
    fn fix_for_intense_and() {
        assert_suggestion_result(
            "to test my site, which for all intense and purposes works",
            AllIntentsAndPurposes::default(),
            "to test my site, which for all intents and purposes works",
        );
    }

    #[test]
    fn fix_in_intensive_purposes() {
        assert_suggestion_result(
            "it should in all intensive purposes keep running",
            AllIntentsAndPurposes::default(),
            "it should for all intents and purposes keep running",
        );
    }

    #[test]
    fn fix_to_intense_and() {
        assert_suggestion_result(
            "The other type, is to all intense and purposes a submit button to the browser",
            AllIntentsAndPurposes::default(),
            "The other type, is to all intents and purposes a submit button to the browser",
        );
    }

    // Doesn't try to deal with qualified "all"

    #[test]
    fn dont_flag_for_basically_all_intents_and_purposes() {
        assert_no_lints(
            "For basically all intents and purposes, this works fine.",
            AllIntentsAndPurposes::default(),
        );
    }

    #[test]
    fn dont_flag_for_nearly_all_intents_and_purposes() {
        assert_no_lints(
            "but for nearly all intents and purposes this should be negligable",
            AllIntentsAndPurposes::default(),
        );
    }

    #[test]
    fn dont_flag_for_pretty_much_all_intents_and_purposes() {
        assert_no_lints(
            "or for pretty much all intents and purposes, between Android devices",
            AllIntentsAndPurposes::default(),
        );
    }

    // Strange false positives

    #[test]
    #[ignore = "Rare and unusual false positive"]
    fn false_positive_for_99_percent_of_all_intents_and_purposes() {
        assert_no_lints(
            "But for 99% of all intents and purposes they can be treated as lists.",
            AllIntentsAndPurposes::default(),
        );
    }

    // US Constitution false positive

    #[test]
    fn false_positive_for_us_constitution_space() {
        assert_no_lints(
            "Amendments, which, in either Case, shall be valid to all Intents and Purposes, as Part of this Constitution",
            AllIntentsAndPurposes::default(),
        );
    }

    #[test]
    #[ignore = "The linefeed should be treated as a space!"]
    fn false_positive_for_us_constitution_line_break() {
        assert_no_lints(
            "Amendments, which, in either Case, shall be valid to all Intents and\nPurposes, as Part of this Constitution",
            AllIntentsAndPurposes::default(),
        );
    }
}



================================================
FILE: harper-core/src/linting/allow_to.rs
================================================
use crate::expr::{Expr, SequenceExpr};
use crate::linting::expr_linter::Chunk;
use crate::linting::{ExprLinter, Lint, LintKind};
use crate::token::Token;
use crate::token_string_ext::TokenStringExt;

pub struct AllowTo {
    exp: Box<dyn Expr>,
}

impl Default for AllowTo {
    fn default() -> Self {
        Self {
            // Note: Does not include "allowed to", which is a legitimate usage in its own right.
            exp: Box::new(
                SequenceExpr::word_set(&["allow", "allowing", "allows"])
                    .t_ws()
                    .t_aco("to")
                    .then_optional(SequenceExpr::default().t_ws().then_adverb())
                    .t_ws()
                    .then_any_word(),
            ),
        }
    }
}

impl ExprLinter for AllowTo {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.exp.as_ref()
    }

    fn match_to_lint(&self, toks: &[Token], _src: &[char]) -> Option<Lint> {
        let span = toks.span()?;
        let first = toks.first()?;
        let allow = first.span.get_content_string(_src);

        let message = format!(
            "For correct usage, either add a subject between `{allow}` and `to` (e.g., `{allow} someone to do`) or use the present participle (e.g., `{allow} doing`)."
        );

        Some(Lint {
            span,
            lint_kind: LintKind::Grammar,
            suggestions: vec![],
            message,
            ..Default::default()
        })
    }

    fn description(&self) -> &'static str {
        "Flags erroneous usage of `allow to` without a subject."
    }
}

#[cfg(test)]
mod tests {
    use super::AllowTo;
    use crate::linting::tests::{assert_lint_count, assert_no_lints};

    #[test]
    fn flag_allow_to() {
        assert_lint_count(
            "Allow to change approval policy during running task # 4394.",
            AllowTo::default(),
            1,
        );
    }

    #[test]
    fn flag_allowing_to() {
        assert_lint_count(
            "Allowing to have multiple views with different filtering # 952.",
            AllowTo::default(),
            1,
        );
    }

    #[test]
    fn flag_allows_to() {
        assert_lint_count(
            "It is easily doable for classic IHostBuilder, because its extension allows to pass configure action",
            AllowTo::default(),
            1,
        );
    }

    #[test]
    fn dont_flag_allowed_to() {
        assert_no_lints(
            "In C and C++ aliasing has to do with what expression types we are allowed to access stored values through.",
            AllowTo::default(),
        );
    }

    #[test]
    fn dont_flag_allow_pronoun_to() {
        assert_no_lints(
            "It would be really great to allow me to enter body data using multipart form",
            AllowTo::default(),
        );
    }

    #[test]
    fn dont_flag_allow_noun_to() {
        assert_no_lints(
            "Allows users to export SMART statistics from any connected hard drive",
            AllowTo::default(),
        );
    }

    #[test]
    fn dont_flag_allow_np_to() {
        assert_no_lints(
            "This vulnerability allows an authenticated attacker to infer data from the database by measuring response times",
            AllowTo::default(),
        );
    }
}



================================================
FILE: harper-core/src/linting/am_in_the_morning.rs
================================================
use crate::linting::expr_linter::Chunk;
use crate::{
    Span, Token, TokenStringExt,
    expr::{Expr, FixedPhrase, LongestMatchOf, SequenceExpr},
    linting::{ExprLinter, Lint, LintKind, Suggestion},
    patterns::WordSet,
};

pub struct AmInTheMorning {
    expr: Box<dyn Expr>,
}

impl Default for AmInTheMorning {
    fn default() -> Self {
        let am = WordSet::new(&["am", "a.m."]);
        let pm = WordSet::new(&["pm", "p.m."]);

        let maybe_ws_am = LongestMatchOf::new(vec![
            Box::new(SequenceExpr::with(am.clone())),
            Box::new(SequenceExpr::default().then_whitespace().then(am)),
        ]);
        let maybe_ws_pm = LongestMatchOf::new(vec![
            Box::new(SequenceExpr::with(pm.clone())),
            Box::new(SequenceExpr::default().then_whitespace().then(pm)),
        ]);

        let ws_in_periods = SequenceExpr::default()
            .then(FixedPhrase::from_phrase(" in the "))
            .then(WordSet::new(&["morning", "afternoon", "evening", "night"]));

        let ws_at_periods = FixedPhrase::from_phrase(" at night");

        let expr = SequenceExpr::default()
            .then_any_of(vec![Box::new(maybe_ws_am), Box::new(maybe_ws_pm)])
            .then_any_of(vec![Box::new(ws_in_periods), Box::new(ws_at_periods)]);

        Self {
            expr: Box::new(expr),
        }
    }
}

impl ExprLinter for AmInTheMorning {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, toks: &[Token], src: &[char]) -> Option<Lint> {
        let all_after_number_span = toks[0..].span()?;
        let am_pm_idx = if toks[0].kind.is_whitespace() { 1 } else { 0 };

        let maybe_ws_am_pm_span = Span::new(toks[0].span.start, toks[am_pm_idx].span.end);
        let sugg_am_pm_only =
            Suggestion::ReplaceWith(maybe_ws_am_pm_span.get_content(src).to_vec());

        let ws_prep_period = Span::new(toks[am_pm_idx + 1].span.start, all_after_number_span.end);
        let sugg_prep_period_only =
            Suggestion::ReplaceWith(ws_prep_period.get_content(src).to_vec());

        Some(Lint {
            span: all_after_number_span,
            lint_kind: LintKind::Redundancy,
            suggestions: vec![sugg_am_pm_only, sugg_prep_period_only],
            message: "The time period is redundant because it repeats what's already specified by the AM/PM indicator.".to_owned(),            priority: 50,
        })
    }

    fn description(&self) -> &'static str {
        "Finds redundant am/pm indicators used together with time periods such as 'in the morning' or 'at night'."
    }
}

#[cfg(test)]
mod tests {
    use super::AmInTheMorning;
    use crate::linting::tests::{
        assert_lint_count, assert_nth_suggestion_result, assert_suggestion_result,
    };

    #[test]
    fn flag_at_4am_in_the_morning() {
        assert_lint_count("At 4am in the morning", AmInTheMorning::default(), 1);
    }

    #[test]
    fn fix_at_4am_in_the_morning() {
        assert_suggestion_result("At 4am in the morning", AmInTheMorning::default(), "At 4am");
    }

    #[test]
    fn flag_at_4_am_in_the_morning() {
        assert_lint_count("At 4 am in the morning", AmInTheMorning::default(), 1);
    }

    #[test]
    fn fix_at_4_am_in_the_morning() {
        assert_suggestion_result(
            "At 4 am in the morning",
            AmInTheMorning::default(),
            "At 4 am",
        );
    }

    #[test]
    fn flag_at_4am_in_the_morning_caps() {
        assert_lint_count("At 4AM in the morning", AmInTheMorning::default(), 1);
    }

    #[test]
    fn fix_at_4am_in_the_morning_caps() {
        assert_suggestion_result("At 4AM in the morning", AmInTheMorning::default(), "At 4AM");
    }

    #[test]
    fn flag_at_4_am_in_the_morning_caps() {
        assert_lint_count("At 4 AM in the morning", AmInTheMorning::default(), 1);
    }

    #[test]
    fn fix_at_4_am_in_the_morning_caps() {
        assert_suggestion_result(
            "At 4 AM in the morning",
            AmInTheMorning::default(),
            "At 4 AM",
        );
    }

    #[test]
    fn at_4_a_dot_m_dot_in_the_morning() {
        assert_lint_count("At 4 a.m. in the morning", AmInTheMorning::default(), 1)
    }

    #[test]
    fn fix_at_4_a_dot_m_dot_in_the_morning() {
        assert_suggestion_result(
            "At 4 a.m. in the morning",
            AmInTheMorning::default(),
            "At 4 a.m.",
        );
    }

    // real-world examples

    #[test]
    fn fix_real_world_1_am_in_the_morning() {
        assert_suggestion_result(
            "I wrote this whole program as a joke, at 1 AM in the morning. Nothing else to say.",
            AmInTheMorning::default(),
            "I wrote this whole program as a joke, at 1 AM. Nothing else to say.",
        );
        assert_nth_suggestion_result(
            "I wrote this whole program as a joke, at 1 AM in the morning. Nothing else to say.",
            AmInTheMorning::default(),
            "I wrote this whole program as a joke, at 1 in the morning. Nothing else to say.",
            1,
        );
    }

    #[test]
    fn fix_real_world_3am_in_the_morning() {
        assert_suggestion_result(
            "Luckily I was at home, but it was not fun at 3am in the morning.",
            AmInTheMorning::default(),
            "Luckily I was at home, but it was not fun at 3am.",
        );
        assert_nth_suggestion_result(
            "Luckily I was at home, but it was not fun at 3am in the morning.",
            AmInTheMorning::default(),
            "Luckily I was at home, but it was not fun at 3 in the morning.",
            1,
        );
    }

    #[test]
    fn fix_real_world_3am_at_night() {
        assert_suggestion_result(
            "If I want to run my script or some cron job at 3am at night, it seems to be not possible after macOS is in sleep mode.",
            AmInTheMorning::default(),
            "If I want to run my script or some cron job at 3am, it seems to be not possible after macOS is in sleep mode.",
        );
        assert_nth_suggestion_result(
            "If I want to run my script or some cron job at 3am at night, it seems to be not possible after macOS is in sleep mode.",
            AmInTheMorning::default(),
            "If I want to run my script or some cron job at 3 at night, it seems to be not possible after macOS is in sleep mode.",
            1,
        );
    }

    #[test]
    fn fix_real_world_9pm_at_night() {
        assert_suggestion_result(
            "The servers stop at 9PM at night and starts again at 9AM.",
            AmInTheMorning::default(),
            "The servers stop at 9PM and starts again at 9AM.",
        );
        assert_nth_suggestion_result(
            "The servers stop at 9PM at night and starts again at 9AM.",
            AmInTheMorning::default(),
            "The servers stop at 9 at night and starts again at 9AM.",
            1,
        );
    }

    #[test]
    fn fix_real_world_3_30_am_in_the_morning() {
        assert_suggestion_result(
            "Hello I can't believe my neighbor had the nerve to knock on my door at 3:30 AM in the morning.",
            AmInTheMorning::default(),
            "Hello I can't believe my neighbor had the nerve to knock on my door at 3:30 AM.",
        );
        assert_nth_suggestion_result(
            "Hello I can't believe my neighbor had the nerve to knock on my door at 3:30 AM in the morning.",
            AmInTheMorning::default(),
            "Hello I can't believe my neighbor had the nerve to knock on my door at 3:30 in the morning.",
            1,
        );
    }

    #[test]
    fn fix_real_world_5_pm_in_the_afternoon_caps_dots() {
        assert_suggestion_result(
            "Style issues get a blue marker: It's 5 P.M. in the afternoon.",
            AmInTheMorning::default(),
            "Style issues get a blue marker: It's 5 P.M..",
        );
        assert_nth_suggestion_result(
            "Style issues get a blue marker: It's 5 P.M. in the afternoon.",
            AmInTheMorning::default(),
            "Style issues get a blue marker: It's 5 in the afternoon.",
            1,
        );
    }

    #[test]
    fn fix_real_world_5_pm_in_the_afternoon_caps() {
        assert_suggestion_result(
            "Its a impressively versatile tool if youd like to tell a colleague from over sea's about at 5 PM in the afternoon on Monday, 27 May 2007.",
            AmInTheMorning::default(),
            "Its a impressively versatile tool if youd like to tell a colleague from over sea's about at 5 PM on Monday, 27 May 2007.",
        );
        assert_nth_suggestion_result(
            "Its a impressively versatile tool if youd like to tell a colleague from over sea's about at 5 PM in the afternoon on Monday, 27 May 2007.",
            AmInTheMorning::default(),
            "Its a impressively versatile tool if youd like to tell a colleague from over sea's about at 5 in the afternoon on Monday, 27 May 2007.",
            1,
        );
    }

    #[test]
    fn fix_real_world_6_pm_in_the_evening() {
        assert_suggestion_result(
            "I am in China and it is six pm in the evening.",
            AmInTheMorning::default(),
            "I am in China and it is six pm.",
        );
        assert_nth_suggestion_result(
            "I am in China and it is six pm in the evening.",
            AmInTheMorning::default(),
            "I am in China and it is six in the evening.",
            1,
        );
    }

    #[test]
    fn fix_real_world_4_am_in_the_morning() {
        assert_suggestion_result(
            "On the second application, we normally have the 503 between 1am and 4 am in the morning, almost every day.",
            AmInTheMorning::default(),
            "On the second application, we normally have the 503 between 1am and 4 am, almost every day.",
        );
        assert_nth_suggestion_result(
            "On the second application, we normally have the 503 between 1am and 4 am in the morning, almost every day.",
            AmInTheMorning::default(),
            "On the second application, we normally have the 503 between 1am and 4 in the morning, almost every day.",
            1,
        );
    }
}



================================================
FILE: harper-core/src/linting/amounts_for.rs
================================================
use crate::expr::Expr;
use crate::expr::FirstMatchOf;
use crate::expr::FixedPhrase;
use crate::expr::SequenceExpr;
use crate::{Token, TokenStringExt, patterns::WordSet};

use super::{ExprLinter, Lint, LintKind, Suggestion};
use crate::linting::expr_linter::Chunk;

pub struct AmountsFor {
    expr: Box<dyn Expr>,
}

impl Default for AmountsFor {
    fn default() -> Self {
        let singular_context = WordSet::new(&["that", "which", "it", "this"]);

        let singular_pattern = SequenceExpr::default()
            .then(singular_context)
            .then_whitespace()
            .then(FixedPhrase::from_phrase("amounts for"));

        let singular_context = WordSet::new(&[
            "they", "can", "could", "may", "might", "must", "should", "will", "would",
        ]);

        let plural_pattern = SequenceExpr::default()
            .then(singular_context)
            .then_whitespace()
            .then(FixedPhrase::from_phrase("amount for"));

        Self {
            expr: Box::new(FirstMatchOf::new(vec![
                Box::new(singular_pattern),
                Box::new(plural_pattern),
            ])),
        }
    }
}

impl ExprLinter for AmountsFor {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, toks: &[Token], src: &[char]) -> Option<Lint> {
        let content = toks.span()?.get_content_string(src).to_lowercase();

        if content.ends_with("amounts for") {
            let span = toks[2..5].span()?;

            return Some(Lint {
                span,
                lint_kind: LintKind::WordChoice,
                suggestions: vec![
                    Suggestion::replace_with_match_case(
                        "amounts to".chars().collect(),
                        span.get_content(src),
                    ),
                    Suggestion::replace_with_match_case(
                        "accounts for".chars().collect(),
                        span.get_content(src),
                    ),
                ],
                message: "`amounts for` is not idiomatic English. You probably meant `amounts to` or `accounts for`.".to_owned(),
                priority: 63,
            });
        }

        if content.ends_with("amount for") {
            let span = toks[2..5].span()?;

            return Some(Lint {
                span,
                lint_kind: LintKind::WordChoice,
                suggestions: vec![
                    Suggestion::replace_with_match_case(
                        "amount to".chars().collect(),
                        span.get_content(src),
                    ),
                    Suggestion::replace_with_match_case(
                        "account for".chars().collect(),
                        span.get_content(src),
                    ),
                ],
                message: "`amounts for` is not idiomatic English. You probably meant `amounts to` or `accounts for`.".to_owned(),
                priority: 63,
            });
        }

        None
    }

    fn description(&self) -> &str {
        "Corrects `amounts for` to either `amounts to` or `accounts for`"
    }
}

#[cfg(test)]
mod tests {
    use super::AmountsFor;
    use crate::linting::tests::assert_top3_suggestion_result;

    #[test]
    fn corrects_that_amounts_for_to_amounts_to_entire_value() {
        assert_top3_suggestion_result(
            "Skyler stated the car wash is worth close to $800k, that amounts for the entire value of the company",
            AmountsFor::default(),
            "Skyler stated the car wash is worth close to $800k, that amounts to the entire value of the company",
        );
    }

    #[test]
    fn corrects_that_amounts_for_to_amounts_to_percent() {
        assert_top3_suggestion_result(
            "Together, that amounts for 1157 calls or 60% of the failures.",
            AmountsFor::default(),
            "Together, that amounts to 1157 calls or 60% of the failures.",
        );
    }

    #[test]
    fn corrects_that_amounts_for_to_accounts_for_setting_up() {
        assert_top3_suggestion_result(
            "One solution to this would be to have separate controllers but the amount of code that amounts for setting up, processing and calling",
            AmountsFor::default(),
            "One solution to this would be to have separate controllers but the amount of code that accounts for setting up, processing and calling",
        );
    }

    #[test]
    fn corrects_which_amounts_for_to_accounts_for_16k() {
        assert_top3_suggestion_result(
            "It has an offset of 0xC000 which amounts for the 16k.",
            AmountsFor::default(),
            "It has an offset of 0xC000 which accounts for the 16k.",
        );
    }

    #[test]
    fn corrects_this_amounts_for_to_accounts_for_large_part() {
        assert_top3_suggestion_result(
            "I'm pretty sure that this amounts for a large part of the speed I gained when typing, in addition to touch-typing.",
            AmountsFor::default(),
            "I'm pretty sure that this accounts for a large part of the speed I gained when typing, in addition to touch-typing.",
        );
    }

    #[test]
    fn corrects_they_amount_for_to_amount_to_16kb() {
        assert_top3_suggestion_result(
            "it is obvious that the messages are being held \"somewhere\" until they amount for 16kB and then the whole lot come at once.",
            AmountsFor::default(),
            "it is obvious that the messages are being held \"somewhere\" until they amount to 16kB and then the whole lot come at once.",
        );
    }

    #[test]
    fn corrects_which_amounts_for_to_amounts_to_10_minutes() {
        assert_top3_suggestion_result(
            "set a small TTL for your hostname (like 600 which amounts for 10 minutes).",
            AmountsFor::default(),
            "set a small TTL for your hostname (like 600 which amounts to 10 minutes).",
        );
    }

    #[test]
    fn corrects_it_amounts_for_to_amounts_to_redefinition() {
        assert_top3_suggestion_result(
            "included for convenience to get a Lorentz invariant result (it amounts for a redefinition of ap).",
            AmountsFor::default(),
            "included for convenience to get a Lorentz invariant result (it amounts to a redefinition of ap).",
        );
    }

    #[test]
    fn corrects_they_amount_for_to_amount_to_nothing() {
        assert_top3_suggestion_result(
            "Matter and antimatter are spread throughout the Universe, and in total, they amount for nothing",
            AmountsFor::default(),
            "Matter and antimatter are spread throughout the Universe, and in total, they amount to nothing",
        );
    }

    #[test]
    fn would_amount_for_to_amount_to_api_requests() {
        assert_top3_suggestion_result(
            "10% of 6,782,091 would amount for 678,209 API requests",
            AmountsFor::default(),
            "10% of 6,782,091 would amount to 678,209 API requests",
        );
    }

    #[test]
    fn will_amount_for_to_amount_to_relationships() {
        assert_top3_suggestion_result(
            "Consider this statistic from Gartner, that artificial intelligence will amount for 85% of customer relationships by 2020.",
            AmountsFor::default(),
            "Consider this statistic from Gartner, that artificial intelligence will amount to 85% of customer relationships by 2020.",
        );
    }

    #[test]
    fn should_amount_for_to_amount_to_half_pack() {
        assert_top3_suggestion_result(
            "It doesn't seem realistic that this single elite should amount for half the pack",
            AmountsFor::default(),
            "It doesn't seem realistic that this single elite should amount to half the pack",
        );
    }

    #[test]
    fn can_amount_for_to_amount_to_draw_calls() {
        assert_top3_suggestion_result(
            "That can amount for a lot of draw calls and work for the engine to cull. ",
            AmountsFor::default(),
            "That can amount to a lot of draw calls and work for the engine to cull. ",
        );
    }
}



================================================
FILE: harper-core/src/linting/an_a.rs
================================================
use std::borrow::Cow;

use itertools::Itertools;

use crate::case::Case::Upper;
use crate::char_ext::CharExt;
use crate::linting::{Lint, LintKind, Linter, Suggestion};
use crate::{CaseIterExt, Dialect, Document, TokenStringExt};

#[derive(PartialEq)]
pub enum InitialSound {
    Vowel,
    Consonant,
    Either, // for SQL
}

#[derive(Debug)]
pub struct AnA {
    dialect: Dialect,
}

impl AnA {
    pub fn new(dialect: Dialect) -> Self {
        Self { dialect }
    }
}

impl Linter for AnA {
    fn lint(&mut self, document: &Document) -> Vec<Lint> {
        let mut lints = Vec::new();

        for chunk in document.iter_chunks() {
            for (first_idx, second_idx) in chunk.iter_word_indices().tuple_windows() {
                // [`TokenKind::Unlintable`] might have semantic meaning.
                if chunk[first_idx..second_idx].iter_unlintables().count() > 0
                    || chunk[first_idx + 1..second_idx]
                        .iter_word_like_indices()
                        .count()
                        > 0
                {
                    continue;
                }

                let first = &chunk[first_idx];
                let second = &chunk[second_idx];

                let chars_first = document.get_span_content(&first.span);
                let chars_second = document.get_span_content(&second.span);
                // Break the second word on hyphens for this lint.
                // Example: "An ML-based" is an acceptable noun phrase.
                let chars_second = chars_second
                    .split(|c| !c.is_alphanumeric())
                    .next()
                    .unwrap_or(chars_second);

                let is_a_an = match chars_first {
                    ['a'] => Some(true),
                    ['A'] => Some(true),
                    ['a', 'n'] => Some(false),
                    ['A', 'n'] => Some(false),
                    _ => None,
                };

                let Some(a_an) = is_a_an else {
                    continue;
                };

                let should_be_a_an = match starts_with_vowel(chars_second, self.dialect)
                    .expect("No empty word tokens")
                {
                    InitialSound::Vowel => false,
                    InitialSound::Consonant => true,
                    InitialSound::Either => return lints,
                };

                if a_an != should_be_a_an {
                    let replacement = match a_an {
                        true => vec!['a', 'n'],
                        false => vec!['a'],
                    };

                    lints.push(Lint {
                        span: first.span,
                        lint_kind: LintKind::Miscellaneous,
                        suggestions: vec![Suggestion::replace_with_match_case(
                            replacement,
                            chars_first,
                        )],
                        message: "Incorrect indefinite article.".to_string(),
                        priority: 31,
                    })
                }
            }
        }

        lints
    }

    fn description(&self) -> &'static str {
        "A rule that looks for incorrect indefinite articles. For example, `this is an mule` would be flagged as incorrect."
    }
}

fn to_lower_word(word: &[char]) -> Cow<'_, [char]> {
    if word.iter().any(|c| c.is_uppercase()) {
        Cow::Owned(
            word.iter()
                .flat_map(|c| c.to_lowercase())
                .collect::<Vec<_>>(),
        )
    } else {
        Cow::Borrowed(word)
    }
}

/// Checks whether a provided word begins with a vowel _sound_. Returns `None` if `word` is empty.
///
/// It was produced through trial and error.
/// Matches with 99.71% and 99.77% of vowels and non-vowels in the
/// Carnegie-Mellon University word -> pronunciation dataset.
fn starts_with_vowel(word: &[char], dialect: Dialect) -> Option<InitialSound> {
    if word.is_empty() {
        return None;
    }

    if matches!(word, ['S', 'Q', 'L'] | ['L', 'E', 'D']) {
        return Some(InitialSound::Either);
    }

    // Try to get the first chunk of a word that appears to be a partial initialism.
    // For example:
    // - `RFL` from `RFLink`
    // - `m` from `mDNS`
    let word = {
        let word_casing = word.get_casing_unfiltered();
        match word_casing.as_slice() {
            // Lower-upper or upper-upper, possibly a (partial) initialism.
            [Some(first_char_case), Some(Upper), ..] => {
                &word[0..word_casing
                    .iter()
                    .position(|c| *c != Some(*first_char_case))
                    .unwrap_or(word.len())]
            }
            // Lower-lower or upper-lower, unlikely to be a partial initialism.
            _ => word,
        }
    };

    let is_likely_initialism = word.iter().all(|c| !c.is_alphabetic() || c.is_uppercase());

    if word.len() == 1 || (is_likely_initialism && !is_likely_acronym(word)) {
        return Some(
            if matches!(
                word[0].to_ascii_uppercase(),
                'A' | 'E' | 'F' | 'H' | 'I' | 'L' | 'M' | 'N' | 'O' | 'R' | 'S' | 'X'
            ) {
                InitialSound::Vowel
            } else {
                InitialSound::Consonant
            },
        );
    }

    let word = to_lower_word(word);
    let word = word.as_ref();

    if matches!(word, ['u', 'b', 'i', ..]) {
        return Some(InitialSound::Either);
    }

    if matches!(word, ['e', 'u', 'l', 'e', ..]) {
        return Some(InitialSound::Vowel);
    }

    if matches!(
        word,
        ['u', 'k', ..]
            | ['u', 'd', 'e', ..] // for 'udev'
            | ['e', 'u', 'p', 'h', ..]
            | ['e', 'u', 'g' | 'l' | 'c', ..]
            | ['o', 'n', 'e', ..]
            | ['o', 'n', 'c', 'e']
    ) {
        return Some(InitialSound::Consonant);
    }

    if matches!(
        word,
        ['h', 'o', 'u', 'r', ..]
            | ['u', 'n', 'i', 'n' | 'm', ..]
            | ['u', 'n', 'a' | 'u', ..]
            | ['u', 'r', 'b', ..]
            | ['i', 'n', 't', ..]
    ) {
        return Some(InitialSound::Vowel);
    }

    if matches!(word, ['h', 'e', 'r', 'b', ..] if dialect == Dialect::American || dialect == Dialect::Canadian)
    {
        return Some(InitialSound::Vowel);
    }

    if matches!(word, ['u', 'n' | 's', 'i' | 'a' | 'u', ..]) {
        return Some(InitialSound::Consonant);
    }

    if matches!(word, ['u', 'n', ..]) {
        return Some(InitialSound::Vowel);
    }

    if matches!(word, ['u', 'r', 'g', ..]) {
        return Some(InitialSound::Vowel);
    }

    if matches!(word, ['u', 't', 't', ..]) {
        return Some(InitialSound::Vowel);
    }

    if matches!(
        word,
        ['u', 't' | 'r' | 'n', ..] | ['e', 'u', 'r', ..] | ['u', 'w', ..] | ['u', 's', 'e', ..]
    ) {
        return Some(InitialSound::Consonant);
    }

    if matches!(word, ['o', 'n', 'e', 'a' | 'e' | 'i' | 'u', 'l' | 'd', ..]) {
        return Some(InitialSound::Vowel);
    }

    if matches!(word, ['o', 'n', 'e', 'a' | 'e' | 'i' | 'u' | '-' | 's', ..]) {
        return Some(InitialSound::Consonant);
    }

    if matches!(
        word,
        ['s', 'o', 's']
            | ['r', 'z', ..]
            | ['n', 'g', ..]
            | ['n', 'v', ..]
            | ['x', 'b', 'o', 'x']
            | ['h', 'e', 'i', 'r', ..]
            | ['h', 'o', 'n', 'o', 'r', ..]
            | ['h', 'o', 'n', 'e', 's', ..]
    ) {
        return Some(InitialSound::Vowel);
    }

    if matches!(
        word,
        ['j', 'u' | 'o', 'n', ..] | ['j', 'u', 'r', 'a' | 'i' | 'o', ..]
    ) {
        return Some(InitialSound::Consonant);
    }

    if matches!(word, ['x', '-' | '\'' | '.' | 'o' | 's', ..]) {
        return Some(InitialSound::Vowel);
    }

    if word[0].is_vowel() {
        return Some(InitialSound::Vowel);
    }

    Some(InitialSound::Consonant)
}

fn is_likely_acronym(word: &[char]) -> bool {
    /// Does the word contain any sequences that might indicate it's not an acronym?
    fn word_contains_false_positive_sequence(word: &[char]) -> bool {
        let likely_false_positive_sequences = [['V', 'C']];
        for fp_sequence in likely_false_positive_sequences {
            if word
                .windows(fp_sequence.len())
                .any(|subslice| subslice == fp_sequence)
            {
                return true;
            }
        }
        false
    }

    // If the initialism is shorter than this, skip it.
    const MIN_LEN: usize = 3;

    if let Some(first_chars) = word.get(..MIN_LEN)
        // Unlikely to be an acronym if it contains non-alphabetic characters.
        && first_chars.iter().copied().all(char::is_alphabetic)
        && !word_contains_false_positive_sequence(word)
    {
        let vowel_map = first_chars
            .iter()
            .map(CharExt::is_vowel)
            .collect_array::<MIN_LEN>()
            .unwrap();
        matches!(vowel_map, [false, true, false] | [false, true, true])
    } else {
        false
    }
}

#[cfg(test)]
mod tests {
    use super::AnA;
    use crate::Dialect;
    use crate::linting::tests::{assert_lint_count, assert_suggestion_result};

    #[test]
    fn detects_html_as_vowel() {
        assert_lint_count("Here is a HTML document.", AnA::new(Dialect::American), 1);
    }

    #[test]
    fn detects_llm_as_vowel() {
        assert_lint_count("Here is a LLM document.", AnA::new(Dialect::American), 1);
    }

    #[test]
    fn detects_llm_hyphen_as_vowel() {
        assert_lint_count(
            "Here is a LLM-based system.",
            AnA::new(Dialect::American),
            1,
        );
    }

    #[test]
    fn detects_euler_as_vowel() {
        assert_lint_count("This is an Euler brick.", AnA::new(Dialect::American), 0);
        assert_lint_count(
            "The graph has an Eulerian tour.",
            AnA::new(Dialect::American),
            0,
        );
    }

    #[test]
    fn capitalized_fourier() {
        assert_lint_count(
            "Then, perform a Fourier transform.",
            AnA::new(Dialect::American),
            0,
        );
    }

    #[test]
    fn once_over() {
        assert_lint_count("give this a once-over.", AnA::new(Dialect::American), 0);
    }

    #[test]
    fn issue_196() {
        assert_lint_count(
            "This is formatted as an `ext4` file system.",
            AnA::new(Dialect::American),
            0,
        );
    }

    #[test]
    fn allows_lowercase_vowels() {
        assert_lint_count("not an error", AnA::new(Dialect::American), 0);
    }

    #[test]
    fn allows_lowercase_consonants() {
        assert_lint_count("not a crash", AnA::new(Dialect::American), 0);
    }

    #[test]
    fn disallows_lowercase_vowels() {
        assert_lint_count("not a error", AnA::new(Dialect::American), 1);
    }

    #[test]
    fn disallows_lowercase_consonants() {
        assert_lint_count("not an crash", AnA::new(Dialect::American), 1);
    }

    #[test]
    fn allows_uppercase_vowels() {
        assert_lint_count("not an Error", AnA::new(Dialect::American), 0);
    }

    #[test]
    fn allows_uppercase_consonants() {
        assert_lint_count("not a Crash", AnA::new(Dialect::American), 0);
    }

    #[test]
    fn disallows_uppercase_vowels() {
        assert_lint_count("not a Error", AnA::new(Dialect::American), 1);
    }

    #[test]
    fn disallows_uppercase_consonants() {
        assert_lint_count("not an Crash", AnA::new(Dialect::American), 1);
    }

    #[test]
    fn disallows_a_interface() {
        assert_lint_count(
            "A interface for an object that can perform linting actions.",
            AnA::new(Dialect::American),
            1,
        );
    }

    #[test]
    fn allow_issue_751() {
        assert_lint_count(
            "He got a 52% approval rating.",
            AnA::new(Dialect::American),
            0,
        );
    }

    #[test]
    fn allow_an_mp_and_an_mp3() {
        assert_lint_count("an MP and an MP3?", AnA::new(Dialect::American), 0);
    }

    #[test]
    fn disallow_a_mp_and_a_mp3() {
        assert_lint_count("a MP and a MP3?", AnA::new(Dialect::American), 2);
    }

    #[test]
    fn recognize_acronyms() {
        // a
        assert_lint_count("using a MAC address", AnA::new(Dialect::American), 0);
        assert_lint_count("a NASA spacecraft", AnA::new(Dialect::American), 0);
        assert_lint_count("a NAT", AnA::new(Dialect::American), 0);
        assert_lint_count("a REST API", AnA::new(Dialect::American), 0);
        assert_lint_count("a LIBERO", AnA::new(Dialect::American), 0);
        assert_lint_count("a README", AnA::new(Dialect::American), 0);
        assert_lint_count("a LAN", AnA::new(Dialect::American), 0);

        // an
        assert_lint_count("an RA message", AnA::new(Dialect::American), 0);
        assert_lint_count("an SI unit", AnA::new(Dialect::American), 0);
        assert_lint_count(
            "he is an MA of both Oxford and Cambridge",
            AnA::new(Dialect::American),
            0,
        );
        assert_lint_count(
            "in an FA Cup 6th Round match",
            AnA::new(Dialect::American),
            0,
        );
        assert_lint_count("a AM transmitter", AnA::new(Dialect::American), 1);
    }

    #[test]
    fn dont_misrecognize_as_acronym() {
        assert_lint_count("a UPD connection", AnA::new(Dialect::American), 0);
        assert_lint_count("a UPB device", AnA::new(Dialect::American), 0);
        assert_lint_count("a UPS or power device", AnA::new(Dialect::American), 0);
        assert_lint_count("a USB 2.0 port", AnA::new(Dialect::American), 0);
        assert_lint_count("an HEVC HLS stream", AnA::new(Dialect::American), 0);
    }

    #[test]
    fn a_udev() {
        assert_lint_count("a udev rule", AnA::new(Dialect::American), 0);
    }

    #[test]
    fn an_mdns() {
        assert_lint_count("an mDNS tool", AnA::new(Dialect::American), 0);
    }

    #[test]
    fn an_rflink() {
        assert_lint_count("an RFLink device", AnA::new(Dialect::American), 0);
    }

    #[test]
    fn an_ffmpeg() {
        assert_lint_count(
            "an FFmpeg-compatible input file",
            AnA::new(Dialect::American),
            0,
        );
    }

    #[test]
    fn a_honey() {
        assert_lint_count("a Honeywell alarm panel", AnA::new(Dialect::American), 0);
    }

    #[test]
    fn an_onedrive() {
        assert_lint_count("a OneDrive folder", AnA::new(Dialect::American), 0);
    }

    #[test]
    fn a_ubiquiti() {
        assert_lint_count(
            "a Ubiquiti UniFi Network application",
            AnA::new(Dialect::American),
            0,
        );
    }

    #[test]
    fn an_honest() {
        assert_lint_count("an honest mistake", AnA::new(Dialect::American), 0);
    }

    #[test]
    fn dont_flag_an_herb_for_american() {
        assert_lint_count("an herb", AnA::new(Dialect::American), 0);
    }

    #[test]
    fn dont_flag_a_herb_for_british() {
        assert_lint_count("a herb", AnA::new(Dialect::British), 0);
    }

    #[test]
    fn correct_an_herb_for_australian() {
        assert_suggestion_result("an herb", AnA::new(Dialect::Australian), "a herb");
    }

    #[test]
    fn correct_a_herb_for_canadian() {
        assert_suggestion_result("a herb", AnA::new(Dialect::Canadian), "an herb");
    }

    #[test]
    fn dont_flag_a_sql() {
        assert_lint_count("a SQL query", AnA::new(Dialect::American), 0);
    }

    #[test]
    fn dont_flag_an_sql() {
        assert_lint_count("an SQL query", AnA::new(Dialect::Australian), 0);
    }

    #[test]
    fn allow_an_and_a_for_led_2550() {
        assert_lint_count("an LED", AnA::new(Dialect::American), 0);
        assert_lint_count("a LED", AnA::new(Dialect::American), 0);
    }
}



================================================
FILE: harper-core/src/linting/and_in.rs
================================================
use crate::Token;
use crate::expr::{Expr, SequenceExpr};
use crate::linting::expr_linter::Chunk;
use crate::linting::{ExprLinter, Lint, LintKind, Suggestion};

pub struct AndIn {
    expr: Box<dyn Expr>,
}

impl Default for AndIn {
    fn default() -> Self {
        Self {
            expr: Box::new(SequenceExpr::fixed_phrase("an in").then_optional_hyphen()),
        }
    }
}

impl ExprLinter for AndIn {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        &*self.expr
    }

    fn match_to_lint(&self, toks: &[Token], src: &[char]) -> Option<Lint> {
        if toks.len() != 3 {
            return None;
        }

        Some(Lint {
            span: toks[0].span,
            lint_kind: LintKind::Typo,
            message: "Did you mean `and in`?".to_string(),
            suggestions: vec![Suggestion::replace_with_match_case(
                ['a', 'n', 'd'].to_vec(),
                toks[2].span.get_content(src),
            )],
            ..Default::default()
        })
    }

    fn description(&self) -> &str {
        "Fixes the incorrect phrase `an in` to `and in` for proper conjunction usage."
    }
}

#[cfg(test)]
mod tests {
    use super::AndIn;
    use crate::linting::tests::{assert_no_lints, assert_suggestion_result};

    #[test]
    fn dont_flag_an_in_house() {
        assert_no_lints(
            "for several years as an in-house engine, used to ...",
            AndIn::default(),
        );
    }

    #[test]
    fn dont_flag_an_in_memory() {
        assert_no_lints(
            "including an in-memory real-time Vector Index,",
            AndIn::default(),
        );
    }

    #[test]
    fn dont_flag_an_in_the_moment() {
        assert_no_lints(
            "His words serve as an in-the-moment explanation for what had happened.",
            AndIn::default(),
        );
    }

    #[test]
    fn fix_an_in_to_and_in() {
        assert_suggestion_result(
            "This is an expensive operation, so try to only do it at startup an in tests.",
            AndIn::default(),
            "This is an expensive operation, so try to only do it at startup and in tests.",
        );
    }

    #[test]
    #[ignore = "This is a known false positive - `an in` can be valid in some contexts"]
    fn dont_flag_an_in_with_company() {
        assert_no_lints(
            "His parents got him an in with the company.",
            AndIn::default(),
        );
    }
}



================================================
FILE: harper-core/src/linting/and_the_like.rs
================================================
use crate::expr::{All, Expr, FixedPhrase, SequenceExpr};
use crate::linting::expr_linter::Chunk;
use crate::linting::{ExprLinter, LintKind, Suggestion};
use crate::patterns::WordSet;
use crate::token_string_ext::TokenStringExt;
use crate::{Lint, Token};

pub struct AndTheLike {
    expr: Box<dyn Expr>,
}

impl Default for AndTheLike {
    fn default() -> Self {
        Self {
            expr: Box::new(All::new(vec![
                Box::new(
                    // All known variants seen in the wild, good and bad
                    SequenceExpr::word_set(&["and", "or", "an"])
                        .t_ws()
                        .then_optional(SequenceExpr::aco("the").t_ws())
                        .then_word_set(&["alike", "alikes", "like", "likes"]),
                ),
                Box::new(SequenceExpr::unless(
                    SequenceExpr::word_set(&["and", "or"])
                        .t_ws()
                        .then_any_of(vec![
                            // But not the correct variants
                            Box::new(FixedPhrase::from_phrase("the like")),
                            // And not the phrases that were coincidentally caught in the net
                            Box::new(WordSet::new(&["like", "likes"])),
                        ]),
                )),
            ])),
        }
    }
}

impl ExprLinter for AndTheLike {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, toks: &[Token], src: &[char]) -> Option<Lint> {
        let (conj, ws) = (&toks[0], &toks[1]);

        let conj = if conj.span.get_content(src)[0] == 'a' {
            "and"
        } else {
            "or"
        };

        let corrected = format!("{}{}the like", conj, ws.span.get_content_string(src));

        Some(Lint {
            span: toks.span()?,
            lint_kind: LintKind::Usage,
            suggestions: vec![Suggestion::replace_with_match_case(
                corrected.chars().collect(),
                toks.span()?.get_content(src),
            )],
            message: "If you intended the idiom meaning `similar things`, the correct form is with `the like`.".to_string(),
            ..Default::default()
        })
    }

    fn description(&self) -> &str {
        "Corrects mistakes in `and the like` and `or the like`."
    }
}

#[cfg(test)]
mod tests {
    use super::AndTheLike;
    use crate::linting::tests::{assert_no_lints, assert_suggestion_result};

    #[test]
    fn dont_flag_and_the_like() {
        assert_no_lints(
            "The color of brackets and the like appears to be incorrect ...",
            AndTheLike::default(),
        );
    }

    #[test]
    fn dont_flag_or_the_like() {
        assert_no_lints(
            "Does WCAG apply only to English (or the like), or does it aim to cover all languages?",
            AndTheLike::default(),
        );
    }

    #[test]
    fn flag_an_the_likes() {
        assert_suggestion_result(
            "Allow jsSourceDir (an the likes) to refer to the project root. #5",
            AndTheLike::default(),
            "Allow jsSourceDir (and the like) to refer to the project root. #5",
        );
    }

    #[test]
    fn flag_and_alike() {
        assert_suggestion_result(
            "Latest release breaks FilePicker and alike",
            AndTheLike::default(),
            "Latest release breaks FilePicker and the like",
        );
    }

    #[test]
    fn flag_and_alikes() {
        assert_suggestion_result(
            "Compiled functions (and alikes) need to keep references for their module objects",
            AndTheLike::default(),
            "Compiled functions (and the like) need to keep references for their module objects",
        );
    }

    #[test]
    fn flag_and_the_alike() {
        assert_suggestion_result(
            "Suggestions, comments and the alike are welcome on http://waa.ai/4xtC",
            AndTheLike::default(),
            "Suggestions, comments and the like are welcome on http://waa.ai/4xtC",
        );
    }

    #[test]
    fn flag_and_the_likes() {
        assert_suggestion_result(
            "Don't report \"expected semicolon or line break\", \"expected comma\" and the likes at every token boundary",
            AndTheLike::default(),
            "Don't report \"expected semicolon or line break\", \"expected comma\" and the like at every token boundary",
        );
    }

    #[test]
    fn flag_or_alike() {
        assert_suggestion_result(
            "enable biome extension to \"monitor or alike\" the workspace.",
            AndTheLike::default(),
            "enable biome extension to \"monitor or the like\" the workspace.",
        );
    }

    #[test]
    fn flag_or_alikes() {
        assert_suggestion_result(
            "Persistent Compiler Caching with ccache or alikes",
            AndTheLike::default(),
            "Persistent Compiler Caching with ccache or the like",
        );
    }

    #[test]
    fn flag_or_the_likes() {
        assert_suggestion_result(
            "Description of the problem: Implement aria2c or the likes to resume partial downloads.",
            AndTheLike::default(),
            "Description of the problem: Implement aria2c or the like to resume partial downloads.",
        );
    }
}



================================================
FILE: harper-core/src/linting/another_thing_coming.rs
================================================
use crate::linting::expr_linter::Chunk;
use crate::{
    Token, TokenStringExt,
    expr::{Expr, FixedPhrase, SequenceExpr},
    linting::{ExprLinter, Lint, LintKind, Suggestion},
    patterns::WordSet,
};

/// Both `another thing coming` and `another think coming` are correct, but `another think coming` is more common.
pub struct AnotherThingComing {
    expr: Box<dyn Expr>,
}

impl Default for AnotherThingComing {
    fn default() -> Self {
        Self {
            expr: Box::new(
                SequenceExpr::default()
                    .then(WordSet::new(&["had", "has", "have", "got"]))
                    .then(FixedPhrase::from_phrase(" another think coming")),
            ),
        }
    }
}

impl ExprLinter for AnotherThingComing {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, toks: &[Token], src: &[char]) -> Option<Lint> {
        Some(Lint {
            span: toks[2..].span()?,
            lint_kind: LintKind::WordChoice,
            suggestions: vec![Suggestion::replace_with_match_case_str(
                "another thing coming",
                toks.span()?.get_content(src),
            )],
            message: "Corrects `another think coming` to `another thing coming`".to_string(),
            priority: 63,
        })
    }

    fn description(&self) -> &str {
        "Though `another think coming` is the original phrase, `another thing coming` is now more common."
    }
}

#[cfg(test)]
pub mod tests {
    use super::AnotherThingComing;
    use crate::linting::tests::assert_suggestion_result;

    #[test]
    fn fix_have_another_think_coming() {
        assert_suggestion_result(
            "If you think that, you have another think coming, English.",
            AnotherThingComing::default(),
            "If you think that, you have another thing coming, English.",
        );
    }

    #[test]
    fn fix_has_another_think_coming() {
        assert_suggestion_result(
            "If the wage earner thinks that he will obtain anything from either of the old parties he has another think coming.",
            AnotherThingComing::default(),
            "If the wage earner thinks that he will obtain anything from either of the old parties he has another thing coming.",
        );
    }

    #[test]
    #[ignore = "A lettercase bug results in 'another thiNG COMing.'"]
    fn fix_got_another_think_coming() {
        assert_suggestion_result(
            "The correct phrase is, “You've got another THINK coming.”",
            AnotherThingComing::default(),
            "The correct phrase is, “You've got another THING coming.”",
        );
    }

    #[test]
    fn fix_had_another_think_coming() {
        assert_suggestion_result(
            "Guess I had another think coming.",
            AnotherThingComing::default(),
            "Guess I had another thing coming.",
        );
    }
}



================================================
FILE: harper-core/src/linting/another_think_coming.rs
================================================
use crate::linting::expr_linter::Chunk;
use crate::{
    Token, TokenStringExt,
    expr::{Expr, FixedPhrase, SequenceExpr},
    linting::{ExprLinter, Lint, LintKind, Suggestion},
    patterns::WordSet,
};

/// Both `another thing coming` and `another think coming` are correct, but `another think coming` is the original.
pub struct AnotherThinkComing {
    expr: Box<dyn Expr>,
}

impl Default for AnotherThinkComing {
    fn default() -> Self {
        Self {
            expr: Box::new(
                SequenceExpr::default()
                    .then(WordSet::new(&["had", "has", "have", "got"]))
                    .then(FixedPhrase::from_phrase(" another thing coming")),
            ),
        }
    }
}

impl ExprLinter for AnotherThinkComing {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, toks: &[Token], src: &[char]) -> Option<Lint> {
        Some(Lint {
            span: toks[2..].span()?,
            lint_kind: LintKind::WordChoice,
            suggestions: vec![Suggestion::replace_with_match_case_str(
                "another think coming",
                toks.span()?.get_content(src),
            )],
            message: "Corrects `another thing coming` to `another think coming`".to_string(),
            priority: 63,
        })
    }

    fn description(&self) -> &str {
        "Though `another thing coming` is now more common, `another think coming` is the original phrase."
    }
}

#[cfg(test)]
pub mod tests {
    use super::AnotherThinkComing;
    use crate::linting::tests::assert_suggestion_result;

    #[test]
    fn fix_got_another_thing_coming() {
        assert_suggestion_result(
            "If Microsoft thinks my Team and I are going to REINSTALL Windows fresh on over 1500 PC's they've got another thing coming!!",
            AnotherThinkComing::default(),
            "If Microsoft thinks my Team and I are going to REINSTALL Windows fresh on over 1500 PC's they've got another think coming!!",
        );
    }

    #[test]
    fn fix_has_another_thing_coming() {
        assert_suggestion_result(
            "Anyone who thinks it's easy to raise a child has another thing coming.",
            AnotherThinkComing::default(),
            "Anyone who thinks it's easy to raise a child has another think coming.",
        );
    }

    #[test]
    fn fix_have_another_thing_coming() {
        assert_suggestion_result(
            "And if you think they're predictable, you have another thing coming still.",
            AnotherThinkComing::default(),
            "And if you think they're predictable, you have another think coming still.",
        );
    }

    #[test]
    fn fix_had_another_thing_coming() {
        assert_suggestion_result(
            "And wouldn't you know it I had another thing coming.",
            AnotherThinkComing::default(),
            "And wouldn't you know it I had another think coming.",
        );
    }
}



================================================
FILE: harper-core/src/linting/apart_from.rs
================================================
use crate::Token;
use crate::expr::{Expr, SequenceExpr};
use crate::linting::expr_linter::Chunk;

use super::{ExprLinter, Lint, LintKind, Suggestion};

pub struct ApartFrom {
    expr: Box<dyn Expr>,
}

impl Default for ApartFrom {
    fn default() -> Self {
        let expr = SequenceExpr::any_capitalization_of("apart")
            .t_ws()
            .then_any_capitalization_of("form");

        Self {
            expr: Box::new(expr),
        }
    }
}

impl ExprLinter for ApartFrom {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], source: &[char]) -> Option<Lint> {
        let span = matched_tokens.last()?.span;

        Some(Lint {
            span,
            lint_kind: LintKind::WordChoice,
            suggestions: vec![Suggestion::replace_with_match_case_str(
                "from",
                span.get_content(source),
            )],
            message: "Use `from` to spell `apart from`.".to_owned(),
            priority: 50,
        })
    }

    fn description(&self) -> &'static str {
        "Flags the misspelling `apart form` and suggests `apart from`."
    }
}

#[cfg(test)]
mod tests {
    use super::ApartFrom;
    use crate::linting::tests::{assert_lint_count, assert_suggestion_result};

    #[test]
    fn corrects_basic_typo() {
        assert_suggestion_result(
            "Christianity was set apart form other religions.",
            ApartFrom::default(),
            "Christianity was set apart from other religions.",
        );
    }

    #[test]
    fn corrects_title_case() {
        assert_suggestion_result(
            "Apart Form these files, everything uploaded fine.",
            ApartFrom::default(),
            "Apart From these files, everything uploaded fine.",
        );
    }

    #[test]
    fn corrects_all_caps() {
        assert_suggestion_result(
            "APART FORM THE REST OF THE FIELD.",
            ApartFrom::default(),
            "APART FROM THE REST OF THE FIELD.",
        );
    }

    #[test]
    fn corrects_with_comma() {
        assert_suggestion_result(
            "It was apart form, not apart from, the original plan.",
            ApartFrom::default(),
            "It was apart from, not apart from, the original plan.",
        );
    }

    #[test]
    fn corrects_with_newline() {
        assert_suggestion_result(
            "They stood apart\nform everyone else at the rally.",
            ApartFrom::default(),
            "They stood apart\nfrom everyone else at the rally.",
        );
    }

    #[test]
    fn corrects_extra_spacing() {
        assert_suggestion_result(
            "We keep the archive apart   form public assets.",
            ApartFrom::default(),
            "We keep the archive apart   from public assets.",
        );
    }

    #[test]
    fn allows_correct_phrase() {
        assert_lint_count(
            "Lebanon's freedoms set it apart from other Arab states.",
            ApartFrom::default(),
            0,
        );
    }

    #[test]
    fn ignores_hyphenated() {
        assert_lint_count(
            "Their apart-form design wasn’t what we needed.",
            ApartFrom::default(),
            0,
        );
    }

    #[test]
    fn ignores_split_by_comma() {
        assert_lint_count(
            "They stood apart, form lines when asked.",
            ApartFrom::default(),
            0,
        );
    }

    #[test]
    fn ignores_unrelated_form_usage() {
        assert_lint_count(
            "The form was kept apart to dry after printing.",
            ApartFrom::default(),
            0,
        );
    }
}



================================================
FILE: harper-core/src/linting/ask_no_preposition.rs
================================================
use crate::expr::Expr;
use crate::expr::SequenceExpr;
use crate::linting::expr_linter::Chunk;
use crate::{
    Span, Token,
    linting::{ExprLinter, Lint, LintKind, Suggestion},
    patterns::WordSet,
};

pub struct AskNoPreposition {
    expr: Box<dyn Expr>,
}

impl Default for AskNoPreposition {
    fn default() -> Self {
        let verbs = WordSet::new(&[
            "ask", "asks", "asked", "asking", "tell", "tells", "told", "telling",
        ]);

        let objs = WordSet::new(&["me", "you", "him", "her", "it", "us", "them", "one"]);

        let pattern = SequenceExpr::default()
            .then(verbs)
            .then_whitespace()
            .t_aco("to")
            .then_whitespace()
            .then(objs);

        Self {
            expr: Box::new(pattern),
        }
    }
}

impl ExprLinter for AskNoPreposition {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, toks: &[Token], src: &[char]) -> Option<Lint> {
        if toks.len() < 5 {
            return None;
        }

        let verb = toks[0].span.get_content_string(src).to_lowercase();
        let span = Span::new(toks[2].span.start, toks[3].span.end);

        Some(Lint {
            span,
            lint_kind: LintKind::WordChoice,
            suggestions: vec![Suggestion::ReplaceWith(Vec::new())],
            message: format!(
                "The verb `to {verb} someone` should not be preceded by the preposition `to`."
            ),
            priority: 63,
        })
    }

    fn description(&self) -> &str {
        "Identifies sequences like `ask to us` or `tell to him` and recommends removing the superfluous “to”."
    }
}

#[cfg(test)]
mod tests {
    use super::AskNoPreposition;
    use crate::linting::tests::{assert_lint_count, assert_suggestion_result};

    #[test]
    fn flags_ask() {
        assert_suggestion_result(
            "Nora asked to us about the concert lineup.",
            AskNoPreposition::default(),
            "Nora asked us about the concert lineup.",
        );
    }

    #[test]
    fn flags_ask_all_caps() {
        assert_suggestion_result(
            "NORA ASKED TO US ABOUT THE CONCERT LINEUP.",
            AskNoPreposition::default(),
            "NORA ASKED US ABOUT THE CONCERT LINEUP.",
        );
    }

    #[test]
    fn flags_tell() {
        assert_suggestion_result(
            "Please tell to him the results promptly.",
            AskNoPreposition::default(),
            "Please tell him the results promptly.",
        );
    }

    #[test]
    fn ignores_correct_usage() {
        assert_lint_count(
            "She asked her mentor a difficult question.",
            AskNoPreposition::default(),
            0,
        );
    }

    #[test]
    fn flags_ask_us() {
        assert_suggestion_result(
            "Can you ask to us for directions?",
            AskNoPreposition::default(),
            "Can you ask us for directions?",
        );
    }

    #[test]
    fn flags_asks_him() {
        assert_suggestion_result(
            "Julia asks to him every morning about the report.",
            AskNoPreposition::default(),
            "Julia asks him every morning about the report.",
        );
    }

    #[test]
    fn flags_asked_me() {
        assert_suggestion_result(
            "They asked to me why I left early.",
            AskNoPreposition::default(),
            "They asked me why I left early.",
        );
    }

    #[test]
    fn flags_told_one() {
        assert_suggestion_result(
            "The guide told to one the secret path.",
            AskNoPreposition::default(),
            "The guide told one the secret path.",
        );
    }

    #[test]
    fn flags_telling_it() {
        assert_suggestion_result(
            "She is telling to it with gentle words.",
            AskNoPreposition::default(),
            "She is telling it with gentle words.",
        );
    }

    #[test]
    fn flags_tells_them() {
        assert_suggestion_result(
            "He tells to them stories at night.",
            AskNoPreposition::default(),
            "He tells them stories at night.",
        );
    }

    #[test]
    fn flags_telling_him() {
        assert_suggestion_result(
            "I was telling to him the latest news.",
            AskNoPreposition::default(),
            "I was telling him the latest news.",
        );
    }

    #[test]
    fn flags_asking_you() {
        assert_suggestion_result(
            "Someone is asking to you for help.",
            AskNoPreposition::default(),
            "Someone is asking you for help.",
        );
    }

    #[test]
    fn ignores_ask_question() {
        assert_lint_count(
            "Ask her the question directly.",
            AskNoPreposition::default(),
            0,
        );
    }

    #[test]
    fn ignores_told_to_leave() {
        assert_lint_count(
            "He was told to leave immediately.",
            AskNoPreposition::default(),
            0,
        );
    }

    #[test]
    fn ignores_tell_us() {
        assert_lint_count("Please tell us your name.", AskNoPreposition::default(), 0);
    }

    #[test]
    fn ignores_ask_about() {
        assert_lint_count(
            "They asked about the schedule.",
            AskNoPreposition::default(),
            0,
        );
    }
}



================================================
FILE: harper-core/src/linting/avoid_curses.rs
================================================
use crate::Token;
use crate::expr::{Expr, SequenceExpr};
use crate::linting::{LintKind, Suggestion};

use super::{ExprLinter, Lint};
use crate::linting::expr_linter::Chunk;

pub struct AvoidCurses {
    expr: Box<dyn Expr>,
}

impl Default for AvoidCurses {
    fn default() -> Self {
        Self {
            expr: Box::new(SequenceExpr::default().then_swear()),
        }
    }
}

impl ExprLinter for AvoidCurses {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, toks: &[Token], src: &[char]) -> Option<Lint> {
        if toks.len() != 1 {
            return None;
        }

        let tok = &toks[0];
        let span = tok.span;
        let bad_word_chars = span.get_content(src);
        let bad_word_str = span.get_content_string(src);
        let bad_word_norm = bad_word_str.to_lowercase();

        // Define offensive morphemes which are common parts of multiple words
        // Each entry maps a morpheme to an optional censored version.
        const MORPHEMES: &[(&str, Option<&str>)] = &[
            ("arse", None),
            ("ass", Some("a**")),
            ("cock", Some("c**k")),
            ("cunt", Some("c**t")),
            ("dick", Some("d**k")),
            ("fuck", Some("f**k")),
            ("piss", Some("p**s")),
            ("shit", Some("sh*t")),
            ("wank", Some("w**k")),
        ];

        // Define offensive words and their possible replacements
        const WORDS: &[(&str, &[&str])] = &[
            ("apeshit", &["crazy", "mad", "insane", "wild"]),
            (
                "arse",
                &["bum", "buttocks", "backside", "bottom", "rump", "posterior"],
            ),
            (
                "arses",
                &[
                    "bums",
                    "buttocks",
                    "backsides",
                    "bottoms",
                    "rumps",
                    "posteriors",
                ],
            ),
            ("arsed", &["bothered"]),
            ("arsehole", &["bumhole"]),
            (
                "ass",
                &[
                    "butt",
                    "buttocks",
                    "backside",
                    "bottom",
                    "rump",
                    "posterior",
                    "tuchus",
                    "tush",
                ],
            ),
            (
                "asses",
                &[
                    "butts",
                    "buttocks",
                    "backsides",
                    "bottoms",
                    "rumps",
                    "posteriors",
                    "tuchuses",
                    "tushes",
                ],
            ),
            ("asshole", &["butthole"]),
            // batshit
            // birdshit
            ("bullshit", &["bullcrap", "bulldust", "lie", "lies"]),
            ("bullshitted", &["bullcrapped", "lied"]),
            ("bullshitting", &["bullcrapping", "lying"]),
            ("bullshitter", &["liar"]),
            // bullshittery
            ("chickenshit", &["gutless", "cowardly"]),
            ("cock", &["pee-pee", "willy", "penis", "phallus", "member"]),
            (
                "cocks",
                &["pee-pees", "willies", "penises", "phalluses", "members"],
            ),
            // cocksucker
            ("cunt", &["vagina"]),
            ("cunts", &["vaginas"]),
            ("dick", &["pee-pee", "penis"]),
            ("dicks", &["pee-pees", "penises"]),
            ("dickhead", &["jerk", "idiot"]),
            ("dichheads", &["jerks", "idiots"]),
            // dipshit
            ("dumbass", &["idiot", "fool"]),
            ("dumbasses", &["idiots", "fools"]),
            ("fart", &["gas", "wind", "break wind"]),
            ("farts", &["gas", "wind", "breaks wind"]),
            ("farted", &["broke wind", "broken wind"]),
            ("farting", &["breaking wind"]),
            ("fuck", &["fudge", "screw", "damn", "hoot"]),
            ("fucks", &["screws"]),
            ("fucked", &["screwed"]),
            ("fucking", &["screwing"]),
            ("fucker", &["jerk"]),
            ("fuckers", &["jerks"]),
            // fuckhead
            ("horseshit", &["nonsense"]),
            // mindfuck
            // motherfucker
            // nigga
            // nigger
            ("piss", &["pee", "urine", "urinate"]),
            ("pisses", &["pees", "urinates"]),
            ("pissed", &["peed", "urinated"]),
            ("pissing", &["peeing", "urinating"]),
            ("pisser", &["toilet", "bathroom", "restroom", "washroom"]),
            // pissy
            (
                "shit",
                &["crap", "poo", "poop", "feces", "dung", "damn", "hoot"],
            ),
            ("shits", &["craps", "poos", "poops"]),
            ("shitted", &["crapped", "pooed", "pooped"]),
            ("shitting", &["crapping", "pooing", "pooping"]),
            // shitcoin
            // shitfaced
            // shitfest
            // shithead
            ("shitless", &["witless"]),
            (
                "shitload",
                &["crapload", "shedload", "shirtload", "load", "tons", "pile"],
            ),
            (
                "shitloads",
                &[
                    "craploads",
                    "shedloads",
                    "shirtloads",
                    "loads",
                    "tons",
                    "piles",
                ],
            ),
            // shitpost
            ("shitty", &["shirty", "crappy", "inferior"]),
            ("shittier", &["crappier", "shirtier"]),
            ("shittiest", &["crappiest", "shirtiest"]),
            ("tit", &["boob", "breast"]),
            ("tits", &["boobs", "breasts"]),
            ("titty", &["boob", "breast"]),
            ("titties", &["boobs", "breasts"]),
            ("turd", &["poo", "poop", "feces", "dung"]),
            ("turds", &["poos", "poops", "feces", "dung"]),
            ("twat", &["vagina"]),
            // wank
            ("wanker", &["jerk"]),
            // wanky
            ("whore", &["prostitute"]),
        ];

        // Replace common morphemes with both specific censored versions and all-asterisk versions
        let morpheme_replacements: Vec<String> = MORPHEMES
            .iter()
            .filter(|(m, _)| bad_word_norm.contains(m))
            .flat_map(|(m, censored)| {
                let mut replacements = Vec::new();

                // Add all-asterisk version for the censored morpheme only
                let asterisked = "*".repeat(m.len());
                let asterisked_word = bad_word_norm.replace(m, &asterisked);
                replacements.push(asterisked_word);

                // Add specific censored version if it exists
                if let Some(c) = censored {
                    let censored_word = bad_word_norm.replace(m, c);
                    replacements.push(censored_word);
                }

                replacements
            })
            .collect();

        // Find all replacement suggestions for the bad word
        let word_replacements: Vec<&str> = WORDS
            .iter()
            .filter(|(bad, _)| *bad == bad_word_norm)
            .flat_map(|(_, suggestions)| suggestions.iter().copied())
            .collect();

        if morpheme_replacements.is_empty() && word_replacements.is_empty() {
            return None;
        }

        let m_suggestions: Vec<Suggestion> = morpheme_replacements
            .into_iter()
            .map(|replacement| {
                Suggestion::replace_with_match_case(replacement.chars().collect(), bad_word_chars)
            })
            .collect();

        let w_suggestions: Vec<Suggestion> = word_replacements
            .into_iter()
            .map(|replacement| {
                Suggestion::replace_with_match_case(replacement.chars().collect(), bad_word_chars)
            })
            .collect();

        let suggestions = m_suggestions.into_iter().chain(w_suggestions).collect();

        Some(Lint {
            span,
            lint_kind: LintKind::WordChoice,
            suggestions,
            message: "Try to avoid offensive language.".to_string(),
            ..Default::default()
        })
    }

    fn description(&self) -> &'static str {
        "Flags offensive language and offers various ways to censor or replace with euphemisms."
    }
}

#[cfg(test)]
mod tests {
    use super::AvoidCurses;
    use crate::linting::tests::{assert_lint_count, assert_top3_suggestion_result};

    #[test]
    fn detects_shit() {
        assert_lint_count(
            "He ate shit when he fell off the bike.",
            AvoidCurses::default(),
            1,
        );
    }

    #[test]
    fn fix_shit() {
        assert_top3_suggestion_result("shit", AvoidCurses::default(), "crap")
    }

    #[test]
    fn fix_shit_titlecase() {
        assert_top3_suggestion_result("Shit", AvoidCurses::default(), "Crap")
    }

    #[test]
    fn fix_shit_allcaps() {
        assert_top3_suggestion_result("SHIT", AvoidCurses::default(), "CRAP")
    }

    #[test]
    fn fix_f_word_to_all_asterisks() {
        assert_top3_suggestion_result(
            "fuck those fucking fuckers",
            AvoidCurses::default(),
            "**** those ****ing ****ers",
        )
    }

    #[test]
    fn fix_shit_with_single_asterisk() {
        assert_top3_suggestion_result("shit", AvoidCurses::default(), "sh*t")
    }

    #[test]
    fn fix_shite_all_caps_with_single_asterisk() {
        assert_top3_suggestion_result("SHIT", AvoidCurses::default(), "SH*T")
    }
}



================================================
FILE: harper-core/src/linting/back_in_the_day.rs
================================================
use crate::expr::Expr;
use crate::expr::FixedPhrase;
use crate::expr::OwnedExprExt;
use crate::expr::SequenceExpr;
use crate::{
    Lrc, Token, TokenStringExt,
    patterns::{Pattern, WordSet},
};

use super::{ExprLinter, Lint, LintKind, Suggestion};
use crate::linting::expr_linter::Chunk;

pub struct BackInTheDay {
    expr: Box<dyn Expr>,
    // The trailing words that should tell us to ignore the rule.
    exceptions: Lrc<WordSet>,
}

impl Default for BackInTheDay {
    fn default() -> Self {
        let exceptions = Lrc::new(WordSet::new(&["before", "of", "when"]));
        let phrase = Lrc::new(FixedPhrase::from_phrase("back in the days"));

        let pattern = SequenceExpr::default()
            .then(phrase.clone())
            .then_whitespace()
            .then(exceptions.clone())
            .or_longest(phrase);

        Self {
            expr: Box::new(pattern),
            exceptions,
        }
    }
}

impl ExprLinter for BackInTheDay {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], source: &[char]) -> Option<Lint> {
        if let Some(tail) = matched_tokens.get(8..)
            && self.exceptions.matches(tail, source).is_some()
        {
            return None;
        }

        let span = matched_tokens.span()?;
        let chars = span.get_content(source);

        Some(Lint {
            span,
            lint_kind: LintKind::WordChoice,
            suggestions: vec![Suggestion::replace_with_match_case(
                "back in the day".chars().collect(),
                chars,
            )],
            message: "Use the more idiomatic version of this phrase.".to_owned(),
            priority: 127,
        })
    }

    fn description(&self) -> &'static str {
        "This linter flags instances of the nonstandard phrase `back in the days`. The correct, more accepted form is `back in the day`"
    }
}

#[cfg(test)]
mod tests {
    use super::BackInTheDay;
    use crate::linting::tests::{assert_lint_count, assert_suggestion_result};

    #[test]
    fn detects_gem_update_case() {
        assert_suggestion_result(
            "... has been resolved through a gem update back in the days",
            BackInTheDay::default(),
            "... has been resolved through a gem update back in the day",
        );
    }

    #[test]
    fn detects_install_case() {
        assert_suggestion_result(
            "Back in the days we're used to install it directly from ...",
            BackInTheDay::default(),
            "Back in the day we're used to install it directly from ...",
        );
    }

    #[test]
    fn detects_composer_json_case() {
        assert_suggestion_result(
            "Back in the days there was only composer.json and ...",
            BackInTheDay::default(),
            "Back in the day there was only composer.json and ...",
        );
    }

    #[test]
    fn detects_version_release_case() {
        assert_suggestion_result(
            "... should have been released back in the days in a version 11",
            BackInTheDay::default(),
            "... should have been released back in the day in a version 11",
        );
    }

    #[test]
    fn avoids_false_positive_springfox() {
        assert_lint_count(
            "Back in the days of SpringFox, there were several requests to ...",
            BackInTheDay::default(),
            0,
        );
    }

    #[test]
    fn avoids_false_positive_ie() {
        assert_lint_count(
            "Back in the days of IE, Powershell used to ...",
            BackInTheDay::default(),
            0,
        );
    }

    #[test]
    fn avoids_false_positive_code_usage() {
        assert_lint_count(
            "Back in the days when I had 100% of my code in ...",
            BackInTheDay::default(),
            0,
        );
    }
    #[test]
    fn catches_uppercase() {
        assert_lint_count(
            "Back in the days, we went for a walk.",
            BackInTheDay::default(),
            1,
        );
    }

    #[test]
    fn catches_lowercase() {
        assert_lint_count(
            "We used to go for walks back in the days.",
            BackInTheDay::default(),
            1,
        );
    }

    #[test]
    fn doesnt_catch_false_positive_of() {
        assert_lint_count(
            "Back in the days of CRTs, computers were expensive.",
            BackInTheDay::default(),
            0,
        );
    }

    #[test]
    fn doesnt_catch_false_positive_when() {
        assert_lint_count(
            "Back in the days when videogame arcades were popular.",
            BackInTheDay::default(),
            0,
        );
    }

    #[test]
    fn catches_comma_when() {
        assert_lint_count(
            "Back in the days, when we were children, we played outside.",
            BackInTheDay::default(),
            1,
        );
    }

    #[test]
    fn doesnt_catch_false_positive_before() {
        assert_lint_count(
            "Back in the days before laptops we had \"luggables\".",
            BackInTheDay::default(),
            0,
        );
    }

    #[test]
    fn catches_comma_before() {
        assert_lint_count(
            "Back in the days, before laptops.",
            BackInTheDay::default(),
            1,
        );
    }

    #[test]
    fn doesnt_catch_qualified_days() {
        assert_lint_count(
            "Back in the old days we did this by hand.",
            BackInTheDay::default(),
            0,
        );
    }
}



================================================
FILE: harper-core/src/linting/be_allowed.rs
================================================
use std::sync::Arc;

use crate::linting::expr_linter::Chunk;
use crate::{
    Token,
    expr::{Expr, ExprMap, SequenceExpr},
    linting::{ExprLinter, Lint, LintKind, Suggestion},
};

pub struct BeAllowed {
    expr: Box<dyn Expr>,
    map: Arc<ExprMap<usize>>,
}

impl Default for BeAllowed {
    fn default() -> Self {
        let mut map = ExprMap::default();

        map.insert(
            SequenceExpr::default()
                .t_aco("will")
                .t_ws()
                .then_word_set(&["not"])
                .t_ws()
                .t_aco("allowed")
                .t_ws()
                .t_aco("to")
                .t_ws()
                .then_verb(),
            4,
        );

        map.insert(
            SequenceExpr::default()
                .t_aco("won't")
                .t_ws()
                .t_aco("allowed")
                .t_ws()
                .t_aco("to")
                .t_ws()
                .then_verb(),
            2,
        );

        let map = Arc::new(map);

        Self {
            expr: Box::new(map.clone()),
            map,
        }
    }
}

impl ExprLinter for BeAllowed {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], source: &[char]) -> Option<Lint> {
        let allowed_index = *self.map.lookup(0, matched_tokens, source)?;
        let allowed_token = matched_tokens.get(allowed_index)?;
        let span = allowed_token.span;
        let template = span.get_content(source);

        Some(Lint {
            span,
            lint_kind: LintKind::Grammar,
            suggestions: vec![Suggestion::replace_with_match_case(
                "be allowed".chars().collect(),
                template,
            )],
            message: "Add `be` so this reads `be allowed`.".to_owned(),
            priority: 31,
        })
    }

    fn description(&self) -> &'static str {
        "Ensures the passive form uses `be allowed` after future negatives."
    }
}

#[cfg(test)]
mod tests {
    use crate::linting::tests::{assert_lint_count, assert_suggestion_result};

    use super::BeAllowed;

    #[test]
    fn corrects_basic_sentence() {
        assert_suggestion_result(
            "You will not allowed to enter the lab.",
            BeAllowed::default(),
            "You will not be allowed to enter the lab.",
        );
    }

    #[test]
    fn corrects_first_person_subject() {
        assert_suggestion_result(
            "I will not allowed to go tonight.",
            BeAllowed::default(),
            "I will not be allowed to go tonight.",
        );
    }

    #[test]
    fn corrects_plural_subject() {
        assert_suggestion_result(
            "Students will not allowed to submit late work.",
            BeAllowed::default(),
            "Students will not be allowed to submit late work.",
        );
    }

    #[test]
    fn corrects_with_intro_clause() {
        assert_suggestion_result(
            "Because of policy, workers will not allowed to take photos.",
            BeAllowed::default(),
            "Because of policy, workers will not be allowed to take photos.",
        );
    }

    #[test]
    fn corrects_contracted_form() {
        assert_suggestion_result(
            "They won't allowed to park here during events.",
            BeAllowed::default(),
            "They won't be allowed to park here during events.",
        );
    }

    #[test]
    fn corrects_all_caps() {
        assert_suggestion_result(
            "THEY WILL NOT ALLOWED TO ENTER.",
            BeAllowed::default(),
            "THEY WILL NOT BE ALLOWED TO ENTER.",
        );
    }

    #[test]
    fn corrects_with_trailing_clause() {
        assert_suggestion_result(
            "Without a permit, guests will not allowed to stay overnight at the cabin.",
            BeAllowed::default(),
            "Without a permit, guests will not be allowed to stay overnight at the cabin.",
        );
    }

    #[test]
    fn corrects_with_modal_context() {
        assert_suggestion_result(
            "Even with approval, contractors will not allowed to access production.",
            BeAllowed::default(),
            "Even with approval, contractors will not be allowed to access production.",
        );
    }

    #[test]
    fn leaves_correct_phrase_untouched() {
        assert_suggestion_result(
            "They will not be allowed to park here during events.",
            BeAllowed::default(),
            "They will not be allowed to park here during events.",
        );
    }

    #[test]
    fn leaves_other_verbs_alone() {
        assert_lint_count(
            "We will not allow visitors after nine.",
            BeAllowed::default(),
            0,
        );
    }

    #[test]
    fn leaves_similar_sequence_without_to() {
        assert_lint_count(
            "They won't be allowed to park here during events.",
            BeAllowed::default(),
            0,
        );
    }
}



================================================
FILE: harper-core/src/linting/behind_the_scenes.rs
================================================
use crate::{
    Lint, Token,
    expr::{Expr, SequenceExpr},
    linting::{ExprLinter, LintKind, Suggestion, expr_linter::Chunk},
};

pub struct BehindTheScenes {
    expr: Box<dyn Expr>,
}

impl Default for BehindTheScenes {
    fn default() -> Self {
        Self {
            expr: Box::new(
                SequenceExpr::aco("behind")
                    .t_ws_h()
                    .t_aco("the")
                    .t_ws_h()
                    .t_aco("scene"),
            ),
        }
    }
}

impl ExprLinter for BehindTheScenes {
    type Unit = Chunk;

    fn description(&self) -> &str {
        "Corrects `behind the scene` to `behind the scenes`."
    }

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint_with_context(
        &self,
        toks: &[Token],
        src: &[char],
        ctx: Option<(&[Token], &[Token])>,
    ) -> Option<Lint> {
        if let Some((before, _)) = ctx
            && before.last().is_some_and(|t| t.kind.is_hyphen())
        {
            return None;
        }

        let span = toks.last()?.span;
        Some(Lint {
            span,
            lint_kind: LintKind::Usage,
            suggestions: [Suggestion::replace_with_match_case_str(
                "scenes",
                span.get_content(src),
            )]
            .to_vec(),
            message: "This idiom uses the plural `scenes`.".to_string(),
            ..Default::default()
        })
    }
}

#[cfg(test)]
mod tests {
    use crate::linting::{
        behind_the_scenes::BehindTheScenes,
        tests::{assert_no_lints, assert_suggestion_result},
    };

    #[test]
    fn pluralize_work_bts() {
        assert_suggestion_result(
            "How does this tool work behind the scene.",
            BehindTheScenes::default(),
            "How does this tool work behind the scenes.",
        );
    }

    #[test]
    #[ignore = "Correcting hyphenation is not yet implemented."]
    fn pluralize_and_hyphenate() {
        assert_suggestion_result(
            "So, to open the 'real' behind the scene menu i need to do these steps:",
            BehindTheScenes::default(),
            "So, to open the 'real' behind-the-scenes menu i need to do these steps:",
        );
    }

    #[test]
    fn dont_flag_when_hyphenated_to_previous_word() {
        assert_no_lints(
            "Contribute to techking11/react-behind-the-scene development by creating an account on GitHub.",
            BehindTheScenes::default(),
        );
    }

    #[test]
    fn pluralize_bts_processing() {
        assert_suggestion_result(
            "Behind-the-scene processing details are printed in the Log window.",
            BehindTheScenes::default(),
            "Behind-the-scenes processing details are printed in the Log window.",
        );
    }
}



================================================
FILE: harper-core/src/linting/best_of_all_time.rs
================================================
use crate::Token;
use crate::expr::{Expr, Repeating, SequenceExpr};
use crate::linting::{ExprLinter, Lint, LintKind, Suggestion, expr_linter::Sentence};

pub struct BestOfAllTime {
    expr: Box<dyn Expr>,
}

impl Default for BestOfAllTime {
    fn default() -> Self {
        // Best, Biggest
        let inflection_superlative = SequenceExpr::default().then_superlative_adjective();
        // Most interesting
        let most_superlative = SequenceExpr::default()
            .t_aco("most")
            .t_ws()
            .then_positive_adjective();
        // Some resources call 'favourite' an 'absolute adjective', some consider it a superlative.
        let fave_or_top = SequenceExpr::word_set(&["favorite", "favourite", "top"]);

        // We can't use the noun phrase Expr because it allows determiners before the nouns and "best the thing" wouldn't be right
        let expr = SequenceExpr::default()
            .then_any_of(vec![
                Box::new(inflection_superlative),
                Box::new(most_superlative),
                Box::new(fave_or_top),
            ])
            // There is no non-greedy `Repeating` in Harper, so we have to do match non-noun-oov tokens
            // rather than matching arbitrary tokens.
            // We include OOV because novel words not in the dictionary tend to be nouns.
            .then(Repeating::new(
                Box::new(|tok: &Token, _: &[char]| !tok.kind.is_noun() && !tok.kind.is_oov()),
                0,
            ))
            .then_kind_where(|kind| kind.is_noun() || kind.is_oov())
            .then(Repeating::new(
                Box::new(
                    SequenceExpr::default()
                        .t_ws()
                        .then_kind_where(|kind| kind.is_noun() || kind.is_oov()),
                ),
                0,
            ))
            .then_fixed_phrase(" of all times");

        Self {
            expr: Box::new(expr),
        }
    }
}

impl ExprLinter for BestOfAllTime {
    type Unit = Sentence;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, toks: &[Token], src: &[char]) -> Option<Lint> {
        let times_span = toks.last()?.span;

        if let Some((_, time_singular)) = times_span.get_content(src).split_last() {
            return Some(Lint {
                span: times_span,
                lint_kind: LintKind::WordChoice,
                suggestions: vec![Suggestion::ReplaceWith(time_singular.to_vec())],
                message: "This expression uses singular `time`".to_string(),
                ..Default::default()
            });
        }

        None
    }

    fn description(&self) -> &'static str {
        "Checks for nonstandard `of all times` in superlatives instead of singular `time`"
    }
}

#[cfg(test)]
mod tests {
    use crate::linting::tests::{assert_lint_count, assert_suggestion_result};

    use super::BestOfAllTime;

    #[test]
    fn dont_flag_list_of_all_times() {
        assert_lint_count(
            "Provides a formatted list of all times that SDO was non-nominal",
            BestOfAllTime::default(),
            0,
        );
    }

    #[test]
    fn fix_after_best() {
        assert_suggestion_result(
            "And also in the best IDE of all times Visual Studio",
            BestOfAllTime::default(),
            "And also in the best IDE of all time Visual Studio",
        );
    }

    #[test]
    fn fix_after_greatest() {
        assert_suggestion_result(
            "This app shows you why Sachin Tendulkar is the greatest cricket of all times, by using interactive stories.",
            BestOfAllTime::default(),
            "This app shows you why Sachin Tendulkar is the greatest cricket of all time, by using interactive stories.",
        );
    }

    #[test]
    fn fix_after_biggest() {
        assert_suggestion_result(
            "THIS IS THE BIGGEST QUESTIONS OF ALL TIMES...",
            BestOfAllTime::default(),
            "THIS IS THE BIGGEST QUESTIONS OF ALL TIME...",
        );
    }

    #[test]
    fn fix_after_most_influential() {
        assert_suggestion_result(
            "It is an open source project that aggregates multiple lists of \"the best/most influential games of all times\"",
            BestOfAllTime::default(),
            "It is an open source project that aggregates multiple lists of \"the best/most influential games of all time\"",
        );
    }

    #[test]
    fn dont_flag_sum_of_all_times() {
        assert_lint_count(
            "The original TotalTime seems not be the sum of all times",
            BestOfAllTime::default(),
            0,
        );
    }

    #[test]
    fn dont_flag_history_stacks_of_all_times() {
        assert_lint_count(
            "Didn't this imply all history stacks of all times, which itself implied all those saved.",
            BestOfAllTime::default(),
            0,
        );
    }

    #[test]
    fn fix_after_favorite() {
        assert_suggestion_result(
            "Red Dead Redemption 2 is my nr 1 favorite game of all times",
            BestOfAllTime::default(),
            "Red Dead Redemption 2 is my nr 1 favorite game of all time",
        );
    }

    #[test]
    fn fix_after_favourite() {
        assert_suggestion_result(
            "Just made this website to show you my favourite movies of all times.",
            BestOfAllTime::default(),
            "Just made this website to show you my favourite movies of all time.",
        );
    }

    #[test]
    fn fix_top_out_of_vocabulary() {
        assert_suggestion_result(
            "Can I Play the Top 10 Basslines of All Times?",
            BestOfAllTime::default(),
            "Can I Play the Top 10 Basslines of All Time?",
        );
    }

    #[test]
    fn fix_compound_noun() {
        assert_suggestion_result(
            "Is he the best bass guitarist of all times?",
            BestOfAllTime::default(),
            "Is he the best bass guitarist of all time?",
        );
    }

    #[test]
    fn fix_containing_commas() {
        assert_suggestion_result(
            "I am the biggest, best, and most humble of all times",
            BestOfAllTime::default(),
            "I am the biggest, best, and most humble of all time",
        );
    }
}



================================================
FILE: harper-core/src/linting/boring_words.rs
================================================
use itertools::Itertools;

use crate::expr::{Expr, WordExprGroup};
use crate::thesaurus_helper;
use crate::{Token, TokenStringExt};

use super::{ExprLinter, Lint, LintKind};
use crate::linting::expr_linter::Chunk;

pub struct BoringWords {
    expr: Box<dyn Expr>,
}

impl Default for BoringWords {
    fn default() -> Self {
        let mut expr = WordExprGroup::default();

        expr.add_word("very");
        expr.add_word("interesting");
        expr.add_word("several");
        expr.add_word("most");
        expr.add_word("many");

        Self {
            expr: Box::new(expr),
        }
    }
}

impl ExprLinter for BoringWords {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], source: &[char]) -> Option<Lint> {
        let matched_word = matched_tokens.span()?.get_content_string(source);

        Some(Lint {
            span: matched_tokens.span()?,
            lint_kind: LintKind::Enhancement,
            suggestions: thesaurus_helper::get_synonym_replacement_suggestions(
                &matched_word,
                &matched_tokens[0].kind,
            )
            .take(5)
            .collect_vec(),
            message: format!(
                "“{matched_word}” is a boring word. Try something a little more exotic."
            ),
            priority: 127,
        })
    }

    fn description(&self) -> &'static str {
        "This rule looks for particularly boring or overused words. Using varied language is an easy way to keep a reader's attention."
    }
}



================================================
FILE: harper-core/src/linting/bought.rs
================================================
use super::{ExprLinter, Lint, LintKind};
use crate::Token;
use crate::expr::{Expr, SequenceExpr};
use crate::linting::Suggestion;
use crate::linting::expr_linter::Chunk;

pub struct Bought {
    expr: Box<dyn Expr>,
}

impl Default for Bought {
    fn default() -> Self {
        let subject = SequenceExpr::default()
            .then(Self::is_subject_pronoun_like)
            .t_ws()
            .then_optional(SequenceExpr::default().then_adverb().t_ws())
            .then_optional(SequenceExpr::default().then_auxiliary_verb().t_ws())
            .then_optional(SequenceExpr::default().then_adverb().t_ws())
            .then_any_capitalization_of("bough");

        Self {
            expr: Box::new(subject),
        }
    }
}

impl ExprLinter for Bought {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], source: &[char]) -> Option<Lint> {
        let typo = matched_tokens.last()?;

        Some(Lint {
            span: typo.span,
            lint_kind: LintKind::WordChoice,
            suggestions: vec![Suggestion::replace_with_match_case(
                "bought".chars().collect(),
                typo.span.get_content(source),
            )],
            message: "Prefer the past-tense form `bought` here.".to_owned(),
            priority: 31,
        })
    }

    fn description(&self) -> &'static str {
        "Replaces the incorrect past-tense spelling `bough` with `bought` after subject pronouns."
    }
}

impl Bought {
    fn is_subject_pronoun_like(token: &Token, source: &[char]) -> bool {
        if token.kind.is_subject_pronoun() {
            return true;
        }

        if !token.kind.is_word() || !token.kind.is_apostrophized() {
            return false;
        }

        let text = token.span.get_content_string(source);
        let lower = text.to_ascii_lowercase();

        let Some((stem, suffix)) = lower.split_once('\'') else {
            return false;
        };

        let is_subject_stem = matches!(stem, "i" | "you" | "we" | "they" | "he" | "she" | "it");
        let is_supported_suffix = matches!(suffix, "d" | "ve");

        is_subject_stem && is_supported_suffix
    }
}

#[cfg(test)]
mod tests {
    use super::Bought;
    use crate::linting::tests::{assert_no_lints, assert_suggestion_result};

    #[test]
    fn corrects_he_bough() {
        assert_suggestion_result(
            "He bough a laptop yesterday.",
            Bought::default(),
            "He bought a laptop yesterday.",
        );
    }

    #[test]
    fn corrects_she_never_bough() {
        assert_suggestion_result(
            "She never bough fresh herbs there.",
            Bought::default(),
            "She never bought fresh herbs there.",
        );
    }

    #[test]
    fn corrects_they_already_bough() {
        assert_suggestion_result(
            "They already bough the train tickets.",
            Bought::default(),
            "They already bought the train tickets.",
        );
    }

    #[test]
    fn corrects_we_have_bough() {
        assert_suggestion_result(
            "We have bough extra paint.",
            Bought::default(),
            "We have bought extra paint.",
        );
    }

    #[test]
    fn corrects_they_have_never_bough() {
        assert_suggestion_result(
            "They have never bough theatre seats online.",
            Bought::default(),
            "They have never bought theatre seats online.",
        );
    }

    #[test]
    fn corrects_ive_bough() {
        assert_suggestion_result(
            "I've bough the ingredients already.",
            Bought::default(),
            "I've bought the ingredients already.",
        );
    }

    #[test]
    fn corrects_wed_bough() {
        assert_suggestion_result(
            "We'd bough snacks before the film.",
            Bought::default(),
            "We'd bought snacks before the film.",
        );
    }

    #[test]
    fn no_lint_for_tree_bough() {
        assert_no_lints("The heavy bough cracked under the snow.", Bought::default());
    }

    #[test]
    fn no_lint_for_he_bought() {
        assert_no_lints("He bought a laptop yesterday.", Bought::default());
    }

    #[test]
    fn no_lint_for_plural_boughs() {
        assert_no_lints("Boughs swayed in the evening breeze.", Bought::default());
    }
}



================================================
FILE: harper-core/src/linting/brand_brandish.rs
================================================
use crate::{
    Lint, Token, TokenKind,
    expr::{Expr, SequenceExpr},
    linting::{ExprLinter, LintKind, Suggestion, expr_linter::Chunk},
};

pub struct BrandBrandish {
    expr: Box<dyn Expr>,
}

impl Default for BrandBrandish {
    fn default() -> Self {
        Self {
            expr: Box::new(
                SequenceExpr::word_set(&["brandish", "brandished", "brandishes", "brandishing"])
                    .t_ws()
                    // "her" is also a possessive determiner as in "she brandished her sword"
                    // "it" and "them" can refer to objects as in "draw your sword(s) and brandish it/them"
                    .then_kind_except(TokenKind::is_object_pronoun, &["her", "it", "them"]),
            ),
        }
    }
}

impl ExprLinter for BrandBrandish {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, toks: &[Token], src: &[char]) -> Option<Lint> {
        let verb_span = toks.first()?.span;
        let verb_chars = verb_span.get_content(src);

        enum Form {
            Base,
            Past,
            ThirdPerson,
            Ing,
        }

        let infl = match verb_chars.last().map(|c| c.to_ascii_lowercase()) {
            Some('h') => Form::Base,
            Some('d') => Form::Past,
            Some('s') => Form::ThirdPerson,
            Some('g') => Form::Ing,
            _ => return None,
        };

        Some(Lint {
            span: verb_span,
            lint_kind: LintKind::Malapropism,
            suggestions: vec![Suggestion::replace_with_match_case_str(
                match infl {
                    Form::Base => "brand",
                    Form::Past => "branded",
                    Form::ThirdPerson => "brands",
                    Form::Ing => "branding",
                },
                verb_chars,
            )],
            message: "`Brandish` means to wield a weapon. You probably mean `brand`.".to_string(),
            ..Default::default()
        })
    }

    fn description(&self) -> &str {
        "Looks for `brandish` wrongly used when `brand` is intended."
    }
}

#[cfg(test)]
mod tests {
    use crate::linting::{brand_brandish::BrandBrandish, tests::assert_suggestion_result};

    #[test]
    fn correct_brandish_a_traitor() {
        assert_suggestion_result(
            "Unretire Gretzky's sweater . Brandish him a traitor.",
            BrandBrandish::default(),
            "Unretire Gretzky's sweater . Brand him a traitor.",
        );
    }

    #[test]
    fn correct_brandish_a_criminal() {
        assert_suggestion_result(
            "lied to stop kuma's ideology from taking root and to brandish him a criminal that they could arrest",
            BrandBrandish::default(),
            "lied to stop kuma's ideology from taking root and to brand him a criminal that they could arrest",
        );
    }

    #[test]
    fn correct_brandish_as_a() {
        assert_suggestion_result(
            "he was so afraid his thoughts could brandish him as a paedophile",
            BrandBrandish::default(),
            "he was so afraid his thoughts could brand him as a paedophile",
        );
    }

    #[test]
    fn correct_brandish_an_offender() {
        assert_suggestion_result(
            "Chanel Oberlin's reason for purposely leading on Pete Martinez in order to humiliate him and brandish him a registered sex offender",
            BrandBrandish::default(),
            "Chanel Oberlin's reason for purposely leading on Pete Martinez in order to humiliate him and brand him a registered sex offender",
        );
    }

    #[test]
    fn correct_brandish_with_nicknames() {
        assert_suggestion_result(
            "?? spoke out over the move by Kenyans to continuously brandish him with nicknames even after ...",
            BrandBrandish::default(),
            "?? spoke out over the move by Kenyans to continuously brand him with nicknames even after ...",
        );
    }

    #[test]
    fn correct_brandish_as_a_aymbol() {
        assert_suggestion_result(
            "brandish him as an acclaimed symbol of humility, integrity and incorruptibility in the face of today's corrupt economic and political elite1",
            BrandBrandish::default(),
            "brand him as an acclaimed symbol of humility, integrity and incorruptibility in the face of today's corrupt economic and political elite1",
        );
    }

    #[test]
    fn correct_brandish_as_illegal() {
        assert_suggestion_result(
            "To attempt to brandish him as an “illegal immigrant” is absolutely ridiculous and warrants an immediate retraction and apology.",
            BrandBrandish::default(),
            "To attempt to brand him as an “illegal immigrant” is absolutely ridiculous and warrants an immediate retraction and apology.",
        );
    }

    #[test]
    fn correct_brandish_with_nickname() {
        assert_suggestion_result(
            "The small minded townsfolk brandish him with the nickname \"Genepool\" due to his physical and cognitive shortcomings.",
            BrandBrandish::default(),
            "The small minded townsfolk brand him with the nickname \"Genepool\" due to his physical and cognitive shortcomings.",
        );
    }

    #[test]
    fn correct_brandish_with_label() {
        assert_suggestion_result(
            "One such reason that critics brandish him with this label is due to Peterson's opposition to Canada's Bill C-16",
            BrandBrandish::default(),
            "One such reason that critics brand him with this label is due to Peterson's opposition to Canada's Bill C-16",
        );
    }

    #[test]
    fn correct_brandished_us() {
        assert_suggestion_result(
            "The mark they brandished us with will fade to dust when we finally meet our end.",
            BrandBrandish::default(),
            "The mark they branded us with will fade to dust when we finally meet our end.",
        )
    }

    #[test]
    fn correct_brandishing_him() {
        assert_suggestion_result(
            "he said some words trying to hit back at the center for brandishing him as a Pakistani at an NRC rally",
            BrandBrandish::default(),
            "he said some words trying to hit back at the center for branding him as a Pakistani at an NRC rally",
        )
    }

    #[test]
    fn correct_brandish_us() {
        assert_suggestion_result(
            "Our resolute determination for the ultimate quality and all-inclusive directory of food commodities brandish us as a flawless associate in B2B",
            BrandBrandish::default(),
            "Our resolute determination for the ultimate quality and all-inclusive directory of food commodities brand us as a flawless associate in B2B",
        )
    }

    #[test]
    fn correct_brandished_him() {
        assert_suggestion_result(
            "Frank discovers Myra brandished him with the letter 'R', for rapist.",
            BrandBrandish::default(),
            "Frank discovers Myra branded him with the letter 'R', for rapist.",
        )
    }

    #[test]
    fn correct_brandishes_him() {
        assert_suggestion_result(
            "Whether one turns a blind eye to Tim's wrongs or brandishes him a traitor will plant audiences in their own personal line in the sand.",
            BrandBrandish::default(),
            "Whether one turns a blind eye to Tim's wrongs or brands him a traitor will plant audiences in their own personal line in the sand.",
        )
    }
}



================================================
FILE: harper-core/src/linting/call_them.rs
================================================
use std::{ops::Range, sync::Arc};

use crate::expr::{Expr, ExprMap, SequenceExpr};
use crate::patterns::{DerivedFrom, WordSet};
use crate::{Token, TokenStringExt};

use super::{ExprLinter, Lint, LintKind, Suggestion};
use crate::linting::expr_linter::Chunk;

pub struct CallThem {
    expr: Box<dyn Expr>,
    map: Arc<ExprMap<Range<usize>>>,
}

impl Default for CallThem {
    fn default() -> Self {
        let mut map = ExprMap::default();

        let post_exception = Arc::new(
            SequenceExpr::default()
                .t_ws()
                .then(WordSet::new(&["if", "it"])),
        );

        map.insert(
            SequenceExpr::default()
                .then(DerivedFrom::new_from_str("call"))
                .t_ws()
                .then_pronoun()
                .t_ws()
                .t_aco("as")
                .then_unless(post_exception.clone()),
            3..5,
        );

        map.insert(
            SequenceExpr::default()
                .then(DerivedFrom::new_from_str("call"))
                .t_ws()
                .t_aco("as")
                .t_ws()
                .then_pronoun()
                .then_unless(post_exception.clone()),
            1..3,
        );

        let map = Arc::new(map);

        Self {
            expr: Box::new(map.clone()),
            map,
        }
    }
}

impl ExprLinter for CallThem {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], source: &[char]) -> Option<Lint> {
        let removal_range = self.map.lookup(0, matched_tokens, source)?.clone();
        let offending_tokens = matched_tokens.get(removal_range)?;

        Some(Lint {
            span: offending_tokens.span()?,
            lint_kind: LintKind::Redundancy,
            suggestions: vec![Suggestion::Remove],
            message: "`as` is redundant in this context.".to_owned(),
            ..Default::default()
        })
    }

    fn description(&self) -> &'static str {
        "Addresses the non-idiomatic phrases `call them as`."
    }
}

#[cfg(test)]
mod tests {
    #[allow(unused_imports)]
    use crate::Document;
    use crate::linting::tests::{assert_no_lints, assert_suggestion_result};

    use super::CallThem;

    #[test]
    fn prefer_plug_and_receptacle() {
        assert_suggestion_result(
            r#"I prefer to call them as Plug (male) and Receptacle (female). Receptacles are seen in laptops, mobile phones etc.."#,
            CallThem::default(),
            r#"I prefer to call them Plug (male) and Receptacle (female). Receptacles are seen in laptops, mobile phones etc.."#,
        );
    }

    #[test]
    fn builtins_id() {
        assert_suggestion_result(
            r#"I’d categorically ignore *id* as a builtin, and when you do need it in a module, make it super explicit and `import builtins` and call it as `builtins.id`."#,
            CallThem::default(),
            r#"I’d categorically ignore *id* as a builtin, and when you do need it in a module, make it super explicit and `import builtins` and call it `builtins.id`."#,
        );
    }

    #[test]
    fn non_modal_dialogue() {
        assert_suggestion_result(
            r#"We usually call it as non-modal dialogue e.g. when hit Gmail compose button, a nonmodal dialogue opens."#,
            CallThem::default(),
            r#"We usually call it non-modal dialogue e.g. when hit Gmail compose button, a nonmodal dialogue opens."#,
        );
    }

    #[test]
    fn prefer_to_call_them() {
        assert_suggestion_result(
            r#"So, how do you typically prefer to call them as?"#,
            CallThem::default(),
            r#"So, how do you typically prefer to call them?"#,
        );
    }

    #[test]
    fn called_them_allies() {
        assert_suggestion_result(
            r#"Yes as tribes or nomads you called them as allies but you didn’t get their levies as your own."#,
            CallThem::default(),
            r#"Yes as tribes or nomads you called them allies but you didn’t get their levies as your own."#,
        );
    }

    #[test]
    fn character_development() {
        assert_suggestion_result(
            r#"I call this as character development."#,
            CallThem::default(),
            r#"I call this character development."#,
        );
    }

    #[test]
    fn fate_or_time() {
        assert_suggestion_result(
            r#"Should I Call It As Fate Or Time"#,
            CallThem::default(),
            r#"Should I Call It Fate Or Time"#,
        );
    }

    #[test]
    fn abstract_latte_art() {
        assert_suggestion_result(
            r#"Can we just call it as abstract latte art."#,
            CallThem::default(),
            r#"Can we just call it abstract latte art."#,
        );
    }

    #[test]
    fn sounding_boards() {
        assert_suggestion_result(
            r#"I call them as my ‘sounding boards’"#,
            CallThem::default(),
            r#"I call them my ‘sounding boards’"#,
        );
    }

    #[test]
    fn calling_them_disaster() {
        assert_suggestion_result(
            r#"I totally disagree with your point listed and calling them as disaster."#,
            CallThem::default(),
            r#"I totally disagree with your point listed and calling them disaster."#,
        );
    }

    #[test]
    fn battle_of_boxes() {
        assert_suggestion_result(
            r#"Windows Sandbox and VirtualBox or I would like to call this as “Battle of Boxes.”"#,
            CallThem::default(),
            r#"Windows Sandbox and VirtualBox or I would like to call this “Battle of Boxes.”"#,
        );
    }

    #[test]
    fn called_her_shinnasan() {
        assert_suggestion_result(
            r#"Nice meeting a follower from reddit I called her as Shinna-san, welcome again to Toram!!"#,
            CallThem::default(),
            r#"Nice meeting a follower from reddit I called her Shinna-san, welcome again to Toram!!"#,
        );
    }

    #[test]
    fn calling_it_otp() {
        assert_suggestion_result(
            r#"Calling it as OTP in this case misleading"#,
            CallThem::default(),
            r#"Calling it OTP in this case misleading"#,
        );
    }

    #[test]
    fn call_it_procrastination() {
        assert_suggestion_result(
            r#"To summarise it in just one word I would call it as procrastination."#,
            CallThem::default(),
            r#"To summarise it in just one word I would call it procrastination."#,
        );
    }

    #[test]
    fn call_her_important() {
        assert_suggestion_result(
            r#"Liked the article overall but to call her as important to rap as Jay or Dre is a bold overstatement."#,
            CallThem::default(),
            r#"Liked the article overall but to call her important to rap as Jay or Dre is a bold overstatement."#,
        );
    }

    #[test]
    fn call_him_kindles() {
        assert_suggestion_result(
            r#"The days when I had my first best friend, I would rather call him as human version of kindle audiobook, who keeps on talking about everything under the umbrella."#,
            CallThem::default(),
            r#"The days when I had my first best friend, I would rather call him human version of kindle audiobook, who keeps on talking about everything under the umbrella."#,
        );
    }

    #[test]
    fn call_them_defenders() {
        assert_suggestion_result(
            r#"Declaring war challenging land of a vassal should call them as defenders!"#,
            CallThem::default(),
            r#"Declaring war challenging land of a vassal should call them defenders!"#,
        );
    }

    #[test]
    fn call_it_magical() {
        assert_suggestion_result(
            r#"I would like to call it as magical."#,
            CallThem::default(),
            r#"I would like to call it magical."#,
        );
    }

    #[test]
    fn forward_lateral() {
        assert_suggestion_result(
            r#"Surprised the refs didn’t call this as a forward lateral."#,
            CallThem::default(),
            r#"Surprised the refs didn’t call this a forward lateral."#,
        );
    }

    #[test]
    fn calling_best_friend() {
        assert_suggestion_result(
            r#"Meet my buddy! I love calling him as my best friend, because he never failed to bring some cheer in me!"#,
            CallThem::default(),
            r#"Meet my buddy! I love calling him my best friend, because he never failed to bring some cheer in me!"#,
        );
    }

    #[test]
    fn calling_everyone_titles() {
        assert_suggestion_result(
            r#"Currently, I’m teaching in Asia and the students have the local custom of calling everyone as Mr. Givenname or Miss Givenname"#,
            CallThem::default(),
            r#"Currently, I’m teaching in Asia and the students have the local custom of calling everyone Mr. Givenname or Miss Givenname"#,
        );
    }

    #[test]
    fn called_as_he() {
        assert_suggestion_result(
            r#"I prefer to be called as he when referred in 3rd person and I’m sure that everyone would be ok to call me as he."#,
            CallThem::default(),
            r#"I prefer to be called he when referred in 3rd person and I’m sure that everyone would be ok to call me he."#,
        );
    }

    #[test]
    fn calls_him_bob() {
        assert_suggestion_result(
            r#"In Twelve Monkeys, Cole hears someone who calls him as “Bob”"#,
            CallThem::default(),
            r#"In Twelve Monkeys, Cole hears someone who calls him “Bob”"#,
        );
    }

    #[test]
    fn pliny_called_it() {
        assert_suggestion_result(
            r#"Pliny the Elder called it as lake of Gennesaret or Taricheae in his encyclopedia, Natural History."#,
            CallThem::default(),
            r#"Pliny the Elder called it lake of Gennesaret or Taricheae in his encyclopedia, Natural History."#,
        );
    }

    #[test]
    fn students_call_you() {
        assert_suggestion_result(
            r#"In the same way your students will call you as ~先生 even after they graduated/move to higher education."#,
            CallThem::default(),
            r#"In the same way your students will call you ~先生 even after they graduated/move to higher education."#,
        );
    }

    #[test]
    fn paradoxical_reaction() {
        assert_suggestion_result(
            r#"We can call it as Paradoxical Reaction which means a medicine which is used to reduce pain increases the pain when it is"#,
            CallThem::default(),
            r#"We can call it Paradoxical Reaction which means a medicine which is used to reduce pain increases the pain when it is"#,
        );
    }

    #[test]
    fn rust_module() {
        assert_no_lints(
            "I want to call them as if they were just another Rust module",
            CallThem::default(),
        );
    }

    #[test]
    fn want_to_do() {
        assert_no_lints(
            "however its a design choice to not call it as it does things I don't want to do.",
            CallThem::default(),
        );
    }
}



================================================
FILE: harper-core/src/linting/cant.rs
================================================
use super::{ExprLinter, Suggestion};
use crate::Lint;
use crate::expr::{Expr, LongestMatchOf, SequenceExpr};
use crate::linting::LintKind;
use crate::linting::expr_linter::Chunk;
use crate::linting::expr_linter::find_the_only_token_matching;
use crate::{CharStringExt, Token};

pub struct Cant {
    expr: Box<dyn Expr>,
}

impl Default for Cant {
    fn default() -> Self {
        let nom_cant = SequenceExpr::default()
            .then_kind_except(|kind| kind.is_nominal(), &["or"])
            .t_ws()
            .t_aco("cant");
        let cant_pron = SequenceExpr::aco("cant").t_ws().then_personal_pronoun();
        let cant_verb = SequenceExpr::aco("cant")
            .t_ws()
            .then_kind_is_but_is_not(|kind| kind.is_verb_lemma(), |kind| kind.is_noun());

        Self {
            expr: Box::new(LongestMatchOf::new(vec![
                Box::new(nom_cant),
                Box::new(cant_pron),
                Box::new(cant_verb),
            ])),
        }
    }
}

impl ExprLinter for Cant {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, toks: &[Token], src: &[char]) -> Option<Lint> {
        let token = find_the_only_token_matching(toks, src, |tok, src| {
            tok.span
                .get_content(src)
                .eq_ignore_ascii_case_chars(&['c', 'a', 'n', 't'])
        })?;

        let jargon = token.span.get_content(src);
        let cannot = "can't";

        Some(Lint {
            span: token.span,
            lint_kind: LintKind::Enhancement,
            suggestions: vec![Suggestion::replace_with_match_case_str(cannot, jargon)],
            message: "`Cant` is secret language or jargon. If that's not what you mean you should use `can't` here.".to_string(),
            priority: 127,
        })
    }

    fn description(&self) -> &'static str {
        "Suggests correcting `cant` to `can't`."
    }
}

#[cfg(test)]
mod tests {
    use super::Cant;
    use crate::linting::tests::{assert_lint_count, assert_suggestion_result};

    #[test]
    fn corrects_pronoun_cant() {
        assert_suggestion_result(
            "I cant go to the store.",
            Cant::default(),
            "I can't go to the store.",
        );
    }

    #[test]
    fn corrects_proper_noun_cant() {
        assert_suggestion_result(
            "Bob cant go to the store.",
            Cant::default(),
            "Bob can't go to the store.",
        );
    }

    #[test]
    fn corrects_common_noun_cant() {
        // "dog" and "cat" are
        assert_suggestion_result(
            "A horse cant drink bottled water.",
            Cant::default(),
            "A horse can't drink bottled water.",
        );
    }

    #[test]
    fn corrects_cant_pronoun() {
        assert_suggestion_result(
            "Cant you go to the store?",
            Cant::default(),
            "Can't you go to the store?",
        );
    }

    #[test]
    fn dont_flag_if_cant_is_part_of_noun_phrase() {
        assert_lint_count("Cant cant be the same as jargon.", Cant::default(), 0);
    }

    #[test]
    fn dont_flag_cant_project() {
        assert_lint_count(
            "The CANT project is designed to allow people to screw around with CAN easily at layers 1/2.",
            Cant::default(),
            0,
        );
    }

    #[test]
    #[ignore = "'Convert' is also a noun, so a 'cant convert' could be a person who switched to speaking jargon"]
    fn corrects_cant_verb() {
        assert_suggestion_result(
            "Cant convert widget to input",
            Cant::default(),
            "Can't convert widget to input",
        );
    }

    #[test]
    fn dont_flag_legit_noun_sense() {
        assert_lint_count(
            "CB Slang Dictionary is the distinctive anti-language, argot or cant which developed amongst users of citizens' band radio (CB), especially truck drivers",
            Cant::default(),
            0,
        );
    }
}



================================================
FILE: harper-core/src/linting/capitalize_personal_pronouns.rs
================================================
use crate::TokenStringExt;

use super::{Lint, LintKind, Linter, Suggestion};

/// A linter that makes sure you capitalize "I" and its contractions.
#[derive(Default)]
pub struct CapitalizePersonalPronouns;

impl Linter for CapitalizePersonalPronouns {
    fn lint(&mut self, document: &crate::Document) -> Vec<Lint> {
        document
            .iter_words()
            .filter_map(|tok| {
                let span_content = document.get_span_content(&tok.span);

                if matches!(
                    span_content,
                    ['i']
                        | ['i', '\'', 'd']
                        | ['i', '\'', 'd', '\'', 'v', 'e']
                        | ['i', '\'', 'l', 'l']
                        | ['i', '\'', 'm']
                        | ['i', '\'', 'v', 'e']
                ) {
                    let mut replacement = span_content.to_vec();
                    replacement[0] = 'I';
                    Some(Lint {
                        span: tok.span,
                        lint_kind: LintKind::Capitalization,
                        suggestions: vec![Suggestion::ReplaceWith(replacement)],
                        message: "The first-person singular subject pronoun must be capitalized."
                            .to_string(),
                        priority: 31,
                    })
                } else {
                    None
                }
            })
            .collect()
    }

    fn description(&self) -> &'static str {
        "Forgetting to capitalize personal pronouns, like \"I\" or \"I'm\" is one of the most common errors. This rule helps with that."
    }
}

#[cfg(test)]
mod tests {
    use crate::linting::tests::{assert_lint_count, assert_suggestion_result};

    use super::CapitalizePersonalPronouns;

    #[test]
    fn start() {
        assert_suggestion_result("i am hungry", CapitalizePersonalPronouns, "I am hungry");
    }

    #[test]
    fn end() {
        assert_suggestion_result(
            "There is no one stronger than i",
            CapitalizePersonalPronouns,
            "There is no one stronger than I",
        );
    }

    #[test]
    fn middle() {
        assert_suggestion_result(
            "First of all, i am not happy with this.",
            CapitalizePersonalPronouns,
            "First of all, I am not happy with this.",
        );
    }

    #[test]
    fn issue_365() {
        assert_lint_count(
            "access will succeed, unlike with UDEREF/i386.",
            CapitalizePersonalPronouns,
            0,
        );
    }

    #[test]
    fn corrects_id() {
        assert_suggestion_result("i'd", CapitalizePersonalPronouns, "I'd");
    }

    #[test]
    fn correct_real_world_id() {
        assert_suggestion_result(
            "Personal Homebrew tap with tools i'd like to use",
            CapitalizePersonalPronouns,
            "Personal Homebrew tap with tools I'd like to use",
        )
    }

    #[test]
    fn corrects_idve() {
        assert_suggestion_result("i'd've", CapitalizePersonalPronouns, "I'd've");
    }

    #[test]
    fn correct_real_world_idve() {
        assert_suggestion_result(
            "... i'd've loved this even more twice length , but let not get greedy",
            CapitalizePersonalPronouns,
            "... I'd've loved this even more twice length , but let not get greedy",
        )
    }

    #[test]
    fn corrects_ill() {
        assert_suggestion_result("i'll", CapitalizePersonalPronouns, "I'll");
    }

    #[test]
    fn correct_real_world_ill() {
        assert_suggestion_result(
            "Hey i deploy my contract it give me error and i'll match with the script file both are same if someone have idea how i slove this please ...",
            CapitalizePersonalPronouns,
            "Hey I deploy my contract it give me error and I'll match with the script file both are same if someone have idea how I slove this please ...",
        )
    }

    #[test]
    fn corrects_im() {
        assert_suggestion_result("i'm", CapitalizePersonalPronouns, "I'm");
    }

    #[test]
    fn correct_real_world_im() {
        assert_suggestion_result(
            "Grid view not working, i'm not using any template",
            CapitalizePersonalPronouns,
            "Grid view not working, I'm not using any template",
        )
    }

    #[test]
    fn corrects_ive() {
        assert_suggestion_result("i've", CapitalizePersonalPronouns, "I've");
    }

    #[test]
    fn correct_real_world_ive() {
        assert_suggestion_result(
            "Can't use Github Pro although i've verified for student pack",
            CapitalizePersonalPronouns,
            "Can't use Github Pro although I've verified for student pack",
        )
    }
}



================================================
FILE: harper-core/src/linting/cautionary_tale.rs
================================================
use crate::linting::expr_linter::Chunk;
use crate::{
    Token,
    expr::{Expr, SequenceExpr},
    linting::{ExprLinter, Lint, LintKind, Suggestion},
    patterns::WordSet,
};

/// Corrects the homophone confusion between "tale" (story) and "tail" (appendage)
/// in common phrases like "cautionary tale" and "inspirational tale".
pub struct CautionaryTale {
    expr: Box<dyn Expr>,
}

impl Default for CautionaryTale {
    fn default() -> Self {
        let adjectives = WordSet::new(&["cautionary", "inspirational"]);

        let pattern = SequenceExpr::default()
            .then(adjectives)
            .t_ws()
            .t_aco("tail");

        Self {
            expr: Box::new(pattern),
        }
    }
}

impl ExprLinter for CautionaryTale {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, toks: &[Token], src: &[char]) -> Option<Lint> {
        let tail_span = toks.last()?.span;
        let tail_text = tail_span.get_content(src);

        Some(Lint {
            span: tail_span,
            lint_kind: LintKind::Miscellaneous,
            suggestions: vec![Suggestion::replace_with_match_case(
                ['t', 'a', 'l', 'e'].to_vec(),
                tail_text,
            )],
            message: "Did you mean `tale` (story)?".to_owned(),
            priority: 31,
        })
    }

    fn description(&self) -> &'static str {
        "Corrects confusion between `tale` (story) and `tail` (appendage) in common phrases."
    }
}

#[cfg(test)]
mod tests {
    use super::CautionaryTale;
    use crate::linting::tests::{assert_lint_count, assert_suggestion_result};

    #[test]
    fn catches_cautionary_tail() {
        assert_suggestion_result(
            "It serves as a cautionary tail.",
            CautionaryTale::default(),
            "It serves as a cautionary tale.",
        );
    }

    #[test]
    fn catches_inspirational_tail() {
        assert_suggestion_result(
            "Her journey is an inspirational tail of perseverance.",
            CautionaryTale::default(),
            "Her journey is an inspirational tale of perseverance.",
        );
    }

    #[test]
    fn catches_capitalized_cautionary_tail() {
        assert_suggestion_result(
            "The article discusses a Cautionary Tail about privacy.",
            CautionaryTale::default(),
            "The article discusses a Cautionary Tale about privacy.",
        );
    }

    #[test]
    fn catches_uppercase_cautionary_tail() {
        assert_suggestion_result(
            "THE STORY IS A CAUTIONARY TAIL.",
            CautionaryTale::default(),
            "THE STORY IS A CAUTIONARY TALE.",
        );
    }

    #[test]
    fn catches_mixed_case() {
        assert_suggestion_result(
            "This serves as an inspirational Tail for all.",
            CautionaryTale::default(),
            "This serves as an inspirational Tale for all.",
        );
    }

    #[test]
    fn allows_actual_tail() {
        assert_lint_count(
            "The dog wagged its tail happily.",
            CautionaryTale::default(),
            0,
        );
    }

    #[test]
    fn allows_different_adjective_with_tail() {
        assert_lint_count("The cat has a long tail.", CautionaryTale::default(), 0);
    }

    #[test]
    fn allows_correct_tale() {
        assert_lint_count(
            "It serves as a cautionary tale.",
            CautionaryTale::default(),
            0,
        );
    }

    #[test]
    fn allows_inspirational_tale() {
        assert_lint_count(
            "Her story is an inspirational tale.",
            CautionaryTale::default(),
            0,
        );
    }

    #[test]
    fn catches_in_longer_text() {
        assert_suggestion_result(
            "The movie presents a cautionary tail about the dangers of AI. It's really scary.",
            CautionaryTale::default(),
            "The movie presents a cautionary tale about the dangers of AI. It's really scary.",
        );
    }

    #[test]
    fn catches_multiple_occurrences() {
        assert_lint_count(
            "This cautionary tail is also an inspirational tail about overcoming adversity.",
            CautionaryTale::default(),
            2,
        );
    }

    #[test]
    fn allows_tail_in_different_context() {
        assert_lint_count(
            "The inspirational speaker told the tale of a dog's tail.",
            CautionaryTale::default(),
            0,
        );
    }

    #[test]
    fn catches_at_start_of_sentence() {
        assert_suggestion_result(
            "Cautionary tail: don't trust strangers.",
            CautionaryTale::default(),
            "Cautionary tale: don't trust strangers.",
        );
    }
}



================================================
FILE: harper-core/src/linting/change_tack.rs
================================================
use crate::{
    Token,
    expr::{Expr, FirstMatchOf, SequenceExpr},
    linting::{ExprLinter, Lint, LintKind, Suggestion, expr_linter::Chunk},
    patterns::Word,
};

pub struct ChangeTack {
    expr: Box<dyn Expr>,
}

impl Default for ChangeTack {
    fn default() -> Self {
        let verb_forms = &["change", "changes", "changing", "changed"];
        let noun_forms = &verb_forms[..3];
        let eggcorns = &["tact", "tacks", "tacts"];

        Self {
            expr: Box::new(FirstMatchOf::new(vec![
                Box::new(
                    SequenceExpr::default()
                        .then_longest_of(vec![
                            Box::new(SequenceExpr::word_set(verb_forms).then_optional(
                                SequenceExpr::default().t_ws().then_any_of(vec![
                                    Box::new(SequenceExpr::default().then_possessive_determiner()),
                                    Box::new(Word::new("it's")),
                                ]),
                            )),
                            Box::new(SequenceExpr::word_set(noun_forms).t_ws().t_aco("of")),
                        ])
                        .t_ws()
                        .then_word_set(eggcorns),
                ),
                Box::new(SequenceExpr::aco("different").t_ws().t_aco("tact")),
            ])),
        }
    }
}

impl ExprLinter for ChangeTack {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, toks: &[Token], src: &[char]) -> Option<Lint> {
        let tact_tok = toks.last()?;
        let tact_span = tact_tok.span;
        let tact_chars = tact_span.get_content(src);

        Some(Lint {
            span: tact_span,
            lint_kind: LintKind::Eggcorn,
            suggestions: vec![Suggestion::replace_with_match_case(
                ['t', 'a', 'c', 'k'].to_vec(),
                tact_chars,
            )],
            message: "A change in direction or approach is a change of `tack`. Not `tact` (or `tacks` or `tacts`).".to_owned(),
            priority: 32,
        })
    }

    fn description(&self) -> &'static str {
        "Locates errors in the idioms `to change tack` and `change of tack` to convey the correct meaning of altering one's course or strategy."
    }
}

#[cfg(test)]
mod tests {
    use super::ChangeTack;
    use crate::linting::tests::assert_suggestion_result;

    // Verbs: change tack

    #[test]
    fn change_tact_atomic() {
        assert_suggestion_result("change tact", ChangeTack::default(), "change tack");
    }

    #[test]
    fn changed_tacks_atomic() {
        assert_suggestion_result("changed tacks", ChangeTack::default(), "changed tack");
    }

    #[test]
    fn changes_tacts_atomic() {
        assert_suggestion_result("changes tacts", ChangeTack::default(), "changes tack");
    }

    #[test]
    fn changing_tact_atomic() {
        assert_suggestion_result("changing tact", ChangeTack::default(), "changing tack");
    }

    // Nouns: change of tack

    #[test]
    fn change_of_tacks_atomic() {
        assert_suggestion_result("change of tacks", ChangeTack::default(), "change of tack");
    }

    #[test]
    fn change_of_tact_real_world() {
        assert_suggestion_result(
            "Change of tact : come give your concerns - Death Knight",
            ChangeTack::default(),
            "Change of tack : come give your concerns - Death Knight",
        );
    }

    #[test]
    fn change_of_tacts_real_world() {
        assert_suggestion_result(
            "2013.08.15 - A Change of Tacts | Hero MUX Wiki | Fandom",
            ChangeTack::default(),
            "2013.08.15 - A Change of Tack | Hero MUX Wiki | Fandom",
        );
    }

    #[test]
    fn changing_of_tacks_real_world() {
        assert_suggestion_result(
            "Duffy's changing of tacks hidden in her poetry collection ...",
            ChangeTack::default(),
            "Duffy's changing of tack hidden in her poetry collection ...",
        );
    }

    #[test]
    fn changes_of_tact_real_world() {
        assert_suggestion_result(
            "While the notes and the changes of tact started to ...",
            ChangeTack::default(),
            "While the notes and the changes of tack started to ...",
        );
    }

    // With possessive determiners

    #[test]
    fn changed_my_tact() {
        assert_suggestion_result(
            "I have changed my tact this year, and have two second dates in the next week.",
            ChangeTack::default(),
            "I have changed my tack this year, and have two second dates in the next week.",
        );
    }

    #[test]
    fn changed_our_tact() {
        assert_suggestion_result(
            "That being said we have changed our tact slightly and gone for making all UI elements lazy.",
            ChangeTack::default(),
            "That being said we have changed our tack slightly and gone for making all UI elements lazy.",
        );
    }

    #[test]
    fn change_your_tact() {
        assert_suggestion_result(
            "If you've ever heard the phrase “you've got to change your tact”, this is probably where it comes from.",
            ChangeTack::default(),
            "If you've ever heard the phrase “you've got to change your tack”, this is probably where it comes from.",
        );
    }

    #[test]
    fn change_his_tact() {
        assert_suggestion_result(
            "Why did Sephiroth change his tact with Cloud midway through the game?",
            ChangeTack::default(),
            "Why did Sephiroth change his tack with Cloud midway through the game?",
        );
    }

    #[test]
    fn changed_her_tact() {
        assert_suggestion_result(
            "Only the last commitment ceremony I think she changed her tact and went on about George needing to be the real George.",
            ChangeTack::default(),
            "Only the last commitment ceremony I think she changed her tack and went on about George needing to be the real George.",
        );
    }

    #[test]
    fn change_its_tact() {
        assert_suggestion_result(
            "The show seems to change its tact depending on the episode.",
            ChangeTack::default(),
            "The show seems to change its tack depending on the episode.",
        );
    }

    #[test]
    fn changing_its_tact_apostrophe() {
        assert_suggestion_result(
            "FYI, USL is changing it's tact internally about MLS II teams.",
            ChangeTack::default(),
            "FYI, USL is changing it's tack internally about MLS II teams.",
        );
    }

    #[test]
    fn changes_their_tact() {
        assert_suggestion_result(
            "As we become inoculated to attention grifts, the grifter changes their tact.",
            ChangeTack::default(),
            "As we become inoculated to attention grifts, the grifter changes their tack.",
        );
    }

    #[test]
    fn different_tact() {
        assert_suggestion_result(
            "So, I recently took a different tact: I put all my models etc. in a single folder.",
            ChangeTack::default(),
            "So, I recently took a different tack: I put all my models etc. in a single folder.",
        );
    }
}



================================================
FILE: harper-core/src/linting/chock_full.rs
================================================
use crate::expr::Expr;
use crate::weir::weir_expr_to_expr;
use crate::{Token, TokenStringExt};

use super::{ExprLinter, Lint, LintKind, Suggestion};
use crate::linting::expr_linter::Chunk;

pub struct ChockFull {
    expr: Box<dyn Expr>,
}

impl Default for ChockFull {
    fn default() -> Self {
        Self {
            expr: weir_expr_to_expr("[chalk, choke][( ), -]full").unwrap(),
        }
    }
}

impl ExprLinter for ChockFull {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_toks: &[Token], source: &[char]) -> Option<Lint> {
        let span = matched_toks.span()?;

        Some(Lint {
            span,
            lint_kind: LintKind::WordChoice,
            suggestions: vec![Suggestion::replace_with_match_case_str(
                "chock-full",
                span.get_content(source),
            )],
            message: format!(
                "The standard term is \"chock-full\"{}.",
                if matched_toks[1].kind.is_whitespace() {
                    ", and it should be hyphenated"
                } else {
                    ""
                }
            ),
            priority: 126,
        })
    }

    fn description(&self) -> &'static str {
        "Flags common soundalikes of \"chock-full\" and makes sure they're hyphenated."
    }
}

#[cfg(test)]
mod tests {
    use super::ChockFull;
    use crate::linting::tests::{assert_lint_count, assert_suggestion_result};

    #[test]
    fn allows_correct_form() {
        assert_lint_count(
            "'Chalk full', 'chalk-full', 'choke full', and 'choke-full' are nonstandard forms of 'chock-full'.",
            ChockFull::default(),
            4,
        );
    }

    #[test]
    fn lower_space_chalk() {
        assert_suggestion_result(
            "The codebase is chalk full of errors that we need to address.",
            ChockFull::default(),
            "The codebase is chock-full of errors that we need to address.",
        );
    }

    #[test]
    fn lower_space_choke() {
        assert_suggestion_result(
            "The project is choke full of questionable decisions that we need to revisit.",
            ChockFull::default(),
            "The project is chock-full of questionable decisions that we need to revisit.",
        );
    }

    #[test]
    fn upper_space_chalk() {
        assert_suggestion_result(
            "Chalk full of deprecated methods; we should refactor.",
            ChockFull::default(),
            "Chock-full of deprecated methods; we should refactor.",
        );
    }

    #[test]
    fn upper_space_choke() {
        assert_suggestion_result(
            "Choke full of unnecessary complexity; simplify it.",
            ChockFull::default(),
            "Chock-full of unnecessary complexity; simplify it.",
        );
    }

    #[test]
    fn lower_hyphen_chalk() {
        assert_suggestion_result(
            "The code is chalk-full of bugs; we need to debug before release.",
            ChockFull::default(),
            "The code is chock-full of bugs; we need to debug before release.",
        );
    }

    #[test]
    fn lower_hyphen_choke() {
        assert_suggestion_result(
            "The project is choke-full of warnings; we should address them.",
            ChockFull::default(),
            "The project is chock-full of warnings; we should address them.",
        );
    }

    #[test]
    fn upper_hyphen_chalk() {
        assert_suggestion_result(
            "Chalk-full of features, but we only need a few.",
            ChockFull::default(),
            "Chock-full of features, but we only need a few.",
        );
    }

    #[test]
    fn upper_hyphen_choke() {
        assert_suggestion_result(
            "Choke-full of pitfalls; let's consider alternatives.",
            ChockFull::default(),
            "Chock-full of pitfalls; let's consider alternatives.",
        );
    }
}



================================================
FILE: harper-core/src/linting/closed_compounds.rs
================================================
use crate::linting::LintGroup;

use super::MapPhraseLinter;

pub fn lint_group() -> LintGroup {
    let mut group = LintGroup::empty();

    macro_rules! add_compound_mappings {
        ($group:expr, { $($name:expr => ($bad:expr, $good:expr)),+ $(,)? }) => {
            $(
                $group.add(
                    $name,
                    Box::new(MapPhraseLinter::new_closed_compound($bad, $good)),
                );
            )+
        };
    }

    // These are compound words that should be condensed.
    // The first column is the name of the rule (which shows up in settings).
    // The second column is the incorrect form of the word and the third column is the correct
    // form.
    add_compound_mappings!(group, {
        "Anybody"         => ("any body", "anybody"),
        "Anyhow"          => ("any how", "anyhow"),
        "Anywhere"        => ("any where", "anywhere"),
        "Backplane"       => ("back plane", "backplane"),
        "Desktop"         => ("desk top", "desktop"),
        "Devops"          => ("dev ops", "devops"),
        "Everybody"       => ("every body", "everybody"),
        "Everyone"        => ("every one", "everyone"),
        "Everywhere"      => ("every where", "everywhere"),
        "Furthermore"     => ("further more", "furthermore"),
        "Henceforth"      => ("hence forth", "henceforth"),
        "However"         => ("how ever", "however"),
        "Insofar"         => ("in so far", "insofar"),
        "Instead"         => ("in stead", "instead"),
        "Intact"          => ("in tact", "intact"),
        "Itself"          => ("it self", "itself"),
        "Laptop"          => ("lap top", "laptop"),
        "Middleware"      => ("middle ware", "middleware"),
        "Misunderstand"   => ("miss understand", "misunderstand"),
        "Misunderstood"   => ("miss understood", "misunderstood"),
        "Misuse"          => ("miss use", "misuse"),
        "Misused"         => ("miss used", "misused"),
        "Multicore"       => ("multi core", "multicore"),
        "Multimedia"      => ("multi media", "multimedia"),
        "Multithreading"  => ("multi threading", "multithreading"),
        "Myself"          => ("my self", "myself"),
        "Nonetheless"     => ("none the less", "nonetheless"),
        "Nobody"          => ("no body", "nobody"),
        "Nowhere"         => ("no where", "nowhere"),
        "Nothing"         => ("no thing", "nothing"),
        "Notwithstanding" => ("not with standing", "notwithstanding"),
        "Overall"         => ("over all", "overall"),
        "Overclocking"    => ("over clocking", "overclocking"),
        "Overload"        => ("over load", "overload"),
        "Overnight"       => ("over night", "overnight"),
        "Postpone"        => ("post pone", "postpone"),
        "Proofread"       => ("proof read", "proofread"),
        "Regardless"      => ("regard less", "regardless"),
        "Somebody"        => ("some body", "somebody"),
        "Somehow"         => ("some how", "somehow"),
        "Someone"         => ("some one", "someone"),
        "Somewhere"       => ("some where", "somewhere"),
        "Therefore"       => ("there fore", "therefore"),
        "Thereupon"       => ("there upon", "thereupon"),
        "Underclock"      => ("under clock", "underclock"),
        "Upset"           => ("up set", "upset"),
        "Upward"          => ("up ward", "upward"),
        "Whereupon"       => ("where upon", "whereupon"),
        "Widespread"      => ("wide spread", "widespread"),
        "Worldwide"       => ("world wide", "worldwide"),
    });

    group.set_all_rules_to(Some(true));

    group
}

#[cfg(test)]
mod tests {
    use crate::linting::tests::assert_suggestion_result;

    use super::lint_group;

    #[test]
    fn it_self() {
        let test_sentence = "The project, it self, was quite challenging.";
        let expected = "The project, itself, was quite challenging.";
        assert_suggestion_result(test_sentence, lint_group(), expected);
    }

    #[test]
    fn my_self() {
        let test_sentence = "He treated my self with respect.";
        let expected = "He treated myself with respect.";
        assert_suggestion_result(test_sentence, lint_group(), expected);
    }

    #[test]
    fn there_fore() {
        let test_sentence = "This is the reason; there fore, this is true.";
        let expected = "This is the reason; therefore, this is true.";
        assert_suggestion_result(test_sentence, lint_group(), expected);
    }

    #[test]
    fn mis_understood() {
        let test_sentence = "She miss understood the instructions.";
        let expected = "She misunderstood the instructions.";
        assert_suggestion_result(test_sentence, lint_group(), expected);
    }

    #[test]
    fn mis_use() {
        let test_sentence = "He tends to miss use the tool.";
        let expected = "He tends to misuse the tool.";
        assert_suggestion_result(test_sentence, lint_group(), expected);
    }

    #[test]
    fn mis_used() {
        let test_sentence = "The software was miss used.";
        let expected = "The software was misused.";
        assert_suggestion_result(test_sentence, lint_group(), expected);
    }

    #[test]
    fn world_wide() {
        let test_sentence = "The world wide impact was significant.";
        let expected = "The worldwide impact was significant.";
        assert_suggestion_result(test_sentence, lint_group(), expected);
    }

    #[test]
    fn over_all() {
        let test_sentence = "The over all performance was good.";
        let expected = "The overall performance was good.";
        assert_suggestion_result(test_sentence, lint_group(), expected);
    }

    #[test]
    fn how_ever() {
        let test_sentence = "This is true, how ever, details matter.";
        let expected = "This is true, however, details matter.";
        assert_suggestion_result(test_sentence, lint_group(), expected);
    }

    #[test]
    fn wide_spread() {
        let test_sentence = "The news was wide spread throughout the region.";
        let expected = "The news was widespread throughout the region.";
        assert_suggestion_result(test_sentence, lint_group(), expected);
    }

    #[test]
    fn not_with_standing() {
        let test_sentence = "They decided to proceed not with standing any further delay.";
        let expected = "They decided to proceed notwithstanding any further delay.";
        assert_suggestion_result(test_sentence, lint_group(), expected);
    }

    #[test]
    fn any_how() {
        let test_sentence = "She solved the problem any how, even under pressure.";
        let expected = "She solved the problem anyhow, even under pressure.";
        assert_suggestion_result(test_sentence, lint_group(), expected);
    }

    #[test]
    fn none_the_less() {
        let test_sentence = "The results were disappointing, none the less, they continued.";
        let expected = "The results were disappointing, nonetheless, they continued.";
        assert_suggestion_result(test_sentence, lint_group(), expected);
    }

    #[test]
    fn there_upon() {
        let test_sentence = "A decision was made there upon reviewing the data.";
        let expected = "A decision was made thereupon reviewing the data.";
        assert_suggestion_result(test_sentence, lint_group(), expected);
    }

    #[test]
    fn in_so_far() {
        let test_sentence = "This rule applies in so far as it covers all cases.";
        let expected = "This rule applies insofar as it covers all cases.";
        assert_suggestion_result(test_sentence, lint_group(), expected);
    }

    #[test]
    fn where_upon() {
        let test_sentence = "They acted where upon the circumstances allowed.";
        let expected = "They acted whereupon the circumstances allowed.";
        assert_suggestion_result(test_sentence, lint_group(), expected);
    }

    #[test]
    fn up_ward() {
        let test_sentence = "The temperature moved up ward during the afternoon.";
        let expected = "The temperature moved upward during the afternoon.";
        assert_suggestion_result(test_sentence, lint_group(), expected);
    }

    #[test]
    fn hence_forth() {
        let test_sentence = "All new policies apply hence forth immediately.";
        let expected = "All new policies apply henceforth immediately.";
        assert_suggestion_result(test_sentence, lint_group(), expected);
    }

    #[test]
    fn regard_less() {
        let test_sentence = "The decision was made, regard less of the opposition.";
        let expected = "The decision was made, regardless of the opposition.";
        assert_suggestion_result(test_sentence, lint_group(), expected);
    }

    #[test]
    fn over_night() {
        let test_sentence = "They set off on their journey over night.";
        let expected = "They set off on their journey overnight.";
        assert_suggestion_result(test_sentence, lint_group(), expected);
    }
}



================================================
FILE: harper-core/src/linting/comma_fixes.rs
================================================
use super::{Lint, LintKind, Linter, Suggestion};
use crate::{
    Span,
    TokenKind::{Space, Unlintable, Word},
    TokenStringExt,
};

const MSG_SPACE_BEFORE: &str = "Don't use a space before a comma.";
const MSG_AVOID_ASIAN: &str = "Avoid East Asian commas in English contexts.";
const MSG_SPACE_AFTER: &str = "Use a space after a comma.";

/// A linter that fixes common comma errors:
/// No space after.
/// Inappropriate space before.
/// Asian commas instead of English commas.
/// This linter only Asian commas anywhere, and wrong spacing of commas between words.
/// Commas between numbers are used differently in different contexts and these are not checked:
/// Lists of numbers: 1, 2, 3
/// Thousands separators: 1,000,000
/// Decimal points used mistakenly by Europeans: 3,14159
#[derive(Debug, Default)]
pub struct CommaFixes;

impl Linter for CommaFixes {
    fn lint(&mut self, document: &crate::Document) -> Vec<Lint> {
        let mut lints = Vec::new();
        let source = document.get_source();

        for ci in document.iter_comma_indices() {
            let mut toks = (None, None, document.get_token(ci).unwrap(), None, None);
            toks.0 = (ci >= 2).then(|| document.get_token(ci - 2).unwrap());
            toks.1 = (ci >= 1).then(|| document.get_token(ci - 1).unwrap());
            toks.3 = document.get_token(ci + 1);
            toks.4 = document.get_token(ci + 2);

            let kinds = (
                toks.0.map(|t| &t.kind),
                toks.1.map(|t| &t.kind),
                *toks.2.span.get_content(source).first().unwrap(),
                toks.3.map(|t| &t.kind),
                toks.4.map(|t| &t.kind),
            );

            let (span, suggestion, message) = match kinds {
                (_, Some(Word(_)), '、' | '，', Some(Space(_)), Some(Word(_))) => (
                    toks.2.span,
                    Suggestion::ReplaceWith(vec![',']),
                    vec![MSG_AVOID_ASIAN],
                ),

                (Some(Word(_)), Some(Space(_)), ',', Some(Space(_)), Some(Word(_))) => (
                    toks.1.unwrap().span,
                    Suggestion::Remove,
                    vec![MSG_SPACE_BEFORE],
                ),

                (Some(Word(_)), Some(Space(_)), '、' | '，', Some(Space(_)), Some(Word(_))) => (
                    Span::new(toks.1.unwrap().span.start, toks.2.span.end),
                    Suggestion::ReplaceWith(vec![',']),
                    vec![MSG_SPACE_BEFORE, MSG_AVOID_ASIAN],
                ),

                (_, Some(Word(_)), ',', Some(Word(_)), _) => (
                    toks.2.span,
                    Suggestion::InsertAfter(vec![' ']),
                    vec![MSG_SPACE_AFTER],
                ),

                (_, Some(Word(_)), '、' | '，', Some(Word(_)), _) => (
                    toks.2.span,
                    Suggestion::ReplaceWith(vec![',', ' ']),
                    vec![MSG_AVOID_ASIAN, MSG_SPACE_AFTER],
                ),

                (Some(Word(_)), Some(Space(_)), ',', Some(Word(_)), _) => (
                    Span::new(toks.1.unwrap().span.start, toks.2.span.end),
                    Suggestion::ReplaceWith(vec![',', ' ']),
                    vec![MSG_SPACE_BEFORE, MSG_SPACE_AFTER],
                ),

                (Some(Word(_)), Some(Space(_)), '、' | '，', Some(Word(_)), _) => (
                    Span::new(toks.1.unwrap().span.start, toks.2.span.end),
                    Suggestion::ReplaceWith(vec![',', ' ']),
                    vec![MSG_SPACE_BEFORE, MSG_AVOID_ASIAN, MSG_SPACE_AFTER],
                ),

                // Handles Asian commas in all other contexts
                // Unlintable is used for non-English tokens to prevent changing commas in CJK text
                (_, Some(Unlintable), '、' | '，', _, _) => continue,
                (_, _, '、' | '，', Some(Unlintable), _) => continue,

                (_, _, '、' | '，', _, _) => (
                    toks.2.span,
                    Suggestion::ReplaceWith(vec![',']),
                    vec![MSG_AVOID_ASIAN],
                ),

                _ => continue,
            };

            lints.push(Lint {
                span,
                lint_kind: LintKind::Punctuation,
                suggestions: vec![suggestion],
                message: message.join(" "),
                priority: 32,
            });
        }

        lints
    }

    fn description(&self) -> &'static str {
        "Fix common comma errors such as no space after, erroneous space before, etc., Asian commas instead of English commas, etc."
    }
}

#[cfg(test)]
mod tests {
    use super::CommaFixes;
    use crate::linting::tests::{assert_lint_count, assert_no_lints, assert_suggestion_result};

    #[test]
    fn allows_english_comma_atomic() {
        assert_lint_count(",", CommaFixes, 0);
    }

    #[test]
    fn flags_fullwidth_comma_atomic() {
        assert_lint_count("，", CommaFixes, 1);
    }

    #[test]
    fn flags_ideographic_comma_atomic() {
        assert_lint_count("、", CommaFixes, 1);
    }

    #[test]
    fn corrects_fullwidth_comma_real_world() {
        assert_suggestion_result(
            "higher 2 bits of the number of nodes， whether abandoned or not decided by .index section",
            CommaFixes,
            "higher 2 bits of the number of nodes, whether abandoned or not decided by .index section",
        );
    }

    #[test]
    fn corrects_ideographic_comma_real_world() {
        assert_suggestion_result("cout、endl、string", CommaFixes, "cout, endl, string")
    }

    #[test]
    fn doesnt_flag_comma_space_between_words() {
        assert_lint_count("foo, bar", CommaFixes, 0);
    }

    #[test]
    fn flags_fullwidth_comma_space_between_words() {
        assert_lint_count("foo， bar", CommaFixes, 1);
    }

    #[test]
    fn flags_ideographic_comma_space_between_words() {
        assert_lint_count("foo、 bar", CommaFixes, 1);
    }

    #[test]
    fn doesnt_flag_semicolon_space_between_words() {
        assert_lint_count("foo; bar", CommaFixes, 0);
    }

    #[test]
    fn corrects_comma_between_words_with_no_space() {
        assert_suggestion_result("foo,bar", CommaFixes, "foo, bar")
    }

    #[test]
    fn corrects_asian_comma_between_words_with_no_space() {
        assert_suggestion_result("foo，bar", CommaFixes, "foo, bar")
    }

    #[test]
    fn corrects_space_on_wrong_side_of_comma_between_words() {
        assert_suggestion_result("foo ,bar", CommaFixes, "foo, bar")
    }

    #[test]
    fn corrects_comma_on_wrong_side_of_asian_comma_between_words() {
        assert_suggestion_result("foo ，bar", CommaFixes, "foo, bar")
    }

    #[test]
    fn corrects_comma_between_words_with_space_on_both_sides() {
        assert_suggestion_result("foo , bar", CommaFixes, "foo, bar")
    }

    #[test]
    fn corrects_asian_comma_between_words_with_space_on_both_sides() {
        assert_suggestion_result("foo 、 bar", CommaFixes, "foo, bar")
    }

    #[test]
    fn doesnt_correct_comma_between_non_english_tokens() {
        assert_lint_count("严禁采摘花、 果、叶，挖掘树根、草药!", CommaFixes, 0);
    }

    #[test]
    fn issue_2233() {
        assert_no_lints(
            "In foobar, apple is a fruit, and \"beer\" is not a fruit.",
            CommaFixes,
        );
    }
}



================================================
FILE: harper-core/src/linting/compound_subject_i.rs
================================================
use crate::linting::expr_linter::Chunk;
use crate::{
    Token, TokenKind,
    expr::{AnchorStart, Expr, SequenceExpr},
    linting::{ExprLinter, Lint, LintKind, Suggestion},
};

const POSSESSIVE_DETERMINERS: &[&str] = &["my", "your", "her", "his", "their", "our"];

pub struct CompoundSubjectI {
    expr: Box<dyn Expr>,
}

impl Default for CompoundSubjectI {
    fn default() -> Self {
        let expr = SequenceExpr::default()
            .then(AnchorStart)
            .then_optional(
                SequenceExpr::default()
                    .then_quote()
                    .then_optional(SequenceExpr::default().t_ws()),
            )
            .then_optional(
                SequenceExpr::default()
                    .then_punctuation()
                    .then_optional(SequenceExpr::default().t_ws()),
            )
            .then_word_set(POSSESSIVE_DETERMINERS)
            .t_ws()
            .then_nominal()
            .t_ws()
            .t_aco("and")
            .t_ws()
            .t_aco("me")
            .t_ws()
            .then_kind_either(TokenKind::is_verb, TokenKind::is_auxiliary_verb);

        Self {
            expr: Box::new(expr),
        }
    }
}

impl ExprLinter for CompoundSubjectI {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], source: &[char]) -> Option<Lint> {
        let pronoun = matched_tokens.iter().find(|tok| {
            tok.kind.is_word()
                && tok
                    .span
                    .get_content_string(source)
                    .eq_ignore_ascii_case("me")
        })?;
        Some(Lint {
            span: pronoun.span,
            lint_kind: LintKind::Grammar,
            suggestions: vec![Suggestion::ReplaceWith("I".chars().collect())],
            message: "Use `I` when this pronoun is part of a compound subject.".to_owned(),
            priority: 31,
        })
    }

    fn description(&self) -> &'static str {
        "Promotes `I` in compound subjects headed by a possessive determiner."
    }
}

#[cfg(test)]
mod tests {
    use super::CompoundSubjectI;
    use crate::linting::tests::{assert_lint_count, assert_suggestion_result};

    #[test]
    fn corrects_my_mother_and_me() {
        assert_suggestion_result(
            "My mother and me went to California.",
            CompoundSubjectI::default(),
            "My mother and I went to California.",
        );
    }

    #[test]
    fn corrects_my_brother_and_me() {
        assert_suggestion_result(
            "My brother and me would often go to the cinema.",
            CompoundSubjectI::default(),
            "My brother and I would often go to the cinema.",
        );
    }

    #[test]
    fn corrects_your_friend_and_me() {
        assert_suggestion_result(
            "Your friend and me are heading out.",
            CompoundSubjectI::default(),
            "Your friend and I are heading out.",
        );
    }

    #[test]
    fn corrects_her_manager_and_me() {
        assert_suggestion_result(
            "Her manager and me have talked about it.",
            CompoundSubjectI::default(),
            "Her manager and I have talked about it.",
        );
    }

    #[test]
    fn corrects_his_cat_and_me() {
        assert_suggestion_result(
            "His cat and me were inseparable.",
            CompoundSubjectI::default(),
            "His cat and I were inseparable.",
        );
    }

    #[test]
    fn corrects_their_kids_and_me() {
        assert_suggestion_result(
            "Their kids and me will play outside.",
            CompoundSubjectI::default(),
            "Their kids and I will play outside.",
        );
    }

    #[test]
    fn corrects_our_neighbor_and_me() {
        assert_suggestion_result(
            "Our neighbor and me can help tomorrow.",
            CompoundSubjectI::default(),
            "Our neighbor and I can help tomorrow.",
        );
    }

    #[test]
    fn corrects_with_quote_prefix() {
        assert_suggestion_result(
            "\"My mother and me went to California,\" she said.",
            CompoundSubjectI::default(),
            "\"My mother and I went to California,\" she said.",
        );
    }

    #[test]
    fn corrects_all_caps() {
        assert_suggestion_result(
            "MY BROTHER AND ME WILL HANDLE IT.",
            CompoundSubjectI::default(),
            "MY BROTHER AND I WILL HANDLE IT.",
        );
    }

    #[test]
    fn ignores_between_you_and_me() {
        assert_lint_count(
            "Between you and me, this stays here.",
            CompoundSubjectI::default(),
            0,
        );
    }

    #[test]
    fn ignores_comma_after_me() {
        assert_lint_count(
            "My mother and me, as usual, went to the park.",
            CompoundSubjectI::default(),
            0,
        );
    }
}



================================================
FILE: harper-core/src/linting/confident.rs
================================================
use crate::expr::Expr;
use crate::expr::OwnedExprExt;
use crate::expr::SequenceExpr;
use crate::linting::expr_linter::Chunk;
use crate::{Token, patterns::Word};

use super::{ExprLinter, Lint, LintKind, Suggestion};

pub struct Confident {
    expr: Box<dyn Expr>,
}

impl Default for Confident {
    fn default() -> Self {
        let pattern = SequenceExpr::default()
            .then(
                SequenceExpr::from(|tok: &Token, _source: &[char]| {
                    tok.kind.is_verb() || tok.kind.is_determiner()
                })
                .or(Word::new("very")),
            )
            .then_whitespace()
            .t_aco("confidant");

        Self {
            expr: Box::new(pattern),
        }
    }
}

impl ExprLinter for Confident {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], _source: &[char]) -> Option<Lint> {
        let span = matched_tokens.last()?.span;

        Some(Lint {
            span,
            lint_kind: LintKind::WordChoice,
            suggestions: vec![Suggestion::ReplaceWith("confident".chars().collect())],
            message: "Use the adjective.".to_owned(),
            priority: 127,
        })
    }

    fn description(&self) -> &'static str {
        "This linter detects instances where the noun `confidant` is incorrectly used in place of the adjective `confident`. `Confidant` refers to a trusted person, whereas `confident` describes certainty or self-assurance. The rule suggests replacing `confidant` with `confident` when used in an adjectival context."
    }
}

#[cfg(test)]
mod tests {
    use super::Confident;
    use crate::linting::tests::{assert_lint_count, assert_suggestion_result};

    #[test]
    fn describing_person_incorrect() {
        assert_suggestion_result(
            "She felt confidant about her presentation.",
            Confident::default(),
            "She felt confident about her presentation.",
        );
    }

    #[test]
    fn describing_person_correct() {
        assert_lint_count(
            "She felt confident about her presentation.",
            Confident::default(),
            0,
        );
    }

    #[test]
    fn certainty_incorrect() {
        assert_suggestion_result(
            "I am confidant the test results are accurate.",
            Confident::default(),
            "I am confident the test results are accurate.",
        );
    }

    #[test]
    fn certainty_correct() {
        assert_lint_count(
            "I am confident the test results are accurate.",
            Confident::default(),
            0,
        );
    }

    #[test]
    fn demeanor_incorrect() {
        assert_suggestion_result(
            "He walked to the stage with a confidant stride.",
            Confident::default(),
            "He walked to the stage with a confident stride.",
        );
    }

    #[test]
    fn demeanor_correct() {
        assert_lint_count(
            "He walked to the stage with a confident stride.",
            Confident::default(),
            0,
        );
    }

    #[test]
    fn professional_incorrect() {
        assert_suggestion_result(
            "You should sound confidant during job interviews.",
            Confident::default(),
            "You should sound confident during job interviews.",
        );
    }

    #[test]
    fn professional_correct() {
        assert_lint_count(
            "You should sound confident during job interviews.",
            Confident::default(),
            0,
        );
    }

    #[test]
    fn assured_tone_incorrect() {
        assert_suggestion_result(
            "Present your argument in a confidant, persuasive manner.",
            Confident::default(),
            "Present your argument in a confident, persuasive manner.",
        );
    }

    #[test]
    fn assured_tone_correct() {
        assert_lint_count(
            "Present your argument in a confident, persuasive manner.",
            Confident::default(),
            0,
        );
    }

    #[test]
    fn extra_text_between() {
        assert_suggestion_result(
            "She felt very confidant about her presentation.",
            Confident::default(),
            "She felt very confident about her presentation.",
        );
    }

    #[test]
    fn linking_verb_was_confidant() {
        assert_suggestion_result(
            "She was confidant about her presentation.",
            Confident::default(),
            "She was confident about her presentation.",
        );
    }
}



================================================
FILE: harper-core/src/linting/correct_number_suffix.rs
================================================
use super::{Lint, LintKind, Linter, Suggestion};
use crate::{Document, OrdinalSuffix, Span, TokenKind};
use crate::{Number, TokenStringExt};

/// Detect incorrect number suffix (e.g. "2st").
#[derive(Debug, Clone, Copy, Default)]
pub struct CorrectNumberSuffix;

impl Linter for CorrectNumberSuffix {
    fn lint(&mut self, document: &Document) -> Vec<Lint> {
        let mut output = Vec::new();

        for number_tok in document.iter_numbers() {
            let Some(suffix_span) = Span::new_with_len(number_tok.span.end, 2).pulled_by(2) else {
                continue;
            };

            if let TokenKind::Number(Number {
                value,
                suffix: Some(suffix),
                ..
            }) = number_tok.kind
                && let Some(correct_suffix) = OrdinalSuffix::correct_suffix_for(value)
                && suffix != correct_suffix
            {
                output.push(Lint {
                    span: suffix_span,
                    lint_kind: LintKind::Miscellaneous,
                    message: "This number needs a different suffix to sound right.".to_string(),
                    suggestions: vec![Suggestion::ReplaceWith(correct_suffix.to_chars().to_vec())],
                    ..Default::default()
                })
            }
        }

        output
    }

    fn description(&self) -> &'static str {
        "When making quick edits, it is common for authors to change the value of a number without changing its suffix. This rule looks for these cases, for example: `2st`."
    }
}

#[cfg(test)]
mod tests {
    use super::CorrectNumberSuffix;
    use crate::linting::tests::assert_lint_count;

    #[test]
    fn passes_correct_cases() {
        assert_lint_count("2nd", CorrectNumberSuffix, 0);
        assert_lint_count("101st", CorrectNumberSuffix, 0);
        assert_lint_count("1012th", CorrectNumberSuffix, 0);
    }

    #[test]
    fn detects_incorrect_cases() {
        assert_lint_count("2st", CorrectNumberSuffix, 1);
        assert_lint_count("101nd", CorrectNumberSuffix, 1);
        assert_lint_count("1012rd", CorrectNumberSuffix, 1);
    }
}



================================================
FILE: harper-core/src/linting/criteria_phenomena.rs
================================================
use super::Suggestion;
use super::expr_linter::ExprLinter;
use crate::expr::Expr;
use crate::expr::SequenceExpr;
use crate::linting::LintKind;
use crate::linting::expr_linter::Chunk;
use crate::patterns::WordSet;
use crate::{Lint, Lrc, Token, TokenStringExt};

/// Linter that checks if 'criteria' or 'phenomena' is used as singular.
pub struct CriteriaPhenomena {
    expr: Box<dyn Expr>,
    plural_words: Lrc<WordSet>,
    singular_modifiers: Lrc<WordSet>,
}

impl CriteriaPhenomena {
    fn new() -> Self {
        let plural_words = Lrc::new(WordSet::new(&["criteria", "phenomena"]));

        let singular_modifiers = Lrc::new(WordSet::new(&["this", "that", "a", "one"]));

        Self {
            expr: Box::new(
                SequenceExpr::default()
                    .then(singular_modifiers.clone())
                    .then_whitespace()
                    .then(plural_words.clone()),
            ),
            plural_words,
            singular_modifiers,
        }
    }
}

impl ExprLinter for CriteriaPhenomena {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], source: &[char]) -> Option<Lint> {
        let mut second_word: String = matched_tokens[2]
            .span
            .get_content(source)
            .iter()
            .copied()
            .collect();
        second_word.make_ascii_lowercase();

        let suggestions = match second_word.as_str() {
            "criteria" => vec![Suggestion::ReplaceWith("criterion".chars().collect())],
            "phenomena" => vec![Suggestion::ReplaceWith("phenomenon".chars().collect())],
            _ => panic!("Don't know what to say about '{second_word}'!"),
        };

        Some(Lint {
            span: matched_tokens.span()?,
            lint_kind: LintKind::Repetition,
            message: "You used a plural noun as singular.".to_owned(),
            priority: 63,
            suggestions,
        })
    }

    fn description(&self) -> &'static str {
        "The words “criteria” and “phenomena” are the plurals of “criterion” and “phenomenon”, respectively. They are often incorrectly used as singular."
    }
}

impl Default for CriteriaPhenomena {
    fn default() -> Self {
        Self::new()
    }
}

#[cfg(test)]
mod tests {
    use super::CriteriaPhenomena;
    use crate::linting::tests::assert_lint_count;

    #[test]
    fn can_detect_incorrect_criteria() {
        assert_lint_count(
            "...One criteria is essential...",
            CriteriaPhenomena::new(),
            1,
        )
    }

    #[test]
    fn can_detect_incorrect_phenomena() {
        assert_lint_count(
            "...I would like to see that phenomena.",
            CriteriaPhenomena::new(),
            1,
        )
    }

    #[test]
    fn allows_correct_criteria() {
        assert_lint_count(
            "...She disagrees with those criteria.",
            CriteriaPhenomena::new(),
            0,
        )
    }

    #[test]
    fn allows_correct_phenomena() {
        assert_lint_count(
            "...Many phenomena were on display.",
            CriteriaPhenomena::new(),
            0,
        )
    }
}



================================================
FILE: harper-core/src/linting/cure_for.rs
================================================
use crate::{
    Span, Token,
    expr::{Expr, SequenceExpr},
    linting::expr_linter::Chunk,
    linting::{ExprLinter, Lint, LintKind, Suggestion},
    patterns::{DerivedFrom, Word},
};

pub struct CureFor {
    expr: Box<dyn Expr>,
}

impl Default for CureFor {
    fn default() -> Self {
        let expr = SequenceExpr::default()
            .then(DerivedFrom::new_from_str("cure"))
            .t_ws()
            .then(Word::new("against"));

        Self {
            expr: Box::new(expr),
        }
    }
}

impl ExprLinter for CureFor {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], source: &[char]) -> Option<Lint> {
        let against = matched_tokens.last()?;

        let template: Vec<char> = against.span.get_content(source).to_vec();
        let suggestion = Suggestion::replace_with_match_case_str("for", &template);

        Some(Lint {
            span: Span::new(against.span.start, against.span.end),
            lint_kind: LintKind::Usage,
            suggestions: vec![suggestion],
            message: "Prefer `cure for` when describing a treatment target.".to_owned(),
            priority: 31,
        })
    }

    fn description(&self) -> &str {
        "Flags `cure against` and prefers the standard `cure for` pairing."
    }
}

#[cfg(test)]
mod tests {
    use super::CureFor;
    use crate::linting::tests::{assert_lint_count, assert_suggestion_result};

    #[test]
    fn corrects_simple_cure_against() {
        assert_suggestion_result(
            "Researchers sought a cure against the stubborn illness.",
            CureFor::default(),
            "Researchers sought a cure for the stubborn illness.",
        );
    }

    #[test]
    fn corrects_plural_cures_against() {
        assert_suggestion_result(
            "Doctors insist this serum cures against the new variant.",
            CureFor::default(),
            "Doctors insist this serum cures for the new variant.",
        );
    }

    #[test]
    fn corrects_past_participle_cured_against() {
        assert_suggestion_result(
            "The remedy was cured against the infection last spring.",
            CureFor::default(),
            "The remedy was cured for the infection last spring.",
        );
    }

    #[test]
    fn corrects_uppercase_against() {
        assert_suggestion_result(
            "We still trust the cure AGAINST the dreaded plague.",
            CureFor::default(),
            "We still trust the cure FOR the dreaded plague.",
        );
    }

    #[test]
    fn corrects_at_sentence_start() {
        assert_suggestion_result(
            "Cure against that condition became the rallying cry.",
            CureFor::default(),
            "Cure for that condition became the rallying cry.",
        );
    }

    #[test]
    fn does_not_flag_cure_for() {
        assert_lint_count(
            "They finally found a cure for the fever.",
            CureFor::default(),
            0,
        );
    }

    #[test]
    fn does_not_flag_cure_from() {
        assert_lint_count(
            "A cure from this rare herb is on the horizon.",
            CureFor::default(),
            0,
        );
    }

    #[test]
    fn does_not_flag_with_comma() {
        assert_lint_count(
            "A cure, against all odds, appeared in the files.",
            CureFor::default(),
            0,
        );
    }

    #[test]
    fn does_not_flag_unrelated_against() {
        assert_lint_count(
            "Travelers stand against the roaring wind on the cliffs.",
            CureFor::default(),
            0,
        );
    }

    #[test]
    fn does_not_flag_secure_against() {
        assert_lint_count(
            "The fortress stayed secure against the invaders.",
            CureFor::default(),
            0,
        );
    }
}



================================================
FILE: harper-core/src/linting/currency_placement.rs
================================================
use itertools::Itertools;

use crate::{Document, Span, Token, TokenStringExt, remove_overlaps};

use super::{Lint, LintKind, Linter, Suggestion};

#[derive(Debug, Default)]
pub struct CurrencyPlacement {}

impl Linter for CurrencyPlacement {
    fn lint(&mut self, document: &Document) -> Vec<Lint> {
        let mut lints = Vec::new();

        for chunk in document.iter_chunks() {
            for (a, b) in chunk.iter().tuple_windows() {
                lints.extend(generate_lint_for_tokens(a, b, document));
            }

            for (p, a, b, c) in chunk.iter().tuple_windows() {
                if !b.kind.is_whitespace() || p.kind.is_currency() {
                    continue;
                }

                lints.extend(generate_lint_for_tokens(a, c, document));
            }
        }

        remove_overlaps(&mut lints);

        lints
    }

    fn description(&self) -> &str {
        "The location of currency symbols varies by country. The rule looks for and corrects improper positioning."
    }
}

// Given two tokens that may have an error, check if they do and create a [`Lint`].
fn generate_lint_for_tokens(a: &Token, b: &Token, document: &Document) -> Option<Lint> {
    let punct = a.kind.as_punctuation().or(b.kind.as_punctuation())?;
    let currency = punct.as_currency()?;

    let number = a.kind.as_number().or(b.kind.as_number())?;

    let span = Span::new(a.span.start, b.span.end);

    let correct: Vec<_> = currency.format_amount(number).chars().collect();
    let actual = document.get_span_content(&span);

    if correct != actual {
        Some(Lint {
            span,
            lint_kind: LintKind::Formatting,
            suggestions: vec![Suggestion::ReplaceWith(correct)],
            message: "The position of the currency symbol matters.".to_string(),
            priority: 63,
        })
    } else {
        None
    }
}

#[cfg(test)]
mod tests {
    use crate::linting::tests::{assert_lint_count, assert_suggestion_result};

    use super::CurrencyPlacement;

    #[test]
    fn eof() {
        assert_suggestion_result(
            "It was my last bill worth more than 4$.",
            CurrencyPlacement::default(),
            "It was my last bill worth more than $4.",
        );
    }

    #[test]
    fn blog_title_allows_correct() {
        assert_lint_count("The Best $25 I Ever Spent", CurrencyPlacement::default(), 0);
    }

    #[test]
    fn blog_title() {
        assert_suggestion_result(
            "The Best 25$ I Ever Spent",
            CurrencyPlacement::default(),
            "The Best $25 I Ever Spent",
        );
    }

    #[test]
    fn blog_title_cents() {
        assert_suggestion_result(
            "The Best ¢25 I Ever Spent",
            CurrencyPlacement::default(),
            "The Best 25¢ I Ever Spent",
        );
    }

    #[test]
    fn blog_title_with_space() {
        assert_suggestion_result(
            "The Best 25   $ I Ever Spent",
            CurrencyPlacement::default(),
            "The Best $25 I Ever Spent",
        );
    }

    #[test]
    fn multiple_dollar() {
        assert_suggestion_result(
            "They were either 25\\$ 24\\$ or 23\\$.",
            CurrencyPlacement::default(),
            "They were either $25 $24 or $23.",
        );
    }

    #[test]
    fn multiple_pound() {
        assert_suggestion_result(
            "They were either 25£ 24£ or 23£.",
            CurrencyPlacement::default(),
            "They were either £25 £24 or £23.",
        );
    }

    #[test]
    fn suffix() {
        assert_suggestion_result(
            "It was my 20th$.",
            CurrencyPlacement::default(),
            "It was my $20th.",
        );
    }

    #[test]
    fn seven_even_two_decimal_clean() {
        assert_lint_count("$7.00", CurrencyPlacement::default(), 0);
    }
}



================================================
FILE: harper-core/src/linting/dashes.rs
================================================
use crate::expr::Expr;
use crate::expr::LongestMatchOf;
use crate::expr::SequenceExpr;
use crate::{Token, TokenStringExt};

use super::{ExprLinter, Lint, LintKind, Suggestion};
use crate::linting::expr_linter::Chunk;

const EN_DASH: char = '–';
const EM_DASH: char = '—';

pub struct Dashes {
    expr: Box<dyn Expr>,
}

impl Default for Dashes {
    fn default() -> Self {
        let en_dash = SequenceExpr::default().then_hyphen().then_hyphen();
        let em_dash_or_longer = SequenceExpr::default()
            .then_hyphen()
            .then_hyphen()
            .then_one_or_more_hyphens();

        let pattern = LongestMatchOf::new(vec![Box::new(em_dash_or_longer), Box::new(en_dash)]);

        Self {
            expr: Box::new(pattern),
        }
    }
}

impl ExprLinter for Dashes {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], _source: &[char]) -> Option<Lint> {
        let span = matched_tokens.span()?;
        let lint_kind = LintKind::Formatting;

        match matched_tokens.len() {
            2 => Some(Lint {
                span,
                lint_kind,
                suggestions: vec![Suggestion::ReplaceWith(vec![EN_DASH])],
                message: "Replace these two hyphens with an en dash (–).".to_owned(),
                priority: 63,
            }),
            3 => Some(Lint {
                span,
                lint_kind,
                suggestions: vec![Suggestion::ReplaceWith(vec![EM_DASH])],
                message: "Replace these three hyphens with an em dash (—).".to_owned(),
                priority: 63,
            }),
            4.. => None, // Ignore longer hyphen sequences.
            _ => panic!("Received unexpected number of tokens."),
        }
    }

    fn description(&self) -> &'static str {
        "Writers often type `--` or `---` expecting their editor to convert them into proper dashes. Replace these sequences with the correct characters: use an en dash (–) for ranges or connections and an em dash (—) for a break in thought."
    }
}

#[cfg(test)]
mod tests {
    use crate::linting::tests::{assert_suggestion_count, assert_suggestion_result};

    use super::Dashes;
    use super::{EM_DASH, EN_DASH};

    #[test]
    fn catches_en_dash() {
        assert_suggestion_result(
            "pre--Industrial Revolution",
            Dashes::default(),
            &format!("pre{EN_DASH}Industrial Revolution"),
        );
    }

    #[test]
    fn catches_em_dash() {
        assert_suggestion_result(
            "'There is no box' --- Scott",
            Dashes::default(),
            &format!("'There is no box' {EM_DASH} Scott"),
        );
    }

    #[test]
    fn no_overlaps() {
        assert_suggestion_count("'There is no box' --- Scott", Dashes::default(), 1);
    }

    #[test]
    fn no_lint_for_long_hyphen_sequences() {
        assert_suggestion_count("'There is no box' ------ Scott", Dashes::default(), 0);
    }
}



================================================
FILE: harper-core/src/linting/despite_it_is.rs
================================================
//! Linter for correcting "despite" used with incorrect verb forms.
//!
//! Handles cases like "despite it is" -> "despite it being" or "despite its being"

use crate::{
    CharStringExt, Token, TokenStringExt,
    dict_word_metadata::Person,
    expr::{Expr, SequenceExpr},
    linting::{ExprLinter, Lint, LintKind, Suggestion, expr_linter::Chunk},
    patterns::WordSet,
};

/// Linter that corrects incorrect verb forms after "despite".
///
/// For example:
/// - "despite it is" -> "despite it being" or "despite its being"
/// - "despite I am" -> "despite me being" or "despite my being"
pub struct DespiteItIs {
    expr: Box<dyn Expr>,
}

impl Default for DespiteItIs {
    fn default() -> Self {
        let subj = SequenceExpr::default().then_subject_pronoun();
        let be = WordSet::new(&["am", "are", "is", "was", "were"]);

        let expr = SequenceExpr::aco("despite")
            .t_ws()
            .then(subj)
            .t_ws()
            .then(be);

        Self {
            expr: Box::new(expr),
        }
    }
}

impl ExprLinter for DespiteItIs {
    type Unit = Chunk;

    fn description(&self) -> &'static str {
        "Corrects `despite` being used with the wrong form of `is`."
    }

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint_with_context(
        &self,
        toks: &[Token],
        src: &[char],
        ctx: Option<(&[Token], &[Token])>,
    ) -> Option<Lint> {
        let next_is_ing = ctx.is_some_and(|(_, then)| {
            then.first().is_some_and(|t| t.kind.is_whitespace())
                && then
                    .get(1)
                    .is_some_and(|t| t.kind.is_verb_progressive_form())
        });

        let subj = toks.get(2)?;
        let be = toks.get(4)?;

        let subj_kind = &subj.kind;

        // Only handle personal subject pronouns
        if !(subj_kind.is_personal_pronoun() && subj_kind.is_subject_pronoun()) {
            return None;
        }

        let subj_chars = subj.span.get_content(src);
        let be_chars = be.span.get_content(src);
        let pron_be_toks = &toks[2..5];

        let subj_pers = subj_kind.get_pronoun_person()?;

        // BUT BUT BUT
        // despite I  am happy   -> me/my  being happy
        // despite I  am eating  -> me/my        eating
        // despite it is big     ->        being
        //                       -> it/its being big
        // despite it is running -> it           running
        //                       -> it/its       running

        let (obj, poss) = match (
            subj_pers,
            subj_kind.is_singular_pronoun(),
            subj_kind.is_plural_pronoun(),
        ) {
            (Person::First, true, false) => ("me", "my"),
            (Person::First, false, true) => ("us", "our"),
            (Person::Second, true, true) => ("you", "your"),
            (Person::Third, false, true) => ("them", "their"),
            (Person::Third, true, false) => match subj_chars {
                chs if chs.eq_ignore_ascii_case_chars(&['h', 'e']) => ("him", "his"),
                chs if chs.eq_ignore_ascii_case_chars(&['s', 'h', 'e']) => ("her", "her"),
                chs if chs.eq_ignore_ascii_case_chars(&['i', 't']) => ("it", "its"),
                _ => return None,
            },
            _ => return None,
        };

        let mut suggestions = Vec::with_capacity(3);

        // Special case for "it" which can also be omitted
        if subj_chars.eq_any_ignore_ascii_case_str(&["it", "they"]) {
            suggestions.push(Suggestion::replace_with_match_case_str("being", be_chars));
        }

        let [obj_vec, poss_vec] = [obj, poss].map(|pron| {
            if !next_is_ing {
                format!("{} being", pron).chars().collect()
            } else {
                pron.chars().collect()
            }
        });

        suggestions.push(Suggestion::replace_with_match_case(obj_vec, be_chars));
        suggestions.push(Suggestion::replace_with_match_case(poss_vec, be_chars));

        if suggestions.is_empty() {
            return None;
        }

        let span_to_replace = pron_be_toks.span()?;

        Some(Lint {
            span: span_to_replace,
            lint_kind: LintKind::Grammar,
            suggestions,
            message: "Use the gerund form of the verb after `despite`.".into(),
            ..Lint::default()
        })
    }
}

#[cfg(test)]
mod tests {
    use super::DespiteItIs;
    use crate::linting::tests::{assert_good_and_bad_suggestions, assert_no_lints};

    #[test]
    fn despite_i_am() {
        assert_good_and_bad_suggestions(
            "Cronicle shuts down randomly despite I am running simple Python scripts via \"Test Plugin\"",
            DespiteItIs::default(),
            &[
                "Cronicle shuts down randomly despite me running simple Python scripts via \"Test Plugin\"",
                "Cronicle shuts down randomly despite my running simple Python scripts via \"Test Plugin\"",
            ],
            &[],
        );
    }

    #[test]
    fn despite_it_is_available() {
        assert_good_and_bad_suggestions(
            "Actual behavior Extension not installed despite it is available in PECL",
            DespiteItIs::default(),
            &[
                "Actual behavior Extension not installed despite being available in PECL",
                "Actual behavior Extension not installed despite it being available in PECL",
                "Actual behavior Extension not installed despite its being available in PECL",
            ],
            &[],
        );
    }

    #[test]
    fn despite_it_is_detected() {
        assert_good_and_bad_suggestions(
            "FP2 not detected despite it is detected - split brain?",
            DespiteItIs::default(),
            &[
                "FP2 not detected despite being detected - split brain?",
                "FP2 not detected despite it being detected - split brain?",
                "FP2 not detected despite its being detected - split brain?",
            ],
            &[],
        );
    }

    #[test]
    fn despite_i_am_in() {
        assert_good_and_bad_suggestions(
            "My application was rejected due to location basis despite I am in the same city as my campus.",
            DespiteItIs::default(),
            &[
                "My application was rejected due to location basis despite me being in the same city as my campus.",
                "My application was rejected due to location basis despite my being in the same city as my campus.",
            ],
            &[],
        );
    }

    #[test]
    #[ignore = "negatives are not handled yet"]
    fn despite_it_was_not() {
        assert_good_and_bad_suggestions(
            "despite it was not able to fulfill desired ordering with these modules",
            DespiteItIs::default(),
            &[
                "despite it not being able to fulfill desired ordering with these modules",
                "despite its not being able to fulfill desired ordering with these modules",
                "despite not being able to fulfill desired ordering with these modules",
            ],
            &[],
        );
    }

    #[test]
    fn despite_we_are_using() {
        assert_good_and_bad_suggestions(
            "However, GFW still can decode the content despite we are using overlapped ip fragmentation.",
            DespiteItIs::default(),
            &[
                "However, GFW still can decode the content despite us using overlapped ip fragmentation.",
                "However, GFW still can decode the content despite our using overlapped ip fragmentation.",
            ],
            &[],
        );
    }

    #[test]
    fn despite_they_are_already() {
        assert_good_and_bad_suggestions(
            "v5.7.2 keeps adding temperature commands on start_gcode despite they are already present",
            DespiteItIs::default(),
            &[
                "v5.7.2 keeps adding temperature commands on start_gcode despite them being already present",
                "v5.7.2 keeps adding temperature commands on start_gcode despite their being already present",
            ],
            &[],
        );
    }

    #[test]
    fn despite_it_was_removed() {
        assert_good_and_bad_suggestions(
            "Freshwater Research Station is selectable as starting location despite it was removed by Dark Days of the Dead mod",
            DespiteItIs::default(),
            &[
                "Freshwater Research Station is selectable as starting location despite being removed by Dark Days of the Dead mod",
                // TODO: Freshwater Research Station is selectable as starting location despite having been removed by Dark Days of the Dead mod
                "Freshwater Research Station is selectable as starting location despite it being removed by Dark Days of the Dead mod",
                // TODO: Freshwater Research Station is selectable as starting location despite it having been removed by Dark Days of the Dead mod
                "Freshwater Research Station is selectable as starting location despite its being removed by Dark Days of the Dead mod",
                // TODO: Freshwater Research Station is selectable as starting location despite its having been removed by Dark Days of the Dead mod
            ],
            &[],
        );
    }

    #[test]
    fn ignore_despite_they_shouldnt() {
        assert_no_lints(
            "Some tools and gears have attack damage values despite they shouldn't",
            DespiteItIs::default(),
        );
    }

    #[test]
    fn ignore_despite_i_was_playing() {
        assert_good_and_bad_suggestions(
            "it showed me Maria despite I was playing someone else",
            DespiteItIs::default(),
            &[
                "it showed me Maria despite me playing someone else",
                "it showed me Maria despite my playing someone else",
            ],
            &[],
        );
    }

    #[test]
    fn ignore_despite_they_were_valid() {
        assert_good_and_bad_suggestions(
            "You'll get pages that becomes invalid with time despite they were valid before",
            DespiteItIs::default(),
            &[
                "You'll get pages that becomes invalid with time despite being valid before",
                "You'll get pages that becomes invalid with time despite them being valid before",
                "You'll get pages that becomes invalid with time despite their being valid before",
            ],
            &[],
        );
    }
}



================================================
FILE: harper-core/src/linting/despite_of.rs
================================================
use crate::expr::Expr;
use crate::expr::SequenceExpr;
use crate::{Token, TokenStringExt};

use super::{ExprLinter, Lint, LintKind, Suggestion};
use crate::linting::expr_linter::Chunk;

pub struct DespiteOf {
    expr: Box<dyn Expr>,
}

impl Default for DespiteOf {
    fn default() -> Self {
        let pattern = SequenceExpr::aco("despite")
            .then_whitespace()
            .then_exact_word("of");

        Self {
            expr: Box::new(pattern),
        }
    }
}

impl ExprLinter for DespiteOf {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched: &[Token], source: &[char]) -> Option<Lint> {
        let span = matched.span()?;
        let matched = span.get_content(source);

        Some(Lint {
            span,
            lint_kind: LintKind::WordChoice,
            suggestions: vec![
                Suggestion::replace_with_match_case_str("despite", matched),
                Suggestion::replace_with_match_case_str("in spite of", matched)
            ],
            message: "The phrase “despite of” is incorrect. Please use either “despite” or “in spite of” instead.".to_string(),
            priority: 126,
        })
    }

    fn description(&self) -> &'static str {
        "Corrects the misuse of `despite of` and suggests the proper alternatives `despite` or `in spite of`."
    }
}

#[cfg(test)]
mod tests {
    use super::DespiteOf;
    use crate::linting::tests::{assert_lint_count, assert_suggestion_result};

    #[test]
    fn catches_lowercase() {
        assert_suggestion_result(
            "The team performed well, despite of the difficulties they faced.",
            DespiteOf::default(),
            "The team performed well, despite the difficulties they faced.",
        );
    }

    #[test]
    fn catches_different_cases() {
        assert_lint_count(
            "Despite of the rain, we went for a walk.",
            DespiteOf::default(),
            1,
        );
    }

    #[test]
    fn likes_correction() {
        assert_lint_count(
            "The team performed well, despite the difficulties they faced. In spite of the rain, we went for a walk.",
            DespiteOf::default(),
            0,
        );
    }
}



================================================
FILE: harper-core/src/linting/determiner_without_noun.rs
================================================
use crate::expr::Expr;
use crate::expr::SequenceExpr;
use crate::{Token, TokenStringExt};

use super::{ExprLinter, Lint, LintKind, Suggestion};
use crate::linting::expr_linter::Chunk;

pub struct DeterminerWithoutNoun {
    expr: Box<dyn Expr>,
}

impl Default for DeterminerWithoutNoun {
    fn default() -> Self {
        let expr = SequenceExpr::default()
            .then_kind_where(|kind| kind.is_determiner())
            .t_ws()
            .then_conjunction();

        Self {
            expr: Box::new(expr),
        }
    }
}

impl ExprLinter for DeterminerWithoutNoun {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], _source: &[char]) -> Option<Lint> {
        let span = matched_tokens.span()?;
        Some(Lint {
            span,
            lint_kind: LintKind::Miscellaneous,
            suggestions: Vec::<Suggestion>::new(),
            message: "A determiner should not be immediately followed by a conjunction."
                .to_string(),
            priority: 32,
        })
    }

    fn description(&self) -> &'static str {
        "Flags sequences where a determiner (`a`, `an`, `the`, etc.) is directly followed by a coordinating or subordinating conjunction (`and`, `or`, `but`, `because`, etc.), indicating a missing noun."
    }
}

#[cfg(test)]
mod tests {
    use super::DeterminerWithoutNoun;
    use crate::linting::tests::assert_lint_count;

    #[test]
    fn flags_determiner_followed_by_conjunction() {
        assert_lint_count(
            "The and other options were ignored.",
            DeterminerWithoutNoun::default(),
            1,
        );
    }

    #[test]
    fn flags_indefinite_article_followed_by_conjunction() {
        assert_lint_count("A because I said so.", DeterminerWithoutNoun::default(), 1);
        assert_lint_count("An because I said so.", DeterminerWithoutNoun::default(), 1);
    }

    #[test]
    fn allows_correct_use_with_noun() {
        assert_lint_count("The dog barked.", DeterminerWithoutNoun::default(), 0);
    }

    #[test]
    fn allows_determiner_noun_then_conjunction() {
        assert_lint_count(
            "The dog and the cat played.",
            DeterminerWithoutNoun::default(),
            0,
        );
    }
}



================================================
FILE: harper-core/src/linting/didnt.rs
================================================
use crate::Token;
use crate::expr::{Expr, SequenceExpr};
use crate::linting::expr_linter::Chunk;
use crate::linting::{ExprLinter, Lint, LintKind, Suggestion};

pub struct Didnt {
    expr: Box<dyn Expr>,
}

impl Default for Didnt {
    fn default() -> Self {
        let pattern = SequenceExpr::default()
            .then_subject_pronoun()
            .t_ws()
            .t_aco("dint");

        Self {
            expr: Box::new(pattern),
        }
    }
}

impl ExprLinter for Didnt {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, toks: &[Token], src: &[char]) -> Option<Lint> {
        let suspect = toks.last()?;

        Some(Lint {
            span: suspect.span,
            lint_kind: LintKind::Typo,
            suggestions: vec![Suggestion::replace_with_match_case_str(
                "didn't",
                suspect.span.get_content(src),
            )],
            message: "Consider using `didn't` here.".to_string(),
            priority: 63,
        })
    }

    fn description(&self) -> &str {
        "Corrects `dint` to `didn't` after subject pronouns."
    }
}

#[cfg(test)]
mod tests {
    use super::Didnt;
    use crate::linting::tests::{assert_lint_count, assert_no_lints, assert_suggestion_result};

    #[test]
    fn corrects_i_dint() {
        assert_suggestion_result(
            "I dint lock the gate.",
            Didnt::default(),
            "I didn't lock the gate.",
        );
    }

    #[test]
    fn corrects_you_dint() {
        assert_suggestion_result(
            "You dint look this way.",
            Didnt::default(),
            "You didn't look this way.",
        );
    }

    #[test]
    fn corrects_he_dint() {
        assert_suggestion_result(
            "He dint see the sign.",
            Didnt::default(),
            "He didn't see the sign.",
        );
    }

    #[test]
    fn corrects_she_dint() {
        assert_suggestion_result(
            "She dint call me back.",
            Didnt::default(),
            "She didn't call me back.",
        );
    }

    #[test]
    fn corrects_we_dint() {
        assert_suggestion_result(
            "We dint sleep much.",
            Didnt::default(),
            "We didn't sleep much.",
        );
    }

    #[test]
    fn corrects_they_dint() {
        assert_suggestion_result(
            "They dint enjoy the show.",
            Didnt::default(),
            "They didn't enjoy the show.",
        );
    }

    #[test]
    fn corrects_it_dint() {
        assert_suggestion_result(
            "It dint rain today.",
            Didnt::default(),
            "It didn't rain today.",
        );
    }

    #[test]
    fn does_not_flag_dint_noun() {
        assert_no_lints("The blow left a small dint in the metal.", Didnt::default());
    }

    #[test]
    fn does_not_flag_quoted_dint() {
        assert_no_lints("He muttered 'dint' under his breath.", Didnt::default());
    }

    #[test]
    fn does_not_flag_past_tense_with_not() {
        assert_lint_count("I did not lock the gate.", Didnt::default(), 0);
    }
}



================================================
FILE: harper-core/src/linting/discourse_markers.rs
================================================
use harper_brill::UPOS;

use crate::expr::{Expr, FirstMatchOf, FixedPhrase, SequenceExpr};
use crate::patterns::UPOSSet;
use crate::{Document, Token, TokenStringExt};

use super::{Lint, LintKind, Linter, Suggestion};

pub struct DiscourseMarkers {
    expr: SequenceExpr,
}

impl DiscourseMarkers {
    pub fn new() -> Self {
        let phrases = &[
            "however",
            "therefore",
            "meanwhile",
            "furthermore",
            "nevertheless",
            "consequently",
            "thus",
            "instead",
            "moreover",
            "honestly",
            "alternatively",
            "frankly",
            "additionally",
            "subsequently",
            "accordingly",
            "otherwise",
            "incidentally",
            "conversely",
            "notwithstanding",
            "hence",
            "indeed",
            "for example",
            "on the other hand",
        ];

        let phrases_expr = FirstMatchOf::new(
            phrases
                .iter()
                .map(|text: &&str| Box::new(FixedPhrase::from_phrase(text)) as Box<dyn Expr>)
                .collect(),
        );

        Self {
            expr: SequenceExpr::default()
                .then(phrases_expr)
                .t_ws()
                .then_unless(UPOSSet::new(&[UPOS::ADJ, UPOS::ADV, UPOS::ADP])),
        }
    }

    fn lint_sentence(&self, sent: &[Token], source: &[char]) -> Option<Lint> {
        let first_word_idx = sent.iter_word_indices().next()?;

        if let Some(matched_phrase) = self.expr.run(first_word_idx, sent, source) {
            Some(Lint {
                span: sent[matched_phrase.start..matched_phrase.end - 2].span()?,
                lint_kind: LintKind::Punctuation,
                suggestions: vec![Suggestion::InsertAfter(vec![','])],
                message: "Discourse markers at the beginning of a sentence should be followed by a comma.".into(),
                priority: 31,
            })
        } else {
            None
        }
    }
}

impl Default for DiscourseMarkers {
    fn default() -> Self {
        Self::new()
    }
}

impl Linter for DiscourseMarkers {
    fn lint(&mut self, document: &Document) -> Vec<Lint> {
        document
            .iter_sentences()
            .flat_map(|sent| self.lint_sentence(sent, document.get_source()))
            .collect()
    }

    fn description(&self) -> &str {
        "Flags sentences that begin with a discourse marker but omit the required following comma."
    }
}

#[cfg(test)]
mod tests {
    use crate::linting::tests::{assert_no_lints, assert_suggestion_result};

    use super::DiscourseMarkers;

    #[test]
    fn corrects_frankly() {
        assert_suggestion_result(
            "Frankly I think he is wrong.",
            DiscourseMarkers::default(),
            "Frankly, I think he is wrong.",
        );
    }

    #[test]
    fn corrects_however() {
        assert_suggestion_result(
            "However I disagree with your conclusion.",
            DiscourseMarkers::default(),
            "However, I disagree with your conclusion.",
        );
    }

    #[test]
    fn corrects_therefore() {
        assert_suggestion_result(
            "Therefore we must act now.",
            DiscourseMarkers::default(),
            "Therefore, we must act now.",
        );
    }

    #[test]
    fn corrects_meanwhile() {
        assert_suggestion_result(
            "Meanwhile preparations continued in the background.",
            DiscourseMarkers::default(),
            "Meanwhile, preparations continued in the background.",
        );
    }

    #[test]
    fn corrects_furthermore() {
        assert_suggestion_result(
            "Furthermore this approach reduces complexity.",
            DiscourseMarkers::default(),
            "Furthermore, this approach reduces complexity.",
        );
    }

    #[test]
    fn corrects_nevertheless() {
        assert_suggestion_result(
            "Nevertheless we persevered despite the odds.",
            DiscourseMarkers::default(),
            "Nevertheless, we persevered despite the odds.",
        );
    }

    #[test]
    fn corrects_consequently() {
        assert_suggestion_result(
            "Consequently the system halted unexpectedly.",
            DiscourseMarkers::default(),
            "Consequently, the system halted unexpectedly.",
        );
    }

    #[test]
    fn corrects_thus() {
        assert_suggestion_result(
            "Thus we arrive at the final verdict.",
            DiscourseMarkers::default(),
            "Thus, we arrive at the final verdict.",
        );
    }

    #[test]
    fn allows_thus_far() {
        assert_no_lints(
            "Thus far there have been no problems.",
            DiscourseMarkers::default(),
        );
    }

    #[test]
    fn corrects_instead() {
        assert_suggestion_result(
            "Instead he chose a different path.",
            DiscourseMarkers::default(),
            "Instead, he chose a different path.",
        );
    }

    #[test]
    fn corrects_moreover() {
        assert_suggestion_result(
            "Moreover this solution is more efficient.",
            DiscourseMarkers::default(),
            "Moreover, this solution is more efficient.",
        );
    }

    #[test]
    fn corrects_alternatively() {
        assert_suggestion_result(
            "Alternatively we could defer the decision.",
            DiscourseMarkers::default(),
            "Alternatively, we could defer the decision.",
        );
    }

    #[test]
    fn no_suggestion_if_comma_present() {
        assert_no_lints(
            "However, I disagree with your point.",
            DiscourseMarkers::default(),
        );
    }

    #[test]
    fn no_lint_for_mid_sentence_marker() {
        assert_no_lints(
            "I said however I would consider it.",
            DiscourseMarkers::default(),
        );
    }

    #[test]
    fn preserves_whitespace() {
        assert_suggestion_result(
            "However   I disagree.",
            DiscourseMarkers::default(),
            "However,   I disagree.",
        );
    }

    #[test]
    fn corrects_semicolon_case() {
        assert_suggestion_result(
            "However I disagree.",
            DiscourseMarkers::default(),
            "However, I disagree.",
        );
    }

    #[test]
    fn corrects_multiple_sentences() {
        assert_suggestion_result(
            "However I disagree. Therefore I propose an alternative.",
            DiscourseMarkers::default(),
            "However, I disagree. Therefore, I propose an alternative.",
        );
    }

    #[test]
    fn allows_single_word_sentence() {
        assert_no_lints("Thus", DiscourseMarkers::default());
    }

    #[test]
    fn corrects_for_example() {
        assert_suggestion_result(
            "For example I recommend updating the configuration.",
            DiscourseMarkers::default(),
            "For example, I recommend updating the configuration.",
        );
    }

    #[test]
    fn no_suggestion_if_comma_after_for_example() {
        assert_no_lints(
            "For example, I recommend updating the configuration.",
            DiscourseMarkers::default(),
        );
    }

    #[test]
    fn preserves_whitespace_for_example() {
        assert_suggestion_result(
            "For example   the outcome was unexpected.",
            DiscourseMarkers::default(),
            "For example,   the outcome was unexpected.",
        );
    }

    #[test]
    fn corrects_on_the_other_hand() {
        assert_suggestion_result(
            "On the other hand we could delay the deployment.",
            DiscourseMarkers::default(),
            "On the other hand, we could delay the deployment.",
        );
    }

    #[test]
    fn no_lint_for_mid_sentence_on_the_other_hand() {
        assert_no_lints(
            "We might postpone, on the other hand this introduces risk.",
            DiscourseMarkers::default(),
        );
    }
}



================================================
FILE: harper-core/src/linting/disjoint_prefixes.rs
================================================
use crate::{
    Lint, Token, TokenKind, TokenStringExt,
    expr::{Expr, OwnedExprExt, SequenceExpr},
    linting::{ExprLinter, LintKind, Suggestion, expr_linter::Chunk},
    spell::Dictionary,
};

pub struct DisjointPrefixes<D> {
    expr: Box<dyn Expr>,
    dict: D,
}

// Known false positives not to join to these prefixes:
const OUT_EXCEPTIONS: &[&str] = &["boxes", "facing", "live", "numbers", "playing"];
const OVER_EXCEPTIONS: &[&str] = &["all", "joy", "long", "night", "reading", "steps", "time"];
const UNDER_EXCEPTIONS: &[&str] = &["development", "mine"];
const UP_EXCEPTIONS: &[&str] = &["loading", "right", "state", "time", "trend"];

impl<D> DisjointPrefixes<D>
where
    D: Dictionary,
{
    pub fn new(dict: D) -> Self {
        Self {
            expr: Box::new(
                SequenceExpr::word_set(&[
                    // These prefixes rarely cause false positives
                    "anti", "auto", "bi", "counter", "de", "dis", "extra", "fore", "hyper", "il",
                    "im", "inter", "ir", "macro", "mal", "micro", "mid", "mini", "mis", "mono",
                    "multi", "non", "omni", "post", "pre", "pro", "re", "semi", "sub", "super",
                    "trans", "tri", "ultra", "un", "uni",
                    // "co" has one very common false positive: co-op != coop
                    "co",
                    // These prefixes are all also words in their own right, which leads to more false positives.
                    "out", "over", "under",
                    "up",
                    // These prefixes are commented out due to too many false positives
                    // or incorrect transformations:
                    // "a": a live -> alive
                    // "in": in C -> inc; in action -> inaction
                ])
                .t_ws_h()
                .then_kind_either(TokenKind::is_verb, TokenKind::is_noun)
                .then_optional_hyphen()
                .and_not(SequenceExpr::any_of(vec![
                    // No trailing hyphen. Ex: Custom patterns take precedence over built-in patterns -> overbuilt
                    Box::new(SequenceExpr::anything().t_any().t_any().then_hyphen()),
                    // Don't merge "co op" whether separated by space or hyphen.
                    Box::new(SequenceExpr::aco("co").t_any().t_set(&["op", "ops"])),
                    // Merge these if they're separated by hyphen, but not space.
                    Box::new(SequenceExpr::aco("out").t_ws().t_set(OUT_EXCEPTIONS)),
                    Box::new(SequenceExpr::aco("over").t_ws().t_set(OVER_EXCEPTIONS)),
                    Box::new(SequenceExpr::aco("under").t_ws().t_set(UNDER_EXCEPTIONS)),
                    Box::new(SequenceExpr::aco("up").t_ws().t_set(UP_EXCEPTIONS)),
                ])),
            ),
            dict,
        }
    }
}

impl<D> ExprLinter for DisjointPrefixes<D>
where
    D: Dictionary,
{
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint_with_context(
        &self,
        toks: &[Token],
        src: &[char],
        ctx: Option<(&[Token], &[Token])>,
    ) -> Option<Lint> {
        let toks_span = toks.span()?;
        let (pre, _) = ctx?;

        // Cloud Native Pub-Sub System at Pinterest -> subsystem
        if pre.last().is_some_and(|p| p.kind.is_hyphen()) {
            return None;
        }

        // Avoid including text from unlintable sections between tokens
        // that could result from naively using toks.span()?.get_content_string(src)
        let original = format!(
            "{}{}{}",
            toks[0].span.get_content_string(src),
            if toks[1].kind.is_hyphen() { '-' } else { ' ' },
            toks[2].span.get_content_string(src)
        );

        // If the original form is in the dictionary, return None
        if self.dict.contains_word_str(&original) {
            return None;
        }

        let mut hyphenated = None;
        if !toks[1].kind.is_hyphen() {
            hyphenated = Some(format!(
                "{}-{}",
                toks[0].span.get_content_string(src),
                toks[2].span.get_content_string(src)
            ));
        }
        let joined = Some(format!(
            "{}{}",
            toks[0].span.get_content_string(src),
            toks[2].span.get_content_string(src)
        ));

        // Check if either joined or hyphenated form is in the dictionary
        let joined_valid = joined
            .as_ref()
            .is_some_and(|j| self.dict.contains_word_str(j));
        let hyphenated_valid = hyphenated
            .as_ref()
            .is_some_and(|h| self.dict.contains_word_str(h));

        if !joined_valid && !hyphenated_valid {
            return None;
        }

        // Joining with a hyphen when original is separated by space is more likely correct
        //   if hyphenated form is in the dictionary. So add first if verified.
        // Joining when separated by a space is more common but also has more false positives, so add them second.
        let suggestions = [(&hyphenated, hyphenated_valid), (&joined, joined_valid)]
            .into_iter()
            .filter_map(|(word, is_valid)| word.as_ref().filter(|_| is_valid))
            .collect::<Vec<_>>();

        let suggestions = suggestions
            .iter()
            .map(|s| {
                Suggestion::replace_with_match_case(s.chars().collect(), toks_span.get_content(src))
            })
            .collect();

        Some(Lint {
            span: toks_span,
            lint_kind: LintKind::Spelling,
            suggestions,
            message: "This looks like a prefix that can be joined with the rest of the word."
                .to_string(),
            ..Default::default()
        })
    }

    fn description(&self) -> &str {
        "Looks for words with their prefixes written with a space or hyphen between instead of joined."
    }
}

#[cfg(test)]
mod tests {
    use super::DisjointPrefixes;
    use crate::{
        linting::tests::{assert_no_lints, assert_suggestion_result},
        spell::FstDictionary,
    };

    #[test]
    fn fix_hyphenated_to_joined() {
        assert_suggestion_result(
            "Download pre-built binaries or build from source.",
            DisjointPrefixes::new(FstDictionary::curated()),
            "Download prebuilt binaries or build from source.",
        );
    }

    #[test]
    fn fix_open_to_joined() {
        assert_suggestion_result(
            "Advanced Nginx configuration available for super users",
            DisjointPrefixes::new(FstDictionary::curated()),
            "Advanced Nginx configuration available for superusers",
        );
    }

    #[test]
    fn dont_join_open_co_op() {
        assert_no_lints(
            "They are cheaper at the co op.",
            DisjointPrefixes::new(FstDictionary::curated()),
        );
    }

    #[test]
    fn dont_join_hyphenated_co_op() {
        assert_no_lints(
            "Almost everything is cheaper at the co-op.",
            DisjointPrefixes::new(FstDictionary::curated()),
        );
    }

    #[test]
    fn fix_open_to_hyphenated() {
        assert_suggestion_result(
            "My hobby is de extinction of the dinosaurs.",
            DisjointPrefixes::new(FstDictionary::curated()),
            "My hobby is de-extinction of the dinosaurs.",
        );
    }
}



================================================
FILE: harper-core/src/linting/dot_initialisms.rs
================================================
use crate::expr::Expr;
use crate::expr::SequenceExpr;
use crate::expr::WordExprGroup;
use hashbrown::HashMap;

use super::{ExprLinter, Lint, LintKind, Suggestion};
use crate::linting::expr_linter::Chunk;
use crate::{Token, TokenStringExt};

pub struct DotInitialisms {
    expr: Box<dyn Expr>,
    corrections: HashMap<&'static str, &'static str>,
}

impl Default for DotInitialisms {
    fn default() -> Self {
        let mut patterns = WordExprGroup::default();

        let mut corrections = HashMap::new();
        corrections.insert("ie", "i.e.");
        corrections.insert("eg", "e.g.");

        for target in corrections.keys() {
            let pattern = SequenceExpr::default()
                .then_exact_word(target)
                .then_punctuation();

            patterns.add(target, pattern);
        }

        Self {
            expr: Box::new(patterns),
            corrections,
        }
    }
}

impl ExprLinter for DotInitialisms {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], source: &[char]) -> Option<Lint> {
        let found_word_tok = matched_tokens.first()?;
        let found_word = found_word_tok.span.get_content_string(source);

        let correction = self.corrections.get(found_word.as_str())?;

        Some(Lint {
            span: matched_tokens.span()?,
            lint_kind: LintKind::Formatting,
            suggestions: vec![Suggestion::ReplaceWith(correction.chars().collect())],
            message: "Initialisms should have dot-separated letters.".to_owned(),
            priority: 63,
        })
    }

    fn description(&self) -> &'static str {
        "Ensures common initialisms (like \"i.e.\") are properly dot-separated."
    }
}

#[cfg(test)]
mod tests {
    use super::DotInitialisms;
    use crate::linting::tests::assert_suggestion_result;

    #[test]
    fn matches_eg() {
        assert_suggestion_result(
            "Some text here (eg. more text).",
            DotInitialisms::default(),
            "Some text here (e.g. more text).",
        )
    }
}



================================================
FILE: harper-core/src/linting/double_click.rs
================================================
use std::sync::Arc;

use crate::linting::expr_linter::Chunk;
use crate::{
    Token, TokenKind, TokenStringExt,
    expr::{Expr, ExprMap, SequenceExpr},
    linting::{ExprLinter, Lint, LintKind, Suggestion},
};

pub struct DoubleClick {
    expr: Box<dyn Expr>,
    map: Arc<ExprMap<usize>>,
}

impl DoubleClick {
    fn double_click_sequence() -> SequenceExpr {
        SequenceExpr::default()
            .t_aco("double")
            .t_ws()
            .then_word_set(&["click", "clicked", "clicking", "clicks"])
    }
}

impl Default for DoubleClick {
    fn default() -> Self {
        let mut map = ExprMap::default();

        map.insert(
            SequenceExpr::default()
                .then_seq(Self::double_click_sequence())
                .t_ws()
                .then_any_word(),
            0,
        );

        map.insert(
            SequenceExpr::default()
                .then_seq(Self::double_click_sequence())
                .then_punctuation(),
            0,
        );

        map.insert(
            SequenceExpr::default()
                .then_seq(Self::double_click_sequence())
                .t_ws()
                .then_kind_is_but_is_not(TokenKind::is_word, TokenKind::is_verb),
            0,
        );

        let map = Arc::new(map);

        Self {
            expr: Box::new(map.clone()),
            map,
        }
    }
}

impl ExprLinter for DoubleClick {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], source: &[char]) -> Option<Lint> {
        let double_idx = *self.map.lookup(0, matched_tokens, source)?;
        let click_idx = 2;
        let span = matched_tokens.get(double_idx..=click_idx)?.span()?;
        let template = span.get_content(source);

        let double_word = matched_tokens.get(double_idx)?.span.get_content(source);
        let click_word = matched_tokens.get(click_idx)?.span.get_content(source);

        let replacement: Vec<char> = double_word
            .iter()
            .copied()
            .chain(['-'])
            .chain(click_word.iter().copied())
            .collect();

        Some(Lint {
            span,
            lint_kind: LintKind::Punctuation,
            suggestions: vec![Suggestion::replace_with_match_case(replacement, template)],
            message: "Add a hyphen to this command.".to_owned(),
            priority: 40,
        })
    }

    fn description(&self) -> &'static str {
        "Encourages hyphenating `double-click` and its inflections."
    }
}

#[cfg(test)]
mod tests {
    use super::DoubleClick;
    use crate::linting::tests::{assert_lint_count, assert_suggestion_result};

    #[test]
    fn corrects_basic_command() {
        assert_suggestion_result(
            "Double click the icon.",
            DoubleClick::default(),
            "Double-click the icon.",
        );
    }

    #[test]
    fn corrects_with_preposition() {
        assert_suggestion_result(
            "Please double click on the link.",
            DoubleClick::default(),
            "Please double-click on the link.",
        );
    }

    #[test]
    fn corrects_with_pronoun() {
        assert_suggestion_result(
            "You should double click it to open.",
            DoubleClick::default(),
            "You should double-click it to open.",
        );
    }

    #[test]
    fn corrects_plural_form() {
        assert_suggestion_result(
            "Double clicks are recorded in the log.",
            DoubleClick::default(),
            "Double-clicks are recorded in the log.",
        );
    }

    #[test]
    fn corrects_past_tense() {
        assert_suggestion_result(
            "They double clicked the submit button.",
            DoubleClick::default(),
            "They double-clicked the submit button.",
        );
    }

    #[test]
    fn corrects_gerund() {
        assert_suggestion_result(
            "Double clicking the item highlights it.",
            DoubleClick::default(),
            "Double-clicking the item highlights it.",
        );
    }

    #[test]
    fn corrects_with_caps() {
        assert_suggestion_result(
            "He DOUBLE CLICKED the file.",
            DoubleClick::default(),
            "He DOUBLE-CLICKED the file.",
        );
    }

    #[test]
    fn corrects_multiline() {
        assert_suggestion_result(
            "Double\nclick the checkbox.",
            DoubleClick::default(),
            "Double-click the checkbox.",
        );
    }

    #[test]
    fn corrects_at_sentence_end() {
        assert_suggestion_result(
            "Just double click.",
            DoubleClick::default(),
            "Just double-click.",
        );
    }

    #[test]
    fn allows_hyphenated_form() {
        assert_lint_count("Double-click the icon.", DoubleClick::default(), 0);
    }

    #[test]
    fn ignores_other_double_words() {
        assert_lint_count(
            "She said the double rainbow was beautiful.",
            DoubleClick::default(),
            0,
        );
    }
}



================================================
FILE: harper-core/src/linting/double_modal.rs
================================================
use crate::expr::Expr;
use crate::expr::SequenceExpr;
use crate::patterns::ModalVerb;
use crate::{Token, TokenStringExt};

use super::Suggestion;
use super::{ExprLinter, Lint, LintKind};
use crate::linting::expr_linter::Chunk;

pub struct DoubleModal {
    expr: Box<dyn Expr>,
}

impl Default for DoubleModal {
    fn default() -> Self {
        let expr = SequenceExpr::default()
            .then(ModalVerb::default())
            .t_ws()
            .then(ModalVerb::default());

        Self {
            expr: Box::new(expr),
        }
    }
}

impl ExprLinter for DoubleModal {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], source: &[char]) -> Option<Lint> {
        let first_chars = matched_tokens.first()?.span.get_content(source);
        let second_chars = matched_tokens.last()?.span.get_content(source);

        Some(Lint {
            span: matched_tokens.span()?,
            lint_kind: LintKind::Miscellaneous,
            suggestions: vec![
                Suggestion::ReplaceWith(first_chars.into()),
                Suggestion::ReplaceWith(second_chars.into()),
            ],
            message: "Two modal verbs in a row are rarely grammatical; remove one.".to_string(),
            priority: 31,
        })
    }

    fn description(&self) -> &'static str {
        "Two modal verbs in a row are rarely grammatical; remove one of them."
    }
}

#[cfg(test)]
mod tests {
    use super::DoubleModal;
    use crate::linting::tests::{assert_lint_count, assert_no_lints, assert_suggestion_result};

    #[test]
    fn detects_might_could() {
        assert_lint_count(
            "They might could finish the project by Friday.",
            DoubleModal::default(),
            1,
        );
    }

    #[test]
    fn detects_should_ought() {
        assert_lint_count("You should ought to apologize.", DoubleModal::default(), 1);
    }

    #[test]
    fn allows_single_modal() {
        assert_lint_count("She must leave early.", DoubleModal::default(), 0);
    }

    #[test]
    fn detects_two_double_modals() {
        assert_lint_count(
            "He may can join us, and you might could too.",
            DoubleModal::default(),
            2,
        );
    }

    #[test]
    fn suggests_removing_second_modal_keeps_first() {
        assert_suggestion_result(
            "They might could finish the project by Friday.",
            DoubleModal::default(),
            "They might finish the project by Friday.",
        );
    }

    #[test]
    fn suggests_removing_second_modal_keeps_first_variant_order() {
        assert_suggestion_result(
            "You could might want to double-check that.",
            DoubleModal::default(),
            "You could want to double-check that.",
        );
    }

    #[test]
    fn suggests_removing_second_modal_keeps_first_capitalised() {
        assert_suggestion_result(
            "We Must Should be consistent.",
            DoubleModal::default(),
            "We Must be consistent.",
        );
    }

    #[test]
    fn allows_will_need() {
        assert_no_lints(
            "You will need administrator or editor level access",
            DoubleModal::default(),
        );
    }
}



================================================
FILE: harper-core/src/linting/ellipsis_length.rs
================================================
use itertools::Itertools;

use super::{Lint, LintKind, Linter, Suggestion};
use crate::TokenStringExt;

/// A linter that checks that an ellipsis doesn't contain too many periods (or
/// too few).
#[derive(Debug, Default)]
pub struct EllipsisLength;

impl Linter for EllipsisLength {
    fn lint(&mut self, document: &crate::Document) -> Vec<Lint> {
        let mut lints = Vec::new();

        for tok in document.iter_ellipsiss() {
            let tok_content = document.get_span_content(&tok.span);

            if tok_content.is_empty() {
                continue;
            }

            if tok_content.first().cloned() == Some('.')
                && tok_content.iter().all_equal()
                && tok_content.len() != 3
            {
                lints.push(Lint {
                    span: tok.span,
                    lint_kind: LintKind::Formatting,
                    suggestions: vec![Suggestion::ReplaceWith(vec!['.', '.', '.'])],
                    message: "Horizontal ellipsis must have 3 dots.".to_string(),
                    priority: 31,
                })
            }
        }

        lints
    }

    fn description(&self) -> &'static str {
        "Make sure you have the correct number of dots in your ellipsis."
    }
}

#[cfg(test)]
mod tests {
    use super::EllipsisLength;
    use crate::linting::tests::{assert_lint_count, assert_suggestion_result};

    #[test]
    fn allows_correct_ellipsis() {
        assert_lint_count("...", EllipsisLength, 0);
    }

    #[test]
    fn corrects_long_ellipsis() {
        assert_lint_count(".....", EllipsisLength, 1);
        assert_suggestion_result(".....", EllipsisLength, "...");
    }

    #[test]
    fn corrects_short_ellipsis() {
        assert_lint_count("..", EllipsisLength, 1);
        assert_suggestion_result("..", EllipsisLength, "...");
    }
}



================================================
FILE: harper-core/src/linting/else_possessive.rs
================================================
use crate::expr::Expr;
use crate::expr::OwnedExprExt;
use crate::expr::SequenceExpr;
use crate::linting::expr_linter::Chunk;
use crate::{
    Token,
    linting::{ExprLinter, Lint, LintKind, Suggestion},
    patterns::WordSet,
};

pub struct ElsePossessive {
    expr: Box<dyn Expr>,
}

impl Default for ElsePossessive {
    fn default() -> Self {
        let pronouns = WordSet::new(&[
            "somebody",
            "someone",
            "anybody",
            "anyone",
            "everybody",
            "everyone",
            "nobody",
        ])
        .or(SequenceExpr::aco("no").then_whitespace().t_aco("one"));

        let pattern = SequenceExpr::default()
            .then(pronouns)
            .then_whitespace()
            .t_aco("elses");

        Self {
            expr: Box::new(pattern),
        }
    }
}

impl ExprLinter for ElsePossessive {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, toks: &[Token], _src: &[char]) -> Option<Lint> {
        let offender = toks.last()?;
        Some(Lint {
            span: offender.span,
            lint_kind: LintKind::Miscellaneous,
            suggestions: vec![Suggestion::ReplaceWith("else's".chars().collect())],
            message: "Add the missing possessive apostrophe: use `else’s`.".to_owned(),
            priority: 60,
        })
    }

    fn description(&self) -> &str {
        "Detects missing apostrophes in phrases like `someone elses book` and suggests the correct possessive form `else’s`."
    }
}

#[cfg(test)]
mod tests {
    use super::ElsePossessive;
    use crate::linting::tests::{assert_lint_count, assert_suggestion_result};

    #[test]
    fn fixes_no_one_elses() {
        assert_suggestion_result(
            "It's no one elses problem.",
            ElsePossessive::default(),
            "It's no one else's problem.",
        );
    }

    #[test]
    fn fixes_someone_elses() {
        assert_suggestion_result(
            "It's someone elses problem.",
            ElsePossessive::default(),
            "It's someone else's problem.",
        );
    }

    #[test]
    fn fixes_anybody_elses() {
        assert_suggestion_result(
            "Was that anybody elses idea?",
            ElsePossessive::default(),
            "Was that anybody else's idea?",
        );
    }

    #[test]
    fn fixes_everyone_elses() {
        assert_suggestion_result(
            "He echoed everyone elses concerns.",
            ElsePossessive::default(),
            "He echoed everyone else's concerns.",
        );
    }

    #[test]
    fn ignores_correct_form() {
        assert_lint_count(
            "She borrowed someone else's notes.",
            ElsePossessive::default(),
            0,
        );
    }
}



================================================
FILE: harper-core/src/linting/ever_every.rs
================================================
use crate::{
    Lint, Token,
    expr::{Expr, OwnedExprExt, SequenceExpr},
    linting::{ExprLinter, LintKind, Suggestion, expr_linter::Chunk},
    patterns::{ModalVerb, WordSet},
};

pub struct EverEvery {
    expr: Box<dyn Expr>,
}

impl Default for EverEvery {
    fn default() -> Self {
        Self {
            expr: Box::new(
                SequenceExpr::any_of(vec![
                    Box::new(WordSet::new(&[
                        "are", "aren't", "arent", "did", "didn't", "didnt", "do", "does",
                        "doesn't", "doesnt", "dont", "don't", "had", "hadn't", "hadnt", "has",
                        "hasn't", "hasnt", "have", "haven't", "havent", "is", "isn't", "isnt",
                        "was", "wasn't", "wasnt", "were", "weren't", "werent",
                    ])),
                    Box::new(ModalVerb::with_common_errors()),
                ])
                .t_ws()
                .then_subject_pronoun()
                .t_ws()
                .t_aco("every")
                .and_not(SequenceExpr::anything().t_any().t_aco("it")),
            ),
        }
    }
}

impl ExprLinter for EverEvery {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, toks: &[Token], src: &[char]) -> Option<Lint> {
        let span = toks[4].span;
        let content = span.get_content(src);
        Some(Lint {
            span,
            lint_kind: LintKind::Typo,
            suggestions: vec![Suggestion::replace_with_match_case(
                content[..content.len() - 1].to_vec(),
                content,
            )],
            message: "Is this `every` a typo that should be `ever`?".to_string(),
            ..Default::default()
        })
    }

    fn description(&self) -> &str {
        "Tries to correct typos of `every` instead of `ever`."
    }
}

#[cfg(test)]
mod tests {
    use super::EverEvery;
    use crate::linting::tests::{assert_no_lints, assert_suggestion_result};

    #[test]
    fn fix_can_i_every() {
        assert_suggestion_result(
            "Odd, how can i every become negative in that case?",
            EverEvery::default(),
            "Odd, how can i ever become negative in that case?",
        );
    }

    #[test]
    fn fix_can_they_every() {
        assert_suggestion_result(
            "if each component has its own instance of NameService, how can they every share state?",
            EverEvery::default(),
            "if each component has its own instance of NameService, how can they ever share state?",
        )
    }

    #[test]
    fn fix_can_we_every() {
        assert_suggestion_result(
            "can we every have a good dev UX?",
            EverEvery::default(),
            "can we ever have a good dev UX?",
        );
    }

    #[test]
    fn fix_did_we_every() {
        assert_suggestion_result(
            "Did we every fix that?",
            EverEvery::default(),
            "Did we ever fix that?",
        )
    }

    #[test]
    fn fix_did_you_every() {
        assert_suggestion_result(
            "Did you every get vtsls working properly?",
            EverEvery::default(),
            "Did you ever get vtsls working properly?",
        )
    }

    #[test]
    fn fix_do_i_every() {
        assert_suggestion_result(
            "Rarely do I every look forward to the new ui.",
            EverEvery::default(),
            "Rarely do I ever look forward to the new ui.",
        )
    }

    #[test]
    fn fix_do_we_every() {
        assert_suggestion_result(
            "do we every stop learning new things?",
            EverEvery::default(),
            "do we ever stop learning new things?",
        )
    }

    #[test]
    fn fix_do_you_every() {
        assert_suggestion_result(
            "Do you every faced the issue or have any idea why this could happen?",
            EverEvery::default(),
            "Do you ever faced the issue or have any idea why this could happen?",
        )
    }

    #[test]
    fn fix_dont_i_every() {
        assert_suggestion_result(
            "WHY DONT I EVERY SEE OR HEAR ABOUT THINGS HAPPENING IN SOUTHPORT?",
            EverEvery::default(),
            "WHY DONT I EVER SEE OR HEAR ABOUT THINGS HAPPENING IN SOUTHPORT?",
        )
    }

    #[test]
    fn fix_dont_they_every() {
        assert_suggestion_result(
            "And why dont they every smile first?",
            EverEvery::default(),
            "And why dont they ever smile first?",
        )
    }

    #[test]
    fn fix_dont_you_every() {
        assert_suggestion_result(
            "Dont you every forget this and believe nothing else.",
            EverEvery::default(),
            "Dont you ever forget this and believe nothing else.",
        )
    }

    #[test]
    fn fix_have_you_every() {
        assert_suggestion_result(
            "Have you every wanted to generate geometric structures from data.frames",
            EverEvery::default(),
            "Have you ever wanted to generate geometric structures from data.frames",
        )
    }

    #[test]
    fn fix_should_i_every() {
        assert_suggestion_result(
            "I.e. why would I every use deepcopy ?",
            EverEvery::default(),
            "I.e. why would I ever use deepcopy ?",
        )
    }

    #[test]
    fn fix_should_we_every() {
        assert_suggestion_result(
            "Should we every meet, I'll get you a beverage of your choosing!",
            EverEvery::default(),
            "Should we ever meet, I'll get you a beverage of your choosing!",
        )
    }

    #[test]
    fn fix_should_you_every() {
        assert_suggestion_result(
            "but you will always have a place in his home should you every truly desire it",
            EverEvery::default(),
            "but you will always have a place in his home should you ever truly desire it",
        )
    }

    #[test]
    fn fix_would_i_every() {
        assert_suggestion_result(
            "Why would I every do that?",
            EverEvery::default(),
            "Why would I ever do that?",
        )
    }

    #[test]
    fn fix_would_they_every() {
        assert_suggestion_result(
            "Would they every be installed together?",
            EverEvery::default(),
            "Would they ever be installed together?",
        )
    }

    // known false positive - future contributors: please feel free to tackle this!

    #[test]
    #[ignore = "unusual but not wrong position of time phrase, maybe should have commas?"]
    fn dont_flag_should_we_every() {
        assert_no_lints(
            "MM: should we every month or two have a roundup of what's been happening in WGSL",
            EverEvery::default(),
        )
    }
}



================================================
FILE: harper-core/src/linting/everyday.rs
================================================
use super::{ExprLinter, Lint, LintKind, Suggestion};
use crate::expr::All;
use crate::expr::Expr;
use crate::expr::LongestMatchOf;
use crate::expr::SequenceExpr;
use crate::linting::expr_linter::Chunk;
use crate::{Lrc, Punctuation, Token, TokenKind, TokenStringExt, patterns::Word};

pub struct Everyday {
    expr: Box<dyn Expr>,
}

impl Default for Everyday {
    fn default() -> Self {
        let everyday = Word::new("everyday");
        let every_day = Lrc::new(SequenceExpr::aco("every").t_ws().t_aco("day"));

        let everyday_bad_after = All::new(vec![
            Box::new(
                SequenceExpr::default()
                    .then(everyday.clone())
                    .t_ws()
                    .then_any_word(),
            ),
            Box::new(SequenceExpr::anything().t_any().then_kind_where(|kind| {
                !kind.is_noun() && !kind.is_oov() && !kind.is_verb_progressive_form()
            })),
        ]);

        let bad_before_every_day = All::new(vec![
            Box::new(
                SequenceExpr::default()
                    .then_any_word()
                    .t_ws()
                    .then(every_day.clone()),
            ),
            Box::new(|tok: &Token, _src: &[char]| {
                // "this" and "that" are both determiners and pronouns
                tok.kind.is_determiner() && !tok.kind.is_pronoun()
            }),
        ]);

        // (why does) everyday feel the (same ?)
        let everyday_ambiverb_after_then_noun = All::new(vec![
            Box::new(
                SequenceExpr::default()
                    .then(everyday.clone())
                    .t_ws()
                    .then_any_word()
                    .t_ws()
                    .then_any_word(),
            ),
            Box::new(
                SequenceExpr::anything()
                    .t_any()
                    .then_kind_both(TokenKind::is_noun, TokenKind::is_verb)
                    .t_any()
                    .then_determiner(),
            ),
        ]);

        // (Do you actually improve if you draw) everyday?
        let everyday_punctuation_after = All::new(vec![
            Box::new(
                SequenceExpr::default()
                    .then(everyday.clone())
                    .then_punctuation(),
            ),
            Box::new(SequenceExpr::anything().then_kind_where(|kind| {
                matches!(
                    kind,
                    TokenKind::Punctuation(
                        Punctuation::Question | Punctuation::Comma | Punctuation::Period
                    )
                )
            })),
        ]);

        // (However, the message goes far beyond) every day things.
        let every_day_noun_after_then_punctuation = All::new(vec![
            Box::new(
                SequenceExpr::default()
                    .then(every_day.clone())
                    .t_ws()
                    .then_plural_noun()
                    .then_punctuation(),
            ),
            Box::new(
                SequenceExpr::anything()
                    .t_any()
                    .t_any()
                    .t_any()
                    .t_any()
                    .then_kind_where(|kind| {
                        matches!(
                            kind,
                            TokenKind::Punctuation(
                                Punctuation::Question | Punctuation::Comma | Punctuation::Period
                            )
                        )
                    }),
            ),
        ]);

        // Can we detect all mistakes with just one token before or after?

        // ❌ after adjective ✅ after adverb
        // $ (end of chunk)

        // ✅ after adjective ❌ after adverb
        // singular count noun: "An everyday task"

        // ✅ after adjective ✅ after adverb - can't disambiguate!
        // plural noun: "Everyday tasks are boring." vs "Every day tasks get completed."
        // mass noun: "Everyday information" vs "Every day information gets processed."

        // ❌ before adjective ✅ before adverb
        // none found yet

        // ✅ before adjective ❌ before adverb
        // none found yet

        // ✅ before adjective ✅ before adverb - can't disambiguate!
        // "some": "some everyday tasks" / "Do some every day"
        // verb, past form: "I coded every day" / "I learned everyday phrases"

        Self {
            expr: Box::new(LongestMatchOf::new(vec![
                Box::new(everyday_bad_after),
                Box::new(bad_before_every_day),
                Box::new(everyday_ambiverb_after_then_noun),
                Box::new(everyday_punctuation_after),
                Box::new(every_day_noun_after_then_punctuation),
            ])),
        }
    }
}

impl ExprLinter for Everyday {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, toks: &[Token], src: &[char]) -> Option<Lint> {
        // Helper functions make the match tables more compact and readable.
        let norm = |i: usize| toks[i].span.get_content_string(src).to_lowercase();
        let isws = |i: usize| toks[i].kind.is_whitespace();
        let tokspan = |i: usize| toks[i].span;
        let slicespan = |i: usize| toks[i..i + 3].span().unwrap();

        let (span, replacement, pos) = match toks.len() {
            2 => match (norm(0).as_str(), norm(1).as_str()) {
                ("everyday", _) => Some((tokspan(0), "every day", "adverb")),
                _ => None,
            },
            3 => match (norm(0).as_str(), norm(2).as_str()) {
                ("everyday", _) if isws(1) => Some((tokspan(0), "every day", "adverb")),
                (_, "everyday") if isws(1) => Some((tokspan(2), "every day", "adverb")),
                _ => None,
            },
            5 => match (norm(0).as_str(), norm(2).as_str(), norm(4).as_str()) {
                ("every", "day", _) if isws(1) && isws(3) => {
                    Some((slicespan(0), "everyday", "adjective"))
                }
                (_, "every", "day") if isws(1) && isws(3) => {
                    Some((slicespan(2), "everyday", "adjective"))
                }
                ("everyday", _, _) if isws(1) && isws(3) => {
                    Some((tokspan(0), "every day", "adverb"))
                }
                _ => None,
            },
            6 => match (
                norm(0).as_str(),
                norm(2).as_str(),
                norm(4).as_str(),
                norm(5).as_str(),
            ) {
                ("every", "day", _, _) if isws(1) && isws(3) => {
                    Some((slicespan(0), "everyday", "adjective"))
                }
                _ => None,
            },
            _ => None,
        }?;

        Some(Lint {
            span,
            lint_kind: LintKind::WordChoice,
            suggestions: vec![Suggestion::replace_with_match_case_str(
                replacement,
                span.get_content(src),
            )],
            message: format!("You probably mean the {pos} `{replacement}` here."),
            priority: 31,
        })
    }

    fn description(&self) -> &str {
        "This rule tries to sort out confusing the adjective `everyday` and the adverb `every day`."
    }
}

#[cfg(test)]
mod tests {
    use super::Everyday;
    use crate::linting::tests::{
        assert_lint_count, assert_no_lints, assert_suggestion_result, assert_top3_suggestion_result,
    };

    #[test]
    fn dont_flag_lone_adjective() {
        assert_lint_count("everyday", Everyday::default(), 0);
    }

    #[test]
    fn dont_flag_lone_adverb() {
        assert_lint_count("every day", Everyday::default(), 0);
    }

    #[test]
    fn correct_adjective_at_end_of_chunk() {
        assert_suggestion_result(
            "This is something I do everyday.",
            Everyday::default(),
            "This is something I do every day.",
        );
    }

    #[test]
    fn correct_adverb_after_article_before_noun() {
        assert_suggestion_result(
            "It's nothing special, just an every day thing.",
            Everyday::default(),
            "It's nothing special, just an everyday thing.",
        );
    }

    #[test]
    #[ignore = "Can't yet match end-of-chunk after it. Adjective before is legit for both adjective and adverb."]
    fn correct_adjective_without_following_noun() {
        assert_suggestion_result(
            "Some git commands used everyday",
            Everyday::default(),
            "Some git commands used every day",
        );
    }

    #[test]
    fn dont_flag_everyday_adjective_before_dev() {
        assert_lint_count(
            "At everyday dev, engineering isn't just a job - it's our passion.",
            Everyday::default(),
            0,
        );
    }

    #[test]
    fn dont_flag_everyday_adjective_before_present_participle() {
        assert_lint_count("Everyday coding projects.", Everyday::default(), 0);
    }

    #[test]
    fn dont_flag_everyday_adjective_before_plural_noun() {
        assert_lint_count(
            "Exploring Everyday Things with R and Ruby",
            Everyday::default(),
            0,
        );
    }

    #[test]
    fn correct_everyday_at_end_of_sentence_after_past_verb() {
        assert_suggestion_result(
            "Trying to write about what I learned everyday.",
            Everyday::default(),
            "Trying to write about what I learned every day.",
        );
    }

    #[test]
    fn dont_flag_every_day_at_start_of_sentence_before_comma() {
        assert_lint_count(
            "Every day, a new concept or improvement will be shared",
            Everyday::default(),
            0,
        );
    }

    #[test]
    fn dont_flag_every_day_at_start_of_sentence_before_copula() {
        assert_lint_count("Every day is worth remembering...", Everyday::default(), 0);
    }

    #[test]
    fn dont_flag_every_day_at_end_of_sentence_after_noun() {
        assert_lint_count("You learn new stuff every day.", Everyday::default(), 0);
    }

    #[test]
    fn dont_flag_every_day_after_noun_before_conjunction() {
        assert_lint_count(
            "Pick a different test item every day and confirm it is present.",
            Everyday::default(),
            0,
        );
    }

    #[test]
    #[ignore = "replace_with_match_case_str converts to EveryDay instead of Everyday"]
    fn correct_every_day_after_article() {
        assert_suggestion_result(
            "The Every Day Calendar with Dark Mode",
            Everyday::default(),
            "The Everyday Calendar with Dark Mode",
        );
    }

    #[test]
    fn dont_flag_everyday_before_unknown_word() {
        assert_lint_count(
            "It's just a normal everyday splorg.",
            Everyday::default(),
            0,
        );
    }

    #[test]
    fn dont_flag_every_day_at_end_of_chunk_after_adverb() {
        assert_lint_count(
            "I use the same amount of energy basically every day",
            Everyday::default(),
            0,
        );
    }

    #[test]
    fn dont_flag_every_day_after_verb_before_if() {
        assert_lint_count(
            "This would happen every day if left alone.",
            Everyday::default(),
            0,
        );
    }

    #[test]
    fn dont_flag_every_day_after_noun_before_preposition() {
        assert_lint_count(
            "An animal can do training and inference every day of its existence until the day of its death.",
            Everyday::default(),
            0,
        );
    }

    #[test]
    fn dont_flag_every_day_after_time() {
        assert_lint_count(
            "Can I take a picture at 12:00 every day?",
            Everyday::default(),
            0,
        );
    }

    #[test]
    fn dont_flag_every_day_at_start_of_chunk_before_np() {
        assert_lint_count(
            "Every day the application crashes several times on macOS Sequoia version 15.3",
            Everyday::default(),
            0,
        );
    }

    #[test]
    fn fix_everyday_and_every_day_used_wrongly() {
        assert_top3_suggestion_result(
            "Each and everyday you ought to strive to learn something that is not an every day thing.",
            Everyday::default(),
            "Each and every day you ought to strive to learn something that is not an everyday thing.",
        );
    }

    #[test]
    fn fix_reddit_why_does_everyday() {
        assert_top3_suggestion_result(
            "Why does everyday feel the same?",
            Everyday::default(),
            "Why does every day feel the same?",
        );
    }

    #[test]
    fn fix_reddit_everyday_is_going_to() {
        assert_top3_suggestion_result(
            "... everyday is going to be a good day that's just the way it is!",
            Everyday::default(),
            "... every day is going to be a good day that's just the way it is!",
        );
    }

    #[test]
    fn fix_reddit_draw_everyday() {
        assert_top3_suggestion_result(
            "Do you actually improve if you draw everyday?",
            Everyday::default(),
            "Do you actually improve if you draw every day?",
        );
    }

    #[test]
    fn fix_reddit_two_bad_out_of_three() {
        assert_top3_suggestion_result(
            "Yes you can jog everyday, not a personal best every day, but a steady pace run everyday.",
            Everyday::default(),
            "Yes you can jog every day, not a personal best every day, but a steady pace run every day.",
        );
    }

    #[test]
    fn fix_reddit_every_day_routine() {
        assert_top3_suggestion_result(
            "Habit stacking - stacking the small skill with something that's already worked into my every day routine.",
            Everyday::default(),
            "Habit stacking - stacking the small skill with something that's already worked into my everyday routine.",
        );
    }

    #[test]
    fn fix_stackoverflow_every_day_things() {
        assert_top3_suggestion_result(
            "However, the message goes far beyond every day things.",
            Everyday::default(),
            "However, the message goes far beyond everyday things.",
        );
    }

    #[test]
    fn fix_reddit_everyday_is_same() {
        assert_top3_suggestion_result(
            "Everyday is exactly the same",
            Everyday::default(),
            "Every day is exactly the same",
        );
    }

    #[test]
    #[ignore = "doesn't work yet because title case demands 'Every Day' but we get 'Every day'"]
    fn fix_medium_little_bit_everyday() {
        assert_top3_suggestion_result(
            "Does Learning A Little Bit Everyday Actually Work?",
            Everyday::default(),
            "Does Learning A Little Bit Every Day Actually Work?",
        );
    }

    #[test]
    fn fix_stackexchange_use_everyday() {
        assert_top3_suggestion_result(
            "We use this everyday without noticing, but we hate it when ...",
            Everyday::default(),
            "We use this every day without noticing, but we hate it when ...",
        );
    }

    #[test]
    fn fix_github_what_i_learned_everyday() {
        assert_top3_suggestion_result(
            "Trying to write about what I learned everyday.",
            Everyday::default(),
            "Trying to write about what I learned every day.",
        );
    }

    #[test]
    fn fix_medium_one_bad_out_of_three() {
        assert_top3_suggestion_result(
            "Even inside a routine, everyday we adapt to changes and challenges ... We are not the same person every day, but every day we are ourselves…",
            Everyday::default(),
            "Even inside a routine, every day we adapt to changes and challenges ... We are not the same person every day, but every day we are ourselves…",
        );
    }

    #[test]
    fn fix_medium_doing_something_everyday() {
        assert_top3_suggestion_result(
            "There was nothing wrong with my braincells processing the concepts of doing something everyday and ...",
            Everyday::default(),
            "There was nothing wrong with my braincells processing the concepts of doing something every day and ...",
        );
    }

    #[test]
    fn fix_medium_all_caps() {
        assert_top3_suggestion_result(
            "MEET SOMEONE NEW EVERYDAY.",
            Everyday::default(),
            "MEET SOMEONE NEW EVERY DAY.",
        );
    }

    #[test]
    fn dont_flag_every_day_singular_noun_2020() {
        assert_no_lints("50 requests per day, every day free.", Everyday::default());
    }
}



================================================
FILE: harper-core/src/linting/expand_memory_shorthands.rs
================================================
use std::sync::Arc;

use super::{ExprLinter, Lint, LintKind};
use crate::Token;
use crate::expr::{Expr, SequenceExpr, SpaceOrHyphen};
use crate::linting::Suggestion;
use crate::linting::expr_linter::Chunk;
use crate::patterns::{ImpliesQuantity, WordSet};

pub struct ExpandMemoryShorthands {
    expr: Box<dyn Expr>,
}

impl ExpandMemoryShorthands {
    pub fn new() -> Self {
        let hotwords = Arc::new(WordSet::new(&[
            "B", "kB", "MB", "GB", "TB", "PB", "EB", "ZB", "YB", "RB", "QB", "KiB", "MiB", "GiB",
            "TiB", "PiB", "EiB", "ZiB", "YiB", "RiB", "QiB",
        ]));

        Self {
            expr: Box::new(
                SequenceExpr::default()
                    .then(ImpliesQuantity)
                    .then_longest_of(vec![
                        Box::new(SequenceExpr::with(hotwords.clone())),
                        Box::new(
                            SequenceExpr::default()
                                .then(SpaceOrHyphen)
                                .then(hotwords.clone()),
                        ),
                    ]),
            ),
        }
    }

    fn get_replacement(abbreviation: &str, plural: Option<bool>) -> Option<&'static str> {
        let is_plural = plural.unwrap_or(abbreviation.ends_with('s'));
        match abbreviation {
            "B" => Some(if is_plural { "bytes" } else { "byte" }),
            "kB" => Some(if is_plural { "kilobytes" } else { "kilobyte" }),
            "MB" => Some(if is_plural { "megabytes" } else { "megabyte" }),
            "GB" => Some(if is_plural { "gigabytes" } else { "gigabyte" }),
            "TB" => Some(if is_plural { "terabytes" } else { "terabyte" }),
            "PB" => Some(if is_plural { "petabytes" } else { "petabyte" }),
            "EB" => Some(if is_plural { "exabytes" } else { "exabyte" }),
            "ZB" => Some(if is_plural { "zettabytes" } else { "zettabyte" }),
            "YB" => Some(if is_plural { "yottabytes" } else { "yottabyte" }),
            "RB" => Some(if is_plural { "ronnabytes" } else { "ronnabyte" }),
            "QB" => Some(if is_plural {
                "quettabytes"
            } else {
                "quettabyte"
            }),
            "KiB" => Some(if is_plural { "kibibytes" } else { "kibibyte" }),
            "MiB" => Some(if is_plural { "mebibytes" } else { "mebibyte" }),
            "GiB" => Some(if is_plural { "gibibytes" } else { "gibibyte" }),
            "TiB" => Some(if is_plural { "tebibytes" } else { "tebibyte" }),
            "PiB" => Some(if is_plural { "pebibytes" } else { "pebibyte" }),
            "EiB" => Some(if is_plural { "exbibytes" } else { "exbibyte" }),
            "ZiB" => Some(if is_plural { "zebibytes" } else { "zebibyte" }),
            "YiB" => Some(if is_plural { "yobibytes" } else { "yobibyte" }),
            "RiB" => Some(if is_plural { "robibytes" } else { "robibyte" }),
            "QiB" => Some(if is_plural { "quebibytes" } else { "quebibyte" }),

            _ => None,
        }
    }
}

impl Default for ExpandMemoryShorthands {
    fn default() -> Self {
        Self::new()
    }
}

impl ExprLinter for ExpandMemoryShorthands {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], source: &[char]) -> Option<Lint> {
        let offending_span = matched_tokens.last()?.span;
        let implies_plural = ImpliesQuantity::implies_plurality(matched_tokens.first()?, source);

        let offending_text = offending_span.get_content(source);

        let replacement =
            Self::get_replacement(&offending_text.iter().collect::<String>(), implies_plural)?;

        let mut replacement_chars = Vec::new();

        // If there isn't spacing, insert a space
        if matched_tokens.len() == 2 {
            replacement_chars.push(' ');
        }

        replacement_chars.extend(replacement.chars());

        if replacement_chars == offending_text {
            return None;
        }

        Some(Lint {
            span: offending_span,
            lint_kind: LintKind::WordChoice,
            suggestions: vec![Suggestion::ReplaceWith(replacement_chars)],
            message: format!("Did you mean `{replacement}`?"),
            priority: 31,
        })
    }

    fn description(&self) -> &str {
        "Expands memory-related abbreviations (`B`, `kB`, `MB`, `GB`, `TB`, `PB`, `KiB`, `MiB`, `GiB`, `TiB`, `PiB`, etc.) to their full forms (`byte`, `kilobyte`, `megabyte`, `gigabyte`, `terabyte`, `petabyte`, `kibibyte`, `mebibyte`, `gibibyte`, `tebibyte`, `pebibyte`, etc.)."
    }
}

#[cfg(test)]
mod tests {
    use crate::linting::tests::{assert_lint_count, assert_suggestion_result};

    use super::ExpandMemoryShorthands;

    #[test]
    fn detects_bytes() {
        assert_suggestion_result("5 B", ExpandMemoryShorthands::new(), "5 bytes");
    }

    #[test]
    fn detects_kilobytes() {
        assert_suggestion_result("10 kB", ExpandMemoryShorthands::new(), "10 kilobytes");
    }

    #[test]
    fn detects_megabytes() {
        assert_suggestion_result("30 MB", ExpandMemoryShorthands::new(), "30 megabytes");
    }

    #[test]
    fn detects_gigabytes() {
        assert_suggestion_result("16 GB", ExpandMemoryShorthands::new(), "16 gigabytes");
    }

    #[test]
    fn detects_terabytes() {
        assert_suggestion_result("2 TB", ExpandMemoryShorthands::new(), "2 terabytes");
    }

    #[test]
    fn detects_kibibytes() {
        assert_suggestion_result("1024 KiB", ExpandMemoryShorthands::new(), "1024 kibibytes");
    }

    #[test]
    fn detects_mebibytes() {
        assert_suggestion_result("2048 MiB", ExpandMemoryShorthands::new(), "2048 mebibytes");
    }

    #[test]
    fn detects_gibibytes() {
        assert_suggestion_result("4 GiB", ExpandMemoryShorthands::new(), "4 gibibytes");
    }

    #[test]
    fn detects_tebibytes() {
        assert_suggestion_result("8 TiB", ExpandMemoryShorthands::new(), "8 tebibytes");
    }

    #[test]
    fn detects_petabytes() {
        assert_suggestion_result("1 PB", ExpandMemoryShorthands::new(), "1 petabyte");
    }

    #[test]
    fn detects_exabytes() {
        assert_suggestion_result("1 EB", ExpandMemoryShorthands::new(), "1 exabyte");
    }

    #[test]
    fn detects_zettabytes() {
        assert_suggestion_result("1 ZB", ExpandMemoryShorthands::new(), "1 zettabyte");
    }

    #[test]
    fn detects_yottabytes() {
        assert_suggestion_result("1 YB", ExpandMemoryShorthands::new(), "1 yottabyte");
    }

    #[test]
    fn detects_quettabytes() {
        assert_suggestion_result("1 QB", ExpandMemoryShorthands::new(), "1 quettabyte");
    }

    #[test]
    fn detects_pebibytes() {
        assert_suggestion_result("1 PiB", ExpandMemoryShorthands::new(), "1 pebibyte");
    }

    #[test]
    fn detects_exbibytes() {
        assert_suggestion_result("1 EiB", ExpandMemoryShorthands::new(), "1 exbibyte");
    }

    #[test]
    fn detects_zebibytes() {
        assert_suggestion_result("1 ZiB", ExpandMemoryShorthands::new(), "1 zebibyte");
    }

    #[test]
    fn detects_yobibytes() {
        assert_suggestion_result("1 YiB", ExpandMemoryShorthands::new(), "1 yobibyte");
    }

    #[test]
    fn detects_robibytes() {
        assert_suggestion_result("1 RiB", ExpandMemoryShorthands::new(), "1 robibyte");
    }

    #[test]
    fn detects_quebibytes() {
        assert_suggestion_result("1 QiB", ExpandMemoryShorthands::new(), "1 quebibyte");
    }

    #[test]
    fn handles_punctuation() {
        assert_suggestion_result("8 GB.", ExpandMemoryShorthands::new(), "8 gigabytes.");
    }

    #[test]
    fn handles_adjacent_number() {
        assert_suggestion_result("16GB", ExpandMemoryShorthands::new(), "16 gigabytes");
    }

    #[test]
    fn handles_hyphen_separated() {
        assert_suggestion_result("32-GB", ExpandMemoryShorthands::new(), "32-gigabytes");
    }

    #[test]
    fn doesnt_handle_wrong_kb_cases() {
        assert_lint_count(
            "48kb and 64 KB were common in the 8-bit era.",
            ExpandMemoryShorthands::new(),
            0,
        );
    }
}



================================================
FILE: harper-core/src/linting/expand_time_shorthands.rs
================================================
use crate::expr::Expr;
use crate::expr::SequenceExpr;
use crate::expr::SpaceOrHyphen;
use std::sync::Arc;

use super::{ExprLinter, Lint, LintKind};
use crate::Token;
use crate::linting::Suggestion;
use crate::linting::expr_linter::Chunk;
use crate::patterns::{ImpliesQuantity, WordSet};

pub struct ExpandTimeShorthands {
    expr: Box<dyn Expr>,
}

impl ExpandTimeShorthands {
    pub fn new() -> Self {
        let hotwords = Arc::new(WordSet::new(&[
            "hr", "hrs", "min", "mins", "sec", "secs", "ms", "msec", "msecs",
        ]));

        Self {
            expr: Box::new(
                SequenceExpr::default()
                    .then(ImpliesQuantity)
                    .then_longest_of(vec![
                        Box::new(SequenceExpr::with(hotwords.clone())),
                        Box::new(
                            SequenceExpr::default()
                                .then(SpaceOrHyphen)
                                .then(hotwords.clone()),
                        ),
                    ]),
            ),
        }
    }

    fn get_replacement(abbreviation: &str, plural: Option<bool>) -> Option<&'static str> {
        let is_plural = plural.unwrap_or(matches!(abbreviation, "hrs" | "mins" | "secs" | "msecs"));
        match abbreviation {
            "hr" | "hrs" => Some(if is_plural { "hours" } else { "hour" }),
            "min" | "mins" => Some(if is_plural { "minutes" } else { "minute" }),
            "sec" | "secs" => Some(if is_plural { "seconds" } else { "second" }),
            "ms" | "msec" | "msecs" => Some(if is_plural {
                "milliseconds"
            } else {
                "millisecond"
            }),
            _ => None,
        }
    }
}

impl Default for ExpandTimeShorthands {
    fn default() -> Self {
        Self::new()
    }
}

impl ExprLinter for ExpandTimeShorthands {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], source: &[char]) -> Option<Lint> {
        let offending_span = matched_tokens.last()?.span;
        let implies_plural = ImpliesQuantity::implies_plurality(matched_tokens.first()?, source);

        let offending_text = offending_span.get_content(source);

        let replacement =
            Self::get_replacement(&offending_text.iter().collect::<String>(), implies_plural)?;

        let mut replacement_chars = Vec::new();

        // If there isn't spacing, insert a space
        if matched_tokens.len() == 2 {
            replacement_chars.push(' ');
        }

        replacement_chars.extend(replacement.chars());

        if replacement_chars == offending_text {
            return None;
        }

        Some(Lint {
            span: offending_span,
            lint_kind: LintKind::WordChoice,
            suggestions: vec![Suggestion::ReplaceWith(replacement_chars)],
            message: format!("Did you mean `{replacement}`?"),
            priority: 31,
        })
    }

    fn description(&self) -> &str {
        "Expands time-related abbreviations (`hr`, `hrs`, `min`, `mins`, `sec`, `secs`, `ms`, `msec`, `msecs`) to their full forms (`hour`, `hours`, `minute`, `minutes`, `second`, `seconds`, `millisecond`, `milliseconds`)."
    }
}

#[cfg(test)]
mod tests {
    use crate::linting::tests::assert_suggestion_result;

    use super::ExpandTimeShorthands;

    #[test]
    fn detects_singular_hour() {
        assert_suggestion_result("5 hr", ExpandTimeShorthands::new(), "5 hours");
    }

    #[test]
    fn detects_singular_minute() {
        assert_suggestion_result("10 min", ExpandTimeShorthands::new(), "10 minutes");
    }

    #[test]
    fn detects_singular_second() {
        assert_suggestion_result("30 sec", ExpandTimeShorthands::new(), "30 seconds");
    }

    #[test]
    fn detects_plural_hours() {
        assert_suggestion_result("5 hrs", ExpandTimeShorthands::new(), "5 hours");
    }

    #[test]
    fn detects_plural_minutes() {
        assert_suggestion_result("10 mins", ExpandTimeShorthands::new(), "10 minutes");
    }

    #[test]
    fn detects_plural_seconds() {
        assert_suggestion_result("30 secs", ExpandTimeShorthands::new(), "30 seconds");
    }

    #[test]
    fn detects_millisecond() {
        assert_suggestion_result("5 ms", ExpandTimeShorthands::new(), "5 milliseconds");
    }

    #[test]
    fn detects_milliseconds() {
        assert_suggestion_result("10 msecs", ExpandTimeShorthands::new(), "10 milliseconds");
    }

    #[test]
    fn handles_punctuation_hour() {
        assert_suggestion_result("5 hr.", ExpandTimeShorthands::new(), "5 hours.");
    }

    #[test]
    fn handles_punctuation_minute() {
        assert_suggestion_result("10 min,", ExpandTimeShorthands::new(), "10 minutes,");
    }

    #[test]
    fn handles_punctuation_second() {
        assert_suggestion_result("30 sec!", ExpandTimeShorthands::new(), "30 seconds!");
    }

    #[test]
    fn handles_adjacent_number_hour() {
        assert_suggestion_result("5hr", ExpandTimeShorthands::new(), "5 hours");
    }

    #[test]
    fn handles_adjacent_number_minute() {
        assert_suggestion_result("10-min", ExpandTimeShorthands::new(), "10-minutes");
    }

    #[test]
    fn handles_adjacent_number_second() {
        assert_suggestion_result("30sec", ExpandTimeShorthands::new(), "30 seconds");
    }
}



================================================
FILE: harper-core/src/linting/expr_linter.rs
================================================
use crate::expr::{Expr, ExprExt};
use blanket::blanket;

use crate::{Document, LSend, Token, TokenStringExt};

use super::{Lint, Linter};

pub trait DocumentIterator {
    type Unit;

    fn iter_units<'a>(document: &'a Document) -> Box<dyn Iterator<Item = &'a [Token]> + 'a>;
}

/// Process text in chunks (clauses between commas)
pub struct Chunk;
/// Process text in full sentences
pub struct Sentence;

impl DocumentIterator for Chunk {
    type Unit = Chunk;

    fn iter_units<'a>(document: &'a Document) -> Box<dyn Iterator<Item = &'a [Token]> + 'a> {
        Box::new(document.iter_chunks())
    }
}

impl DocumentIterator for Sentence {
    type Unit = Sentence;

    fn iter_units<'a>(document: &'a Document) -> Box<dyn Iterator<Item = &'a [Token]> + 'a> {
        Box::new(document.iter_sentences())
    }
}

/// A trait that searches for tokens that fulfil [`Expr`]s in a [`Document`].
///
/// Makes use of [`TokenStringExt::iter_chunks`] by default, or [`TokenStringExt::iter_sentences`] to process either
/// a chunk (clause) or a sentence at a time.
#[blanket(derive(Box))]
pub trait ExprLinter: LSend {
    type Unit: DocumentIterator;

    /// A simple getter for the expression you want Harper to search for.
    fn expr(&self) -> &dyn Expr;
    /// If any portions of a [`Document`] match [`Self::expr`], they are passed through [`ExprLinter::match_to_lint`]
    /// or [`ExprLinter::match_to_lint_with_context`] to be transformed into a [`Lint`] for editor consumption.
    ///
    /// Transform matched tokens into a [`Lint`] for editor consumption.
    ///
    /// This is the simple version that only sees the matched tokens. For context-aware linting,
    /// implement `match_to_lint_with_context` instead.
    ///
    /// Return `None` to skip producing a lint for this match.
    fn match_to_lint(&self, matched_tokens: &[Token], source: &[char]) -> Option<Lint> {
        self.match_to_lint_with_context(matched_tokens, source, None)
    }

    /// Transform matched tokens into a [`Lint`] with access to surrounding context.
    ///
    /// The context provides access to tokens before and after the match. When implementing
    /// this method, you can call `self.match_to_lint()` as a fallback if the context isn't needed.
    ///
    /// Return `None` to skip producing a lint for this match.
    fn match_to_lint_with_context(
        &self,
        matched_tokens: &[Token],
        source: &[char],
        _context: Option<(&[Token], &[Token])>,
    ) -> Option<Lint> {
        // Default implementation falls back to the simple version
        self.match_to_lint(matched_tokens, source)
    }
    /// A user-facing description of what kinds of grammatical errors this rule looks for.
    /// It is usually shown in settings menus.
    fn description(&self) -> &str;
}

/// Helper function to find the only occurrence of a token matching a predicate
///
/// Returns `Some(token)` if exactly one token matches the predicate, `None` otherwise.
/// TODO: This can be used in the [`ThenThan`] linter when #1819 is merged.
pub fn find_the_only_token_matching<'a, F>(
    tokens: &'a [Token],
    source: &[char],
    predicate: F,
) -> Option<&'a Token>
where
    F: Fn(&Token, &[char]) -> bool,
{
    let mut matches = tokens.iter().filter(|&tok| predicate(tok, source));
    match (matches.next(), matches.next()) {
        (Some(tok), None) => Some(tok),
        _ => None,
    }
}

impl<L, U> Linter for L
where
    L: ExprLinter<Unit = U>,
    U: DocumentIterator,
{
    fn lint(&mut self, document: &Document) -> Vec<Lint> {
        let mut lints = Vec::new();
        let source = document.get_source();

        for unit in U::iter_units(document) {
            lints.extend(run_on_chunk(self, unit, source));
        }

        lints
    }

    fn description(&self) -> &str {
        self.description()
    }
}

pub fn run_on_chunk<'a>(
    linter: &'a impl ExprLinter,
    unit: &'a [Token],
    source: &'a [char],
) -> impl Iterator<Item = Lint> + 'a {
    linter
        .expr()
        .iter_matches(unit, source)
        .filter_map(|match_span| {
            linter.match_to_lint_with_context(
                &unit[match_span.start..match_span.end],
                source,
                Some((&unit[..match_span.start], &unit[match_span.end..])),
            )
        })
}

#[cfg(test)]
mod tests_context {
    use crate::expr::{Expr, FixedPhrase};
    use crate::linting::expr_linter::{Chunk, Sentence};
    use crate::linting::tests::assert_suggestion_result;
    use crate::linting::{ExprLinter, Suggestion};
    use crate::token_string_ext::TokenStringExt;
    use crate::{Lint, Token};

    pub struct TestSimpleLinter {
        expr: Box<dyn Expr>,
    }

    impl Default for TestSimpleLinter {
        fn default() -> Self {
            Self {
                expr: Box::new(FixedPhrase::from_phrase("two")),
            }
        }
    }

    impl ExprLinter for TestSimpleLinter {
        type Unit = Chunk;

        fn expr(&self) -> &dyn Expr {
            &*self.expr
        }

        fn match_to_lint(&self, toks: &[Token], _src: &[char]) -> Option<Lint> {
            Some(Lint {
                span: toks.span()?,
                message: "simple".to_string(),
                suggestions: vec![Suggestion::ReplaceWith(vec!['2'])],
                ..Default::default()
            })
        }

        fn description(&self) -> &str {
            "test linter"
        }
    }

    pub struct TestContextLinter {
        expr: Box<dyn Expr>,
    }

    impl Default for TestContextLinter {
        fn default() -> Self {
            Self {
                expr: Box::new(FixedPhrase::from_phrase("two")),
            }
        }
    }

    impl ExprLinter for TestContextLinter {
        type Unit = Chunk;

        fn expr(&self) -> &dyn Expr {
            &*self.expr
        }

        fn match_to_lint_with_context(
            &self,
            toks: &[Token],
            src: &[char],
            context: Option<(&[Token], &[Token])>,
        ) -> Option<Lint> {
            if let Some((before, after)) = context {
                let before = before.span()?.get_content_string(src);
                let after = after.span()?.get_content_string(src);

                let (message, suggestions) = if before.eq_ignore_ascii_case("one ")
                    && after.eq_ignore_ascii_case(" three")
                {
                    (
                        "ascending".to_string(),
                        vec![Suggestion::ReplaceWith(vec!['>'])],
                    )
                } else if before.eq_ignore_ascii_case("three ")
                    && after.eq_ignore_ascii_case(" one")
                {
                    (
                        "descending".to_string(),
                        vec![Suggestion::ReplaceWith(vec!['<'])],
                    )
                } else {
                    (
                        "dunno".to_string(),
                        vec![Suggestion::ReplaceWith(vec!['?'])],
                    )
                };

                return Some(Lint {
                    span: toks.span()?,
                    message,
                    suggestions,
                    ..Default::default()
                });
            } else {
                None
            }
        }

        fn description(&self) -> &str {
            "context linter"
        }
    }

    pub struct TestSentenceLinter {
        expr: Box<dyn Expr>,
    }

    impl Default for TestSentenceLinter {
        fn default() -> Self {
            Self {
                expr: Box::new(FixedPhrase::from_phrase("two, two")),
            }
        }
    }

    impl ExprLinter for TestSentenceLinter {
        type Unit = Sentence;

        fn expr(&self) -> &dyn Expr {
            self.expr.as_ref()
        }

        fn match_to_lint(&self, toks: &[Token], _src: &[char]) -> Option<Lint> {
            Some(Lint {
                span: toks.span()?,
                message: "sentence".to_string(),
                suggestions: vec![Suggestion::ReplaceWith(vec!['2', '&', '2'])],
                ..Default::default()
            })
        }

        fn description(&self) -> &str {
            "sentence linter"
        }
    }

    #[test]
    fn simple_test_123() {
        assert_suggestion_result("one two three", TestSimpleLinter::default(), "one 2 three");
    }

    #[test]
    fn context_test_123() {
        assert_suggestion_result("one two three", TestContextLinter::default(), "one > three");
    }

    #[test]
    fn context_test_321() {
        assert_suggestion_result("three two one", TestContextLinter::default(), "three < one");
    }

    #[test]
    fn sentence_test_123() {
        assert_suggestion_result(
            "one, two, two, three",
            TestSentenceLinter::default(),
            "one, 2&2, three",
        );
    }
}



================================================
FILE: harper-core/src/linting/far_be_it.rs
================================================
use crate::char_string::CharStringExt;
use crate::expr::{Expr, SequenceExpr};
use crate::linting::expr_linter::Chunk;
use crate::linting::{ExprLinter, Lint, LintKind, Suggestion};
use crate::token::Token;

pub struct FarBeIt {
    expr: Box<dyn Expr>,
}

impl Default for FarBeIt {
    fn default() -> Self {
        Self {
            expr: Box::new(
                SequenceExpr::default()
                    .t_aco("far")
                    .t_ws()
                    .t_aco("be")
                    .t_ws()
                    .t_aco("it")
                    .t_ws()
                    .then_word_except(&["from"]),
            ),
        }
    }
}

impl ExprLinter for FarBeIt {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, toks: &[Token], src: &[char]) -> Option<Lint> {
        let span = toks.last()?.span;
        let content = span.get_content(src);

        // We can only correct using `far be it for`, otherwise we recommend rephrasing the sentence.
        let (suggestions, message) = if span.get_content(src).eq_ignore_ascii_case_str("for") {
            (
                vec![Suggestion::replace_with_match_case(
                    vec!['f', 'r', 'o', 'm'],
                    content,
                )],
                "`Far be it for` is a common error for `far be it from`".to_string(),
            )
        } else {
            (vec![], "The correct usage of the idiom is `far be it from` [someone] to [do something]. Try to rephrase the sentence.".to_string())
        };

        Some(Lint {
            span,
            lint_kind: LintKind::Usage,
            suggestions,
            message,
            ..Default::default()
        })
    }

    fn description(&self) -> &'static str {
        "Flags misuse of `far be it` and suggests using `from` when it is followed by `for`"
    }
}

#[cfg(test)]
mod tests {
    use super::FarBeIt;
    use crate::linting::tests::{
        assert_no_lints, assert_suggestion_count, assert_suggestion_result,
    };

    #[test]
    fn far_be_it_for_me_capitalized() {
        assert_suggestion_result(
            "Far be it for me to suggestion that additional cardinality be added to the already TOO MUCH CARDINALITY metric space.",
            FarBeIt::default(),
            "Far be it from me to suggestion that additional cardinality be added to the already TOO MUCH CARDINALITY metric space.",
        );
    }

    #[test]
    fn far_be_it_for_me_lowercase() {
        assert_suggestion_result(
            "Far be it for me to tell people what to do so I'm not earnestly proposing to take away the ability to add literals to lazyframes.",
            FarBeIt::default(),
            "Far be it from me to tell people what to do so I'm not earnestly proposing to take away the ability to add literals to lazyframes.",
        );
    }

    #[test]
    fn far_be_it_that() {
        assert_suggestion_count(
            "Far be it that I get in the middle of this thread (and the complexity WebAuthn has spawned)",
            FarBeIt::default(),
            0,
        );
    }

    #[test]
    fn far_be_it_for_the_software() {
        assert_suggestion_result(
            "Far be it for the software to give any indication of that fact.",
            FarBeIt::default(),
            "Far be it from the software to give any indication of that fact.",
        );
    }

    #[test]
    #[ignore = "No punctuation between '... so far' and 'be it ...'"]
    fn missing_punctuation_false_positive() {
        assert_no_lints(
            "but it is failing for master and all the 11.x branches i have tried so far be it 11.0.0, 11.0.1 ...",
            FarBeIt::default(),
        );
    }

    #[test]
    fn far_be_it_to() {
        assert_suggestion_count(
            "I'm not a marketing guy, so far be it to second guess that.",
            FarBeIt::default(),
            0,
        );
    }
}



================================================
FILE: harper-core/src/linting/fascinated_by.rs
================================================
use crate::{
    CharStringExt, Lint, Token,
    expr::{Expr, SequenceExpr},
    linting::{ExprLinter, LintKind, Suggestion, expr_linter::Chunk},
};

pub struct FascinatedBy {
    expr: Box<dyn Expr>,
}

impl Default for FascinatedBy {
    fn default() -> Self {
        Self {
            expr: Box::new(SequenceExpr::aco("fascinated").t_ws().then_preposition()),
        }
    }
}

impl ExprLinter for FascinatedBy {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, toks: &[Token], src: &[char]) -> Option<Lint> {
        let prep_span = toks.last()?.span;
        let prep_chars = prep_span.get_content(src);
        if prep_chars.eq_any_ignore_ascii_case_str(&["by", "with"]) {
            return None;
        }

        Some(Lint {
            span: prep_span,
            lint_kind: LintKind::Usage,
            suggestions: vec![
                Suggestion::replace_with_match_case_str("by", prep_chars),
                Suggestion::replace_with_match_case_str("with", prep_chars),
            ],
            message: "The correct prepositions to use with `fascinated` are `by` or `with`."
                .to_string(),
            ..Default::default()
        })
    }

    fn description(&self) -> &str {
        "Ensures the correct prepositions are used with `fascinated` (e.g., `fascinated by` or `fascinated with`)."
    }
}

#[cfg(test)]
mod tests {
    use crate::linting::{fascinated_by::FascinatedBy, tests::assert_good_and_bad_suggestions};

    #[test]
    fn fix_amiga() {
        assert_good_and_bad_suggestions(
            "Now, one aspect of the Amiga that I've always been fascinated about is making my own games for the Amiga.",
            FascinatedBy::default(),
            &[
                "Now, one aspect of the Amiga that I've always been fascinated by is making my own games for the Amiga.",
                "Now, one aspect of the Amiga that I've always been fascinated with is making my own games for the Amiga.",
            ][..],
            &[],
        );
    }

    #[test]
    fn fix_microbit() {
        assert_good_and_bad_suggestions(
            "also why I am very fascinated about the micro:bit itself",
            FascinatedBy::default(),
            &[
                "also why I am very fascinated by the micro:bit itself",
                "also why I am very fascinated with the micro:bit itself",
            ][..],
            &[],
        );
    }

    #[test]
    fn fix_software_development() {
        assert_good_and_bad_suggestions(
            "Self-learner, fascinated about software development, especially computer graphics and web - marcus-phi.",
            FascinatedBy::default(),
            &[
                "Self-learner, fascinated by software development, especially computer graphics and web - marcus-phi.",
                "Self-learner, fascinated with software development, especially computer graphics and web - marcus-phi.",
            ][..],
            &[],
        );
    }

    #[test]
    fn fix_computer_science() {
        assert_good_and_bad_suggestions(
            "Fascinated about Computer Science, Finance and Statistics.",
            FascinatedBy::default(),
            &[
                "Fascinated by Computer Science, Finance and Statistics.",
                "Fascinated with Computer Science, Finance and Statistics.",
            ][..],
            &[],
        );
    }

    #[test]
    fn fix_possibilities() {
        assert_good_and_bad_suggestions(
            "m relatively new to deCONZ and Conbee2 but already very fascinated about the possibilities compared to Philips and Ikea's",
            FascinatedBy::default(),
            &[
                "m relatively new to deCONZ and Conbee2 but already very fascinated by the possibilities compared to Philips and Ikea's",
                "m relatively new to deCONZ and Conbee2 but already very fascinated with the possibilities compared to Philips and Ikea's",
            ][..],
            &[],
        );
    }

    #[test]
    fn fix_project() {
        assert_good_and_bad_suggestions(
            "I have been using browser use in local mode for a while and i am pretty fascinated about the project.",
            FascinatedBy::default(),
            &[
                "I have been using browser use in local mode for a while and i am pretty fascinated by the project.",
                "I have been using browser use in local mode for a while and i am pretty fascinated with the project.",
            ][..],
            &[],
        );
    }

    #[test]
    fn fix_work() {
        assert_good_and_bad_suggestions(
            "Hey guys, I am really fascinated about your work and I tried to build Magisk so I will be able to contribute for the project.",
            FascinatedBy::default(),
            &[
                "Hey guys, I am really fascinated by your work and I tried to build Magisk so I will be able to contribute for the project.",
                "Hey guys, I am really fascinated with your work and I tried to build Magisk so I will be able to contribute for the project.",
            ][..],
            &[],
        );
    }

    #[test]
    fn fix_ais() {
        assert_good_and_bad_suggestions(
            "I am a retired Dutch telecom engineer and fascinated about AIS applications.",
            FascinatedBy::default(),
            &[
                "I am a retired Dutch telecom engineer and fascinated by AIS applications.",
                "I am a retired Dutch telecom engineer and fascinated with AIS applications.",
            ][..],
            &[],
        );
    }

    #[test]
    fn fix_innovative_ideas() {
        assert_good_and_bad_suggestions(
            "Software Developer fascinated about innovative ideas, love to learn and share new technologies and ideas.",
            FascinatedBy::default(),
            &[
                "Software Developer fascinated by innovative ideas, love to learn and share new technologies and ideas.",
                "Software Developer fascinated with innovative ideas, love to learn and share new technologies and ideas.",
            ][..],
            &[],
        );
    }

    #[test]
    fn fix_coding() {
        assert_good_and_bad_suggestions(
            "m fascinated about coding and and sharing my code to the world.",
            FascinatedBy::default(),
            &[
                "m fascinated by coding and and sharing my code to the world.",
                "m fascinated with coding and and sharing my code to the world.",
            ][..],
            &[],
        );
    }
}



================================================
FILE: harper-core/src/linting/feel_fell.rs
================================================
use crate::Token;
use crate::char_string::CharStringExt;
use crate::expr::{Expr, SequenceExpr};
use crate::linting::expr_linter::Chunk;
use crate::linting::expr_linter::find_the_only_token_matching;
use crate::linting::{ExprLinter, Lint, LintKind, Suggestion};

pub struct FeelFell {
    expr: Box<dyn Expr>,
}

impl Default for FeelFell {
    fn default() -> Self {
        let with_word_before = SequenceExpr::default()
            .then_word_set(&["didn't", "doesn't"])
            .t_ws()
            .t_aco("fell");

        let with_word_after = SequenceExpr::default()
            .t_aco("fell")
            .t_ws()
            .then_word_set(&[
                "comfortable",
                "free",
                "good",
                "I",
                "I'm",
                "it",
                "it's",
                "like",
                "that",
                "we",
                "you",
            ]);

        Self {
            expr: Box::new(SequenceExpr::any_of(vec![
                Box::new(with_word_before),
                Box::new(with_word_after),
            ])),
        }
    }
}

impl ExprLinter for FeelFell {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, toks: &[Token], src: &[char]) -> Option<Lint> {
        let fell_token = find_the_only_token_matching(toks, src, |tok, src| {
            tok.span
                .get_content(src)
                .eq_ignore_ascii_case_chars(&['f', 'e', 'l', 'l'])
        })?;

        Some(Lint {
            span: fell_token.span,
            lint_kind: LintKind::Typo,
            suggestions: vec![Suggestion::replace_with_match_case_str(
                "feel",
                fell_token.span.get_content(src),
            )],
            message: "It looks like this is a typo, did you mean `feel`?".to_string(),
            ..Default::default()
        })
    }

    fn description(&self) -> &'static str {
        "Corrects some expressions using `fell` where `feel` is correct."
    }
}

#[cfg(test)]
mod tests {
    use crate::linting::tests::{assert_no_lints, assert_suggestion_result};

    use super::FeelFell;

    #[test]
    fn fix_i_fell_like() {
        assert_suggestion_result(
            "But I fell like i am having a knot in my brain ...",
            FeelFell::default(),
            "But I feel like i am having a knot in my brain ...",
        );
    }

    #[test]
    fn fix_if_you_fell_like_it() {
        assert_suggestion_result(
            "If you fell like it create w2ui-postgres for server side implementation",
            FeelFell::default(),
            "If you feel like it create w2ui-postgres for server side implementation",
        );
    }

    #[test]
    fn fix_i_dont_fell_like() {
        assert_suggestion_result(
            "But with this bug in place, I don't fell like asking the student to work with this tool",
            FeelFell::default(),
            "But with this bug in place, I don't feel like asking the student to work with this tool",
        );
    }

    #[test]
    fn fix_fell_comfortable() {
        assert_suggestion_result(
            "Technology that I fell comfortable to wok Php,Laravel, Javascript,Vue, Jquery, MySqli, sqLite.",
            FeelFell::default(),
            "Technology that I feel comfortable to wok Php,Laravel, Javascript,Vue, Jquery, MySqli, sqLite.",
        );
    }

    #[test]
    fn fix_fell_good() {
        assert_suggestion_result(
            "I've ha a touch of the flu and didn't fell good enough to mess with the computer.",
            FeelFell::default(),
            "I've ha a touch of the flu and didn't feel good enough to mess with the computer.",
        );
    }

    #[test]
    fn fix_didnt_fell() {
        assert_suggestion_result(
            "They have served me well, and I didn't fell that it's a gamble.",
            FeelFell::default(),
            "They have served me well, and I didn't feel that it's a gamble.",
        );
    }

    #[test]
    fn fix_fell_free() {
        assert_suggestion_result(
            "Please fell free to add more songs.",
            FeelFell::default(),
            "Please feel free to add more songs.",
        );
    }

    #[test]
    #[ignore = "Needs more context or better heuristics"]
    fn fix_fell_right() {
        assert_suggestion_result(
            "It may fell right first but only causes confusion in long run.",
            FeelFell::default(),
            "It may feel right first but only causes confusion in long run.",
        );
    }

    #[test]
    fn dont_flag_fell_right_into() {
        assert_no_lints(
            "I followed the instructions in the browser, and waited, then it fell right into shape, and the system is working out.",
            FeelFell::default(),
        );
    }

    #[test]
    fn dont_flag_fell_right_through() {
        assert_no_lints(
            "In this case the whole Piper context menu entry is missing since the uncaught exception fell right through the whole context menu factory.",
            FeelFell::default(),
        );
    }

    #[test]
    fn fix_does_not_fell_comfortable() {
        assert_suggestion_result(
            "she does not fell comfortable with the \" iso \"-format",
            FeelFell::default(),
            "she does not feel comfortable with the \" iso \"-format",
        );
    }

    #[test]
    #[ignore = "Needs more context or better heuristics"]
    fn dont_flag_didnt_fell_for_it() {
        assert_no_lints(
            "I even tried to trick someone else to delete and add the device but he didn't fell for it...",
            FeelFell::default(),
        );
    }

    #[test]
    fn fix_fell_that() {
        assert_suggestion_result(
            "I fell that a libSQL adapter would be a reasonable addition to the core offering.",
            FeelFell::default(),
            "I feel that a libSQL adapter would be a reasonable addition to the core offering.",
        );
    }

    #[test]
    fn fix_fell_it() {
        assert_suggestion_result(
            "I personally fell it makes the screens difficult to use",
            FeelFell::default(),
            "I personally feel it makes the screens difficult to use",
        );
    }

    #[test]
    fn fix_fell_its() {
        assert_suggestion_result(
            "but I fell it's too late to update that specific part of the API",
            FeelFell::default(),
            "but I feel it's too late to update that specific part of the API",
        );
    }

    #[test]
    fn fix_fell_im() {
        assert_suggestion_result(
            "I fell I'm missing sth and I need help.",
            FeelFell::default(),
            "I feel I'm missing sth and I need help.",
        );
    }

    #[test]
    fn fix_fell_we() {
        assert_suggestion_result(
            "i fell we will have to directly use BigDecimal here for Json encoding",
            FeelFell::default(),
            "i feel we will have to directly use BigDecimal here for Json encoding",
        );
    }

    #[test]
    fn fix_fell_i() {
        assert_suggestion_result(
            "feel free to reopen if you fell I have missed something",
            FeelFell::default(),
            "feel free to reopen if you feel I have missed something",
        );
    }

    #[test]
    fn fix_fell_you() {
        assert_suggestion_result(
            "But, I maybe fell you are stepping away from what a Markdown link actually is",
            FeelFell::default(),
            "But, I maybe feel you are stepping away from what a Markdown link actually is",
        );
    }
}



================================================
FILE: harper-core/src/linting/few_units_of_time_ago.rs
================================================
use crate::expr::Expr;
use crate::expr::SequenceExpr;
use crate::expr::TimeUnitExpr;
use crate::linting::expr_linter::Chunk;
use crate::{
    Lrc, Token,
    linting::{ExprLinter, Lint, Suggestion},
};

pub struct FewUnitsOfTimeAgo {
    expr: Box<dyn Expr>,
}

impl Default for FewUnitsOfTimeAgo {
    fn default() -> Self {
        let units = TimeUnitExpr;

        let start = SequenceExpr::default().then_word_except(&["a"]).t_ws();

        let expr = Lrc::new(
            SequenceExpr::default()
                .then(start)
                .t_aco("few")
                .then_whitespace()
                .then(units)
                .then_whitespace()
                .t_aco("ago"),
        );

        Self {
            expr: Box::new(expr),
        }
    }
}

impl ExprLinter for FewUnitsOfTimeAgo {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, toks: &[Token], src: &[char]) -> Option<Lint> {
        let mut span = None;

        for tok in toks.iter().take(3) {
            if tok.span.get_content_string(src).eq_ignore_ascii_case("few") {
                span = Some(tok.span);
                break;
            }
        }

        span?;

        Some(Lint {
            span: span.unwrap(),
            message: "In this construction you need to use `a few` instead of just `few`."
                .to_string(),
            suggestions: vec![Suggestion::replace_with_match_case_str(
                "a few",
                span.unwrap().get_content(src),
            )],
            ..Default::default()
        })
    }

    fn description(&self) -> &'static str {
        "Corrects some expressions using `few` where `a few` is correct."
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::linting::tests::{
        assert_lint_count, assert_suggestion_result, assert_top3_suggestion_result,
    };

    // Basic unit tests

    #[test]
    #[ignore = "Needs ^ zero-width anchor that matches the start of a chunk"]
    fn fix_few_minutes_ago() {
        assert_suggestion_result(
            "Few minutes ago",
            FewUnitsOfTimeAgo::default(),
            "A few minutes ago",
        );
    }

    #[test]
    fn dont_flag_a_few_minutes_ago() {
        assert_lint_count("A few minutes ago", FewUnitsOfTimeAgo::default(), 0);
    }

    #[test]
    fn fix_done_few_minutes_ago() {
        assert_top3_suggestion_result(
            "Done few minutes ago",
            FewUnitsOfTimeAgo::default(),
            "Done a few minutes ago",
        );
    }

    #[test]
    fn dont_flag_done_a_few_minutes_ago() {
        assert_lint_count("Done a few minutes ago", FewUnitsOfTimeAgo::default(), 0);
    }

    #[test]
    #[ignore = "Needs ^ zero-width anchor that matches the start of a chunk"]
    fn fix_after_space() {
        assert_suggestion_result(
            " Few minutes ago.",
            FewUnitsOfTimeAgo::default(),
            " A few minutes ago.",
        );
    }

    #[test]
    #[ignore = "Needs ^ zero-width anchor that matches the start of a chunk"]
    fn fix_2nd_sentence() {
        assert_suggestion_result(
            "Hello World. Few minutes ago I bought your planet.",
            FewUnitsOfTimeAgo::default(),
            "Hello World. A few minutes ago I bought your planet.",
        );
    }

    // Real world examples from GitHub

    #[test]
    fn fix_days() {
        assert_suggestion_result(
            "My jupyter kernel always says restarting and never ever runs i ran into the problem few days ago before it was fine dont know what happened",
            FewUnitsOfTimeAgo::default(),
            "My jupyter kernel always says restarting and never ever runs i ran into the problem a few days ago before it was fine dont know what happened",
        );
    }

    #[test]
    fn fix_decades() {
        assert_suggestion_result(
            "This is very old piece of software I wrote few decades ago.",
            FewUnitsOfTimeAgo::default(),
            "This is very old piece of software I wrote a few decades ago.",
        );
    }

    #[test]
    fn fix_hours() {
        assert_suggestion_result(
            "I just updated my index file few hours ago and there's this error.",
            FewUnitsOfTimeAgo::default(),
            "I just updated my index file a few hours ago and there's this error.",
        );
    }

    #[test]
    fn fix_minutes() {
        assert_suggestion_result(
            "mysql installed few minutes ago somehow , ubuntu bash thinks its not installed.",
            FewUnitsOfTimeAgo::default(),
            "mysql installed a few minutes ago somehow , ubuntu bash thinks its not installed.",
        );
    }

    #[test]
    fn fix_months() {
        assert_suggestion_result(
            "Hello, I was working with D455 few months ago, and everything was working fine.",
            FewUnitsOfTimeAgo::default(),
            "Hello, I was working with D455 a few months ago, and everything was working fine.",
        );
    }

    #[test]
    fn fix_ms() {
        assert_suggestion_result(
            "So I not sure, by getting old signal (get from few ms ago), will it affected my result badly?",
            FewUnitsOfTimeAgo::default(),
            "So I not sure, by getting old signal (get from a few ms ago), will it affected my result badly?",
        );
    }

    #[test]
    fn fix_seconds() {
        assert_suggestion_result(
            "I have submitted the same issue few seconds ago.",
            FewUnitsOfTimeAgo::default(),
            "I have submitted the same issue a few seconds ago.",
        );
    }

    #[test]
    fn fix_weekends() {
        assert_suggestion_result(
            "This challenge is a Python jail escape and lucky for me our team had just done one few weekends ago so I was fairly familiar with the tricks to break out.",
            FewUnitsOfTimeAgo::default(),
            "This challenge is a Python jail escape and lucky for me our team had just done one a few weekends ago so I was fairly familiar with the tricks to break out.",
        );
    }

    #[test]
    fn fix_weeks() {
        assert_suggestion_result(
            "Terraform cloud crashes on plan (same configuration worked few weeks ago)",
            FewUnitsOfTimeAgo::default(),
            "Terraform cloud crashes on plan (same configuration worked a few weeks ago)",
        );
    }

    #[test]
    fn fix_years() {
        assert_suggestion_result(
            "sandbox-exec was deprecated on MacOS few years ago",
            FewUnitsOfTimeAgo::default(),
            "sandbox-exec was deprecated on MacOS a few years ago",
        );
    }

    // Real world non-errors from GitHub

    #[test]
    fn dont_flag_centuries() {
        assert_lint_count(
            "Would have been useful a few centuries ago.",
            FewUnitsOfTimeAgo::default(),
            0,
        );
    }

    #[test]
    fn dont_flag_days() {
        assert_lint_count(
            "A few days ago, I upgraded ComfyUI to the latest version, then the prompt node can't upload prompt list text file in Ubuntu",
            FewUnitsOfTimeAgo::default(),
            0,
        );
    }

    #[test]
    fn dont_flag_decades() {
        assert_lint_count(
            "With your QA background you may have heard of the IBM black team of testers back a few decades ago.",
            FewUnitsOfTimeAgo::default(),
            0,
        );
    }

    #[test]
    fn dont_flag_hours() {
        assert_lint_count(
            "It was working well and we could see the installation page a few hours ago.",
            FewUnitsOfTimeAgo::default(),
            0,
        );
    }

    #[test]
    fn dont_flag_milliseconds() {
        assert_lint_count(
            "It is actually the true motor angle observed a few milliseconds ago (pd latency).",
            FewUnitsOfTimeAgo::default(),
            0,
        );
    }

    #[test]
    fn dont_flag_minutes() {
        assert_lint_count(
            "Example from DoD The following was circulated a few minutes ago on an IDESG/NSTIC list",
            FewUnitsOfTimeAgo::default(),
            0,
        );
    }

    #[test]
    fn dont_flag_moments() {
        assert_lint_count(
            "Our microservices started failing a few moments ago when creating new...",
            FewUnitsOfTimeAgo::default(),
            0,
        );
    }

    #[test]
    fn dont_flag_months() {
        assert_lint_count(
            "A few months ago there was an mixed reality project.",
            FewUnitsOfTimeAgo::default(),
            0,
        );
    }

    #[test]
    fn dont_flag_nights() {
        assert_lint_count(
            "As an example, a few nights ago I was working on my laptop and stuff that had been working stopped working.",
            FewUnitsOfTimeAgo::default(),
            0,
        );
    }

    #[test]
    fn dont_flag_seconds() {
        assert_lint_count(
            "0 - 45 seconds, a few seconds ago.",
            FewUnitsOfTimeAgo::default(),
            0,
        );
    }

    #[test]
    fn dont_flag_weeks() {
        assert_lint_count(
            "It was all working perfectly till a few weeks ago.",
            FewUnitsOfTimeAgo::default(),
            0,
        );
    }

    #[test]
    fn dont_flag_years() {
        assert_lint_count(
            "Hello, I've been an intensive user of your dada2 pipeline until a few years ago.",
            FewUnitsOfTimeAgo::default(),
            0,
        );
    }

    // Real world non-errors from GitHub (but using singular forms)

    #[test]
    fn dont_flag_decade() {
        assert_lint_count(
            "With your QA background you may have heard of the IBM black team of testers back a few decade ago.",
            FewUnitsOfTimeAgo::default(),
            0,
        );
    }

    #[test]
    fn dont_flag_hour() {
        assert_lint_count(
            "It was working well and we could see the installation page a few hour ago.",
            FewUnitsOfTimeAgo::default(),
            0,
        );
    }

    #[test]
    fn dont_flag_millennia() {
        assert_lint_count(
            "A few millennia ago, there was a civilization here",
            FewUnitsOfTimeAgo::default(),
            0,
        );
    }

    #[test]
    fn dont_flag_minute() {
        assert_lint_count(
            "Example from DoD The following was circulated a few minute ago on an IDESG/NSTIC list",
            FewUnitsOfTimeAgo::default(),
            0,
        );
    }

    #[test]
    fn dont_flag_moment() {
        assert_lint_count(
            "No problem should be in the updated version pushed a few moment ago will be live in beta in about 10 min.",
            FewUnitsOfTimeAgo::default(),
            0,
        );
    }

    #[test]
    fn dont_flag_month() {
        assert_lint_count(
            "I noticed the same thing a few month ago.",
            FewUnitsOfTimeAgo::default(),
            0,
        );
    }

    #[test]
    fn dont_flag_second() {
        assert_lint_count(
            "Bug it doesnt even answer me rn, like a few second ago he did",
            FewUnitsOfTimeAgo::default(),
            0,
        );
    }

    #[test]
    fn dont_flag_week() {
        assert_lint_count(
            "A few week ago, when logging in the usual way",
            FewUnitsOfTimeAgo::default(),
            0,
        );
    }

    #[test]
    fn dont_flag_year() {
        assert_lint_count(
            "Hello, I've been an intensive user of your dada2 pipeline until a few year ago.",
            FewUnitsOfTimeAgo::default(),
            0,
        );
    }

    // Real world non-errors from GitHub using apostrophes

    #[test]
    fn dont_flag_days_apos() {
        assert_lint_count(
            "And finally it got released a few day's ago.",
            FewUnitsOfTimeAgo::default(),
            0,
        );
    }

    #[test]
    fn dont_flag_months_apos() {
        assert_lint_count(
            "I had thought that since I had done this process a few month's ago the database could just be updated.",
            FewUnitsOfTimeAgo::default(),
            0,
        );
    }

    #[test]
    fn dont_flag_weeks_apos() {
        assert_lint_count(
            "A few week's ago, I was alerted in Webmin that Webmin was eligible to upgrade to 1.880 which I did through Webmin.",
            FewUnitsOfTimeAgo::default(),
            0,
        );
    }

    #[test]
    fn dont_flag_years_apos() {
        assert_lint_count(
            "A few year's ago a spammer registered an unused base url",
            FewUnitsOfTimeAgo::default(),
            0,
        );
    }

    // Real world mistakes from GitHub using singular forms

    #[test]
    fn fix_day() {
        assert_suggestion_result(
            "That worked few day ago with the same setting.",
            FewUnitsOfTimeAgo::default(),
            "That worked a few day ago with the same setting.",
        );
    }

    #[test]
    #[ignore = "Needs ^ zero-width anchor that matches the start of a chunk"]
    fn fix_decade() {
        assert_suggestion_result(
            "few decade ago, African Americans weren't allowed to swim in public",
            FewUnitsOfTimeAgo::default(),
            "a few decade ago, African Americans weren't allowed to swim in public",
        );
    }

    #[test]
    fn fix_minute() {
        assert_suggestion_result(
            "All works fine, but few minute ago the device stop responding from web",
            FewUnitsOfTimeAgo::default(),
            "All works fine, but a few minute ago the device stop responding from web",
        );
    }

    #[test]
    fn fix_weekend() {
        assert_suggestion_result(
            "I have done this few weekend ago.",
            FewUnitsOfTimeAgo::default(),
            "I have done this a few weekend ago.",
        );
    }
}



================================================
FILE: harper-core/src/linting/filler_words.rs
================================================
use crate::linting::expr_linter::Chunk;
use crate::{
    Lrc, Token, TokenStringExt,
    expr::{Expr, SequenceExpr},
    linting::{ExprLinter, Lint, LintKind, Suggestion},
    patterns::WordSet,
};

pub struct FillerWords {
    expr: Box<dyn Expr>,
}

impl Default for FillerWords {
    // A filler is unlikely to be completely on its own, so check for and remove with whitespace either before or after.
    fn default() -> Self {
        let filler_words = Lrc::new(WordSet::new(&["uh", "um"]));

        let pattern = SequenceExpr::default().then_any_of(vec![
            Box::new(
                SequenceExpr::default()
                    .then(filler_words.clone())
                    .then_whitespace(),
            ),
            Box::new(SequenceExpr::default().then_whitespace().then(filler_words)),
        ]);

        Self {
            expr: Box::new(pattern),
        }
    }
}

impl ExprLinter for FillerWords {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, toks: &[Token], _src: &[char]) -> Option<Lint> {
        // A filler is unlikely to be completely on its own, so check for and remove with whitespace either before or after.
        Some(Lint {
            span: toks.span()?,
            lint_kind: LintKind::Miscellaneous,
            suggestions: vec![Suggestion::Remove],
            message: "Remove this unnecessary filler word.".to_string(),
            priority: 31,
        })
    }

    fn description(&self) -> &str {
        "Removes filler words."
    }
}

#[cfg(test)]
mod tests {
    use super::FillerWords;
    use crate::linting::tests::assert_suggestion_result;

    #[test]
    fn remove_uh() {
        assert_suggestion_result(
            "Let's remove all the uh filler words.",
            FillerWords::default(),
            "Let's remove all the filler words.",
        );
    }

    #[test]
    fn remove_um_st_start() {
        assert_suggestion_result(
            "Um but I'll just add some context for this.",
            FillerWords::default(),
            "but I'll just add some context for this.",
        );
    }
}



================================================
FILE: harper-core/src/linting/find_fine.rs
================================================
use crate::Token;
use crate::expr::Expr;
use crate::expr::SequenceExpr;
use crate::patterns::InflectionOfBe;

use super::expr_linter::Chunk;
use super::{ExprLinter, Lint, LintKind, Suggestion};

pub struct FindFine {
    expr: Box<dyn Expr>,
}

impl Default for FindFine {
    fn default() -> Self {
        let expr = SequenceExpr::default()
            .then(InflectionOfBe::default())
            .t_ws()
            .t_aco("find");

        Self {
            expr: Box::new(expr),
        }
    }
}

impl ExprLinter for FindFine {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], source: &[char]) -> Option<Lint> {
        let offending_word = matched_tokens.get(2)?;

        Some(Lint {
            span: offending_word.span,
            lint_kind: LintKind::Typo,
            suggestions: vec![Suggestion::replace_with_match_case_str(
                "fine",
                offending_word.span.get_content(source),
            )],
            message: "Did you mean `fine`?".to_owned(),
            priority: 63,
        })
    }

    fn description(&self) -> &'static str {
        "Fixes the common typo where writers write `find` when they mean `fine`."
    }
}

#[cfg(test)]
mod tests {
    use crate::linting::tests::assert_suggestion_result;

    use super::FindFine;

    #[test]
    fn issue_2115() {
        assert_suggestion_result(
            "I was using oil.nvim from an year and everything was find for me but I was missing a very key feature",
            FindFine::default(),
            "I was using oil.nvim from an year and everything was fine for me but I was missing a very key feature",
        );
        assert_suggestion_result(
            "I made several observations throughout the evening and everything was find.",
            FindFine::default(),
            "I made several observations throughout the evening and everything was fine.",
        );
        assert_suggestion_result(
            "I am find not using GPU at all for open3d.",
            FindFine::default(),
            "I am fine not using GPU at all for open3d.",
        );
    }
}



================================================
FILE: harper-core/src/linting/first_aid_kit.rs
================================================
use crate::expr::Expr;
use crate::expr::SequenceExpr;
use crate::linting::expr_linter::Chunk;
use crate::{
    Token,
    linting::{ExprLinter, Lint, LintKind, Suggestion},
    patterns::WordSet,
};

pub struct FirstAidKit {
    expr: Box<dyn Expr>,
}

impl Default for FirstAidKit {
    fn default() -> Self {
        let supply_words = WordSet::new(&["aid", "starter", "travel", "tool"]);
        let pattern = SequenceExpr::default()
            .then(supply_words)
            .then_whitespace()
            .then_any_capitalization_of("kid");
        Self {
            expr: Box::new(pattern),
        }
    }
}

impl ExprLinter for FirstAidKit {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, tokens: &[Token], source: &[char]) -> Option<Lint> {
        let typo_token = tokens.last()?;
        let typo_span = typo_token.span;
        let typo_text = typo_span.get_content(source);
        Some(Lint {
            span: typo_span,
            lint_kind: LintKind::WordChoice,
            suggestions: vec![Suggestion::replace_with_match_case(
                "kit".chars().collect(),
                typo_text,
            )],
            message: "Did you mean `kit` (a set of items) instead of “kid”?".to_string(),
            priority: 31,
        })
    }

    fn description(&self) -> &str {
        "Detects when “kid” after “aid”, “starter”, “travel”, or “tool” should be “kit” (a set of supplies)."
    }
}

#[cfg(test)]
mod tests {
    use super::FirstAidKit;
    use crate::linting::tests::{assert_lint_count, assert_suggestion_result};

    #[test]
    fn corrects_first_aid_kid() {
        assert_suggestion_result(
            "A first aid kid is a collection of medical supplies.",
            FirstAidKit::default(),
            "A first aid kit is a collection of medical supplies.",
        );
    }

    #[test]
    fn corrects_starter_kid() {
        assert_suggestion_result(
            "Check the starter kid before proceeding.",
            FirstAidKit::default(),
            "Check the starter kit before proceeding.",
        );
    }

    #[test]
    fn corrects_travel_kid() {
        assert_suggestion_result(
            "Pack your travel kid for the trip.",
            FirstAidKit::default(),
            "Pack your travel kit for the trip.",
        );
    }

    #[test]
    fn corrects_tool_kid() {
        assert_suggestion_result(
            "Don't forget the tool kid for assembly.",
            FirstAidKit::default(),
            "Don't forget the tool kit for assembly.",
        );
    }

    #[test]
    fn does_not_flag_kid_in_other_contexts() {
        assert_lint_count(
            "The kid ran through the aid station.",
            FirstAidKit::default(),
            0,
        );
    }
}



================================================
FILE: harper-core/src/linting/flesh_out_vs_full_fledged.rs
================================================
use crate::{
    expr::{Expr, SequenceExpr},
    linting::{ExprLinter, LintKind, Suggestion, expr_linter::Chunk},
    {CharStringExt, Lint, Token, TokenStringExt},
};

pub struct FleshOutVsFullFledged {
    expr: Box<dyn Expr>,
}

impl Default for FleshOutVsFullFledged {
    fn default() -> Self {
        Self {
            expr: Box::new(
                SequenceExpr::optional(SequenceExpr::word_set(&["full", "fully"]).t_ws_h())
                    .then_word_set(&[
                        "fledge", "fledged", "fledged", "fledges", "fledging", "flesh", "fleshed",
                        "fleshed", "fleshes", "fleshing", "pledge", "pledged", "pledged",
                        "pledges", "pledging",
                    ])
                    .then_optional(SequenceExpr::default().t_ws_h().t_aco("out")),
            ),
        }
    }
}

impl ExprLinter for FleshOutVsFullFledged {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint_with_context(
        &self,
        toks: &[Token],
        src: &[char],
        ctx: Option<(&[Token], &[Token])>,
    ) -> Option<Lint> {
        // Is the first word is "full" or "fully"?
        let has_full_y = toks
            .first()
            .map(|t| {
                t.span
                    .get_content(src)
                    .eq_any_ignore_ascii_case_str(&["full", "fully"])
            })
            .unwrap_or(false);

        // Is the last word is "out"?
        let mut has_out = toks
            .last()
            .map(|t| t.span.get_content(src).eq_ignore_ascii_case_str("out"))
            .unwrap_or(false);

        // Adjust tokens to exclude "out" when it's part of a hyphenated compound
        let toks = if has_out
            && ctx
                .is_some_and(|(_, next)| next.first().map(|t| t.kind.is_hyphen()).unwrap_or(false))
        {
            has_out = false;
            &toks[..toks.len() - 2]
        } else {
            toks
        };

        // Parse the verb form (tense)

        enum Form {
            Lemma,
            Past,
            ThirdPersonSingular,
            Ing,
        }

        let vtok_idx = if has_full_y { 2 } else { 0 };
        let vtok = &toks[vtok_idx];
        let vtok_chars = vtok.span.get_content(src);

        let form = match vtok_chars.last() {
            Some('d') => Form::Past,
            Some('s') => Form::ThirdPersonSingular,
            Some('g') => Form::Ing,
            _ => Form::Lemma,
        };

        // Parse which verb

        enum Verb {
            Fledge,
            Flesh,
            Pledge,
        }

        let verb = if vtok_chars.starts_with_ignore_ascii_case_str("fledg") {
            Verb::Fledge
        } else if vtok_chars.starts_with_ignore_ascii_case_str("flesh") {
            Verb::Flesh
        } else {
            Verb::Pledge
        };

        // Separated by spaces or hyphens? Abort if it's mixed.

        let mut sep_flags = 0;
        for sep_tok in toks.iter().skip(1).step_by(2) {
            if sep_tok.kind.is_hyphen() {
                sep_flags |= 1;
            } else if sep_tok.kind.is_whitespace() {
                sep_flags |= 2;
            } else {
                sep_flags |= 4;
            }
        }
        let is_hy = match sep_flags {
            1 => true,
            2 => false,
            _ => return None,
        };

        match (has_full_y, verb, &form, has_out) {
            // full pledge(d) -> full fledged
            // full fledge -> full fledged
            (true, Verb::Pledge, Form::Lemma | Form::Past, false)
            | (true, Verb::Fledge, Form::Lemma, false) => {
                let verb_and_sep_toks = &toks[0..2];
                let verb_and_sep_span = verb_and_sep_toks.span()?;

                Some(Lint {
                    span: toks.span()?,
                    lint_kind: LintKind::Usage,
                    suggestions: vec![Suggestion::replace_with_match_case(
                        format!("{}fledged", verb_and_sep_span.get_content_string(src))
                            .chars()
                            .collect(),
                        verb_and_sep_span.get_content(src),
                    )],
                    message: "This idiom uses the word `fledged`.".to_string(),
                    ..Default::default()
                })
            }
            // fledge out -> flesh out
            (false, Verb::Fledge | Verb::Pledge, _, true) => Some(Lint {
                span: vtok.span,
                lint_kind: LintKind::Usage,
                suggestions: vec![Suggestion::replace_with_match_case_str(
                    match &form {
                        Form::Lemma => "flesh",
                        Form::Past => "fleshed",
                        Form::Ing => "fleshing",
                        Form::ThirdPersonSingular => "fleshes",
                    },
                    vtok_chars,
                )],
                message: "This idiom uses the word `flesh`.".to_string(),
                ..Default::default()
            }),
            // TODO: only with "fully" and not "full"?
            // fully fledged/pledged out -> fully fledged / fully fleshed out
            // fully fleshed             -> fully fledged / fully fleshed out
            (true, Verb::Fledge | Verb::Pledge, Form::Past, true)
            | (true, Verb::Flesh, Form::Past, false) => Some(Lint {
                span: toks[vtok_idx..].span()?,
                lint_kind: LintKind::Usage,
                suggestions: vec![
                    Suggestion::replace_with_match_case_str("fledged", vtok_chars),
                    Suggestion::replace_with_match_case(
                        format!("fleshed{}out", if is_hy { '-' } else { ' ' })
                            .chars()
                            .collect(),
                        vtok_chars,
                    ),
                ],
                message: "Perhaps you're confusing `fully fledged` and `fleshed out`?".to_string(),
                ..Default::default()
            }),
            _ => None,
        }
    }

    fn description(&self) -> &str {
        "Corrects mixing up `flesh out` and `full fledged`."
    }
}

#[cfg(test)]
mod tests {
    use crate::linting::{
        flesh_out_vs_full_fledged::FleshOutVsFullFledged,
        tests::{assert_good_and_bad_suggestions, assert_suggestion_result},
    };

    // FULL

    // full Vlemma

    #[test]
    fn full_fledge_hyphen() {
        assert_suggestion_result(
            "Or do we want to become a full-fledge out-of-core ml library?",
            FleshOutVsFullFledged::default(),
            "Or do we want to become a full-fledged out-of-core ml library?",
        );
    }

    // full Vpast

    #[test]
    fn full_fleshed_space() {
        assert_suggestion_result(
            "Run a full fleshed ubuntu in termux without rooting your android.",
            FleshOutVsFullFledged::default(),
            "Run a full fledged ubuntu in termux without rooting your android.",
        );
    }

    #[test]
    fn full_fleshed_webscraper_hyphen() {
        assert_suggestion_result(
            "A full-fleshed webscraper web app build on Next.js13 with tracking the prices of different product you want",
            FleshOutVsFullFledged::default(),
            "A full-fledged webscraper web app build on Next.js13 with tracking the prices of different product you want",
        );
    }

    #[test]
    fn full_fleshed_implementation_hyphen() {
        assert_suggestion_result(
            "almost provides a full-fleshed implementation allowing to read binary files into a tensor in a torchscript-compatible way.",
            FleshOutVsFullFledged::default(),
            "almost provides a full-fledged implementation allowing to read binary files into a tensor in a torchscript-compatible way.",
        );
    }

    #[test]
    fn full_pledged_space() {
        assert_suggestion_result(
            "Any plan to make full pledged php server with swoole?",
            FleshOutVsFullFledged::default(),
            "Any plan to make full fledged php server with swoole?",
        );
    }

    #[test]
    fn full_pledged_hyphen() {
        assert_suggestion_result(
            "Not yet, but I am considering the full-pledged snapshotting built-in.",
            FleshOutVsFullFledged::default(),
            "Not yet, but I am considering the full-fledged snapshotting built-in.",
        );
    }

    // FULLY

    // fully Vpast - out

    #[test]
    fn not_fully_fledged_out() {
        assert_good_and_bad_suggestions(
            "There, it's not fully fledged out yet, but it's just an idea for now.",
            FleshOutVsFullFledged::default(),
            &[
                "There, it's not fully fleshed out yet, but it's just an idea for now.",
                "There, it's not fully fledged yet, but it's just an idea for now.",
            ],
            &[],
        );
    }

    #[test]
    fn fully_fledged_out() {
        assert_good_and_bad_suggestions(
            "Is the spawning process fully fledged out yet or am I joining the party too early?",
            FleshOutVsFullFledged::default(),
            &[
                "Is the spawning process fully fleshed out yet or am I joining the party too early?",
                "Is the spawning process fully fledged yet or am I joining the party too early?",
            ],
            &[],
        );
    }

    #[test]
    fn fully_fleshed_space() {
        assert_good_and_bad_suggestions(
            "A Fully Fleshed E-Commerce web application, built with React, Redux and Firebase",
            FleshOutVsFullFledged::default(),
            &[
                "A Fully Fledged E-Commerce web application, built with React, Redux and Firebase",
                "A Fully Fleshed out E-Commerce web application, built with React, Redux and Firebase",
            ],
            &[],
        );
    }

    #[test]
    fn fully_fleshed_hyphen() {
        assert_good_and_bad_suggestions(
            "This issue tracks the current progress towards publishing a fully-fleshed Fabric version of Gallery",
            FleshOutVsFullFledged::default(),
            &[
                "This issue tracks the current progress towards publishing a fully-fleshed-out Fabric version of Gallery",
                "This issue tracks the current progress towards publishing a fully-fledged Fabric version of Gallery",
            ],
            &[],
        );
    }

    #[test]
    fn fully_pledged_space() {
        assert_suggestion_result(
            "Overall, we are already moving closer to having a fully pledged distributed recording and replay.",
            FleshOutVsFullFledged::default(),
            "Overall, we are already moving closer to having a fully fledged distributed recording and replay.",
        );
    }

    // V.LEMMA - out

    #[test]
    fn fledge_out() {
        assert_suggestion_result(
            "For this we could fledge out the rule evaluation in a library and link this library to the server.",
            FleshOutVsFullFledged::default(),
            "For this we could flesh out the rule evaluation in a library and link this library to the server.",
        );
    }

    // V.PAST - out

    #[test]
    fn fledged_out_space() {
        assert_suggestion_result(
            "We will be talking more about this when the technical details a more fledged out.",
            FleshOutVsFullFledged::default(),
            "We will be talking more about this when the technical details a more fleshed out.",
        );
    }
}



================================================
FILE: harper-core/src/linting/for_noun.rs
================================================
use crate::expr::Expr;
use crate::expr::OwnedExprExt;
use crate::expr::SequenceExpr;
use crate::{
    Token,
    patterns::{NominalPhrase, Word},
};

use super::{ExprLinter, Lint, LintKind, Suggestion};
use crate::linting::expr_linter::Chunk;

pub struct ForNoun {
    expr: Box<dyn Expr>,
}

impl Default for ForNoun {
    fn default() -> Self {
        let pattern = SequenceExpr::aco("fro")
            .then_whitespace()
            .then(NominalPhrase.or(Word::new("sure")));

        Self {
            expr: Box::new(pattern),
        }
    }
}

impl ExprLinter for ForNoun {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], source: &[char]) -> Option<Lint> {
        let span = matched_tokens.first()?.span;
        let problem_chars = span.get_content(source);

        Some(Lint {
            span,
            lint_kind: LintKind::WordChoice,
            suggestions: vec![Suggestion::replace_with_match_case_str(
                "for",
                problem_chars,
            )],
            message: "`For` is more common in this context.".to_owned(),
            priority: 31,
        })
    }

    fn description(&self) -> &'static str {
        "Corrects the archaic or mistaken `fro` to `for` when followed by a noun."
    }
}

#[cfg(test)]
mod tests {
    use super::ForNoun;
    use crate::linting::tests::{assert_lint_count, assert_suggestion_result};

    #[test]
    fn corrects_fro_basic_correction() {
        assert_suggestion_result(
            "I got a text fro Sarah.",
            ForNoun::default(),
            "I got a text for Sarah.",
        );
    }

    #[test]
    fn allows_for_clean() {
        assert_lint_count("I got a text for Sarah.", ForNoun::default(), 0);
    }

    #[test]
    fn corrects_fro_sure() {
        assert_suggestion_result(
            "He was away fro sure!",
            ForNoun::default(),
            "He was away for sure!",
        );
    }
}



================================================
FILE: harper-core/src/linting/free_predicate.rs
================================================
use std::sync::Arc;

use crate::Token;
use crate::TokenKind;
use crate::char_string::CharStringExt;
use crate::expr::{Expr, ExprMap, SequenceExpr};
use crate::patterns::WhitespacePattern;

use super::{ExprLinter, Lint, LintKind, Suggestion};
use crate::linting::expr_linter::Chunk;

pub struct FreePredicate {
    expr: Box<dyn Expr>,
    map: Arc<ExprMap<usize>>,
}

impl Default for FreePredicate {
    fn default() -> Self {
        let mut map = ExprMap::default();

        let no_modifier = SequenceExpr::default()
            .then(linking_like)
            .t_ws()
            .then(matches_fee)
            .then_optional(WhitespacePattern)
            .then(follows_fee);

        map.insert(no_modifier, 2);

        let with_adverb = SequenceExpr::default()
            .then(linking_like)
            .t_ws()
            .then_adverb()
            .t_ws()
            .then(matches_fee)
            .then_optional(WhitespacePattern)
            .then(follows_fee);

        map.insert(with_adverb, 4);

        let map = Arc::new(map);

        Self {
            expr: Box::new(map.clone()),
            map,
        }
    }
}

impl ExprLinter for FreePredicate {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], source: &[char]) -> Option<Lint> {
        let offending_idx = *self.map.lookup(0, matched_tokens, source)?;
        let offending = matched_tokens.get(offending_idx)?;

        Some(Lint {
            span: offending.span,
            lint_kind: LintKind::WordChoice,
            suggestions: vec![Suggestion::replace_with_match_case_str(
                "free",
                offending.span.get_content(source),
            )],
            message: "Use `free` here to show that something costs nothing.".to_owned(),
            priority: 38,
        })
    }

    fn description(&self) -> &'static str {
        "Helps swap in `free` when a linking verb is followed by the noun `fee`."
    }
}

fn matches_fee(token: &Token, source: &[char]) -> bool {
    if !token.kind.is_noun() {
        return false;
    }

    const FEE: [char; 3] = ['f', 'e', 'e'];
    let content = token.span.get_content(source);

    content.len() == FEE.len()
        && content
            .iter()
            .zip(FEE)
            .all(|(actual, expected)| actual.eq_ignore_ascii_case(&expected))
}

fn follows_fee(token: &Token, _source: &[char]) -> bool {
    if token.kind.is_hyphen() {
        return false;
    }

    token.kind.is_preposition()
        || token.kind.is_conjunction()
        || matches!(token.kind, TokenKind::Punctuation(_))
}

fn linking_like(token: &Token, source: &[char]) -> bool {
    const BE_FORMS: [&str; 8] = ["be", "is", "am", "are", "was", "were", "being", "been"];
    let content = token.span.get_content(source);

    BE_FORMS
        .iter()
        .any(|form| content.eq_ignore_ascii_case_str(form))
}

#[cfg(test)]
mod tests {
    use crate::linting::tests::{assert_lint_count, assert_no_lints, assert_suggestion_result};

    use super::FreePredicate;

    #[test]
    fn corrects_is_fee_for() {
        assert_suggestion_result(
            "The trial is fee for new members.",
            FreePredicate::default(),
            "The trial is free for new members.",
        );
    }

    #[test]
    fn corrects_totally_fee() {
        assert_suggestion_result(
            "Customer support is totally fee.",
            FreePredicate::default(),
            "Customer support is totally free.",
        );
    }

    #[test]
    fn corrects_really_fee_to() {
        assert_suggestion_result(
            "The workshop is really fee to attend.",
            FreePredicate::default(),
            "The workshop is really free to attend.",
        );
    }

    #[test]
    fn corrects_fee_with_comma() {
        assert_suggestion_result(
            "Our platform is fee, and always available.",
            FreePredicate::default(),
            "Our platform is free, and always available.",
        );
    }

    #[test]
    fn corrects_fee_period() {
        assert_suggestion_result(
            "Access is fee.",
            FreePredicate::default(),
            "Access is free.",
        );
    }

    #[test]
    fn corrects_fee_past_tense() {
        assert_suggestion_result(
            "The program was fee for nonprofits.",
            FreePredicate::default(),
            "The program was free for nonprofits.",
        );
    }

    #[test]
    fn allows_fee_based() {
        assert_no_lints("The pricing model is fee-based.", FreePredicate::default());
    }

    #[test]
    fn allows_fee_paying() {
        assert_no_lints("The membership is fee-paying.", FreePredicate::default());
    }

    #[test]
    fn allows_fee_schedule_statement() {
        assert_no_lints(
            "This plan has a fee for standard support.",
            FreePredicate::default(),
        );
    }

    #[test]
    fn allows_fee_free_phrase() {
        assert_no_lints(
            "Our service is fee-free for students.",
            FreePredicate::default(),
        );
    }

    #[test]
    fn counts_single_lint() {
        assert_lint_count(
            "The upgrade is fee for existing users.",
            FreePredicate::default(),
            1,
        );
    }
}



================================================
FILE: harper-core/src/linting/friend_of_me.rs
================================================
use crate::linting::expr_linter::Chunk;
use crate::{
    Token,
    expr::{Expr, SequenceExpr},
    linting::{ExprLinter, Lint, LintKind, Suggestion},
};

pub struct FriendOfMe {
    expr: Box<dyn Expr>,
}

impl Default for FriendOfMe {
    fn default() -> Self {
        Self {
            expr: Box::new(
                SequenceExpr::word_set(&["friend", "friends", "enemy", "enemies"])
                    .then_whitespace()
                    .t_aco("of")
                    .t_ws()
                    .then_object_pronoun(),
            ),
        }
    }
}

impl ExprLinter for FriendOfMe {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, toks: &[Token], src: &[char]) -> Option<Lint> {
        let obj_pron_tok = toks.last()?;
        let obj_pron_str = obj_pron_tok.span.get_content_string(src);

        let poss_pron_str = match obj_pron_str.as_str() {
            "me" => "mine",
            "you" => "yours",
            "him" => "his",
            // "her" is also a possessive determiner, which leads to many false positives
            "her" => return None,
            "it" => return None,
            "us" => "ours",
            "them" => "theirs",
            _ => return None,
        };

        Some(Lint {
            span: obj_pron_tok.span,
            lint_kind: LintKind::Grammar,
            suggestions: vec![Suggestion::replace_with_match_case_str(
                poss_pron_str,
                obj_pron_tok.span.get_content(src),
            )],
            message: format!("Use `{poss_pron_str}` instead of `{obj_pron_str}`."),
            priority: 31,
        })
    }

    fn description(&self) -> &'static str {
        "Corrects wrong pronoun usage in constructions like `a friend of me`."
    }
}

#[cfg(test)]
mod tests {
    use super::FriendOfMe;
    use crate::linting::tests::assert_suggestion_result;

    #[test]
    fn corrects_friend_of_me() {
        assert_suggestion_result(
            "Last year a friend of me died unexpectedly (not a close friend).",
            FriendOfMe::default(),
            "Last year a friend of mine died unexpectedly (not a close friend).",
        );
    }

    #[test]
    fn corrects_friend_of_you() {
        assert_suggestion_result(
            "imagine a friend of you wants to disturb your call, and send you a session-terminate with a wrong SID",
            FriendOfMe::default(),
            "imagine a friend of yours wants to disturb your call, and send you a session-terminate with a wrong SID",
        );
    }

    #[test]
    fn corrects_friend_of_us() {
        assert_suggestion_result(
            "You have denounced a friend of us! You have denounced an enemy of us.",
            FriendOfMe::default(),
            "You have denounced a friend of ours! You have denounced an enemy of ours.",
        );
    }

    #[test]
    fn corrects_friends_of_them() {
        assert_suggestion_result(
            "guest has friend and they see which friends of them are comming",
            FriendOfMe::default(),
            "guest has friend and they see which friends of theirs are comming",
        );
    }

    #[test]
    fn corrects_friend_of_him() {
        assert_suggestion_result(
            "Ah, got it, i thought you may was a friend of him",
            FriendOfMe::default(),
            "Ah, got it, i thought you may was a friend of his",
        );
    }

    #[test]
    fn corrects_friends_of_me() {
        assert_suggestion_result(
            "guest has friend and they see which friends of me are comming",
            FriendOfMe::default(),
            "guest has friend and they see which friends of mine are comming",
        );
    }

    #[test]
    fn corrects_friends_of_us() {
        assert_suggestion_result(
            "This project was created for friends of us.",
            FriendOfMe::default(),
            "This project was created for friends of ours.",
        );
    }
}



================================================
FILE: harper-core/src/linting/go_so_far_as_to.rs
================================================
use crate::Token;
use crate::TokenStringExt;
use crate::expr::{Expr, SequenceExpr};
use crate::linting::Suggestion;
use crate::linting::expr_linter::Chunk;
use crate::linting::{ExprLinter, Lint, LintKind};

pub struct GoSoFarAsTo {
    exp: Box<dyn Expr>,
}

impl Default for GoSoFarAsTo {
    fn default() -> Self {
        Self {
            exp: Box::new(
                SequenceExpr::word_set(&["go", "goes", "going", "gone", "went"])
                    .then_fixed_phrase(" so far to ")
                    .then_optional(SequenceExpr::default().then_adverb().t_ws())
                    .then_any_word(),
            ),
        }
    }
}

impl ExprLinter for GoSoFarAsTo {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.exp.as_ref()
    }

    fn match_to_lint(&self, toks: &[Token], src: &[char]) -> Option<Lint> {
        let toks_len = toks.len();

        if toks_len != 9 && toks_len != 11 {
            return None;
        }

        let last = toks.last().unwrap();
        let penult = &toks[toks_len - 3];

        match (toks_len, penult.kind.is_adverb(), last.kind.is_verb_lemma()) {
            (11, true, true) => (),
            (9, _, true) => (),
            _ => return None,
        }

        let go_so_far_to_toks = &toks[0..=6];
        let go_so_far_to_span = go_so_far_to_toks.span()?;
        let go_so_far_toks = &toks[0..=4];
        let to_tok = &toks[6];

        let sugg = Suggestion::replace_with_match_case(
            format!(
                "{} as {}",
                go_so_far_toks.span()?.get_content_string(src),
                to_tok.span.get_content_string(src)
            )
            .chars()
            .collect(),
            go_so_far_to_span.get_content(src),
        );

        Some(Lint {
            span: go_so_far_to_span,
            lint_kind: LintKind::Nonstandard,
            suggestions: vec![sugg],
            message: "If this is intended to express going beyond what's expected, the standard idiom is `go so far as to`".to_string(),
            ..Default::default()
        })
    }

    fn description(&self) -> &'static str {
        "Flags 'go so far to' when it should be 'go so far as to' to express going beyond expectations"
    }
}

#[cfg(test)]
mod tests {
    use super::GoSoFarAsTo;
    use crate::linting::tests::{assert_no_lints, assert_suggestion_result};

    #[test]
    fn go_so_far_to() {
        assert_suggestion_result(
            "I'd even go so far to say as it's a good way to get started with getting things onto ...",
            GoSoFarAsTo::default(),
            "I'd even go so far as to say as it's a good way to get started with getting things onto ...",
        );
    }

    #[test]
    fn goes_so_far_to() {
        assert_suggestion_result(
            "I believe Java goes so far to even throw a runtime exception.",
            GoSoFarAsTo::default(),
            "I believe Java goes so far as to even throw a runtime exception.",
        );
    }

    #[test]
    fn gone_so_far_to() {
        assert_suggestion_result(
            "I've gone so far to reinstall Mac OS, which got the runner to finally start",
            GoSoFarAsTo::default(),
            "I've gone so far as to reinstall Mac OS, which got the runner to finally start",
        );
    }

    #[test]
    fn went_so_far_to() {
        assert_suggestion_result(
            "I've read these posts but only went so far to conclude that I need to potentially add sql statements into the blocks",
            GoSoFarAsTo::default(),
            "I've read these posts but only went so far as to conclude that I need to potentially add sql statements into the blocks",
        );
    }

    #[test]
    fn went_so_far_to_adverb() {
        assert_suggestion_result(
            "I even went so far to manually replace the .AppImage with a different file in the Applications folder",
            GoSoFarAsTo::default(),
            "I even went so far as to manually replace the .AppImage with a different file in the Applications folder",
        );
    }

    #[test]
    #[ignore = "A false positive we can't detect due to the next word being a verb lemma"]
    fn dont_flag_going_so_far_to() {
        assert_no_lints(
            "Why dictate that the system must be canonically described through a textual syntax – especially after going so far to make that unnecessary?",
            GoSoFarAsTo::default(),
        );
    }

    #[test]
    fn dont_flag_goes_so_far_to() {
        assert_no_lints(
            "... even so much that one line goes so far to the right",
            GoSoFarAsTo::default(),
        );
    }

    #[test]
    fn dont_flag_go_so_far_to() {
        assert_no_lints(
            "Unfortunetly, our logs don't go so far to that time, but I found something interesting.",
            GoSoFarAsTo::default(),
        );
    }
}



================================================
FILE: harper-core/src/linting/good_at.rs
================================================
use crate::{
    Lint, Token, TokenStringExt,
    expr::{Expr, FirstMatchOf, SequenceExpr},
    linting::{ExprLinter, LintKind, Suggestion, expr_linter::Chunk},
    patterns::{InflectionOfBe, WordSet},
};

pub struct GoodAt {
    expr: Box<dyn Expr>,
}

impl Default for GoodAt {
    fn default() -> Self {
        let we_re_not_always_very_good_in_sth = SequenceExpr::default()
            .then_any_of(vec![
                Box::new(InflectionOfBe::default()),
                Box::new(WordSet::new(&[
                    "I'm", "we're", "you're", "he's", "she's", "it's", "they're", "Im", "were",
                    "youre", "your", "hes", "shes", "its", "theyre",
                ])),
            ])
            .t_ws()
            .then_optional(SequenceExpr::aco("not").t_ws())
            .then_optional(SequenceExpr::default().then_frequency_adverb().t_ws())
            .then_optional(SequenceExpr::default().then_degree_adverb().t_ws())
            .then_word_set(&["good", "bad", "great", "okay", "OK"])
            .t_ws()
            .t_aco("in")
            .t_ws()
            .then_any_word();

        let good_in_skill_or_subject =
            SequenceExpr::word_set(&["good", "bad", "great", "okay", "OK"])
                .t_ws()
                .t_aco("in")
                .t_ws()
                .then_word_set(&[
                    // sciences
                    "biology",
                    "chemistry",
                    "math",
                    "mathematics",
                    "physics",
                    // programming
                    "programming",
                    "coding",
                    "c", // Note: C++ would be multiple tokens
                    "debugging",
                    "go",
                    "java",
                    "javascript",
                    "laravel",
                    "python",
                    "ruby",
                    // languages
                    "english",
                    "chinese",
                    "french",
                    "german",
                    "japanese",
                    "spanish",
                ]);

        let expr = FirstMatchOf::new(vec![
            Box::new(we_re_not_always_very_good_in_sth),
            Box::new(good_in_skill_or_subject),
        ]);

        Self {
            expr: Box::new(expr),
        }
    }
}

impl ExprLinter for GoodAt {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, toks: &[Token], src: &[char]) -> Option<Lint> {
        let prep_span = toks.get_rel(-3)?.span;

        Some(Lint {
            span: prep_span,
            lint_kind: LintKind::Usage,
            suggestions: vec![Suggestion::replace_with_match_case(
                "at".chars().collect(),
                prep_span.get_content(src),
            )],
            message: "Use 'good at' to describe proficiency with a skill.".to_string(),
            ..Default::default()
        })
    }

    fn description(&self) -> &'static str {
        "Checks for `good in` used instead of `good at` to describe proficiency with a skill."
    }
}

#[cfg(test)]
mod tests {
    use super::GoodAt;
    use crate::linting::tests::assert_suggestion_result;

    #[test]
    fn fix_good_in_being_frugal() {
        assert_suggestion_result(
            "but we found that Claude is not always very good in being frugal ( Gemini seemed better at it ) .",
            GoodAt::default(),
            "but we found that Claude is not always very good at being frugal ( Gemini seemed better at it ) .",
        );
    }

    #[test]
    fn fix_im_not_good_in_python() {
        assert_suggestion_result(
            "can't run it i'm not good in python",
            GoodAt::default(),
            "can't run it i'm not good at python",
        );
    }

    #[test]
    fn fix_not_good_in_go() {
        assert_suggestion_result(
            "Hi, I have very similar problem and I'm not good in go either.",
            GoodAt::default(),
            "Hi, I have very similar problem and I'm not good at go either.",
        );
    }

    #[test]
    fn fix_not_good_in_coding_stuff() {
        assert_suggestion_result(
            "Unfortunately I can't help in anyway but testing, because I'm not good in coding stuff.",
            GoodAt::default(),
            "Unfortunately I can't help in anyway but testing, because I'm not good at coding stuff.",
        );
    }

    #[test]
    fn fix_very_good_in_mathematics() {
        assert_suggestion_result(
            "They were very good in Mathematics and were the pets of Ranjani Ma'am.",
            GoodAt::default(),
            "They were very good at Mathematics and were the pets of Ranjani Ma'am.",
        );
    }

    #[test]
    fn fix_not_good_in_coding() {
        assert_suggestion_result(
            "Didnt know these things.. and since im not good in coding, maybe one day someone will work on this.",
            GoodAt::default(),
            "Didnt know these things.. and since im not good at coding, maybe one day someone will work on this.",
        );
    }

    #[test]
    fn fix_very_good_in_most_things() {
        assert_suggestion_result(
            "But I do want to continue using riverpod because its very good in most things I need from my app.",
            GoodAt::default(),
            "But I do want to continue using riverpod because its very good at most things I need from my app.",
        );
    }

    #[test]
    fn fix_not_good_in_laravel() {
        assert_suggestion_result(
            "im not good in laravel.",
            GoodAt::default(),
            "im not good at laravel.",
        );
    }

    #[test]
    fn fixim_not_good_in_english() {
        assert_suggestion_result(
            "Sorry about my grammar im not good in English.",
            GoodAt::default(),
            "Sorry about my grammar im not good at English.",
        );
    }

    #[test]
    fn fix_not_all_good_in_english() {
        assert_suggestion_result(
            "I think if there is translation support will be great, our school society not all good in english.",
            GoodAt::default(),
            "I think if there is translation support will be great, our school society not all good at english.",
        );
    }

    #[test]
    fn fix_i_am_not_good_in_english() {
        assert_suggestion_result(
            "I am in Togo, i am not good in english but i will ask you to apologize me for my speaking.",
            GoodAt::default(),
            "I am in Togo, i am not good at english but i will ask you to apologize me for my speaking.",
        );
    }

    #[test]
    fn fix_not_good_in_programming() {
        assert_suggestion_result(
            "Is it My Drive,Chess or \"My Drive\",\"Chess\" or what? Because I'm not good in programming.",
            GoodAt::default(),
            "Is it My Drive,Chess or \"My Drive\",\"Chess\" or what? Because I'm not good at programming.",
        );
    }

    #[test]
    fn fix_not_so_good_in_coding() {
        assert_suggestion_result(
            "I'm not so good in coding to understand how to handle all these bytes...",
            GoodAt::default(),
            "I'm not so good at coding to understand how to handle all these bytes...",
        );
    }

    #[test]
    fn fix_im_not_good_in_programming() {
        assert_suggestion_result(
            "Im not good in programming , but can i ask what is the password of your codes?",
            GoodAt::default(),
            "Im not good at programming , but can i ask what is the password of your codes?",
        );
    }
}



================================================
FILE: harper-core/src/linting/handful.rs
================================================
use crate::expr::{Expr, SequenceExpr, SpaceOrHyphen};
use crate::linting::expr_linter::Chunk;
use crate::{Token, TokenStringExt};

use super::{ExprLinter, Lint, LintKind, Suggestion};

pub struct Handful {
    expr: Box<dyn Expr>,
}

impl Default for Handful {
    fn default() -> Self {
        let expr = SequenceExpr::default()
            .then_any_capitalization_of("hand")
            .then_one_or_more(SpaceOrHyphen)
            .then_any_capitalization_of("full")
            .then_one_or_more(SpaceOrHyphen)
            .then_any_capitalization_of("of");

        Self {
            expr: Box::new(expr),
        }
    }
}

impl ExprLinter for Handful {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], source: &[char]) -> Option<Lint> {
        if matched_tokens.len() < 2 {
            return None;
        }

        let mut highlight_end = matched_tokens.len() - 1;
        while highlight_end > 0 {
            let prev = &matched_tokens[highlight_end - 1];
            if prev.kind.is_whitespace() || prev.kind.is_hyphen() {
                highlight_end -= 1;
            } else {
                break;
            }
        }

        if highlight_end == 0 {
            return None;
        }

        let replacement = &matched_tokens[..highlight_end];
        let span = replacement.span()?;
        let template = matched_tokens.first()?.span.get_content(source);

        Some(Lint {
            span,
            lint_kind: LintKind::BoundaryError,
            suggestions: vec![Suggestion::replace_with_match_case(
                "handful".chars().collect(),
                template,
            )],
            message: "Write this quantity as the single word `handful`.".to_owned(),
            priority: 31,
        })
    }

    fn description(&self) -> &'static str {
        "Keeps the palm-sized quantity expressed by `handful` as one word."
    }
}

#[cfg(test)]
mod tests {
    use super::Handful;
    use crate::linting::tests::{assert_lint_count, assert_no_lints, assert_suggestion_result};

    #[test]
    fn suggests_plain_spacing() {
        assert_suggestion_result(
            "Her basket held a hand full of berries.",
            Handful::default(),
            "Her basket held a handful of berries.",
        );
    }

    #[test]
    fn suggests_capitalized_form() {
        assert_suggestion_result(
            "Hand full of tales lined the shelf.",
            Handful::default(),
            "Handful of tales lined the shelf.",
        );
    }

    #[test]
    fn suggests_hyphenated_form() {
        assert_suggestion_result(
            "A hand-full of marbles scattered across the floor.",
            Handful::default(),
            "A handful of marbles scattered across the floor.",
        );
    }

    #[test]
    fn suggests_space_hyphen_combo() {
        assert_suggestion_result(
            "A hand - full of seeds spilled on the workbench.",
            Handful::default(),
            "A handful of seeds spilled on the workbench.",
        );
    }

    #[test]
    fn suggests_initial_hyphen_variants() {
        assert_suggestion_result(
            "Hand-Full of furniture, the cart creaked slowly.",
            Handful::default(),
            "Handful of furniture, the cart creaked slowly.",
        );
    }

    #[test]
    fn flags_multiple_instances() {
        assert_lint_count(
            "She carried a hand full of carrots and a hand full of radishes.",
            Handful::default(),
            2,
        );
    }

    #[test]
    fn allows_correct_handful() {
        assert_no_lints(
            "A handful of volunteers arrived in time.",
            Handful::default(),
        );
    }

    #[test]
    fn allows_parenthetical_hand() {
        assert_no_lints(
            "His hand, full of ink, kept writing without pause.",
            Handful::default(),
        );
    }

    #[test]
    fn allows_hand_is_full() {
        assert_no_lints("The hand is full of water.", Handful::default());
    }

    #[test]
    fn allows_handfull_typo() {
        assert_no_lints(
            "The word handfull is an incorrect spelling.",
            Handful::default(),
        );
    }
}



================================================
FILE: harper-core/src/linting/have_pronoun.rs
================================================
use crate::expr::{AnchorStart, Expr, SequenceExpr};
use crate::{Token, TokenKind};

use super::{ExprLinter, Lint, LintKind, Suggestion};
use crate::linting::expr_linter::Chunk;

pub struct HavePronoun {
    expr: Box<dyn Expr>,
}

impl Default for HavePronoun {
    fn default() -> Self {
        let expr = SequenceExpr::default()
            .then(AnchorStart)
            .t_aco("has")
            .t_ws()
            .then_kind_either(
                TokenKind::is_first_person_singular_pronoun,
                TokenKind::is_plural_pronoun,
            );

        Self {
            expr: Box::new(expr),
        }
    }
}

impl ExprLinter for HavePronoun {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, toks: &[Token], src: &[char]) -> Option<Lint> {
        // First real word in the match is always "has".
        let has_tok = toks.iter().find(|t| t.kind.is_word())?;
        let span = has_tok.span;
        let original = span.get_content(src);

        Some(Lint {
            span,
            lint_kind: LintKind::Agreement,
            suggestions: vec![Suggestion::replace_with_match_case(
                "have".chars().collect(),
                original,
            )],
            message: "Use `have` with first-person singular or plural pronouns.".to_owned(),
            priority: 31,
        })
    }

    fn description(&self) -> &'static str {
        "Flags questions that begin with `has` followed by a pronoun that requires `have`, \
         such as `Has we …` or `Has I …`, and suggests the correct auxiliary."
    }
}

#[cfg(test)]
mod tests {
    use super::HavePronoun;
    use crate::linting::tests::{assert_lint_count, assert_suggestion_result};

    #[test]
    fn corrects_has_we() {
        assert_suggestion_result(
            "Has we finished the report?",
            HavePronoun::default(),
            "Have we finished the report?",
        );
    }

    #[test]
    fn corrects_has_you() {
        assert_suggestion_result(
            "Has you misunderstood?",
            HavePronoun::default(),
            "Have you misunderstood?",
        );
    }

    #[test]
    fn corrects_has_i() {
        assert_suggestion_result(
            "Has I misunderstood?",
            HavePronoun::default(),
            "Have I misunderstood?",
        );
    }

    #[test]
    fn corrects_has_they() {
        assert_suggestion_result(
            "Has they arrived yet?",
            HavePronoun::default(),
            "Have they arrived yet?",
        );
    }

    #[test]
    fn allows_has_he() {
        assert_lint_count("Has he arrived yet?", HavePronoun::default(), 0);
    }

    #[test]
    fn ignores_non_initial_usage() {
        assert_lint_count(
            "The system has we confused for a moment.",
            HavePronoun::default(),
            0,
        );
    }
}



================================================
FILE: harper-core/src/linting/have_take_a_look.rs
================================================
use crate::linting::expr_linter::Chunk;
use crate::{
    Dialect, Token,
    expr::{Expr, FixedPhrase, SequenceExpr},
    linting::{ExprLinter, Lint, LintKind, Suggestion},
    patterns::WordSet,
};

pub struct HaveTakeALook {
    expr: Box<dyn Expr>,
    dialect: Dialect,
}

impl HaveTakeALook {
    pub fn new(dialect: Dialect) -> Self {
        let light_verb = match dialect {
            // Match the opposite of what is used in the dialect.
            Dialect::British | Dialect::Australian => &["take", "took", "taken", "takes", "taking"],
            _ => &["have", "had", "had", "has", "having"],
        };

        let expr = SequenceExpr::default()
            .then(WordSet::new(light_verb))
            .t_ws()
            .then(FixedPhrase::from_phrase("a look"));

        Self {
            expr: Box::new(expr),
            dialect,
        }
    }
}

impl ExprLinter for HaveTakeALook {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, toks: &[Token], src: &[char]) -> Option<Lint> {
        let light_verb_tok = toks.first().unwrap();
        let light_verb_str = light_verb_tok.span.get_content_string(src);
        let light_verb = light_verb_str.to_ascii_lowercase();

        let translated_light_verb: &[&str] = match light_verb.as_str() {
            "have" => &["take"],
            "had" => &["took", "taken"],
            "has" => &["takes"],
            "having" => &["taking"],
            "take" => &["have"],
            "took" => &["had"],
            "taken" => &["had"],
            "takes" => &["has"],
            "taking" => &["having"],
            _ => return None,
        };

        let suggestions = translated_light_verb
            .iter()
            .map(|s| {
                Suggestion::replace_with_match_case(
                    s.chars().collect(),
                    light_verb_tok.span.get_content(src),
                )
            })
            .collect();

        let message = format!(
            "{} English prefers {} over `{} a look`.",
            self.dialect,
            translated_light_verb
                .iter()
                .map(|lv| format!("`{lv} a look`"))
                .collect::<Vec<_>>()
                .join(" or "),
            light_verb,
        );

        Some(Lint {
            span: light_verb_tok.span,
            lint_kind: LintKind::Regionalism,
            suggestions,
            message,
            priority: 63,
        })
    }

    fn description(&self) -> &str {
        "Corrects either `have a look` or `take a look` to the other, depending on the dialect."
    }
}

#[cfg(test)]
mod tests {
    use super::HaveTakeALook;
    use crate::{Dialect, linting::tests::assert_suggestion_result};

    #[test]
    fn correct_taking_a_look() {
        assert_suggestion_result(
            "Consider taking a look at crossorigin attribute.",
            HaveTakeALook::new(Dialect::British),
            "Consider having a look at crossorigin attribute.",
        );
    }

    #[test]
    fn correct_take_a_look() {
        assert_suggestion_result(
            "Have time to help take a look at the jdk21 upgrade issue.",
            HaveTakeALook::new(Dialect::Australian),
            "Have time to help have a look at the jdk21 upgrade issue.",
        );
    }

    #[test]
    fn correct_have_a_look() {
        assert_suggestion_result(
            "Have a look at this question crashing histoire using init-state and ref.",
            HaveTakeALook::new(Dialect::American),
            "Take a look at this question crashing histoire using init-state and ref.",
        );
    }

    #[test]
    fn correct_taken_a_look() {
        assert_suggestion_result(
            "Have you taken a look at HQEMU?",
            HaveTakeALook::new(Dialect::British),
            "Have you had a look at HQEMU?",
        );
    }

    #[test]
    fn correct_had_a_look() {
        assert_suggestion_result(
            "I had a look at the podman.go and have some theories I could test.",
            HaveTakeALook::new(Dialect::Canadian),
            "I took a look at the podman.go and have some theories I could test.",
        );
    }

    #[test]
    fn correct_took_a_look() {
        assert_suggestion_result(
            "I though GitHub's “Dashboard” page might help with this, so I took a look.",
            HaveTakeALook::new(Dialect::Australian),
            "I though GitHub's “Dashboard” page might help with this, so I had a look.",
        );
    }

    #[test]
    fn correct_takes_a_look() {
        assert_suggestion_result(
            "I'm closing this one, but it would be nice if someone takes a look at the notes in the original issue.",
            HaveTakeALook::new(Dialect::British),
            "I'm closing this one, but it would be nice if someone has a look at the notes in the original issue.",
        );
    }

    #[test]
    fn correct_having_a_look() {
        assert_suggestion_result(
            "It only appeared after I was having a look through the files.",
            HaveTakeALook::new(Dialect::American),
            "It only appeared after I was taking a look through the files.",
        );
    }

    #[test]
    fn correct_has_a_look() {
        assert_suggestion_result(
            "When Serializing messages the code in SchemaRegistrySerde has a look into the registry using the topic name.",
            HaveTakeALook::new(Dialect::Canadian),
            "When Serializing messages the code in SchemaRegistrySerde takes a look into the registry using the topic name.",
        );
    }
}



================================================
FILE: harper-core/src/linting/hedging.rs
================================================
use crate::expr::Expr;
use crate::expr::FirstMatchOf;
use crate::expr::FixedPhrase;
use crate::linting::expr_linter::Chunk;
use crate::linting::{ExprLinter, Lint, LintKind};
use crate::{Token, TokenStringExt};

/// A linter that detects hedging language.
pub struct Hedging {
    expr: Box<dyn Expr>,
}

impl Default for Hedging {
    fn default() -> Self {
        let phrases = vec!["I would argue that", ", so to speak", "to a certain degree"];

        let patterns: Vec<Box<dyn Expr>> = phrases
            .into_iter()
            .map(|s| Box::new(FixedPhrase::from_phrase(s)) as Box<dyn Expr>)
            .collect();

        let expr = Box::new(FirstMatchOf::new(patterns));
        Self { expr }
    }
}

impl ExprLinter for Hedging {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], _source: &[char]) -> Option<Lint> {
        let span = matched_tokens.span()?;
        Some(Lint {
            span,
            lint_kind: LintKind::Miscellaneous,
            suggestions: Vec::new(),
            message: "You're hedging.".to_string(),
            priority: 31,
        })
    }

    fn description(&self) -> &str {
        "Flags hedging language (e.g. `I would argue that`, `..., so to speak`, `to a certain degree`)."
    }
}

#[cfg(test)]
mod tests {
    use super::Hedging;
    use crate::linting::tests::assert_lint_count;

    #[test]
    fn detects_hedging_phrase() {
        assert_lint_count("I would argue that this is correct.", Hedging::default(), 1);
    }

    #[test]
    fn does_not_flag_clean_text() {
        assert_lint_count("This is clear and direct.", Hedging::default(), 0);
    }

    #[test]
    fn lowercase_hedging() {
        assert_lint_count(
            "i would argue that the outcome is uncertain.",
            Hedging::default(),
            1,
        );
    }

    #[test]
    fn incomplete_phrase_not_flagged() {
        assert_lint_count("I would argue the data is clear.", Hedging::default(), 0);
    }

    #[test]
    fn phrase_with_trailing_comma() {
        let text = "I would argue that, this method works.";
        assert_lint_count(text, Hedging::default(), 1);
    }

    #[test]
    fn phrase_with_extra_whitespace() {
        assert_lint_count(
            "to   a   certain   degree the results are ambiguous.",
            Hedging::default(),
            1,
        );
    }

    #[test]
    fn does_not_flag_similar_but_incorrect_phrase() {
        assert_lint_count(
            "He spoke so to speakingly about the event.",
            Hedging::default(),
            0,
        );
    }

    #[test]
    fn phrase_split_by_line_break() {
        assert_lint_count(
            "I would argue\nthat this approach fails.",
            Hedging::default(),
            1,
        );
    }
}



================================================
FILE: harper-core/src/linting/hello_greeting.rs
================================================
use crate::linting::expr_linter::Chunk;
use crate::{
    Token,
    expr::{AnchorStart, Expr, SequenceExpr},
    linting::{ExprLinter, Lint, LintKind, Suggestion},
};

pub struct HelloGreeting {
    expr: Box<dyn Expr>,
}

impl Default for HelloGreeting {
    fn default() -> Self {
        let expr = SequenceExpr::default()
            .then(AnchorStart)
            .then_optional(SequenceExpr::default().t_ws())
            .then_optional(
                SequenceExpr::default()
                    .then_quote()
                    .then_optional(SequenceExpr::default().t_ws()),
            )
            .t_aco("halo");

        Self {
            expr: Box::new(expr),
        }
    }
}

impl ExprLinter for HelloGreeting {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], source: &[char]) -> Option<Lint> {
        let word = matched_tokens.iter().find(|tok| tok.kind.is_word())?;
        let span = word.span;
        let original = span.get_content(source);

        Some(Lint {
            span,
            lint_kind: LintKind::WordChoice,
            suggestions: vec![Suggestion::replace_with_match_case(
                "hello".chars().collect(),
                original,
            )],
            message: "Prefer `hello` as a greeting; `halo` refers to the optical effect."
                .to_owned(),
            priority: 31,
        })
    }

    fn description(&self) -> &'static str {
        "Encourages greeting someone with `hello` instead of the homophone `halo`."
    }
}

#[cfg(test)]
mod tests {
    use super::HelloGreeting;
    use crate::linting::tests::{assert_lint_count, assert_suggestion_result};

    #[test]
    fn corrects_basic_greeting() {
        assert_suggestion_result("Halo John!", HelloGreeting::default(), "Hello John!");
    }

    #[test]
    fn corrects_with_comma() {
        assert_suggestion_result("Halo, Jane.", HelloGreeting::default(), "Hello, Jane.");
    }

    #[test]
    fn corrects_with_world() {
        assert_suggestion_result("Halo world!", HelloGreeting::default(), "Hello world!");
    }

    #[test]
    fn corrects_without_punctuation() {
        assert_suggestion_result(
            "Halo there friend.",
            HelloGreeting::default(),
            "Hello there friend.",
        );
    }

    #[test]
    fn corrects_single_word_sentence() {
        assert_suggestion_result("Halo!", HelloGreeting::default(), "Hello!");
    }

    #[test]
    fn corrects_question() {
        assert_suggestion_result("Halo?", HelloGreeting::default(), "Hello?");
    }

    #[test]
    fn corrects_uppercase() {
        assert_suggestion_result("HALO!", HelloGreeting::default(), "HELLO!");
    }

    #[test]
    fn no_lint_for_optical_term() {
        assert_lint_count(
            "The halo around the moon glowed softly.",
            HelloGreeting::default(),
            0,
        );
    }

    #[test]
    fn no_lint_mid_sentence() {
        assert_lint_count(
            "They shouted hello, not Halo, during rehearsal.",
            HelloGreeting::default(),
            0,
        );
    }

    #[test]
    fn corrects_in_quotes() {
        assert_suggestion_result(
            "\"Halo John!\"",
            HelloGreeting::default(),
            "\"Hello John!\"",
        );
    }
}



================================================
FILE: harper-core/src/linting/hereby.rs
================================================
use crate::expr::Expr;
use crate::expr::SequenceExpr;
use crate::{Token, TokenStringExt};

use super::{ExprLinter, Lint, LintKind, Suggestion};
use crate::linting::expr_linter::Chunk;

pub struct Hereby {
    expr: Box<dyn Expr>,
}

impl Default for Hereby {
    fn default() -> Self {
        let pattern = SequenceExpr::aco("here")
            .then_whitespace()
            .t_aco("by")
            .then_whitespace()
            .then_verb();

        Self {
            expr: Box::new(pattern),
        }
    }
}

impl ExprLinter for Hereby {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], source: &[char]) -> Option<Lint> {
        let span = matched_tokens[0..3].span()?;
        let orig_chars = span.get_content(source);
        Some(Lint {
            span,
            lint_kind: LintKind::WordChoice,
            suggestions: vec![Suggestion::replace_with_match_case(
                "hereby".chars().collect(),
                orig_chars,
            )],
            message: "Did you mean the closed compound `hereby`?".to_owned(),
            ..Default::default()
        })
    }

    fn description(&self) -> &'static str {
        "`Here by` in some contexts should be `hereby`"
    }
}

#[cfg(test)]
mod tests {
    use crate::linting::tests::assert_suggestion_result;

    use super::Hereby;

    #[test]
    fn declare() {
        assert_suggestion_result(
            "I here by declare this state to be free.",
            Hereby::default(),
            "I hereby declare this state to be free.",
        );
    }
}



================================================
FILE: harper-core/src/linting/hope_youre.rs
================================================
use crate::linting::expr_linter::Chunk;
use crate::{
    Token,
    expr::SequenceExpr,
    linting::{ExprLinter, Lint, LintKind, Suggestion},
    patterns::WordSet,
};

pub struct HopeYoure {
    expr: Box<dyn crate::expr::Expr>,
}

impl Default for HopeYoure {
    fn default() -> Self {
        let loc = WordSet::new(&["here", "there"]);

        let prep = SequenceExpr::default().t_ws().then_preposition();

        let expr = SequenceExpr::aco("hope")
            .t_ws()
            .t_aco("your")
            .t_ws()
            .then_adjective()
            .then_optional(prep)
            .t_ws()
            .then(loc);

        Self {
            expr: Box::new(expr),
        }
    }
}

impl ExprLinter for HopeYoure {
    type Unit = Chunk;

    fn expr(&self) -> &dyn crate::expr::Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, toks: &[Token], src: &[char]) -> Option<Lint> {
        let your_tok = toks.get(2)?;
        let span = your_tok.span;
        let original = span.get_content(src);

        Some(Lint {
            span,
            lint_kind: LintKind::WordChoice,
            suggestions: vec![Suggestion::replace_with_match_case(
                "you're".chars().collect(),
                original,
            )],
            message: "Prefer `you're`—the contraction of “you are”—when expressing a hope about someone’s condition."
                .into(),
            priority: 31,
        })
    }

    fn description(&self) -> &str {
        "Detects the misuse of possessive **your** after “hope” and an adjective \
         (e.g., “I hope your well”) and advises using **you’re** to supply the \
         missing verb “are.”"
    }
}

#[cfg(test)]
mod tests {
    use super::HopeYoure;
    use crate::linting::tests::{assert_lint_count, assert_suggestion_result};

    #[test]
    fn corrects_excited_here() {
        assert_suggestion_result(
            "I hope your excited here.",
            HopeYoure::default(),
            "I hope you're excited here.",
        );
    }

    #[test]
    fn corrects_safe_there() {
        assert_suggestion_result(
            "I hope your safe there.",
            HopeYoure::default(),
            "I hope you're safe there.",
        );
    }

    #[test]
    fn corrects_safe_over_there() {
        assert_suggestion_result(
            "I hope your safe over there.",
            HopeYoure::default(),
            "I hope you're safe over there.",
        );
    }

    #[test]
    fn corrects_fine_here() {
        assert_suggestion_result(
            "I hope your fine here.",
            HopeYoure::default(),
            "I hope you're fine here.",
        );
    }

    #[test]
    fn corrects_happy_there() {
        assert_suggestion_result(
            "I hope your happy there.",
            HopeYoure::default(),
            "I hope you're happy there.",
        );
    }

    #[test]
    fn corrects_healthy_out_here() {
        assert_suggestion_result(
            "I hope your healthy out here.",
            HopeYoure::default(),
            "I hope you're healthy out here.",
        );
    }

    #[test]
    fn corrects_strong_there() {
        assert_suggestion_result(
            "We hope your strong there.",
            HopeYoure::default(),
            "We hope you're strong there.",
        );
    }

    #[test]
    fn corrects_sorry_here() {
        assert_suggestion_result(
            "Hope your sorry here.",
            HopeYoure::default(),
            "Hope you're sorry here.",
        );
    }

    #[test]
    fn no_lint_with_contraction() {
        assert_lint_count("I hope you're excited here.", HopeYoure::default(), 0);
    }

    #[test]
    fn no_lint_without_adjective() {
        assert_lint_count("I hope your trip went well.", HopeYoure::default(), 0);
    }

    #[test]
    fn no_lint_with_following_clause() {
        assert_lint_count(
            "I hope your friends are well there.",
            HopeYoure::default(),
            0,
        );
    }

    #[test]
    fn no_lint_when_possessive_context() {
        assert_lint_count(
            "I hope your advice on punctuation is helpful.",
            HopeYoure::default(),
            0,
        );
    }
}



================================================
FILE: harper-core/src/linting/how_to.rs
================================================
use harper_brill::UPOS;

use crate::linting::expr_linter::Chunk;
use crate::{
    Token, TokenKind, TokenStringExt,
    expr::{All, Expr, OwnedExprExt, SequenceExpr},
    linting::{ExprLinter, Lint, LintKind, Suggestion},
    patterns::{InflectionOfBe, UPOSSet},
};

pub struct HowTo {
    expr: Box<dyn Expr>,
}

impl Default for HowTo {
    fn default() -> Self {
        let mut pattern = All::default();

        let pos_pattern = SequenceExpr::anything()
            .then_anything()
            .t_aco("how")
            .then_whitespace()
            .then_verb_lemma();
        pattern.add(pos_pattern);

        let exceptions = SequenceExpr::default()
            .then_unless(UPOSSet::new(&[UPOS::PART]))
            .then_anything()
            .then_unless(|tok: &Token, _: &[char]| tok.kind.is_np_member())
            .then_anything()
            .then_unless(
                InflectionOfBe::new().or(SequenceExpr::default().then_kind_any_or_words(
                    &[
                        TokenKind::is_auxiliary_verb,
                        TokenKind::is_adjective,
                        TokenKind::is_conjunction,
                        TokenKind::is_proper_noun,
                    ] as &[_],
                    &["did", "come", "does"],
                )),
            );

        pattern.add(exceptions);

        Self {
            expr: Box::new(pattern),
        }
    }
}

impl ExprLinter for HowTo {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, toks: &[Token], _src: &[char]) -> Option<Lint> {
        let span = toks[2..4].span()?;
        let fix: Vec<char> = "to ".chars().collect();

        Some(Lint {
            span,
            lint_kind: LintKind::WordChoice,
            suggestions: vec![Suggestion::InsertAfter(fix)],
            message: "Insert `to` after `how` (e.g., `how to clone`).".into(),
            priority: 63,
        })
    }

    fn description(&self) -> &str {
        "Detects the omission of `to` in constructions like `how clone / how install` and suggests `how to …`."
    }
}

#[cfg(test)]
mod tests {
    use super::HowTo;
    use crate::linting::tests::{assert_lint_count, assert_no_lints, assert_suggestion_result};

    #[test]
    fn flags_missing_to() {
        assert_suggestion_result(
            "Here's how clone the repository.",
            HowTo::default(),
            "Here's how to clone the repository.",
        );
    }

    #[test]
    fn ignores_correct_phrase() {
        assert_lint_count("Here's how to clone the repository.", HowTo::default(), 0);
    }

    #[test]
    fn flags_other_verbs() {
        assert_suggestion_result(
            "Learn how install Rust.",
            HowTo::default(),
            "Learn how to install Rust.",
        );
    }

    #[test]
    fn ros_package_install() {
        assert_suggestion_result(
            "Can someone explain how install this ROS package on Humble?",
            HowTo::default(),
            "Can someone explain how to install this ROS package on Humble?",
        );
    }

    #[test]
    fn extract_and_install_app() {
        assert_suggestion_result(
            "Here’s a quick guide on how install an app you’ve extracted from a tarball.",
            HowTo::default(),
            "Here’s a quick guide on how to install an app you’ve extracted from a tarball.",
        );
    }

    #[test]
    fn dll_files() {
        assert_suggestion_result(
            "This video shows how fix missing DLL files on Windows.",
            HowTo::default(),
            "This video shows how to fix missing DLL files on Windows.",
        );
    }

    #[test]
    fn dofus_on_ubuntu() {
        assert_suggestion_result(
            "Full tutorial on how install Dofus under Ubuntu.",
            HowTo::default(),
            "Full tutorial on how to install Dofus under Ubuntu.",
        );
    }

    #[test]
    fn tar_gz_install() {
        assert_suggestion_result(
            "Find out how install software shipped as a .tar.gz archive.",
            HowTo::default(),
            "Find out how to install software shipped as a .tar.gz archive.",
        );
    }

    #[test]
    fn thrift_libraries() {
        assert_suggestion_result(
            "Anyone know how install the Thrift libraries from source?",
            HowTo::default(),
            "Anyone know how to install the Thrift libraries from source?",
        );
    }

    #[test]
    fn windows_adk() {
        assert_suggestion_result(
            "Lost the Windows ADK again—remind me how install it?",
            HowTo::default(),
            "Lost the Windows ADK again—remind me how to install it?",
        );
    }

    #[test]
    fn accounting_errors() {
        assert_suggestion_result(
            "Eight common accounting errors and how fix them.",
            HowTo::default(),
            "Eight common accounting errors and how to fix them.",
        );
    }

    #[test]
    fn sentence_fragments() {
        assert_suggestion_result(
            "Here’s what sentence fragments are and how fix them.",
            HowTo::default(),
            "Here’s what sentence fragments are and how to fix them.",
        );
    }

    #[test]
    fn zipper_slider() {
        assert_suggestion_result(
            "Quick demo on how fix a broken zipper slider.",
            HowTo::default(),
            "Quick demo on how to fix a broken zipper slider.",
        );
    }

    #[test]
    fn door_lock() {
        assert_suggestion_result(
            "Tips on how fix a door that won’t lock.",
            HowTo::default(),
            "Tips on how to fix a door that won’t lock.",
        );
    }

    #[test]
    fn already_correct_install() {
        assert_lint_count(
            "See how to install the package with apt.",
            HowTo::default(),
            0,
        );
    }

    #[test]
    fn already_correct_fix() {
        assert_lint_count(
            "He showed me how to fix the zipper in ten minutes.",
            HowTo::default(),
            0,
        );
    }

    #[test]
    fn how_are_you() {
        assert_lint_count("How are you?", HowTo::default(), 0);
    }

    #[test]
    fn how_calm_you_are() {
        assert_lint_count("I like how calm you are.", HowTo::default(), 0);
    }

    #[test]
    fn how_will_you_make_up() {
        assert_lint_count(
            "How will you make up for your mistakes?",
            HowTo::default(),
            0,
        );
    }

    #[test]
    fn storytelling_clause() {
        assert_lint_count(
            "I will tell about how leaving my husband led to my dog winning a Nobel Prize.",
            HowTo::default(),
            0,
        );
    }

    #[test]
    fn dont_flag_how_did_you() {
        assert_lint_count("How did you get to school every day?", HowTo::default(), 0);
    }

    #[test]
    fn dont_flag_how_come() {
        assert_lint_count(
            "How come this has to be a special case?",
            HowTo::default(),
            0,
        );
    }

    #[test]
    fn allows_how_has() {
        assert_lint_count("How Has This Been Tested?", HowTo::default(), 0);
    }

    #[test]
    fn issue_1492() {
        assert_no_lints(
            "I hope to provide some insight into correct HTML formatting, in addition to how authors can avoid these issues.",
            HowTo::default(),
        );

        assert_no_lints("But how does something like this...", HowTo::default());
    }

    #[test]
    fn allow_issue_1298() {
        assert_no_lints(
            "The story of how and why things came to this point.",
            HowTo::default(),
        );
    }

    #[test]
    fn dont_flag_false_positive_pr_1846() {
        assert_no_lints(
            "About how Microsoft, Google, and others are training people in Rust.",
            HowTo::default(),
        )
    }

    #[test]
    fn dont_flag_false_positives_1492_how_indexes() {
        assert_no_lints(
            "controls how indexes will be added to unwrapped keys of flat array-like objects",
            HowTo::default(),
        );
    }

    #[test]
    fn issue_2124() {
        assert_no_lints(
            "I like how discord shows Spotify status on your profile.",
            HowTo::default(),
        );
        assert_no_lints(
            "To be determined based on how error handling is done in new paradigm.",
            HowTo::default(),
        );
    }
}



================================================
FILE: harper-core/src/linting/hyphenate_number_day.rs
================================================
use crate::expr::Expr;
use crate::expr::SequenceExpr;
use crate::{Token, patterns::NominalPhrase};

use super::{ExprLinter, Lint, LintKind, Suggestion};
use crate::linting::expr_linter::Chunk;

pub struct HyphenateNumberDay {
    expr: Box<dyn Expr>,
}

impl Default for HyphenateNumberDay {
    fn default() -> Self {
        let pattern = SequenceExpr::default()
            .then_number()
            .then_whitespace()
            .t_aco("day")
            .then_longest_of(vec![
                Box::new(
                    SequenceExpr::default()
                        .then_whitespace()
                        .then(NominalPhrase),
                ),
                Box::new(
                    SequenceExpr::default()
                        .then_hyphen()
                        .then_adjective()
                        .then_whitespace()
                        .then(NominalPhrase),
                ),
            ]);

        Self {
            expr: Box::new(pattern),
        }
    }
}

impl ExprLinter for HyphenateNumberDay {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], _source: &[char]) -> Option<Lint> {
        let number = matched_tokens[0].kind.as_number()?;
        let space = &matched_tokens[1];

        Some(Lint {
            span: space.span,
            lint_kind: LintKind::Miscellaneous,
            suggestions: vec![Suggestion::ReplaceWith(vec!['-'])],
            message: format!("Use a hyphen in `{number}-day` when forming an adjectival compound."),
            priority: 31,
        })
    }

    fn description(&self) -> &'static str {
        "Ensures a hyphen is used in `X-day` when it is part of a compound adjective, such as `4-day work week`."
    }
}

#[cfg(test)]
mod tests {
    use super::HyphenateNumberDay;
    use crate::linting::tests::assert_suggestion_result;

    #[test]
    fn corrects_three_day_training() {
        assert_suggestion_result(
            "The company offers a 3 day training program.",
            HyphenateNumberDay::default(),
            "The company offers a 3-day training program.",
        );
    }

    #[test]
    fn corrects_five_day_challenge() {
        assert_suggestion_result(
            "Join the 5 day challenge to improve your skills.",
            HyphenateNumberDay::default(),
            "Join the 5-day challenge to improve your skills.",
        );
    }

    #[test]
    fn corrects_seven_day_plan() {
        assert_suggestion_result(
            "She followed a strict 7 day meal plan.",
            HyphenateNumberDay::default(),
            "She followed a strict 7-day meal plan.",
        );
    }

    #[test]
    fn does_not_correct_when_not_adjective() {
        assert_suggestion_result(
            "The seminar lasts for 2 days.",
            HyphenateNumberDay::default(),
            "The seminar lasts for 2 days.",
        );
    }

    #[test]
    fn corrects_varied_phrases() {
        assert_suggestion_result(
            "They implemented a new 6 day work schedule.",
            HyphenateNumberDay::default(),
            "They implemented a new 6-day work schedule.",
        );

        assert_suggestion_result(
            "Enroll in our 10 day fitness bootcamp!",
            HyphenateNumberDay::default(),
            "Enroll in our 10-day fitness bootcamp!",
        );
    }

    #[test]
    fn edge_case_day_long() {
        assert_suggestion_result(
            "The 4 day-long seminar was insightful.",
            HyphenateNumberDay::default(),
            "The 4-day-long seminar was insightful.",
        );
    }

    #[test]
    fn edge_case_plural_days() {
        assert_suggestion_result(
            "The trip was a fun 5 day experience.",
            HyphenateNumberDay::default(),
            "The trip was a fun 5-day experience.",
        );
    }

    #[test]
    fn ignores_spelled_out_numbers() {
        assert_suggestion_result(
            "We had a three day holiday.",
            HyphenateNumberDay::default(),
            "We had a three day holiday.",
        );
    }
}



================================================
FILE: harper-core/src/linting/i_am_agreement.rs
================================================
use crate::linting::expr_linter::Chunk;
use crate::{
    Lrc, Token, TokenStringExt,
    expr::{AnchorStart, Expr, FirstMatchOf, FixedPhrase, SequenceExpr},
    linting::{ExprLinter, Lint, LintKind, Suggestion},
};

pub struct IAmAgreement {
    expr: Box<dyn Expr>,
}

impl Default for IAmAgreement {
    fn default() -> Self {
        let i_are = Lrc::new(FixedPhrase::from_phrase("I are"));

        let nothing_before_i_are = SequenceExpr::default()
            .then(AnchorStart)
            .then(i_are.clone());

        let non_and_word_before_i_are = SequenceExpr::default()
            .then_word_except(&["and"])
            .t_ws()
            .then(i_are);

        let expr = FirstMatchOf::new(vec![
            Box::new(nothing_before_i_are),
            Box::new(non_and_word_before_i_are),
        ]);

        Self {
            expr: Box::new(expr),
        }
    }
}

impl ExprLinter for IAmAgreement {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, toks: &[Token], src: &[char]) -> Option<Lint> {
        let toks = &toks[toks.len() - 3..];
        Some(Lint {
            span: toks.span()?,
            lint_kind: LintKind::Agreement,
            suggestions: vec![Suggestion::replace_with_match_case(
                "I am".chars().collect(),
                toks.span()?.get_content(src),
            )],
            message: "The first-person singular pronoun `I` requires the verb form `am`; `are` belongs to second-person or plural contexts.".to_string(),
            priority: 31,
        })
    }

    fn description(&self) -> &str {
        "Corrects `I are` to `I am`."
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::linting::tests::{assert_lint_count, assert_suggestion_result};

    #[test]
    fn corrects_i_are_simple() {
        assert_suggestion_result("I are", IAmAgreement::default(), "I am");
    }

    #[test]
    fn corrects_i_are() {
        assert_suggestion_result(
            "I are really happy about this release.",
            IAmAgreement::default(),
            "I am really happy about this release.",
        );
    }

    #[test]
    fn dont_flag_you_and_i_are() {
        assert_lint_count(
            "You know, you and I are sitting on the Titanic and the iceberg is over there.",
            IAmAgreement::default(),
            0,
        );
    }

    #[test]
    fn dont_flag_mention_and_i_are() {
        assert_lint_count(
            "Hello, @another-rex and I are attempting to package packageurl-go for Debian as we need it for a build dependency.",
            IAmAgreement::default(),
            0,
        );
    }

    #[test]
    fn dont_flag_z_and_i_are() {
        assert_lint_count(
            "The url is copied from a manual search, and Z and I are modified.",
            IAmAgreement::default(),
            0,
        )
    }

    #[test]
    fn dont_flag_name_and_i_are() {
        assert_lint_count(
            "Paper that Lena Baunaz and I are working on as part of my SNSF-funded 'Focus in diachrony'",
            IAmAgreement::default(),
            0,
        );
    }

    #[test]
    fn fix_so_i_are() {
        assert_suggestion_result(
            "I have not yet been able to reproduce this issue in my environment, so I are still trying to figure it out",
            IAmAgreement::default(),
            "I have not yet been able to reproduce this issue in my environment, so I am still trying to figure it out",
        );
    }

    #[test]
    fn fix_if_i_are() {
        assert_suggestion_result(
            "If i are on creative inventory, and try to clean my inventory holding shift is disconnected too.",
            IAmAgreement::default(),
            "If i am on creative inventory, and try to clean my inventory holding shift is disconnected too.",
        );
    }

    #[test]
    fn fix_what_i_are() {
        assert_suggestion_result(
            "in this situation I can't see what I are typing",
            IAmAgreement::default(),
            "in this situation I can't see what I am typing",
        );
    }

    #[test]
    fn fix_where_i_are() {
        assert_suggestion_result(
            "I have a logging application where I are append to a topic",
            IAmAgreement::default(),
            "I have a logging application where I am append to a topic",
        );
    }
}



================================================
FILE: harper-core/src/linting/if_wouldve.rs
================================================
use crate::expr::{Expr, SequenceExpr};
use crate::linting::expr_linter::Chunk;
use crate::linting::{ExprLinter, LintKind, Suggestion};
use crate::patterns::{NominalPhrase, WordSet};
use crate::token_string_ext::TokenStringExt;
use crate::{CharStringExt, Lint, Token};

pub struct IfWouldve {
    expr: Box<dyn Expr>,
}

impl Default for IfWouldve {
    fn default() -> Self {
        Self {
            expr: Box::new(
                SequenceExpr::aco("if")
                    .t_ws()
                    .then(NominalPhrase)
                    .t_ws()
                    .then_any_of(vec![
                        Box::new(
                            SequenceExpr::default()
                                .then_word_set(&["would", "had"])
                                .t_ws()
                                .then_word_set(&["have", "of"]),
                        ),
                        Box::new(WordSet::new(&["would've", "wouldve", "had've", "hadve"])),
                    ])
                    .t_ws()
                    .then_verb_past_participle_form(),
            ),
        }
    }
}

impl ExprLinter for IfWouldve {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    /// Identifies and corrects incorrect conditional phrases like "would've", "would have", "would of", etc.
    /// to use the correct "had" construction in conditional statements.
    fn match_to_lint(&self, toks: &[Token], src: &[char]) -> Option<Lint> {
        // We examine tokens in pairs, moving backwards from the end of the phrase
        // to find the incorrect verb construction to replace with "had".
        // The pattern we're looking for is: [if] [NP] [would/had] [have/of/ve] [verb]

        // Start from the end of the token sequence (before the verb)
        let matched_tokens = (2..toks.len() - 2)
            .rev()
            .step_by(2) // Check every other token since we're looking at pairs
            .find_map(|i| {
                let prev = toks[i - 2].span.get_content(src);
                let curr = toks[i].span.get_content(src);

                let would_had = &["would", "had"];

                // Determine which tokens to replace based on the pattern
                match () {
                    // Handle contractions like "would've" or "had've"
                    _ if curr.ends_with_ignore_ascii_case_str("ve") => {
                        if curr.starts_with_any_ignore_ascii_case_str(would_had) {
                            Some(&toks[i..=i]) // Single token like "would've"
                        } else if prev.starts_with_any_ignore_ascii_case_str(would_had) {
                            Some(&toks[i - 2..=i]) // Two tokens like "would have"
                        } else {
                            None
                        }
                    }
                    // Handle "would of" / "had of"
                    _ if curr.ends_with_ignore_ascii_case_str("of")
                        && prev.starts_with_any_ignore_ascii_case_str(would_had) =>
                    {
                        Some(&toks[i - 2..=i])
                    }
                    _ => None,
                }
            });

        matched_tokens.and_then(|tokens_to_replace| {
            let span = tokens_to_replace.span()?;

            Some(Lint {
                span,
                lint_kind: LintKind::Nonstandard,
                suggestions: vec![Suggestion::replace_with_match_case(
                    vec!['h', 'a', 'd'],
                    span.get_content(src),
                )],
                message: "If this is counterfactual or hypothetical, use `had` after `if` rather than `would have` or `had have`.".to_string(),
                ..Default::default()
            })
        })
    }

    fn description(&self) -> &str {
        "Corrects `if I would've done` etc. to `if I had done` etc."
    }
}

#[cfg(test)]
mod tests {
    use crate::linting::tests::{assert_no_lints, assert_suggestion_result};

    use super::*;

    #[test]
    fn flag_if_i_wouldve_done_x() {
        assert_suggestion_result(
            "If I would've done X...",
            IfWouldve::default(),
            "If I had done X...",
        );
    }

    #[test]
    fn flag_if_you_would_have_done_y() {
        assert_suggestion_result(
            "If you would have done Y...",
            IfWouldve::default(),
            "If you had done Y...",
        );
    }

    #[test]
    fn flag_if_we_would_of_z() {
        assert_suggestion_result(
            "If we would of done Z...",
            IfWouldve::default(),
            "If we had done Z...",
        );
    }

    #[test]
    fn flag_if_he_hadve_done_w() {
        assert_suggestion_result(
            "If he hadve done W...",
            IfWouldve::default(),
            "If he had done W...",
        );
    }

    #[test]
    fn flag_if_she_hadve_done_x() {
        assert_suggestion_result(
            "If she had've done X...",
            IfWouldve::default(),
            "If she had done X...",
        );
    }

    #[test]
    fn flag_if_it_had_of_done_x() {
        assert_suggestion_result(
            "If it had of done X...",
            IfWouldve::default(),
            "If it had done X...",
        );
    }

    #[test]
    fn flag_if_np_wouldve() {
        assert_suggestion_result(
            "If that guy would've thought it through...",
            IfWouldve::default(),
            "If that guy had thought it through...",
        );
    }

    // The linter cannot yet detect when this pattern is a counterfactual.
    // If you can improve this linter to do so, here are some example sentences.

    #[test]
    #[ignore = "Can't detect correct use not in counterfactual"]
    fn dont_flag_non_counterfactual_done() {
        assert_no_lints(
            "I don't know if they would have done that for a designer",
            IfWouldve::default(),
        );
    }

    #[test]
    #[ignore = "Can't detect correct use not in counterfactual"]
    fn dont_flag_non_counterfactual_gotten() {
        assert_no_lints(
            "I don't know if a normal programmer would have gotten that treatment.",
            IfWouldve::default(),
        );
    }

    #[test]
    #[ignore = "Can't detect correct use not in counterfactual"]
    fn dont_flag_non_counterfactual_been() {
        assert_no_lints(
            "I don't know if they would have been interested anyway",
            IfWouldve::default(),
        );
    }
}



================================================
FILE: harper-core/src/linting/in_on_the_cards.rs
================================================
use crate::{
    CharStringExt, Dialect, Token,
    expr::{Expr, FirstMatchOf, FixedPhrase, SequenceExpr},
    linting::{LintKind, Suggestion},
    patterns::{InflectionOfBe, WordSet},
};

use super::{ExprLinter, Lint};
use crate::linting::expr_linter::Chunk;

pub struct InOnTheCards {
    expr: Box<dyn Expr>,
    dialect: Dialect,
}

impl InOnTheCards {
    pub fn new(dialect: Dialect) -> Self {
        // Quick research suggested that Australian and Canadian English agree with American English.
        let preposition = match dialect {
            Dialect::British => "in",
            _ => "on",
        };

        let pre_context = FirstMatchOf::new(vec![
            Box::new(InflectionOfBe::new()),
            Box::new(WordSet::new(&[
                "isn't", "it's", "wasn't", "weren't", "not", "isnt", "its", "wasnt", "werent",
            ])),
        ]);

        let expr = SequenceExpr::default()
            .then(pre_context)
            .t_ws()
            .t_aco(preposition)
            .then(FixedPhrase::from_phrase(" the cards"));

        Self {
            expr: Box::new(expr),
            dialect,
        }
    }
}

impl ExprLinter for InOnTheCards {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, toks: &[Token], src: &[char]) -> Option<Lint> {
        let prep_span = toks[2].span;
        let prep = prep_span.get_content(src);

        let new_prep = [
            match prep[0] {
                'i' => 'o',
                'o' => 'i',
                'I' => 'O',
                'O' => 'I',
                _ => return None,
            },
            prep[1],
        ];

        let sugg = Suggestion::ReplaceWith(new_prep.to_vec());

        let message = format!(
            "Use `{} the cards` instead of `{} the cards` in {} English.",
            new_prep.to_string(),
            prep.to_string(),
            self.dialect,
        );

        Some(Lint {
            span: prep_span,
            lint_kind: LintKind::Regionalism,
            suggestions: vec![sugg],
            message,
            priority: 63,
        })
    }

    fn description(&self) -> &str {
        "Corrects either `in the cards` or `on the cards` to the other, depending on the dialect."
    }
}

#[cfg(test)]
mod tests {
    use super::InOnTheCards;
    use crate::{
        Dialect,
        linting::tests::{assert_lint_count, assert_suggestion_result},
    };

    // On the cards

    #[test]
    fn correct_are_on_for_american() {
        assert_suggestion_result(
            "Both these features are on the cards, but for now we want to let users know if they have requested an invalid example.",
            InOnTheCards::new(Dialect::American),
            "Both these features are in the cards, but for now we want to let users know if they have requested an invalid example.",
        );
    }

    #[test]
    fn dont_correct_is_on_for_british() {
        assert_lint_count(
            "Yes, I think this is on the cards.",
            InOnTheCards::new(Dialect::British),
            0,
        );
    }

    #[test]
    fn correct_not_on_for_american() {
        assert_suggestion_result(
            "If a permanent unique identifier is not on the cards any time soon for WebHID, we should consider a WebUSB alternative.",
            InOnTheCards::new(Dialect::American),
            "If a permanent unique identifier is not in the cards any time soon for WebHID, we should consider a WebUSB alternative.",
        );
    }

    #[test]
    fn correct_be_on_for_american() {
        assert_suggestion_result(
            "a full breach of genomics (patient?) data can be on the cards since S3 AWS bucket credentials can be slurped from the process's memory",
            InOnTheCards::new(Dialect::American),
            "a full breach of genomics (patient?) data can be in the cards since S3 AWS bucket credentials can be slurped from the process's memory",
        );
    }

    #[test]
    fn correct_was_on_for_american() {
        assert_suggestion_result(
            "Virtualising the message summaries ObservableCollection was on the cards so I also take note of your last point.",
            InOnTheCards::new(Dialect::American),
            "Virtualising the message summaries ObservableCollection was in the cards so I also take note of your last point.",
        );
    }

    #[test]
    fn correct_isnt_on_no_apostrophe_for_american() {
        assert_suggestion_result(
            "parallelising that part isnt on the cards since there would be no noticeable ...",
            InOnTheCards::new(Dialect::American),
            "parallelising that part isnt in the cards since there would be no noticeable ...",
        );
    }

    #[test]
    fn correct_its_on_for_american() {
        assert_suggestion_result(
            "Regarding extensive documentation, as mentioned, its on the cards, project being sponsored by the aforementioned organisations.",
            InOnTheCards::new(Dialect::American),
            "Regarding extensive documentation, as mentioned, its in the cards, project being sponsored by the aforementioned organisations.",
        );
    }

    #[test]
    fn correct_were_on_for_american() {
        assert_suggestion_result(
            "lots of high altitudes were on the cards again",
            InOnTheCards::new(Dialect::American),
            "lots of high altitudes were in the cards again",
        );
    }

    #[test]
    fn correct_isnt_on_for_american() {
        assert_suggestion_result(
            "downgrading to an end-of-life operating system isn't on the cards",
            InOnTheCards::new(Dialect::American),
            "downgrading to an end-of-life operating system isn't in the cards",
        );
    }

    #[test]
    fn correct_wasnt_on_for_american() {
        assert_suggestion_result(
            "it's only a middleground for an org because passwordless wasn't on the cards previously",
            InOnTheCards::new(Dialect::American),
            "it's only a middleground for an org because passwordless wasn't in the cards previously",
        );
    }

    // In the cards

    #[test]
    fn correct_was_in_for_british() {
        assert_suggestion_result(
            "Just wondering if it was in the cards or not for something like the Quest3 to get support in the future.",
            InOnTheCards::new(Dialect::British),
            "Just wondering if it was on the cards or not for something like the Quest3 to get support in the future.",
        );
    }

    #[test]
    fn dont_correct_is_in_for_american() {
        assert_lint_count(
            "Not sure if such a project is in the cards",
            InOnTheCards::new(Dialect::American),
            0,
        );
    }

    #[test]
    fn correct_not_in_for_british() {
        assert_suggestion_result(
            "Is that just not in the cards for WASM at this time?",
            InOnTheCards::new(Dialect::British),
            "Is that just not on the cards for WASM at this time?",
        );
    }

    #[test]
    fn correct_be_in_for_british() {
        assert_suggestion_result(
            "Would this be in the cards?",
            InOnTheCards::new(Dialect::British),
            "Would this be on the cards?",
        );
    }

    #[test]
    fn correct_are_in_for_british() {
        assert_suggestion_result(
            "Manifest files are in the cards but haven't been implemented yet.",
            InOnTheCards::new(Dialect::British),
            "Manifest files are on the cards but haven't been implemented yet.",
        );
    }

    #[test]
    fn correct_its_in_for_british() {
        assert_suggestion_result(
            "As far as an error, that probably would be helpful but doesn't sound like its in the cards.",
            InOnTheCards::new(Dialect::British),
            "As far as an error, that probably would be helpful but doesn't sound like its on the cards.",
        );
    }

    #[test]
    fn correct_were_in_for_british() {
        assert_suggestion_result(
            "a year or two given the major overhauls that were in the cards at the time",
            InOnTheCards::new(Dialect::British),
            "a year or two given the major overhauls that were on the cards at the time",
        );
    }

    #[test]
    fn correct_isnt_in_for_british() {
        assert_suggestion_result(
            "I'm going to close this as opting out of the installation framework that Electron gives us isn't in the cards for the project at this time.",
            InOnTheCards::new(Dialect::British),
            "I'm going to close this as opting out of the installation framework that Electron gives us isn't on the cards for the project at this time.",
        );
    }

    #[test]
    fn correct_wasnt_in_for_british() {
        assert_suggestion_result(
            "doing something better than just swapping our internal log package for glog wasn’t in the cards back then",
            InOnTheCards::new(Dialect::British),
            "doing something better than just swapping our internal log package for glog wasn’t on the cards back then",
        );
    }

    #[test]
    fn correct_werent_in_for_british() {
        assert_suggestion_result(
            "I had thought stacked borrows was mostly in a final tweaking phase and major changes weren't in the cards.",
            InOnTheCards::new(Dialect::British),
            "I had thought stacked borrows was mostly in a final tweaking phase and major changes weren't on the cards.",
        );
    }
}



================================================
FILE: harper-core/src/linting/inflected_verb_after_to.rs
================================================
use super::{Lint, LintKind, Linter, Suggestion};
use crate::char_string::CharStringExt;
use crate::spell::Dictionary;
use crate::{Document, Span, TokenStringExt};

pub struct InflectedVerbAfterTo<T>
where
    T: Dictionary,
{
    dictionary: T,
}

impl<T: Dictionary> InflectedVerbAfterTo<T> {
    pub fn new(dictionary: T) -> Self {
        Self { dictionary }
    }
}

impl<T: Dictionary> Linter for InflectedVerbAfterTo<T> {
    fn lint(&mut self, document: &Document) -> Vec<Lint> {
        let mut lints = Vec::new();
        for pi in document.iter_preposition_indices() {
            let prep = document.get_token(pi).unwrap();
            let Some(space) = document.get_token(pi + 1) else {
                continue;
            };
            let Some(word) = document.get_token(pi + 2) else {
                continue;
            };
            if !space.kind.is_whitespace() || !word.kind.is_word() {
                continue;
            }
            let prep_to = document.get_span_content(&prep.span);
            if !prep_to.eq_ignore_ascii_case_chars(&['t', 'o']) {
                continue;
            }

            let chars = document.get_span_content(&word.span);

            if chars.len() < 4 {
                continue;
            }

            let check_stem = |stem: &[char]| {
                if let Some(metadata) = self.dictionary.get_word_metadata(stem)
                    && metadata.is_verb()
                    && !metadata.is_noun()
                {
                    return true;
                }
                false
            };

            let mut lint_from_stem = |stem: &[char]| {
                lints.push(Lint {
                    span: Span::new(prep.span.start, word.span.end),
                    lint_kind: LintKind::WordChoice,
                    message: "The base form of the verb is needed here.".to_string(),
                    suggestions: vec![Suggestion::ReplaceWith(
                        prep_to
                            .iter()
                            .chain([' '].iter())
                            .chain(stem.iter())
                            .copied()
                            .collect(),
                    )],
                    ..Default::default()
                });
            };

            #[derive(PartialEq)]
            enum ToVerbExpects {
                ExpectsInfinitive,
                ExpectsNominal,
            }

            use ToVerbExpects::*;

            let ed_specific_heuristics = || {
                if let Some(prev) = document.get_next_word_from_offset(pi, -1) {
                    let prev_chars = document.get_span_content(&prev.span);
                    if let Some(metadata) = self.dictionary.get_word_metadata(prev_chars) {
                        // adj: "able to" expects an infinitive verb
                        // verb: "have/had/has/having to" expect an infinitive verb
                        if metadata.is_adjective() || metadata.is_verb() {
                            return ToVerbExpects::ExpectsInfinitive;
                        }
                    }
                } else {
                    // Assume a chunk beginning with "to" and a verb in -ed should expect an infinitive verb
                    return ToVerbExpects::ExpectsInfinitive;
                }
                // Default assumption is that "to" is a preposition so a noun etc. should come after it
                ToVerbExpects::ExpectsNominal
            };

            if chars.ends_with(&['e', 'd']) {
                let ed = check_stem(&chars[..chars.len() - 2]);
                if ed && ed_specific_heuristics() == ExpectsInfinitive {
                    lint_from_stem(&chars[..chars.len() - 2]);
                };
                let d = check_stem(&chars[..chars.len() - 1]);
                // Add -d specific heuristics when needed
                if d {
                    lint_from_stem(&chars[..chars.len() - 1]);
                };
            }
            if chars.ends_with(&['e', 's']) {
                let es = check_stem(&chars[..chars.len() - 2]);
                // Add -es specific heuristics when needed
                if es {
                    lint_from_stem(&chars[..chars.len() - 2]);
                };
            }
            if chars.ends_with(&['s']) {
                let s = check_stem(&chars[..chars.len() - 1]);
                // Add -s specific heuristics when needed
                if s {
                    lint_from_stem(&chars[..chars.len() - 1]);
                };
            }
        }
        lints
    }

    fn description(&self) -> &str {
        "This rule looks for `to verb` where `verb` is not in the infinitive form."
    }
}

#[cfg(test)]
mod tests {
    use super::InflectedVerbAfterTo;
    use crate::linting::tests::{assert_lint_count, assert_suggestion_result};
    use crate::spell::FstDictionary;

    #[test]
    fn dont_flag_to_check_both_verb_and_noun() {
        assert_lint_count(
            "to check",
            InflectedVerbAfterTo::new(FstDictionary::curated()),
            0,
        );
    }

    #[test]
    fn dont_flag_to_checks_both_verb_and_noun() {
        assert_lint_count(
            "to checks",
            InflectedVerbAfterTo::new(FstDictionary::curated()),
            0,
        );
    }

    #[test]
    fn dont_flag_to_cheques_not_a_verb() {
        assert_lint_count(
            "to cheques",
            InflectedVerbAfterTo::new(FstDictionary::curated()),
            0,
        );
    }

    #[test]
    #[ignore = "-ing forms can act as nouns, current heuristics cannot distinguish"]
    fn flag_to_checking() {
        assert_lint_count(
            "to checking",
            InflectedVerbAfterTo::new(FstDictionary::curated()),
            1,
        );
    }

    #[test]
    fn dont_flag_check_ed() {
        assert_lint_count(
            "to checked",
            InflectedVerbAfterTo::new(FstDictionary::curated()),
            0,
        );
    }

    #[test]
    fn dont_flag_noun_belief_s() {
        assert_lint_count(
            "to beliefs",
            InflectedVerbAfterTo::new(FstDictionary::curated()),
            0,
        );
    }

    #[test]
    fn dont_flag_noun_meat_s() {
        assert_lint_count(
            "to meats",
            InflectedVerbAfterTo::new(FstDictionary::curated()),
            0,
        );
    }

    #[test]
    #[ignore = "can't check yet. 'capture' is noun as well as verb. \"to nouns\" is good English. we can't disambiguate verbs from nouns."]
    fn check_993_suggestions() {
        assert_suggestion_result(
            "A location-agnostic structure that attempts to captures the context and content that a Lint occurred.",
            InflectedVerbAfterTo::new(FstDictionary::curated()),
            "A location-agnostic structure that attempts to capture the context and content that a Lint occurred.",
        );
    }

    #[test]
    fn dont_flag_embarrass_not_in_dictionary() {
        assert_lint_count(
            "Second I'm going to embarrass you for a.",
            InflectedVerbAfterTo::new(FstDictionary::curated()),
            0,
        );
    }

    #[test]
    fn corrects_exist_s() {
        assert_suggestion_result(
            "A valid solution is expected to exists.",
            InflectedVerbAfterTo::new(FstDictionary::curated()),
            "A valid solution is expected to exist.",
        );
    }

    #[test]
    #[ignore = "can't check yet. 'catch' is noun as well as verb. 'to nouns' is good English. we can't disambiguate verbs from nouns."]
    fn corrects_es_ending() {
        assert_suggestion_result(
            "I need it to catches every exception.",
            InflectedVerbAfterTo::new(FstDictionary::curated()),
            "I need it to catch every exception.",
        );
    }

    #[test]
    fn corrects_ed_ending() {
        assert_suggestion_result(
            "I had to expanded my horizon.",
            InflectedVerbAfterTo::new(FstDictionary::curated()),
            "I had to expand my horizon.",
        );
    }

    #[test]
    fn flags_expire_d() {
        assert_lint_count(
            "I didn't know it was going to expired.",
            InflectedVerbAfterTo::new(FstDictionary::curated()),
            1,
        );
    }

    #[test]
    fn corrects_explain_ed() {
        assert_suggestion_result(
            "To explained the rules to the team.",
            InflectedVerbAfterTo::new(FstDictionary::curated()),
            "To explain the rules to the team.",
        );
    }

    #[test]
    #[ignore = "can't check yet. surprisingly, 'explore' is noun as well as verb. 'to nouns' is good English. we can't disambiguate verbs from nouns."]
    fn corrects_explor_ed() {
        assert_suggestion_result(
            "I went to explored distant galaxies.",
            InflectedVerbAfterTo::new(FstDictionary::curated()),
            "I went to explore distant galaxies.",
        );
    }

    #[test]
    fn cant_flag_express_ed_also_noun() {
        assert_lint_count(
            "I failed to clearly expressed my point.",
            InflectedVerbAfterTo::new(FstDictionary::curated()),
            0,
        );
    }

    #[test]
    fn correct_feign_ed() {
        // adj "able" before "to" works with "to", making "to" part of an infinitive verb
        assert_suggestion_result(
            "I was able to feigned ignorance.",
            InflectedVerbAfterTo::new(FstDictionary::curated()),
            "I was able to feign ignorance.",
        );
    }

    #[test]
    fn issue_241() {
        // Hypothesis: when before "to" is not an adj, assume "to" is a preposition
        assert_lint_count(
            "Comparison to Expected Results",
            InflectedVerbAfterTo::new(FstDictionary::curated()),
            0,
        );
    }
}



================================================
FILE: harper-core/src/linting/initialism_linter.rs
================================================
use crate::expr::Expr;

use crate::{Token, patterns::Word};

use super::{ExprLinter, Lint, LintKind, Suggestion};
use crate::linting::expr_linter::Chunk;

/// Alias for a word in an initialism expansion
type InitialismWord = Vec<char>;
/// Alias for a phrase an initialism expands to
type InitialismPhrase = Vec<InitialismWord>;

/// A struct that can be composed to expand initialisms, respecting the capitalization of each
/// item.
pub struct InitialismLinter {
    expr: Box<dyn Expr>,
    /// The lowercase-normalized expansion of the initialism.
    expansions_lower: Vec<InitialismPhrase>,
}

impl InitialismLinter {
    /// Construct a linter that can correct an initialism to
    pub fn new(initialism: &str, expansions: &[&str]) -> Self {
        let expansions_lower = expansions
            .iter()
            .map(|expansion| {
                expansion
                    .split(' ')
                    .map(|s| s.chars().map(|v| v.to_ascii_lowercase()).collect())
                    .collect()
            })
            .collect();

        Self {
            expr: Box::new(Word::from_char_string(initialism.chars().collect())),
            expansions_lower,
        }
    }
}

impl ExprLinter for InitialismLinter {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], source: &[char]) -> Option<Lint> {
        let tok = matched_tokens.first()?;
        let source = tok.span.get_content(source);

        let suggestions = self
            .expansions_lower
            .iter()
            .map(|expansion_lower| {
                let mut expansion = expansion_lower.clone();
                let first_letter = &mut expansion[0][0];
                *first_letter = if source[0].is_ascii_uppercase() {
                    first_letter.to_ascii_uppercase()
                } else {
                    first_letter.to_ascii_lowercase()
                };
                Suggestion::ReplaceWith(
                    expansion
                        .iter()
                        .flat_map(|word| std::iter::once(' ').chain(word.iter().copied()))
                        .skip(1)
                        .collect::<Vec<_>>(),
                )
            })
            .collect::<Vec<_>>();

        Some(Lint {
            span: tok.span,
            lint_kind: LintKind::Miscellaneous,
            suggestions,
            message: "Try expanding this initialism.".to_owned(),
            priority: 127,
        })
    }

    fn description(&self) -> &'static str {
        "Expands an initialism."
    }
}

#[cfg(test)]
mod tests {}



================================================
FILE: harper-core/src/linting/initialisms.rs
================================================
use crate::linting::LintGroup;

use super::InitialismLinter;

pub fn lint_group() -> LintGroup {
    let mut group = LintGroup::empty();

    macro_rules! add_initialism_mappings {
        ($group:expr, { $($name:expr => ($initialism:expr, $expanded:expr)),+ $(,)? }) => {
            $(
                $group.add_chunk_expr_linter(
                    $name,
                    Box::new(InitialismLinter::new($initialism, $expanded)),
                );
            )+
        };
    }

    add_initialism_mappings!(group, {
        "ByTheWay"           => ("btw", &["by the way"]),
        "ForYourInformation" => ("fyi", &["for your information"]),
        "AsSoonAsPossible"   => ("asap", &["as soon as possible"]),
        "InMyOpinion"        => ("imo", &["in my opinion"]),
        "InMyHumbleOpinion"  => ("imho", &["in my humble opinion", "in my honest opinion"]),
        "OhMyGod"            => ("omg", &["oh my god"]),
        "BeRightBack"        => ("brb", &["be right back"]),
        "TalkToYouLater"     => ("ttyl", &["talk to you later"]),
        "NeverMind"          => ("nvm", &["never mind"]),
        "ToBeHonest"         => ("tbh", &["to be honest"]),
        "AsFarAsIKnow"       => ("afaik", &["as far as I know"]),
        "Really"             => ("rly", &["really"]),
        "ExplainLikeImFive"  => ("eli5", &["explain like i'm five"]),
        "ForWhatItsWorth"    => ("fwiw", &["for what it's worth"]),
        "IDontKnow"          => ("idk", &["I don't know"]),
        "IfIRecallCorrectly" => ("iirc", &["if I recall correctly"]),
        "IfYouKnowYouKnow"   => ("iykyk", &["if you know, you know"]),
        "InCaseYouMissedIt"  => ("icymi", &["in case you missed it"]),
        "InRealLife"         => ("irl", &["in real life"]),
        "PleaseTakeALook"    => ("ptal", &["please take a look"]),
    });

    group.set_all_rules_to(Some(true));

    group
}

#[cfg(test)]
mod tests {
    use crate::linting::tests::{assert_good_and_bad_suggestions, assert_suggestion_result};

    use super::lint_group;

    #[test]
    fn corrects_btw() {
        assert_suggestion_result(
            "Btw, are you ready to go shopping soon?",
            lint_group(),
            "By the way, are you ready to go shopping soon?",
        );
    }

    #[test]
    fn corrects_style() {
        assert_suggestion_result(
            "I love the fit, btw.",
            lint_group(),
            "I love the fit, by the way.",
        );
    }

    #[test]
    fn corrects_fyi() {
        assert_suggestion_result(
            "Fyi, the meeting is at 3.",
            lint_group(),
            "For your information, the meeting is at 3.",
        );
    }

    #[test]
    fn corrects_asap() {
        assert_suggestion_result(
            "Please respond asap.",
            lint_group(),
            "Please respond as soon as possible.",
        );
    }

    #[test]
    fn corrects_imo() {
        assert_suggestion_result(
            "Imo, that is the best option.",
            lint_group(),
            "In my opinion, that is the best option.",
        );
    }

    #[test]
    fn corrects_omg() {
        assert_suggestion_result(
            "Omg! That's incredible!",
            lint_group(),
            "Oh my god! That's incredible!",
        );
    }

    #[test]
    fn corrects_brb() {
        assert_suggestion_result("Hold on, brb.", lint_group(), "Hold on, be right back.");
    }

    #[test]
    fn corrects_tbh() {
        assert_suggestion_result(
            "Tbh, I'm not impressed.",
            lint_group(),
            "To be honest, I'm not impressed.",
        );
    }

    #[test]
    fn corrects_rly() {
        assert_suggestion_result(
            "Rly excited for this.",
            lint_group(),
            "Really excited for this.",
        );
    }

    #[test]
    fn issue_2181() {
        assert_suggestion_result(
            "AFAIK, we don't currently have an issue for it.",
            lint_group(),
            "As far as i know, we don't currently have an issue for it.",
        );
    }

    #[test]
    fn corrects_eli5() {
        assert_suggestion_result(
            "Can you eli5 how this works?",
            lint_group(),
            "Can you explain like i'm five how this works?",
        );
    }

    #[test]
    fn corrects_fwiw() {
        assert_suggestion_result(
            "Fwiw, I think it's a good idea.",
            lint_group(),
            "For what it's worth, I think it's a good idea.",
        );
    }

    #[test]
    fn corrects_idk() {
        assert_suggestion_result(
            "Idk if I'll make it to the party.",
            lint_group(),
            "I don't know if I'll make it to the party.",
        );
    }

    #[test]
    fn corrects_iirc() {
        assert_suggestion_result(
            "Iirc, the event starts at 6 PM.",
            lint_group(),
            "If i recall correctly, the event starts at 6 PM.",
        );
    }

    #[test]
    fn corrects_iykyk() {
        assert_suggestion_result(
            "Iykyk, this place is amazing.",
            lint_group(),
            "If you know, you know, this place is amazing.",
        );
    }

    #[test]
    fn corrects_icymi() {
        assert_suggestion_result(
            "Icymi, the deadline is tomorrow.",
            lint_group(),
            "In case you missed it, the deadline is tomorrow.",
        );
    }

    #[test]
    fn corrects_irl() {
        assert_suggestion_result(
            "We should meet irl sometime.",
            lint_group(),
            "We should meet in real life sometime.",
        );
    }

    #[test]
    fn corrects_ptal() {
        assert_suggestion_result(
            "Ptal at the document I sent.",
            lint_group(),
            "Please take a look at the document I sent.",
        );
    }

    #[test]
    fn expands_imho_both_ways() {
        assert_good_and_bad_suggestions(
            "Imho, this is a good idea.",
            lint_group(),
            &[
                "In my humble opinion, this is a good idea.",
                "In my honest opinion, this is a good idea.",
            ],
            &["In my horrible opinion, this is a good idea."],
        );
    }
}



================================================
FILE: harper-core/src/linting/interested_in.rs
================================================
use crate::linting::expr_linter::Chunk;
use crate::{
    CharStringExt, Token, TokenKind,
    expr::{Expr, SequenceExpr},
    linting::{ExprLinter, Lint, LintKind, Suggestion},
};

pub struct InterestedIn {
    expr: Box<dyn Expr>,
}

impl Default for InterestedIn {
    fn default() -> Self {
        let pattern = SequenceExpr::default()
            .t_aco("interested")
            .t_ws()
            .then_kind_except(
                TokenKind::is_preposition,
                &["around", "for", "through", "to", "within"],
            );

        Self {
            expr: Box::new(pattern),
        }
    }
}

impl ExprLinter for InterestedIn {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, tokens: &[Token], source: &[char]) -> Option<Lint> {
        let prep_span = tokens.last().unwrap().span;
        let prep_chars = prep_span.get_content(source);

        if prep_chars.eq_ignore_ascii_case_chars(&['i', 'n']) {
            return None;
        }

        Some(Lint {
            span: prep_span,
            lint_kind: LintKind::Usage,
            suggestions: vec![Suggestion::replace_with_match_case(
                "in".chars().collect(),
                prep_chars,
            )],
            message: "The correct preposition to use with `interested` is `in`.".to_string(),
            ..Default::default()
        })
    }

    fn description(&self) -> &str {
        "Ensures the correct preposition is used with the word `interested` (e.g. `interested in`)."
    }
}

#[cfg(test)]
mod tests {
    use super::InterestedIn;
    use crate::linting::tests::{assert_lint_count, assert_suggestion_result};

    #[test]
    fn fix_about() {
        assert_suggestion_result(
            "It suggests some useful programs the user could be interested about - NyarchLinux/NyarchWizard.",
            InterestedIn::default(),
            "It suggests some useful programs the user could be interested in - NyarchLinux/NyarchWizard.",
        );
    }

    #[test]
    fn dont_flag_around() {
        assert_lint_count(
            "We want to figure out why this is, and how to keep those interested around for longer.",
            InterestedIn::default(),
            0,
        );
    }

    #[test]
    fn fix_at() {
        assert_suggestion_result(
            "If someone is interested at the processed data, please email me.",
            InterestedIn::default(),
            "If someone is interested in the processed data, please email me.",
        );
    }

    #[test]
    #[ignore = "Requires more context because 'interested for now/for sure' are not errors"]
    fn fix_for() {
        assert_suggestion_result(
            "but the user is only interested for the examples in one of the modes",
            InterestedIn::default(),
            "but the user is only interested in the examples in one of the modes",
        );
    }

    #[test]
    fn dont_flag_for_sure() {
        assert_lint_count("I am interested for sure!", InterestedIn::default(), 0);
    }

    #[test]
    fn fix_into() {
        assert_suggestion_result(
            "This is one of the first complex software I wrote, and it prefigures so much of the reasons why I was interested into working on designing HTML and CSS.",
            InterestedIn::default(),
            "This is one of the first complex software I wrote, and it prefigures so much of the reasons why I was interested in working on designing HTML and CSS.",
        );
    }

    #[test]
    fn fix_of() {
        assert_suggestion_result(
            "If you are interested of tinkering.",
            InterestedIn::default(),
            "If you are interested in tinkering.",
        );
    }

    #[test]
    fn fix_on() {
        assert_suggestion_result(
            "The creator of Photopea, a great free alternative to Photoshop, is not interested on making an offline version, so I took it upon myself to make it.",
            InterestedIn::default(),
            "The creator of Photopea, a great free alternative to Photoshop, is not interested in making an offline version, so I took it upon myself to make it.",
        );
    }

    #[test]
    fn dont_flag_through() {
        assert_lint_count(
            "I'm happy to help walk anyone interested through doing this",
            InterestedIn::default(),
            0,
        );
    }

    #[test]
    fn does_not_flag_to() {
        assert_lint_count(
            "Hi, As title suggest i am interested to know if we can run a custom model trained on yolov9 inference running on two GPU-s.",
            InterestedIn::default(),
            0,
        );
    }

    #[test]
    fn fix_with() {
        assert_suggestion_result(
            "no_std support (is anybody interested with this?)",
            InterestedIn::default(),
            "no_std support (is anybody interested in this?)",
        );
    }

    #[test]
    fn dont_flag_within() {
        assert_lint_count(
            "But with no one being interested within 8 months, what help would it be.",
            InterestedIn::default(),
            0,
        );
    }
}



================================================
FILE: harper-core/src/linting/it_is.rs
================================================
use crate::expr::{Expr, SequenceExpr};
use crate::linting::expr_linter::Chunk;
use crate::{
    Token, TokenKind,
    linting::{ExprLinter, Lint, LintKind, Suggestion},
};

pub struct ItIs {
    expr: Box<dyn Expr>,
}

impl Default for ItIs {
    fn default() -> Self {
        let pattern = SequenceExpr::default()
            .t_aco("its")
            .then_whitespace()
            .then_kind_except(
                TokenKind::is_adjective,
                &[
                    "1st",
                    "animal",
                    "assault",
                    "body",
                    "budget",
                    "business",
                    "center",
                    "centre",
                    "frontline",
                    "head",
                    "key",
                    "mainline",
                    "material",
                    "mean",
                    "own",
                    "power",
                    "regulation",
                    "runtime",
                    "size",
                    "state",
                    "team",
                    "turnover",
                    "utility",
                    "woman",
                ],
            )
            .then_whitespace()
            .then_preposition();
        Self {
            expr: Box::new(pattern),
        }
    }
}

impl ExprLinter for ItIs {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, tokens: &[Token], source: &[char]) -> Option<Lint> {
        let its_token = &tokens[0];
        let span = its_token.span;
        let text = span.get_content(source);
        Some(Lint {
            span,
            lint_kind: LintKind::Miscellaneous,
            suggestions: vec![Suggestion::replace_with_match_case(
                "it's".chars().collect(),
                text,
            )],
            message: "Consider using 'it's' (it is) instead of 'its' (possessive form)."
                .to_string(),
            priority: 31,
        })
    }

    fn description(&self) -> &str {
        "Detects when “its” is used before an adjective + preposition and suggests the contraction “it's”."
    }
}

#[cfg(test)]
mod tests {
    use super::ItIs;
    use crate::linting::tests::{assert_lint_count, assert_suggestion_result};

    #[test]
    fn flags_simple_case() {
        assert_suggestion_result(
            "Its amazing to see this.",
            ItIs::default(),
            "It's amazing to see this.",
        );
    }

    #[test]
    fn flags_with_preposition() {
        assert_suggestion_result(
            "Its critical for the project.",
            ItIs::default(),
            "It's critical for the project.",
        );
    }

    #[test]
    fn does_not_flag_exception_own() {
        assert_lint_count("Its own design is unique.", ItIs::default(), 0);
    }

    #[test]
    fn does_not_flag_exception_team() {
        assert_lint_count("Its team lead is excellent.", ItIs::default(), 0);
    }

    #[test]
    #[ignore = "This case fails, but I think that's acceptable"]
    fn does_not_flag_non_adjective() {
        assert_lint_count(
            "The cat chased its tail around the room.",
            ItIs::default(),
            0,
        );
    }

    #[test]
    fn does_not_flag_already_correct() {
        assert_lint_count("It's important to note.", ItIs::default(), 0);
    }

    #[test]
    fn flags_search_filter_context() {
        assert_suggestion_result(
            "Its important to note that the search filter will currently only search the current page.",
            ItIs::default(),
            "It's important to note that the search filter will currently only search the current page.",
        );
    }

    #[test]
    fn flags_ens_restart_context() {
        assert_suggestion_result(
            "Today is the third day and I am still stuck on Register. Its important to note that after hours of waiting, I tried to restart the process and clicked on register again but it gets stuck at TX pending.",
            ItIs::default(),
            "Today is the third day and I am still stuck on Register. It's important to note that after hours of waiting, I tried to restart the process and clicked on register again but it gets stuck at TX pending.",
        );
    }

    #[test]
    fn flags_academics_support_context() {
        assert_suggestion_result(
            "To assist learners, because its critical for academics to support their ideas and arguments with sources of published research.",
            ItIs::default(),
            "To assist learners, because it's critical for academics to support their ideas and arguments with sources of published research.",
        );
    }

    #[test]
    fn flags_parents_explain_context() {
        assert_suggestion_result(
            "I also think its critical for parents to explain their reason for saying no though I would advise against attempting to use logic in the face of either toddler or teenage rage.",
            ItIs::default(),
            "I also think it's critical for parents to explain their reason for saying no though I would advise against attempting to use logic in the face of either toddler or teenage rage.",
        );
    }

    #[test]
    fn flags_chapter_context() {
        assert_suggestion_result(
            "I think it's okay since its critical for the rest of the chapter in terms of tone and approach.",
            ItIs::default(),
            "I think it's okay since it's critical for the rest of the chapter in terms of tone and approach.",
        );
    }

    #[test]
    fn flags_microsoft_work_context() {
        assert_suggestion_result(
            "... Need help, its critical for my work, as i am a technical blog writer ...",
            ItIs::default(),
            "... Need help, it's critical for my work, as i am a technical blog writer ...",
        );
    }

    #[test]
    fn flags_feminists_context() {
        assert_suggestion_result(
            "when it comes to the teaching of grammar and diverse linguistics practices. Its critical for feminists to think about the ways in which they frame language.",
            ItIs::default(),
            "when it comes to the teaching of grammar and diverse linguistics practices. It's critical for feminists to think about the ways in which they frame language.",
        );
    }

    #[test]
    fn flags_students_proofreading_context() {
        assert_suggestion_result(
            "its critical for students to develop a similarly sharp eye for misspellings and grammatical errors.",
            ItIs::default(),
            "it's critical for students to develop a similarly sharp eye for misspellings and grammatical errors.",
        );
    }

    #[test]
    fn flags_americans_context() {
        assert_suggestion_result(
            "Its critical for Americans to realize that Fox has nothing to do with news.",
            ItIs::default(),
            "It's critical for Americans to realize that Fox has nothing to do with news.",
        );
    }

    // Negative guard: correct possessive use
    #[test]
    fn does_not_flag_its_team_lead() {
        assert_lint_count("Its team lead is excellent.", ItIs::default(), 0);
    }

    // Imagined edge cases based on real usage:
    #[test]
    fn flags_crucial_api_context() {
        assert_suggestion_result(
            "Its crucial to understand the API before using it.",
            ItIs::default(),
            "It's crucial to understand the API before using it.",
        );
    }

    #[test]
    fn flags_essential_standards_context() {
        assert_suggestion_result(
            "Its essential to follow the coding standards in this project.",
            ItIs::default(),
            "It's essential to follow the coding standards in this project.",
        );
    }

    #[test]
    fn flags_vital_dependencies_context() {
        assert_suggestion_result(
            "Its vital to keep dependencies up to date.",
            ItIs::default(),
            "It's vital to keep dependencies up to date.",
        );
    }
}



================================================
FILE: harper-core/src/linting/it_looks_like_that.rs
================================================
use crate::Token;
use crate::expr::{Expr, SequenceExpr};
use crate::linting::expr_linter::Chunk;
use crate::linting::{ExprLinter, Lint, LintKind, Suggestion};
use crate::token_string_ext::TokenStringExt;

pub struct ItLooksLikeThat {
    expr: Box<dyn Expr>,
}

impl Default for ItLooksLikeThat {
    fn default() -> Self {
        Self {
            expr: Box::new(
                SequenceExpr::default()
                    .then_fixed_phrase("it looks like that")
                    .then_whitespace()
                    .then_kind_where(|kind| {
                        // Heuristics on the word after "that" which show "that" was used
                        // as a relative pronoun, which is a mistake
                        let is_subj = kind.is_subject_pronoun();
                        let is_ing = kind.is_verb_progressive_form();
                        let is_definitely_rel_pron = is_subj || is_ing;

                        // Heuristics on the word after "that" which show "that"
                        // could possibly be a legitimate demonstrative pronoun or determiner
                        // as a demonstrative pronoun or a determiner
                        // which would not be a mistake.
                        let is_v3psgpres = kind.is_verb_third_person_singular_present_form();
                        // NOTE: we don't have .is_modal_verb() but maybe we need it now!
                        let is_vmodal_or_aux = kind.is_auxiliary_verb();
                        let is_vpret = kind.is_verb_simple_past_form();
                        let is_noun = kind.is_noun();
                        let is_oov = kind.is_oov();

                        let maybe_demonstrative_or_determiner =
                            is_v3psgpres || is_vmodal_or_aux || is_vpret || is_noun || is_oov;

                        is_definitely_rel_pron || !maybe_demonstrative_or_determiner
                    }),
            ),
        }
    }
}

impl ExprLinter for ItLooksLikeThat {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, toks: &[Token], _: &[char]) -> Option<Lint> {
        let that_span = toks[6..8].span()?;

        Some(Lint {
            span: that_span,
            lint_kind: LintKind::Redundancy,
            suggestions: vec![Suggestion::Remove],
            message: "`that` is redundant and ungrammatical here".to_string(),
            priority: 31,
        })
    }

    fn description(&self) -> &str {
        "Corrects `it looks like that` to just `it looks like`."
    }
}

#[cfg(test)]
mod tests {
    mod that_noun {
        use super::super::ItLooksLikeThat;
        use crate::linting::tests::assert_no_lints;

        #[test]
        fn dont_flag_that_noun_is_also_verb_part_of_np() {
            // "that" could be legit demonstrative, indicating which 'file tree view'
            // "file" is both a noun and a verb
            assert_no_lints(
                "It looks like that file tree view is just for things that have already been committed?",
                ItLooksLikeThat::default(),
            );
        }
        #[test]
        fn dont_flag_that_noun_is_also_adj() {
            // "metric" is both a noun and an adjective
            assert_no_lints(
                "Yes, unfortunately it looks like that metric kind isn't supported yet.",
                ItLooksLikeThat::default(),
            );
        }
        #[test]
        fn cant_flag_that_noun_is_also_verb_function() {
            // "that" is not demonstrative, but heuristics can't determine that.
            // "function" is both a noun and a verb
            assert_no_lints(
                "It looks like that function Config.validate_doc_path is only called in one place",
                ItLooksLikeThat::default(),
            );
        }
        #[test]
        fn dont_flag_that_noun_is_also_verb_test() {
            assert_no_lints(
                "It looks like that test runs with -sOFFSCREEN_FRAMEBUFFER",
                ItLooksLikeThat::default(),
            );
        }

        #[test]
        fn dont_flag_that_oov() {
            // "that" could be legit demonstrative, indicating which 'nms'
            // because OOV words are most commonly nouns.
            assert_no_lints(
                "It looks like that nms is not working.",
                ItLooksLikeThat::default(),
            );
        }

        #[test]
        fn dont_flag_that_noun_pad() {
            assert_no_lints(
                "It looks like that pad was not covered in solder mask or glue",
                ItLooksLikeThat::default(),
            );
        }

        #[test]
        fn dont_flag_that_noun_plural() {
            assert_no_lints(
                "The issue we're running into is that it looks like that nodes not only want to peer via raft",
                ItLooksLikeThat::default(),
            );
        }
    }

    mod that_det {
        use super::super::ItLooksLikeThat;
        use crate::linting::tests::assert_suggestion_result;

        #[test]
        fn fix_that_the() {
            // "that" is being wrongly used as a relative pronoun
            assert_suggestion_result(
                "it looks like that the original products should have NULL in the value column",
                ItLooksLikeThat::default(),
                "it looks like the original products should have NULL in the value column",
            );
        }

        #[test]
        fn fix_that_some() {
            assert_suggestion_result(
                "From first expresion it looks like that some tokkens or what was cached",
                ItLooksLikeThat::default(),
                "From first expresion it looks like some tokkens or what was cached",
            );
        }
    }

    mod that_verb {
        use super::super::ItLooksLikeThat;
        use crate::linting::tests::{assert_no_lints, assert_suggestion_result};

        #[test]
        fn dont_flag_that_verb_3p_sing_pres_is() {
            // "that" is definitely legit demonstrative pronoun
            // Because "is" is a linking verb in 3rd person singular present form.
            assert_no_lints(
                "Looking at the code it looks like that is not the case",
                ItLooksLikeThat::default(),
            );
        }

        #[test]
        fn dont_flag_that_verb_3p_sing_pres_comes() {
            assert_no_lints(
                "it looks like that comes with additional compile-time dependencies",
                ItLooksLikeThat::default(),
            );
        }

        #[test]
        fn fix_that_it_verb_lemma() {
            // "that" is being wrongly used as a relative pronoun
            // But it's hard to check becuase 'renovate' is a verb but is being used as a noun
            assert_suggestion_result(
                "It looks like that Renovate decides to not reuse the branch when there are no changes in it",
                ItLooksLikeThat::default(),
                "It looks like Renovate decides to not reuse the branch when there are no changes in it",
            );
        }

        #[test]
        fn dont_flag_that_modal_verb_might() {
            assert_no_lints(
                "It looks like that might be exactly what I needed!",
                ItLooksLikeThat::default(),
            );
        }

        #[test]
        fn dont_flag_that_verb_modal_would() {
            assert_no_lints(
                "but it looks like that would require writing the data out to vsimem and reading it back",
                ItLooksLikeThat::default(),
            );
        }

        #[test]
        fn fix_that_verb_ing_have() {
            // Verbs in -ing are also gerunds, which are nouns.
            // But at least in this case, "having", it doesn't work after "that".
            assert_suggestion_result(
                "It looks like that having <br> tags inside them breaks the rendering",
                ItLooksLikeThat::default(),
                "It looks like having <br> tags inside them breaks the rendering",
            );
        }

        #[test]
        fn fix_that_verb_ing_using() {
            assert_suggestion_result(
                "it looks like that using TensorFlow in conjunction with packages that use pybind11_abseil will fail",
                ItLooksLikeThat::default(),
                "it looks like using TensorFlow in conjunction with packages that use pybind11_abseil will fail",
            );
        }

        #[test]
        fn dont_flag_that_verb_simple_past() {
            assert_no_lints(
                "but it looks like that got accidentally reverted at some point",
                ItLooksLikeThat::default(),
            );
        }
    }

    mod pronoun {
        use super::super::ItLooksLikeThat;
        use crate::linting::tests::{assert_no_lints, assert_suggestion_result};

        #[test]
        fn fix_that_subj_obj_pronoun_it_was() {
            // "that" is being wrongly used as a relative pronoun
            assert_suggestion_result(
                "It looks like that it was not improved a lot.",
                ItLooksLikeThat::default(),
                "It looks like it was not improved a lot.",
            );
        }
        #[test]
        fn fix_that_subj_obj_pronoun_it_works() {
            // "that" is being wrongly used as a relative pronoun
            assert_suggestion_result(
                "Thx, it looks like that it works for Inpainting itself",
                ItLooksLikeThat::default(),
                "Thx, it looks like it works for Inpainting itself",
            );
        }

        #[test]
        fn fix_that_subj_obj_pronoun_you() {
            assert_suggestion_result(
                "It looks like that you can't use the files in combination.",
                ItLooksLikeThat::default(),
                "It looks like you can't use the files in combination.",
            );
        }

        #[test]
        fn dont_flag_thats() {
            assert_no_lints(
                "it looks like that's how you access the system changeset functionality",
                ItLooksLikeThat::default(),
            );
        }
    }

    mod conjunction {
        use super::super::ItLooksLikeThat;
        use crate::linting::tests::assert_no_lints;

        #[test]
        fn cant_flag_that_if() {
            // This can be read two ways, so we can't flag it
            assert_no_lints(
                "It looks like that if the server goes away in the middle of a request, and a request is cancelled",
                ItLooksLikeThat::default(),
            );
        }

        #[test]
        fn cant_flag_that_but() {
            // This can be read two ways, so we can't flag it
            assert_no_lints(
                "Yes, it looks like that but it is unreasonable since the shim executable is in the same directory",
                ItLooksLikeThat::default(),
            );
        }
    }
}



================================================
FILE: harper-core/src/linting/it_would_be.rs
================================================
use crate::expr::Expr;
use crate::expr::OwnedExprExt;
use crate::expr::SequenceExpr;
use crate::linting::expr_linter::Chunk;
use crate::{
    Token,
    linting::{ExprLinter, Lint, LintKind, Suggestion},
    patterns::WordSet,
};

pub struct ItWouldBe {
    expr: Box<dyn Expr>,
}

impl Default for ItWouldBe {
    fn default() -> Self {
        /* ─────────────── helpers ─────────────── */
        let head_verbs = WordSet::new(&["believe", "doubt", "think", "assume", "guess"]);
        let modals = WordSet::new(&["might", "would", "will"]);
        let adjectives = WordSet::new(&["good", "bad", "wonderful", "real"]);
        let tail_nouns = WordSet::new(&[
            "bummer",
            "pity",
            "shame",
            "pleasure",
            "idea",
            "experience",
            "problem",
            "catastrophe",
            "disaster",
            "trap",
            "challenge",
        ]);

        let branch = |has_not: bool, has_adj: bool| {
            let mut p = SequenceExpr::default()
                .then(head_verbs.clone())
                .then_whitespace()
                .t_aco("i") // the mistaken pronoun
                .then_whitespace()
                .then(modals.clone());

            if has_not {
                p = p.then_whitespace().t_aco("not");
            }

            p = p.then_whitespace().t_aco("be").then_whitespace().t_aco("a");

            if has_adj {
                p = p.then_whitespace().then(adjectives.clone());
            }

            p.then_whitespace().then(tail_nouns.clone())
        };

        let combined = branch(false, false)
            .or(branch(false, true))
            .or(branch(true, false))
            .or(branch(true, true));

        Self {
            expr: Box::new(combined),
        }
    }
}

impl ExprLinter for ItWouldBe {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, toks: &[Token], _src: &[char]) -> Option<Lint> {
        let pronoun = &toks[2];
        let span = pronoun.span;

        Some(Lint {
            span,
            lint_kind: LintKind::WordChoice,
            suggestions: vec![Suggestion::ReplaceWith("it".chars().collect())],
            message: "In this construction the pronoun should be “it”, not “I”. \
                      e.g. *“I think **it** would be a shame …”*"
                .to_owned(),
            priority: 31,
        })
    }

    fn description(&self) -> &str {
        "Replaces the incorrect sequence “I might/would/will (not) be a …” with “it …”, \
         as in “I think **it** would be a shame.”"
    }
}

#[cfg(test)]
mod tests {
    use super::ItWouldBe;
    use crate::linting::tests::{assert_lint_count, assert_suggestion_result};

    #[test]
    fn flags_simple_shame() {
        assert_suggestion_result(
            "I think I would be a shame if this happened.",
            ItWouldBe::default(),
            "I think it would be a shame if this happened.",
        );
    }

    #[test]
    fn flags_believe_bummer() {
        assert_suggestion_result(
            "We believe I might not be a bummer after all.",
            ItWouldBe::default(),
            "We believe it might not be a bummer after all.",
        );
    }

    #[test]
    fn flags_doubt_good_idea() {
        assert_suggestion_result(
            "They doubt I will be a good idea for the team.",
            ItWouldBe::default(),
            "They doubt it will be a good idea for the team.",
        );
    }

    #[test]
    fn ignores_correct_it() {
        assert_lint_count(
            "I think it would be a shame if this happened.",
            ItWouldBe::default(),
            0,
        );
    }

    #[test]
    fn ignores_first_person_statement() {
        assert_lint_count(
            "I would be a good fit for the role.",
            ItWouldBe::default(),
            0,
        );
    }
}



================================================
FILE: harper-core/src/linting/its_possessive.rs
================================================
use std::sync::Arc;

use harper_brill::UPOS;

use crate::Token;
use crate::expr::AnchorStart;
use crate::expr::Expr;
use crate::expr::ExprMap;
use crate::expr::OwnedExprExt;
use crate::expr::SequenceExpr;
use crate::patterns::UPOSSet;
use crate::patterns::WordSet;

use super::{ExprLinter, Lint, LintKind, Suggestion};
use crate::linting::expr_linter::Chunk;

pub struct ItsPossessive {
    expr: Box<dyn Expr>,
    map: Arc<ExprMap<usize>>,
}

impl Default for ItsPossessive {
    fn default() -> Self {
        let mut map = ExprMap::default();

        let adj_term = SequenceExpr::default()
            .t_ws()
            .then(UPOSSet::new(&[UPOS::ADJ]));

        let mid_sentence = SequenceExpr::default()
            .then(UPOSSet::new(&[UPOS::VERB, UPOS::ADP]))
            .t_ws()
            .t_aco("it's")
            .then_optional(adj_term)
            .t_ws()
            .then(
                UPOSSet::new(&[UPOS::NOUN, UPOS::PROPN]).or(|tok: &Token, _: &[char]| {
                    tok.kind.as_number().is_some_and(|n| n.suffix.is_some())
                }),
            );

        map.insert(mid_sentence, 2);

        let start_of_sentence = SequenceExpr::default()
            .then(AnchorStart)
            .t_aco("it's")
            .t_ws()
            .then(UPOSSet::new(&[UPOS::ADJ, UPOS::NOUN, UPOS::PROPN]))
            .t_ws()
            .then_unless(UPOSSet::new(&[
                UPOS::VERB,
                UPOS::PART,
                UPOS::ADP,
                UPOS::NOUN,
                UPOS::PRON,
                UPOS::SCONJ,
                UPOS::CCONJ,
                UPOS::ADV,
            ]));

        map.insert(start_of_sentence, 0);

        let special = SequenceExpr::aco("it's")
            .t_ws()
            .then(WordSet::new(&["various"]));

        map.insert(special, 0);

        let map = Arc::new(map);

        Self {
            expr: Box::new(map.clone()),
            map,
        }
    }
}

impl ExprLinter for ItsPossessive {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], source: &[char]) -> Option<Lint> {
        let offending_idx = self.map.lookup(0, matched_tokens, source).unwrap();
        let span = matched_tokens[*offending_idx].span;

        Some(Lint {
            span,
            lint_kind: LintKind::Agreement,
            suggestions: vec![Suggestion::replace_with_match_case_str(
                "its",
                span.get_content(source),
            )],
            message: "Use the possessive pronoun `its` (without an apostrophe) to show ownership. The word `it's` (with an apostrophe) is a contraction of 'it is' or 'it has' and should not be used to indicate possession.".to_string(),
            priority: 31,
        })
    }

    fn description(&self) -> &'static str {
        "In English, possessive pronouns never take an apostrophe. Use `its` to show ownership (e.g. “its texture”) and avoid confusing it with `it's`, which always means “it is” or “it has.”"
    }
}

#[cfg(test)]
mod tests {
    use crate::linting::tests::{assert_lint_count, assert_no_lints, assert_suggestion_result};

    use super::ItsPossessive;

    #[test]
    fn corrects_its_various() {
        assert_suggestion_result(
            "I like it's various colors.",
            ItsPossessive::default(),
            "I like its various colors.",
        );
    }

    #[test]
    fn fixes_inspiration() {
        assert_suggestion_result(
            "I would just put `Orthography` and it's various function implementations in their own `orthography.rs` file.",
            ItsPossessive::default(),
            "I would just put `Orthography` and its various function implementations in their own `orthography.rs` file.",
        );
    }

    #[test]
    fn engine_lost_its_compression() {
        assert_lint_count(
            "The engine lost it's compression.",
            ItsPossessive::default(),
            1,
        );
    }

    #[test]
    fn admired_sculpture_for_its_intricacy() {
        assert_suggestion_result(
            "I admired the sculpture for it's intricacy.",
            ItsPossessive::default(),
            "I admired the sculpture for its intricacy.",
        );
    }

    #[test]
    fn paris_is_known_for_its_architecture() {
        assert_lint_count(
            "Paris is known for it's architecture.",
            ItsPossessive::default(),
            1,
        );
    }

    #[test]
    fn plain_sentence_with_apostrophe_s() {
        assert_suggestion_result(
            "It's benefits are numerous.",
            ItsPossessive::default(),
            "Its benefits are numerous.",
        );
    }

    #[test]
    fn device_reached_its_100th_cycle() {
        assert_lint_count(
            "The device reached it's 100th cycle.",
            ItsPossessive::default(),
            1,
        );
    }

    #[test]
    fn oddly_its_wheels_misaligned() {
        assert_lint_count(
            "Oddly, it's wheels were misaligned.",
            ItsPossessive::default(),
            1,
        );
    }

    #[test]
    fn leaking_oil_constant_issue() {
        assert_lint_count("It's leaking oil constantly.", ItsPossessive::default(), 0);
    }

    #[test]
    fn fiftyth_anniversary() {
        assert_lint_count(
            "The company celebrated it's 50th anniversary.",
            ItsPossessive::default(),
            1,
        );
    }

    #[test]
    fn second_attempt() {
        assert_lint_count("He failed it's 2nd attempt.", ItsPossessive::default(), 1);
    }

    #[test]
    fn third_iteration() {
        assert_lint_count(
            "The program finished it's 3rd iteration.",
            ItsPossessive::default(),
            1,
        );
    }

    #[test]
    fn tenth_milestone() {
        assert_lint_count(
            "They reached it's 10th milestone.",
            ItsPossessive::default(),
            1,
        );
    }

    #[test]
    fn seventh_chapter() {
        assert_lint_count(
            "The novel lost it's 7th chapter.",
            ItsPossessive::default(),
            1,
        );
    }

    #[test]
    fn fifth_version() {
        assert_lint_count(
            "Software updated to it's 5th version.",
            ItsPossessive::default(),
            1,
        );
    }

    #[test]
    fn eighth_floor() {
        assert_lint_count(
            "Elevator stopped at it's 8th floor.",
            ItsPossessive::default(),
            1,
        );
    }

    #[test]
    fn twelfth_episode() {
        assert_lint_count(
            "Series ended it's 12th episode.",
            ItsPossessive::default(),
            1,
        );
    }

    #[test]
    fn fourth_draft() {
        assert_lint_count("He completed it's 4th draft.", ItsPossessive::default(), 1);
    }

    #[test]
    fn ninth_revision() {
        assert_lint_count(
            "The report saved it's 9th revision.",
            ItsPossessive::default(),
            1,
        );
    }

    #[test]
    fn allows_hard_to_tell() {
        assert_no_lints("It's hard to tell from here.", ItsPossessive::default());
    }

    #[test]
    fn allows_illegible() {
        assert_no_lints(
            "When you write in cursive, its illegible",
            ItsPossessive::default(),
        );
    }

    #[test]
    fn allows_good_practice() {
        assert_no_lints(
            "it's good practice to review the general settings",
            ItsPossessive::default(),
        );
    }

    #[test]
    fn allows_understandable() {
        assert_no_lints(
            "It's understandable that you'd feel the weight of responsibility.",
            ItsPossessive::default(),
        );
    }

    #[test]
    fn allows_insincere() {
        assert_no_lints(
            "But feel free to omit it if you feel it's insincere.",
            ItsPossessive::default(),
        );
    }

    #[test]
    fn allows_its_possible() {
        assert_no_lints(
            "It's possible that a record was improperly handled. ",
            ItsPossessive::default(),
        );
    }

    #[test]
    fn allows_many_times_harder() {
        assert_no_lints(
            "It's many times harder to do this than that.",
            ItsPossessive::default(),
        );
    }

    #[test]
    fn allow_issue_1658() {
        assert_no_lints(
            "It's kind of a nuisance, but it will work.",
            ItsPossessive::default(),
        );
    }

    #[test]
    fn allow_issue_2001() {
        assert_no_lints(
            "It's worth highlighting that while using a fork instead of a spoon is easy, it sometimes isn't.",
            ItsPossessive::default(),
        );
    }

    #[test]
    fn dont_flag_issue_1722_its_whats_accessible() {
        assert_no_lints(
            "The base execution context is the global execution context: it's what's accessible everywhere in your code.",
            ItsPossessive::default(),
        );
    }

    #[test]
    fn dont_flag_issue_1722_its_early_and() {
        assert_no_lints(
            "it's early and there's plenty of room for novel and potentially",
            ItsPossessive::default(),
        );
    }

    #[test]
    fn dont_flag_issue_1722_its_big_enough() {
        assert_no_lints("It's big enough.", ItsPossessive::default());
    }
}



================================================
FILE: harper-core/src/linting/jealous_of.rs
================================================
use crate::{
    Token,
    expr::{Expr, SequenceExpr},
    linting::expr_linter::Chunk,
    linting::{ExprLinter, Lint, LintKind, Suggestion},
};

pub struct JealousOf {
    expr: Box<dyn Expr>,
}

impl Default for JealousOf {
    fn default() -> Self {
        let valid_object = |tok: &Token, _source: &[char]| {
            (tok.kind.is_nominal() || !tok.kind.is_verb())
                && (tok.kind.is_oov() || tok.kind.is_nominal())
                && !tok.kind.is_preposition()
        };

        let pattern = SequenceExpr::default()
            .t_aco("jealous")
            .t_ws()
            .t_aco("from")
            .t_ws()
            .then_optional(SequenceExpr::default().then_determiner().t_ws())
            .then(valid_object);

        Self {
            expr: Box::new(pattern),
        }
    }
}

impl ExprLinter for JealousOf {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, tokens: &[Token], source: &[char]) -> Option<Lint> {
        let from_token = &tokens[2];

        Some(Lint {
            span: from_token.span,
            lint_kind: LintKind::Usage,
            suggestions: vec![Suggestion::replace_with_match_case_str(
                "of",
                from_token.span.get_content(source),
            )],
            message: "Use `of` after `jealous`.".to_owned(),
            ..Default::default()
        })
    }

    fn description(&self) -> &str {
        "Encourages the standard preposition after `jealous`."
    }
}

#[cfg(test)]
mod tests {
    use super::JealousOf;
    use crate::linting::tests::{assert_lint_count, assert_suggestion_result};

    #[test]
    fn replaces_basic_from() {
        assert_suggestion_result(
            "She was jealous from her sister's success.",
            JealousOf::default(),
            "She was jealous of her sister's success.",
        );
    }

    #[test]
    fn handles_optional_determiner() {
        assert_suggestion_result(
            "He grew jealous from the attention.",
            JealousOf::default(),
            "He grew jealous of the attention.",
        );
    }

    #[test]
    fn fixes_pronoun_object() {
        assert_suggestion_result(
            "They became jealous from him.",
            JealousOf::default(),
            "They became jealous of him.",
        );
    }

    #[test]
    fn allows_oov_target() {
        assert_suggestion_result(
            "I'm jealous from Zybrix.",
            JealousOf::default(),
            "I'm jealous of Zybrix.",
        );
    }

    #[test]
    fn corrects_uppercase_preposition() {
        assert_suggestion_result(
            "Jealous FROM his fame.",
            JealousOf::default(),
            "Jealous OF his fame.",
        );
    }

    #[test]
    fn fixes_longer_phrase() {
        assert_suggestion_result(
            "They felt jealous from the sudden praise she received.",
            JealousOf::default(),
            "They felt jealous of the sudden praise she received.",
        );
    }

    #[test]
    fn fixes_minimal_phrase() {
        assert_suggestion_result(
            "jealous from success",
            JealousOf::default(),
            "jealous of success",
        );
    }

    #[test]
    fn does_not_flag_correct_usage() {
        assert_lint_count(
            "She was jealous of her sister's success.",
            JealousOf::default(),
            0,
        );
    }

    #[test]
    fn does_not_flag_other_preposition_sequence() {
        assert_lint_count(
            "They stayed jealous from within the fortress.",
            JealousOf::default(),
            0,
        );
    }

    #[test]
    fn fixes_following_gerund() {
        assert_suggestion_result(
            "He was jealous from being ignored.",
            JealousOf::default(),
            "He was jealous of being ignored.",
        );
    }

    #[test]
    fn ignores_numbers_after_from() {
        assert_lint_count(
            "She remained jealous from 2010 through 2015.",
            JealousOf::default(),
            0,
        );
    }
}



================================================
FILE: harper-core/src/linting/johns_hopkins.rs
================================================
use crate::{
    CharStringExt, Token,
    expr::{Expr, SequenceExpr},
    linting::expr_linter::Chunk,
    linting::{ExprLinter, Lint, LintKind, Suggestion},
};

pub struct JohnsHopkins {
    expr: Box<dyn Expr>,
}

impl Default for JohnsHopkins {
    fn default() -> Self {
        let expr = SequenceExpr::default()
            .then(|tok: &Token, src: &[char]| {
                tok.kind.is_proper_noun()
                    && tok.span.get_content(src).eq_ignore_ascii_case_str("john")
            })
            .t_ws()
            .then(|tok: &Token, src: &[char]| {
                tok.kind.is_proper_noun()
                    && tok
                        .span
                        .get_content(src)
                        .eq_ignore_ascii_case_str("hopkins")
            });

        Self {
            expr: Box::new(expr),
        }
    }
}

impl ExprLinter for JohnsHopkins {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], source: &[char]) -> Option<Lint> {
        let span = matched_tokens.first()?.span;
        let template = span.get_content(source);

        Some(Lint {
            span,
            lint_kind: LintKind::WordChoice,
            suggestions: vec![Suggestion::replace_with_match_case_str("Johns", template)],
            message: "Use `Johns Hopkins` for this name.".to_owned(),
            priority: 31,
        })
    }

    fn description(&self) -> &'static str {
        "Recommends the proper spelling `Johns Hopkins`."
    }
}

#[cfg(test)]
mod tests {
    use super::JohnsHopkins;
    use crate::linting::tests::{assert_lint_count, assert_suggestion_result};

    #[test]
    fn corrects_university_reference() {
        assert_suggestion_result(
            "I applied to John Hopkins University last fall.",
            JohnsHopkins::default(),
            "I applied to Johns Hopkins University last fall.",
        );
    }

    #[test]
    fn corrects_hospital_reference() {
        assert_suggestion_result(
            "She works at the John Hopkins hospital.",
            JohnsHopkins::default(),
            "She works at the Johns Hopkins hospital.",
        );
    }

    #[test]
    fn corrects_standalone_name() {
        assert_suggestion_result(
            "We toured John Hopkins yesterday.",
            JohnsHopkins::default(),
            "We toured Johns Hopkins yesterday.",
        );
    }

    #[test]
    fn corrects_lowercase_usage() {
        assert_suggestion_result(
            "I studied at john hopkins online.",
            JohnsHopkins::default(),
            "I studied at johns hopkins online.",
        );
    }

    #[test]
    fn corrects_across_newline_whitespace() {
        assert_suggestion_result(
            "We met at John\nHopkins for lunch.",
            JohnsHopkins::default(),
            "We met at Johns\nHopkins for lunch.",
        );
    }

    #[test]
    fn corrects_with_trailing_punctuation() {
        assert_suggestion_result(
            "I toured John Hopkins, and it was great.",
            JohnsHopkins::default(),
            "I toured Johns Hopkins, and it was great.",
        );
    }

    #[test]
    fn corrects_before_hyphenated_unit() {
        assert_suggestion_result(
            "She joined the John Hopkins-affiliated lab.",
            JohnsHopkins::default(),
            "She joined the Johns Hopkins-affiliated lab.",
        );
    }

    #[test]
    fn allows_correct_spelling() {
        assert_lint_count(
            "Johns Hopkins University has a great program.",
            JohnsHopkins::default(),
            0,
        );
    }

    #[test]
    fn allows_apostrophized_form() {
        assert_lint_count(
            "John Hopkins's novel won awards.",
            JohnsHopkins::default(),
            0,
        );
    }

    #[test]
    fn allows_reversed_name_order() {
        assert_lint_count("Hopkins, John is a contact.", JohnsHopkins::default(), 0);
    }
}



================================================
FILE: harper-core/src/linting/left_right_hand.rs
================================================
use crate::expr::Expr;
use crate::expr::SequenceExpr;
use crate::{Token, patterns::WordSet};

use super::{ExprLinter, Lint, LintKind, Suggestion};
use crate::linting::expr_linter::Chunk;

pub struct LeftRightHand {
    expr: Box<dyn Expr>,
}

impl Default for LeftRightHand {
    fn default() -> Self {
        let pattern = SequenceExpr::default()
            .then(WordSet::new(&["left", "right"]))
            .then_whitespace()
            .t_aco("hand")
            .then_whitespace()
            .then_noun();

        Self {
            expr: Box::new(pattern),
        }
    }
}

impl ExprLinter for LeftRightHand {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], _source: &[char]) -> Option<Lint> {
        let space = &matched_tokens[1];

        Some(Lint {
            span: space.span,
            lint_kind: LintKind::Miscellaneous,
            suggestions: vec![Suggestion::ReplaceWith(vec!['-'])],
            message: "Use a hyphen in `left-hand` or `right-hand` when modifying a noun."
                .to_owned(),
            priority: 31,
        })
    }

    fn description(&self) -> &'static str {
        "Ensures `left hand` and `right hand` are hyphenated when used as adjectives before a noun, such as in `left-hand side` or `right-hand corner`."
    }
}

#[cfg(test)]
mod tests {
    use super::LeftRightHand;
    use crate::linting::tests::assert_suggestion_result;

    #[test]
    fn corrects_left_hand_side() {
        assert_suggestion_result(
            "You'll see it on the left hand side.",
            LeftRightHand::default(),
            "You'll see it on the left-hand side.",
        );
    }

    #[test]
    fn corrects_right_hand_corner() {
        assert_suggestion_result(
            "It's in the right hand corner.",
            LeftRightHand::default(),
            "It's in the right-hand corner.",
        );
    }

    #[test]
    fn does_not_correct_noun_usage() {
        assert_suggestion_result(
            "She raised her right hand.",
            LeftRightHand::default(),
            "She raised her right hand.",
        );
    }
}



================================================
FILE: harper-core/src/linting/less_worse.rs
================================================
use crate::expr::{Expr, SequenceExpr, SpaceOrHyphen};
use crate::patterns::WordSet;
use crate::{CharStringExt, Token, TokenStringExt};

use super::{ExprLinter, Lint, LintKind, Suggestion};
use crate::linting::expr_linter::Chunk;

pub struct LessWorse {
    expr: Box<dyn Expr>,
}

impl Default for LessWorse {
    fn default() -> Self {
        Self {
            expr: Box::new(
                SequenceExpr::default()
                    .then(WordSet::new(&["less", "least"]))
                    .then(SpaceOrHyphen)
                    .then(WordSet::new(&["worse", "worst"])),
            ),
        }
    }
}

impl ExprLinter for LessWorse {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, toks: &[Token], src: &[char]) -> Option<Lint> {
        if toks.len() != 3 {
            return None;
        }

        let span = toks.span()?;

        let how_little = toks[0].span.get_content(src).to_lower();
        let space_or_hyphen = &toks[1];
        let how_bad = toks[2].span.get_content(src).to_lower();

        let (suggestions, message): (&[&[char]], &str) = match (
            how_little.as_ref(),
            space_or_hyphen.kind.is_hyphen(),
            how_bad.as_ref(),
        ) {
            // "Least worst": Not standard or grammatical but idiomatic and popular.
            (['l', 'e', 'a', 's', 't'], false, ['w', 'o', 'r', 's', 't']) => (
                &[&['l', 'e', 'a', 's', 't', ' ', 'b', 'a', 'd']],
                "Though `least worst` is a common idiom, `least bad` is the standard way to compare bad options.",
            ),
            // "Least-worst": As above but also the hyphen is incorrect.
            (['l', 'e', 'a', 's', 't'], true, ['w', 'o', 'r', 's', 't']) => (
                &[
                    &['l', 'e', 'a', 's', 't', ' ', 'w', 'o', 'r', 's', 't'],
                    &['l', 'e', 'a', 's', 't', ' ', 'b', 'a', 'd'],
                ],
                "`Least worst` (without the hyphen) is a common idiom, but `least bad` is the standard way to compare bad options.",
            ),
            // About 1/3 as common as "least worst" so less acceptable as an idiom.
            (['l', 'e', 's', 's'], _, ['w', 'o', 'r', 's', 'e']) => (
                &[&['l', 'e', 's', 's', ' ', 'b', 'a', 'd']],
                "The standard way to compare bad options is `less bad`.",
            ),
            // Ambiguous. Is it supposed to be comparative or superlative?
            (['l', 'e', 's', 's'], _, ['w', 'o', 'r', 's', 't']) => (
                &[
                    &['l', 'e', 's', 's', ' ', 'b', 'a', 'd'],
                    &['l', 'e', 'a', 's', 't', ' ', 'b', 'a', 'd'],
                ],
                "These words conflict with each other. Choose `less bad` or `least bad`.",
            ),
            // Ambiguous. Probably a non-native speaker that means "least worst", but offer all three options.
            (['l', 'e', 'a', 's', 't'], _, ['w', 'o', 'r', 's', 'e']) => (
                &[
                    &['l', 'e', 'a', 's', 't', ' ', 'w', 'o', 'r', 's', 't'],
                    &['l', 'e', 'a', 's', 't', ' ', 'b', 'a', 'd'],
                    &['l', 'e', 's', 's', ' ', 'b', 'a', 'd'],
                ],
                "These words conflict with each other. Choose `less bad` or `least bad` for more standard English, or `least worst` for more idiomatic English.",
            ),
            _ => return None,
        };

        let template = span.get_content(src);

        Some(Lint {
            span,
            lint_kind: LintKind::WordChoice,
            suggestions: suggestions
                .iter()
                .map(|s| Suggestion::replace_with_match_case(s.to_vec(), template))
                .collect::<Vec<_>>(),
            message: message.to_string(),
            priority: 126,
        })
    }

    fn description(&self) -> &'static str {
        "Suggests alternatives to `less/least worse/worst` for more standard, clearer comparisons."
    }
}

#[cfg(test)]
mod tests {
    use crate::linting::tests::{assert_good_and_bad_suggestions, assert_top3_suggestion_result};

    use super::LessWorse;

    #[test]
    fn correct_least_worse() {
        assert_good_and_bad_suggestions(
            "Maybe downstream packaging folks could advice what would be least worse option.",
            LessWorse::default(),
            &[
                "Maybe downstream packaging folks could advice what would be least worst option.",
                "Maybe downstream packaging folks could advice what would be least bad option.",
                "Maybe downstream packaging folks could advice what would be less bad option.",
            ],
            &[],
        );
    }

    #[test]
    fn correct_least_worst_hyphen() {
        assert_good_and_bad_suggestions(
            "async-dropper is probably the least-worst ad-hoc AsyncDrop implementation you've seen.",
            LessWorse::default(),
            &[
                "async-dropper is probably the least worst ad-hoc AsyncDrop implementation you've seen.",
                "async-dropper is probably the least bad ad-hoc AsyncDrop implementation you've seen.",
            ],
            &[],
        );
    }

    #[test]
    fn correct_less_worse() {
        assert_top3_suggestion_result(
            "Professionally I've convinced the team at @Roave to pay me for making their PHP code marginally less worse.",
            LessWorse::default(),
            "Professionally I've convinced the team at @Roave to pay me for making their PHP code marginally less bad.",
        );
    }

    #[test]
    fn correct_less_worst() {
        assert_good_and_bad_suggestions(
            "May be the less worst choice for some little playlists.",
            LessWorse::default(),
            &[
                "May be the less bad choice for some little playlists.",
                "May be the least bad choice for some little playlists.",
            ],
            &[],
        );
    }
}



================================================
FILE: harper-core/src/linting/let_to_do.rs
================================================
use crate::Token;
use crate::expr::{Expr, SequenceExpr};
use crate::linting::{LintKind, Suggestion};
use crate::token_string_ext::TokenStringExt;

use super::{ExprLinter, Lint};
use crate::linting::expr_linter::Chunk;

pub struct LetToDo {
    expr: Box<dyn Expr>,
}

impl Default for LetToDo {
    fn default() -> Self {
        Self {
            expr: Box::new(
                SequenceExpr::default()
                    .then_word_set(&["let", "lets", "let's"])
                    .t_ws()
                    .then_any_of(vec![
                        Box::new(SequenceExpr::default().then_object_pronoun()),
                        Box::new(SequenceExpr::word_set(&[
                            // Elective existential indefinite pronouns
                            "anybody",
                            "anyone",
                            // Universal indefinite pronouns
                            "everybody",
                            "everyone",
                            // Negative indefinite pronouns (correct)
                            "nobody",
                            // Negative indefinite pronouns (incorrect)
                            "noone",
                            // Assertive existential indefinite pronouns
                            "somebody",
                            "someone",
                        ])),
                        Box::new(
                            SequenceExpr::word_set(&["any", "every", "no", "some"])
                                .t_ws()
                                .then_word_set(&["body", "one"]),
                        ),
                    ])
                    .t_ws()
                    .t_aco("to"),
            ),
        }
    }
}

impl ExprLinter for LetToDo {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, toks: &[Token], _src: &[char]) -> Option<Lint> {
        Some(Lint {
            span: toks[toks.len() - 2..].span()?,
            lint_kind: LintKind::Usage,
            suggestions: vec![Suggestion::Remove],
            message: "The word `to` should not be used with `let` in this way.".to_string(),
            ..Default::default()
        })
    }

    fn description(&self) -> &'static str {
        "Corrects extraneous `to` after `let`."
    }
}

#[cfg(test)]
mod tests {
    use super::LetToDo;
    use crate::linting::tests::assert_suggestion_result;

    // let

    #[test]
    fn let_me_to() {
        assert_suggestion_result(
            "Let me to decide show player controls or not",
            LetToDo::default(),
            "Let me decide show player controls or not",
        );
    }

    #[test]
    fn let_you_to() {
        assert_suggestion_result(
            "Azure provider does not let you to ask for approval",
            LetToDo::default(),
            "Azure provider does not let you ask for approval",
        );
    }

    #[test]
    fn let_us_to() {
        assert_suggestion_result(
            "Currently JavaScript syntax does not let us to pick one or more properties from an object",
            LetToDo::default(),
            "Currently JavaScript syntax does not let us pick one or more properties from an object",
        );
    }

    #[test]
    fn let_it_to() {
        assert_suggestion_result(
            "I modified the load_checkpoints and let it to only load the autoencoder's checkpoint.",
            LetToDo::default(),
            "I modified the load_checkpoints and let it only load the autoencoder's checkpoint.",
        );
    }

    #[test]
    fn let_him_to() {
        assert_suggestion_result(
            "let him to delete the information he wrote",
            LetToDo::default(),
            "let him delete the information he wrote",
        );
    }

    #[test]
    fn let_anybody_to() {
        assert_suggestion_result(
            "but at least will not let anybody to sub from tls as far as i understood this properly",
            LetToDo::default(),
            "but at least will not let anybody sub from tls as far as i understood this properly",
        );
    }

    #[test]
    fn let_anyone_to() {
        assert_suggestion_result(
            "How would you let anyone to help you?",
            LetToDo::default(),
            "How would you let anyone help you?",
        );
    }

    #[test]
    fn let_any_one_to() {
        assert_suggestion_result(
            "set up a mcp server to let any one to query how to use the api in the repo",
            LetToDo::default(),
            "set up a mcp server to let any one query how to use the api in the repo",
        );
    }

    #[test]
    fn let_everybody_to() {
        assert_suggestion_result(
            "on a project that let everybody to create things",
            LetToDo::default(),
            "on a project that let everybody create things",
        );
    }

    #[test]
    fn let_everyone_to() {
        assert_suggestion_result(
            "We want to let everyone to be able to select between the servers we have right now",
            LetToDo::default(),
            "We want to let everyone be able to select between the servers we have right now",
        );
    }

    #[test]
    fn let_every_one_to() {
        assert_suggestion_result(
            "you SHOULDN'T DO THIS because you let every one to upload an executable",
            LetToDo::default(),
            "you SHOULDN'T DO THIS because you let every one upload an executable",
        );
    }

    #[test]
    fn let_nobody_to() {
        assert_suggestion_result(
            "i wouldn't let nobody to snoop on user's data",
            LetToDo::default(),
            "i wouldn't let nobody snoop on user's data",
        );
    }

    #[test]
    fn let_no_one_to() {
        assert_suggestion_result(
            "hide video download link in wordpress - let no one to see video download link",
            LetToDo::default(),
            "hide video download link in wordpress - let no one see video download link",
        );
    }

    #[test]
    fn let_somebody_to() {
        assert_suggestion_result(
            "So it should be the same let somebody to make required for reviewers.",
            LetToDo::default(),
            "So it should be the same let somebody make required for reviewers.",
        );
    }

    #[test]
    fn let_some_one_to() {
        assert_suggestion_result(
            "let some one to help me who can do it",
            LetToDo::default(),
            "let some one help me who can do it",
        );
    }

    // lets

    #[test]
    fn lets_me_to() {
        assert_suggestion_result(
            "Also, clicking on the gear lets me to put login credentials",
            LetToDo::default(),
            "Also, clicking on the gear lets me put login credentials",
        );
    }

    #[test]
    fn lets_you_to() {
        assert_suggestion_result(
            "A chrome extension which lets you to create your own customised text snippets and use in your browser.",
            LetToDo::default(),
            "A chrome extension which lets you create your own customised text snippets and use in your browser.",
        );
    }

    #[test]
    fn lets_us_to() {
        assert_suggestion_result(
            "A menu which lets us to get money",
            LetToDo::default(),
            "A menu which lets us get money",
        );
    }

    #[test]
    fn lets_anyone_to() {
        assert_suggestion_result(
            "fake ssh server that lets anyone to connect and monitor their activty",
            LetToDo::default(),
            "fake ssh server that lets anyone connect and monitor their activty",
        );
    }

    #[test]
    fn lets_everybody_to() {
        assert_suggestion_result(
            "Use set.seed function which lets everybody to check your result on their computers.",
            LetToDo::default(),
            "Use set.seed function which lets everybody check your result on their computers.",
        );
    }

    #[test]
    fn lets_everyone_to() {
        assert_suggestion_result(
            "what lets everyone to know what to expect",
            LetToDo::default(),
            "what lets everyone know what to expect",
        );
    }

    #[test]
    fn lets_someone_to() {
        assert_suggestion_result(
            "it works correctly and lets someone to connect using telnet",
            LetToDo::default(),
            "it works correctly and lets someone connect using telnet",
        );
    }

    // erroneous let's

    #[test]
    fn lets_me_to_apostrophe() {
        assert_suggestion_result(
            "I need be able to clone receiver, which crossbeam let's me to do.",
            LetToDo::default(),
            "I need be able to clone receiver, which crossbeam let's me do.",
        );
    }

    #[test]
    fn lets_us_to_apostrophe() {
        assert_suggestion_result(
            "this option let's us to cut the whole project in smaller pieces, like time based sprites.",
            LetToDo::default(),
            "this option let's us cut the whole project in smaller pieces, like time based sprites.",
        );
    }

    #[test]
    fn lets_you_to_apostrophe() {
        assert_suggestion_result(
            "Let's you to migrate/transfer save files from older outward versions to outward definitive edition.",
            LetToDo::default(),
            "Let's you migrate/transfer save files from older outward versions to outward definitive edition.",
        );
    }

    #[test]
    fn lets_him_to_apostrophe() {
        assert_suggestion_result(
            "A good woman gives wings to a man and let's him to take on the whole world",
            LetToDo::default(),
            "A good woman gives wings to a man and let's him take on the whole world",
        );
    }

    #[test]
    fn lets_her_to_apostrophe() {
        assert_suggestion_result(
            "if Igor let's her to be with Wonder she would crush everyone",
            LetToDo::default(),
            "if Igor let's her be with Wonder she would crush everyone",
        );
    }

    #[test]
    fn lets_it_to_apostrophe() {
        assert_suggestion_result(
            "It's as accurate as your GPS let's it to be.",
            LetToDo::default(),
            "It's as accurate as your GPS let's it be.",
        );
    }

    #[test]
    fn lets_them_to_apostrophe() {
        assert_suggestion_result(
            "it does not cut the dataset into 2 separate subsets in each step but let's them to get predictions from both branches",
            LetToDo::default(),
            "it does not cut the dataset into 2 separate subsets in each step but let's them get predictions from both branches",
        );
    }

    #[test]
    fn lets_anyone_to_apostrophe() {
        assert_suggestion_result(
            "It let's anyone to discover, take, or even teach a class.",
            LetToDo::default(),
            "It let's anyone discover, take, or even teach a class.",
        );
    }

    #[test]
    fn lets_any_one_to_apostrophe() {
        assert_suggestion_result(
            "Whyyyy hashmeet let's any one to create their own tinder like swipe clubs or groups?",
            LetToDo::default(),
            "Whyyyy hashmeet let's any one create their own tinder like swipe clubs or groups?",
        );
    }

    #[test]
    fn lets_everyone_to_apostrophe() {
        assert_suggestion_result(
            "How do you feel that America let's everyone to have guns",
            LetToDo::default(),
            "How do you feel that America let's everyone have guns",
        );
    }

    #[test]
    fn lets_someone_to_apostrophe() {
        assert_suggestion_result(
            "Commands and attributes let's someone to compare it with other TRV",
            LetToDo::default(),
            "Commands and attributes let's someone compare it with other TRV",
        );
    }
}



================================================
FILE: harper-core/src/linting/likewise.rs
================================================
use crate::expr::All;
use crate::expr::Expr;
use crate::expr::SequenceExpr;
use crate::{Token, TokenStringExt};

use super::{ExprLinter, Lint, LintKind, Suggestion};
use crate::linting::expr_linter::Chunk;

pub struct Likewise {
    expr: Box<dyn Expr>,
}
impl Default for Likewise {
    fn default() -> Self {
        let mut expr = All::default();

        expr.add(SequenceExpr::aco("like").then_whitespace().t_aco("wise"));
        expr.add(
            SequenceExpr::default().then_unless(
                SequenceExpr::anything()
                    .then_whitespace()
                    .then_anything()
                    .then_whitespace()
                    .then_noun(),
            ),
        );

        Self {
            expr: Box::new(expr),
        }
    }
}
impl ExprLinter for Likewise {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }
    fn match_to_lint(&self, matched_tokens: &[Token], source: &[char]) -> Option<Lint> {
        let span = matched_tokens.span()?;
        let orig_chars = span.get_content(source);
        Some(Lint {
            span,
            lint_kind: LintKind::WordChoice,
            suggestions: vec![Suggestion::replace_with_match_case(
                "likewise".chars().collect(),
                orig_chars,
            )],
            message: format!("Did you mean the closed compound `{}`?", "likewise"),
            ..Default::default()
        })
    }
    fn description(&self) -> &'static str {
        "Looks for incorrect spacing inside the closed compound `likewise`."
    }
}

#[cfg(test)]
mod tests {
    use crate::linting::tests::assert_suggestion_result;

    use super::Likewise;

    #[test]
    fn wise_men() {
        assert_suggestion_result(
            "Like wise men, we waited.",
            Likewise::default(),
            "Like wise men, we waited.",
        );
    }

    #[test]
    fn like_wise() {
        assert_suggestion_result(
            "He acted, like wise, without hesitation.",
            Likewise::default(),
            "He acted, likewise, without hesitation.",
        );
    }
}



================================================
FILE: harper-core/src/linting/lint.rs
================================================
use std::hash::{DefaultHasher, Hash, Hasher};

use serde::{Deserialize, Serialize};

use crate::{Span, render_markdown::render_markdown};

use super::{LintKind, Suggestion};

/// An error found in text.
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
pub struct Lint {
    /// The location in the source text the error lies.
    /// Important for automatic lint resolution through [`Self::suggestions`].
    pub span: Span<char>,
    /// The general category the lint belongs to.
    /// Mostly used for UI elements in integrations.
    pub lint_kind: LintKind,
    /// A list of zero or more suggested edits that would resolve the underlying problem.
    /// See [`Suggestion`].
    pub suggestions: Vec<Suggestion>,
    /// A message to be displayed to the user describing the specific error found.
    ///
    /// You may use the [`format`] macro to generate more complex messages.
    pub message: String,
    /// A numerical value for the importance of a lint.
    /// Lower = more important.
    pub priority: u8,
}

impl Lint {
    /// Creates a SHA-3 hash of all elements of the lint, sans [`Self::span`].
    /// This is useful for comparing lints while ignoring their position within the document.
    ///
    /// Do not assume that these hash values are stable across Harper versions.
    pub fn spanless_hash(&self) -> u64 {
        let mut hasher = DefaultHasher::new();

        self.lint_kind.hash(&mut hasher);
        self.suggestions.hash(&mut hasher);
        self.message.hash(&mut hasher);
        self.priority.hash(&mut hasher);

        hasher.finish()
    }

    /// Interpret the message as Markdown and render it to HTML.
    pub fn message_html(&self) -> String {
        render_markdown(&self.message)
    }
}

impl Default for Lint {
    fn default() -> Self {
        Self {
            span: Default::default(),
            lint_kind: Default::default(),
            suggestions: Default::default(),
            message: Default::default(),
            priority: 127,
        }
    }
}



================================================
FILE: harper-core/src/linting/lint_group.rs
================================================
use std::collections::BTreeMap;
use std::hash::Hash;
use std::hash::{BuildHasher, Hasher};
use std::mem;
use std::num::NonZero;
use std::sync::Arc;

use cached::proc_macro::cached;
use foldhash::quality::RandomState;
use hashbrown::HashMap;
use lru::LruCache;
use serde::{Deserialize, Deserializer, Serialize, Serializer};

use super::a_part::APart;
use super::a_while::AWhile;
use super::addicting::Addicting;
use super::adjective_double_degree::AdjectiveDoubleDegree;
use super::adjective_of_a::AdjectiveOfA;
use super::after_later::AfterLater;
use super::all_intents_and_purposes::AllIntentsAndPurposes;
use super::allow_to::AllowTo;
use super::am_in_the_morning::AmInTheMorning;
use super::amounts_for::AmountsFor;
use super::an_a::AnA;
use super::and_in::AndIn;
use super::and_the_like::AndTheLike;
use super::another_thing_coming::AnotherThingComing;
use super::another_think_coming::AnotherThinkComing;
use super::apart_from::ApartFrom;
use super::ask_no_preposition::AskNoPreposition;
use super::avoid_curses::AvoidCurses;
use super::back_in_the_day::BackInTheDay;
use super::be_allowed::BeAllowed;
use super::behind_the_scenes::BehindTheScenes;
use super::best_of_all_time::BestOfAllTime;
use super::boring_words::BoringWords;
use super::bought::Bought;
use super::brand_brandish::BrandBrandish;
use super::cant::Cant;
use super::capitalize_personal_pronouns::CapitalizePersonalPronouns;
use super::cautionary_tale::CautionaryTale;
use super::change_tack::ChangeTack;
use super::chock_full::ChockFull;
use super::comma_fixes::CommaFixes;
use super::compound_nouns::CompoundNouns;
use super::compound_subject_i::CompoundSubjectI;
use super::confident::Confident;
use super::correct_number_suffix::CorrectNumberSuffix;
use super::criteria_phenomena::CriteriaPhenomena;
use super::cure_for::CureFor;
use super::currency_placement::CurrencyPlacement;
use super::despite_it_is::DespiteItIs;
use super::despite_of::DespiteOf;
use super::didnt::Didnt;
use super::discourse_markers::DiscourseMarkers;
use super::disjoint_prefixes::DisjointPrefixes;
use super::dot_initialisms::DotInitialisms;
use super::double_click::DoubleClick;
use super::double_modal::DoubleModal;
use super::ellipsis_length::EllipsisLength;
use super::else_possessive::ElsePossessive;
use super::ever_every::EverEvery;
use super::everyday::Everyday;
use super::expand_memory_shorthands::ExpandMemoryShorthands;
use super::expand_time_shorthands::ExpandTimeShorthands;
use super::expr_linter::run_on_chunk;
use super::far_be_it::FarBeIt;
use super::fascinated_by::FascinatedBy;
use super::feel_fell::FeelFell;
use super::few_units_of_time_ago::FewUnitsOfTimeAgo;
use super::filler_words::FillerWords;
use super::find_fine::FindFine;
use super::first_aid_kit::FirstAidKit;
use super::flesh_out_vs_full_fledged::FleshOutVsFullFledged;
use super::for_noun::ForNoun;
use super::free_predicate::FreePredicate;
use super::friend_of_me::FriendOfMe;
use super::go_so_far_as_to::GoSoFarAsTo;
use super::good_at::GoodAt;
use super::handful::Handful;
use super::have_pronoun::HavePronoun;
use super::have_take_a_look::HaveTakeALook;
use super::hedging::Hedging;
use super::hello_greeting::HelloGreeting;
use super::hereby::Hereby;
use super::hop_hope::HopHope;
use super::how_to::HowTo;
use super::hyphenate_number_day::HyphenateNumberDay;
use super::i_am_agreement::IAmAgreement;
use super::if_wouldve::IfWouldve;
use super::in_on_the_cards::InOnTheCards;
use super::inflected_verb_after_to::InflectedVerbAfterTo;
use super::interested_in::InterestedIn;
use super::it_looks_like_that::ItLooksLikeThat;
use super::its_contraction::ItsContraction;
use super::its_possessive::ItsPossessive;
use super::jealous_of::JealousOf;
use super::johns_hopkins::JohnsHopkins;
use super::left_right_hand::LeftRightHand;
use super::less_worse::LessWorse;
use super::let_to_do::LetToDo;
use super::lets_confusion::LetsConfusion;
use super::likewise::Likewise;
use super::long_sentences::LongSentences;
use super::looking_forward_to::LookingForwardTo;
use super::mass_nouns::MassNouns;
use super::merge_words::MergeWords;
use super::missing_preposition::MissingPreposition;
use super::missing_to::MissingTo;
use super::misspell::Misspell;
use super::mixed_bag::MixedBag;
use super::modal_be_adjective::ModalBeAdjective;
use super::modal_of::ModalOf;
use super::modal_seem::ModalSeem;
use super::months::Months;
use super::more_adjective::MoreAdjective;
use super::more_better::MoreBetter;
use super::most_number::MostNumber;
use super::most_of_the_times::MostOfTheTimes;
use super::multiple_sequential_pronouns::MultipleSequentialPronouns;
use super::nail_on_the_head::NailOnTheHead;
use super::need_to_noun::NeedToNoun;
use super::no_french_spaces::NoFrenchSpaces;
use super::no_match_for::NoMatchFor;
use super::no_oxford_comma::NoOxfordComma;
use super::nobody::Nobody;
use super::nominal_wants::NominalWants;
use super::nor_modal_pronoun::NorModalPronoun;
use super::noun_verb_confusion::NounVerbConfusion;
use super::number_suffix_capitalization::NumberSuffixCapitalization;
use super::obsess_preposition::ObsessPreposition;
use super::of_course::OfCourse;
use super::oldest_in_the_book::OldestInTheBook;
use super::on_floor::OnFloor;
use super::once_or_twice::OnceOrTwice;
use super::one_and_the_same::OneAndTheSame;
use super::one_of_the_singular::OneOfTheSingular;
use super::open_the_light::OpenTheLight;
use super::orthographic_consistency::OrthographicConsistency;
use super::ought_to_be::OughtToBe;
use super::out_of_date::OutOfDate;
use super::oxford_comma::OxfordComma;
use super::oxymorons::Oxymorons;
use super::phrasal_verb_as_compound_noun::PhrasalVerbAsCompoundNoun;
use super::pique_interest::PiqueInterest;
use super::plural_wrong_word_of_phrase::PluralWrongWordOfPhrase;
use super::possessive_noun::PossessiveNoun;
use super::possessive_your::PossessiveYour;
use super::progressive_needs_be::ProgressiveNeedsBe;
use super::pronoun_are::PronounAre;
use super::pronoun_contraction::PronounContraction;
use super::pronoun_inflection_be::PronounInflectionBe;
use super::pronoun_knew::PronounKnew;
use super::pronoun_verb_agreement::PronounVerbAgreement;
use super::proper_noun_capitalization_linters;
use super::quantifier_needs_of::QuantifierNeedsOf;
use super::quantifier_numeral_conflict::QuantifierNumeralConflict;
use super::quite_quiet::QuiteQuiet;
use super::quote_spacing::QuoteSpacing;
use super::redundant_acronyms::RedundantAcronyms;
use super::redundant_additive_adverbs::RedundantAdditiveAdverbs;
use super::regionalisms::Regionalisms;
use super::repeated_words::RepeatedWords;
use super::respond::Respond;
use super::right_click::RightClick;
use super::roller_skated::RollerSkated;
use super::safe_to_save::SafeToSave;
use super::save_to_safe::SaveToSafe;
use super::semicolon_apostrophe::SemicolonApostrophe;
use super::sentence_capitalization::SentenceCapitalization;
use super::shoot_oneself_in_the_foot::ShootOneselfInTheFoot;
use super::simple_past_to_past_participle::SimplePastToPastParticiple;
use super::since_duration::SinceDuration;
use super::single_be::SingleBe;
use super::some_without_article::SomeWithoutArticle;
use super::something_is::SomethingIs;
use super::somewhat_something::SomewhatSomething;
use super::soon_to_be::SoonToBe;
use super::sought_after::SoughtAfter;
use super::spaces::Spaces;
use super::spell_check::SpellCheck;
use super::spelled_numbers::SpelledNumbers;
use super::split_words::SplitWords;
use super::subject_pronoun::SubjectPronoun;
use super::take_a_look_to::TakeALookTo;
use super::take_medicine::TakeMedicine;
use super::that_than::ThatThan;
use super::that_which::ThatWhich;
use super::the_how_why::TheHowWhy;
use super::the_my::TheMy;
use super::the_proper_noun_possessive::TheProperNounPossessive;
use super::then_than::ThenThan;
use super::theres::Theres;
use super::theses_these::ThesesThese;
use super::thing_think::ThingThink;
use super::this_type_of_thing::ThisTypeOfThing;
use super::though_thought::ThoughThought;
use super::throw_away::ThrowAway;
use super::throw_rubbish::ThrowRubbish;
use super::to_adverb::ToAdverb;
use super::to_two_too::ToTwoToo;
use super::touristic::Touristic;
use super::transposed_space::TransposedSpace;
use super::try_ones_hand_at::TryOnesHandAt;
use super::unclosed_quotes::UnclosedQuotes;
use super::update_place_names::UpdatePlaceNames;
use super::use_title_case::UseTitleCase;
use super::verb_to_adjective::VerbToAdjective;
use super::very_unique::VeryUnique;
use super::vice_versa::ViceVersa;
use super::vicious_loop::ViciousCircle;
use super::vicious_loop::ViciousCircleOrCycle;
use super::vicious_loop::ViciousCycle;
use super::was_aloud::WasAloud;
use super::way_too_adjective::WayTooAdjective;
use super::well_educated::WellEducated;
use super::whereas::Whereas;
use super::whom_subject_of_verb::WhomSubjectOfVerb;
use super::widely_accepted::WidelyAccepted;
use super::win_prize::WinPrize;
use super::wish_could::WishCould;
use super::wordpress_dotcom::WordPressDotcom;
use super::would_never_have::WouldNeverHave;
use super::{ExprLinter, Lint};
use super::{HtmlDescriptionLinter, Linter};
use crate::linting::dashes::Dashes;
use crate::linting::expr_linter::Chunk;
use crate::linting::open_compounds::OpenCompounds;
use crate::linting::{closed_compounds, initialisms, phrase_set_corrections, weir_rules};
use crate::spell::{Dictionary, MutableDictionary};
use crate::{CharString, Dialect, Document, TokenStringExt};

fn ser_ordered<S>(map: &HashMap<String, Option<bool>>, ser: S) -> Result<S::Ok, S::Error>
where
    S: Serializer,
{
    let ordered: BTreeMap<_, _> = map.iter().map(|(k, v)| (k.clone(), *v)).collect();
    ordered.serialize(ser)
}

fn de_hashbrown<'de, D>(de: D) -> Result<HashMap<String, Option<bool>>, D::Error>
where
    D: Deserializer<'de>,
{
    let ordered: BTreeMap<String, Option<bool>> = BTreeMap::deserialize(de)?;
    Ok(ordered.into_iter().collect())
}

/// The configuration for a [`LintGroup`].
/// Each child linter can be enabled, disabled, or set to a curated value.
#[derive(Debug, Serialize, Deserialize, Default, Clone, PartialEq, Eq)]
#[serde(transparent)]
pub struct LintGroupConfig {
    /// We do this shenanigans with the [`BTreeMap`] to keep the serialized format consistent.
    #[serde(serialize_with = "ser_ordered", deserialize_with = "de_hashbrown")]
    inner: HashMap<String, Option<bool>>,
}

#[cached]
fn curated_config() -> LintGroupConfig {
    // The Dictionary and Dialect do not matter, we're just after the config.
    let group = LintGroup::new_curated(MutableDictionary::new().into(), Dialect::American);
    group.config
}

impl LintGroupConfig {
    /// Check if a rule exists in the configuration.
    pub fn has_rule(&self, key: impl AsRef<str>) -> bool {
        self.inner.contains_key(key.as_ref())
    }

    pub fn set_rule_enabled(&mut self, key: impl ToString, val: bool) {
        self.inner.insert(key.to_string(), Some(val));
    }

    /// Remove any configuration attached to a rule.
    /// This allows it to assume its default (curated) state.
    pub fn unset_rule_enabled(&mut self, key: impl AsRef<str>) {
        self.inner.remove(key.as_ref());
    }

    pub fn set_rule_enabled_if_unset(&mut self, key: impl AsRef<str>, val: bool) {
        if !self.inner.contains_key(key.as_ref()) {
            self.set_rule_enabled(key.as_ref().to_string(), val);
        }
    }

    pub fn is_rule_enabled(&self, key: &str) -> bool {
        self.inner.get(key).cloned().flatten().unwrap_or(false)
    }

    /// Clear all config options.
    /// This will reset them all to disable them.
    pub fn clear(&mut self) {
        for val in self.inner.values_mut() {
            *val = None
        }
    }

    /// Merge the contents of another [`LintGroupConfig`] into this one.
    /// The other config will be left empty after this operation.
    ///
    /// Conflicting keys will be overridden by the value in the other group.
    pub fn merge_from(&mut self, other: &mut LintGroupConfig) {
        for (key, val) in other.inner.iter() {
            if val.is_none() {
                continue;
            }

            self.inner.insert(key.to_string(), *val);
        }

        other.clear();
    }

    /// Fill the group with the values for the curated lint group.
    pub fn fill_with_curated(&mut self) {
        let mut temp = Self::new_curated();
        mem::swap(self, &mut temp);
        self.merge_from(&mut temp);
    }

    pub fn new_curated() -> Self {
        curated_config()
    }
}

impl Hash for LintGroupConfig {
    fn hash<H: Hasher>(&self, hasher: &mut H) {
        for (key, value) in &self.inner {
            hasher.write(key.as_bytes());
            if let Some(value) = value {
                hasher.write_u8(1);
                hasher.write_u8(*value as u8);
            } else {
                // Do it twice so we fill the same number of bytes as the other branch.
                hasher.write_u8(0);
                hasher.write_u8(0);
            }
        }
    }
}

/// A struct for collecting the output of a number of individual [Linter]s.
/// Each child can be toggled via the public, mutable `Self::config` object.
pub struct LintGroup {
    pub config: LintGroupConfig,
    /// We use a binary map here so the ordering is stable.
    linters: BTreeMap<String, Box<dyn Linter>>,
    /// We use a binary map here so the ordering is stable.
    chunk_expr_linters: BTreeMap<String, Box<dyn ExprLinter<Unit = Chunk>>>,
    /// Since [`ExprLinter`]s operate on a chunk-basis, we can store a
    /// mapping of `Chunk -> Lint` and only re-run the expr linters
    /// when a chunk changes.
    ///
    /// Since the expr linter results also depend on the config, we hash it and pass it as part
    /// of the key.
    chunk_expr_cache: LruCache<(CharString, u64), BTreeMap<String, Vec<Lint>>>,
    hasher_builder: RandomState,
}

impl LintGroup {
    // Constructor methods

    pub fn empty() -> Self {
        Self {
            config: LintGroupConfig::default(),
            linters: BTreeMap::new(),
            chunk_expr_linters: BTreeMap::new(),
            chunk_expr_cache: LruCache::new(NonZero::new(1000).unwrap()),
            hasher_builder: RandomState::default(),
        }
    }

    /// Swap out [`Self::config`] with another [`LintGroupConfig`].
    pub fn with_lint_config(mut self, config: LintGroupConfig) -> Self {
        self.config = config;
        self
    }

    pub fn new_curated(dictionary: Arc<impl Dictionary + 'static>, dialect: Dialect) -> Self {
        let mut out = Self::empty();

        /// Add a `Linter` to the group, setting it to be enabled by default.
        macro_rules! insert_struct_rule {
            ($rule:ident, $default_config:expr) => {
                out.add(stringify!($rule), $rule::default());
                out.config
                    .set_rule_enabled(stringify!($rule), $default_config);
            };
        }

        /// Add a chunk-based `ExprLinter` to the group, setting it to be enabled by default.
        /// While you _can_ pass an `ExprLinter` to `insert_struct_rule`, using this macro instead
        /// will allow it to use more aggressive caching strategies.
        macro_rules! insert_expr_rule {
            ($rule:ident, $default_config:expr) => {
                out.add_chunk_expr_linter(stringify!($rule), $rule::default());
                out.config
                    .set_rule_enabled(stringify!($rule), $default_config);
            };
        }

        out.merge_from(&mut weir_rules::lint_group());
        out.merge_from(&mut phrase_set_corrections::lint_group());
        out.merge_from(&mut proper_noun_capitalization_linters::lint_group(
            dictionary.clone(),
        ));
        out.merge_from(&mut closed_compounds::lint_group());
        out.merge_from(&mut initialisms::lint_group());

        // Add all the more complex rules to the group.
        // Please maintain alphabetical order.
        // On *nix you can maintain sort order with `sort -t'(' -k2`
        insert_expr_rule!(APart, true);
        insert_expr_rule!(AWhile, true);
        insert_expr_rule!(Addicting, true);
        insert_expr_rule!(AdjectiveDoubleDegree, true);
        insert_struct_rule!(AdjectiveOfA, true);
        insert_expr_rule!(AfterLater, true);
        insert_expr_rule!(AllIntentsAndPurposes, true);
        insert_expr_rule!(AllowTo, true);
        insert_expr_rule!(AmInTheMorning, true);
        insert_expr_rule!(AmountsFor, true);
        insert_expr_rule!(AndIn, true);
        insert_expr_rule!(AndTheLike, true);
        insert_expr_rule!(AnotherThingComing, true);
        insert_expr_rule!(AnotherThinkComing, false);
        insert_expr_rule!(ApartFrom, true);
        insert_expr_rule!(AskNoPreposition, true);
        insert_expr_rule!(AvoidCurses, true);
        insert_expr_rule!(BackInTheDay, true);
        insert_expr_rule!(BeAllowed, true);
        insert_expr_rule!(BehindTheScenes, true);
        insert_struct_rule!(BestOfAllTime, true);
        insert_expr_rule!(BoringWords, false);
        insert_expr_rule!(Bought, true);
        insert_expr_rule!(BrandBrandish, true);
        insert_expr_rule!(Cant, true);
        insert_struct_rule!(CapitalizePersonalPronouns, true);
        insert_expr_rule!(CautionaryTale, true);
        insert_expr_rule!(ChangeTack, true);
        insert_expr_rule!(ChockFull, true);
        insert_struct_rule!(CommaFixes, true);
        insert_struct_rule!(CompoundNouns, true);
        insert_expr_rule!(CompoundSubjectI, true);
        insert_expr_rule!(Confident, true);
        insert_struct_rule!(CorrectNumberSuffix, true);
        insert_expr_rule!(CriteriaPhenomena, true);
        insert_expr_rule!(CureFor, true);
        insert_struct_rule!(CurrencyPlacement, true);
        insert_expr_rule!(Dashes, true);
        insert_expr_rule!(DespiteItIs, true);
        insert_expr_rule!(DespiteOf, true);
        insert_expr_rule!(Didnt, true);
        insert_struct_rule!(DiscourseMarkers, true);
        insert_expr_rule!(DotInitialisms, true);
        insert_expr_rule!(DoubleClick, true);
        insert_expr_rule!(DoubleModal, true);
        insert_struct_rule!(EllipsisLength, true);
        insert_expr_rule!(ElsePossessive, true);
        insert_expr_rule!(EverEvery, true);
        insert_expr_rule!(Everyday, true);
        insert_expr_rule!(ExpandMemoryShorthands, true);
        insert_expr_rule!(ExpandTimeShorthands, true);
        insert_expr_rule!(FarBeIt, true);
        insert_expr_rule!(FascinatedBy, true);
        insert_expr_rule!(FeelFell, true);
        insert_expr_rule!(FewUnitsOfTimeAgo, true);
        insert_expr_rule!(FillerWords, true);
        insert_struct_rule!(FindFine, true);
        insert_expr_rule!(FirstAidKit, true);
        insert_expr_rule!(FleshOutVsFullFledged, true);
        insert_expr_rule!(ForNoun, true);
        insert_expr_rule!(FreePredicate, true);
        insert_expr_rule!(FriendOfMe, true);
        insert_expr_rule!(GoSoFarAsTo, true);
        insert_expr_rule!(GoodAt, true);
        insert_expr_rule!(Handful, true);
        insert_expr_rule!(HavePronoun, true);
        insert_expr_rule!(Hedging, true);
        insert_expr_rule!(HelloGreeting, true);
        insert_expr_rule!(Hereby, true);
        insert_struct_rule!(HopHope, true);
        insert_expr_rule!(HowTo, true);
        insert_expr_rule!(HyphenateNumberDay, true);
        insert_expr_rule!(IAmAgreement, true);
        insert_expr_rule!(IfWouldve, true);
        insert_expr_rule!(InterestedIn, true);
        insert_expr_rule!(ItLooksLikeThat, true);
        insert_struct_rule!(ItsContraction, true);
        insert_expr_rule!(ItsPossessive, true);
        insert_expr_rule!(JealousOf, true);
        insert_expr_rule!(JohnsHopkins, true);
        insert_expr_rule!(LeftRightHand, true);
        insert_expr_rule!(LessWorse, true);
        insert_expr_rule!(LetToDo, true);
        insert_struct_rule!(LetsConfusion, true);
        insert_expr_rule!(Likewise, true);
        insert_struct_rule!(LongSentences, true);
        insert_expr_rule!(LookingForwardTo, true);
        insert_struct_rule!(MergeWords, true);
        insert_expr_rule!(MissingPreposition, true);
        insert_expr_rule!(MissingTo, true);
        insert_expr_rule!(Misspell, true);
        insert_expr_rule!(MixedBag, true);
        insert_expr_rule!(ModalBeAdjective, true);
        insert_expr_rule!(ModalOf, true);
        insert_expr_rule!(ModalSeem, true);
        insert_expr_rule!(Months, true);
        insert_expr_rule!(MoreBetter, true);
        insert_expr_rule!(MostNumber, true);
        insert_expr_rule!(MostOfTheTimes, true);
        insert_expr_rule!(MultipleSequentialPronouns, true);
        insert_expr_rule!(NailOnTheHead, true);
        insert_expr_rule!(NeedToNoun, true);
        insert_struct_rule!(NoFrenchSpaces, true);
        insert_expr_rule!(NoMatchFor, true);
        insert_struct_rule!(NoOxfordComma, false);
        insert_expr_rule!(Nobody, true);
        insert_expr_rule!(NominalWants, true);
        insert_expr_rule!(NorModalPronoun, true);
        insert_struct_rule!(NounVerbConfusion, true);
        insert_struct_rule!(NumberSuffixCapitalization, true);
        insert_expr_rule!(ObsessPreposition, true);
        insert_expr_rule!(OfCourse, true);
        insert_expr_rule!(OldestInTheBook, true);
        insert_expr_rule!(OnFloor, true);
        insert_expr_rule!(OnceOrTwice, true);
        insert_expr_rule!(OneAndTheSame, true);
        insert_expr_rule!(OpenCompounds, true);
        insert_expr_rule!(OpenTheLight, true);
        insert_expr_rule!(OrthographicConsistency, true);
        insert_expr_rule!(OughtToBe, true);
        insert_expr_rule!(OutOfDate, true);
        insert_struct_rule!(OxfordComma, true);
        insert_expr_rule!(Oxymorons, true);
        insert_struct_rule!(PhrasalVerbAsCompoundNoun, true);
        insert_expr_rule!(PiqueInterest, true);
        insert_expr_rule!(PluralWrongWordOfPhrase, true);
        insert_expr_rule!(PossessiveYour, true);
        insert_expr_rule!(ProgressiveNeedsBe, true);
        insert_expr_rule!(PronounAre, true);
        insert_struct_rule!(PronounContraction, true);
        insert_expr_rule!(PronounInflectionBe, true);
        insert_expr_rule!(PronounKnew, true);
        insert_expr_rule!(QuantifierNeedsOf, true);
        insert_expr_rule!(QuantifierNumeralConflict, true);
        insert_expr_rule!(QuiteQuiet, true);
        insert_struct_rule!(QuoteSpacing, true);
        insert_expr_rule!(RedundantAcronyms, true);
        insert_expr_rule!(RedundantAdditiveAdverbs, true);
        insert_struct_rule!(RepeatedWords, true);
        insert_expr_rule!(Respond, true);
        insert_expr_rule!(RightClick, true);
        insert_expr_rule!(RollerSkated, true);
        insert_expr_rule!(SafeToSave, true);
        insert_expr_rule!(SaveToSafe, true);
        insert_expr_rule!(SemicolonApostrophe, true);
        insert_expr_rule!(ShootOneselfInTheFoot, true);
        insert_expr_rule!(SimplePastToPastParticiple, true);
        insert_expr_rule!(SinceDuration, true);
        insert_expr_rule!(SingleBe, true);
        insert_expr_rule!(SomeWithoutArticle, true);
        insert_expr_rule!(SomethingIs, true);
        insert_expr_rule!(SomewhatSomething, true);
        insert_expr_rule!(SoonToBe, true);
        insert_expr_rule!(SoughtAfter, true);
        insert_struct_rule!(Spaces, true);
        insert_struct_rule!(SpelledNumbers, false);
        insert_expr_rule!(SplitWords, true);
        insert_struct_rule!(SubjectPronoun, true);
        insert_expr_rule!(TakeALookTo, true);
        insert_expr_rule!(TakeMedicine, true);
        insert_expr_rule!(ThatThan, true);
        insert_expr_rule!(ThatWhich, true);
        insert_expr_rule!(TheHowWhy, true);
        insert_expr_rule!(TheMy, true);
        insert_expr_rule!(TheProperNounPossessive, true);
        insert_expr_rule!(ThenThan, true);
        insert_expr_rule!(Theres, true);
        insert_expr_rule!(ThesesThese, true);
        insert_expr_rule!(ThingThink, true);
        insert_expr_rule!(ThisTypeOfThing, true);
        insert_expr_rule!(ThoughThought, true);
        insert_expr_rule!(ThrowAway, true);
        insert_struct_rule!(ThrowRubbish, true);
        insert_expr_rule!(ToAdverb, true);
        insert_struct_rule!(ToTwoToo, true);
        insert_expr_rule!(Touristic, true);
        insert_expr_rule!(TryOnesHandAt, true);
        insert_struct_rule!(UnclosedQuotes, true);
        insert_expr_rule!(UpdatePlaceNames, true);
        insert_expr_rule!(VerbToAdjective, true);
        insert_expr_rule!(VeryUnique, true);
        insert_expr_rule!(ViceVersa, true);
        insert_expr_rule!(ViciousCircle, true);
        insert_expr_rule!(ViciousCircleOrCycle, false);
        insert_expr_rule!(ViciousCycle, false);
        insert_expr_rule!(WasAloud, true);
        insert_expr_rule!(WayTooAdjective, true);
        insert_expr_rule!(WellEducated, true);
        insert_expr_rule!(Whereas, true);
        insert_expr_rule!(WhomSubjectOfVerb, true);
        insert_expr_rule!(WidelyAccepted, true);
        insert_expr_rule!(WinPrize, true);
        insert_expr_rule!(WishCould, true);
        insert_struct_rule!(WordPressDotcom, true);
        insert_expr_rule!(WouldNeverHave, true);

        out.add("SpellCheck", SpellCheck::new(dictionary.clone(), dialect));
        out.config.set_rule_enabled("SpellCheck", true);

        out.add(
            "InflectedVerbAfterTo",
            InflectedVerbAfterTo::new(dictionary.clone()),
        );
        out.config.set_rule_enabled("InflectedVerbAfterTo", true);

        out.add("InOnTheCards", InOnTheCards::new(dialect));
        out.config.set_rule_enabled("InOnTheCards", true);

        out.add(
            "SentenceCapitalization",
            SentenceCapitalization::new(dictionary.clone()),
        );
        out.config.set_rule_enabled("SentenceCapitalization", true);

        out.add("PossessiveNoun", PossessiveNoun::new(dictionary.clone()));
        out.config.set_rule_enabled("PossessiveNoun", false);

        out.add("Regionalisms", Regionalisms::new(dialect));
        out.config.set_rule_enabled("Regionalisms", true);

        out.add("HaveTakeALook", HaveTakeALook::new(dialect));
        out.config.set_rule_enabled("HaveTakeALook", true);

        out.add("MassNouns", MassNouns::new(dictionary.clone()));
        out.config.set_rule_enabled("MassNouns", true);

        out.add("UseTitleCase", UseTitleCase::new(dictionary.clone()));
        out.config.set_rule_enabled("UseTitleCase", true);

        out.add_chunk_expr_linter(
            "DisjointPrefixes",
            DisjointPrefixes::new(dictionary.clone()),
        );
        out.config.set_rule_enabled("DisjointPrefixes", true);

        out.add(
            "PronounVerbAgreement",
            PronounVerbAgreement::new(dictionary.clone()),
        );
        out.config.set_rule_enabled("PronounVerbAgreement", true);

        out.add_chunk_expr_linter("TransposedSpace", TransposedSpace::new(dictionary.clone()));
        out.config.set_rule_enabled("TransposedSpace", true);

        out.add_chunk_expr_linter(
            "OneOfTheSingular",
            OneOfTheSingular::new(dictionary.clone()),
        );
        out.config.set_rule_enabled("OneOfTheSingular", true);

        out.add("AnA", AnA::new(dialect));
        out.config.set_rule_enabled("AnA", true);

        out.add("MoreAdjective", MoreAdjective::new(dictionary.clone()));
        out.config.set_rule_enabled("MoreAdjective", true);

        out
    }

    /// Create a new curated group with all config values cleared out.
    pub fn new_curated_empty_config(
        dictionary: Arc<impl Dictionary + 'static>,
        dialect: Dialect,
    ) -> Self {
        let mut group = Self::new_curated(dictionary, dialect);
        group.config.clear();
        group
    }

    // Non-constructor methods

    /// Check if the group already contains a linter with a given name.
    pub fn contains_key(&self, name: impl AsRef<str>) -> bool {
        self.linters.contains_key(name.as_ref())
            || self.chunk_expr_linters.contains_key(name.as_ref())
    }

    /// Add a [`Linter`] to the group, returning whether the operation was successful.
    /// If it returns `false`, it is because a linter with that key already existed in the group.
    pub fn add(&mut self, name: impl AsRef<str>, linter: impl Linter + 'static) -> bool {
        if self.contains_key(&name) {
            false
        } else {
            self.linters
                .insert(name.as_ref().to_string(), Box::new(linter));
            true
        }
    }

    /// Add a chunk-based [`ExprLinter`] to the group, returning whether the operation was successful.
    /// If it returns `false`, it is because a linter with that key already existed in the group.
    ///
    /// This function is not significantly different from [`Self::add`], but allows us to take
    /// advantage of some properties of chunk-based [`ExprLinter`]s for cache optimization.
    pub fn add_chunk_expr_linter(
        &mut self,
        name: impl AsRef<str>,
        // linter: impl ExprLinter + 'static,
        linter: impl ExprLinter<Unit = Chunk> + 'static,
    ) -> bool {
        if self.contains_key(&name) {
            false
        } else {
            self.chunk_expr_linters
                .insert(name.as_ref().to_string(), Box::new(linter) as _);
            true
        }
    }

    /// Merge the contents of another [`LintGroup`] into this one.
    /// The other lint group will be left empty after this operation.
    pub fn merge_from(&mut self, other: &mut LintGroup) {
        self.config.merge_from(&mut other.config);

        let other_linters = std::mem::take(&mut other.linters);
        self.linters.extend(other_linters);

        let other_expr_linters = std::mem::take(&mut other.chunk_expr_linters);
        self.chunk_expr_linters.extend(other_expr_linters);
    }

    pub fn iter_keys(&self) -> impl Iterator<Item = &str> {
        self.linters
            .keys()
            .chain(self.chunk_expr_linters.keys())
            .map(|v| v.as_str())
    }

    /// Set all contained rules to a specific value.
    /// Passing `None` will unset that rule, allowing it to assume its default state.
    pub fn set_all_rules_to(&mut self, enabled: Option<bool>) {
        let keys = self.iter_keys().map(|v| v.to_string()).collect::<Vec<_>>();

        for key in keys {
            match enabled {
                Some(v) => self.config.set_rule_enabled(key, v),
                None => self.config.unset_rule_enabled(key),
            }
        }
    }

    /// Get map from each contained linter's name to its associated description.
    pub fn all_descriptions(&self) -> HashMap<&str, &str> {
        self.linters
            .iter()
            .map(|(key, value)| (key.as_str(), value.description()))
            .chain(
                self.chunk_expr_linters
                    .iter()
                    .map(|(key, value)| (key.as_str(), ExprLinter::description(value))),
            )
            .collect()
    }

    /// Get map from each contained linter's name to its associated description, rendered to HTML.
    pub fn all_descriptions_html(&self) -> HashMap<&str, String> {
        self.linters
            .iter()
            .map(|(key, value)| (key.as_str(), value.description_html()))
            .chain(
                self.chunk_expr_linters
                    .iter()
                    .map(|(key, value)| (key.as_str(), value.description_html())),
            )
            .collect()
    }

    pub fn organized_lints(&mut self, document: &Document) -> BTreeMap<String, Vec<Lint>> {
        let mut results = BTreeMap::new();

        // Normal linters
        for (key, linter) in &mut self.linters {
            if self.config.is_rule_enabled(key) {
                results.insert(key.clone(), linter.lint(document));
            }
        }

        // Expr linters
        for chunk in document.iter_chunks() {
            let Some(chunk_span) = chunk.span() else {
                continue;
            };

            let chunk_chars = document.get_span_content(&chunk_span);
            let config_hash = self.hasher_builder.hash_one(&self.config);
            let cache_key = (chunk_chars.into(), config_hash);

            let mut chunk_results = if let Some(hit) = self.chunk_expr_cache.get(&cache_key) {
                hit.clone()
            } else {
                let mut pattern_lints = BTreeMap::new();

                for (key, linter) in &mut self.chunk_expr_linters {
                    if self.config.is_rule_enabled(key) {
                        let lints =
                            run_on_chunk(linter, chunk, document.get_source()).map(|mut l| {
                                l.span.pull_by(chunk_span.start);
                                l
                            });

                        pattern_lints.insert(key.clone(), lints.collect());
                    }
                }

                self.chunk_expr_cache.put(cache_key, pattern_lints.clone());
                pattern_lints
            };

            // Bring the spans back into document-space
            for value in chunk_results.values_mut() {
                for lint in value {
                    lint.span.push_by(chunk_span.start);
                }
            }

            for (key, mut vec) in chunk_results {
                results.entry(key).or_default().append(&mut vec);
            }
        }

        results
    }
}

impl Default for LintGroup {
    fn default() -> Self {
        Self::empty()
    }
}

impl Linter for LintGroup {
    fn lint(&mut self, document: &Document) -> Vec<Lint> {
        self.organized_lints(document)
            .into_values()
            .flatten()
            .collect()
    }

    fn description(&self) -> &str {
        "A collection of linters that can be run as one."
    }
}

#[cfg(test)]
mod tests {
    use std::sync::Arc;

    use super::{LintGroup, LintGroupConfig};
    use crate::linting::LintKind;
    use crate::linting::tests::assert_no_lints;
    use crate::spell::{FstDictionary, MutableDictionary};
    use crate::{Dialect, Document, linting::Linter};

    fn test_group() -> LintGroup {
        LintGroup::new_curated(Arc::new(MutableDictionary::curated()), Dialect::American)
    }

    #[test]
    fn clean_interjection() {
        assert_no_lints(
            "Although I only saw the need to interject once, I still saw it.",
            test_group(),
        );
    }

    #[test]
    fn clean_consensus() {
        assert_no_lints("But there is less consensus on this.", test_group());
    }

    #[test]
    fn can_get_all_descriptions() {
        let group =
            LintGroup::new_curated(Arc::new(MutableDictionary::default()), Dialect::American);
        group.all_descriptions();
    }

    #[test]
    fn can_get_all_descriptions_as_html() {
        let group =
            LintGroup::new_curated(Arc::new(MutableDictionary::default()), Dialect::American);
        group.all_descriptions_html();
    }

    #[test]
    fn dont_flag_low_hanging_fruit_msg() {
        assert_no_lints(
            "The standard form is low-hanging fruit with a hyphen and singular form.",
            test_group(),
        );
    }

    #[test]
    fn dont_flag_low_hanging_fruit_desc() {
        assert_no_lints(
            "Corrects nonstandard variants of low-hanging fruit.",
            test_group(),
        );
    }

    /// Tests that no linters' descriptions contain errors handled by other linters.
    ///
    /// This test verifies that the description of each linter (which is written in natural language)
    /// doesn't trigger any other linter's rules, with the exception of certain linters that
    /// suggest mere alternatives rather than flagging actual errors.
    ///
    /// For example, we disable the "MoreAdjective" linter since some comparative and superlative
    /// adjectives can be more awkward than their two-word counterparts, even if technically correct.
    ///
    /// If this test fails, it means either:
    /// 1. A linter's description contains an actual error that should be fixed, or
    /// 2. A linter is being too aggressive in flagging text that is actually correct English
    ///    in the context of another linter's description.
    #[test]
    fn lint_descriptions_are_clean() {
        let lints_to_check = LintGroup::new_curated(FstDictionary::curated(), Dialect::American);

        let enforcer_config = LintGroupConfig::new_curated();
        let mut lints_to_enforce =
            LintGroup::new_curated(FstDictionary::curated(), Dialect::American)
                .with_lint_config(enforcer_config);

        let name_description_pairs: Vec<_> = lints_to_check
            .all_descriptions()
            .into_iter()
            .map(|(n, d)| (n.to_string(), d.to_string()))
            .collect();

        for (lint_name, description) in name_description_pairs {
            let doc = Document::new_markdown_default_curated(&description);
            eprintln!("{lint_name}: {description}");

            let mut lints = lints_to_enforce.lint(&doc);

            // Remove ones related to style
            lints.retain(|l| l.lint_kind != LintKind::Style);

            if !lints.is_empty() {
                dbg!(lints);
                panic!();
            }
        }
    }
}



================================================
FILE: harper-core/src/linting/lint_kind.rs
================================================
use std::fmt::Display;

use is_macro::Is;
use serde::{Deserialize, Serialize};

/// The general category a [`Lint`](super::Lint) falls into.
/// There's no reason not to add a new item here if you are adding a new rule that doesn't fit
/// the existing categories.
#[derive(Debug, Clone, Copy, Serialize, Deserialize, Is, Default, Hash, PartialEq, Eq)]
pub enum LintKind {
    Agreement,
    /// For errors where words are joined or split at the wrong boundaries
    /// (e.g., "each and everyone" vs. "each and every one")
    BoundaryError,
    Capitalization,
    /// For cases where a word or phrase is misused for a similar-sounding word or phrase,
    /// where the incorrect version makes logical sense (e.g., 'egg corn' for 'acorn',
    /// 'on mass' for 'en masse').
    Eggcorn,
    /// For suggesting improvements that enhance clarity or impact without fixing errors
    Enhancement,
    Formatting,
    Grammar,
    /// For cases where a word is mistakenly used for a similar-sounding word with a different meaning
    /// (e.g., 'eluded to' instead of 'alluded to'). Unlike eggcorns, these don't create new meanings.
    Malapropism,
    /// For any other lint that doesn't fit neatly into the other categories
    #[default]
    Miscellaneous,
    Nonstandard,
    /// For issues with punctuation, including hyphenation in compound adjectives
    /// (e.g., "face first" vs. "face-first" when used before a noun)
    Punctuation,
    Readability,
    /// For cases where words duplicate meaning that's already expressed
    /// (e.g., "basic fundamentals" → "fundamentals", "free gift" → "gift")
    Redundancy,
    /// For variations that are standard in some regions or dialects but not others
    Regionalism,
    Repetition,
    /// When your brain doesn't know the right spelling.
    /// This should only be used by linters doing spellcheck on individual words.
    Spelling,
    /// For cases where multiple options are correct but one is preferred for style or clarity,
    /// such as expanding abbreviations in formal writing (e.g., 'min' → 'minimum')
    Style,
    /// When your brain knows the right spelling but your fingers made a mistake.
    /// (e.g., 'can be seem' → 'can be seen')
    Typo,
    /// For conventional word usage and standard collocations
    /// (e.g., 'by accident' vs. 'on accident' in standard English)
    Usage,
    /// For choosing between different words or phrases in a given context
    WordChoice,
}

impl LintKind {
    /// The inverse of [`Self::to_string_key`]
    pub fn from_string_key(s: &str) -> Option<Self> {
        match s {
            "Agreement" => Some(LintKind::Agreement),
            "BoundaryError" => Some(LintKind::BoundaryError),
            "Capitalization" => Some(LintKind::Capitalization),
            "Eggcorn" => Some(LintKind::Eggcorn),
            "Enhancement" => Some(LintKind::Enhancement),
            "Formatting" => Some(LintKind::Formatting),
            "Grammar" => Some(LintKind::Grammar),
            "Malapropism" => Some(LintKind::Malapropism),
            "Miscellaneous" => Some(LintKind::Miscellaneous),
            "Nonstandard" => Some(LintKind::Nonstandard),
            "Punctuation" => Some(LintKind::Punctuation),
            "Readability" => Some(LintKind::Readability),
            "Redundancy" => Some(LintKind::Redundancy),
            "Regionalism" => Some(LintKind::Regionalism),
            "Repetition" => Some(LintKind::Repetition),
            "Spelling" => Some(LintKind::Spelling),
            "Style" => Some(LintKind::Style),
            "Typo" => Some(LintKind::Typo),
            "Usage" => Some(LintKind::Usage),
            "WordChoice" => Some(LintKind::WordChoice),
            _ => None,
        }
    }

    /// Produce a string representation, which can be used as keys in a map or CSS variables.
    pub fn to_string_key(&self) -> String {
        match self {
            LintKind::Agreement => "Agreement",
            LintKind::BoundaryError => "BoundaryError",
            LintKind::Capitalization => "Capitalization",
            LintKind::Eggcorn => "Eggcorn",
            LintKind::Enhancement => "Enhancement",
            LintKind::Formatting => "Formatting",
            LintKind::Grammar => "Grammar",
            LintKind::Malapropism => "Malapropism",
            LintKind::Miscellaneous => "Miscellaneous",
            LintKind::Nonstandard => "Nonstandard",
            LintKind::Punctuation => "Punctuation",
            LintKind::Readability => "Readability",
            LintKind::Redundancy => "Redundancy",
            LintKind::Regionalism => "Regionalism",
            LintKind::Repetition => "Repetition",
            LintKind::Spelling => "Spelling",
            LintKind::Style => "Style",
            LintKind::Typo => "Typo",
            LintKind::Usage => "Usage",
            LintKind::WordChoice => "WordChoice",
        }
        .to_owned()
    }
}

impl Display for LintKind {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        let s = match self {
            LintKind::Agreement => "Agreement",
            LintKind::BoundaryError => "BoundaryError",
            LintKind::Capitalization => "Capitalization",
            LintKind::Eggcorn => "Eggcorn",
            LintKind::Enhancement => "Enhancement",
            LintKind::Formatting => "Formatting",
            LintKind::Grammar => "Grammar",
            LintKind::Malapropism => "Malapropism",
            LintKind::Miscellaneous => "Miscellaneous",
            LintKind::Nonstandard => "Nonstandard",
            LintKind::Punctuation => "Punctuation",
            LintKind::Readability => "Readability",
            LintKind::Redundancy => "Redundancy",
            LintKind::Regionalism => "Regionalism",
            LintKind::Repetition => "Repetition",
            LintKind::Spelling => "Spelling",
            LintKind::Style => "Style",
            LintKind::Typo => "Typo",
            LintKind::Usage => "Usage",
            LintKind::WordChoice => "Word Choice",
        };

        write!(f, "{s}")
    }
}



================================================
FILE: harper-core/src/linting/long_sentences.rs
================================================
use super::{Lint, LintKind, Linter};
use crate::TokenStringExt;
use crate::{Document, Span};

/// Detect and warn that the sentence is too long.
#[derive(Debug, Clone, Copy, Default)]
pub struct LongSentences;

impl Linter for LongSentences {
    fn lint(&mut self, document: &Document) -> Vec<Lint> {
        let mut output = Vec::new();

        for sentence in document.iter_sentences() {
            let word_count = sentence.iter_words().count();

            if word_count > 40 {
                output.push(Lint {
                    span: Span::new(
                        sentence.first_word().unwrap().span.start,
                        sentence.last().unwrap().span.end,
                    ),
                    lint_kind: LintKind::Readability,
                    message: format!("This sentence is {word_count} words long."),
                    ..Default::default()
                })
            }
        }

        output
    }

    fn description(&self) -> &'static str {
        "This rule looks for run-on sentences, which can make your work harder to grok."
    }
}



================================================
FILE: harper-core/src/linting/looking_forward_to.rs
================================================
use hashbrown::HashSet;

use crate::linting::expr_linter::Chunk;
use crate::{
    Token,
    expr::{Expr, FixedPhrase, SequenceExpr},
    linting::{ExprLinter, Lint, LintKind, Suggestion},
};

pub struct LookingForwardTo {
    expr: Box<dyn Expr>,
}

impl Default for LookingForwardTo {
    fn default() -> Self {
        let looking_forward_to = FixedPhrase::from_phrase("looking forward to");

        let pattern = SequenceExpr::default()
            .then(looking_forward_to)
            .t_ws()
            // TODO: update the use the verb with progressive tense function later
            .then_verb();

        Self {
            expr: Box::new(pattern),
        }
    }
}

impl ExprLinter for LookingForwardTo {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], src: &[char]) -> Option<Lint> {
        let span = matched_tokens.last()?.span;
        let verb = matched_tokens.last()?.span.get_content_string(src);
        if verb.ends_with("ing") {
            return None;
        }

        // TODO: create a util function to handle the appending of -ing
        // to verbs, taking into account exceptions and irregular forms.
        let exception_word: HashSet<&str> = [
            // Verbs ending in -ee
            "see",
            "flee",
            "agree",
            "knee",
            "guarantee",
            // Verbs ending in -oe
            "hoe",
            "toe",
            // Verbs ending in -ye or to avoid confusion
            "dye",
            "eye",
            // Irregular/spelling clarification
            "singe",
            "tinge",
        ]
        .iter()
        .cloned()
        .collect();

        let gerund_form: String =
            if verb.to_lowercase().ends_with('e') && !exception_word.contains(verb.as_str()) {
                verb.trim_end_matches('e').to_string() + "ing"
            } else {
                format!("{verb}ing")
            };

        println!("gerund_form: -{gerund_form}- -- verb: -{verb}-");
        Some(Lint {
            span,
            lint_kind: LintKind::WordChoice,
            message: format!(
                "The verb `{verb}` must be in the gerund form (verb + -ing) after 'looking forward to'.",
            ),
            suggestions: vec![Suggestion::replace_with_match_case(
                gerund_form.chars().collect(),
                span.get_content(src),
            )],
            ..Default::default()
        })
    }

    fn description(&self) -> &'static str {
        "This rule identifies instances where the phrase `looking forward to` is followed by a base form verb instead of the required gerund (verb + `-ing` form)."
    }
}

#[cfg(test)]
mod tests {
    use crate::linting::tests::{assert_lint_count, assert_suggestion_result};

    use super::LookingForwardTo;

    #[test]
    fn not_lint_with_correct_verb() {
        assert_suggestion_result(
            "She was looking forward to see the grandchildren again.",
            LookingForwardTo::default(),
            "She was looking forward to seeing the grandchildren again.",
        );
        // assert_lint_count(
        //     "She was looking forward to seeing the grandchildren again.",
        //     LookingForwardTo::default(),
        //     0,
        // );
    }

    #[test]
    fn lint_with_incorrect_verb() {
        assert_suggestion_result(
            "She was looking forward to see the grandchildren again.",
            LookingForwardTo::default(),
            "She was looking forward to seeing the grandchildren again.",
        );
    }

    #[test]
    fn lint_with_incorrect_verb_ending_in_e() {
        assert_suggestion_result(
            "She was looking forward to make the grandchildren happy.",
            LookingForwardTo::default(),
            "She was looking forward to making the grandchildren happy.",
        );
    }

    #[test]
    fn not_lint_with_non_verb() {
        assert_lint_count(
            "She was looking forward to the grandchildren's visit.",
            LookingForwardTo::default(),
            0,
        );
    }
}



================================================
FILE: harper-core/src/linting/map_phrase_linter.rs
================================================
use super::{ExprLinter, Lint, LintKind};
use crate::expr::Expr;
use crate::expr::FixedPhrase;
use crate::expr::LongestMatchOf;
use crate::expr::SimilarToPhrase;
use crate::linting::Suggestion;
use crate::linting::expr_linter::Chunk;
use crate::weir::weir_expr_to_expr;
use crate::{Token, TokenStringExt};

pub struct MapPhraseLinter {
    description: String,
    expr: Box<dyn Expr>,
    correct_forms: Vec<String>,
    message: String,
    lint_kind: LintKind,
}

impl MapPhraseLinter {
    pub fn new(
        expr: Box<dyn Expr>,
        correct_forms: impl IntoIterator<Item = impl ToString>,
        message: impl ToString,
        description: impl ToString,
        lint_kind: Option<LintKind>,
    ) -> Self {
        Self {
            description: description.to_string(),
            expr,
            correct_forms: correct_forms.into_iter().map(|f| f.to_string()).collect(),
            message: message.to_string(),
            lint_kind: lint_kind.unwrap_or(LintKind::Miscellaneous),
        }
    }

    pub fn new_similar_to_phrase(phrase: &'static str, detectable_distance: u8) -> Self {
        Self::new(
            Box::new(SimilarToPhrase::from_phrase(phrase, detectable_distance)),
            [phrase],
            format!("Did you mean the phrase `{phrase}`?"),
            format!("Looks for slight improper modifications to the phrase `{phrase}`."),
            None,
        )
    }

    pub fn new_fixed_phrases(
        phrase: impl IntoIterator<Item = impl AsRef<str>>,
        correct_forms: impl IntoIterator<Item = impl ToString>,
        message: impl ToString,
        description: impl ToString,
        lint_kind: Option<LintKind>,
    ) -> Self {
        let patterns = LongestMatchOf::new(
            phrase
                .into_iter()
                .map(|p| {
                    let expr: Box<dyn Expr> = Box::new(weir_expr_to_expr(p.as_ref()).unwrap());
                    expr
                })
                .collect(),
        );

        Self::new(
            Box::new(patterns),
            correct_forms,
            message,
            description,
            lint_kind,
        )
    }

    pub fn new_fixed_phrase(
        phrase: impl AsRef<str>,
        correct_forms: impl IntoIterator<Item = impl ToString>,
        message: impl ToString,
        description: impl ToString,
        lint_kind: Option<LintKind>,
    ) -> Self {
        Self::new(
            Box::new(FixedPhrase::from_phrase(phrase.as_ref())),
            correct_forms,
            message,
            description,
            lint_kind,
        )
    }

    pub fn new_closed_compound(phrase: impl AsRef<str>, correct_form: impl ToString) -> Self {
        let message = format!(
            "Did you mean the closed compound `{}`?",
            correct_form.to_string()
        );

        let description = format!(
            "Looks for incorrect spacing inside the closed compound `{}`.",
            correct_form.to_string()
        );

        Self::new_fixed_phrase(
            phrase,
            [correct_form],
            message,
            description,
            Some(LintKind::Miscellaneous),
        )
    }
}

impl ExprLinter for MapPhraseLinter {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], source: &[char]) -> Option<Lint> {
        let span = matched_tokens.span()?;
        let matched_text = span.get_content(source);

        Some(Lint {
            span,
            lint_kind: self.lint_kind,
            suggestions: self
                .correct_forms
                .iter()
                .map(|correct_form| {
                    Suggestion::replace_with_match_case(
                        correct_form.chars().collect(),
                        matched_text,
                    )
                })
                .collect(),
            message: self.message.to_string(),
            priority: 31,
        })
    }

    fn description(&self) -> &str {
        self.description.as_str()
    }
}



================================================
FILE: harper-core/src/linting/map_phrase_set_linter.rs
================================================
use super::{ExprLinter, Lint, LintKind};
use crate::CharStringExt;
use crate::expr::Expr;
use crate::expr::FixedPhrase;
use crate::expr::LongestMatchOf;
use crate::linting::Suggestion;
use crate::linting::expr_linter::Chunk;
use crate::{Token, TokenStringExt};

pub struct MapPhraseSetLinter<'a> {
    description: String,
    expr: Box<dyn Expr>,
    wrong_forms_to_correct_forms: &'a [(&'a str, &'a str)],
    multi_wrong_forms_to_multi_correct_forms: &'a [(&'a [&'a str], &'a [&'a str])],
    message: String,
    lint_kind: LintKind,
}

impl<'a> MapPhraseSetLinter<'a> {
    pub fn one_to_one(
        wrong_forms_to_correct_forms: &'a [(&'a str, &'a str)],
        message: impl ToString,
        description: impl ToString,
        lint_kind: Option<LintKind>,
    ) -> Self {
        let expr = Box::new(LongestMatchOf::new(
            wrong_forms_to_correct_forms
                .iter()
                .map(|(wrong_form, _correct_form)| {
                    let expr: Box<dyn Expr> = Box::new(FixedPhrase::from_phrase(wrong_form));
                    expr
                })
                .collect(),
        ));

        Self {
            description: description.to_string(),
            expr,
            wrong_forms_to_correct_forms,
            multi_wrong_forms_to_multi_correct_forms: &[],
            message: message.to_string(),
            lint_kind: lint_kind.unwrap_or(LintKind::Miscellaneous),
        }
    }

    pub fn many_to_many(
        multi_wrong_forms_to_multi_correct_forms: &'a [(&'a [&'a str], &'a [&'a str])],
        message: impl ToString,
        description: impl ToString,
        lint_kind: Option<LintKind>,
    ) -> Self {
        let mut lmo = LongestMatchOf::new(Vec::new());
        for (wrong_forms, _correct_forms) in multi_wrong_forms_to_multi_correct_forms {
            for wrong_form in wrong_forms.iter() {
                lmo.add(FixedPhrase::from_phrase(wrong_form));
            }
        }
        let expr = Box::new(lmo);

        Self {
            description: description.to_string(),
            expr,
            wrong_forms_to_correct_forms: &[],
            multi_wrong_forms_to_multi_correct_forms,
            message: message.to_string(),
            lint_kind: lint_kind.unwrap_or(LintKind::Miscellaneous),
        }
    }
}

impl<'a> ExprLinter for MapPhraseSetLinter<'a> {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], source: &[char]) -> Option<Lint> {
        let span = matched_tokens.span()?;
        let matched_text = span.get_content(source);

        let mut suggestions: Vec<_> = self
            .wrong_forms_to_correct_forms
            .iter()
            .filter(|(wrong_form, _)| matched_text.eq_ignore_ascii_case_str(wrong_form))
            .map(|(_, correct_form)| {
                Suggestion::replace_with_match_case(correct_form.chars().collect(), matched_text)
            })
            .collect();

        let many_to_many_suggestions: Vec<_> = self
            .multi_wrong_forms_to_multi_correct_forms
            .iter()
            .flat_map(|(wrong_forms, correct_forms)| {
                wrong_forms
                    .iter()
                    .filter(move |&&wrong_form| matched_text.eq_ignore_ascii_case_str(wrong_form))
                    .flat_map(move |_| {
                        correct_forms.iter().map(move |correct_form| {
                            Suggestion::replace_with_match_case(
                                correct_form.chars().collect(),
                                matched_text,
                            )
                        })
                    })
            })
            .collect();

        suggestions.extend(many_to_many_suggestions);

        if suggestions.is_empty() {
            return None;
        }

        Some(Lint {
            span,
            lint_kind: self.lint_kind,
            suggestions,
            message: self.message.to_string(),
            priority: 31,
        })
    }

    fn description(&self) -> &str {
        self.description.as_str()
    }
}



================================================
FILE: harper-core/src/linting/merge_linters.rs
================================================
macro_rules! merge_linters {
    ($name:ident => $($linter:ident),* => $desc:expr) => {
        pub use merge_rule_hidden::$name;

        mod merge_rule_hidden {
            use paste::paste;
            use crate::{Document, linting::{Lint, Linter}, remove_overlaps};

            $(
                use super::$linter;
            )*

            paste! {
                #[derive(Default)]
                pub struct $name {
                    $(
                        [< $linter:snake >]: $linter,
                    )*
                }

                impl Linter for $name {
                    fn lint(&mut self, document: &Document) -> Vec<Lint>{
                        let mut lints = Vec::new();

                        $(
                            lints.extend(self.[< $linter:snake >].lint(document));
                        )*

                        remove_overlaps(&mut lints);

                        lints
                    }

                    fn description(&self) -> &'static str {
                        $desc
                    }
                }
            }
        }
    };
}

pub(crate) use merge_linters;



================================================
FILE: harper-core/src/linting/merge_words.rs
================================================
use std::sync::Arc;

use itertools::Itertools;

use super::{Lint, LintKind, Linter, Suggestion};
use crate::spell::{Dictionary, FstDictionary};
use crate::{CharString, Document, Span};

pub struct MergeWords {
    dict: Arc<FstDictionary>,
}

impl MergeWords {
    pub fn new() -> Self {
        Self {
            dict: FstDictionary::curated(),
        }
    }
}

impl Default for MergeWords {
    fn default() -> Self {
        Self::new()
    }
}

impl Linter for MergeWords {
    fn lint(&mut self, document: &Document) -> Vec<Lint> {
        let mut lints = Vec::new();

        let mut merged_word = CharString::new();

        for (a, w, b) in document.tokens().tuple_windows() {
            if !a.kind.is_word() || !w.kind.is_whitespace() || !b.kind.is_word() {
                continue;
            }

            let a_chars = document.get_span_content(&a.span);
            let b_chars = document.get_span_content(&b.span);

            if (a_chars.len() == 1 && a_chars[0].is_uppercase())
                || (b_chars.len() == 1 && b_chars[0].is_uppercase())
            {
                continue;
            }

            // Not super helpful in this case, so we skip it
            if matches!(a_chars, ['a']) || matches!(b_chars, ['a']) {
                continue;
            }

            merged_word.clear();
            merged_word.extend_from_slice(a_chars);
            merged_word.extend_from_slice(b_chars);

            if self.dict.contains_word(&merged_word)
                && (!self.dict.contains_word(a_chars) || !self.dict.contains_word(b_chars))
            {
                lints.push(Lint {
                    span: Span::new(a.span.start, b.span.end),
                    lint_kind: LintKind::WordChoice,
                    suggestions: vec![Suggestion::ReplaceWith(merged_word.to_vec())],
                    message: "It seems these words would go better together.".to_owned(),
                    priority: 63,
                });
            }

            merged_word.clear();
            merged_word.extend_from_slice(a_chars);
            merged_word.push('\'');
            merged_word.extend_from_slice(b_chars);

            if self.dict.contains_word(&merged_word)
                && (!self.dict.contains_word(a_chars) || !self.dict.contains_word(b_chars))
            {
                lints.push(Lint {
                    span: Span::new(a.span.start, b.span.end),
                    lint_kind: LintKind::WordChoice,
                    suggestions: vec![Suggestion::ReplaceWith(merged_word.to_vec())],
                    message: "It seems you intended to make this a contraction.".to_owned(),
                    priority: 63,
                });
            }
        }

        lints
    }

    fn description(&self) -> &str {
        "Accidentally inserting a space inside a word is common. This rule looks for valid words that are split by whitespace."
    }
}

#[cfg(test)]
mod tests {
    use crate::linting::tests::{assert_lint_count, assert_suggestion_result};

    use super::MergeWords;

    #[test]
    fn clean() {
        assert_lint_count(
            "When referring to the political party, make sure to treat them as a proper noun.",
            MergeWords::default(),
            0,
        );
    }

    #[test]
    fn heretofore() {
        assert_lint_count(
            "This is a her etofore unseen problem.",
            MergeWords::default(),
            1,
        );
    }

    #[test]
    fn therefore() {
        assert_lint_count("The refore", MergeWords::default(), 1);
    }

    #[test]
    fn that_is_contraction() {
        assert_suggestion_result("That s", MergeWords::default(), "That's");
    }

    #[test]
    fn allows_issue_722() {
        assert_lint_count("Leaving S and K alone.", MergeWords::default(), 0);
        assert_lint_count("Similarly an S with a line.", MergeWords::default(), 0);
    }
}



================================================
FILE: harper-core/src/linting/missing_preposition.rs
================================================
use harper_brill::UPOS;

use crate::expr::AnchorStart;
use crate::expr::Expr;
use crate::expr::OwnedExprExt;
use crate::expr::SequenceExpr;
use crate::patterns::AnyPattern;
use crate::patterns::UPOSSet;
use crate::{Token, TokenStringExt};

use super::{ExprLinter, Lint, LintKind};
use crate::linting::expr_linter::Chunk;

pub struct MissingPreposition {
    expr: Box<dyn Expr>,
}

impl Default for MissingPreposition {
    fn default() -> Self {
        let expr = SequenceExpr::default()
            .then(
                AnchorStart.or_longest(
                    SequenceExpr::default()
                        .then_non_quantifier_determiner()
                        .t_ws(),
                ),
            )
            .then(UPOSSet::new(&[UPOS::NOUN, UPOS::PRON, UPOS::PROPN]))
            .t_ws()
            .then(UPOSSet::new(&[UPOS::AUX]))
            .t_ws()
            .then(UPOSSet::new(&[UPOS::ADJ]))
            .t_ws()
            .then(UPOSSet::new(&[UPOS::NOUN, UPOS::PRON, UPOS::PROPN]))
            .then_optional(AnyPattern)
            .then_optional(AnyPattern);

        Self {
            expr: Box::new(expr),
        }
    }
}

impl ExprLinter for MissingPreposition {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], _source: &[char]) -> Option<Lint> {
        if matched_tokens.last()?.kind.is_upos(UPOS::ADP) {
            return None;
        }

        Some({
            Lint {
                span: matched_tokens[2..4].span()?,
                lint_kind: LintKind::Miscellaneous,
                suggestions: vec![],
                message: "You may be missing a preposition here.".to_owned(),
                priority: 31,
            }
        })
    }

    fn description(&self) -> &'static str {
        "Locates potentially missing prepositions."
    }
}

#[cfg(test)]
mod tests {
    use crate::linting::tests::{assert_lint_count, assert_no_lints};

    use super::MissingPreposition;

    #[test]
    fn fixes_issue_1513() {
        assert_lint_count(
            "The city is famous its beaches.",
            MissingPreposition::default(),
            1,
        );
        assert_lint_count(
            "The students are interested learning.",
            MissingPreposition::default(),
            1,
        );
    }

    #[test]
    fn allows_corrected_issue_1513() {
        assert_no_lints(
            "The city is famous for its beaches.",
            MissingPreposition::default(),
        );
        assert_no_lints(
            "The students are interested in learning.",
            MissingPreposition::default(),
        );
    }

    #[test]
    fn no_lint_without_adj_noun_sequence() {
        assert_lint_count("She is happy.", MissingPreposition::default(), 0);
    }

    #[test]
    fn no_lint_with_preposition_present() {
        assert_lint_count("They are fond of music.", MissingPreposition::default(), 0);
        assert_lint_count(
            "Students are interested in history.",
            MissingPreposition::default(),
            0,
        );
    }

    #[test]
    fn flag_adj_pron_pair() {
        assert_lint_count("He was angry him.", MissingPreposition::default(), 1);
    }

    #[test]
    fn no_lint_empty() {
        assert_lint_count("", MissingPreposition::default(), 0);
    }

    #[test]
    fn allows_tired_herself() {
        assert_no_lints(
            "She had tired herself out with trying.",
            MissingPreposition::default(),
        );
    }

    #[test]
    fn allows_terrible_stuff() {
        assert_no_lints(
            "Either it was terrible stuff or the whiskey distorted things.",
            MissingPreposition::default(),
        );
    }

    #[test]
    fn allows_issue_1585() {
        assert_no_lints(
            "Each agent has specific tools and tasks orchestrated through a crew workflow.",
            MissingPreposition::default(),
        );
    }
}



================================================
FILE: harper-core/src/linting/missing_space.rs
================================================
use itertools::Itertools;

use crate::{Document, Punctuation};

use super::{Lint, LintKind, Linter, Suggestion};

pub struct MissingSpace;

impl Linter for MissingSpace {
    fn lint(&mut self, document: &Document) -> Vec<Lint> {
        let mut lints = Vec::new();

        for (a, b, c) in document.tokens().tuple_windows() {
            if let Some(punct) = b.kind.as_punctuation()
                && [
                    Punctuation::Period,
                    Punctuation::Bang,
                    Punctuation::Question,
                    Punctuation::Semicolon,
                ]
                .contains(punct)
                && a.kind.is_word()
                && c.kind.is_word()
            {
                lints.push(Lint {
                    span: b.span,
                    lint_kind: LintKind::Formatting,
                    suggestions: vec![Suggestion::InsertAfter(vec![' '])],
                    message: "It looks like you're missing a space here.".to_owned(),
                    priority: 31,
                });
            }
        }

        lints
    }

    fn description(&self) -> &str {
        "Looks for missing spaces after a comma or period."
    }
}

#[cfg(test)]
mod tests {
    use crate::linting::tests::assert_suggestion_result;

    use super::MissingSpace;

    #[test]
    fn issue_2191() {
        assert_suggestion_result(
            "people that can help us.So I feel like there",
            MissingSpace,
            "people that can help us. So I feel like there",
        );
    }

    #[test]
    fn coffee_table() {
        assert_suggestion_result(
            "The coffee cooled on the table.The room stayed quiet.",
            MissingSpace,
            "The coffee cooled on the table. The room stayed quiet.",
        );
    }

    #[test]
    fn open_window() {
        assert_suggestion_result(
            "A small breeze moved through the open window.The curtains lifted and fell in slow waves.",
            MissingSpace,
            "A small breeze moved through the open window. The curtains lifted and fell in slow waves.",
        );
    }

    #[test]
    fn hallway_cat() {
        assert_suggestion_result(
            "The cat watched the hallway.Its tail twitched with steady focus.",
            MissingSpace,
            "The cat watched the hallway. Its tail twitched with steady focus.",
        );
    }

    #[test]
    fn rain_glass() {
        assert_suggestion_result(
            "Rain tapped against the glass.The sound made the afternoon feel longer.",
            MissingSpace,
            "Rain tapped against the glass. The sound made the afternoon feel longer.",
        );
    }

    #[test]
    fn cyclist_house() {
        assert_suggestion_result(
            "A cyclist passed by the house.The wheels hummed softly on the road.",
            MissingSpace,
            "A cyclist passed by the house. The wheels hummed softly on the road.",
        );
    }

    #[test]
    fn kettle_stove() {
        assert_suggestion_result(
            "The kettle hissed on the stove.A thin ribbon of steam curled toward the ceiling.",
            MissingSpace,
            "The kettle hissed on the stove. A thin ribbon of steam curled toward the ceiling.",
        );
    }

    #[test]
    fn sparrow_fence() {
        assert_suggestion_result(
            "A sparrow landed on the fence.Its wings fluttered once before it settled.",
            MissingSpace,
            "A sparrow landed on the fence. Its wings fluttered once before it settled.",
        );
    }

    #[test]
    fn streetlamp_dusk() {
        assert_suggestion_result(
            "The streetlamp flickered at dusk.A pale glow spread across the sidewalk.",
            MissingSpace,
            "The streetlamp flickered at dusk. A pale glow spread across the sidewalk.",
        );
    }

    #[test]
    fn distant_laughter() {
        assert_suggestion_result(
            "Someone laughed in the distance.The echo drifted between the buildings.",
            MissingSpace,
            "Someone laughed in the distance. The echo drifted between the buildings.",
        );
    }

    #[test]
    fn notebook_desk() {
        assert_suggestion_result(
            "A notebook lay open on the desk.Its blank pages waited for a pen.",
            MissingSpace,
            "A notebook lay open on the desk. Its blank pages waited for a pen.",
        );
    }

    #[test]
    fn question_mark_mid_sentence() {
        assert_suggestion_result(
            "Where are you?I looked around the room.",
            MissingSpace,
            "Where are you? I looked around the room.",
        );
    }

    #[test]
    fn question_mark_before_name() {
        assert_suggestion_result(
            "Are you coming?Elijah is already waiting.",
            MissingSpace,
            "Are you coming? Elijah is already waiting.",
        );
    }

    #[test]
    fn exclamation_mid_sentence() {
        assert_suggestion_result(
            "The door slammed shut!Everyone in the hall jumped.",
            MissingSpace,
            "The door slammed shut! Everyone in the hall jumped.",
        );
    }

    #[test]
    fn exclamation_before_clause() {
        assert_suggestion_result(
            "You actually solved it!That changes everything.",
            MissingSpace,
            "You actually solved it! That changes everything.",
        );
    }

    #[test]
    fn semicolon_before_adverb() {
        assert_suggestion_result(
            "He wanted to leave;however, he stayed until the end.",
            MissingSpace,
            "He wanted to leave; however, he stayed until the end.",
        );
    }

    #[test]
    fn semicolon_connecting_clauses() {
        assert_suggestion_result(
            "The night was cold;stars glittered above the dark field.",
            MissingSpace,
            "The night was cold; stars glittered above the dark field.",
        );
    }
}



================================================
FILE: harper-core/src/linting/missing_to.rs
================================================
use std::sync::Arc;

use harper_brill::UPOS;

use crate::linting::expr_linter::Chunk;
use crate::{
    Token,
    expr::{Expr, ExprMap, SequenceExpr},
    linting::{ExprLinter, Lint, LintKind, Suggestion},
    patterns::WordSet,
};

pub struct MissingTo {
    expr: Box<dyn Expr>,
    map: Arc<ExprMap<usize>>,
}

impl MissingTo {
    fn controller_words() -> WordSet {
        WordSet::new(&[
            "aim",
            "aimed",
            "aiming",
            "aims",
            "agree",
            "agreed",
            "agreeing",
            "agrees",
            "arrange",
            "arranged",
            "arranges",
            "arranging",
            "aspire",
            "aspired",
            "aspires",
            "aspiring",
            "attempt",
            "attempted",
            "attempting",
            "attempts",
            "decide",
            "decided",
            "decides",
            "deciding",
            "endeavor",
            "endeavored",
            "endeavoring",
            "endeavors",
            "endeavour",
            "endeavoured",
            "endeavouring",
            "endeavours",
            "eager",
            "expect",
            "expected",
            "expecting",
            "expects",
            "fail",
            "failed",
            "failing",
            "fails",
            "forget",
            "forgot",
            "forgotten",
            "forgetting",
            "forgets",
            "hope",
            "hoped",
            "hopes",
            "hoping",
            "incline",
            "inclined",
            "inclines",
            "inclining",
            "intend",
            "intended",
            "intending",
            "intends",
            "learn",
            "learned",
            "learning",
            "learns",
            "learnt",
            "long",
            "longed",
            "longing",
            "longs",
            "manage",
            "managed",
            "manages",
            "managing",
            "mean",
            "means",
            "meant",
            "need",
            "needed",
            "needing",
            "needs",
            "neglect",
            "neglected",
            "neglecting",
            "neglects",
            "prepare",
            "prepared",
            "prepares",
            "preparing",
            "ready",
            "refuse",
            "refused",
            "refuses",
            "refusing",
            "resolve",
            "resolved",
            "resolves",
            "resolving",
            "struggle",
            "struggled",
            "struggles",
            "struggling",
            "try",
            "tried",
            "trying",
            "tries",
            "want",
            "wanted",
            "wanting",
            "wants",
        ])
    }

    fn previous_word_with_span(source: &[char], start: usize) -> Option<(String, usize)> {
        let mut cursor = start;

        while cursor > 0 && source[cursor - 1].is_whitespace() {
            cursor -= 1;
        }

        if cursor == 0 {
            return None;
        }

        let end = cursor;

        while cursor > 0 {
            let ch = source[cursor - 1];
            if ch.is_alphabetic() || ch == '\'' {
                cursor -= 1;
            } else {
                break;
            }
        }

        if cursor == end {
            return None;
        }

        Some((
            source[cursor..end]
                .iter()
                .collect::<String>()
                .to_ascii_lowercase(),
            cursor,
        ))
    }

    fn previous_word(source: &[char], start: usize) -> Option<String> {
        Self::previous_word_with_span(source, start).map(|(word, _)| word)
    }

    fn previous_non_whitespace_char(source: &[char], start: usize) -> Option<char> {
        let mut cursor = start;

        while cursor > 0 {
            cursor -= 1;
            let ch = source[cursor];
            if !ch.is_whitespace() {
                return Some(ch);
            }
        }

        None
    }

    fn next_non_whitespace_char(source: &[char], start: usize) -> Option<char> {
        let mut cursor = start;

        while cursor < source.len() {
            let ch = source[cursor];
            if !ch.is_whitespace() {
                return Some(ch);
            }
            cursor += 1;
        }

        None
    }
}

impl Default for MissingTo {
    fn default() -> Self {
        let mut map = ExprMap::default();

        let pattern = SequenceExpr::default()
            .then(Self::controller_words())
            .t_ws()
            .then_kind_where(|kind| kind.is_verb_lemma());

        map.insert(pattern, 0);

        let map = Arc::new(map);

        Self {
            expr: Box::new(map.clone()),
            map,
        }
    }
}

impl ExprLinter for MissingTo {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], source: &[char]) -> Option<Lint> {
        let offending_idx = *self.map.lookup(0, matched_tokens, source)?;
        let controller = &matched_tokens[offending_idx];
        let span = controller.span;

        let controller_text = controller.span.get_content_string(source).to_lowercase();

        let is_adjective_controller =
            matches!(controller_text.as_str(), "eager" | "inclined" | "ready");

        if controller.kind.is_upos(UPOS::ADJ) && !is_adjective_controller {
            return None;
        }

        if !controller.kind.is_upos(UPOS::VERB) && !is_adjective_controller {
            return None;
        }

        let previous_word_info = Self::previous_word_with_span(source, span.start);
        let previous_word = previous_word_info.as_ref().map(|(word, _)| word.as_str());

        let mut determiner_within_three = false;
        let mut determiner_scan_cursor = span.start;

        for _ in 0..3 {
            let Some((word, start)) = Self::previous_word_with_span(source, determiner_scan_cursor)
            else {
                break;
            };

            if matches!(word.as_str(), "and" | "or" | "but") {
                determiner_scan_cursor = start;
                continue;
            }

            if matches!(
                word.as_str(),
                "a" | "an" | "the" | "this" | "that" | "these" | "those"
            ) {
                determiner_within_three = true;
                break;
            }

            determiner_scan_cursor = start;
        }

        if matches!(
            previous_word,
            Some("a")
                | Some("an")
                | Some("the")
                | Some("this")
                | Some("that")
                | Some("these")
                | Some("those")
        ) {
            return None;
        }

        if matches!(
            previous_word,
            Some("very") | Some("so") | Some("too") | Some("quite") | Some("rather")
        ) {
            return None;
        }

        if previous_word == Some("of")
            && (controller_text.ends_with('d') || controller_text.ends_with("en"))
        {
            return None;
        }

        if controller_text.starts_with("hope") && previous_word == Some("of") {
            return None;
        }

        if controller_text == "needs" && previous_word == Some("must") {
            return None;
        }

        if controller_text == "prepare"
            && matches!(
                Self::previous_non_whitespace_char(source, span.start),
                None | Some('.') | Some('!') | Some('?')
            )
        {
            return None;
        }

        let next_token = matched_tokens
            .iter()
            .skip(offending_idx + 1)
            .find(|tok| !tok.kind.is_whitespace())?;

        let next_text = next_token.span.get_content_string(source).to_lowercase();
        let next_non_whitespace_char = Self::next_non_whitespace_char(source, next_token.span.end);

        if controller_text.starts_with("try") && next_text == "and" {
            return None;
        }

        let next_is_verb = next_token.kind.is_upos(UPOS::VERB);
        let next_is_noun = next_token.kind.is_upos(UPOS::NOUN)
            || next_token.kind.is_upos(UPOS::PROPN)
            || next_token.kind.is_upos(UPOS::ADJ);

        if next_token.kind.is_np_member()
            && !next_is_verb
            && (previous_word == Some("to") || determiner_within_three)
        {
            return None;
        }

        if !next_is_verb
            && (next_token.kind.is_upos(UPOS::ADV)
                || next_token.kind.is_upos(UPOS::ADJ)
                || next_token.kind.is_upos(UPOS::ADP)
                || next_token.kind.is_upos(UPOS::SCONJ)
                || next_token.kind.is_upos(UPOS::CCONJ))
        {
            return None;
        }

        if next_text.ends_with("ing") {
            return None;
        }

        if matches!(
            controller_text.as_str(),
            "learn" | "learned" | "learning" | "learns" | "learnt"
        ) && next_is_noun
            && !next_is_verb
        {
            return None;
        }

        if matches!(
            controller_text.as_str(),
            "hope" | "hoped" | "hopes" | "hoping"
        ) && next_is_noun
            && !next_is_verb
        {
            return None;
        }

        if matches!(
            controller_text.as_str(),
            "need" | "needed" | "needing" | "needs"
        ) && next_is_noun
            && !next_is_verb
        {
            return None;
        }

        if matches!(
            controller_text.as_str(),
            "need" | "needed" | "needing" | "needs"
        ) && next_text == "help"
        {
            return None;
        }

        if matches!(
            controller_text.as_str(),
            "hope" | "hoped" | "hopes" | "hoping"
        ) && next_token.kind.is_upos(UPOS::AUX)
        {
            return None;
        }

        if matches!(controller_text.as_str(), "mean" | "means" | "meant")
            && next_is_noun
            && !next_is_verb
        {
            return None;
        }

        if matches!(
            controller_text.as_str(),
            "need" | "needed" | "needing" | "needs"
        ) && matches!(next_non_whitespace_char, Some('-'))
        {
            return None;
        }

        if next_token.kind.is_upos(UPOS::PROPN)
            && matches!(
                Self::previous_non_whitespace_char(source, span.start),
                Some('"') | Some('\'') | Some('”') | Some('’') | Some('!') | Some('?') | Some(',')
            )
        {
            return None;
        }

        Some(Lint {
            span,
            lint_kind: LintKind::WordChoice,
            suggestions: vec![Suggestion::InsertAfter(" to".chars().collect())],
            message: "Insert `to` to complete the infinitive (e.g., `need to talk`).".to_string(),
            priority: 62,
        })
    }

    fn description(&self) -> &str {
        "Flags verbs and adjectives like `need`, `want`, or `ready` that are missing `to` before an infinitive."
    }
}

#[cfg(test)]
mod tests {
    use super::MissingTo;
    use crate::linting::tests::{assert_lint_count, assert_suggestion_result};

    #[test]
    fn inserts_to_after_meant() {
        assert_suggestion_result(
            "I meant call you last night.",
            MissingTo::default(),
            "I meant to call you last night.",
        );
    }

    #[test]
    fn inserts_to_after_wants() {
        assert_suggestion_result(
            "She wants finish early.",
            MissingTo::default(),
            "She wants to finish early.",
        );
    }

    #[test]
    fn inserts_to_after_need() {
        assert_suggestion_result(
            "We need talk about pricing.",
            MissingTo::default(),
            "We need to talk about pricing.",
        );
    }

    #[test]
    fn inserts_to_after_agreed() {
        assert_suggestion_result(
            "They agreed meet at dawn.",
            MissingTo::default(),
            "They agreed to meet at dawn.",
        );
    }

    #[test]
    fn inserts_to_after_forgot() {
        assert_suggestion_result(
            "He forgot send the file.",
            MissingTo::default(),
            "He forgot to send the file.",
        );
    }

    #[test]
    fn inserts_to_after_trying() {
        assert_suggestion_result(
            "I'm trying get better at chess.",
            MissingTo::default(),
            "I'm trying to get better at chess.",
        );
    }

    #[test]
    fn inserts_to_after_refused() {
        assert_suggestion_result(
            "She refused answer the question.",
            MissingTo::default(),
            "She refused to answer the question.",
        );
    }

    #[test]
    fn inserts_to_after_ready() {
        assert_suggestion_result(
            "We're ready start the meeting.",
            MissingTo::default(),
            "We're ready to start the meeting.",
        );
    }

    #[test]
    fn inserts_to_after_eager() {
        assert_suggestion_result(
            "I'm eager see the results.",
            MissingTo::default(),
            "I'm eager to see the results.",
        );
    }

    #[test]
    fn inserts_to_after_inclined() {
        assert_suggestion_result(
            "I'm inclined believe you.",
            MissingTo::default(),
            "I'm inclined to believe you.",
        );
    }

    #[test]
    fn no_lint_when_to_present() {
        assert_lint_count("She wants to finish early.", MissingTo::default(), 0);
    }

    #[test]
    fn no_lint_with_noun_after_controller() {
        assert_lint_count("They arranged a meeting at noon.", MissingTo::default(), 0);
    }

    #[test]
    fn no_lint_needs_follow_up_appointments() {
        assert_lint_count(
            "Gus is recovering well, though he needs follow-up appointments.",
            MissingTo::default(),
            0,
        );
    }

    #[test]
    fn no_lint_delays_meant_decisions() {
        assert_lint_count(
            "The delays meant decisions were often made on outdated information, hindering agility and potentially impacting return on investment.",
            MissingTo::default(),
            0,
        );
    }

    #[test]
    fn no_lint_bouquet_of_roses() {
        assert_lint_count(
            "I made a note to request a small bouquet of roses for his room, a simple gesture that I hoped would bring a moment of solace.",
            MissingTo::default(),
            0,
        );
    }

    #[test]
    fn no_lint_for_intended_word_phrase() {
        assert_lint_count(
            "Detects incorrect usage of `peak` when the intended word is `pique`.",
            MissingTo::default(),
            0,
        );
    }

    #[test]
    fn no_lint_long_passage() {
        assert_lint_count(
            "Before her was another long passage illuminated by lamps.",
            MissingTo::default(),
            0,
        );
    }

    #[test]
    fn no_lint_long_island_sound() {
        assert_lint_count(
            "The sailboat drifted along Long Island Sound at sunrise.",
            MissingTo::default(),
            0,
        );
    }

    #[test]
    fn no_lint_learn_tag_probabilities() {
        assert_lint_count(
            "These models learn tag probabilities from annotated corpora.",
            MissingTo::default(),
            0,
        );
    }

    #[test]
    fn no_lint_standard_feature_nominal_phrase() {
        assert_lint_count(
            "This is a standard and expected feature for any e-commerce site selling visually-driven products.",
            MissingTo::default(),
            0,
        );
    }

    #[test]
    fn no_lint_mixing_bowl_nominal_phrase() {
        assert_lint_count(
            "This is a 2-quart mixing bowl, ideal for everything from whipping cream to preparing cake batter.",
            MissingTo::default(),
            0,
        );
    }

    #[test]
    fn no_lint_try_and_say() {
        assert_lint_count(
            "I'll try and say hello before I leave.",
            MissingTo::default(),
            0,
        );
    }
}



================================================
FILE: harper-core/src/linting/misspell.rs
================================================
use crate::linting::expr_linter::Chunk;
use crate::{
    Token, TokenStringExt,
    expr::{Expr, SequenceExpr},
    linting::{ExprLinter, Lint, LintKind, Suggestion},
    patterns::WordSet,
};

pub struct Misspell {
    expr: Box<dyn Expr>,
}

impl Default for Misspell {
    fn default() -> Self {
        let expr = SequenceExpr::default()
            .then(WordSet::new(&["miss"]))
            .t_ws_h()
            .then(WordSet::new(&[
                "spell",
                "spelled",
                "spelling",
                "spells",
                "spellings",
            ]));

        Self {
            expr: Box::new(expr),
        }
    }
}

impl ExprLinter for Misspell {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], source: &[char]) -> Option<Lint> {
        let span = matched_tokens.span()?;
        let misspell_variant = matched_tokens.last()?;

        let variant_chars = misspell_variant.span.get_content(source);
        let variant_lower = variant_chars
            .iter()
            .map(|c| c.to_ascii_lowercase())
            .collect::<String>();

        let replacement = match variant_lower.as_str() {
            "spell" => "misspell",
            "spelled" => "misspelled",
            "spelling" => "misspelling",
            "spells" => "misspells",
            "spellings" => "misspellings",
            _ => return None,
        };

        let suggestions = vec![Suggestion::replace_with_match_case(
            replacement.chars().collect(),
            span.get_content(source),
        )];

        Some(Lint {
            span,
            lint_kind: LintKind::BoundaryError,
            suggestions,
            message: "Write `misspell` and its inflections as a single word.".to_string(),
            priority: 63,
        })
    }

    fn description(&self) -> &'static str {
        "Ensures `misspell` and its inflected forms are written as a single word."
    }
}

#[cfg(test)]
mod tests {
    use crate::linting::tests::assert_suggestion_result;

    use super::Misspell;

    #[test]
    fn base_form() {
        assert_suggestion_result(
            "They often miss spell names in the log.",
            Misspell::default(),
            "They often misspell names in the log.",
        );
    }

    #[test]
    fn past_tense() {
        assert_suggestion_result(
            "She miss spelled the answer on the quiz.",
            Misspell::default(),
            "She misspelled the answer on the quiz.",
        );
    }

    #[test]
    fn past_tense_hyphen() {
        assert_suggestion_result(
            "She miss-spelled the answer on the quiz.",
            Misspell::default(),
            "She misspelled the answer on the quiz.",
        );
    }

    #[test]
    fn gerund_form() {
        assert_suggestion_result(
            "His constant miss spelling frustrated the team.",
            Misspell::default(),
            "His constant misspelling frustrated the team.",
        );
    }
}



================================================
FILE: harper-core/src/linting/mixed_bag.rs
================================================
use crate::CharStringExt;
use crate::linting::expr_linter::Chunk;
use crate::linting::expr_linter::find_the_only_token_matching;
use crate::linting::{ExprLinter, LintKind, Suggestion};
use crate::{
    Lint, Token, TokenKind,
    expr::{Expr, SequenceExpr},
};

pub struct MixedBag {
    expr: Box<dyn Expr>,
}

impl Default for MixedBag {
    fn default() -> Self {
        Self {
            expr: Box::new(
                SequenceExpr::default()
                    .then_kind_any_or_words(
                        &[TokenKind::is_adjective, TokenKind::is_adverb] as &[_],
                        &["a"],
                    )
                    .t_ws()
                    .t_aco("mixed")
                    .t_ws()
                    .t_aco("bad"),
            ),
        }
    }
}

impl ExprLinter for MixedBag {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, toks: &[Token], src: &[char]) -> Option<Lint> {
        let bad_span = find_the_only_token_matching(toks, src, |tok, _src| {
            tok.span
                .get_content(src)
                .eq_ignore_ascii_case_chars(&['b', 'a', 'd'])
        })?
        .span;

        Some(Lint {
            span: bad_span,
            lint_kind: LintKind::Eggcorn,
            suggestions: vec![Suggestion::replace_with_match_case_str(
                "bag",
                bad_span.get_content(src),
            )],
            message: "Corrects the eggcorn `mixed bad` to `mixed bag`.".to_string(),
            ..Default::default()
        })
    }

    fn description(&self) -> &'static str {
        "Corrects the eggcorn `mixed bad` to `mixed bag`."
    }
}

#[cfg(test)]
mod tests {
    use super::MixedBag;
    use crate::linting::tests::assert_suggestion_result;

    #[test]
    fn a_mixed_bad() {
        assert_suggestion_result(
            "CommandLine interface is already a mixed bad of wstring and #ifdef to   string or wstring.",
            MixedBag::default(),
            "CommandLine interface is already a mixed bag of wstring and #ifdef to   string or wstring.",
        );
    }

    #[test]
    fn big_mixed_bag() {
        assert_suggestion_result(
            "Speaking of dungeons , the dungeons in this game are a big mixed bad.",
            MixedBag::default(),
            "Speaking of dungeons , the dungeons in this game are a big mixed bag.",
        );
    }

    #[test]
    fn damn_mixed_bag() {
        assert_suggestion_result(
            "This is a damn mixed bad which left me frustrated, and yet longing for more.",
            MixedBag::default(),
            "This is a damn mixed bag which left me frustrated, and yet longing for more.",
        );
    }

    #[test]
    fn huge_mixed_bag() {
        assert_suggestion_result(
            "Also a huge mixed bad of no name monitors of different sizes that all have different color settings on.",
            MixedBag::default(),
            "Also a huge mixed bag of no name monitors of different sizes that all have different color settings on.",
        );
    }

    #[test]
    fn large_mixed_bag() {
        assert_suggestion_result(
            "I’m still struggling to comprehend how it throws such a large mixed bad of symptoms in the mix this time.",
            MixedBag::default(),
            "I’m still struggling to comprehend how it throws such a large mixed bag of symptoms in the mix this time.",
        );
    }

    #[test]
    fn massive_mixed_bad() {
        assert_suggestion_result(
            "Anyway. In topic, Swano was a massive mixed bad in this game.",
            MixedBag::default(),
            "Anyway. In topic, Swano was a massive mixed bag in this game.",
        );
    }

    #[test]
    fn massively_mixed_bag() {
        assert_suggestion_result(
            "While certain things are more common to be either way, it's a massively mixed bad overall.",
            MixedBag::default(),
            "While certain things are more common to be either way, it's a massively mixed bag overall.",
        );
    }

    #[test]
    fn pretty_mixed_bag() {
        assert_suggestion_result(
            "It's a pretty mixed bad for me: Evolution Xavier for comic Xavier. Evolution Magneto for comic Magneto.",
            MixedBag::default(),
            "It's a pretty mixed bag for me: Evolution Xavier for comic Xavier. Evolution Magneto for comic Magneto.",
        );
    }

    #[test]
    fn rather_mixed_bag() {
        assert_suggestion_result(
            "Well chaps, as expected the TS contains a rather mixed bad of promise and disappointment.",
            MixedBag::default(),
            "Well chaps, as expected the TS contains a rather mixed bag of promise and disappointment.",
        );
    }

    #[test]
    fn really_mixed_bag() {
        assert_suggestion_result(
            "This is a really mixed bad On one hand you have some of Eminem's highest highs and his lowest lows but ever.",
            MixedBag::default(),
            "This is a really mixed bag On one hand you have some of Eminem's highest highs and his lowest lows but ever.",
        );
    }

    #[test]
    fn slightly_mixed_bag() {
        assert_suggestion_result(
            "I absolutely love Yes Minister and Yes Prime Minister but it did end up a slightly mixed bad in terms of impact.",
            MixedBag::default(),
            "I absolutely love Yes Minister and Yes Prime Minister but it did end up a slightly mixed bag in terms of impact.",
        );
    }

    #[test]
    fn somewhat_mixed_bag() {
        assert_suggestion_result(
            "A somewhat mixed bad. The space is pleasant with a rustic vibe.",
            MixedBag::default(),
            "A somewhat mixed bag. The space is pleasant with a rustic vibe.",
        );
    }

    #[test]
    fn very_mixed_bag() {
        assert_suggestion_result(
            "AVAILABLE MEN is a very mixed bad of short films about gay subjects that very from excellent to weak.",
            MixedBag::default(),
            "AVAILABLE MEN is a very mixed bag of short films about gay subjects that very from excellent to weak.",
        );
    }
}



================================================
FILE: harper-core/src/linting/mod.rs
================================================
//! Frameworks and rules that locate errors in text.
//!
//! See the [`Linter`] trait and the [documentation for authoring a rule](https://writewithharper.com/docs/contributors/author-a-rule) for more information.

mod a_part;
mod a_while;
mod addicting;
mod adjective_double_degree;
mod adjective_of_a;
mod after_later;
mod all_intents_and_purposes;
mod allow_to;
mod am_in_the_morning;
mod amounts_for;
mod an_a;
mod and_in;
mod and_the_like;
mod another_thing_coming;
mod another_think_coming;
mod apart_from;
mod ask_no_preposition;
mod avoid_curses;
mod back_in_the_day;
mod be_allowed;
mod behind_the_scenes;
mod best_of_all_time;
mod boring_words;
mod bought;
mod brand_brandish;
mod call_them;
mod cant;
mod capitalize_personal_pronouns;
mod cautionary_tale;
mod change_tack;
mod chock_full;
mod closed_compounds;
mod comma_fixes;
mod compound_nouns;
mod compound_subject_i;
mod confident;
mod correct_number_suffix;
mod criteria_phenomena;
mod cure_for;
mod currency_placement;
mod dashes;
mod despite_it_is;
mod despite_of;
mod determiner_without_noun;
mod didnt;
mod discourse_markers;
mod disjoint_prefixes;
mod dot_initialisms;
mod double_click;
mod double_modal;
mod ellipsis_length;
mod else_possessive;
mod ever_every;
mod everyday;
mod expand_memory_shorthands;
mod expand_time_shorthands;
mod expr_linter;
mod far_be_it;
mod fascinated_by;
mod feel_fell;
mod few_units_of_time_ago;
mod filler_words;
mod find_fine;
mod first_aid_kit;
mod flesh_out_vs_full_fledged;
mod for_noun;
mod free_predicate;
mod friend_of_me;
mod go_so_far_as_to;
mod good_at;
mod handful;
mod have_pronoun;
mod have_take_a_look;
mod hedging;
mod hello_greeting;
mod hereby;
mod hop_hope;
mod hope_youre;
mod how_to;
mod hyphenate_number_day;
mod i_am_agreement;
mod if_wouldve;
mod in_on_the_cards;
mod inflected_verb_after_to;
mod initialism_linter;
mod initialisms;
mod interested_in;
mod it_is;
mod it_looks_like_that;
mod it_would_be;
mod its_contraction;
mod its_possessive;
mod jealous_of;
mod johns_hopkins;
mod left_right_hand;
mod less_worse;
mod let_to_do;
mod lets_confusion;
mod likewise;
mod lint;
mod lint_group;
mod lint_kind;
mod long_sentences;
mod looking_forward_to;
mod map_phrase_linter;
mod map_phrase_set_linter;
mod mass_nouns;
mod merge_linters;
mod merge_words;
mod missing_preposition;
mod missing_space;
mod missing_to;
mod misspell;
mod mixed_bag;
mod modal_be_adjective;
mod modal_of;
mod modal_seem;
mod months;
mod more_adjective;
mod more_better;
mod most_number;
mod most_of_the_times;
mod multiple_sequential_pronouns;
mod nail_on_the_head;
mod need_to_noun;
mod no_french_spaces;
mod no_match_for;
mod no_oxford_comma;
mod nobody;
mod nominal_wants;
mod nor_modal_pronoun;
mod noun_verb_confusion;
mod number_suffix_capitalization;
mod obsess_preposition;
mod of_course;
mod oldest_in_the_book;
mod on_floor;
mod once_or_twice;
mod one_and_the_same;
mod one_of_the_singular;
mod open_compounds;
mod open_the_light;
mod orthographic_consistency;
mod ought_to_be;
mod out_of_date;
mod oxford_comma;
mod oxymorons;
mod phrasal_verb_as_compound_noun;
mod phrase_set_corrections;
mod pique_interest;
mod plural_wrong_word_of_phrase;
mod possessive_noun;
mod possessive_your;
mod progressive_needs_be;
mod pronoun_are;
mod pronoun_contraction;
mod pronoun_inflection_be;
mod pronoun_knew;
mod pronoun_verb_agreement;
mod proper_noun_capitalization_linters;
mod quantifier_needs_of;
mod quantifier_numeral_conflict;
mod quite_quiet;
mod quote_spacing;
mod redundant_acronyms;
mod redundant_additive_adverbs;
mod regionalisms;
mod repeated_words;
mod respond;
mod right_click;
mod roller_skated;
mod safe_to_save;
mod save_to_safe;
mod semicolon_apostrophe;
mod sentence_capitalization;
mod shoot_oneself_in_the_foot;
mod simple_past_to_past_participle;
mod since_duration;
mod single_be;
mod some_without_article;
mod something_is;
mod somewhat_something;
mod soon_to_be;
mod sought_after;
mod spaces;
mod spell_check;
mod spelled_numbers;
mod split_words;
mod subject_pronoun;
mod suggestion;
mod take_a_look_to;
mod take_medicine;
mod take_serious;
mod that_than;
mod that_which;
mod the_how_why;
mod the_my;
mod the_proper_noun_possessive;
mod then_than;
mod theres;
mod theses_these;
mod thing_think;
mod this_type_of_thing;
mod though_thought;
mod throw_away;
mod throw_rubbish;
mod to_adverb;
mod to_two_too;
mod touristic;
mod transposed_space;
mod try_ones_hand_at;
mod unclosed_quotes;
mod update_place_names;
mod use_title_case;
mod verb_to_adjective;
mod very_unique;
mod vice_versa;
mod vicious_loop;
mod was_aloud;
mod way_too_adjective;
mod weir_rules;
mod well_educated;
mod whereas;
mod whom_subject_of_verb;
mod widely_accepted;
mod win_prize;
mod wish_could;
mod wordpress_dotcom;
mod would_never_have;

pub use expr_linter::{Chunk, ExprLinter};
pub use initialism_linter::InitialismLinter;
pub use lint::Lint;
pub use lint_group::{LintGroup, LintGroupConfig};
pub use lint_kind::LintKind;
pub use map_phrase_linter::MapPhraseLinter;
pub use map_phrase_set_linter::MapPhraseSetLinter;
pub use spell_check::SpellCheck;
pub use suggestion::{Suggestion, SuggestionCollectionExt};

use crate::{Document, LSend, render_markdown};

/// A __stateless__ rule that searches documents for grammatical errors.
///
/// Commonly implemented via [`ExprLinter`].
///
/// See also: [`LintGroup`].
pub trait Linter: LSend {
    /// Analyzes a document and produces zero or more [`Lint`]s.
    /// We pass `self` mutably for caching purposes.
    fn lint(&mut self, document: &Document) -> Vec<Lint>;
    /// A user-facing description of what kinds of grammatical errors this rule looks for.
    /// It is usually shown in settings menus.
    fn description(&self) -> &str;
}

/// A blanket-implemented trait that renders the Markdown description field of a linter to HTML.
pub trait HtmlDescriptionLinter {
    fn description_html(&self) -> String;
}

impl<L: ?Sized> HtmlDescriptionLinter for L
where
    L: Linter,
{
    fn description_html(&self) -> String {
        let desc = self.description();
        render_markdown(desc)
    }
}

#[cfg(test)]
pub mod tests {
    use crate::parsers::Markdown;
    use crate::{Document, Span, Token};
    use hashbrown::HashSet;

    /// Extension trait for converting spans of tokens back to their original text
    pub trait SpanVecExt {
        fn to_strings(&self, doc: &Document) -> Vec<String>;
    }

    impl SpanVecExt for Vec<Span<Token>> {
        fn to_strings(&self, doc: &Document) -> Vec<String> {
            self.iter()
                .map(|sp| {
                    doc.get_tokens()[sp.start..sp.end]
                        .iter()
                        .map(|tok| doc.get_span_content_str(&tok.span))
                        .collect::<String>()
                })
                .collect()
        }
    }

    use super::Linter;
    use crate::spell::FstDictionary;

    #[track_caller]
    pub fn assert_no_lints(text: &str, linter: impl Linter) {
        assert_lint_count(text, linter, 0);
    }

    #[track_caller]
    pub fn assert_lint_count(text: &str, mut linter: impl Linter, count: usize) {
        let test = Document::new_markdown_default_curated(text);
        let lints = linter.lint(&test);
        dbg!(&lints);
        if lints.len() != count {
            panic!(
                "Expected \"{text}\" to create {count} lints, but it created {}.",
                lints.len()
            );
        }
    }

    /// Assert the total number of suggestions produced by a [`Linter`], spread across all produced
    /// [`Lint`]s.
    #[track_caller]
    pub fn assert_suggestion_count(text: &str, mut linter: impl Linter, count: usize) {
        let test = Document::new_markdown_default_curated(text);
        let lints = linter.lint(&test);
        assert_eq!(
            lints.iter().map(|l| l.suggestions.len()).sum::<usize>(),
            count
        );
    }

    /// Runs a provided linter on text, applies the first suggestion from each lint
    /// and asserts whether the result is equal to a given value.
    #[track_caller]
    pub fn assert_suggestion_result(text: &str, linter: impl Linter, expected_result: &str) {
        assert_nth_suggestion_result(text, linter, expected_result, 0);
    }

    /// Runs a provided linter on text, applies the nth suggestion from each lint
    /// and asserts whether the result is equal to a given value.
    ///
    /// Note that `n` starts at zero.
    #[track_caller]
    pub fn assert_nth_suggestion_result(
        text: &str,
        mut linter: impl Linter,
        expected_result: &str,
        n: usize,
    ) {
        let transformed_str = transform_nth_str(text, &mut linter, n);

        if transformed_str.as_str() != expected_result {
            panic!("Expected \"{expected_result}\"\n But got \"{transformed_str}\"");
        }

        // Applying the suggestions should fix all the lints.
        assert_lint_count(&transformed_str, linter, 0);
    }

    #[track_caller]
    pub fn assert_top3_suggestion_result(
        text: &str,
        mut linter: impl Linter,
        expected_result: &str,
    ) {
        let zeroth = transform_nth_str(text, &mut linter, 0);
        let first = transform_nth_str(text, &mut linter, 1);
        let second = transform_nth_str(text, &mut linter, 2);

        match (
            zeroth.as_str() == expected_result,
            first.as_str() == expected_result,
            second.as_str() == expected_result,
        ) {
            (true, false, false) => assert_lint_count(&zeroth, linter, 0),
            (false, true, false) => assert_lint_count(&first, linter, 0),
            (false, false, true) => assert_lint_count(&second, linter, 0),
            (false, false, false) => panic!(
                "None of the top 3 suggestions produced the expected result:\n\
                Expected: \"{expected_result}\"\n\
                Got:\n\
                [0]: \"{zeroth}\"\n\
                [1]: \"{first}\"\n\
                [2]: \"{second}\""
            ),
            // I think it's not possible for more than one suggestion to be correct
            _ => {}
        }
    }

    /// Asserts that none of the suggestions from the linter match the given text.
    #[track_caller]
    pub fn assert_not_in_suggestion_result(
        text: &str,
        mut linter: impl Linter,
        bad_suggestion: &str,
    ) {
        let test = Document::new_markdown_default_curated(text);
        let lints = linter.lint(&test);

        for (i, lint) in lints.iter().enumerate() {
            for (j, suggestion) in lint.suggestions.iter().enumerate() {
                let mut text_chars: Vec<char> = text.chars().collect();
                suggestion.apply(lint.span, &mut text_chars);
                let suggestion_text: String = text_chars.into_iter().collect();

                if suggestion_text == bad_suggestion {
                    panic!(
                        "Found undesired suggestion at lint[{i}].suggestions[{j}]:\n\
                        Expected to not find suggestion: \"{bad_suggestion}\"\n\
                        But found: \"{suggestion_text}\""
                    );
                }
            }
        }
    }

    /// Asserts both that the given text matches the expected good suggestions and that none of the
    /// suggestions are in the bad suggestions list.
    #[track_caller]
    pub fn assert_good_and_bad_suggestions(
        text: &str,
        mut linter: impl Linter,
        good: &[&str],
        bad: &[&str],
    ) {
        let test = Document::new_markdown_default_curated(text);
        let lints = linter.lint(&test);

        let mut unseen_good: HashSet<_> = good.iter().cloned().collect();
        let mut found_bad = Vec::new();
        let mut found_good = Vec::new();

        for (i, lint) in lints.into_iter().enumerate() {
            for (j, suggestion) in lint.suggestions.into_iter().enumerate() {
                let mut text_chars: Vec<char> = text.chars().collect();
                suggestion.apply(lint.span, &mut text_chars);
                let suggestion_text: String = text_chars.into_iter().collect();

                // Check for bad suggestions
                if bad.contains(&&*suggestion_text) {
                    found_bad.push((i, j, suggestion_text.clone()));
                    eprintln!(
                        "  ❌ Found bad suggestion at lint[{i}].suggestions[{j}]: \"{suggestion_text}\""
                    );
                }
                // Check for good suggestions
                else if good.contains(&&*suggestion_text) {
                    found_good.push((i, j, suggestion_text.clone()));
                    eprintln!(
                        "  ✅ Found good suggestion at lint[{i}].suggestions[{j}]: \"{suggestion_text}\""
                    );
                    unseen_good.remove(suggestion_text.as_str());
                }
            }
        }

        // Print summary
        if !found_bad.is_empty() || !unseen_good.is_empty() {
            eprintln!("\n=== Test Summary ===");

            // In the summary section, change these loops:
            if !found_bad.is_empty() {
                eprintln!("\n❌ Found {} bad suggestions:", found_bad.len());
                for (i, j, text) in &found_bad {
                    eprintln!("  - lint[{i}].suggestions[{j}]: \"{text}\"");
                }
            }

            // And for the good suggestions:
            if !unseen_good.is_empty() {
                eprintln!(
                    "\n❌ Missing {} expected good suggestions:",
                    unseen_good.len()
                );
                for text in &unseen_good {
                    eprintln!("  - \"{text}\"");
                }
            }

            eprintln!("\n✅ Found {} good suggestions", found_good.len());
            eprintln!("==================\n");

            if !found_bad.is_empty() || !unseen_good.is_empty() {
                panic!("Test failed - see error output above");
            }
        } else {
            eprintln!(
                "\n✅ All {} good suggestions found, no bad suggestions\n",
                found_good.len()
            );
        }
    }

    /// Asserts that the lint's message matches the expected message.
    #[track_caller]
    pub fn assert_lint_message(text: &str, mut linter: impl Linter, expected_message: &str) {
        let test = Document::new_markdown_default_curated(text);
        let lints = linter.lint(&test);

        // Just check the first lint for now
        if let Some(lint) = lints.first() {
            if lint.message != expected_message {
                panic!(
                    "Expected lint message \"{expected_message}\", but got \"{}\"",
                    lint.message
                );
            }
        }
    }

    fn transform_nth_str(text: &str, linter: &mut impl Linter, n: usize) -> String {
        let mut text_chars: Vec<char> = text.chars().collect();

        let mut iter_count = 0;

        loop {
            let test = Document::new_from_vec(
                text_chars.clone().into(),
                &Markdown::default(),
                &FstDictionary::curated(),
            );
            let lints = linter.lint(&test);

            if let Some(lint) = lints.first() {
                if let Some(sug) = lint.suggestions.get(n) {
                    sug.apply(lint.span, &mut text_chars);

                    let transformed_str: String = text_chars.iter().collect();
                    dbg!(transformed_str);
                } else {
                    break;
                }
            } else {
                break;
            }

            iter_count += 1;

            if iter_count == 100 {
                break;
            }
        }

        eprintln!("Corrected {iter_count} times.");

        text_chars.iter().collect()
    }
}



================================================
FILE: harper-core/src/linting/modal_be_adjective.rs
================================================
use crate::{
    CharStringExt, Lint, Token, TokenKind,
    expr::{Expr, SequenceExpr},
    linting::{ExprLinter, Suggestion, expr_linter::Chunk},
    patterns::ModalVerb,
};

pub struct ModalBeAdjective {
    expr: Box<dyn Expr>,
}

impl Default for ModalBeAdjective {
    fn default() -> Self {
        Self {
            expr: Box::new(
                SequenceExpr::default()
                    .then(ModalVerb::default())
                    .t_ws()
                    .then_kind_is_but_isnt_any_of_except(
                        TokenKind::is_adjective,
                        &[
                            TokenKind::is_verb_lemma,  // set
                            TokenKind::is_adverb,      // ever
                            TokenKind::is_preposition, // on
                            TokenKind::is_determiner,  // all
                            TokenKind::is_pronoun,     // all
                        ] as &[_],
                        &[
                            "backup", // adjective commonly misused as a verb
                            "likely", // adjective but with special usage
                        ] as &[_],
                    ),
            ),
        }
    }
}

impl ExprLinter for ModalBeAdjective {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint_with_context(
        &self,
        toks: &[Token],
        src: &[char],
        ctx: Option<(&[Token], &[Token])>,
    ) -> Option<Lint> {
        if let Some((_, after)) = ctx
            && after.len() >= 2
            && after[0].kind.is_whitespace()
        {
            // If the 'after' context is whitespace followed by a noun, there is no error
            // (Not including these marginal nouns: "at", "by", "if")
            if after[1].kind.is_noun()
                && !after[1]
                    .span
                    .get_content(src)
                    .eq_any_ignore_ascii_case_str(&["at", "by", "if"])
            {
                return None;
            }

            // If the adjective plus the next word is "kind of"
            if toks
                .last()
                .unwrap()
                .span
                .get_content_string(src)
                .eq_ignore_ascii_case("kind")
                && after[1]
                    .span
                    .get_content(src)
                    .eq_ignore_ascii_case_str("of")
            {
                return None;
            }
        }

        Some(Lint {
            span: toks[0].span,
            suggestions: vec![Suggestion::InsertAfter(" be".chars().collect())],
            message: "You may be missing the word `be` between this modal verb and adjective."
                .to_string(),
            ..Default::default()
        })
    }

    fn description(&self) -> &str {
        "Looks for `be` missing between a modal verb and adjective."
    }
}

#[cfg(test)]
mod tests {
    use crate::linting::tests::{assert_no_lints, assert_suggestion_result};

    use super::ModalBeAdjective;

    #[test]
    fn fix_would_nice() {
        assert_suggestion_result(
            "It would nice if Harper could detect this.",
            ModalBeAdjective::default(),
            "It would be nice if Harper could detect this.",
        );
    }

    #[test]
    fn fix_could_configured() {
        assert_suggestion_result(
            "It could configured by parameters and the commands above effectively disable it.",
            ModalBeAdjective::default(),
            "It could be configured by parameters and the commands above effectively disable it.",
        );
    }

    #[test]
    fn fix_will_accessible() {
        assert_suggestion_result(
            "Your WordPress site will accessible at http://localhost",
            ModalBeAdjective::default(),
            "Your WordPress site will be accessible at http://localhost",
        );
    }

    #[test]
    fn ignore_would_external_traffic() {
        assert_no_lints(
            "And why would external traffic be trying to access my server if I don't know who or what it is?",
            ModalBeAdjective::default(),
        )
    }

    #[test]
    fn ignore_could_kind_of() {
        assert_no_lints("you could kind of see the ...", ModalBeAdjective::default())
    }

    // Known false positives. You may want to improve the code to handle some of these.

    #[test]
    #[ignore = "false positive: 'backup' is an adjective but also a spello for the verb 'back up'"]
    fn ignore_you_can_backup() {
        assert_no_lints("You can backup Userdata.", ModalBeAdjective::default());
    }

    #[test]
    #[ignore = "false positive: 'incorrect' should be 'incorrectly'."]
    fn ignore_would_incorrect() {
        assert_no_lints(
            "Bug in versions 4.0 and 4.1 would incorrect list the address module",
            ModalBeAdjective::default(),
        );
    }

    #[test]
    #[ignore = "false positive: 'upper-bound' is an ad-hoc verb here."]
    fn ignore_should_upper() {
        assert_no_lints(
            "we should upper-bound it to the next MAJOR version.",
            ModalBeAdjective::default(),
        );
        assert_no_lints(
            "some older software (filezilla on debian-stable) cannot passive-mode with TLS",
            ModalBeAdjective::default(),
        );
    }
}



================================================
FILE: harper-core/src/linting/modal_of.rs
================================================
use crate::expr::Expr;
use crate::expr::LongestMatchOf;
use crate::expr::SequenceExpr;
use crate::patterns::ModalVerb;
use crate::{Lrc, Token, TokenStringExt};

use super::{ExprLinter, Lint, LintKind, Suggestion};
use crate::linting::expr_linter::Chunk;

pub struct ModalOf {
    expr: Box<dyn Expr>,
}

impl Default for ModalOf {
    fn default() -> Self {
        // Note 1. "shan't of" is plausible but very unlikely
        // Note 2. "had of" has trickier false positives and is less common anyway
        // "The only other report we've had of this kind of problem ..."
        // "The code I had of this used to work fine ..."

        let modal_of = Lrc::new(
            SequenceExpr::default()
                .then(ModalVerb::default())
                .then_whitespace()
                .t_aco("of"),
        );

        // "will of" is a false positive if "will" is a noun
        // "The will of the many"
        let noun_will_of_naive = Lrc::new(
            SequenceExpr::default()
                .then_word_set(&["the", "a"])
                .then_whitespace()
                .t_aco("will")
                .then_whitespace()
                .t_aco("of"),
        );

        let ws_course = Lrc::new(SequenceExpr::default().then_whitespace().t_aco("course"));

        let modal_of_course = Lrc::new(
            SequenceExpr::default()
                .then(modal_of.clone())
                .then(ws_course.clone()),
        );

        let anyword_might_of = Lrc::new(
            SequenceExpr::default()
                .then_any_word()
                .then_whitespace()
                .t_aco("might")
                .then_whitespace()
                .t_aco("of"),
        );

        let anyword_might_of_course = Lrc::new(
            SequenceExpr::default()
                .then(anyword_might_of.clone())
                .then(ws_course.clone()),
        );

        Self {
            expr: Box::new(LongestMatchOf::new(vec![
                Box::new(anyword_might_of_course),
                Box::new(modal_of_course),
                Box::new(anyword_might_of),
                Box::new(noun_will_of_naive),
                Box::new(modal_of),
            ])),
        }
    }
}

impl ExprLinter for ModalOf {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_toks: &[Token], source_chars: &[char]) -> Option<Lint> {
        let modal_index = match matched_toks.len() {
            // Without context, always an error from the start
            3 => 0,
            5 => {
                // False positives: modal _ of _ course / adj. _ might _ of / art. _ might _ of
                let w3_text = matched_toks
                    .last()
                    .unwrap()
                    .span
                    .get_content(source_chars)
                    .iter()
                    .collect::<String>();
                if w3_text.as_str() != "of" {
                    return None;
                }
                let w1_kind = &matched_toks.first().unwrap().kind;
                // the might of something, great might of something
                if w1_kind.is_adjective() || w1_kind.is_determiner() {
                    return None;
                }
                // not a false positive, skip context before
                2
            }
            // False positive: <word> _ might _ of _ course
            7 => return None,
            _ => unreachable!(),
        };

        let span_modal_of = matched_toks[modal_index..modal_index + 3].span().unwrap();

        let modal_have = format!(
            "{} have",
            matched_toks[modal_index]
                .span
                .get_content_string(source_chars)
        )
        .chars()
        .collect();

        Some(Lint {
            span: span_modal_of,
            lint_kind: LintKind::WordChoice,
            suggestions: vec![Suggestion::replace_with_match_case(
                modal_have,
                span_modal_of.get_content(source_chars),
            )],
            message: "Use `have` rather than `of` here.".to_string(),
            priority: 126,
        })
    }

    fn description(&self) -> &'static str {
        "Detects `of` mistakenly used with `would`, `could`, `should`, etc."
    }
}

#[cfg(test)]
mod tests {
    use super::ModalOf;
    use crate::linting::tests::{assert_lint_count, assert_suggestion_result};

    // atomic unit tests

    #[test]
    fn test_lowercase() {
        assert_suggestion_result("could of", ModalOf::default(), "could have");
    }

    #[test]
    fn test_negative() {
        assert_suggestion_result("mightn't of", ModalOf::default(), "mightn't have");
    }

    #[test]
    fn test_uppercase_negative() {
        assert_suggestion_result("Mustn't of", ModalOf::default(), "Mustn't have");
    }

    #[test]
    fn test_false_positive_of_course() {
        assert_lint_count("should of course", ModalOf::default(), 0);
    }

    #[test]
    fn test_false_positive_the_might_of() {
        assert_lint_count("the might of", ModalOf::default(), 0);
    }

    #[test]
    fn test_false_positive_great_might_of() {
        assert_lint_count("great might of", ModalOf::default(), 0);
    }

    #[test]
    fn test_false_positive_capital_negative() {
        assert_lint_count("Wouldn't of course", ModalOf::default(), 0);
    }

    // real-world tests

    #[test]
    fn test_buggy_implementation() {
        assert_lint_count(
            "... could of just been a buggy implementation",
            ModalOf::default(),
            1,
        );
    }

    #[test]
    fn test_missed_one() {
        assert_lint_count(
            "We already have a function ... that nedb can understand so we might of missed one.",
            ModalOf::default(),
            1,
        );
    }

    #[test]
    fn test_user_option() {
        assert_lint_count(
            "im more likely to believe you might of left in the 'user' option",
            ModalOf::default(),
            1,
        );
    }

    #[test]
    fn catches_must_of() {
        assert_suggestion_result(
            "Ah I must of missed that part.",
            ModalOf::default(),
            "Ah I must have missed that part.",
        );
    }

    #[test]
    fn catches_should_of() {
        assert_lint_count(
            "Yeah I should of just mentioned it should of been a for of.",
            ModalOf::default(),
            2,
        );
    }

    #[test]
    fn catches_would_of() {
        assert_suggestion_result(
            "now this issue would of caused hundreds of thousands of extra lines",
            ModalOf::default(),
            "now this issue would have caused hundreds of thousands of extra lines",
        );
    }

    #[test]
    fn doesnt_catch_you_could_of_course() {
        assert_lint_count(
            "You could of course explicit the else with each possibility",
            ModalOf::default(),
            0,
        );
    }

    #[test]
    fn doesnt_catch_compiler_could_of_course() {
        assert_lint_count(
            "The compiler could of course detect this too",
            ModalOf::default(),
            0,
        );
    }

    #[test]
    fn doesnt_catch_might_of_course_be() {
        assert_lint_count(
            "There might of course be other places where not implementing the IMemberSource might break ...",
            ModalOf::default(),
            0,
        );
    }

    #[test]
    fn doesnt_catch_not_a_must_of_course() {
        assert_lint_count(
            "Not a must of course if the convention should be .ts",
            ModalOf::default(),
            0,
        );
    }

    #[test]
    fn doesnt_catch_must_of_course_also() {
        assert_lint_count(
            "the schedular must of course also have run through",
            ModalOf::default(),
            0,
        );
    }

    #[test]
    fn doesnt_catch_should_of_course_not() {
        assert_lint_count(
            "not being local should of course not be supported",
            ModalOf::default(),
            0,
        );
    }

    #[test]
    fn doesnt_catch_would_of_course_just() {
        assert_lint_count(
            "I would of course just test this by compiling with MATX_MULTI_GPU=ON",
            ModalOf::default(),
            0,
        );
    }

    #[test]
    fn doesnt_catch_to_take_on_the_full_might_of_nato() {
        assert_lint_count("To take on the full might of NATO.", ModalOf::default(), 0);
    }

    #[test]
    fn doesnt_catch_mixed_case_of_course() {
        assert_lint_count(
            "... for now you could of Course put ...",
            ModalOf::default(),
            0,
        );
    }

    #[test]
    fn catches_mixed_case_could_of_put() {
        assert_lint_count("... for now you could of Put ...", ModalOf::default(), 1);
    }

    #[test]
    fn doesnt_catch_noun_will_of() {
        assert_lint_count("the will of the many", ModalOf::default(), 0);
    }

    #[test]
    fn doesnt_catch_noun_will_of_edgecase() {
        assert_lint_count("he sent us a will of his", ModalOf::default(), 0);
    }

    #[test]
    fn catch_modal_will_of() {
        assert_lint_count("that will of an impact", ModalOf::default(), 1);
    }
}



================================================
FILE: harper-core/src/linting/modal_seem.rs
================================================
use std::sync::Arc;

use crate::linting::expr_linter::Chunk;
use crate::{
    CharStringExt, Token,
    expr::{Expr, ExprMap, SequenceExpr},
    linting::{ExprLinter, Lint, LintKind, Suggestion},
    patterns::ModalVerb,
};

#[derive(Clone, Copy, Default)]
struct MatchContext {
    modal_index: usize,
}

pub struct ModalSeem {
    expr: Box<dyn Expr>,
    map: Arc<ExprMap<MatchContext>>,
}

impl ModalSeem {
    fn base_sequence() -> SequenceExpr {
        SequenceExpr::default()
            .then(ModalVerb::default())
            .t_ws()
            .t_aco("seen")
    }

    fn adjective_step() -> SequenceExpr {
        SequenceExpr::default()
            .t_ws()
            .then_kind_where(|kind| kind.is_adjective())
    }

    fn adverb_then_adjective_step() -> SequenceExpr {
        SequenceExpr::default()
            .t_ws()
            .then_kind_where(|kind| kind.is_adverb())
            .t_ws()
            .then_kind_where(|kind| kind.is_adjective())
    }
}

impl Default for ModalSeem {
    fn default() -> Self {
        let mut map = ExprMap::default();

        map.insert(
            SequenceExpr::default()
                .then_seq(Self::base_sequence())
                .then(Self::adjective_step()),
            MatchContext::default(),
        );

        map.insert(
            SequenceExpr::default()
                .then_seq(Self::base_sequence())
                .then(Self::adverb_then_adjective_step()),
            MatchContext::default(),
        );

        let map = Arc::new(map);

        Self {
            expr: Box::new(map.clone()),
            map,
        }
    }
}

impl ExprLinter for ModalSeem {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], source: &[char]) -> Option<Lint> {
        let context = self.map.lookup(0, matched_tokens, source)?;

        let seen_token = matched_tokens
            .iter()
            .skip(context.modal_index)
            .find(|tok| {
                tok.span
                    .get_content(source)
                    .eq_ignore_ascii_case_str("seen")
            })?;

        let span = seen_token.span;
        let original = span.get_content(source);

        Some(Lint {
            span,
            lint_kind: LintKind::Grammar,
            suggestions: vec![
                Suggestion::replace_with_match_case("seem".chars().collect(), original),
                Suggestion::replace_with_match_case("be".chars().collect(), original),
            ],
            message: "Swap `seen` for a linking verb when it follows a modal before an adjective."
                .to_owned(),
            priority: 32,
        })
    }

    fn description(&self) -> &str {
        "Detects modal verbs followed by `seen` before adjectives and suggests `seem` or `be`."
    }
}

#[cfg(test)]
mod tests {
    use super::ModalSeem;
    use crate::linting::tests::{
        assert_lint_count, assert_no_lints, assert_nth_suggestion_result, assert_suggestion_result,
    };

    #[test]
    fn corrects_basic_case() {
        assert_suggestion_result(
            "It may seen impossible to finish.",
            ModalSeem::default(),
            "It may seem impossible to finish.",
        );
    }

    #[test]
    fn corrects_with_adverb() {
        assert_suggestion_result(
            "That might seen utterly ridiculous.",
            ModalSeem::default(),
            "That might seem utterly ridiculous.",
        );
    }

    #[test]
    fn offers_be_option() {
        assert_nth_suggestion_result(
            "It may seen impossible to finish.",
            ModalSeem::default(),
            "It may be impossible to finish.",
            1,
        );
    }

    #[test]
    fn respects_uppercase() {
        assert_suggestion_result(
            "THIS COULD SEEN TERRIBLE.",
            ModalSeem::default(),
            "THIS COULD SEEM TERRIBLE.",
        );
    }

    #[test]
    fn corrects_before_punctuation() {
        assert_suggestion_result(
            "Still, it may seen absurd, but we will continue.",
            ModalSeem::default(),
            "Still, it may seem absurd, but we will continue.",
        );
    }

    #[test]
    fn corrects_across_newline() {
        assert_suggestion_result(
            "It may seen\n impossible to pull off.",
            ModalSeem::default(),
            "It may seem\n impossible to pull off.",
        );
    }

    #[test]
    fn ignores_correct_seem() {
        assert_no_lints("It may seem impossible to finish.", ModalSeem::default());
    }

    #[test]
    fn ignores_modal_with_be_seen() {
        assert_no_lints("It may be seen as unfair.", ModalSeem::default());
    }

    #[test]
    fn ignores_modal_seen_noun() {
        assert_no_lints(
            "It may seen results sooner than expected.",
            ModalSeem::default(),
        );
    }

    #[test]
    fn ignores_modal_seen_clause() {
        assert_lint_count(
            "It may seen that we are improving.",
            ModalSeem::default(),
            0,
        );
    }
}



================================================
FILE: harper-core/src/linting/months.rs
================================================
use crate::linting::expr_linter::Chunk;
use crate::{
    Lrc, Token, TokenKind,
    expr::{Expr, FirstMatchOf, SequenceExpr},
    linting::{ExprLinter, Lint, LintKind, Suggestion},
    patterns::WordSet,
};

// Static array of all month names
const ALL_MONTHS: &[&str] = &[
    "january",
    "february",
    "march",
    "april",
    "may",
    "june",
    "july",
    "august",
    "september",
    "october",
    "november",
    "december",
];

pub struct Months {
    expr: Box<dyn Expr>,
}

impl Default for Months {
    fn default() -> Self {
        // Define ambiguous months (those that are also common words)
        let ambiguous_months = Lrc::new(WordSet::new(&["march", "may", "august"]));

        // The unambiguous months
        let only_months: Vec<&str> = ALL_MONTHS
            .iter()
            .filter(|&&m| !ambiguous_months.contains(m))
            .copied()
            .collect();

        let only_months = WordSet::new(&only_months);

        let before_month_sense_only = WordSet::new(&[
            // Determiners.
            // These words won't disambiguate months: "each", "this", "that"
            // "each may do as he likes"
            // "this may be the best month"
            "every",
            // Prepositions.
            // Possible false positives:
            // "the first word at the beginning of the next may be fragmented"
            // "Next may be to offer all the color tables in some way"
            // "First and last may have been swapped"
            "by", "during", "in", "last", "next", "of", "until",
        ]);

        let year_or_day_of_month = SequenceExpr::default().then_kind_where(|kind| {
            if let TokenKind::Number(number) = &kind {
                let v = number.value.into_inner() as u32;
                (1500..=2500).contains(&v) || (1..=31).contains(&v)
            } else {
                false
            }
        });

        // An Expr that matches either a plain month
        // Or an ambiguous month after a disambiguating word
        let month_expr = SequenceExpr::with(FirstMatchOf::new(vec![
            Box::new(only_months),
            Box::new(
                SequenceExpr::default()
                    .then(before_month_sense_only)
                    .then_whitespace()
                    .then(ambiguous_months.clone()),
            ),
            Box::new(
                SequenceExpr::default()
                    .then(ambiguous_months)
                    .then_whitespace()
                    .then(year_or_day_of_month),
            ),
        ]));

        Self {
            expr: Box::new(month_expr),
        }
    }
}

impl ExprLinter for Months {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, tokens: &[Token], src: &[char]) -> Option<Lint> {
        // `find` which token is the month by seeing which tok's content (lowercased) is in ALL_MONTHS
        let month_tok = tokens.iter().find(|token| {
            let token_str = token.span.get_content_string(src);
            ALL_MONTHS.iter().any(|&m| m == token_str.to_lowercase())
        })?; // Return None if no month token found

        // let month_tok = tokens.last().unwrap();
        let month_ch = month_tok.span.get_content(src);

        if month_ch[0].is_uppercase() {
            return None;
        }

        let mut month_vec = month_ch.to_vec();
        month_vec[0] = month_vec[0].to_ascii_uppercase();

        Some(Lint {
            span: month_tok.span,
            lint_kind: LintKind::Miscellaneous,
            suggestions: vec![Suggestion::ReplaceWith(month_vec)],
            message: "Months should be written with a capital letter.".to_string(),
            priority: 126,
        })
    }

    fn description(&self) -> &str {
        "Detects months written with a lowercase first letter."
    }
}

#[cfg(test)]
mod tests {
    use super::Months;
    use crate::linting::tests::assert_suggestion_result;

    #[test]
    fn fix_in_august() {
        assert_suggestion_result(
            "I worked for WebstaurantStore doing Quality Assurance Automation and am now transitioning to a new graduate developer role at BNY Mellon, starting in august.",
            Months::default(),
            "I worked for WebstaurantStore doing Quality Assurance Automation and am now transitioning to a new graduate developer role at BNY Mellon, starting in August.",
        );
    }

    #[test]
    fn fix_in_march() {
        assert_suggestion_result(
            "This game was originally written by me in march 2000.",
            Months::default(),
            "This game was originally written by me in March 2000.",
        );
    }

    #[test]
    fn fix_in_may() {
        assert_suggestion_result(
            "typo in may 2024 updates",
            Months::default(),
            "typo in May 2024 updates",
        );
    }

    #[test]
    fn fix_last_august() {
        assert_suggestion_result(
            "since last august smart has been leading talks to open up japan",
            Months::default(),
            "since last August smart has been leading talks to open up japan",
        );
    }

    #[test]
    fn fix_last_may() {
        assert_suggestion_result(
            "I have a 2019 mini countryman that i purchased last may.",
            Months::default(),
            "I have a 2019 mini countryman that i purchased last May.",
        );
    }

    #[test]
    fn fix_of_august() {
        assert_suggestion_result(
            "change abbreviation of august for Indonesian locale",
            Months::default(),
            "change abbreviation of August for Indonesian locale",
        )
    }

    #[test]
    fn fix_march_2019() {
        assert_suggestion_result(
            "How to disable drop cap today (late march 2019)",
            Months::default(),
            "How to disable drop cap today (late March 2019)",
        );
    }

    #[test]
    fn fix_may_2022() {
        assert_suggestion_result(
            "That will be ende from 30 may 2022.",
            Months::default(),
            "That will be ende from 30 May 2022.",
        );
    }

    #[test]
    fn fix_days() {
        assert_suggestion_result(
            "Between march 15 and august 27.",
            Months::default(),
            "Between March 15 and August 27.",
        );
    }
}



================================================
FILE: harper-core/src/linting/more_adjective.rs
================================================
use itertools::Itertools;

use crate::expr::{Expr, SequenceExpr};
use crate::linting::{ExprLinter, LintKind, Suggestion, expr_linter::Chunk};
use crate::spell::Dictionary;
use crate::{CharStringExt, Lint, Token, TokenStringExt};

const VOWELS: [char; 5] = ['a', 'e', 'i', 'o', 'u'];

pub struct MoreAdjective<D> {
    expr: Box<dyn Expr>,
    dict: D,
}

impl<D> MoreAdjective<D>
where
    D: Dictionary,
{
    pub fn new(dict: D) -> Self {
        Self {
            expr: Box::new(
                SequenceExpr::word_set(&["more", "most"])
                    .t_ws()
                    .then_positive_adjective(),
            ),
            dict,
        }
    }

    fn add_valid_candidate(&self, candidates: &mut Vec<String>, candidate: String) -> bool {
        if let Some(metadata) = self.dict.get_word_metadata_str(&candidate)
            && (metadata.is_comparative_adjective() || metadata.is_superlative_adjective())
        {
            candidates.push(candidate);
            true
        } else {
            false
        }
    }
}

impl<D> ExprLinter for MoreAdjective<D>
where
    D: Dictionary,
{
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, toks: &[Token], src: &[char]) -> Option<Lint> {
        // Check invariants just in case the Expr changes
        if toks.len() != 3 || !toks[1].kind.is_whitespace() || !toks[2].kind.is_positive_adjective()
        {
            return None;
        }

        let phrase = toks.span()?;

        enum Degree {
            Comparative,
            Superlative,
        }

        let degree_tok = &toks[0];
        let degree_chars = degree_tok.span.get_content(src);

        let degree = if degree_chars.eq_ignore_ascii_case_str("more") {
            Degree::Comparative
        } else if degree_chars.eq_ignore_ascii_case_str("most") {
            Degree::Superlative
        } else {
            return None;
        };

        let ending = match degree {
            Degree::Comparative => "er",
            Degree::Superlative => "est",
        };

        let adj_tok = &toks[2];
        let adj_span = adj_tok.span;
        let adj_chars = adj_span.get_content(src);
        let adj_str = adj_span.get_content_string(src);

        if adj_chars.len() < 2 {
            return None;
        }

        // "humaner" = "more humane", not "more human"
        if adj_str == "human" {
            return None;
        }

        let mut candidates: Vec<String> = vec![];

        // Only a handful of adjectives are irregular
        let new_candidates = match adj_str.as_str() {
            "bad" => match degree {
                Degree::Comparative => Some(&["worse"][..]),
                Degree::Superlative => Some(&["worst"][..]),
            },
            "good" => match degree {
                Degree::Comparative => Some(&["better"][..]),
                Degree::Superlative => Some(&["best"][..]),
            },
            "far" => match degree {
                Degree::Comparative => Some(&["further", "farther"][..]),
                Degree::Superlative => Some(&["furthest", "farthest"][..]),
            },
            _ => None,
        };
        if let Some(irregulars) = new_candidates {
            candidates.extend(irregulars.iter().map(|c| c.to_string()));
        }

        // Just add the ending: smart -> smarter/smartest
        self.add_valid_candidate(&mut candidates, format!("{}{}", adj_str, ending));

        // Double consonant: big -> bigger/biggest
        let penult = adj_chars[adj_chars.len() - 2];
        let last = adj_chars[adj_chars.len() - 1];
        if VOWELS.contains(&penult) && !VOWELS.contains(&last) {
            self.add_valid_candidate(&mut candidates, format!("{}{}{}", adj_str, last, ending));
        }

        if last == 'y' {
            // smelly -> smellier/smelliest
            self.add_valid_candidate(
                &mut candidates,
                format!(
                    "{}i{}",
                    &adj_chars[0..adj_chars.len() - 1].iter().collect::<String>(),
                    ending
                ),
            );
        } else if last == 'e' {
            // cute -> cuter/cutest
            self.add_valid_candidate(
                &mut candidates,
                format!(
                    "{}{}",
                    &adj_chars[0..adj_chars.len() - 1].iter().collect::<String>(),
                    ending
                ),
            );
        }

        if candidates.is_empty() {
            return None;
        }

        let suggestions = candidates
            .iter()
            .map(|c| {
                Suggestion::replace_with_match_case(
                    c.chars().collect_vec(),
                    phrase.get_content(src),
                )
            })
            .collect::<Vec<Suggestion>>();

        Some(Lint {
            span: phrase,
            lint_kind: LintKind::Style,
            suggestions,
            message: "This is not an error, but an inflected form of this adjective also exists"
                .to_string(),
            ..Default::default()
        })
    }

    fn description(&self) -> &str {
        "Looks for comparative adjective constructions with `more` than could use inflected forms."
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::linting::tests::{
        assert_good_and_bad_suggestions, assert_no_lints, assert_suggestion_result,
    };
    use crate::spell::FstDictionary;

    // True positives

    #[test]
    fn add_er() {
        assert_suggestion_result(
            "The red car is more fast.",
            MoreAdjective::new(FstDictionary::curated()),
            "The red car is faster.",
        );
    }

    #[test]
    fn add_r() {
        assert_suggestion_result(
            "The fluffy one is more cute.",
            MoreAdjective::new(FstDictionary::curated()),
            "The fluffy one is cuter.",
        );
    }

    #[test]
    fn double_final_consonant() {
        assert_suggestion_result(
            "You'll find out when you're more big.",
            MoreAdjective::new(FstDictionary::curated()),
            "You'll find out when you're bigger.",
        )
    }

    #[test]
    fn final_y() {
        assert_suggestion_result(
            "That one was even more smelly!",
            MoreAdjective::new(FstDictionary::curated()),
            "That one was even smellier!",
        );
    }

    #[test]
    fn irregular_good() {
        assert_suggestion_result(
            "I bet you couldn't do more good.",
            MoreAdjective::new(FstDictionary::curated()),
            "I bet you couldn't do better.",
        );
    }

    #[test]
    fn irregular_far() {
        assert_good_and_bad_suggestions(
            "Is it much more far?",
            MoreAdjective::new(FstDictionary::curated()),
            &["Is it much further?", "Is it much farther?"],
            &[],
        );
    }

    #[test]
    fn humane() {
        assert_suggestion_result(
            "That Klingon is more humane than the humans!",
            MoreAdjective::new(FstDictionary::curated()),
            "That Klingon is humaner than the humans!",
        );
    }

    // False positives

    #[test]
    fn dont_flag_more_time() {
        assert_no_lints(
            "I need more time.",
            MoreAdjective::new(FstDictionary::curated()),
        );
    }

    #[test]
    fn dont_flag_more_model() {
        assert_no_lints(
            "Expanded access to more model architectures",
            MoreAdjective::new(FstDictionary::curated()),
        );
    }

    #[test]
    fn dont_flag_more_human() {
        assert_no_lints(
            "I am more human than machine.",
            MoreAdjective::new(FstDictionary::curated()),
        );
    }

    #[test]
    fn dont_flag_more_battle() {
        assert_no_lints(
            "and has more battle-tested defaults",
            MoreAdjective::new(FstDictionary::curated()),
        );
    }

    #[test]
    fn dont_flag_more_like() {
        assert_no_lints(
            "It's more like a suggestion than a mistake.",
            MoreAdjective::new(FstDictionary::curated()),
        );
    }

    #[test]
    fn dont_flag_more_ground() {
        assert_no_lints(
            "This E2E security scan covers more ground",
            MoreAdjective::new(FstDictionary::curated()),
        );
    }
}



================================================
FILE: harper-core/src/linting/more_better.rs
================================================
use crate::expr::{Expr, SequenceExpr};
use crate::linting::expr_linter::Chunk;
use crate::linting::{ExprLinter, Lint, LintKind, Suggestion};
use crate::token::Token;
use crate::token_string_ext::TokenStringExt;

pub struct MoreBetter {
    expr: Box<dyn Expr>,
}

impl Default for MoreBetter {
    fn default() -> Self {
        Self {
            expr: Box::new(SequenceExpr::any_of(vec![
                Box::new(
                    SequenceExpr::default()
                        .t_aco("more")
                        .t_ws()
                        .then_comparative_adjective(),
                ),
                Box::new(
                    SequenceExpr::default()
                        .t_aco("most")
                        .t_ws()
                        .then_superlative_adjective(),
                ),
            ])),
        }
    }
}

impl ExprLinter for MoreBetter {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, toks: &[Token], src: &[char]) -> Option<Lint> {
        let phrase_span = toks.span()?;

        let degree_str = toks.first()?.span.get_content_string(src);
        let adj_span = toks.last()?.span;

        let suggestion = Suggestion::replace_with_match_case(
            adj_span.get_content(src).to_vec(),
            phrase_span.get_content(src),
        );

        let message = format!(
            "{} is already in the {} form, the {} is redundant",
            adj_span.get_content_string(src),
            if degree_str.eq_ignore_ascii_case("more") {
                "comparative"
            } else {
                "superlative"
            },
            degree_str,
        );

        Some(Lint {
            span: phrase_span,
            lint_kind: LintKind::Redundancy,
            suggestions: vec![suggestion],
            message,
            ..Default::default()
        })
    }

    fn description(&self) -> &'static str {
        "Finds redundant paring of `more` or `most` with adjectives already in the comparative or superlative form."
    }
}

#[cfg(test)]
mod tests {
    use super::MoreBetter;
    use crate::linting::tests::assert_suggestion_result;

    #[test]
    fn flag_most_biggest() {
        assert_suggestion_result("Most biggest", MoreBetter::default(), "Biggest");
    }

    #[test]
    fn flag_more_better_and_more_better() {
        assert_suggestion_result(
            "More bigger is more better",
            MoreBetter::default(),
            "Bigger is better",
        );
    }
}



================================================
FILE: harper-core/src/linting/most_number.rs
================================================
use crate::expr::All;
use crate::expr::Expr;
use crate::expr::SequenceExpr;
use crate::{Token, TokenStringExt, patterns::WordSet};

use super::{ExprLinter, Lint, LintKind, Suggestion};
use crate::linting::expr_linter::Chunk;

pub struct MostNumber {
    expr: Box<dyn Expr>,
}

impl Default for MostNumber {
    fn default() -> Self {
        Self {
            expr: Box::new(All::new(vec![
                // Main pattern
                Box::new(
                    SequenceExpr::default()
                        .t_aco("most")
                        .t_ws()
                        .then(WordSet::new(&["amount", "number"])),
                ),
                // Context pattern
                Box::new(
                    SequenceExpr::anything()
                        .then_anything()
                        .then_anything()
                        .then_anything()
                        .t_aco("of"),
                ),
            ])),
        }
    }
}

impl ExprLinter for MostNumber {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, toks: &[Token], source: &[char]) -> Option<Lint> {
        let most_amt_num_span = toks[0..3].span()?;
        let noun_string = toks[2].span.get_content_string(source);
        let superlatives = if noun_string == "amount" {
            vec!["largest", "greatest", "maximum"]
        } else {
            vec!["highest", "largest", "maximum"]
        };
        let suggestions = superlatives
            .into_iter()
            .map(|superlative| {
                Suggestion::replace_with_match_case(
                    format!("{superlative} {noun_string}").chars().collect(),
                    most_amt_num_span.get_content(source),
                )
            })
            .collect();
        Some(Lint {
            span: most_amt_num_span,
            lint_kind: LintKind::Miscellaneous,
            suggestions,
            message: format!(
                "`Most` is not standard before `{}`.",
                toks[2].span.get_content_string(source)
            ),
            priority: 31,
        })
    }

    fn description(&self) -> &str {
        "Corrects `most number` and `most amount`"
    }
}

#[cfg(test)]
mod tests {
    use crate::linting::tests::{
        assert_lint_count, assert_suggestion_result, assert_top3_suggestion_result,
    };

    use super::MostNumber;

    #[test]
    fn corrects_most_number() {
        assert_suggestion_result(
            "Find artists that have been on Spotify the most number of times.",
            MostNumber::default(),
            "Find artists that have been on Spotify the highest number of times.",
        );
    }

    #[test]
    #[ignore = "replace_with_match_case currently produces 'GreatEst'"]
    fn corrects_most_amount_title_case() {
        assert_top3_suggestion_result(
            "Area of Container with the Most Amount of Water",
            MostNumber::default(),
            "Area of Container with the Greatest Amount of Water",
        );
    }

    #[test]
    fn corrects_most_amount() {
        assert_top3_suggestion_result(
            "I just wanted to make sure it's good for the most amount of people, not just what I like.",
            MostNumber::default(),
            "I just wanted to make sure it's good for the greatest amount of people, not just what I like.",
        );
    }

    #[test]
    fn dont_correct_most_number_without_context() {
        assert_lint_count(
            "The random non-sequential nature should prevent most number gaming/sniping/lunging.",
            MostNumber::default(),
            0,
        );
    }

    #[test]
    fn corrects_most_amount_with_maximum() {
        assert_top3_suggestion_result(
            "If you want to support the most amount of different architectures ...",
            MostNumber::default(),
            "If you want to support the maximum amount of different architectures ...",
        );
    }
}



================================================
FILE: harper-core/src/linting/most_of_the_times.rs
================================================
use crate::expr::{Expr, FixedPhrase, SequenceExpr};
use crate::linting::expr_linter::Chunk;
use crate::linting::{ExprLinter, LintKind, Suggestion};
use crate::patterns::Word;
use crate::{Lint, Token};

pub struct MostOfTheTimes {
    expr: Box<dyn Expr>,
}

impl Default for MostOfTheTimes {
    fn default() -> Self {
        Self {
            expr: Box::new(
                SequenceExpr::any_of(vec![
                    Box::new(FixedPhrase::from_phrase("a lot")),
                    Box::new(Word::new("most")),
                ])
                .t_ws()
                .then_fixed_phrase("of the times"),
            ),
        }
    }
}

impl ExprLinter for MostOfTheTimes {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, toks: &[Token], src: &[char]) -> Option<Lint> {
        let span = toks.last()?.span;
        Some(Lint {
            span,
            lint_kind: LintKind::Usage,
            suggestions: vec![Suggestion::replace_with_match_case(
                "time".chars().collect(),
                span.get_content(src),
            )],
            message: "Singular `time` is usually the correct form in this context.".to_string(),
            priority: 32,
        })
    }

    fn description(&self) -> &str {
        "Corrects `a lot of the times` and `most of the times` to use singular `time`."
    }
}

#[cfg(test)]
mod tests {
    use crate::linting::tests::assert_suggestion_result;

    use super::MostOfTheTimes;

    #[test]
    fn hangs_forever() {
        assert_suggestion_result(
            "restic backup hangs forever most of the times · Issue #2834",
            MostOfTheTimes::default(),
            "restic backup hangs forever most of the time · Issue #2834",
        );
    }

    #[test]
    fn options_are_ignored() {
        assert_suggestion_result(
            "but other options like device and options are ignored most of the times",
            MostOfTheTimes::default(),
            "but other options like device and options are ignored most of the time",
        );
    }

    #[test]
    fn parenthesized() {
        assert_suggestion_result(
            "prompted html code gets (most of the times) read by copilot but is not displayed.",
            MostOfTheTimes::default(),
            "prompted html code gets (most of the time) read by copilot but is not displayed.",
        );
    }

    #[test]
    fn i_cant_play() {
        assert_suggestion_result(
            "I cannot get the version 1.0 without c so I cant play a lot of the times with other people",
            MostOfTheTimes::default(),
            "I cannot get the version 1.0 without c so I cant play a lot of the time with other people",
        );
    }
}



================================================
FILE: harper-core/src/linting/multiple_sequential_pronouns.rs
================================================
use super::Suggestion;
use super::expr_linter::ExprLinter;
use crate::expr::Expr;
use crate::expr::SequenceExpr;
use crate::linting::LintKind;
use crate::linting::expr_linter::Chunk;
use crate::patterns::WordSet;
use crate::{CharStringExt, Lint, Lrc, Token, TokenStringExt};

/// Linter that checks if multiple pronouns are being used right after each
/// other. This is a common mistake to make during the revision process.
pub struct MultipleSequentialPronouns {
    expr: Box<dyn Expr>,
    subject_pronouns: Lrc<WordSet>,
    object_pronouns: Lrc<WordSet>,
    possessive_adjectives: Lrc<WordSet>,
}

impl MultipleSequentialPronouns {
    fn new() -> Self {
        // Some words occur in multiple positions in the paradigm
        // but this is a set, so it doesn't matter and is much clearer
        let pronouns = Lrc::new(WordSet::new(&[
            "i", "you", "he", "she", "it", // subject case, singular
            "me", "you", "him", "her", "it", // object case, singular
            "we", "you", "they", // subject case, plural
            "us", "you", "them", // object case, plural
            "mine", "yours", "his", "hers", // possessive pronouns, singular
            "ours", "yours", "theirs", // possessive pronouns, plural
            "my", "your", "his", "her", "its", // possessive adjectives, singular
            "our", "your", "their", // possessive adjectives, plural
        ]));

        // TODO: temporary sets of pronouns - remove when DictWordMetadata has this info
        let subject_pronouns = Lrc::new(WordSet::new(&[
            "i", "you", "he", "she", "it", // subject case, singular
            "we", "you", "they", // subject case, plural
        ]));

        let object_pronouns = Lrc::new(WordSet::new(&[
            "me", "you", "him", "her", "it", // object case, singular
            "us", "you", "them", // object case, plural
        ]));

        let possessive_adjectives = Lrc::new(WordSet::new(&[
            "my", "your", "his", "her", "its", // possessive adjectives, singular
            "our", "your", "their", // possessive adjectives, plural
        ]));

        Self {
            expr: Box::new(
                SequenceExpr::default()
                    .then(pronouns.clone())
                    .then_one_or_more(
                        SequenceExpr::default()
                            .then_whitespace()
                            .then(pronouns.clone()),
                    ),
            ),
            subject_pronouns,
            object_pronouns,
            possessive_adjectives,
        }
    }

    fn is_subject_pronoun(&self, word: &str) -> bool {
        self.subject_pronouns.contains(word)
    }

    fn is_object_pronoun(&self, word: &str) -> bool {
        self.object_pronouns.contains(word)
    }

    fn is_possessive_adjective(&self, word: &str) -> bool {
        self.possessive_adjectives.contains(word)
    }
}

impl ExprLinter for MultipleSequentialPronouns {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], source: &[char]) -> Option<Lint> {
        let mut suggestions = Vec::new();

        if matched_tokens.len() == 3 {
            let first_word_raw = matched_tokens[0].span.get_content(source).to_string();
            let first_word = first_word_raw.to_ascii_lowercase();
            let second_word = matched_tokens[2].span.get_content(source).to_string();
            // Bug 578: "I can lend you my car" - if 1st is object and second is possessive adjective, don't lint
            if self.is_object_pronoun(&first_word) && self.is_possessive_adjective(&second_word) {
                return None;
            }
            // Bug 724: "One told me they were able to begin reading" - if 1st is object ans second is subject, don't lint
            if self.is_object_pronoun(&first_word) && self.is_subject_pronoun(&second_word) {
                return None;
            }

            // US is a qualifier meaning American, so uppercase after a possessive is OK.
            if self.is_possessive_adjective(&first_word) && second_word == "US" {
                return None;
            }

            // The same applies to uppercase before a subject pronoun
            if first_word_raw == "US" && self.is_subject_pronoun(&second_word) {
                return None;
            }

            suggestions.push(Suggestion::ReplaceWith(
                matched_tokens[0].span.get_content(source).to_vec(),
            ));
            suggestions.push(Suggestion::ReplaceWith(
                matched_tokens[2].span.get_content(source).to_vec(),
            ));
        }

        Some(Lint {
            span: matched_tokens.span()?,
            lint_kind: LintKind::Repetition,
            message: "There are too many personal pronouns in sequence here.".to_owned(),
            priority: 63,
            suggestions,
        })
    }

    fn description(&self) -> &'static str {
        "When editing work to change point of view (i.e. first-person or third-person) it is common to add pronouns while neglecting to remove old ones. This rule catches cases where you have multiple disparate pronouns in sequence."
    }
}

impl Default for MultipleSequentialPronouns {
    fn default() -> Self {
        Self::new()
    }
}

#[cfg(test)]
mod tests {
    use super::MultipleSequentialPronouns;
    use crate::linting::tests::assert_lint_count;

    #[test]
    fn can_detect_two_pronouns() {
        assert_lint_count(
            "...little bit about my I want to do.",
            MultipleSequentialPronouns::new(),
            1,
        )
    }

    #[test]
    fn can_detect_three_pronouns() {
        assert_lint_count(
            "...little bit about my I you want to do.",
            MultipleSequentialPronouns::new(),
            1,
        )
    }

    #[test]
    fn allows_single_pronouns() {
        assert_lint_count(
            "...little bit about I want to do.",
            MultipleSequentialPronouns::new(),
            0,
        )
    }

    #[test]
    fn detects_multiple_pronouns_at_end() {
        assert_lint_count(
            "...I need to explain this to you them.",
            MultipleSequentialPronouns::new(),
            1,
        )
    }

    #[test]
    fn comma_separated() {
        assert_lint_count("To prove it, we...", MultipleSequentialPronouns::new(), 0)
    }

    #[test]
    fn dont_flag_578() {
        assert_lint_count(
            "I can lend you my car.",
            MultipleSequentialPronouns::new(),
            0,
        )
    }

    #[test]
    fn dont_flag_724() {
        assert_lint_count(
            "One told me they were able to begin reading.",
            MultipleSequentialPronouns::new(),
            0,
        )
    }

    #[test]
    fn dont_flag_us() {
        assert_lint_count(
            "Take the plunge and pull plug from their US tech.",
            MultipleSequentialPronouns::new(),
            0,
        )
    }

    #[test]
    fn dont_flag_my_us_your_us() {
        assert_lint_count(
            "My US passport looks different from your US passport.",
            MultipleSequentialPronouns::new(),
            0,
        )
    }

    #[test]
    fn dont_flag_subject_after_usa() {
        assert_lint_count(
            "And if it’s manufactured in the US it may have more automation.",
            MultipleSequentialPronouns::new(),
            0,
        )
    }

    #[test]
    fn dont_flag_case_insensitive_cost_him_his_life() {
        assert_lint_count(
            "to the point where it very well likely cost Him his life",
            MultipleSequentialPronouns::new(),
            0,
        )
    }
}



================================================
FILE: harper-core/src/linting/nail_on_the_head.rs
================================================
use crate::expr::Expr;
use crate::expr::SequenceExpr;
use crate::linting::expr_linter::Chunk;
use crate::{
    Token,
    linting::{ExprLinter, Lint, LintKind, Suggestion},
    patterns::WordSet,
};

pub struct NailOnTheHead {
    expr: Box<dyn Expr>,
}

impl Default for NailOnTheHead {
    fn default() -> Self {
        let mis = WordSet::new(&["hat", "had", "hit", "hid"]);
        let pattern = SequenceExpr::default()
            .t_aco("nail")
            .then_whitespace()
            .t_aco("on")
            .then_whitespace()
            .t_aco("the")
            .then_whitespace()
            .then(mis);
        Self {
            expr: Box::new(pattern),
        }
    }
}

impl ExprLinter for NailOnTheHead {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, toks: &[Token], _src: &[char]) -> Option<Lint> {
        let offender = toks.last()?;
        Some(Lint {
            span: offender.span,
            lint_kind: LintKind::Miscellaneous,
            suggestions: vec![Suggestion::ReplaceWith("head".chars().collect())],
            message: "Did you mean `head`?".to_owned(),
            priority: 45,
        })
    }

    fn description(&self) -> &str {
        "Replaces hat/had/hit/hid in the idiom `nail on the head` with `head`."
    }
}

#[cfg(test)]
mod tests {
    use super::NailOnTheHead;
    use crate::linting::tests::{assert_lint_count, assert_suggestion_result};

    #[test]
    fn fix_hat() {
        assert_suggestion_result(
            "She hit the nail on the hat.",
            NailOnTheHead::default(),
            "She hit the nail on the head.",
        );
    }

    #[test]
    fn fix_had() {
        assert_suggestion_result(
            "You really put the nail on the had with that comment.",
            NailOnTheHead::default(),
            "You really put the nail on the head with that comment.",
        );
    }

    #[test]
    fn fix_hit() {
        assert_suggestion_result(
            "They hit the nail on the hit regarding our problem.",
            NailOnTheHead::default(),
            "They hit the nail on the head regarding our problem.",
        );
    }

    #[test]
    fn fix_hid() {
        assert_suggestion_result(
            "The article nails the nail on the hid this time.",
            NailOnTheHead::default(),
            "The article nails the nail on the head this time.",
        );
    }

    #[test]
    fn ignore_correct() {
        assert_lint_count("She hit the nail on the head.", NailOnTheHead::default(), 0);
    }
}



================================================
FILE: harper-core/src/linting/need_to_noun.rs
================================================
use crate::Token;
use crate::char_string::char_string;
use crate::expr::Expr;
use crate::expr::LongestMatchOf;
use crate::expr::OwnedExprExt;
use crate::expr::SequenceExpr;
use crate::expr::UnlessStep;
use crate::patterns::DerivedFrom;
use crate::patterns::WordSet;

use super::{ExprLinter, Lint, LintKind, Suggestion};
use crate::linting::expr_linter::Chunk;

pub struct NeedToNoun {
    expr: Box<dyn Expr>,
}

impl Default for NeedToNoun {
    fn default() -> Self {
        let postfix_exceptions = LongestMatchOf::new(vec![
            Box::new(|tok: &Token, _: &[char]| {
                tok.kind.is_adverb()
                    || tok.kind.is_determiner()
                    || tok.kind.is_unlintable()
                    || tok.kind.is_pronoun()
            }),
            Box::new(WordSet::new(&["about", "into", "it"])),
        ]);

        let exceptions = SequenceExpr::anything()
            .t_any()
            .t_any()
            .t_any()
            .then_word_set(&["be", "match"]);

        let a = SequenceExpr::default()
            .then_kind_where(|kind| kind.is_nominal())
            .t_ws()
            .then_unless(postfix_exceptions);

        let b =
            SequenceExpr::default().then_kind_where(|kind| kind.is_nominal() && !kind.is_verb());

        let expr = SequenceExpr::default()
            .then(DerivedFrom::new_from_str("need"))
            .t_ws()
            .t_aco("to")
            .t_ws()
            .then(a.or(b));

        Self {
            expr: Box::new(expr.and(UnlessStep::new(exceptions, |_: &Token, _: &[char]| true))),
        }
    }
}

impl ExprLinter for NeedToNoun {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], source: &[char]) -> Option<Lint> {
        let to_idx = 2;
        let to_token = &matched_tokens[to_idx];

        let noun_idx = 4;
        let noun_token = &matched_tokens[noun_idx];

        let noun_text = noun_token.span.get_content_string(source);
        let span = to_token.span;

        Some(Lint {
            span,
            lint_kind: LintKind::Grammar,
            suggestions: vec![Suggestion::ReplaceWith(char_string!("the").to_vec())],
            message: format!(
                "`need to` should be followed by a verb, not a noun or pronoun like `{noun_text}`."
            ),
            priority: 48,
        })
    }

    fn description(&self) -> &'static str {
        "Flags `need to` when it is immediately followed by a noun, which usually means the infinitive verb is missing."
    }
}

#[cfg(test)]
mod tests {
    use super::NeedToNoun;
    use crate::linting::tests::{assert_lint_count, assert_no_lints, assert_suggestion_result};

    #[test]
    fn flags_need_to_noun() {
        assert_suggestion_result(
            "I need to information now.",
            NeedToNoun::default(),
            "I need the information now.",
        );
    }

    #[test]
    fn allows_need_to_verb() {
        assert_lint_count("I need to leave now.", NeedToNoun::default(), 0);
    }

    #[test]
    fn allows_need_to_finish() {
        assert_lint_count(
            "I need to finish this report by tomorrow.",
            NeedToNoun::default(),
            0,
        );
    }

    #[test]
    fn allows_need_to_call() {
        assert_lint_count(
            "You need to call your mother tonight.",
            NeedToNoun::default(),
            0,
        );
    }

    #[test]
    fn allows_need_to_talk() {
        assert_lint_count(
            "We need to talk about the budget.",
            NeedToNoun::default(),
            0,
        );
    }

    #[test]
    fn allows_need_to_leave() {
        assert_lint_count(
            "They need to leave early to catch the train.",
            NeedToNoun::default(),
            0,
        );
    }

    #[test]
    fn allows_need_to_practice() {
        assert_lint_count(
            "She needs to practice her German more often.",
            NeedToNoun::default(),
            0,
        );
    }

    #[test]
    fn allows_need_to_fix() {
        assert_lint_count(
            "He needs to fix his bike before the weekend.",
            NeedToNoun::default(),
            0,
        );
    }

    #[test]
    fn allows_need_to_decide() {
        assert_lint_count(
            "We need to decide where to go for dinner.",
            NeedToNoun::default(),
            0,
        );
    }

    #[test]
    fn allows_need_to_update() {
        assert_lint_count(
            "You need to update your password.",
            NeedToNoun::default(),
            0,
        );
    }

    #[test]
    fn allows_need_to_take() {
        assert_lint_count(
            "I need to take a break and get some fresh air.",
            NeedToNoun::default(),
            0,
        );
    }

    #[test]
    fn allows_need_to_clean() {
        assert_lint_count(
            "They need to clean the house before guests arrive.",
            NeedToNoun::default(),
            0,
        );
    }

    #[test]
    fn avoids_false_positive_for_need_to_verify() {
        assert_lint_count(
            "I need to verify the expenses before submission.",
            NeedToNoun::default(),
            0,
        );
    }

    #[test]
    fn flags_need_to_compiler() {
        assert_suggestion_result(
            "We simply don't need to compiler to do as much work anymore.",
            NeedToNoun::default(),
            "We simply don't need the compiler to do as much work anymore.",
        );
    }

    #[test]
    fn catches_false_negative_for_need_to_credentials() {
        assert_suggestion_result(
            "I need to credentials before logging in.",
            NeedToNoun::default(),
            "I need the credentials before logging in.",
        );
    }

    #[test]
    fn flags_need_to_report() {
        assert_suggestion_result(
            "We need to report before the meeting starts.",
            NeedToNoun::default(),
            "We need the report before the meeting starts.",
        );
    }

    #[test]
    fn flags_need_to_password() {
        assert_suggestion_result(
            "You need to password to access the server.",
            NeedToNoun::default(),
            "You need the password to access the server.",
        );
    }

    #[test]
    fn flags_need_to_data() {
        assert_suggestion_result(
            "They need to data analyzed by tomorrow.",
            NeedToNoun::default(),
            "They need the data analyzed by tomorrow.",
        );
    }

    #[test]
    fn flags_need_to_approval() {
        assert_suggestion_result(
            "She will need to approval of her manager first.",
            NeedToNoun::default(),
            "She will need the approval of her manager first.",
        );
    }

    #[test]
    fn flags_need_to_backup() {
        assert_suggestion_result(
            "We might need to backup if the main system fails.",
            NeedToNoun::default(),
            "We might need the backup if the main system fails.",
        );
    }

    #[test]
    fn flags_need_to_permit() {
        assert_suggestion_result(
            "He didn’t realize he would need to permit to film there.",
            NeedToNoun::default(),
            "He didn’t realize he would need the permit to film there.",
        );
    }

    #[test]
    fn flags_need_to_tools() {
        assert_suggestion_result(
            "You’ll need to right tools to fix that.",
            NeedToNoun::default(),
            "You’ll need the right tools to fix that.",
        );
    }

    #[test]
    fn flags_need_to_context() {
        assert_suggestion_result(
            "We need to context to make sense of his decision.",
            NeedToNoun::default(),
            "We need the context to make sense of his decision.",
        );
    }

    #[test]
    fn flags_need_to_funds() {
        assert_suggestion_result(
            "They need to funds released before construction begins.",
            NeedToNoun::default(),
            "They need the funds released before construction begins.",
        );
    }

    #[test]
    fn flags_need_to_silence() {
        assert_suggestion_result(
            "I need to silence to think clearly.",
            NeedToNoun::default(),
            "I need the silence to think clearly.",
        );
    }

    #[test]
    fn flags_needs_to_approval() {
        assert_suggestion_result(
            "She needs to approval from her advisor.",
            NeedToNoun::default(),
            "She needs the approval from her advisor.",
        );
    }

    #[test]
    fn avoids_false_positive_for_needs_to_coordinate() {
        assert_lint_count(
            "She needs to collaborate with everyone on the plan.",
            NeedToNoun::default(),
            0,
        );
    }

    #[test]
    fn catches_false_negative_for_needs_to_credentials() {
        assert_suggestion_result(
            "He needs to credentials ready before the audit.",
            NeedToNoun::default(),
            "He needs the credentials ready before the audit.",
        );
    }

    #[test]
    fn allows_needs_to_finalize() {
        assert_lint_count(
            "She needs to finalize the schedule.",
            NeedToNoun::default(),
            0,
        );
    }

    #[test]
    fn flags_needed_to_permit() {
        assert_suggestion_result(
            "They needed to permit before entering the site.",
            NeedToNoun::default(),
            "They needed the permit before entering the site.",
        );
    }

    #[test]
    fn avoids_false_positive_for_needed_to_explain() {
        assert_lint_count(
            "They needed to explain the new policy carefully.",
            NeedToNoun::default(),
            0,
        );
    }

    #[test]
    fn catches_false_negative_for_needed_to_authorization() {
        assert_suggestion_result(
            "They needed to authorization before proceeding.",
            NeedToNoun::default(),
            "They needed the authorization before proceeding.",
        );
    }

    #[test]
    fn allows_needed_to_file() {
        assert_lint_count(
            "They needed to file the paperwork before noon.",
            NeedToNoun::default(),
            0,
        );
    }

    #[test]
    fn flags_needing_to_documentation() {
        assert_suggestion_result(
            "Needing to documentation slowed the entire process.",
            NeedToNoun::default(),
            "Needing the documentation slowed the entire process.",
        );
    }

    #[test]
    fn avoids_false_positive_for_needing_to_calibrate() {
        assert_lint_count(
            "Needing to calibrate the equipment delayed us slightly.",
            NeedToNoun::default(),
            0,
        );
    }

    #[test]
    fn catches_false_negative_for_needing_to_confirmation() {
        assert_suggestion_result(
            "Needing to confirmation from legal stalled the launch.",
            NeedToNoun::default(),
            "Needing the confirmation from legal stalled the launch.",
        );
    }

    #[test]
    fn allows_needing_to_call() {
        assert_lint_count(
            "Needing to call your mother is stressful.",
            NeedToNoun::default(),
            0,
        );
    }

    #[test]
    fn allows_issue_2252() {
        assert_no_lints("Things I need to do today:", NeedToNoun::default());
    }

    #[test]
    fn allows_install() {
        assert_no_lints(
            "You need to install it separately, as it's a standalone application.",
            NeedToNoun::default(),
        );
    }

    #[test]
    fn allows_lay() {
        assert_no_lints(
            "Okay, this is a long one, but I feel like I need to lay everything out.",
            NeedToNoun::default(),
        );
    }

    #[test]
    fn allows_overcome() {
        assert_no_lints(
            "We believe every family deserves the opportunity to flourish, and we are committed to providing the resources they need to overcome adversity.",
            NeedToNoun::default(),
        );
    }

    #[test]
    fn allows_need_to_run_into_2433() {
        assert_no_lints(
            "So that they don't need to run into this problem in the future.",
            NeedToNoun::default(),
        );
    }

    #[test]
    fn allows_need_to_match_2446() {
        assert_no_lints(
            "You don't need to match string errors explicitly.",
            NeedToNoun::default(),
        );
    }

    #[test]
    fn allows_need_to_match_exactly_2446() {
        assert_no_lints("They need to match exactly.", NeedToNoun::default());
    }
}



================================================
FILE: harper-core/src/linting/no_french_spaces.rs
================================================
use super::{Lint, LintKind, Linter, Suggestion};
use crate::TokenStringExt;
use crate::{Document, TokenKind};

#[derive(Debug, Default)]
pub struct NoFrenchSpaces;

impl Linter for NoFrenchSpaces {
    fn lint(&mut self, document: &Document) -> Vec<Lint> {
        let mut output = Vec::new();

        for sentence in document.iter_sentences() {
            if let Some(space_idx) = sentence.iter_space_indices().next() {
                let space = &sentence[space_idx];

                if matches!(space.kind, TokenKind::Space(0)) {
                    continue;
                }
                if space_idx == 0 && space.span.len() != 1 {
                    output.push(Lint {
                        span: space.span,
                        lint_kind: LintKind::Formatting,
                        suggestions: vec![Suggestion::ReplaceWith(vec![' '])],
                        message: "French spaces are generally not recommended.".to_owned(),
                        priority: 15,
                    })
                }
            }
        }

        output
    }

    fn description(&self) -> &str {
        "Stops users from accidentally inserting French spaces."
    }
}

#[cfg(test)]
mod tests {
    use crate::linting::tests::assert_suggestion_result;

    use super::NoFrenchSpaces;

    #[test]
    fn fixes_basic() {
        assert_suggestion_result(
            "This is a short sentence.  This is another short sentence.",
            NoFrenchSpaces::default(),
            "This is a short sentence. This is another short sentence.",
        );
    }
}



================================================
FILE: harper-core/src/linting/no_match_for.rs
================================================
use crate::linting::expr_linter::Chunk;
use crate::{
    CharStringExt, Token, TokenStringExt,
    expr::{Expr, FirstMatchOf, SequenceExpr},
    linting::{ExprLinter, Lint, LintKind, Suggestion},
    patterns::{InflectionOfBe, WordSet},
};

pub struct NoMatchFor {
    expr: Box<dyn Expr>,
}

impl Default for NoMatchFor {
    fn default() -> Self {
        let pre_context = FirstMatchOf::new(vec![
            Box::new(InflectionOfBe::default()),
            Box::new(WordSet::new(&[
                "I'm", "we're", "you're", "he's", "she's", "it's", "they're", "Im", "were",
                "youre", "hes", "shes", "its", "theyre",
            ])),
        ]);

        let expr = SequenceExpr::default()
            .then(pre_context)
            .then_whitespace()
            .t_aco("no")
            .then_whitespace()
            .t_aco("match")
            .then_whitespace()
            .then_preposition();

        Self {
            expr: Box::new(expr),
        }
    }
}

impl ExprLinter for NoMatchFor {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, toks: &[Token], src: &[char]) -> Option<Lint> {
        let prep_tok = toks.last()?;
        let prep_chars = prep_tok.span.get_content(src);
        if prep_chars.eq_ignore_ascii_case_chars(&['f', 'o', 'r']) {
            return None;
        }

        let phrase_toks = &toks[2..];
        let phrase_span = phrase_toks.span()?;

        let suggestion =
            Suggestion::replace_with_match_case_str("no match for", phrase_span.get_content(src));

        Some(Lint {
            span: phrase_span,
            lint_kind: LintKind::WordChoice,
            suggestions: vec![suggestion],
            message: "If you mean the idiom, it's `no match for`.".to_owned(),
            priority: 55,
        })
    }

    fn description(&self) -> &str {
        "No match for"
    }
}

#[cfg(test)]
pub mod tests {
    use super::NoMatchFor;
    use crate::linting::tests::{assert_lint_count, assert_suggestion_result};

    #[test]
    fn fix_against() {
        assert_suggestion_result(
            "Erlang was no match against my sweeping gale.",
            NoMatchFor::default(),
            "Erlang was no match for my sweeping gale.",
        );
    }

    #[test]
    fn fix_to() {
        assert_suggestion_result(
            "My BW5 was no match to his BW7.",
            NoMatchFor::default(),
            "My BW5 was no match for his BW7.",
        );
    }

    #[test]
    fn fix_of() {
        assert_suggestion_result(
            "This Attack Plane Was No Match Of Me So I Did This To Him",
            NoMatchFor::default(),
            "This Attack Plane Was No Match For Me So I Did This To Him",
        );
    }

    #[test]
    fn fix_its_to() {
        assert_suggestion_result(
            "cuz AI is bull crap and its no match to human voice",
            NoMatchFor::default(),
            "cuz AI is bull crap and its no match for human voice",
        );
    }

    #[test]
    fn fix_im_to() {
        assert_suggestion_result(
            "Im no match to you but like let me no what u think",
            NoMatchFor::default(),
            "Im no match for you but like let me no what u think",
        );
    }

    #[test]
    fn theyre_to() {
        assert_suggestion_result(
            "Theyre no match to late 60s early 70s sansuis.",
            NoMatchFor::default(),
            "Theyre no match for late 60s early 70s sansuis.",
        );
    }

    #[test]
    fn fix_hes_to() {
        assert_suggestion_result(
            "Even ouki on drinks with renpa said hes no match to him.",
            NoMatchFor::default(),
            "Even ouki on drinks with renpa said hes no match for him.",
        );
    }

    #[test]
    fn fix_shes_to() {
        assert_suggestion_result(
            "Izma tries to struggle but she's no match to your superior strength",
            NoMatchFor::default(),
            "Izma tries to struggle but she's no match for your superior strength",
        );
    }

    #[test]
    fn dont_fix_for() {
        assert_lint_count(
            "Type to search appears even there is no match for search term when autoFocus is true.",
            NoMatchFor::default(),
            0,
        );
    }
}



================================================
FILE: harper-core/src/linting/no_oxford_comma.rs
================================================
use crate::expr::ExprExt;
use crate::expr::SequenceExpr;
use crate::{
    Document, Token, TokenStringExt,
    patterns::{NominalPhrase, WordSet},
};

use super::{Lint, LintKind, Linter, Suggestion};

pub struct NoOxfordComma {
    expr: SequenceExpr,
}

impl NoOxfordComma {
    pub fn new() -> Self {
        Self {
            expr: {
                let this = {
                    let this = SequenceExpr::default();
                    this.then(NominalPhrase)
                }
                .then_comma()
                .then_whitespace();
                this.then(NominalPhrase)
            }
            .then_comma()
            .then_whitespace()
            .then(WordSet::new(&["and", "or", "nor"])),
        }
    }

    fn match_to_lint(&self, matched_toks: &[Token], _source: &[char]) -> Option<Lint> {
        let last_comma_index = matched_toks.last_comma_index()?;
        let offender = &matched_toks[last_comma_index];

        Some(Lint {
            span: offender.span,
            lint_kind: LintKind::Style,
            suggestions: vec![Suggestion::Remove],
            message: "Remove the Oxford comma here.".to_owned(),
            priority: 31,
        })
    }
}

impl Default for NoOxfordComma {
    fn default() -> Self {
        Self::new()
    }
}

impl Linter for NoOxfordComma {
    fn lint(&mut self, document: &Document) -> Vec<Lint> {
        let mut lints = Vec::new();

        for sentence in document.iter_sentences() {
            for match_span in self.expr.iter_matches(sentence, document.get_source()) {
                let lint = self.match_to_lint(
                    &sentence[match_span.start..match_span.end],
                    document.get_source(),
                );
                lints.extend(lint);
            }
        }

        lints
    }

    fn description(&self) -> &str {
        "The Oxford comma is one of the more controversial rules in common use today. Enabling this lint checks that there is no comma before `and`, `or` or `nor` when listing out more than two ideas."
    }
}

#[cfg(test)]
mod tests {
    use crate::linting::tests::{assert_lint_count, assert_suggestion_result};

    use super::NoOxfordComma;

    #[test]
    fn fruits() {
        assert_lint_count(
            "An apple, a banana, and a pear",
            NoOxfordComma::default(),
            1,
        );
    }

    #[test]
    fn people() {
        assert_suggestion_result(
            "Nancy, Steve, and Carl are going to the coffee shop.",
            NoOxfordComma::default(),
            "Nancy, Steve and Carl are going to the coffee shop.",
        );
    }

    #[test]
    fn places() {
        assert_suggestion_result(
            "I've always wanted to visit Paris, Tokyo, and Rome.",
            NoOxfordComma::default(),
            "I've always wanted to visit Paris, Tokyo and Rome.",
        );
    }

    #[test]
    fn foods() {
        assert_suggestion_result(
            "My favorite foods are pizza, sushi, tacos, and burgers.",
            NoOxfordComma::default(),
            "My favorite foods are pizza, sushi, tacos and burgers.",
        );
    }

    #[test]
    fn allows_clean_music() {
        assert_lint_count(
            "I enjoy listening to pop music, rock, hip-hop, electronic dance and classical music.",
            NoOxfordComma::default(),
            0,
        );
    }

    #[test]
    fn allows_clean_nations() {
        assert_lint_count(
            "The team consists of players from different countries: France, Germany, Italy and Spain.",
            NoOxfordComma::default(),
            0,
        );
    }

    #[test]
    fn or_writing() {
        assert_suggestion_result(
            "Harper can be a lifesaver when writing technical documents, emails, or other formal forms of communication.",
            NoOxfordComma::default(),
            "Harper can be a lifesaver when writing technical documents, emails or other formal forms of communication.",
        );
    }

    #[test]
    fn sports() {
        assert_suggestion_result(
            "They enjoy playing soccer, basketball, or tennis.",
            NoOxfordComma::default(),
            "They enjoy playing soccer, basketball or tennis.",
        );
    }

    #[test]
    fn nor_vegetables() {
        assert_suggestion_result(
            "I like carrots, kale, nor broccoli.",
            NoOxfordComma::default(),
            "I like carrots, kale nor broccoli.",
        );
    }
}



================================================
FILE: harper-core/src/linting/nobody.rs
================================================
use crate::expr::Expr;
use crate::expr::SequenceExpr;
use crate::{Token, TokenStringExt};

use super::{ExprLinter, Lint, LintKind, Suggestion};
use crate::linting::expr_linter::Chunk;

pub struct Nobody {
    expr: Box<dyn Expr>,
}

impl Default for Nobody {
    fn default() -> Self {
        let pattern = SequenceExpr::aco("no")
            .then_whitespace()
            .t_aco("body")
            .then_whitespace()
            .then_verb();
        Self {
            expr: Box::new(pattern),
        }
    }
}

impl ExprLinter for Nobody {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], source: &[char]) -> Option<Lint> {
        let span = matched_tokens[0..3].span()?;
        let orig_chars = span.get_content(source);
        Some(Lint {
            span,
            lint_kind: LintKind::WordChoice,
            suggestions: vec![Suggestion::replace_with_match_case(
                "nobody".chars().collect(),
                orig_chars,
            )],
            message: format!("Did you mean the closed compound `{}`?", "nobody"),
            ..Default::default()
        })
    }

    fn description(&self) -> &'static str {
        "Looks for incorrect spacing inside the closed compound `nobody`."
    }
}

#[cfg(test)]
mod tests {
    use crate::linting::tests::assert_suggestion_result;

    use super::Nobody;

    #[test]
    fn both_valid_and_invalid() {
        assert_suggestion_result(
            "No body told me. I have a head but no body.",
            Nobody::default(),
            "Nobody told me. I have a head but no body.",
        );
    }
}



================================================
FILE: harper-core/src/linting/nominal_wants.rs
================================================
use harper_brill::UPOS;

use crate::CharStringExt;
use crate::expr::Expr;
use crate::expr::SequenceExpr;
use crate::linting::expr_linter::Chunk;
use crate::{
    Token,
    dict_word_metadata::Person,
    linting::{ExprLinter, Lint, LintKind, Suggestion},
    patterns::WordSet,
};

pub struct NominalWants {
    expr: Box<dyn Expr>,
}

impl Default for NominalWants {
    fn default() -> Self {
        fn is_applicable_pronoun(tok: &Token, src: &[char]) -> bool {
            if tok.kind.is_pronoun() && tok.kind.is_upos(UPOS::PRON) {
                let pron = tok.span.get_content(src);
                !pron.eq_any_ignore_ascii_case_chars(&[
                    // "That" can act as two kinds of pronoun: demonstrative and relative.
                    // As a demonstrative pronoun, it's third person singular.
                    // As a relative pronoun, it's behaves as any person:
                    // I am the one that wants to. He is the one that wants to.
                    &['t', 'h', 'a', 't'],
                    // Personal pronouns have case. Object case personal pronouns
                    // can come after "want":
                    // Make them want to believe.
                    // Note: "you" and "it" are both subject and object case.
                    &['m', 'e'],
                    &['u', 's'],
                    // "you" is subject and object both OK before "want".
                    &['h', 'i', 'm'],
                    &['h', 'e', 'r'],
                    // "it" is both subject and object. Subject before "wants", object before "want".
                    &['i', 't'],
                    &['t', 'h', 'e', 'm'],
                    &['w', 'h', 'o'],
                ])
            } else {
                false
            }
        }

        let miss = WordSet::new(&["wont", "wonts", "want", "wants"]);
        let pattern = SequenceExpr::default()
            .then(is_applicable_pronoun)
            .then_whitespace()
            .then(miss);

        Self {
            expr: Box::new(pattern),
        }
    }
}

impl ExprLinter for NominalWants {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, toks: &[Token], source: &[char]) -> Option<Lint> {
        let subject = toks.first()?;
        let offender = &toks.last()?;

        let plural = subject.kind.is_plural_nominal();

        let person = subject
            .kind
            .as_word()
            .unwrap()
            .clone()
            .unwrap()
            .pronoun
            .and_then(|p| p.person)
            .unwrap_or(Person::Third);

        let replacement = if person == Person::Third {
            if plural { "want" } else { "wants" }
        } else {
            "want"
        };

        let replacement_chars: Vec<char> = replacement.chars().collect();

        let offender_span = offender.span;
        let offender_chars = offender_span.get_content(source);

        if offender_chars.eq_ignore_ascii_case_chars(&replacement_chars) {
            return None;
        }

        Some(Lint {
            span: offender_span,
            lint_kind: LintKind::Miscellaneous,
            suggestions: vec![Suggestion::replace_with_match_case(
                replacement_chars,
                offender_chars,
            )],
            message: format!("Did you mean `{replacement}`?"),
            priority: 55,
        })
    }

    fn description(&self) -> &str {
        "Ensures you use the correct `want` / `wants` after a nominal."
    }
}

#[cfg(test)]
mod tests {
    use super::NominalWants;
    use crate::linting::tests::{assert_lint_count, assert_no_lints, assert_suggestion_result};

    #[test]
    fn fixes_he_wonts() {
        assert_suggestion_result(
            "He wonts to join us.",
            NominalWants::default(),
            "He wants to join us.",
        );
    }

    #[test]
    #[ignore = "This is not a grammar error if the previous word is `help`, `let`, or `make`."]
    fn fixes_it_wont() {
        assert_suggestion_result(
            "It wont to move forward.",
            NominalWants::default(),
            "It wants to move forward.",
        );
    }

    #[test]
    fn fixes_she_wont() {
        assert_suggestion_result(
            "She wont to leave early.",
            NominalWants::default(),
            "She wants to leave early.",
        );
    }

    #[test]
    fn fixes_i_wont() {
        assert_suggestion_result(
            "I wonts to leave early.",
            NominalWants::default(),
            "I want to leave early.",
        );
    }

    #[test]
    fn allows_you_want() {
        assert_lint_count("What size do you want to be?", NominalWants::default(), 0);
    }

    #[test]
    fn fixes_you_wants() {
        assert_suggestion_result(
            "What do you wants?",
            NominalWants::default(),
            "What do you want?",
        );
    }

    #[test]
    fn ignores_correct_usage_they() {
        assert_lint_count("They want to help.", NominalWants::default(), 0);
    }

    #[test]
    fn ignores_correct_usage_he() {
        assert_lint_count("He wants to help.", NominalWants::default(), 0);
    }

    #[test]
    fn ignores_correct_usage_that_1298() {
        assert_lint_count(
            "The projects that want to take it seriously are the best.",
            NominalWants::default(),
            0,
        );
    }

    #[test]
    fn ignores_correct_usage_make_me() {
        assert_lint_count(
            "Take another person code make me want to die.",
            NominalWants::default(),
            0,
        );
    }

    #[test]
    fn ignores_correct_usage_makes_me() {
        assert_lint_count(
            "It makes me want to not use GitHub at all.",
            NominalWants::default(),
            0,
        );
    }

    #[test]
    fn ignores_correct_usage_make_us() {
        assert_lint_count(
            "... try harder to make us want to implement it.",
            NominalWants::default(),
            0,
        );
    }

    #[test]
    fn ignores_correct_usage_made_us() {
        assert_lint_count(
            "This change made us want to adopt luxon's strict mode",
            NominalWants::default(),
            0,
        );
    }

    #[test]
    fn ignores_correct_usage_help_us() {
        assert_lint_count("... help us want to help you.", NominalWants::default(), 0);
    }

    #[test]
    fn ignores_correct_usage_make_you() {
        assert_lint_count(
            "I can certainly see why that would make you want to ditch Linux packaging.",
            NominalWants::default(),
            0,
        );
    }

    #[test]
    fn ignores_correct_usage_makes_you() {
        assert_lint_count(
            "If something happens that makes you want to scream from the top of your lungs",
            NominalWants::default(),
            0,
        );
    }

    #[test]
    fn ignores_correct_usage_made_you() {
        assert_lint_count(
            "What made you want to leave the LibFuzzer ...",
            NominalWants::default(),
            0,
        );
    }

    #[test]
    fn ignores_correct_usage_make_him() {
        assert_lint_count(
            "make him want to help with your issue",
            NominalWants::default(),
            0,
        );
    }

    #[test]
    fn ignores_correct_usage_make_her() {
        assert_lint_count(
            "... and make her want to get into coding.",
            NominalWants::default(),
            0,
        );
    }

    #[test]
    fn ignores_correct_usage_make_it() {
        assert_lint_count(
            "you just make it want to appear as a drama",
            NominalWants::default(),
            0,
        );
    }

    #[test]
    fn ignores_correct_usage_makes_it() {
        assert_lint_count(
            "using UHD makes it want to put labels in the corner saying UHD",
            NominalWants::default(),
            0,
        );
    }

    #[test]
    fn ignores_correct_usage_make_them() {
        assert_lint_count(
            "And make them want to believe in it.",
            NominalWants::default(),
            0,
        )
    }

    #[test]
    fn ignores_correct_usage_making_them() {
        assert_lint_count(
            "you're annoying ALMOST ALL of the users and making them want to switch to another ...",
            NominalWants::default(),
            0,
        )
    }

    #[test]
    fn ignores_correct_usage_help_them() {
        assert_lint_count("And help them want to do it.", NominalWants::default(), 0)
    }

    #[test]
    fn allows_want_to() {
        assert_no_lints(
            "Harper is a grammar checker for people who want to write fast.",
            NominalWants::default(),
        );
    }

    #[test]
    fn test_2007() {
        assert_no_lints(
            "### 🙌 **We Want to Hear From You!**",
            NominalWants::default(),
        )
    }
}



================================================
FILE: harper-core/src/linting/nor_modal_pronoun.rs
================================================
use crate::{
    Lint, Token, TokenStringExt,
    expr::{Expr, SequenceExpr},
    linting::{ExprLinter, LintKind, Suggestion, expr_linter::Chunk},
    patterns::ModalVerb,
};

pub struct NorModalPronoun {
    expr: Box<dyn Expr>,
}

impl Default for NorModalPronoun {
    fn default() -> Self {
        Self {
            expr: Box::new(
                SequenceExpr::aco("nor")
                    .t_ws()
                    .then_subject_pronoun()
                    .t_ws()
                    .then(ModalVerb::with_common_errors()),
            ),
        }
    }
}

impl ExprLinter for NorModalPronoun {
    type Unit = Chunk;

    fn description(&self) -> &str {
        "Corrects the order of the pronoun and modal verb after `nor`."
    }

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint_with_context(
        &self,
        toks: &[Token],
        src: &[char],
        ctx: Option<(&[Token], &[Token])>,
    ) -> Option<Lint> {
        if ctx
            .map(|(pre, _)| {
                // Check for pattern 1: subject pronoun [ws]
                let is_subj_pronoun = pre
                    .get_rel(-1)
                    .filter(|t| t.kind.is_whitespace())
                    .and_then(|_| pre.get_rel(-2))
                    .is_some_and(|t| t.kind.is_subject_pronoun());

                // Check for pattern 2: possessive [ws] noun [ws]
                let is_poss_and_noun = pre
                    .get_rel(-1)
                    .filter(|t| t.kind.is_whitespace())
                    .and_then(|_| pre.get_rel(-2))
                    .filter(|t| t.kind.is_noun())
                    .and_then(|_| pre.get_rel(-3))
                    .filter(|t| t.kind.is_whitespace())
                    .and_then(|_| pre.get_rel(-4))
                    .is_some_and(|t| t.kind.is_possessive_determiner());

                is_subj_pronoun || is_poss_and_noun
            })
            .unwrap_or(false)
        {
            return None;
        }

        let (pron_tok, modal_tok) = (toks.get_rel(-3)?, toks.get_rel(-1)?);
        let pron_ws_modal_toks = toks.get_rel_slice(-3, -1)?;
        let (pron_span, modal_span) = (pron_tok.span, modal_tok.span);
        let pron_modal_span = pron_ws_modal_toks.span()?;

        let value = format!(
            "{} {}",
            modal_span.get_content_string(src),
            pron_span.get_content_string(src)
        )
        .chars()
        .collect();

        // Avoid capitalizing the modals verbs just because the pronoun was "I"
        let suggestion = if pron_span.get_content(src) == ['I'] {
            Suggestion::ReplaceWith(value)
        } else {
            Suggestion::replace_with_match_case(value, pron_modal_span.get_content(src))
        };

        Some(Lint {
            span: pron_modal_span,
            lint_kind: LintKind::Grammar,
            suggestions: vec![suggestion],
            message: "After `nor`, the modal verb should come before the pronoun.".to_string(),
            ..Default::default()
        })
    }
}

#[cfg(test)]
mod tests {
    use super::NorModalPronoun;
    use crate::linting::tests::{assert_no_lints, assert_suggestion_result};

    #[test]
    fn fix_nor_i_can() {
        assert_suggestion_result(
            "i can't see the menu nor i can see the features of your app or how it looks !",
            NorModalPronoun::default(),
            "i can't see the menu nor can i see the features of your app or how it looks !",
        );
    }

    #[test]
    fn fix_nor_i_could() {
        assert_suggestion_result(
            "but never saw any warnings nor I could read messages until I debugged",
            NorModalPronoun::default(),
            "but never saw any warnings nor could I read messages until I debugged",
        );
    }

    #[test]
    fn fix_nor_i_will() {
        assert_suggestion_result(
            "I am not the author of the plugins nor I will be updating bugged/unavailable plugins.",
            NorModalPronoun::default(),
            "I am not the author of the plugins nor will I be updating bugged/unavailable plugins.",
        );
    }

    #[test]
    fn fix_nor_i_would() {
        assert_suggestion_result(
            "I would not like to own a Pollock, nor I would hang one of his paintings on a wall inside my home",
            NorModalPronoun::default(),
            "I would not like to own a Pollock, nor would I hang one of his paintings on a wall inside my home",
        );
    }

    #[test]
    fn fix_nor_it_can() {
        assert_suggestion_result(
            "However, since several days ago FreeTube simply doesn't open ANY videos nor it can search.",
            NorModalPronoun::default(),
            "However, since several days ago FreeTube simply doesn't open ANY videos nor can it search.",
        );
    }

    #[test]
    fn fix_nor_it_should() {
        assert_suggestion_result(
            "Since the code doesn't guard against it (nor it should), internalModule.stripBOM is called with an undefined",
            NorModalPronoun::default(),
            "Since the code doesn't guard against it (nor should it), internalModule.stripBOM is called with an undefined",
        );
    }

    #[test]
    fn fix_nor_it_will() {
        assert_suggestion_result(
            "It will never \"create a table\", nor it will issue any query - it will only create the entity instance.",
            NorModalPronoun::default(),
            "It will never \"create a table\", nor will it issue any query - it will only create the entity instance.",
        );
    }

    #[test]
    fn fix_nor_it_would() {
        assert_suggestion_result(
            "Neither whitespace (excepting NL and CR) is special char in this sense, nor it would destroy something, if it gets \"escaped\" as variable",
            NorModalPronoun::default(),
            "Neither whitespace (excepting NL and CR) is special char in this sense, nor would it destroy something, if it gets \"escaped\" as variable",
        );
    }

    #[test]
    fn fix_nor_they_can() {
        assert_suggestion_result(
            "Currently these assets don't include the code provided by the submodules nor they can be disabled",
            NorModalPronoun::default(),
            "Currently these assets don't include the code provided by the submodules nor can they be disabled",
        );
    }

    #[test]
    fn fix_nor_we_can() {
        assert_suggestion_result(
            "The NSLayoutConstraint errors are really Apple bugs, not our fault, nor we can fix them, but they are harmless.",
            NorModalPronoun::default(),
            "The NSLayoutConstraint errors are really Apple bugs, not our fault, nor can we fix them, but they are harmless.",
        );
    }

    #[test]
    fn fix_nor_you_can() {
        assert_suggestion_result(
            "You cannot create a view to do it, nor you can have a function to do it",
            NorModalPronoun::default(),
            "You cannot create a view to do it, nor can you have a function to do it",
        );
    }

    #[test]
    fn fix_nor_you_should() {
        assert_suggestion_result(
            "I believe you cannot create two sessions through one signin, and maybe nor you should.",
            NorModalPronoun::default(),
            "I believe you cannot create two sessions through one signin, and maybe nor should you.",
        );
    }

    // Potential false positives

    #[test]
    fn ignore_neither_they_nor_i_could() {
        assert_no_lints(
            "One of my users was unable to install tools via mise, but neither they nor I could initially figure out why.",
            NorModalPronoun::default(),
        );
    }

    #[test]
    fn ignore_neither_my_tool_nor_i_shall() {
        assert_no_lints(
            "but neither my tool nor I shall feel disrespected",
            NorModalPronoun::default(),
        );
    }
}



================================================
FILE: harper-core/src/linting/number_suffix_capitalization.rs
================================================
use super::{Lint, LintKind, Linter, Suggestion};
use crate::{Document, Span, TokenKind};
use crate::{Number, TokenStringExt};

/// Detect incorrect capitalization for number suffixes (e.g. "2ND").
#[derive(Debug, Clone, Copy, Default)]
pub struct NumberSuffixCapitalization;

impl Linter for NumberSuffixCapitalization {
    fn lint(&mut self, document: &Document) -> Vec<Lint> {
        let mut output = Vec::new();

        for number_tok in document.iter_numbers() {
            if let TokenKind::Number(Number { suffix: None, .. }) = number_tok.kind {
                continue;
            }

            let suffix_span = Span::new_with_len(number_tok.span.end, 2)
                .pulled_by(2)
                .unwrap();
            let chars = document.get_span_content(&suffix_span);

            if chars.iter().any(|c| !c.is_lowercase()) {
                output.push(Lint {
                    span: suffix_span,
                    lint_kind: LintKind::Capitalization,
                    message: "This suffix should be lowercase".to_string(),
                    suggestions: vec![Suggestion::ReplaceWith(
                        chars.iter().map(|c| c.to_ascii_lowercase()).collect(),
                    )],
                    ..Default::default()
                })
            }
        }

        output
    }

    fn description(&self) -> &'static str {
        "You should never capitalize number suffixes."
    }
}

#[cfg(test)]
mod tests {
    use super::NumberSuffixCapitalization;
    use crate::linting::tests::assert_lint_count;

    #[test]
    fn detects_uppercase_suffix() {
        assert_lint_count("2ND", NumberSuffixCapitalization, 1);
    }

    #[test]
    fn detects_inconsistent_suffix() {
        assert_lint_count("2nD", NumberSuffixCapitalization, 1);
    }

    #[test]
    fn passes_correct_case() {
        assert_lint_count("2nd", NumberSuffixCapitalization, 0);
    }
}



================================================
FILE: harper-core/src/linting/obsess_preposition.rs
================================================
use crate::{
    CharStringExt, Lint, Token,
    expr::{Expr, SequenceExpr},
    linting::{ExprLinter, LintKind, Suggestion, expr_linter::Chunk},
};

pub struct ObsessPreposition {
    expr: Box<dyn Expr>,
}

impl Default for ObsessPreposition {
    fn default() -> Self {
        Self {
            expr: Box::new(
                SequenceExpr::word_set(&["obsess", "obsessed", "obsesses", "obsessing"])
                    .t_ws()
                    .then_preposition(),
            ),
        }
    }
}

impl ExprLinter for ObsessPreposition {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn description(&self) -> &str {
        "Ensures valid prepositions are used with `obsess`"
    }

    fn match_to_lint(&self, toks: &[Token], src: &[char]) -> Option<Lint> {
        let verb_idx = 0;
        let verb_tok = toks.get(verb_idx)?;
        let verb_span = verb_tok.span;
        let verb_chars = verb_span.get_content(src);

        let prep_idx = toks.len() - 1;
        let prep_tok = toks.get(prep_idx)?;
        let prep_span = prep_tok.span;
        let prep_chars = prep_span.get_content(src);

        #[derive(PartialEq)]
        enum Conj {
            Lemma,
            Ed,
            Es,
            Ing,
        }

        let conj = if verb_chars.ends_with_ignore_ascii_case_chars(&['e', 'd']) {
            Conj::Ed
        } else if verb_chars.ends_with_ignore_ascii_case_chars(&['e', 's']) {
            Conj::Es
        } else if verb_chars.ends_with_ignore_ascii_case_chars(&['i', 'n', 'g']) {
            Conj::Ing
        } else {
            Conj::Lemma
        };

        // 👍
        // obsess* over - pay close attention to details
        // obsessed with - excessively preoccupied with
        // 👎
        // obsessed of

        if prep_chars.eq_ignore_ascii_case_str("over") {
            return None;
        }

        if conj == Conj::Ed && prep_chars.eq_ignore_ascii_case_str("with") {
            return None;
        }

        let ok_prep_vec: &[&str] = if conj == Conj::Ed {
            &["over", "with"]
        } else {
            &["over"]
        };

        let suggestions = ok_prep_vec
            .iter()
            .map(|p| Suggestion::replace_with_match_case(p.chars().collect(), prep_chars))
            .collect();

        let message = if ok_prep_vec.len() == 1 {
            "Use 'over' instead of 'with'".to_string()
        } else {
            "For `excessively preoccupied with` use `obsessed with`. For `paid close attention to details` use `obsessed over`".to_string()
        };

        Some(Lint {
            span: prep_span,
            lint_kind: LintKind::Usage,
            suggestions,
            message,
            ..Default::default()
        })
    }
}

#[cfg(test)]
mod tests {
    use super::ObsessPreposition;
    use crate::linting::tests::{assert_suggestion_result, assert_top3_suggestion_result};

    #[test]
    fn fix_obsess_on() {
        assert_suggestion_result(
            "Obsess on collecting good answers and you might be precise but irrelevant.",
            ObsessPreposition::default(),
            "Obsess over collecting good answers and you might be precise but irrelevant.",
        );
    }

    #[test]
    fn fix_obsessing_on() {
        assert_suggestion_result(
            "Obsessing on finding new solutions to old problems with AI.",
            ObsessPreposition::default(),
            "Obsessing over finding new solutions to old problems with AI.",
        );
    }

    #[test]
    fn fix_obsessing_with() {
        assert_suggestion_result(
            "I spent too long checking my code over and over, obsessing with just what might cause this",
            ObsessPreposition::default(),
            "I spent too long checking my code over and over, obsessing over just what might cause this",
        );
    }

    #[test]
    fn fix_obsess_with() {
        assert_suggestion_result(
            "And as a programmer I've been taught to obsess with that.",
            ObsessPreposition::default(),
            "And as a programmer I've been taught to obsess over that.",
        );
    }

    #[test]
    fn fix_obsesses_with() {
        assert_suggestion_result(
            "Every developer obsesses with micro-optimizations must be made to read it over and over again.",
            ObsessPreposition::default(),
            "Every developer obsesses over micro-optimizations must be made to read it over and over again.",
        );
    }

    #[test]
    fn fix_obsessed_on() {
        assert_top3_suggestion_result(
            "Secondly, if you get obsessed on any idea, then delve in it and don't worry about anything others until you get there.",
            ObsessPreposition::default(),
            "Secondly, if you get obsessed with any idea, then delve in it and don't worry about anything others until you get there.",
        );
    }
}



================================================
FILE: harper-core/src/linting/of_course.rs
================================================
//! Corrects "of curse/corse" to "of course" while ignoring phrases like "kind of curse".
//!
//! See also:
//! - `OfCourse` in `phrase_corrections` for "off course" / "o course" / "ofcourse" → "of course" corrections.

use crate::expr::Expr;
use crate::expr::SequenceExpr;
use crate::linting::expr_linter::Chunk;
use crate::{
    Token,
    linting::{ExprLinter, Lint, LintKind, Suggestion},
    patterns::WordSet,
};

pub struct OfCourse {
    expr: Box<dyn Expr>,
}

impl Default for OfCourse {
    fn default() -> Self {
        let wrong_forms = WordSet::new(&["curse", "corse"]);
        let expr = SequenceExpr::default()
            .t_aco("of")
            .then_whitespace()
            .then(wrong_forms);

        Self {
            expr: Box::new(expr),
        }
    }
}

impl ExprLinter for OfCourse {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched: &[Token], source: &[char]) -> Option<Lint> {
        // Skip if the word before “of” is “kind” or “sort” → “kind of curse” is valid.
        if let Some(of_idx) = matched.first().map(|t| t.span.start)
            && let Some(prev) = source.get(..of_idx).map(|src| {
                // Walk backwards over whitespace to find the preceding word token.
                let mut i = of_idx.saturating_sub(1);
                while i > 0 && src[i].is_whitespace() {
                    i -= 1;
                }
                // Return slice ending with that char to build a small string.
                let start = src[..=i]
                    .iter()
                    .rposition(|c| c.is_whitespace())
                    .map(|p| p + 1)
                    .unwrap_or(0);
                src[start..=i].iter().collect::<String>()
            })
        {
            let lower = prev.to_ascii_lowercase();
            if lower == "kind" || lower == "sort" {
                return None;
            }
        }

        let typo_span = matched.last()?.span;
        let original = typo_span.get_content(source);

        Some(Lint {
            span: typo_span,
            lint_kind: LintKind::WordChoice,
            suggestions: vec![Suggestion::replace_with_match_case(
                "course".chars().collect(),
                original,
            )],
            message: "Did you mean “of **course**” (= clearly) instead of “of curse / corse”?"
                .to_string(),
            priority: 31,
        })
    }

    fn description(&self) -> &str {
        "Corrects the common eggcorn “of curse / corse” to “of course,” ignoring phrases like “kind of curse.”"
    }
}

#[cfg(test)]
mod tests {
    use super::OfCourse;
    use crate::linting::tests::{assert_lint_count, assert_suggestion_result};

    #[test]
    fn flags_of_curse() {
        assert_suggestion_result("Yes, of curse!", OfCourse::default(), "Yes, of course!");
    }

    #[test]
    fn flags_of_corse() {
        assert_suggestion_result(
            "Well, of corse we can.",
            OfCourse::default(),
            "Well, of course we can.",
        );
    }

    #[test]
    fn ignores_kind_of_curse() {
        assert_lint_count("This kind of curse is dangerous.", OfCourse::default(), 0);
    }

    #[test]
    fn ignores_sort_of_curse() {
        assert_lint_count("It's a sort of curse that lingers.", OfCourse::default(), 0);
    }

    #[test]
    fn ignores_curse_of_title() {
        assert_lint_count(
            "The Curse of Strahd is a famous module.",
            OfCourse::default(),
            0,
        );
    }
}



================================================
FILE: harper-core/src/linting/oldest_in_the_book.rs
================================================
use crate::{
    CharStringExt, Lint, Token,
    expr::{Expr, Repeating, SequenceExpr},
    linting::{ExprLinter, LintKind, Suggestion, expr_linter::Chunk},
};

pub struct OldestInTheBook {
    expr: Box<dyn Expr>,
}

impl Default for OldestInTheBook {
    fn default() -> Self {
        let adj = |t: &Token, s: &[char]| {
            let k = &t.kind;
            (k.is_np_member() || k.is_adjective())
                && !k.is_noun()
                && !t
                    .span
                    .get_content(s)
                    .eq_ignore_ascii_case_chars(&['i', 'n'])
        };

        // Zero or more adjectives
        let adjseq = Repeating::new(Box::new(SequenceExpr::default().then(adj).t_ws()), 0);

        let noun = |t: &Token, s: &[char]| {
            let k = &t.kind;
            (k.is_np_member() || k.is_noun() || k.is_oov())
                && !t
                    .span
                    .get_content(s)
                    .eq_ignore_ascii_case_chars(&['i', 'n'])
        };

        // One or more nouns
        let nounseq = SequenceExpr::default()
            .then(noun)
            .then_optional(Repeating::new(
                Box::new(SequenceExpr::default().t_ws().then(noun)),
                1,
            ));

        let noun_phrase = SequenceExpr::default().then_optional(adjseq).then(nounseq);

        Self {
            expr: Box::new(
                SequenceExpr::fixed_phrase("oldest ")
                    .then(noun_phrase)
                    .then_fixed_phrase(" in the books"),
            ),
        }
    }
}

impl ExprLinter for OldestInTheBook {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint_with_context(
        &self,
        toks: &[Token],
        src: &[char],
        _ctx: Option<(&[Token], &[Token])>,
    ) -> Option<Lint> {
        let np = &toks[2..toks.len() - 4];
        let tricky = np.iter().any(|n| {
            n.span
                .get_content(src)
                .eq_any_ignore_ascii_case_str(&["trick", "tricks"])
        });

        let message = if tricky {
            "This idiom should use singular `book` instead of plural `books`."
        } else {
            "If this is a play on the idiom `oldest trick in the book`, it should use singular `book` instead of plural `books`."
        }
        .to_string();

        Some(Lint {
            span: toks.last()?.span,
            lint_kind: LintKind::Usage,
            suggestions: vec![Suggestion::replace_with_match_case_str(
                "book",
                toks.last()?.span.get_content(src),
            )],
            message,
            ..Default::default()
        })
    }

    fn description(&self) -> &'static str {
        "Detects the idiom `oldest X in the books`, which should use singular `book`."
    }
}

#[cfg(test)]
mod tests {
    use super::OldestInTheBook;
    use crate::linting::tests::{assert_lint_message, assert_suggestion_result};

    // Probable references to the idiom "oldest trick in the book"

    #[test]
    fn fix_delphi_mistake() {
        assert_suggestion_result(
            "This is the oldest Delphi mistake in the books and I'm sure you've made it before (we all have), and I'm sure you recognise it when you see it.",
            OldestInTheBook::default(),
            "This is the oldest Delphi mistake in the book and I'm sure you've made it before (we all have), and I'm sure you recognise it when you see it.",
        );
    }

    #[test]
    fn fix_trick() {
        assert_suggestion_result(
            "... oldest trick in the books, a restart and it works all the times(for now).",
            OldestInTheBook::default(),
            "... oldest trick in the book, a restart and it works all the times(for now).",
        );
    }

    #[test]
    fn fix_virus_trick() {
        assert_suggestion_result(
            "Once the OS is started the MBR is typically protected for virus reasons - this is one of the oldest virus tricks in the books - goes back to ...",
            OldestInTheBook::default(),
            "Once the OS is started the MBR is typically protected for virus reasons - this is one of the oldest virus tricks in the book - goes back to ...",
        )
    }

    #[test]
    fn fix_mistake() {
        assert_suggestion_result(
            "Ok, I realized now that I was making the oldest mistake in the books with my code, dividing my v by 2 instead of dividing it by 5.",
            OldestInTheBook::default(),
            "Ok, I realized now that I was making the oldest mistake in the book with my code, dividing my v by 2 instead of dividing it by 5.",
        );
    }

    #[test]
    fn fix_tricks() {
        assert_suggestion_result(
            "He enables the oldest tricks in the books, create fear from thing like prosperity (we really don't need Foxconn?)",
            OldestInTheBook::default(),
            "He enables the oldest tricks in the book, create fear from thing like prosperity (we really don't need Foxconn?)",
        );
    }

    #[test]
    fn fix_military_plays() {
        assert_suggestion_result(
            "Isnt that like one of the oldest military plays in the books?",
            OldestInTheBook::default(),
            "Isnt that like one of the oldest military plays in the book?",
        );
    }

    // Test messages

    #[test]
    fn is_oldest_trick_in_the_books_ref_to_idom() {
        assert_lint_message(
            "This is one of the oldest trick in the books",
            OldestInTheBook::default(),
            "This idiom should use singular `book` instead of plural `books`.",
        );
    }

    #[test]
    fn is_chromatic_alterations_ref_to_idom() {
        assert_lint_message(
            "One of the oldest chromatic alterations in the books is the raising of the leading tone",
            OldestInTheBook::default(),
            "If this is a play on the idiom `oldest trick in the book`, it should use singular `book` instead of plural `books`.",
        );
    }
}



================================================
FILE: harper-core/src/linting/on_floor.rs
================================================
use crate::CharStringExt;
use crate::expr::Expr;
use crate::expr::LongestMatchOf;
use crate::expr::SequenceExpr;
use crate::linting::expr_linter::Chunk;
use crate::patterns::WordSet;
use crate::{
    Lrc, Token, TokenStringExt,
    linting::{ExprLinter, Lint, LintKind, Suggestion},
};

pub struct OnFloor {
    expr: Box<dyn Expr>,
}

impl Default for OnFloor {
    fn default() -> Self {
        let preposition = WordSet::new(&["in", "at"]);

        let on_the_floor = Lrc::new(
            SequenceExpr::default()
                .then(preposition)
                .t_ws()
                .t_aco("the")
                .t_ws()
                .t_any()
                .t_ws()
                .t_aco("floor"),
        );

        let look_up_phrase = Lrc::new(
            SequenceExpr::default()
                .then(WordSet::new(&["look", "looking", "looks", "looked"]))
                .t_ws()
                .t_aco("up"),
        );

        let stop = Lrc::new(WordSet::new(&["stop", "stopping", "stops", "stopped"]));
        let exceptions = Lrc::new(LongestMatchOf::new(vec![
            Box::new(SequenceExpr::with(look_up_phrase.clone())),
            Box::new(SequenceExpr::with(stop.clone())),
        ]));

        let pattern = LongestMatchOf::new(vec![
            Box::new(on_the_floor.clone()),
            Box::new(
                SequenceExpr::default()
                    .then(exceptions.clone())
                    .t_ws()
                    .then(on_the_floor.clone()),
            ),
        ]);

        Self {
            expr: Box::new(pattern),
        }
    }
}

impl ExprLinter for OnFloor {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], source: &[char]) -> Option<Lint> {
        let incorrect_preposition = matched_tokens[0..1].span()?.get_content(source).to_string();
        // if the first token is not "in" or "at", means that the match is belong to the exceptions
        // so we don't need to lint it
        if !["in", "at"].contains(&incorrect_preposition.to_lowercase().as_str()) {
            return None;
        }
        let span = matched_tokens[0..1].span()?;

        Some(Lint {
            lint_kind: LintKind::WordChoice,
            span,
            suggestions: vec![Suggestion::replace_with_match_case_str(
                "on",
                span.get_content(source),
            )],
            message: format!(
                "Corrects `{incorrect_preposition}` to `on` when talking about position inside a building",
            )
            .to_string(),
            priority: 63,
        })
    }

    fn description(&self) -> &'static str {
        "This rule identifies incorrect uses of the prepositions `in` or `at` when referring to locations inside a building and recommends using `on the floor` instead."
    }
}

#[cfg(test)]
mod tests {
    use super::OnFloor;
    use crate::linting::tests::{assert_lint_count, assert_suggestion_result};

    #[test]
    fn not_lint_with_correct_phrase() {
        assert_lint_count(
            "I'm living on the 3rd floor of a building.",
            OnFloor::default(),
            0,
        );
    }

    #[test]
    fn lint_with_in() {
        assert_suggestion_result(
            "I'm living in the 3rd floor of a building.",
            OnFloor::default(),
            "I'm living on the 3rd floor of a building.",
        );
    }

    #[test]
    fn lint_with_at() {
        assert_suggestion_result(
            "I'm living at the second floor of a building.",
            OnFloor::default(),
            "I'm living on the second floor of a building.",
        );
    }

    #[test]
    fn in_the_start_of_sentence() {
        assert_suggestion_result(
            "In the 3rd floor of a building.",
            OnFloor::default(),
            "On the 3rd floor of a building.",
        );
    }

    #[test]
    fn at_the_start_of_sentence() {
        assert_suggestion_result(
            "At the second floor of a building.",
            OnFloor::default(),
            "On the second floor of a building.",
        );
    }

    #[test]
    fn no_lint_with_look_up_at() {
        assert_lint_count("She looked up at the third floor.", OnFloor::default(), 0);
    }

    #[test]
    fn no_lint_with_stop_at() {
        assert_lint_count(
            "The elevator stops at the 3rd floor of a building.",
            OnFloor::default(),
            0,
        );
    }

    #[test]
    fn no_lint_with_looking_up_at() {
        assert_lint_count(
            "The workers are looking up at the 3rd floor of a building.",
            OnFloor::default(),
            0,
        );
    }
}



================================================
FILE: harper-core/src/linting/once_or_twice.rs
================================================
use crate::CharStringExt;
use crate::Token;
use crate::expr::{Expr, SequenceExpr};

use super::{ExprLinter, Lint, LintKind, Suggestion};
use crate::linting::expr_linter::Chunk;

pub struct OnceOrTwice {
    expr: Box<dyn Expr>,
}

impl Default for OnceOrTwice {
    fn default() -> Self {
        let pattern = SequenceExpr::aco("once")
            .then_whitespace()
            .t_aco("a")
            .then_whitespace()
            .t_aco("twice");

        Self {
            expr: Box::new(pattern),
        }
    }
}

impl ExprLinter for OnceOrTwice {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], source: &[char]) -> Option<Lint> {
        let article = matched_tokens.iter().find(|token| {
            token.kind.is_word() && token.span.get_content(source).eq_ignore_ascii_case_str("a")
        })?;

        let span = article.span;
        let original = span.get_content(source);

        Some(Lint {
            span,
            lint_kind: LintKind::WordChoice,
            suggestions: vec![Suggestion::replace_with_match_case_str("or", original)],
            message: "Did you mean “or”?".to_owned(),
            priority: 31,
        })
    }

    fn description(&self) -> &'static str {
        "Detects the mistaken phrase `once a twice` and suggests `once or twice`."
    }
}

#[cfg(test)]
mod tests {
    use crate::linting::tests::{assert_no_lints, assert_suggestion_result};

    use super::OnceOrTwice;

    #[test]
    fn corrects_once_a_twice() {
        assert_suggestion_result(
            "He wants to do it once a twice a month.",
            OnceOrTwice::default(),
            "He wants to do it once or twice a month.",
        );
    }

    #[test]
    fn allows_once_or_twice() {
        assert_no_lints(
            "He wants to do it once or twice a month.",
            OnceOrTwice::default(),
        );
    }

    #[test]
    fn corrects_once_a_twice_sentence_start() {
        assert_suggestion_result(
            "Once a twice, we gathered for coffee.",
            OnceOrTwice::default(),
            "Once or twice, we gathered for coffee.",
        );
    }

    #[test]
    fn corrects_once_a_twice_uppercase() {
        assert_suggestion_result(
            "ONCE A TWICE WE MET.",
            OnceOrTwice::default(),
            "ONCE OR TWICE WE MET.",
        );
    }

    #[test]
    fn corrects_once_a_twice_mixed_case() {
        assert_suggestion_result(
            "once a Twice sounds odd.",
            OnceOrTwice::default(),
            "once or Twice sounds odd.",
        );
    }

    #[test]
    fn corrects_once_a_twice_with_exclamation() {
        assert_suggestion_result(
            "Let's do it once a twice!",
            OnceOrTwice::default(),
            "Let's do it once or twice!",
        );
    }

    #[test]
    fn corrects_once_a_twice_with_question_mark() {
        assert_suggestion_result(
            "You really tried once a twice?",
            OnceOrTwice::default(),
            "You really tried once or twice?",
        );
    }

    #[test]
    fn corrects_once_a_twice_inside_quotes() {
        assert_suggestion_result(
            "He said, \"once a twice\" without thinking.",
            OnceOrTwice::default(),
            "He said, \"once or twice\" without thinking.",
        );
    }

    #[test]
    fn corrects_once_a_twice_with_comma() {
        assert_suggestion_result(
            "We planned it once a twice, but never finished.",
            OnceOrTwice::default(),
            "We planned it once or twice, but never finished.",
        );
    }

    #[test]
    fn corrects_once_a_twice_with_parentheses() {
        assert_suggestion_result(
            "Try it (just once a twice) before judging.",
            OnceOrTwice::default(),
            "Try it (just once or twice) before judging.",
        );
    }

    #[test]
    fn corrects_once_a_twice_after_colon() {
        assert_suggestion_result(
            "My answer is simple: once a twice is too many.",
            OnceOrTwice::default(),
            "My answer is simple: once or twice is too many.",
        );
    }

    #[test]
    fn corrects_once_a_twice_with_double_space() {
        assert_suggestion_result(
            "We tested once a twice  before launch.",
            OnceOrTwice::default(),
            "We tested once or twice  before launch.",
        );
    }

    #[test]
    fn corrects_once_a_twice_before_semicolon() {
        assert_suggestion_result(
            "They tried once a twice; it still failed.",
            OnceOrTwice::default(),
            "They tried once or twice; it still failed.",
        );
    }

    #[test]
    fn corrects_once_a_twice_newline_split() {
        assert_suggestion_result(
            "We met once a twice\nwhen the cafe was quiet.",
            OnceOrTwice::default(),
            "We met once or twice\nwhen the cafe was quiet.",
        );
    }

    #[test]
    fn corrects_once_a_twice_with_tab() {
        assert_suggestion_result(
            "Schedule it once a twice\tfor testing.",
            OnceOrTwice::default(),
            "Schedule it once or twice\tfor testing.",
        );
    }

    #[test]
    fn corrects_once_a_twice_multiple_sentences() {
        assert_suggestion_result(
            "Do it once a twice. Then rest.",
            OnceOrTwice::default(),
            "Do it once or twice. Then rest.",
        );
    }

    #[test]
    fn corrects_once_a_twice_before_period() {
        assert_suggestion_result(
            "He rehearsed once a twice.",
            OnceOrTwice::default(),
            "He rehearsed once or twice.",
        );
    }

    #[test]
    fn corrects_once_a_twice_with_trailing_space() {
        assert_suggestion_result(
            "Practice once a twice .",
            OnceOrTwice::default(),
            "Practice once or twice .",
        );
    }

    #[test]
    fn corrects_once_a_twice_before_dash() {
        assert_suggestion_result(
            "He called once a twice—no response.",
            OnceOrTwice::default(),
            "He called once or twice—no response.",
        );
    }

    #[test]
    fn corrects_once_a_twice_around_em_dash() {
        assert_suggestion_result(
            "She visits once a twice—maybe thrice.",
            OnceOrTwice::default(),
            "She visits once or twice—maybe thrice.",
        );
    }

    #[test]
    fn corrects_once_a_twice_before_quote() {
        assert_suggestion_result(
            "We heard once a twice, \"she's late.\"",
            OnceOrTwice::default(),
            "We heard once or twice, \"she's late.\"",
        );
    }

    #[test]
    fn corrects_once_a_twice_all_caps_sentence() {
        assert_suggestion_result(
            "DO IT ONCE A TWICE RIGHT NOW!",
            OnceOrTwice::default(),
            "DO IT ONCE OR TWICE RIGHT NOW!",
        );
    }

    #[test]
    fn allows_once_a_time_story() {
        assert_no_lints("Once a time, in a distant land...", OnceOrTwice::default());
    }

    #[test]
    fn allows_once_a_week_routine() {
        assert_no_lints("We meet once a week to sync up.", OnceOrTwice::default());
    }

    #[test]
    fn allows_once_a_while_phrase() {
        assert_no_lints(
            "Check in every once a while to stay updated.",
            OnceOrTwice::default(),
        );
    }

    #[test]
    fn allows_once_or_twice_uppercase() {
        assert_no_lints("ONCE OR TWICE, WE MADE IT WORK.", OnceOrTwice::default());
    }

    #[test]
    fn allows_twice_without_once() {
        assert_no_lints(
            "We only managed it twice this year.",
            OnceOrTwice::default(),
        );
    }

    #[test]
    fn allows_once_and_twice_separated() {
        assert_no_lints("Once I tried; twice I failed.", OnceOrTwice::default());
    }

    #[test]
    fn allows_oncemisatypo() {
        assert_no_lints("oncemisatypo appears once a line.", OnceOrTwice::default());
    }

    #[test]
    fn allows_spaced_words() {
        assert_no_lints(
            "We say once at twice distance to be safe.",
            OnceOrTwice::default(),
        );
    }
}



================================================
FILE: harper-core/src/linting/one_and_the_same.rs
================================================
use crate::expr::Expr;
use crate::expr::FixedPhrase;
use crate::expr::LongestMatchOf;
use crate::expr::SequenceExpr;
use crate::{Lrc, Token, TokenStringExt, patterns::WordSet};

use super::{ExprLinter, Lint, LintKind, Suggestion};
use crate::linting::expr_linter::Chunk;

pub struct OneAndTheSame {
    expr: Box<dyn Expr>,
}

impl Default for OneAndTheSame {
    fn default() -> Self {
        let one_in_the_same = Lrc::new(FixedPhrase::from_phrase("one in the same"));

        Self {
            expr: Box::new(LongestMatchOf::new(vec![
                Box::new(
                    SequenceExpr::default()
                        .then(WordSet::new(&["are", "were"]))
                        .t_ws()
                        .then(one_in_the_same.clone()),
                ),
                Box::new(
                    SequenceExpr::default()
                        .then(one_in_the_same.clone())
                        .t_ws()
                        .t_aco("as"),
                ),
            ])),
        }
    }
}

fn ws_word(word: &'static str) -> SequenceExpr {
    SequenceExpr::default().t_ws().t_aco(word)
}

impl ExprLinter for OneAndTheSame {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], source: &[char]) -> Option<Lint> {
        let phrase = if matched_tokens.last()?.span.get_content(source) == ['a', 's'] {
            matched_tokens[0..matched_tokens.len() - 2].span()?
        } else {
            matched_tokens[2..].span()?
        };

        Some(Lint {
            span: phrase,
            lint_kind: LintKind::WordChoice,
            suggestions: vec![Suggestion::replace_with_match_case(
                "one and the same".chars().collect(),
                phrase.get_content(source),
            )],
            message: "The actual idiom is with the word `and`.".to_owned(),
            priority: 127,
        })
    }

    fn description(&self) -> &'static str {
        "This linter flags instances of the nonstandard phrase `one in the same`. The correct, more accepted form is `one and the same`"
    }
}

#[cfg(test)]
mod tests {
    use super::OneAndTheSame;
    use crate::linting::tests::{assert_lint_count, assert_suggestion_result};

    #[test]
    fn corrects_after_are_atomic() {
        assert_suggestion_result(
            "... are one in the same ...",
            OneAndTheSame::default(),
            "... are one and the same ...",
        );
    }

    #[test]
    fn corrects_after_were_atomic() {
        assert_suggestion_result(
            "... were one in the same ...",
            OneAndTheSame::default(),
            "... were one and the same ...",
        );
    }

    #[test]
    fn doesnt_flag_after_other_words_atomic() {
        assert_lint_count(
            "... and another one in the same place ...",
            OneAndTheSame::default(),
            0,
        );
    }

    #[test]
    fn corrects_github_are() {
        assert_suggestion_result(
            "Yes, I believe they are one in the same.",
            OneAndTheSame::default(),
            "Yes, I believe they are one and the same.",
        );
    }

    #[test]
    fn corrects_github_were() {
        assert_suggestion_result(
            "As prior to OpenShift 4.0, OAuth and Kubernetes REST API were one in the same, option (2) above should still work there.",
            OneAndTheSame::default(),
            "As prior to OpenShift 4.0, OAuth and Kubernetes REST API were one and the same, option (2) above should still work there.",
        );
    }

    #[test]
    fn corrects_before_as_atomic() {
        assert_suggestion_result(
            "... one in the same as ...",
            OneAndTheSame::default(),
            "... one and the same as ...",
        );
    }

    #[test]
    fn corrects_before_as_github() {
        assert_suggestion_result(
            "In our case the slicedState is one in the same as the featureState",
            OneAndTheSame::default(),
            "In our case the slicedState is one and the same as the featureState",
        );
    }

    #[test]
    #[ignore = "needs zero-width end-of-chunk pattern akin to regex `$`"]
    fn corrects_at_end() {
        assert_suggestion_result(
            "I think this is one in the same.",
            OneAndTheSame::default(),
            "I think this is one and the same.",
        );
    }

    #[test]
    fn corrects_is_as() {
        assert_suggestion_result(
            "I believe this and this issue is one in the same as Next.js uses cloudflare workers for it's edge infra.",
            OneAndTheSame::default(),
            "I believe this and this issue is one and the same as Next.js uses cloudflare workers for it's edge infra.",
        );
    }

    #[test]
    fn avoids_false_positive() {
        assert_lint_count(
            "If there is no postgresql.pg_hba either there is one in the same section of patroni.yaml or pg_hba.conf is not managed by Patroni.",
            OneAndTheSame::default(),
            0,
        );
    }

    #[test]
    #[ignore = "Cannot detect unexpected ungrammatical `same of`"]
    fn corrects_is_of() {
        assert_suggestion_result(
            "R3 that Stephan Buhre noted is one-in-the-same of what I posted.",
            OneAndTheSame::default(),
            "R3 that Stephan Buhre noted is one and the same of what I posted.",
        );
    }

    #[test]
    fn doesnt_flag_ambiguous_before_noun() {
        assert_lint_count(
            "I'm guessing this is one in the same request.",
            OneAndTheSame::default(),
            0,
        );
    }
}



================================================
FILE: harper-core/src/linting/one_of_the_singular.rs
================================================
use crate::{
    CharStringExt, Lint, Token,
    expr::{Expr, SequenceExpr},
    linting::{ExprLinter, LintKind, Suggestion, expr_linter::Chunk},
    spell::Dictionary,
};

pub struct OneOfTheSingular<D: Dictionary + 'static> {
    expr: Box<dyn Expr>,
    dict: D,
}

pub trait SeqExprExt {
    fn then_my_noun_or_adjective(self) -> Self;
}

impl SeqExprExt for SequenceExpr {
    fn then_my_noun_or_adjective(self) -> Self {
        self.then(|t: &Token, s: &[char]| {
            // We can't restrict to singular nouns because it will match and then flag the part of a phrase
            // leading up to but not including a plural noun, even when that plural noun is the result of
            // this linter having corrected a mistake.
            // eg. "one of the train station" -> "one of the train stations" will now match on "one of the train".
            (t.kind.is_non_possessive_noun() || t.kind.is_adjective())
                && !t.kind.is_preposition() // "in" etc.
                && !t.kind.is_pronoun() // "who" etc.
                && !t
                    .span
                    .get_content(s)
                    .eq_any_ignore_ascii_case_str(&["ah", "few", "first", "said", "uh"])
        })
    }
}

impl<D: Dictionary + 'static> OneOfTheSingular<D> {
    pub fn new(dict: D) -> Self {
        let advs =
            SequenceExpr::default().then_one_or_more_spaced(SequenceExpr::default().then_adverb());

        let adj_or_nouns = SequenceExpr::default()
            .then_one_or_more_spaced(SequenceExpr::default().then_my_noun_or_adjective());

        Self {
            expr: Box::new(
                SequenceExpr::fixed_phrase("one of the ").then(
                    SequenceExpr::default()
                        .then_optional(advs.t_ws())
                        .then(adj_or_nouns),
                ),
            ),
            dict,
        }
    }
}

impl<D: Dictionary + 'static> ExprLinter for OneOfTheSingular<D> {
    type Unit = Chunk;

    fn description(&self) -> &str {
        "Corrects 'one of the [singular]' to 'one of the [plural]'"
    }

    fn match_to_lint_with_context(
        &self,
        toks: &[Token],
        src: &[char],
        ctx: Option<(&[Token], &[Token])>,
    ) -> Option<Lint> {
        let nountok = toks.last()?;
        // It's only a mistake if the noun phrase ends with a singular noun.
        if !nountok.kind.is_singular_noun()
        // "Being" in eg. one of the most widely used being the bi-directional inference algorithm.
        || nountok.kind.is_verb_progressive_form()
        {
            return None;
        }
        // If any token is a singular noun that's not also a plural noun, don't continue.
        if toks
            .iter()
            .any(|t| t.kind.is_plural_noun() && !t.kind.is_singular_noun())
        {
            return None;
        }
        // But if not if it's part of a hyphenated compound.
        if let Some(next) = ctx?.1.first()
            && (next.kind.is_hyphen() || next.kind.is_comma())
        {
            return None;
        }
        let nounspan = nountok.span;
        let singular = nounspan.get_content(src);
        let mut plural_s = singular.to_vec();
        let mut plural_es = singular.to_vec();
        plural_s.push('s');
        plural_es.extend(['e', 's']);

        let mut suggestions = vec![];

        if self
            .dict
            .get_word_metadata(&plural_s)
            .is_some_and(|m| m.is_plural_noun())
        {
            suggestions.push(Suggestion::replace_with_match_case(plural_s, singular));
        }
        if self
            .dict
            .get_word_metadata(&plural_es)
            .is_some_and(|m| m.is_plural_noun())
        {
            suggestions.push(Suggestion::replace_with_match_case(plural_es, singular));
        }

        if singular.ends_with_ignore_ascii_case_chars(&['y']) {
            // Handle words ending in 'y' -> 'ies' (e.g., "city" -> "cities")
            let mut plural_ies = singular[..singular.len() - 1].to_vec();
            plural_ies.extend(['i', 'e', 's']);
            if self
                .dict
                .get_word_metadata(&plural_ies)
                .is_some_and(|m| m.is_plural_noun())
            {
                suggestions.push(Suggestion::replace_with_match_case(plural_ies, singular));
            }
        }

        if singular.ends_with_ignore_ascii_case_chars(&['f', 'e']) {
            // Handle words ending in 'fe' -> 'ves' (e.g., "wife" -> "wives")
            let mut plural_ves = singular[..singular.len() - 2].to_vec();
            plural_ves.extend(['v', 'e', 's']);
            if self
                .dict
                .get_word_metadata(&plural_ves)
                .is_some_and(|m| m.is_plural_noun())
            {
                suggestions.push(Suggestion::replace_with_match_case(plural_ves, singular));
            }
        }

        Some(Lint {
            span: nounspan,
            lint_kind: LintKind::Usage,
            suggestions,
            message: "The construction `one of the ...` should use a plural noun.".to_string(),
            ..Default::default()
        })
    }

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }
}

#[cfg(test)]
mod tests {
    use super::OneOfTheSingular;
    use crate::linting::tests::{assert_no_lints, assert_top3_suggestion_result};
    use crate::spell::FstDictionary;

    #[test]
    fn fix_one_of_the_noun() {
        assert_top3_suggestion_result(
            "one of the noun",
            OneOfTheSingular::new(FstDictionary::curated()),
            "one of the nouns",
        );
    }

    #[test]
    fn fix_one_of_the_noun_noun() {
        assert_top3_suggestion_result(
            "one of the car park",
            OneOfTheSingular::new(FstDictionary::curated()),
            "one of the car parks",
        );
    }

    #[test]
    fn fix_one_of_the_adj_noun() {
        assert_top3_suggestion_result(
            "one of the best noun",
            OneOfTheSingular::new(FstDictionary::curated()),
            "one of the best nouns",
        );
    }

    #[test]
    fn fix_one_of_the_adv_adv_adj_adj_noun_noun() {
        assert_top3_suggestion_result(
            "one of the really incredibly big red rubber ball",
            OneOfTheSingular::new(FstDictionary::curated()),
            "one of the really incredibly big red rubber balls",
        );
    }

    #[test]
    fn fix_one_of_the_best_tutorial() {
        assert_top3_suggestion_result(
            "Bro casually dropped one of the best graphics tutorial I've ever seen and thought we wouldn't notice",
            OneOfTheSingular::new(FstDictionary::curated()),
            "Bro casually dropped one of the best graphics tutorials I've ever seen and thought we wouldn't notice",
        );
    }

    #[test]
    fn fix_one_of_the_neat_trick() {
        assert_top3_suggestion_result(
            "One of the neat trick with AVX-512 is that given a mask",
            OneOfTheSingular::new(FstDictionary::curated()),
            "One of the neat tricks with AVX-512 is that given a mask",
        );
    }

    #[test]
    fn fix_one_of_the_latest_version() {
        assert_top3_suggestion_result(
            "Footer line shown since one of the latest version",
            OneOfTheSingular::new(FstDictionary::curated()),
            "Footer line shown since one of the latest versions",
        );
    }

    #[test]
    fn fix_one_of_the_node() {
        assert_top3_suggestion_result(
            "... noticed occasional production issue when one of the node loses connection",
            OneOfTheSingular::new(FstDictionary::curated()),
            "... noticed occasional production issue when one of the nodes loses connection",
        );
    }

    #[test]
    fn fix_one_of_the_unstaged_file() {
        assert_top3_suggestion_result(
            "Sublime Merge hangs if one of the unstaged file is a pretty ...",
            OneOfTheSingular::new(FstDictionary::curated()),
            "Sublime Merge hangs if one of the unstaged files is a pretty ...",
        );
    }

    #[test]
    fn fix_one_of_the_tedious_things() {
        assert_top3_suggestion_result(
            "One of the tedious thing in Stack Overflow is to grab example data provided by users",
            OneOfTheSingular::new(FstDictionary::curated()),
            "One of the tedious things in Stack Overflow is to grab example data provided by users",
        );
    }

    #[test]
    fn fix_one_of_the_brave_process() {
        assert_top3_suggestion_result(
            "One of the Brave Process is consuming almost 170%",
            OneOfTheSingular::new(FstDictionary::curated()),
            "One of the Brave Processes is consuming almost 170%",
        );
    }

    #[test]
    fn fix_one_of_the_most_cumbersome_thing() {
        assert_top3_suggestion_result(
            "One of the most cumbersome thing to create in markdown is a table.",
            OneOfTheSingular::new(FstDictionary::curated()),
            "One of the most cumbersome things to create in markdown is a table.",
        );
    }

    #[test]
    fn fix_one_of_the_test() {
        assert_top3_suggestion_result(
            "Not passing one of the test",
            OneOfTheSingular::new(FstDictionary::curated()),
            "Not passing one of the tests",
        );
    }

    #[test]
    fn fix_one_of_the_process_main_thread() {
        assert_top3_suggestion_result(
            "And those threads life cycle is very long, sometimes, it will be one of the process main thread",
            OneOfTheSingular::new(FstDictionary::curated()),
            "And those threads life cycle is very long, sometimes, it will be one of the process main threads",
        );
    }

    #[test]
    fn dont_flag_being() {
        assert_no_lints(
            "HMMs underlie the functioning of stochastic taggers and are used in various algorithms one of the most widely used being the bi-directional inference algorithm.",
            OneOfTheSingular::new(FstDictionary::curated()),
        );
    }

    #[test]
    fn dont_flag_one_of_the_rabbits_gloves() {
        assert_no_lints(
            "As she said this she looked down at her hands, and was surprised to see that she had put on one of the Rabbit’s little white kid gloves while she was talking.",
            OneOfTheSingular::new(FstDictionary::curated()),
        );
    }
}



================================================
FILE: harper-core/src/linting/open_compounds.rs
================================================
use crate::expr::{Expr, LongestMatchOf, SequenceExpr};
use crate::{Lrc, Token, patterns::WordSet};

use super::{ExprLinter, Lint, LintKind, Suggestion};
use crate::linting::expr_linter::Chunk;
use hashbrown::HashMap;

pub struct OpenCompounds {
    expr: Box<dyn Expr>,
    compound_to_phrase: HashMap<String, String>,
}

impl Default for OpenCompounds {
    fn default() -> Self {
        let phrases = [
            "a few",
            "a lot",
            "as well",
            "at least",
            "each other",
            "in case",
            "in fact",
            "in front",
            "up to",
        ];
        let mut compound_to_phrase = HashMap::new();
        for phrase in phrases {
            compound_to_phrase.insert(
                phrase
                    .split_whitespace()
                    .map(|s| s.to_lowercase())
                    .collect::<String>(),
                phrase.to_string(),
            );
        }

        let mut compound_wordset = WordSet::default();
        for compound in compound_to_phrase.keys().cloned().collect::<Vec<_>>() {
            compound_wordset.add(&compound);
        }
        let compound = Lrc::new(SequenceExpr::with(compound_wordset));

        let with_prev = SequenceExpr::anything().then(compound.clone());

        let with_next = SequenceExpr::default()
            .then(compound.clone())
            .then_anything();

        let with_prev_and_next = SequenceExpr::anything()
            .then(compound.clone())
            .then_anything();

        Self {
            expr: Box::new(LongestMatchOf::new(vec![
                Box::new(with_prev_and_next),
                Box::new(with_prev),
                Box::new(with_next),
                Box::new(compound),
            ])),
            compound_to_phrase,
        }
    }
}

impl ExprLinter for OpenCompounds {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_toks: &[Token], source_chars: &[char]) -> Option<Lint> {
        // Because we don't have anything like regex captures we need to find which token matched which compound
        let index = self
            .compound_to_phrase
            .keys()
            .find_map(|compound| get_compound_idx(matched_toks, source_chars, compound))?;

        let span = matched_toks[index].span;
        let compound_string = span.get_content(source_chars).iter().collect::<String>();

        // Ignore if there's a hyphen immediately on either side
        if (0..matched_toks.len())
            .filter(|&i| i != index)
            .any(|i| matched_toks[i].kind.is_hyphen())
        {
            return None;
        }

        // Ignore trademarks etc. like InFront, inFront
        let phrase = self
            .compound_to_phrase
            .get(&compound_string.to_lowercase())?;
        if compound_string
            .chars()
            .nth(phrase.find(' ')?)?
            .is_uppercase()
        {
            return None;
        }

        Some(Lint {
            span,
            lint_kind: LintKind::BoundaryError,
            suggestions: vec![Suggestion::replace_with_match_case(
                phrase.chars().collect(),
                span.get_content(source_chars),
            )],
            message: format!("`{phrase}` should be written as two words."),
            priority: 31,
        })
    }

    fn description(&self) -> &str {
        "Corrects compound words that should be written as two words."
    }
}

fn get_compound_idx(toks: &[Token], src: &[char], compound: &str) -> Option<usize> {
    let len = compound.len();
    let tok_count = toks.len();

    match tok_count {
        1 => Some(0),
        3 => Some(1),
        2 => {
            let [tok0, tok1] = toks else { return None };
            let [len0, len1] = [tok0.span.len(), tok1.span.len()];

            if len0 == len && len1 != len {
                Some(0)
            } else if len1 == len && len0 != len {
                Some(1)
            } else if tok0.kind.is_word() && !tok1.kind.is_word() {
                Some(0)
            } else if !tok0.kind.is_word() && tok1.kind.is_word() {
                Some(1)
            } else {
                Some(
                    !tok0
                        .span
                        .get_content(src)
                        .iter()
                        .collect::<String>()
                        .eq_ignore_ascii_case(compound) as usize,
                )
            }
        }
        _ => None,
    }
}

#[cfg(test)]
mod tests {
    use super::OpenCompounds;
    use crate::linting::tests::{assert_lint_count, assert_suggestion_result};

    // In front

    #[test]
    fn corrects_lone_infront() {
        assert_suggestion_result(
            "Button always overlaps (infront) of other views.",
            OpenCompounds::default(),
            "Button always overlaps (in front) of other views.",
        );
    }

    #[test]
    fn corrects_infront() {
        assert_suggestion_result(
            "So if i have no variable or a running process id/name which indicates that liveley is infront/fullscreen i can't do anything further via batch and must wait ...",
            OpenCompounds::default(),
            "So if i have no variable or a running process id/name which indicates that liveley is in front/fullscreen i can't do anything further via batch and must wait ...",
        );
    }

    #[test]
    fn ignores_pascalcase() {
        assert_lint_count(
            "InFront Labs, LLC has 16 repositories available. Follow their code on GitHub.",
            OpenCompounds::default(),
            0,
        );
    }

    #[test]
    fn ignores_camelcase() {
        assert_lint_count(
            "Click the \"toggle\" button to see how wrapping changes when an inFront is added to a letter in a word.",
            OpenCompounds::default(),
            0,
        );
    }

    #[test]
    fn correct_with_period_after() {
        assert_suggestion_result(
            "Car with a reversed ramp infront.",
            OpenCompounds::default(),
            "Car with a reversed ramp in front.",
        );
    }

    #[test]
    fn ignore_hyphen_before() {
        assert_lint_count("-infront", OpenCompounds::default(), 0);
    }

    #[test]
    fn ignore_hyphen_after() {
        assert_lint_count("infront-", OpenCompounds::default(), 0);
    }

    #[test]
    fn ignores_with_hyphen_before() {
        assert_lint_count(
            "Instantly share code, notes, and snippets. @yossi-infront",
            OpenCompounds::default(),
            0,
        );
    }

    #[test]
    fn ignores_with_hyphen_after() {
        assert_lint_count(
            "infront-cycle.ipe · infront-cycle.ipe · infront-cycle.svg · infront-cycle.svg · infront-s1s2.ipe · infront-s1s2.ipe · infront-s1s2.svg · infront-s1s2.svg.",
            OpenCompounds::default(),
            0,
        );
    }

    #[test]
    fn even_repeated_infront_works() {
        assert_suggestion_result(
            "infront infront",
            OpenCompounds::default(),
            "in front in front",
        );
    }

    // A few

    #[test]
    fn correct_afew_atomic() {
        assert_suggestion_result(
            "ITK code to generate anisotropic metrics, mostly Riemannian metrics and afew particular cases of Finslerian metrics.",
            OpenCompounds::default(),
            "ITK code to generate anisotropic metrics, mostly Riemannian metrics and a few particular cases of Finslerian metrics.",
        );
    }

    // A lot

    #[test]
    fn correct_alot_atomic() {
        assert_suggestion_result("Alot", OpenCompounds::default(), "A lot");
    }

    // As well

    #[test]
    fn correct_aswell_atomic() {
        assert_suggestion_result("Aswell", OpenCompounds::default(), "As well");
    }

    #[test]
    fn corrects_as_keyboards_aswell() {
        assert_suggestion_result(
            "Tool to read physical joystick devices, keyboards aswell, and create virtual joystick devices and output keyboard presses on a Linux system.",
            OpenCompounds::default(),
            "Tool to read physical joystick devices, keyboards as well, and create virtual joystick devices and output keyboard presses on a Linux system.",
        );
    }

    #[test]
    fn corrects_aswell_as() {
        assert_suggestion_result(
            "When UseAcrylic is true in Focused aswell as Unfocused Apearance , changing enableUnfocusedAcrylic at runtime doesn't work",
            OpenCompounds::default(),
            "When UseAcrylic is true in Focused as well as Unfocused Apearance , changing enableUnfocusedAcrylic at runtime doesn't work",
        );
    }

    #[test]
    fn corrects_toml_aswell() {
        assert_suggestion_result(
            "format Cargo.toml aswell #5893 - rust-lang/rustfmt",
            OpenCompounds::default(),
            "format Cargo.toml as well #5893 - rust-lang/rustfmt",
        );
    }

    #[test]
    fn correct_aswell() {
        assert_suggestion_result(
            "'wejoy' is a tool to read physical joystick devices, aswell as keyboards, create virtual joystick devices and output keyboard presses on a Linux system.",
            OpenCompounds::default(),
            "'wejoy' is a tool to read physical joystick devices, as well as keyboards, create virtual joystick devices and output keyboard presses on a Linux system.",
        );
    }

    // At least

    #[test]
    fn correct_atleast_atomic() {
        assert_suggestion_result("Atleast", OpenCompounds::default(), "At least");
    }

    #[test]
    fn ignore_atleast_pascalcase() {
        assert_lint_count(
            "I want to understand if we are using AtLeast correctly.",
            OpenCompounds::default(),
            0,
        );
    }

    #[test]
    fn ignore_atleast_camelcase() {
        assert_lint_count(
            "verfiy with atLeast = 0 should pass even if the mocked function is never called.",
            OpenCompounds::default(),
            0,
        );
    }

    #[test]
    fn correct_atleast() {
        assert_suggestion_result(
            "Mar 22, 2562 BE — constructor - expected atleast one input #250.",
            OpenCompounds::default(),
            "Mar 22, 2562 BE — constructor - expected at least one input #250.",
        );
    }

    // Each other

    #[test]
    fn correct_eachother_atomic() {
        assert_suggestion_result("Eachother", OpenCompounds::default(), "Each other");
    }

    #[test]
    fn correct_eachother() {
        assert_suggestion_result(
            "Script parsing fails when two scenes reference eachother",
            OpenCompounds::default(),
            "Script parsing fails when two scenes reference each other",
        );
    }

    // In case

    #[test]
    fn correct_incase_atomic() {
        assert_suggestion_result("Incase", OpenCompounds::default(), "In case");
    }

    #[test]
    fn correct_in_case() {
        assert_suggestion_result(
            "Support for enum variable incase of reusable enum class",
            OpenCompounds::default(),
            "Support for enum variable in case of reusable enum class",
        );
    }

    #[test]
    fn ignore_incase_pascalcase() {
        assert_lint_count(
            "InCase save your secrets for a friend, so they can use in case it in case you went \"missing\".",
            OpenCompounds::default(),
            0,
        );
    }

    // In fact

    #[test]
    fn correct_infact_atomic() {
        assert_suggestion_result(
            "Yes I do infact exist :O",
            OpenCompounds::default(),
            "Yes I do in fact exist :O",
        );
    }

    // up to

    #[test]
    fn correct_upto() {
        assert_suggestion_result(
            "Free for upto 10k subscribers, unlimited push notifications, in-browser messaging",
            OpenCompounds::default(),
            "Free for up to 10k subscribers, unlimited push notifications, in-browser messaging",
        );
    }
}



================================================
FILE: harper-core/src/linting/open_the_light.rs
================================================
use crate::expr::Expr;
use crate::expr::LongestMatchOf;
use crate::expr::SequenceExpr;
use crate::{
    Lrc, Token, TokenStringExt,
    linting::{LintKind, Suggestion},
    patterns::WordSet,
};

use super::{ExprLinter, Lint};
use crate::linting::expr_linter::Chunk;

pub struct OpenTheLight {
    expr: Box<dyn Expr>,
}

impl Default for OpenTheLight {
    fn default() -> Self {
        const TO_OPEN: &[&str] = &["open", "opens", "opened", "opening"];
        const DEVICES: &[&str] = &[
            "air conditioner",
            "air conditioning",
            "aircon",
            "cellphone",
            "fan",
            "handphone",
            "heater",
            "heating",
            "lamp",
            "light",
            "lights",
            "radio",
            "telephone",
            "television",
            "TV",
        ];

        let open_the_device = Lrc::new(
            SequenceExpr::default()
                .then(WordSet::new(TO_OPEN))
                .t_ws()
                .then_determiner()
                .t_ws()
                .then(WordSet::new(DEVICES)),
        );

        let open_the_device_then_noun = SequenceExpr::default()
            .then(open_the_device.clone())
            .t_ws()
            .then_noun();

        let expr = Box::new(LongestMatchOf::new(vec![
            Box::new(open_the_device),
            Box::new(open_the_device_then_noun),
        ]));

        Self { expr }
    }
}

impl ExprLinter for OpenTheLight {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, toks: &[Token], src: &[char]) -> Option<Lint> {
        // If I try to do this in the Pattern, the shorter pattern matches, without the context token.
        if toks.len() == 7 {
            let (device_tok, context_tok) = (toks.get_rel(-3)?, toks.get_rel(-1)?);
            // The device word is part of compound noun if it's singular and followed by another noun
            if !device_tok.kind.is_plural_noun() || !context_tok.kind.is_noun() {
                return None;
            }
        }

        const ING: &[char] = &['i', 'n', 'g'];
        const ED: &[char] = &['e', 'd'];
        const ES: &[char] = &['e', 's'];
        const LEMMA: &[char] = &[];

        let verb: &[char] = toks.first()?.span.get_content(src);

        let (e, n, d) = (
            verb[verb.len() - 3],
            verb[verb.len() - 2],
            verb[verb.len() - 1],
        );

        let (turn_ending, switch_ending) = match (e, n, d) {
            ('i', 'n', 'g') => (ING, ING),
            (_, 'e', 'd') => (ED, ED),
            (_, _, 's') => (&ES[1..], ES),
            _ => (LEMMA, LEMMA),
        };

        let mut turn_end_on: [char; 7 + 3] =
            ['t', 'u', 'r', 'n', '\0', '\0', '\0', '\0', '\0', '\0'];
        let mut switch_end_on: [char; 9 + 3] = [
            's', 'w', 'i', 't', 'c', 'h', '\0', '\0', '\0', '\0', '\0', '\0',
        ];

        // paste in the inflected ending
        turn_end_on[4..4 + turn_ending.len()].copy_from_slice(turn_ending);
        switch_end_on[6..6 + switch_ending.len()].copy_from_slice(switch_ending);

        turn_end_on[4 + turn_ending.len()..4 + turn_ending.len() + 3]
            .copy_from_slice(&[' ', 'o', 'n']);
        switch_end_on[6 + switch_ending.len()..6 + switch_ending.len() + 3]
            .copy_from_slice(&[' ', 'o', 'n']);

        let turn = &turn_end_on[..4 + turn_ending.len() + 3];
        let switch = &switch_end_on[..6 + switch_ending.len() + 3];

        Some(Lint {
            span: toks.first()?.span,
            lint_kind: LintKind::WordChoice,
            suggestions: vec![
                Suggestion::replace_with_match_case(turn.to_vec(), toks.span()?.get_content(src)),
                Suggestion::replace_with_match_case(switch.to_vec(), toks.span()?.get_content(src)),
            ],
            message: "Are you accessing the device's internals or `turning` it `on`?".to_owned(),
            priority: 63,
        })
    }

    fn description(&self) -> &'static str {
        "Corrects using `open` instead of `turn on` or `switch on`"
    }
}

#[cfg(test)]
mod tests {
    use super::OpenTheLight;
    use crate::linting::tests::{assert_lint_count, assert_suggestion_result};

    // made-up unit tests

    #[test]
    fn fix_open_the_tv() {
        assert_suggestion_result("open the TV", OpenTheLight::default(), "turn on the TV");
    }

    #[test]
    fn fix_he_opens_the_tv() {
        assert_suggestion_result(
            "he opens the TV",
            OpenTheLight::default(),
            "he turns on the TV",
        );
    }

    #[test]
    fn fix_she_opened_the_tv() {
        assert_suggestion_result(
            "she opened the TV",
            OpenTheLight::default(),
            "she turned on the TV",
        );
    }

    #[test]
    fn opening_the_tv() {
        assert_suggestion_result(
            "opening the TV",
            OpenTheLight::default(),
            "turning on the TV",
        );
    }

    #[test]
    fn dont_flag_open_the_tv_app() {
        assert_lint_count("open the TV app", OpenTheLight::default(), 0);
    }

    #[test]
    fn fix_open_the_tv_to_watch_the_news() {
        assert_suggestion_result(
            "open the TV to watch the news",
            OpenTheLight::default(),
            "turn on the TV to watch the news",
        );
    }

    #[test]
    fn fix_dont_forget_to_open_the_lights() {
        assert_suggestion_result(
            "Don't forget to open the lights when you enter the room.",
            OpenTheLight::default(),
            "Don't forget to turn on the lights when you enter the room.",
        );
    }

    #[test]
    fn fix_can_you_open_the_fan() {
        assert_suggestion_result(
            "Can you open the fan? It's quite stuffy.",
            OpenTheLight::default(),
            "Can you turn on the fan? It's quite stuffy.",
        );
    }

    #[test]
    fn fix_opened_the_radio() {
        assert_suggestion_result(
            "I opened the radio to listen to the morning show.",
            OpenTheLight::default(),
            "I turned on the radio to listen to the morning show.",
        );
    }

    #[test]
    fn fix_open_the_aircon() {
        assert_suggestion_result(
            "Can you open the aircon? It's hot.",
            OpenTheLight::default(),
            "Can you turn on the aircon? It's hot.",
        );
    }

    #[test]
    fn dont_flag_open_the_tv_mode() {
        assert_lint_count("open the TV mode", OpenTheLight::default(), 0);
    }

    // real world examples

    #[test]
    fn dont_flag_radio_configuration() {
        assert_lint_count(
            "To open the Radio Configuration click on the three dots on the top right side.",
            OpenTheLight::default(),
            0,
        );
    }

    #[test]
    #[ignore = "Requires much more complex context parsing"]
    fn dont_flag_open_the_lamp() {
        assert_lint_count(
            "Now you will need to open your lamp and solder everything together according to schematics.",
            OpenTheLight::default(),
            0,
        );
    }

    #[test]
    fn dont_flag_open_tv_up_to() {
        assert_lint_count(
            "it opens the TV up to a massive library of software",
            OpenTheLight::default(),
            0,
        );
    }

    #[test]
    #[ignore = "Requires more complex context parsing"]
    fn dont_flag_open_the_light_slash_sound() {
        assert_lint_count(
            "To do so, open the light/sound configuration.",
            OpenTheLight::default(),
            0,
        );
    }

    #[test]
    #[ignore = "Not common enough"]
    fn dont_flag_cutting_open() {
        assert_lint_count(
            "However, instead of cutting open the lights, I opted to 3D print the Minecraft Torch Nightlight",
            OpenTheLight::default(),
            0,
        );
    }

    #[test]
    fn dont_flag_open_the_light_source() {
        assert_lint_count(
            "open the light source light and regulate it to the suitable luminance",
            OpenTheLight::default(),
            0,
        );
    }

    #[test]
    #[ignore = "Requires more complex context parsing"]
    fn dont_flag_opening_lamp() {
        assert_lint_count(
            "After opening the lamp, you need to solder 4 wires to the board in order to connect the USB-to-Serial adapter.",
            OpenTheLight::default(),
            0,
        );
    }

    #[test]
    fn dont_flag_fan_control() {
        assert_lint_count(
            "It seems like it opens the fan control? ",
            OpenTheLight::default(),
            0,
        );
    }

    #[test]
    #[ignore = "Requires more complex context parsing"]
    fn dont_flag_open_tv_to_access_eeprom() {
        assert_lint_count(
            "Involves opening your TV and directly accessing the an EEPROM IC.",
            OpenTheLight::default(),
            0,
        );
    }

    #[test]
    fn dont_flag_open_tv_viewing_application() {
        assert_lint_count(
            "Open your TV viewing application or platform.",
            OpenTheLight::default(),
            0,
        );
    }

    #[test]
    #[ignore = "Requires more complex context parsing"]
    fn dont_flag_open_as_noun() {
        assert_lint_count(
            "when we press open the lamp will be on",
            OpenTheLight::default(),
            0,
        );
    }

    #[test]
    #[ignore = "Requires more complex context parsing"]
    fn dont_flag_opening_as_noun() {
        assert_lint_count(
            "and through that opening the light was streaming in",
            OpenTheLight::default(),
            0,
        );
    }

    #[test]
    fn fix_opening_fan() {
        assert_suggestion_result(
            "If the CO2 passed a set point, it would open the fan, and close it once CO2 dropped enough.",
            OpenTheLight::default(),
            "If the CO2 passed a set point, it would turn on the fan, and close it once CO2 dropped enough.",
        );
    }

    #[test]
    fn fix_opening_tv() {
        assert_suggestion_result(
            "This was to prevent me from falling back into the temptation of opening the TV and breaking up the rule I wanted to implement.",
            OpenTheLight::default(),
            "This was to prevent me from falling back into the temptation of turning on the TV and breaking up the rule I wanted to implement.",
        );
    }

    #[test]
    #[ignore = "We don't yet handle hyphenated words"]
    fn dont_flag_opens_fan_like() {
        assert_lint_count(
            "Out by the garden fence the high ice plant opens its fan-like petals to the sun.",
            OpenTheLight::default(),
            0,
        );
    }

    #[test]
    fn fix_opening_lights() {
        assert_suggestion_result(
            "Steering wheel remains blocked until I open my lights.",
            OpenTheLight::default(),
            "Steering wheel remains blocked until I turn on my lights.",
        );
    }
}



================================================
FILE: harper-core/src/linting/orthographic_consistency.rs
================================================
use crate::linting::{LintKind, Suggestion};
use std::sync::Arc;

use crate::expr::Expr;
use crate::spell::{Dictionary, FstDictionary};
use crate::{OrthFlags, Token};

use super::{ExprLinter, Lint};
use crate::linting::expr_linter::Chunk;

pub struct OrthographicConsistency {
    dict: Arc<FstDictionary>,
    expr: Box<dyn Expr>,
}

impl OrthographicConsistency {
    pub fn new() -> Self {
        Self {
            dict: FstDictionary::curated(),
            expr: Box::new(|tok: &Token, _: &[char]| tok.kind.is_word()),
        }
    }
}

impl Default for OrthographicConsistency {
    fn default() -> Self {
        Self::new()
    }
}

impl ExprLinter for OrthographicConsistency {
    type Unit = Chunk;

    fn description(&self) -> &str {
        "Ensures word casing matches the dictionary's canonical orthography."
    }

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint_with_context(
        &self,
        matched_tokens: &[Token],
        source: &[char],
        context: Option<(&[Token], &[Token])>,
    ) -> Option<Lint> {
        if let Some((pre, post)) = context {
            if let Some(pre_tok) = pre.last()
                && pre_tok.kind.is_hyphen()
            {
                return None;
            }

            if let Some(post_tok) = post.first()
                && post_tok.kind.is_hyphen()
            {
                return None;
            }
        }

        let word = &matched_tokens[0];

        let Some(Some(metadata)) = word.kind.as_word() else {
            return None;
        };

        let chars = word.span.get_content(source);

        let cur_flags = OrthFlags::from_letters(chars);

        if metadata.is_allcaps()
            && !metadata.is_lowercase()
            && !metadata.is_upper_camel()
            && !cur_flags.contains(OrthFlags::ALLCAPS)
        {
            return Some(Lint {
                span: word.span,
                lint_kind: LintKind::Capitalization,
                suggestions: vec![Suggestion::ReplaceWith(
                    chars.iter().map(|c| c.to_ascii_uppercase()).collect(),
                )],
                message: "This word's canonical spelling is all-caps.".to_owned(),
                priority: 127,
            });
        }

        let canonical_flags = metadata.orth_info;
        let flags_to_check = [
            OrthFlags::LOWER_CAMEL,
            OrthFlags::UPPER_CAMEL,
            OrthFlags::APOSTROPHE,
            OrthFlags::HYPHENATED,
        ];

        if flags_to_check
            .into_iter()
            .filter(|flag| canonical_flags.contains(*flag) != cur_flags.contains(*flag))
            .count()
            == 1
            && let Some(canonical) = self.dict.get_correct_capitalization_of(chars)
            && alphabetic_differs(canonical, chars)
        {
            return Some(Lint {
                span: word.span,
                lint_kind: LintKind::Capitalization,
                suggestions: vec![Suggestion::ReplaceWith(canonical.to_vec())],
                message: format!(
                    "The canonical dictionary spelling is `{}`.",
                    canonical.iter().collect::<String>()
                ),
                priority: 31,
            });
        }

        if metadata.is_titlecase()
            && cur_flags.contains(OrthFlags::LOWERCASE)
            && let Some(canonical) = self.dict.get_correct_capitalization_of(chars)
            && alphabetic_differs(canonical, chars)
        {
            return Some(Lint {
                span: word.span,
                lint_kind: LintKind::Capitalization,
                suggestions: vec![Suggestion::ReplaceWith(canonical.to_vec())],
                message: format!(
                    "The canonical dictionary spelling is title case: `{}`.",
                    canonical.iter().collect::<String>()
                ),
                priority: 127,
            });
        }

        None
    }
}

/// Check if the alphabetic characters in the string differ from one another.
/// Ignores non-alphabetic characters.
fn alphabetic_differs(a: &[char], b: &[char]) -> bool {
    a.iter()
        .zip(b.iter())
        .any(|(a, b)| a.is_alphabetic() && b.is_alphabetic() && a != b)
}

#[cfg(test)]
mod tests {
    use crate::linting::tests::{assert_no_lints, assert_suggestion_result};

    use super::OrthographicConsistency;

    #[test]
    fn nasa_should_be_all_caps() {
        assert_suggestion_result(
            "Nasa is a governmental institution.",
            OrthographicConsistency::default(),
            "NASA is a governmental institution.",
        );
    }

    #[test]
    fn ikea_should_be_all_caps() {
        assert_suggestion_result(
            "Ikea operates a vast retail network.",
            OrthographicConsistency::default(),
            "IKEA operates a vast retail network.",
        );
    }

    #[test]
    fn lego_should_be_all_caps() {
        assert_suggestion_result(
            "Lego bricks encourage creativity.",
            OrthographicConsistency::default(),
            "LEGO bricks encourage creativity.",
        );
    }

    #[test]
    fn nato_should_be_all_caps() {
        assert_suggestion_result(
            "Nato is a military alliance.",
            OrthographicConsistency::default(),
            "NATO is a military alliance.",
        );
    }

    #[test]
    fn fbi_should_be_all_caps() {
        assert_suggestion_result(
            "Fbi investigates federal crimes.",
            OrthographicConsistency::default(),
            "FBI investigates federal crimes.",
        );
    }

    #[test]
    fn cia_should_be_all_caps() {
        assert_suggestion_result(
            "Cia gathers intelligence.",
            OrthographicConsistency::default(),
            "CIA gathers intelligence.",
        );
    }

    #[test]
    fn hiv_should_be_all_caps() {
        assert_suggestion_result(
            "Hiv is a virus.",
            OrthographicConsistency::default(),
            "HIV is a virus.",
        );
    }

    #[test]
    fn dna_should_be_all_caps() {
        assert_suggestion_result(
            "Dna carries genetic information.",
            OrthographicConsistency::default(),
            "DNA carries genetic information.",
        );
    }

    #[test]
    fn rna_should_be_all_caps() {
        assert_suggestion_result(
            "Rna participates in protein synthesis.",
            OrthographicConsistency::default(),
            "RNA participates in protein synthesis.",
        );
    }

    #[test]
    fn cpu_should_be_all_caps() {
        assert_suggestion_result(
            "Cpu executes instructions.",
            OrthographicConsistency::default(),
            "CPU executes instructions.",
        );
    }

    #[test]
    fn gpu_should_be_all_caps() {
        assert_suggestion_result(
            "Gpu accelerates graphics.",
            OrthographicConsistency::default(),
            "GPU accelerates graphics.",
        );
    }

    #[test]
    fn html_should_be_all_caps() {
        assert_suggestion_result(
            "Html structures web documents.",
            OrthographicConsistency::default(),
            "HTML structures web documents.",
        );
    }

    #[test]
    fn url_should_be_all_caps() {
        assert_suggestion_result(
            "Url identifies a resource.",
            OrthographicConsistency::default(),
            "URL identifies a resource.",
        );
    }

    #[test]
    fn faq_should_be_all_caps() {
        assert_suggestion_result(
            "Faq answers common questions.",
            OrthographicConsistency::default(),
            "FAQ answers common questions.",
        );
    }

    #[test]
    fn linkedin_should_use_canonical_case() {
        assert_suggestion_result(
            "I updated my linkedin profile yesterday.",
            OrthographicConsistency::default(),
            "I updated my LinkedIn profile yesterday.",
        );
    }

    #[test]
    fn wordpress_should_use_canonical_case() {
        assert_suggestion_result(
            "She writes daily on her wordpress blog.",
            OrthographicConsistency::default(),
            "She writes daily on her WordPress blog.",
        );
    }

    #[test]
    fn pdf_should_be_all_caps() {
        assert_suggestion_result(
            "Pdf preserves formatting.",
            OrthographicConsistency::default(),
            "PDF preserves formatting.",
        );
    }

    #[test]
    fn ceo_should_be_all_caps() {
        assert_suggestion_result(
            "Our Ceo approved the budget.",
            OrthographicConsistency::default(),
            "Our CEO approved the budget.",
        );
    }

    #[test]
    fn cfo_should_be_all_caps() {
        assert_suggestion_result(
            "The Cfo presented the report.",
            OrthographicConsistency::default(),
            "The CFO presented the report.",
        );
    }

    #[test]
    fn hr_should_be_all_caps() {
        assert_suggestion_result(
            "The Hr team scheduled interviews.",
            OrthographicConsistency::default(),
            "The HR team scheduled interviews.",
        );
    }

    #[test]
    fn ai_should_be_all_caps() {
        assert_suggestion_result(
            "Ai enables new capabilities.",
            OrthographicConsistency::default(),
            "AI enables new capabilities.",
        );
    }

    #[test]
    fn ufo_should_be_all_caps() {
        assert_suggestion_result(
            "Ufo sightings provoke debate.",
            OrthographicConsistency::default(),
            "UFO sightings provoke debate.",
        );
    }

    #[test]
    fn markdown_should_be_caps() {
        assert_suggestion_result(
            "I adore markdown.",
            OrthographicConsistency::default(),
            "I adore Markdown.",
        );
    }

    #[test]
    fn canonical_forms_should_not_be_flagged() {
        let sentences = [
            "NASA is a governmental institution.",
            "IKEA operates a vast retail network.",
            "LEGO bricks encourage creativity.",
            "NATO is a military alliance.",
            "FBI investigates federal crimes.",
            "CIA gathers intelligence.",
            "HIV is a virus.",
            "DNA carries genetic information.",
            "RNA participates in protein synthesis.",
            "CPU executes instructions.",
            "GPU accelerates graphics.",
            "HTML structures web documents.",
            "URL identifies a resource.",
            "FAQ answers common questions.",
            "I updated my LinkedIn profile yesterday.",
            "She writes daily on her WordPress blog.",
            "PDF preserves formatting.",
            "Our CEO approved the budget.",
            "The CFO presented the report.",
            "The HR team scheduled interviews.",
            "AI enables new capabilities.",
            "UFO sightings provoke debate.",
            "I adore Markdown.",
        ];

        for sentence in sentences {
            assert_no_lints(sentence, OrthographicConsistency::default());
        }
    }

    #[test]
    fn allows_news() {
        assert_no_lints(
            "This is the best part of the news broadcast.",
            OrthographicConsistency::default(),
        );
    }

    #[test]
    fn allows_issue_2465() {
        assert_no_lints(
            "The post’s problem was not in its complexity.",
            OrthographicConsistency::default(),
        );
    }
}



================================================
FILE: harper-core/src/linting/ought_to_be.rs
================================================
use crate::TokenKind;
use crate::expr::{AnchorStart, Expr, ExprMap, FixedPhrase, SequenceExpr};
use crate::linting::expr_linter::Chunk;
use crate::{
    Token,
    linting::{ExprLinter, Lint, LintKind, Suggestion},
};

/// Detects the eggcorn `out to be` when the intended phrase is `ought to be`.
///
/// Legitimate phrasal-verb uses like `turn out to be`, `work out to be`, or
/// `make it out to be` are ignored.
pub struct OughtToBe {
    expr: Box<dyn Expr>,
    map: std::sync::Arc<ExprMap<usize>>, // index of the `out` token within the match
}

impl Default for OughtToBe {
    fn default() -> Self {
        use std::sync::Arc;

        // We’ll construct three branches and record where the `out` token sits in each.
        // 1) non-verb word + pronoun + "out to be"  → index of `out` = 4 tokens after start
        //    [word(!verb)] [ws] [pronoun] [ws] [out] [ws] [to] [ws] [be]
        let branch_nonverb_pronoun = SequenceExpr::default()
            .then_kind_is_but_is_not(TokenKind::is_word, TokenKind::is_verb)
            .then_whitespace()
            .then_pronoun()
            .then_whitespace()
            .then(FixedPhrase::from_phrase("out to be"));

        // 2) start-of-sentence + pronoun + "out to be" → index of `out` = 2 tokens after start
        //    [AnchorStart] [pronoun] [ws] [out] [ws] [to] [ws] [be]
        let branch_anchor_pronoun = SequenceExpr::default()
            .then(AnchorStart)
            .then_pronoun()
            .then_whitespace()
            .then(FixedPhrase::from_phrase("out to be"));

        // 3) punctuation + pronoun + "out to be" → index of `out` = 4 tokens after start
        //    [punct] [ws] [pronoun] [ws] [out] [ws] [to] [ws] [be]
        let branch_punct_pronoun = SequenceExpr::default()
            .then_punctuation()
            .then_whitespace()
            .then_pronoun()
            .then_whitespace()
            .then(FixedPhrase::from_phrase("out to be"));

        let mut map = ExprMap::default();
        map.insert(branch_nonverb_pronoun, 4);
        map.insert(branch_anchor_pronoun, 2);
        map.insert(branch_punct_pronoun, 4);

        let map = Arc::new(map);

        Self {
            expr: Box::new(map.clone()),
            map,
        }
    }
}

impl ExprLinter for OughtToBe {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched: &[Token], source: &[char]) -> Option<Lint> {
        // Find which branch matched and where the `out` token sits.
        let out_index = *self.map.lookup(0, matched, source)?;
        let out_tok = matched.get(out_index)?;
        let replace_span = out_tok.span; // only replace the word `out`
        let original = replace_span.get_content(source);
        Some(Lint {
            span: replace_span,
            lint_kind: LintKind::Eggcorn,
            suggestions: vec![Suggestion::replace_with_match_case(
                "ought".chars().collect(),
                original,
            )],
            message: "Did you mean `ought to be` (expressing expectation or obligation)?"
                .to_string(),
            priority: 31,
        })
    }

    fn description(&self) -> &str {
        "Detects the mistaken `out to be` and suggests `ought to be`, while ignoring legitimate phrasal-verb uses such as `turn out to be` and `make it out to be`."
    }
}

#[cfg(test)]
mod tests {
    use super::OughtToBe;
    use crate::linting::tests::{assert_lint_count, assert_suggestion_result};

    // Flagged examples
    #[test]
    fn flags_you_out_to_be_able_to_see() {
        assert_suggestion_result(
            "you out to be able to see",
            OughtToBe::default(),
            "you ought to be able to see",
        );
    }

    #[test]
    fn flags_as_it_out_to_be() {
        assert_suggestion_result("as it out to be", OughtToBe::default(), "as it ought to be");
    }

    #[test]
    fn flags_then_it_out_to_be() {
        assert_suggestion_result(
            "then it out to be",
            OughtToBe::default(),
            "then it ought to be",
        );
    }

    // Legit phrasal-verb cases that should be ignored
    #[test]
    fn ignores_turned_out_to_be() {
        assert_lint_count("It turned out to be fine.", OughtToBe::default(), 0);
    }

    #[test]
    fn ignores_turns_out_to_be() {
        assert_lint_count("It turns out to be fine.", OughtToBe::default(), 0);
    }

    #[test]
    fn ignores_make_it_out_to_be() {
        assert_lint_count(
            "It's not as simple as they make it out to be.",
            OughtToBe::default(),
            0,
        );
    }

    #[test]
    fn ignores_makes_it_out_to_be() {
        assert_lint_count(
            "I think this rule may not be as smart as its definition makes it out to be.",
            OughtToBe::default(),
            0,
        );
    }

    #[test]
    fn ignores_worked_out_to_be() {
        assert_lint_count("It worked out to be $5.", OughtToBe::default(), 0);
    }

    #[test]
    fn ignores_figured_it_out_to_be() {
        assert_lint_count(
            "I figured it out to be a memory issue.",
            OughtToBe::default(),
            0,
        );
    }

    #[test]
    fn ignores_try_it_out_to_be() {
        assert_lint_count("Try it out to be sure.", OughtToBe::default(), 0);
    }

    #[test]
    fn ignores_separate_it_out_to_be() {
        assert_lint_count(
            "I want to separate it out to be able to process it later.",
            OughtToBe::default(),
            0,
        );
    }

    #[test]
    fn ignores_rotate_it_out_to_be() {
        assert_lint_count(
            "We will rotate it out to be eventually deleted.",
            OughtToBe::default(),
            0,
        );
    }

    #[test]
    fn ignores_flesh_it_out_to_be() {
        assert_lint_count(
            "This needs some work to flesh it out to be usable.",
            OughtToBe::default(),
            0,
        );
    }
}



================================================
FILE: harper-core/src/linting/out_of_date.rs
================================================
use crate::expr::Expr;
use crate::expr::FirstMatchOf;
use crate::expr::FixedPhrase;
use crate::{Token, TokenStringExt};

use super::{ExprLinter, Lint, LintKind, Suggestion};
use crate::linting::expr_linter::Chunk;

pub struct OutOfDate {
    expr: Box<dyn Expr>,
}

impl Default for OutOfDate {
    fn default() -> Self {
        let pattern = FirstMatchOf::new(vec![
            Box::new(FixedPhrase::from_phrase("out of date")),
            Box::new(FixedPhrase::from_phrase("out-of date")),
            Box::new(FixedPhrase::from_phrase("out of-date")),
        ]);

        Self {
            expr: Box::new(pattern),
        }
    }
}

impl ExprLinter for OutOfDate {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], source: &[char]) -> Option<Lint> {
        let span = matched_tokens.span()?;
        let problem_text = span.get_content(source);

        Some(Lint {
            span,
            lint_kind: LintKind::Miscellaneous,
            suggestions: vec![Suggestion::replace_with_match_case(
                "out-of-date".chars().collect(),
                problem_text,
            )],
            message: "Did you mean the compound adjective?".to_owned(),
            priority: 31,
        })
    }

    fn description(&self) -> &'static str {
        "Ensures that the phrase `out of date` is written with a hyphen as `out-of-date` when used as a compound adjective."
    }
}

#[cfg(test)]
mod tests {
    use super::OutOfDate;
    use crate::linting::tests::assert_suggestion_result;

    #[test]
    fn corrects_out_of_date() {
        assert_suggestion_result(
            "The software is out of date.",
            OutOfDate::default(),
            "The software is out-of-date.",
        );
    }

    #[test]
    fn corrects_out_of_date_with_variation() {
        assert_suggestion_result(
            "This information is out of-date.",
            OutOfDate::default(),
            "This information is out-of-date.",
        );
    }

    #[test]
    fn allows_correct_usage() {
        assert_suggestion_result(
            "The guidelines are out-of-date.",
            OutOfDate::default(),
            "The guidelines are out-of-date.",
        );
    }
}



================================================
FILE: harper-core/src/linting/oxford_comma.rs
================================================
use crate::expr::Expr;
use crate::expr::ExprExt;
use crate::expr::OwnedExprExt;
use crate::expr::SequenceExpr;
use crate::{Lrc, Token, TokenStringExt, linting::Linter, patterns::WordSet};

use super::{super::Lint, LintKind, Suggestion};

pub struct OxfordComma {
    expr: Box<dyn Expr>,
}

impl Default for OxfordComma {
    fn default() -> Self {
        let item = Lrc::new(
            SequenceExpr::default()
                .then_determiner()
                .then_whitespace()
                .then_nominal()
                .or_longest(SequenceExpr::default().then_nominal()),
        );

        let item_chunk = SequenceExpr::default()
            .then(item.clone())
            .then_comma()
            .then_whitespace();

        let pattern = SequenceExpr::default()
            .then_one_or_more(item_chunk)
            .then(item.clone())
            .then_whitespace()
            .then(WordSet::new(&["and", "or", "nor"]))
            .then_whitespace()
            .then(item.clone());

        Self {
            expr: Box::new(pattern),
        }
    }
}

impl OxfordComma {
    fn match_to_lint(&self, matched_toks: &[Token], _source: &[char]) -> Option<Lint> {
        let conj_index = matched_toks.last_conjunction_index()?;
        let offender = &matched_toks[conj_index - 2];

        Some(Lint {
            span: offender.span,
            lint_kind: LintKind::Style,
            suggestions: vec![Suggestion::InsertAfter(vec![','])],
            message: "An Oxford comma is necessary here.".to_owned(),
            priority: 31,
        })
    }
}

impl Linter for OxfordComma {
    fn lint(&mut self, document: &crate::Document) -> Vec<crate::linting::Lint> {
        let mut lints = Vec::new();
        for sentence in document.iter_sentences() {
            let mut skip = 0;

            let mut words = sentence
                .iter_words()
                .filter_map(|v| v.kind.as_word())
                .flatten();

            if let (Some(first), Some(second)) = (words.next(), words.next())
                && first.preposition
                && second.is_likely_homograph()
            {
                skip = sentence
                    .iter()
                    .position(|t| t.kind.is_comma())
                    .unwrap_or(sentence.iter().len())
            }

            let sentence = &sentence[skip..];

            for match_span in self.expr.iter_matches(sentence, document.get_source()) {
                let lint = self.match_to_lint(
                    &sentence[match_span.start..match_span.end],
                    document.get_source(),
                );
                lints.extend(lint);
            }
        }

        lints
    }

    fn description(&self) -> &str {
        "The Oxford comma is one of the more controversial rules in common use today. Enabling this lint checks that there is a comma before `and`, `or`, or `nor` when listing out more than two ideas."
    }
}

#[cfg(test)]
mod tests {
    use crate::linting::tests::{assert_lint_count, assert_suggestion_result};

    use super::OxfordComma;

    #[test]
    fn fruits() {
        assert_lint_count(
            "An apple, a banana and a pear walk into a bar.",
            OxfordComma::default(),
            1,
        );
    }

    #[test]
    fn people() {
        assert_suggestion_result(
            "Nancy, Steve and Carl are going to the coffee shop.",
            OxfordComma::default(),
            "Nancy, Steve, and Carl are going to the coffee shop.",
        );
    }

    #[test]
    fn places() {
        assert_suggestion_result(
            "I've always wanted to visit Paris, Tokyo and Rome.",
            OxfordComma::default(),
            "I've always wanted to visit Paris, Tokyo, and Rome.",
        );
    }

    #[test]
    fn foods() {
        assert_suggestion_result(
            "My favorite foods are pizza, sushi, tacos and burgers.",
            OxfordComma::default(),
            "My favorite foods are pizza, sushi, tacos, and burgers.",
        );
    }

    #[test]
    fn allows_clean_music() {
        assert_lint_count(
            "I enjoy listening to pop music, rock, hip-hop, electronic dance, and classical music.",
            OxfordComma::default(),
            0,
        );
    }

    #[test]
    fn allows_clean_nations() {
        assert_lint_count(
            "The team consists of players from different countries: France, Germany, Italy, and Spain.",
            OxfordComma::default(),
            0,
        );
    }

    #[test]
    fn or_writing() {
        assert_suggestion_result(
            "Harper can be a lifesaver when writing technical documents, emails or other formal forms of communication.",
            OxfordComma::default(),
            "Harper can be a lifesaver when writing technical documents, emails, or other formal forms of communication.",
        );
    }

    #[test]
    fn sports() {
        assert_suggestion_result(
            "They enjoy playing soccer, basketball or tennis.",
            OxfordComma::default(),
            "They enjoy playing soccer, basketball, or tennis.",
        );
    }

    #[test]
    fn nor_vegetables() {
        assert_suggestion_result(
            "I like carrots, kale nor broccoli.",
            OxfordComma::default(),
            "I like carrots, kale, nor broccoli.",
        );
    }

    #[test]
    fn allow_non_list_transportation() {
        assert_lint_count(
            "In transportation, autonomous vehicles and smart traffic management systems promise to reduce accidents and optimize travel routes.",
            OxfordComma::default(),
            0,
        );
    }

    #[test]
    fn allow_pill() {
        assert_lint_count(
            "Develop a pill that causes partial amnesia, affecting relationships and identity.",
            OxfordComma::default(),
            0,
        );
    }

    #[test]
    fn allow_at_first() {
        assert_lint_count(
            "In the heart of a bustling city, Sarah finds herself trapped in an endless cycle of the same day. Each morning, she awakens to find the date unchanged, her life on repeat. At first, confusion and frustration cloud her thoughts, but soon she notices something peculiar—each day has tiny differences, subtle changes that hint at a larger pattern.",
            OxfordComma::default(),
            0,
        );
    }

    #[test]
    fn allow_standoff() {
        assert_lint_count(
            "In a tense standoff, Alex and his reflection engage in a battle of wills.",
            OxfordComma::default(),
            0,
        );
    }
}



================================================
FILE: harper-core/src/linting/oxymorons.rs
================================================
use crate::expr::Expr;
use crate::expr::FirstMatchOf;
use crate::expr::FixedPhrase;
use crate::linting::expr_linter::Chunk;
use crate::linting::{ExprLinter, Lint, LintKind};
use crate::{Token, TokenStringExt};

/// A linter that flags oxymoronic phrases.
pub struct Oxymorons {
    expr: Box<dyn Expr>,
}

impl Oxymorons {
    pub fn new() -> Self {
        // List of phrases that are considered oxymoronic.
        let phrases = vec![
            "amateur expert",
            "increasingly less",
            "advancing backwards?",
            "alludes explicitly to",
            "explicitly alludes to",
            "totally obsolescent",
            "completely obsolescent",
            "generally always",
            "usually always",
            "build down",
            "conspicuous absence",
            "exact estimate",
            "found missing",
            "intense apathy",
            "mandatory choice",
            "nonworking mother",
            "organized mess",
        ];

        // Build a vector of exact-match patterns for each oxymoron.
        let exprs: Vec<Box<dyn Expr>> = phrases
            .into_iter()
            .map(|s| Box::new(FixedPhrase::from_phrase(s)) as Box<dyn Expr>)
            .collect();

        let expr = Box::new(FirstMatchOf::new(exprs));
        Self { expr }
    }
}

impl Default for Oxymorons {
    fn default() -> Self {
        Self::new()
    }
}

impl ExprLinter for Oxymorons {
    type Unit = Chunk;

    /// Returns the underlying pattern.
    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], source: &[char]) -> Option<Lint> {
        let span = matched_tokens.span()?;
        let matched_text: String = span.get_content(source).iter().collect();
        Some(Lint {
            span,
            lint_kind: LintKind::Miscellaneous,
            suggestions: Vec::new(),
            message: format!("'{matched_text}' is an oxymoron."),
            priority: 31,
        })
    }

    fn description(&self) -> &str {
        "Flags oxymoronic phrases (e.g. `amateur expert`, `increasingly less`, etc.)."
    }
}

#[cfg(test)]
mod tests {
    use super::Oxymorons;
    use crate::linting::tests::assert_lint_count;

    #[test]
    fn detects_amateur_expert() {
        assert_lint_count("The amateur expert gave his opinion.", Oxymorons::new(), 1);
    }

    #[test]
    fn detects_increasingly_less() {
        assert_lint_count(
            "The solution was increasingly less effective.",
            Oxymorons::new(),
            1,
        );
    }

    #[test]
    fn detects_advancing_backwards() {
        assert_lint_count("The project is advancing backwards?", Oxymorons::new(), 1);
    }

    #[test]
    fn detects_alludes_explicitly_to() {
        assert_lint_count(
            "The report alludes explicitly to several issues.",
            Oxymorons::new(),
            1,
        );
    }

    #[test]
    fn detects_explicitly_alludes_to() {
        assert_lint_count(
            "The report explicitly alludes to several issues.",
            Oxymorons::new(),
            1,
        );
    }

    #[test]
    fn does_not_flag_clean_text() {
        assert_lint_count("The expert provided clear advice.", Oxymorons::new(), 0);
    }

    #[test]
    fn lowercase_match() {
        assert_lint_count(
            "the amateur expert is often unreliable.",
            Oxymorons::new(),
            1,
        );
    }

    #[test]
    fn phrase_with_extra_whitespace() {
        assert_lint_count("An organized    mess was found.", Oxymorons::new(), 1);
    }

    #[test]
    fn phrase_split_by_line_break() {
        assert_lint_count(
            "nonworking\nmother is not a term to be used.",
            Oxymorons::new(),
            1,
        );
    }
}



================================================
FILE: harper-core/src/linting/phrasal_verb_as_compound_noun.rs
================================================
use std::sync::Arc;

use super::{Lint, LintKind, Linter, Suggestion};
use crate::spell::{Dictionary, FstDictionary};
use crate::{CharStringExt, Document, Span, TokenStringExt};

/// Detect phrasal verbs written as compound nouns.
pub struct PhrasalVerbAsCompoundNoun {
    dict: Arc<FstDictionary>,
}

enum Confidence {
    DefinitelyVerb,
    PossiblyVerb,
}

impl PhrasalVerbAsCompoundNoun {
    pub fn new() -> Self {
        Self {
            dict: FstDictionary::curated(),
        }
    }
}

impl Default for PhrasalVerbAsCompoundNoun {
    fn default() -> Self {
        Self {
            dict: FstDictionary::curated(),
        }
    }
}

impl Linter for PhrasalVerbAsCompoundNoun {
    fn lint(&mut self, document: &Document) -> Vec<Lint> {
        let mut lints = Vec::new();
        for i in document.iter_noun_indices() {
            // It would be handy if there could be a dict flag for nouns which are compounds of phrasal verbs.
            // Instead, let's use a few heuristics.
            let token = document.get_token(i).unwrap();
            // * Can't also be a proper noun or a real verb.
            if token.kind.is_proper_noun() || token.kind.is_verb() {
                continue;
            }
            let nountok_charsl = document.get_span_content(&token.span);
            // * Can't contain space, hyphen or apostrophe
            if nountok_charsl.contains(&' ')
                || nountok_charsl.contains(&'-')
                || nountok_charsl.contains(&'\'')
                || nountok_charsl.contains(&'’')
            {
                continue;
            }

            let nountok_lower = nountok_charsl.to_lower();
            let nountok_lower = nountok_lower.as_ref();

            // * Must not be in the set of known false positives.
            if nountok_lower == ['g', 'a', 'l', 'l', 'o', 'n']
                || nountok_lower == ['d', 'r', 'a', 'g', 'o', 'n']
            {
                continue;
            }

            // * Must end with the same letters as one of the particles used in phrasal verbs.
            let particle_endings: &[&[char]] = &[
                &['a', 'r', 'o', 'u', 'n', 'd'],
                &['b', 'a', 'c', 'k'],
                &['d', 'o', 'w', 'n'],
                &['i', 'n'],
                &['o', 'n'],
                &['o', 'f', 'f'],
                &['o', 'u', 't'],
                &['o', 'v', 'e', 'r'],
                &['u', 'p'],
            ];

            let mut found_particle_len = 0;
            if !particle_endings.iter().any(|ending| {
                let ending_len = ending.len();
                if ending_len <= nountok_charsl.len()
                    && ending
                        .iter()
                        .eq(nountok_charsl[nountok_charsl.len() - ending_len..].iter())
                {
                    found_particle_len = ending_len;
                    true
                } else {
                    false
                }
            }) {
                continue;
            }

            let verb_part = &nountok_charsl[..nountok_charsl.len() - found_particle_len];
            let particle_part = &nountok_charsl[nountok_charsl.len() - found_particle_len..];
            let phrasal_verb: String = verb_part
                .iter()
                .chain(std::iter::once(&' '))
                .chain(particle_part.iter())
                .collect();

            // Check if both things are verbs.
            // So far we only have a small number of phrasal verbs in the dictionary.
            let (verb_part_is_verb, phrasal_verb_is_verb) = (
                self.dict
                    .get_word_metadata(verb_part)
                    .is_some_and(|md| md.verb.is_some()),
                self.dict
                    .get_word_metadata_str(&phrasal_verb)
                    .is_some_and(|md| md.verb.is_some()),
            );

            // If neither is a verb, then it's not a phrasal verb
            if !verb_part_is_verb && !phrasal_verb_is_verb {
                continue;
            }

            // Now we know it matches the pattern of a phrasal verb erroneously written as a compound noun.
            // But we have to check if it's an actual compound noun rather than an error.
            // For that we need some heuristics based on the surrounding context.
            // Let's try to get the word before and the word after.
            // To do that we have to get the tokens immediately before and after, which we expect to be whitespace.
            let maybe_prev_tok = document.get_next_word_from_offset(i, -1);
            let maybe_next_tok = document.get_next_word_from_offset(i, 1);

            // If it's in isolation, a compound noun is fine.
            if maybe_prev_tok.is_none() && maybe_next_tok.is_none() {
                continue;
            }

            let confidence = match (phrasal_verb_is_verb, verb_part_is_verb) {
                (true, _) => Confidence::DefinitelyVerb,
                (false, true) => Confidence::PossiblyVerb,
                _ => continue,
            };

            if let Some(prev_tok) = maybe_prev_tok {
                if prev_tok.kind.is_adjective() || prev_tok.kind.is_determiner() {
                    continue;
                }

                // "dictionary lookup" is not a mistake but "couples breakup" is.
                // But "settings plugin" is not.
                if prev_tok.kind.is_noun() && !prev_tok.kind.is_plural_noun()
                    || prev_tok
                        .span
                        .get_content(document.get_source())
                        .eq_ignore_ascii_case_str("settings")
                {
                    continue;
                }

                if is_part_of_noun_list(document, i) {
                    continue;
                }

                // If the previous word is (only) a preposition, this word is surely a noun
                if prev_tok.kind.is_preposition()
                    && !prev_tok
                        .span
                        .get_content(document.get_source())
                        .eq_ignore_ascii_case_str("to")
                {
                    continue;
                }

                // If the previous word is OOV, those are most commonly nouns
                if prev_tok.kind.is_oov() {
                    continue;
                }
            }

            // A preposition may follow either a verb or a noun.
            // A previous word can help us decide. Without one we can't decide so we won't flag it.
            // ❌ I will never breakup with Gym.
            // ✅ Plugin for text editors.
            // ✅ Plug in for faster performance.
            if maybe_prev_tok.is_none()
                && let Some(next_tok) = maybe_next_tok
                && next_tok.kind.is_preposition()
            {
                continue;
            }

            if let Some(next_tok) = maybe_next_tok {
                // "That" or "which" can follow a noun as relative pronouns.
                if next_tok.kind.is_pronoun()
                    && next_tok
                        .span
                        .get_content(document.get_source())
                        .eq_any_ignore_ascii_case_chars(&[
                            &['t', 'h', 'a', 't'][..],
                            &['w', 'h', 'i', 'c', 'h'][..],
                        ])
                {
                    continue;
                }
            }

            // If the compound noun is followed by another noun, check for larger compound nouns.
            if let Some(next_tok) = maybe_next_tok.filter(|tok| tok.kind.is_noun())
                && match nountok_lower {
                    ['b', 'a', 'c', 'k', 'u', 'p'] => {
                        &["file", "images", "location", "plan", "sites", "snapshots"][..]
                    }
                    ['c', 'a', 'l', 'l', 'b', 'a', 'c', 'k'] => &["function", "handlers"][..],
                    ['l', 'a', 'y', 'o', 'u', 't'] => &["estimation"][..],
                    ['m', 'a', 'r', 'k', 'u', 'p'] => &["language", "languages"][..],
                    ['m', 'o', 'u', 's', 'e', 'o', 'v', 'e', 'r'] => &["hints"][..],
                    ['p', 'l', 'a', 'y', 'b', 'a', 'c', 'k'] => &["latency", "speed"][..],
                    ['p', 'l', 'u', 'g', 'i', 'n'] => &[
                        "architecture",
                        "classes",
                        "development",
                        "developer",
                        "docs",
                        "ecosystem",
                        "files",
                        "interface",
                        "name",
                        "packages",
                        "suite",
                        "support",
                    ][..],
                    ['p', 'o', 'p', 'u', 'p'] => &["window"][..],
                    ['r', 'o', 'l', 'l', 'o', 'u', 't'] => &["logic", "status"][..],
                    ['s', 't', 'a', 'r', 't', 'u', 'p'] => &["environments"][..],
                    ['t', 'h', 'r', 'o', 'w', 'b', 'a', 'c', 'k'] => &["machine"][..],
                    ['w', 'o', 'r', 'k', 'o', 'u', 't'] => &["constraints", "preference"][..],
                    _ => &[],
                }
                .contains(
                    &next_tok
                        .span
                        .get_content_string(document.get_source())
                        .to_lowercase()
                        .as_ref(),
                )
            {
                continue;
            }

            let message = match confidence {
                Confidence::DefinitelyVerb => {
                    "This word should be a phrasal verb, not a compound noun."
                }
                Confidence::PossiblyVerb => {
                    "This word might be a phrasal verb rather than a compound noun."
                }
            };

            lints.push(Lint {
                span: Span::new(token.span.start, token.span.end),
                lint_kind: LintKind::WordChoice,
                suggestions: vec![Suggestion::ReplaceWith(phrasal_verb.chars().collect())],
                message: message.to_string(),
                priority: 63,
            });
        }

        lints
    }

    fn description(&self) -> &str {
        "This rule looks for phrasal verbs written as compound nouns."
    }
}

/// Checks if the current token is part of a list of nouns
fn is_part_of_noun_list(document: &Document, current_index: usize) -> bool {
    // Check for a conjunction before the current word (-1 is whitespace, -2 is the conjunction)
    if !matches!(
        document.get_next_word_from_offset(current_index, -1),
        Some(tok) if tok.kind.is_conjunction()
    ) {
        return false;
    }

    // Check the token sequence before the conjunction
    match document.get_token_offset(current_index, -3) {
        // A comma without the space, assume we're in a list of nouns.
        Some(tok) if tok.kind.is_comma() => true,

        // Whitespace. If the token before that is a noun or a comma, assume we're in a list of nouns.
        Some(ws) if ws.kind.is_whitespace() => {
            document
                .get_token_offset(current_index, -4)
                // `noun and` or `, and`
                .is_some_and(|tok| tok.kind.is_noun() || tok.kind.is_comma())
        }

        _ => false,
    }
}

#[cfg(test)]
mod tests {
    use super::PhrasalVerbAsCompoundNoun;
    use crate::linting::tests::{assert_lint_count, assert_no_lints, assert_suggestion_result};

    #[test]
    fn flag_breakup_and_workout() {
        assert_lint_count(
            "I will never breakup with Gym. We just seem to workout.",
            PhrasalVerbAsCompoundNoun::default(),
            2,
        );
    }

    #[test]
    fn correct_breakup_and_workout() {
        assert_suggestion_result(
            "I will never breakup with Gym. We just seem to workout.",
            PhrasalVerbAsCompoundNoun::default(),
            "I will never break up with Gym. We just seem to work out.",
        );
    }

    #[test]
    fn dont_flag_random_words_that_happen_to_end_like_a_particle() {
        assert_no_lints("I like bacon.", PhrasalVerbAsCompoundNoun::default());
    }

    #[test]
    fn dont_flag_non_verb_particles() {
        assert_no_lints("non", PhrasalVerbAsCompoundNoun::default());
    }

    #[test]
    fn correct_after_i() {
        assert_suggestion_result(
            "I backup",
            PhrasalVerbAsCompoundNoun::default(),
            "I back up",
        );
    }

    #[test]
    fn correct_after_we() {
        assert_suggestion_result(
            "we breakup",
            PhrasalVerbAsCompoundNoun::default(),
            "we break up",
        );
    }

    #[test]
    fn dont_flag_checkin() {
        // It's actually not a noun in English.
        assert_no_lints("checkin", PhrasalVerbAsCompoundNoun::default());
    }

    #[test]
    fn dont_flag_cleanup() {
        assert_no_lints("cleanup", PhrasalVerbAsCompoundNoun::default());
    }

    #[test]
    fn correct_after_you_lowercase() {
        assert_suggestion_result(
            "you checkout",
            PhrasalVerbAsCompoundNoun::default(),
            "you check out",
        );
    }

    #[test]
    fn correct_after_you_capitalized() {
        assert_suggestion_result(
            "You checkout",
            PhrasalVerbAsCompoundNoun::default(),
            "You check out",
        );
    }

    #[test]
    fn flag_checkout_after_you() {
        assert_lint_count("you checkout", PhrasalVerbAsCompoundNoun::default(), 1);
    }

    #[test]
    fn correct_after_they_lowercase() {
        assert_suggestion_result(
            "they cleanup",
            PhrasalVerbAsCompoundNoun::default(),
            "they clean up",
        );
    }

    #[test]
    fn flag_cleanup_after_they() {
        assert_lint_count("they cleanup", PhrasalVerbAsCompoundNoun::default(), 1);
    }

    #[test]
    fn dont_flag_dictionary_lookup() {
        assert_no_lints("dictionary lookup", PhrasalVerbAsCompoundNoun::default());
    }

    #[test]
    fn flag_couples_breakup() {
        assert_lint_count("couples breakup", PhrasalVerbAsCompoundNoun::default(), 1);
    }

    #[test]
    fn dont_flag_gallon() {
        assert_no_lints("gallon", PhrasalVerbAsCompoundNoun::default());
    }

    // Maybe this works by accident because "given" is also an adjective.
    // It should be because "funding" is a noun, but it's a gerund, which makes it also a verb.
    // Still, "given start up" doesn't make sense so maybe this test if fine.
    #[test]
    fn dont_flag_startup_funding() {
        assert_no_lints(
            "Yarvin has actually given startup funding. They hang out and party together",
            PhrasalVerbAsCompoundNoun::default(),
        );
    }

    #[test]
    fn dont_flag_huge_markup() {
        assert_no_lints(
            "Sell it back to Russia at a huge markup.",
            PhrasalVerbAsCompoundNoun::default(),
        );
    }

    #[test]
    fn dont_flag_another_layoff() {
        assert_no_lints(
            "And now just announced another layoff",
            PhrasalVerbAsCompoundNoun::default(),
        );
    }

    #[test]
    #[ignore = "\"Shakedown\" is a compound noun -- it's part of a comma-separated list with another noun \"threat\"\nBut this is not easy to check for so is not implemented yet."]
    fn dont_flag_a_threat_or_shakedown() {
        assert_no_lints(
            "Just a threat or Shakedown.",
            PhrasalVerbAsCompoundNoun::default(),
        );
    }

    #[test]
    fn dont_flag_a_flyover() {
        assert_no_lints(
            "if I'm the Brits I'm doing a flyover",
            PhrasalVerbAsCompoundNoun::default(),
        );
    }

    #[test]
    fn dont_flag_mafia_style_shakedown() {
        assert_no_lints(
            "Basically it's kind of a mafia style shakedown of Ukraine",
            PhrasalVerbAsCompoundNoun::default(),
        );
    }

    #[test]
    fn dont_flag_my_meetup_repository() {
        assert_no_lints(
            "I might have in my Meetup repository",
            PhrasalVerbAsCompoundNoun::default(),
        );
    }

    #[test]
    fn ignore_multi_word() {
        assert_no_lints("I like this add-on!", PhrasalVerbAsCompoundNoun::default());
    }

    #[test]
    fn dont_flag_list_of_nouns_1298() {
        assert_no_lints(
            "A printable format and layout.",
            PhrasalVerbAsCompoundNoun::default(),
        );
    }

    #[test]
    fn dont_flag_oov_nvim_plugin_1280() {
        assert_no_lints(
            "This is the nvim plugin for you.",
            PhrasalVerbAsCompoundNoun::default(),
        );
    }

    #[test]
    fn flag_title_case() {
        assert_lint_count(
            "I Will Never Breakup With Gym. We Just Seem To Workout.",
            PhrasalVerbAsCompoundNoun::default(),
            2,
        );
    }

    #[test]
    fn dont_flag_all_caps() {
        assert_no_lints(
            "I WILL NEVER BREAKUP WITH GYM. WE JUST SEEM TO WORKOUT.",
            PhrasalVerbAsCompoundNoun::default(),
        );
    }

    #[test]
    fn false_positive_issue_1495() {
        assert_no_lints(
            "Color schemes are available by using the Style Settings plugin.",
            PhrasalVerbAsCompoundNoun::default(),
        );
    }

    #[test]
    fn dont_flag_thanks_a_lot_linter_description() {
        assert_lint_count(
            "Thanks a lot` is the fixed, widely accepted form, while variants like `thanks lot` or `thanks alot` are non-standard and can jar readers.",
            PhrasalVerbAsCompoundNoun::default(),
            0,
        );
    }

    #[test]
    fn dont_flag_backup_location() {
        assert_no_lints(
            "Backup location: `%APPDATA%\\Cursor\\User\\globalStorage\\backups`",
            PhrasalVerbAsCompoundNoun::default(),
        );
    }

    #[test]
    fn dont_flag_backup_plan() {
        assert_no_lints(
            "Every backup plan is unique, based on your risk assessment.",
            PhrasalVerbAsCompoundNoun::default(),
        );
    }

    #[test]
    fn dont_flag_backup_program() {
        assert_no_lints(
            "restic is a backup program that is fast, efficient and secure",
            PhrasalVerbAsCompoundNoun::default(),
        );
    }

    #[test]
    fn dont_flag_backup_solution_or_backup_problems() {
        assert_no_lints(
            "NPBackup is a multiparadigm backup solution which tries to solve two major backup problems",
            PhrasalVerbAsCompoundNoun::default(),
        );
    }

    #[test]
    fn dont_flag_backup_utilities_backup_system_or_backup_snapshots() {
        assert_no_lints(
            "GitHub Enterprise Server Backup Utilities is a backup system you install on a separate host, which takes backup snapshots",
            PhrasalVerbAsCompoundNoun::default(),
        );
    }

    #[test]
    fn dont_flag_backup_images() {
        assert_no_lints(
            "This App creates and stores backup images of your Nextcloud.",
            PhrasalVerbAsCompoundNoun::default(),
        );
    }

    #[test]
    fn fix_backup_individual_apps() {
        assert_suggestion_result(
            "It requires root and allows you to backup individual apps and their data.",
            PhrasalVerbAsCompoundNoun::default(),
            "It requires root and allows you to back up individual apps and their data.",
        );
    }

    #[test]
    fn dont_flag_backup_strategy() {
        assert_no_lints(
            "This is for you if you want to quickly set up a backup strategy without much fuss.",
            PhrasalVerbAsCompoundNoun::default(),
        );
    }

    #[test]
    fn dont_flag_helm_backup_plugin() {
        assert_no_lints("Helm Backup Plugin.", PhrasalVerbAsCompoundNoun::default());
    }

    #[test]
    fn dont_flag_callback_function() {
        assert_no_lints(
            "By the time the `setTimeout` callback function was invoked",
            PhrasalVerbAsCompoundNoun::default(),
        );
    }

    #[test]
    fn dont_flag_playback_latency() {
        assert_no_lints(
            "Low-Latency HLS is a recently standardized variant of the protocol that allows to greatly reduce playback latency.",
            PhrasalVerbAsCompoundNoun::default(),
        );
    }

    #[test]
    fn dont_flag_workout_constraints() {
        assert_no_lints("Workout constraints", PhrasalVerbAsCompoundNoun::default());
    }

    #[test]
    fn dont_flag_workout_preference() {
        assert_no_lints("Workout preference", PhrasalVerbAsCompoundNoun::default());
    }

    #[test]
    fn dont_flag_rollout_status() {
        assert_no_lints(
            "Rollout Status of Latest Image Release",
            PhrasalVerbAsCompoundNoun::default(),
        );
    }

    #[test]
    fn font_flag_with_plugin() {
        assert_no_lints(
            "**Xcode** (8.0+, otherwise [with plugin](https://github.com/robertvojta/LigatureXcodePlugin))",
            PhrasalVerbAsCompoundNoun::default(),
        )
    }

    #[test]
    fn dont_flag_and_layout_of_data() {
        assert_no_lints(
            "shape, memory space, and layout of data, while performing the complicated indexing for the user",
            PhrasalVerbAsCompoundNoun::default(),
        );
    }

    #[test]
    fn dont_flag_in_noun_list_without_space_after_comma() {
        assert_no_lints(
            "shape, memory space,and layout of data",
            PhrasalVerbAsCompoundNoun::default(),
        );
    }

    #[test]
    fn dont_flag_layout_estimation() {
        assert_no_lints(
            "Layout estimation focuses on predicting architectural elements, i.e., walls, doors, and windows, within an indoor scene.",
            PhrasalVerbAsCompoundNoun::default(),
        );
    }

    #[test]
    fn dont_flag_plugin_that() {
        assert_no_lints(
            "plugin that provides way for auto-loading of Golang SDK",
            PhrasalVerbAsCompoundNoun::default(),
        );
    }

    #[test]
    fn dont_flag_load_balancing_and_failover() {
        assert_no_lints(
            "resilient mid-tier load balancing and failover",
            PhrasalVerbAsCompoundNoun::default(),
        );
    }

    #[test]
    fn dont_flag_plugin_for() {
        assert_no_lints(
            "Plugin for text editors and IDEs.",
            PhrasalVerbAsCompoundNoun::default(),
        );
    }

    #[test]
    fn dont_flag_markup_language() {
        assert_no_lints(
            "Markup language used for websites & web apps.",
            PhrasalVerbAsCompoundNoun::default(),
        );
    }

    #[test]
    fn dont_flag_plugin_ecosystem_or_plugin_development() {
        assert_no_lints(
            "## 🧩 Plugin Ecosystem\n### Plugin Development",
            PhrasalVerbAsCompoundNoun::default(),
        );
    }

    #[test]
    fn dont_flag_plugin_files_or_plugin_packages() {
        assert_no_lints(
            "plugin files between plugin packages installed with pip must have unique filenames.",
            PhrasalVerbAsCompoundNoun::default(),
        );
    }

    #[test]
    fn dont_flag_plugin_docs() {
        assert_no_lints(
            "building your own plugin: [Plugin Docs]",
            PhrasalVerbAsCompoundNoun::default(),
        );
    }

    #[test]
    fn dont_flag_plugin_suite() {
        assert_no_lints(
            "An all-in-one digital audio workstation (DAW) and plugin suite.",
            PhrasalVerbAsCompoundNoun::default(),
        );
    }

    #[test]
    fn dont_flag_hacker_news_throwback_machine() {
        assert_no_lints(
            "| Hacker News Throwback Machine | Shows what was popular on Hacker News on this day in previous years.",
            PhrasalVerbAsCompoundNoun::default(),
        );
    }

    #[test]
    fn dont_flag_plugin_interface() {
        assert_no_lints("[Plugin interface]", PhrasalVerbAsCompoundNoun::default());
    }

    #[test]
    fn issue_1918() {
        assert_no_lints(
            "Boost your productivity with our JetBrains plugin!",
            PhrasalVerbAsCompoundNoun::default(),
        );
    }

    #[test]
    fn dont_flag_pop_up_2217() {
        assert_no_lints(
            "Popup window instead of command line.",
            PhrasalVerbAsCompoundNoun::default(),
        );
    }

    #[test]
    fn issue_1772() {
        assert_no_lints(
            "By default, only one tile size is instantiated for each data type, math instruction, and layout.",
            PhrasalVerbAsCompoundNoun::default(),
        );
    }

    #[test]
    fn issue_2369() {
        assert_no_lints(
            "## Plugin developer documentation",
            PhrasalVerbAsCompoundNoun::default(),
        );
    }
}



================================================
FILE: harper-core/src/linting/pique_interest.rs
================================================
use crate::TokenKind;
use crate::expr::Expr;
use crate::expr::SequenceExpr;
use crate::{CharString, CharStringExt, Token, char_string::char_string, patterns::WordSet};

use super::{ExprLinter, Lint, LintKind, Suggestion};
use crate::linting::expr_linter::Chunk;

pub struct PiqueInterest {
    expr: Box<dyn Expr>,
}

impl Default for PiqueInterest {
    fn default() -> Self {
        let pattern = SequenceExpr::default()
            .then(WordSet::new(&[
                "peak", "peaked", "peek", "peeked", "peeking", "peaking",
            ]))
            .then_whitespace()
            .then_kind_either(
                TokenKind::is_non_plural_nominal,
                TokenKind::is_possessive_determiner,
            )
            .then_whitespace()
            .t_aco("interest");

        Self {
            expr: Box::new(pattern),
        }
    }
}

impl PiqueInterest {
    fn to_correct(word: &str) -> Option<CharString> {
        Some(match word.to_lowercase().as_str() {
            "peak" => char_string!("pique"),
            "peek" => char_string!("pique"),
            "peeked" => char_string!("piqued"),
            "peaked" => char_string!("piqued"),
            "peaking" => char_string!("piquing"),
            "peeking" => char_string!("piquing"),
            _ => return None,
        })
    }
}

impl ExprLinter for PiqueInterest {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], source: &[char]) -> Option<Lint> {
        let span = matched_tokens[0].span;
        let word = span.get_content_string(source).to_lowercase();
        let correct = Self::to_correct(&word)?;

        Some(Lint {
            span,
            lint_kind: LintKind::WordChoice,
            suggestions: vec![Suggestion::replace_with_match_case(
                correct.to_vec(),
                matched_tokens[0].span.get_content(source),
            )],
            message: format!(
                "Did you mean `{}` instead of `{}`?",
                correct.to_string(),
                word,
            ),
            priority: 31,
        })
    }

    fn description(&self) -> &'static str {
        "Detects incorrect usage of `peak` or `peek` when the intended word is `pique`, as in the phrase `you've peaked my interest`."
    }
}

#[cfg(test)]
mod tests {
    use super::PiqueInterest;
    use crate::linting::tests::assert_suggestion_result;

    #[test]
    fn corrects_peak_interest() {
        assert_suggestion_result(
            "The story managed to peak his interest.",
            PiqueInterest::default(),
            "The story managed to pique his interest.",
        );
    }

    #[test]
    fn corrects_peeked_interest_at_start() {
        assert_suggestion_result(
            "Peeked his interest, did she?",
            PiqueInterest::default(),
            "Piqued his interest, did she?",
        );
    }

    #[test]
    fn corrects_peak_interest_in_middle() {
        assert_suggestion_result(
            "She tried to peak his interest during the lecture.",
            PiqueInterest::default(),
            "She tried to pique his interest during the lecture.",
        );
    }

    #[test]
    fn corrects_peaked_interest_at_end() {
        assert_suggestion_result(
            "All along, she hoped she peaked his interest.",
            PiqueInterest::default(),
            "All along, she hoped she piqued his interest.",
        );
    }

    #[test]
    fn does_not_correct_unrelated_peak() {
        assert_suggestion_result(
            "He reached the peak of the mountain.",
            PiqueInterest::default(),
            "He reached the peak of the mountain.",
        );
    }

    #[test]
    fn corrects_peaking_interest() {
        assert_suggestion_result(
            "She was peaking his interest with her stories.",
            PiqueInterest::default(),
            "She was piquing his interest with her stories.",
        );
    }

    #[test]
    fn corrects_peaked_my_interest() {
        assert_suggestion_result(
            "you've peaked my interest.",
            PiqueInterest::default(),
            "you've piqued my interest.",
        );
    }
}



================================================
FILE: harper-core/src/linting/plural_wrong_word_of_phrase.rs
================================================
use crate::{
    CharStringExt, Lint, Token, TokenStringExt,
    expr::{Expr, SequenceExpr},
    linting::{ExprLinter, LintKind, Suggestion, expr_linter::Chunk},
};

pub struct PluralWrongWordOfPhrase {
    expr: Box<dyn Expr>,
}

// If a noun needs other than an -s suffix to be pluralized, include it as the 2nd array element.
const PATTERNS: &[(&[&str], &str, &[&str])] = &[
    (&["body", "bodies"], "in", &["white"]),
    (&["line"], "of", &["code"]),
    (&["part"], "of", &["speech", "speeches"]),
    (&["point"], "of", &["view"]),
    (&["rule"], "of", &["thumb"]),
];

impl Default for PluralWrongWordOfPhrase {
    fn default() -> Self {
        let word_str = |w| {
            SequenceExpr::default().then(move |t: &Token, s: &[char]| {
                t.kind.is_word() && t.span.get_content(s).eq_ignore_ascii_case_str(w)
            })
        };

        let word_string = |w: String| {
            SequenceExpr::default().then(move |t: &Token, s: &[char]| {
                t.kind.is_word() && t.span.get_content(s).eq_ignore_ascii_case_str(&w)
            })
        };

        let mut mistakes = vec![];

        for &(main_noun, prep, last_noun) in PATTERNS {
            let main_pl = if main_noun.len() == 2 {
                main_noun[1].to_string()
            } else {
                format!("{}s", main_noun[0])
            };
            let last_pl = if last_noun.len() == 2 {
                last_noun[1].to_string()
            } else {
                format!("{}s", last_noun[0])
            };

            mistakes.push(Box::new(
                SequenceExpr::any_of(vec![
                    Box::new(word_str(main_noun[0])),
                    Box::new(word_string(main_pl)),
                ])
                .t_ws_h()
                .t_aco(prep)
                .t_ws_h()
                .then(word_string(last_pl)),
            ) as Box<dyn Expr>);
        }

        Self {
            expr: Box::new(SequenceExpr::any_of(mistakes)),
        }
    }
}

impl ExprLinter for PluralWrongWordOfPhrase {
    type Unit = Chunk;

    fn description(&self) -> &str {
        "Corrects noun phrases that pluralize the last noun instead of the main noun."
    }

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, toks: &[Token], src: &[char]) -> Option<Lint> {
        let (main_noun_tok, last_noun_tok) = (toks.first()?, toks.last()?);
        let (main_noun_span, last_noun_span) = (main_noun_tok.span, last_noun_tok.span);
        let (main_noun_chars, last_noun_chars) = (
            main_noun_span.get_content(src),
            last_noun_span.get_content(src),
        );

        let (main_noun, prep, last_noun) = PATTERNS.iter().find(|(main, _, last)| {
            main_noun_chars.starts_with_ignore_ascii_case_str(main[0])
                && last_noun_chars.starts_with_ignore_ascii_case_str(last[0])
        })?;

        let main_noun_pl = if main_noun.len() == 2 {
            main_noun[1].to_string()
        } else {
            format!("{}s", main_noun[0])
        };

        Some(Lint {
            lint_kind: LintKind::Usage,
            span: toks.span()?,
            suggestions: vec![Suggestion::replace_with_match_case(
                format!("{} {} {}", main_noun_pl, prep, last_noun[0])
                    .chars()
                    .collect::<Vec<char>>(),
                toks.span()?.get_content(src),
            )],
            message: "This phrase is pluralized on the main noun, not on the last noun."
                .to_string(),
            ..Default::default()
        })
    }
}

#[cfg(test)]
mod tests {
    use super::PluralWrongWordOfPhrase;
    use crate::linting::tests::assert_suggestion_result;

    // LinesOfCode

    #[test]
    fn corrects_line_of_codes() {
        assert_suggestion_result(
            "desktop application used to estimate the line of codes to certain software application",
            PluralWrongWordOfPhrase::default(),
            "desktop application used to estimate the lines of code to certain software application",
        );
    }

    #[test]
    #[ignore = "Wrong letters capitalized due to how `Suggstion::replace_with_match_case` works by index."]
    fn corrects_line_of_codes_title_case() {
        assert_suggestion_result(
            "A simple tool for Line Of Codes (LOC) calculation.",
            PluralWrongWordOfPhrase::default(),
            "A simple tool for Lines Of Code (LOC) calculation.",
        );
    }

    #[test]
    fn corrects_lines_of_codes() {
        assert_suggestion_result(
            "I myself don't have something against giving users the ability to show the lines of codes they wrote.",
            PluralWrongWordOfPhrase::default(),
            "I myself don't have something against giving users the ability to show the lines of code they wrote.",
        );
    }

    // PartsOfSpeech

    #[test]
    fn corrects_part_of_speeches() {
        assert_suggestion_result(
            "The part of speeches (POS) or as follows:",
            PluralWrongWordOfPhrase::default(),
            "The parts of speech (POS) or as follows:",
        )
    }

    #[test]
    fn corrects_parts_of_speeches() {
        assert_suggestion_result(
            "It can connect different parts of speeches e.g noun to adjective, adjective to adverb, noun to verb etc.",
            PluralWrongWordOfPhrase::default(),
            "It can connect different parts of speech e.g noun to adjective, adjective to adverb, noun to verb etc.",
        )
    }

    // PointsOfView

    #[test]
    fn corrects_point_of_views() {
        assert_suggestion_result(
            "This will produce a huge amount of raw data, representing the region in multiple point of views.",
            PluralWrongWordOfPhrase::default(),
            "This will produce a huge amount of raw data, representing the region in multiple points of view.",
        )
    }

    #[test]
    fn corrects_points_of_views() {
        assert_suggestion_result(
            "log events, places, moods and self-reflect from various points of views",
            PluralWrongWordOfPhrase::default(),
            "log events, places, moods and self-reflect from various points of view",
        )
    }

    // RulesOfThumb

    #[test]
    fn correct_rule_of_thumbs() {
        assert_suggestion_result(
            "Thanks. 0.2 is just from my rule of thumbs.",
            PluralWrongWordOfPhrase::default(),
            "Thanks. 0.2 is just from my rules of thumb.",
        );
    }

    #[test]
    fn correct_rules_of_thumbs() {
        assert_suggestion_result(
            "But as rules of thumbs, what is said in config file should be respected whatever parameter (field or directory) is passed to php-cs-fixer.phar.",
            PluralWrongWordOfPhrase::default(),
            "But as rules of thumb, what is said in config file should be respected whatever parameter (field or directory) is passed to php-cs-fixer.phar.",
        );
    }

    #[test]
    fn correct_rules_of_thumbs_hyphenated() {
        assert_suggestion_result(
            "Add rule-of-thumbs for basic metrics, like \"Spill more than 1GB is a red flag\".",
            PluralWrongWordOfPhrase::default(),
            "Add rules of thumb for basic metrics, like \"Spill more than 1GB is a red flag\".",
        );
    }

    // BodiesInWhite

    #[test]
    fn correct_body_in_whites_1() {
        assert_suggestion_result(
            "Normally, when they manufacture these body in whites, they would spot weld a lot of the components on.",
            PluralWrongWordOfPhrase::default(),
            "Normally, when they manufacture these bodies in white, they would spot weld a lot of the components on.",
        );
    }

    #[test]
    fn correct_body_in_whites_2() {
        assert_suggestion_result(
            "I'm not sure, but just having seen a lot of body in whites, I know normally they try to spot weld it.",
            PluralWrongWordOfPhrase::default(),
            "I'm not sure, but just having seen a lot of bodies in white, I know normally they try to spot weld it.",
        );
    }
}



================================================
FILE: harper-core/src/linting/possessive_noun.rs
================================================
use harper_brill::UPOS;

use super::{ExprLinter, Lint, LintKind, Suggestion};
use crate::expr::{All, Expr, SequenceExpr};
use crate::linting::expr_linter::Chunk;
use crate::patterns::{UPOSSet, WordSet};
use crate::spell::Dictionary;
use crate::{Token, TokenKind};

pub struct PossessiveNoun<D> {
    expr: Box<dyn Expr>,
    dict: D,
}

impl<D> PossessiveNoun<D>
where
    D: Dictionary,
{
    pub fn new(dict: D) -> Self {
        let expr = SequenceExpr::default()
            .then(UPOSSet::new(&[UPOS::DET, UPOS::PROPN]))
            .t_ws()
            .then_kind_is_but_is_not(TokenKind::is_plural_nominal, TokenKind::is_singular_nominal)
            .t_ws()
            .then(UPOSSet::new(&[UPOS::NOUN, UPOS::PROPN]))
            .then_optional(SequenceExpr::anything().t_any());

        let additional_req = SequenceExpr::anything().t_any().t_any().t_any().then_noun();

        let exceptions = SequenceExpr::default()
            .then_unless(|tok: &Token, _: &[char]| tok.kind.is_demonstrative_determiner())
            .t_any()
            .then_unless(WordSet::new(&["flags", "checks", "catches", "you"]))
            .t_any()
            .then_unless(WordSet::new(&["form", "go"]));

        Self {
            expr: Box::new(All::new(vec![
                Box::new(expr),
                Box::new(additional_req),
                Box::new(exceptions),
            ])),
            dict,
        }
    }
}

impl<D> ExprLinter for PossessiveNoun<D>
where
    D: Dictionary,
{
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], _source: &[char]) -> Option<Lint> {
        let last_kind = &matched_tokens.last()?.kind;

        if last_kind.is_upos(UPOS::ADV) {
            return None;
        }

        let first = matched_tokens.get(2)?;

        let span = first.span;
        let plural = span.get_content_string(_source);
        let singular = if plural.ends_with('s') {
            &plural[..plural.len() - 1]
        } else {
            &plural
        };

        let replacement = format!("{singular}'s");

        if !self.dict.contains_word_str(&replacement) {
            return None;
        }

        Some(Lint {
            span,
            lint_kind: LintKind::Miscellaneous,
            suggestions: vec![Suggestion::ReplaceWith(replacement.chars().collect())],
            message: self.description().to_string(),
            priority: 10,
        })
    }

    fn description(&self) -> &'static str {
        "Use an apostrophe and `s` to form a noun’s possessive."
    }
}

#[cfg(test)]
mod tests {
    use std::sync::Arc;

    use super::PossessiveNoun;
    use crate::linting::tests::{assert_lint_count, assert_suggestion_result};
    use crate::spell::FstDictionary;

    fn test_linter() -> PossessiveNoun<Arc<FstDictionary>> {
        PossessiveNoun::new(FstDictionary::curated())
    }

    /// Sourced from a Hacker News comment
    #[test]
    fn fixes_hn() {
        assert_suggestion_result(
            "Me and Jennifer went to have seen the ducks cousin.",
            test_linter(),
            "Me and Jennifer went to have seen the duck's cousin.",
        );
    }

    #[test]
    fn fixes_cats_tail() {
        assert_suggestion_result(
            "The cats tail is long.",
            test_linter(),
            "The cat's tail is long.",
        );
    }

    #[test]
    fn fixes_children_toys() {
        assert_suggestion_result(
            "The children toys were scattered.",
            test_linter(),
            "The children's toys were scattered.",
        );
    }

    #[test]
    fn fixes_teachers_lounge() {
        assert_suggestion_result(
            "Many schools have a teachers lounge.",
            test_linter(),
            "Many schools have a teacher's lounge.",
        );
    }

    #[test]
    fn fixes_ducks_park() {
        assert_suggestion_result(
            "Kids played in the ducks park.",
            test_linter(),
            "Kids played in the duck's park.",
        );
    }

    #[test]
    fn no_lint_for_already_possessive() {
        assert_lint_count("The duck's cousin visited.", test_linter(), 0);
    }

    #[test]
    fn no_lint_for_alrreaady_possessive() {
        assert_lint_count("The duck's cousin visited.", test_linter(), 0);
    }

    #[test]
    fn fixes_dogs_bone() {
        assert_suggestion_result(
            "The dogs bone is delicious.",
            test_linter(),
            "The dog's bone is delicious.",
        );
    }

    #[test]
    fn fixes_students_books() {
        assert_suggestion_result(
            "The students books are on the desk.",
            test_linter(),
            "The student's books are on the desk.",
        );
    }

    #[test]
    fn fixes_farmers_field() {
        assert_suggestion_result(
            "The farmers field looked beautiful.",
            test_linter(),
            "The farmer's field looked beautiful.",
        );
    }

    #[test]
    fn fixes_women_dress() {
        assert_suggestion_result(
            "The women dress was elegant.",
            test_linter(),
            "The women's dress was elegant.",
        );
    }

    #[test]
    fn fixes_birds_song() {
        assert_suggestion_result(
            "We heard the birds song.",
            test_linter(),
            "We heard the bird's song.",
        );
    }

    #[test]
    fn fixes_scientists_research() {
        assert_suggestion_result(
            "The scientists research was groundbreaking.",
            test_linter(),
            "The scientist's research was groundbreaking.",
        );
    }

    #[test]
    fn fixes_artists_gallery() {
        assert_suggestion_result(
            "The artists gallery is open.",
            test_linter(),
            "The artist's gallery is open.",
        );
    }

    #[test]
    fn no_lint_for_plural_noun() {
        assert_lint_count("The ducks are swimming.", test_linter(), 0);
    }

    #[test]
    fn no_lint_for_proper_noun() {
        assert_lint_count("John's car is red.", test_linter(), 0);
    }

    #[test]
    fn fixes_the_students_assignment() {
        assert_suggestion_result(
            "The students assignment was due yesterday.",
            test_linter(),
            "The student's assignment was due yesterday.",
        );
    }

    #[test]
    fn fixes_the_birds_flight() {
        assert_suggestion_result(
            "The birds flight was graceful.",
            test_linter(),
            "The bird's flight was graceful.",
        );
    }

    #[test]
    fn allows_the_city_lights() {
        assert_lint_count(
            "The city lights twinkled in the distance.",
            test_linter(),
            0,
        );
    }

    #[test]
    fn fixes_the_farmers_crops() {
        assert_suggestion_result(
            "The farmers crops were bountiful this year.",
            test_linter(),
            "The farmer's crops were bountiful this year.",
        );
    }

    #[test]
    fn fixes_the_artists_inspiration() {
        assert_suggestion_result(
            "The artists inspiration came from nature.",
            test_linter(),
            "The artist's inspiration came from nature.",
        );
    }

    #[test]
    fn fixes_the_scientists_discovery() {
        assert_suggestion_result(
            "The scientists discovery revolutionized the field.",
            test_linter(),
            "The scientist's discovery revolutionized the field.",
        );
    }

    #[test]
    fn fixes_the_writers_novel() {
        assert_suggestion_result(
            "The writers novel was a bestseller.",
            test_linter(),
            "The writer's novel was a bestseller.",
        );
    }

    #[test]
    fn fixes_the_students_presentation() {
        assert_suggestion_result(
            "The students presentation was well-received.",
            test_linter(),
            "The student's presentation was well-received.",
        );
    }

    #[test]
    fn fixes_the_teams_victory() {
        assert_suggestion_result(
            "The teams victory was celebrated by the fans.",
            test_linter(),
            "The team's victory was celebrated by the fans.",
        );
    }

    #[test]
    fn fixes_the_museums_collection() {
        assert_suggestion_result(
            "The museums collection included many artifacts.",
            test_linter(),
            "The museum's collection included many artifacts.",
        );
    }

    #[test]
    fn no_lint_for_already_possessive_2() {
        assert_lint_count("John's car is red.", test_linter(), 0);
    }

    #[test]
    fn no_lint_for_proper_noun_2() {
        assert_lint_count("Mary went to the store.", test_linter(), 0);
    }

    #[test]
    fn fixes_the_doctors_office() {
        assert_suggestion_result(
            "The doctors office is on Main Street.",
            test_linter(),
            "The doctor's office is on Main Street.",
        );
    }

    #[test]
    fn fixes_the_neighbors_garden() {
        assert_suggestion_result(
            "The neighbors garden is beautiful.",
            test_linter(),
            "The neighbor's garden is beautiful.",
        );
    }

    #[test]
    fn fixes_the_architects_design() {
        assert_suggestion_result(
            "The architects design was innovative.",
            test_linter(),
            "The architect's design was innovative.",
        );
    }

    #[test]
    fn fixes_the_bakers_shop() {
        assert_suggestion_result(
            "The bakers shop is famous for its bread.",
            test_linter(),
            "The baker's shop is famous for its bread.",
        );
    }

    #[test]
    fn fixes_the_musics_performance() {
        assert_suggestion_result(
            "The musics performance was captivating.",
            test_linter(),
            "The music's performance was captivating.",
        );
    }

    #[test]
    fn fixes_the_flowers_scent() {
        assert_suggestion_result(
            "The flowers scent filled the room.",
            test_linter(),
            "The flower's scent filled the room.",
        );
    }

    #[test]
    fn allows_birds_hurried() {
        assert_lint_count("The birds hurried off.", test_linter(), 0);
    }

    #[test]
    #[ignore = "false positive issue 1582"]
    fn allows_1582_harms_readability() {
        assert_lint_count(
            "This harms readability and maintainability.",
            test_linter(),
            0,
        );
    }

    #[test]
    #[ignore = "false positive issue 1582"]
    fn allows_1582_imports_couples() {
        assert_lint_count(
            "Since using Webpack syntax in the imports couples the code to a module bundler",
            test_linter(),
            0,
        );
    }

    #[test]
    #[ignore = "false positive issue 1582"]
    fn allows_1582_graphics_programmer() {
        assert_lint_count(
            "Are you a graphics programmer or Rust developer?",
            test_linter(),
            0,
        );
    }

    #[test]
    #[ignore = "false positive issue 1582"]
    fn allows_1582_data_sources() {
        assert_lint_count(
            "these data sources can be queried using a full SQL dialect",
            test_linter(),
            0,
        );
    }
}



================================================
FILE: harper-core/src/linting/possessive_your.rs
================================================
use crate::Token;
use crate::TokenKind;
use crate::expr::Expr;
use crate::expr::SequenceExpr;

use super::{ExprLinter, Lint, LintKind, Suggestion};
use crate::linting::expr_linter::Chunk;

pub struct PossessiveYour {
    expr: Box<dyn Expr>,
}

impl Default for PossessiveYour {
    fn default() -> Self {
        let pattern = SequenceExpr::aco("you")
            .then_whitespace()
            .then_kind_is_but_is_not_except(
                TokenKind::is_nominal,
                TokenKind::is_likely_homograph,
                &["guys", "what's"],
            );

        Self {
            expr: Box::new(pattern),
        }
    }
}

impl ExprLinter for PossessiveYour {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint_with_context(
        &self,
        matched_tokens: &[Token],
        source: &[char],
        ctx: Option<(&[Token], &[Token])>,
    ) -> Option<Lint> {
        // Is 'you' the object of a verb? (#1920)
        if let [.., v, ws] = ctx?.0
            && ws.kind.is_whitespace()
            && v.kind.is_verb()
        {
            return None;
        }

        let span = matched_tokens.first()?.span;
        let orig_chars = span.get_content(source);

        Some(Lint {
            span,
            lint_kind: LintKind::WordChoice,
            suggestions: vec![
                Suggestion::replace_with_match_case("your".chars().collect(), orig_chars),
                Suggestion::replace_with_match_case("you're a".chars().collect(), orig_chars),
                Suggestion::replace_with_match_case("you're an".chars().collect(), orig_chars),
            ],
            message: "The possessive version of this word is more common in this context."
                .to_owned(),
            ..Default::default()
        })
    }

    fn description(&self) -> &'static str {
        "The possessive form of `you` is more likely before nouns."
    }
}

#[cfg(test)]
mod tests {
    use crate::linting::tests::{
        assert_lint_count, assert_no_lints, assert_suggestion_result, assert_top3_suggestion_result,
    };

    use super::PossessiveYour;

    #[test]
    #[ignore = "currently fails because comments is a homographs (verb or noun)"]
    fn your_comments() {
        assert_suggestion_result(
            "You comments may end up in the documentation.",
            PossessiveYour::default(),
            "Your comments may end up in the documentation.",
        );
    }

    #[test]
    fn allow_intro_page() {
        assert_lint_count(
            "You can try out an editor that uses Harper under-the-hood here.",
            PossessiveYour::default(),
            0,
        );
    }

    #[test]
    fn allow_you_guys() {
        assert_lint_count(
            "I mean I'm pretty sure you guys can't do anything with this stuff.",
            PossessiveYour::default(),
            0,
        );
    }

    #[test]
    fn test_top3_suggestion_your() {
        assert_top3_suggestion_result(
            "You combination of artist and teacher.",
            PossessiveYour::default(),
            "Your combination of artist and teacher.",
        );
    }

    #[test]
    fn test_top3_suggestion_youre_a() {
        assert_top3_suggestion_result(
            "You combination of artist and teacher.",
            PossessiveYour::default(),
            "You're a combination of artist and teacher.",
        );
    }

    #[test]
    #[ignore]
    fn test_top3_suggestion_multiple() {
        assert_top3_suggestion_result(
            "You knowledge. You imagination. You icosahedron",
            PossessiveYour::default(),
            "Your knowledge. Your imagination. You're an icosahedron",
        );
    }

    #[test]
    fn dont_flag_just_showing_you() {
        assert_lint_count(
            "I'm just showing you what's available and how to use it.",
            PossessiveYour::default(),
            0,
        );
    }

    #[test]
    fn allows_issue_1583() {
        assert_no_lints(
            "Note that in a world with modules everywhere, you almost never need an IIFE",
            PossessiveYour::default(),
        );
    }

    #[test]
    fn dont_flag_1919_brought_you() {
        assert_lint_count(
            "team who also brought you [BloodHound Enterprise](http://specterops.io/bloodhound-verview/).",
            PossessiveYour::default(),
            0,
        );
    }

    #[test]
    fn dont_flag_1919_teaches_you() {
        assert_lint_count(
            "Teaches you PyTorch and many machine learning concepts in a hands-on, code-first way.",
            PossessiveYour::default(),
            0,
        );
    }
}



================================================
FILE: harper-core/src/linting/progressive_needs_be.rs
================================================
use crate::Token;
use crate::expr::{Expr, SequenceExpr};

use super::{ExprLinter, Lint, LintKind, Suggestion};
use crate::linting::expr_linter::Chunk;

pub struct ProgressiveNeedsBe {
    expr: Box<dyn Expr>,
}

impl Default for ProgressiveNeedsBe {
    fn default() -> Self {
        // Support both contracted (I've/We've/You've/They've) and non-contracted
        // (I have/We have/You have/They have) forms before a progressive verb.
        let contracted = SequenceExpr::word_set(&[
            "I've", "We've", "You've", "They've", "Ive", "Weve", "Youve", "Theyve",
        ])
        .t_ws()
        .then_verb_progressive_form();

        let non_contracted = SequenceExpr::word_set(&["I", "We", "You", "They"])
            .t_ws()
            .then_any_capitalization_of("have")
            .t_ws()
            .then_verb_progressive_form();

        let expr = SequenceExpr::any_of(vec![Box::new(contracted), Box::new(non_contracted)]);

        Self {
            expr: Box::new(expr),
        }
    }
}

impl ExprLinter for ProgressiveNeedsBe {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, toks: &[Token], src: &[char]) -> Option<Lint> {
        use crate::CharStringExt;

        // Collect the word tokens in the matched slice
        let word_toks: Vec<&Token> = toks.iter().filter(|t| t.kind.is_word()).collect();
        let first_word = *word_toks.first()?; // contraction or pronoun

        // If this is the non-contracted pattern, extend the replacement span to include "have"
        let have_tok_opt = word_toks
            .iter()
            .find(|t| t.span.get_content(src).eq_ignore_ascii_case_str("have"))
            .copied();

        let span = if let Some(have_tok) = have_tok_opt {
            crate::Span::new(first_word.span.start, have_tok.span.end)
        } else {
            first_word.span
        };

        // Choose the correct "be" contraction based on the pronoun
        let pronoun = first_word.span.get_content(src);
        let progressive_replacement = if pronoun.starts_with_ignore_ascii_case_str("i") {
            "I'm"
        } else if pronoun.starts_with_ignore_ascii_case_str("we") {
            "We're"
        } else if pronoun.starts_with_ignore_ascii_case_str("you") {
            "You're"
        } else if pronoun.starts_with_ignore_ascii_case_str("they") {
            "They're"
        } else {
            "I'm"
        };

        Some(Lint {
            span,
            lint_kind: LintKind::WordChoice,
            suggestions: vec![
                Suggestion::replace_with_match_case(
                    progressive_replacement.chars().collect(),
                    span.get_content(src),
                ),
                Suggestion::InsertAfter(" been".chars().collect()),
            ],
            message: "Use present progressive (`…'re/…'m …`) or present perfect progressive (`… have been …`/`…'ve been …`) instead of `… have …ing` or `…'ve …ing`.".to_string(),
            priority: 31,
        })
    }

    fn description(&self) -> &'static str {
        "Detects the ungrammatical patterns `<pronoun> have …ing` (e.g., `I have …ing`) and `<pronoun>'ve …ing` (e.g., `I've …ing`) and suggests either the present progressive (e.g., `I'm/We're/You're/They're …`) or the present perfect progressive (e.g., `I/We/You/They have been …` or `I've/We've/You've/They've been …`)."
    }
}

#[cfg(test)]
mod tests {
    use super::ProgressiveNeedsBe;
    use crate::linting::tests::{
        assert_good_and_bad_suggestions, assert_lint_count, assert_suggestion_result,
    };

    #[test]
    fn suggests_im_looking() {
        assert_suggestion_result(
            "I've looking into it.",
            ProgressiveNeedsBe::default(),
            "I'm looking into it.",
        );
    }

    #[test]
    fn corrects_basic_im() {
        assert_suggestion_result(
            "I've looking into it.",
            ProgressiveNeedsBe::default(),
            "I'm looking into it.",
        );
    }

    #[test]
    fn offers_both_suggestions() {
        assert_good_and_bad_suggestions(
            "I've looking into it.",
            ProgressiveNeedsBe::default(),
            &["I'm looking into it.", "I've been looking into it."],
            &[],
        );
    }

    #[test]
    fn allows_ive_looked() {
        assert_lint_count("I've looked into it.", ProgressiveNeedsBe::default(), 0);
    }

    #[test]
    fn allows_ive_been_looking() {
        assert_lint_count(
            "I've been looking into it.",
            ProgressiveNeedsBe::default(),
            0,
        );
    }

    #[test]
    fn allows_ive_seen() {
        assert_lint_count("I've seen the results.", ProgressiveNeedsBe::default(), 0);
    }

    #[test]
    fn allows_ive_long_been_looking() {
        assert_lint_count(
            "I've long been looking into it.",
            ProgressiveNeedsBe::default(),
            0,
        );
    }

    #[test]
    fn no_match_with_punctuation_between() {
        assert_lint_count("I've, looking into it.", ProgressiveNeedsBe::default(), 0);
    }

    #[test]
    fn handles_newline_whitespace() {
        assert_suggestion_result(
            "I've\nlooking into it.",
            ProgressiveNeedsBe::default(),
            "I'm\nlooking into it.",
        );
    }

    #[test]
    fn capitalization_all_caps_base() {
        assert_suggestion_result(
            "I'VE looking into it.",
            ProgressiveNeedsBe::default(),
            "I'M looking into it.",
        );
    }

    #[test]
    fn works_for_weve() {
        assert_suggestion_result(
            "We've looking into it.",
            ProgressiveNeedsBe::default(),
            "We're looking into it.",
        );
    }

    #[test]
    fn suggests_im_looking_non_contracted() {
        assert_suggestion_result(
            "I have looking into it.",
            ProgressiveNeedsBe::default(),
            "I'm looking into it.",
        );
    }

    #[test]
    fn offers_both_suggestions_non_contracted() {
        assert_good_and_bad_suggestions(
            "They have looking into it.",
            ProgressiveNeedsBe::default(),
            &[
                "They're looking into it.",
                "They have been looking into it.",
            ],
            &[],
        );
    }

    #[test]
    fn allows_i_have_been_looking() {
        assert_lint_count(
            "I have been looking into it.",
            ProgressiveNeedsBe::default(),
            0,
        );
    }

    #[test]
    fn allows_i_have_looked() {
        assert_lint_count("I have looked into it.", ProgressiveNeedsBe::default(), 0);
    }

    // Additional generalized cases
    // Contracted: I've/We've/You've/They've + gerund
    #[test]
    fn ive_working() {
        assert_suggestion_result(
            "I've working on it today.",
            ProgressiveNeedsBe::default(),
            "I'm working on it today.",
        );
    }
    #[test]
    fn weve_working() {
        assert_suggestion_result(
            "We've working on it today.",
            ProgressiveNeedsBe::default(),
            "We're working on it today.",
        );
    }
    #[test]
    fn youve_working() {
        assert_suggestion_result(
            "You've working on it today.",
            ProgressiveNeedsBe::default(),
            "You're working on it today.",
        );
    }
    #[test]
    fn theyve_working() {
        assert_suggestion_result(
            "They've working on it today.",
            ProgressiveNeedsBe::default(),
            "They're working on it today.",
        );
    }

    #[test]
    fn ive_eating() {
        assert_suggestion_result(
            "I've eating it today.",
            ProgressiveNeedsBe::default(),
            "I'm eating it today.",
        );
    }
    #[test]
    fn weve_eating() {
        assert_suggestion_result(
            "We've eating it today.",
            ProgressiveNeedsBe::default(),
            "We're eating it today.",
        );
    }
    #[test]
    fn youve_eating() {
        assert_suggestion_result(
            "You've eating it today.",
            ProgressiveNeedsBe::default(),
            "You're eating it today.",
        );
    }
    #[test]
    fn theyve_eating() {
        assert_suggestion_result(
            "They've eating it today.",
            ProgressiveNeedsBe::default(),
            "They're eating it today.",
        );
    }

    #[test]
    fn ive_reading() {
        assert_suggestion_result(
            "I've reading it today.",
            ProgressiveNeedsBe::default(),
            "I'm reading it today.",
        );
    }
    #[test]
    fn weve_reading() {
        assert_suggestion_result(
            "We've reading it today.",
            ProgressiveNeedsBe::default(),
            "We're reading it today.",
        );
    }
    #[test]
    fn youve_reading() {
        assert_suggestion_result(
            "You've reading it today.",
            ProgressiveNeedsBe::default(),
            "You're reading it today.",
        );
    }
    #[test]
    fn theyve_reading() {
        assert_suggestion_result(
            "They've reading it today.",
            ProgressiveNeedsBe::default(),
            "They're reading it today.",
        );
    }

    #[test]
    fn ive_writing() {
        assert_suggestion_result(
            "I've writing it today.",
            ProgressiveNeedsBe::default(),
            "I'm writing it today.",
        );
    }
    #[test]
    fn weve_writing() {
        assert_suggestion_result(
            "We've writing it today.",
            ProgressiveNeedsBe::default(),
            "We're writing it today.",
        );
    }
    #[test]
    fn youve_writing() {
        assert_suggestion_result(
            "You've writing it today.",
            ProgressiveNeedsBe::default(),
            "You're writing it today.",
        );
    }
    #[test]
    fn theyve_writing() {
        assert_suggestion_result(
            "They've writing it today.",
            ProgressiveNeedsBe::default(),
            "They're writing it today.",
        );
    }

    #[test]
    fn ive_speaking() {
        assert_suggestion_result(
            "I've speaking about it today.",
            ProgressiveNeedsBe::default(),
            "I'm speaking about it today.",
        );
    }
    #[test]
    fn weve_speaking() {
        assert_suggestion_result(
            "We've speaking about it today.",
            ProgressiveNeedsBe::default(),
            "We're speaking about it today.",
        );
    }
    #[test]
    fn youve_speaking() {
        assert_suggestion_result(
            "You've speaking about it today.",
            ProgressiveNeedsBe::default(),
            "You're speaking about it today.",
        );
    }
    #[test]
    fn theyve_speaking() {
        assert_suggestion_result(
            "They've speaking about it today.",
            ProgressiveNeedsBe::default(),
            "They're speaking about it today.",
        );
    }

    #[test]
    fn ive_studying() {
        assert_suggestion_result(
            "I've studying it today.",
            ProgressiveNeedsBe::default(),
            "I'm studying it today.",
        );
    }
    #[test]
    fn weve_studying() {
        assert_suggestion_result(
            "We've studying it today.",
            ProgressiveNeedsBe::default(),
            "We're studying it today.",
        );
    }
    #[test]
    fn youve_studying() {
        assert_suggestion_result(
            "You've studying it today.",
            ProgressiveNeedsBe::default(),
            "You're studying it today.",
        );
    }
    #[test]
    fn theyve_studying() {
        assert_suggestion_result(
            "They've studying it today.",
            ProgressiveNeedsBe::default(),
            "They're studying it today.",
        );
    }

    #[test]
    fn ive_testing() {
        assert_suggestion_result(
            "I've testing it today.",
            ProgressiveNeedsBe::default(),
            "I'm testing it today.",
        );
    }
    #[test]
    fn weve_testing() {
        assert_suggestion_result(
            "We've testing it today.",
            ProgressiveNeedsBe::default(),
            "We're testing it today.",
        );
    }
    #[test]
    fn youve_testing() {
        assert_suggestion_result(
            "You've testing it today.",
            ProgressiveNeedsBe::default(),
            "You're testing it today.",
        );
    }
    #[test]
    fn theyve_testing() {
        assert_suggestion_result(
            "They've testing it today.",
            ProgressiveNeedsBe::default(),
            "They're testing it today.",
        );
    }

    #[test]
    fn ive_using() {
        assert_suggestion_result(
            "I've using it today.",
            ProgressiveNeedsBe::default(),
            "I'm using it today.",
        );
    }
    #[test]
    fn weve_using() {
        assert_suggestion_result(
            "We've using it today.",
            ProgressiveNeedsBe::default(),
            "We're using it today.",
        );
    }
    #[test]
    fn youve_using() {
        assert_suggestion_result(
            "You've using it today.",
            ProgressiveNeedsBe::default(),
            "You're using it today.",
        );
    }
    #[test]
    fn theyve_using() {
        assert_suggestion_result(
            "They've using it today.",
            ProgressiveNeedsBe::default(),
            "They're using it today.",
        );
    }

    // Non-contracted: I/We/You/They have + gerund
    #[test]
    fn i_have_working() {
        assert_suggestion_result(
            "I have working on it today.",
            ProgressiveNeedsBe::default(),
            "I'm working on it today.",
        );
    }
    #[test]
    fn we_have_working() {
        assert_suggestion_result(
            "We have working on it today.",
            ProgressiveNeedsBe::default(),
            "We're working on it today.",
        );
    }
    #[test]
    fn you_have_working() {
        assert_suggestion_result(
            "You have working on it today.",
            ProgressiveNeedsBe::default(),
            "You're working on it today.",
        );
    }
    #[test]
    fn they_have_working() {
        assert_suggestion_result(
            "They have working on it today.",
            ProgressiveNeedsBe::default(),
            "They're working on it today.",
        );
    }

    #[test]
    fn i_have_eating() {
        assert_suggestion_result(
            "I have eating it today.",
            ProgressiveNeedsBe::default(),
            "I'm eating it today.",
        );
    }
    #[test]
    fn we_have_eating() {
        assert_suggestion_result(
            "We have eating it today.",
            ProgressiveNeedsBe::default(),
            "We're eating it today.",
        );
    }
    #[test]
    fn you_have_eating() {
        assert_suggestion_result(
            "You have eating it today.",
            ProgressiveNeedsBe::default(),
            "You're eating it today.",
        );
    }
    #[test]
    fn they_have_eating() {
        assert_suggestion_result(
            "They have eating it today.",
            ProgressiveNeedsBe::default(),
            "They're eating it today.",
        );
    }

    #[test]
    fn i_have_reading() {
        assert_suggestion_result(
            "I have reading it today.",
            ProgressiveNeedsBe::default(),
            "I'm reading it today.",
        );
    }
    #[test]
    fn we_have_reading() {
        assert_suggestion_result(
            "We have reading it today.",
            ProgressiveNeedsBe::default(),
            "We're reading it today.",
        );
    }
    #[test]
    fn you_have_reading() {
        assert_suggestion_result(
            "You have reading it today.",
            ProgressiveNeedsBe::default(),
            "You're reading it today.",
        );
    }
    #[test]
    fn they_have_reading() {
        assert_suggestion_result(
            "They have reading it today.",
            ProgressiveNeedsBe::default(),
            "They're reading it today.",
        );
    }

    #[test]
    fn i_have_writing() {
        assert_suggestion_result(
            "I have writing it today.",
            ProgressiveNeedsBe::default(),
            "I'm writing it today.",
        );
    }
    #[test]
    fn we_have_writing() {
        assert_suggestion_result(
            "We have writing it today.",
            ProgressiveNeedsBe::default(),
            "We're writing it today.",
        );
    }
    #[test]
    fn you_have_writing() {
        assert_suggestion_result(
            "You have writing it today.",
            ProgressiveNeedsBe::default(),
            "You're writing it today.",
        );
    }
    #[test]
    fn they_have_writing() {
        assert_suggestion_result(
            "They have writing it today.",
            ProgressiveNeedsBe::default(),
            "They're writing it today.",
        );
    }

    #[test]
    fn i_have_speaking() {
        assert_suggestion_result(
            "I have speaking about it today.",
            ProgressiveNeedsBe::default(),
            "I'm speaking about it today.",
        );
    }
    #[test]
    fn we_have_speaking() {
        assert_suggestion_result(
            "We have speaking about it today.",
            ProgressiveNeedsBe::default(),
            "We're speaking about it today.",
        );
    }
    #[test]
    fn you_have_speaking() {
        assert_suggestion_result(
            "You have speaking about it today.",
            ProgressiveNeedsBe::default(),
            "You're speaking about it today.",
        );
    }
    #[test]
    fn they_have_speaking() {
        assert_suggestion_result(
            "They have speaking about it today.",
            ProgressiveNeedsBe::default(),
            "They're speaking about it today.",
        );
    }

    #[test]
    fn i_have_studying() {
        assert_suggestion_result(
            "I have studying it today.",
            ProgressiveNeedsBe::default(),
            "I'm studying it today.",
        );
    }
    #[test]
    fn we_have_studying() {
        assert_suggestion_result(
            "We have studying it today.",
            ProgressiveNeedsBe::default(),
            "We're studying it today.",
        );
    }
    #[test]
    fn you_have_studying() {
        assert_suggestion_result(
            "You have studying it today.",
            ProgressiveNeedsBe::default(),
            "You're studying it today.",
        );
    }
    #[test]
    fn they_have_studying() {
        assert_suggestion_result(
            "They have studying it today.",
            ProgressiveNeedsBe::default(),
            "They're studying it today.",
        );
    }

    #[test]
    fn i_have_testing() {
        assert_suggestion_result(
            "I have testing it today.",
            ProgressiveNeedsBe::default(),
            "I'm testing it today.",
        );
    }
    #[test]
    fn we_have_testing() {
        assert_suggestion_result(
            "We have testing it today.",
            ProgressiveNeedsBe::default(),
            "We're testing it today.",
        );
    }
    #[test]
    fn you_have_testing() {
        assert_suggestion_result(
            "You have testing it today.",
            ProgressiveNeedsBe::default(),
            "You're testing it today.",
        );
    }
    #[test]
    fn they_have_testing() {
        assert_suggestion_result(
            "They have testing it today.",
            ProgressiveNeedsBe::default(),
            "They're testing it today.",
        );
    }

    #[test]
    fn i_have_using() {
        assert_suggestion_result(
            "I have using it today.",
            ProgressiveNeedsBe::default(),
            "I'm using it today.",
        );
    }
    #[test]
    fn we_have_using() {
        assert_suggestion_result(
            "We have using it today.",
            ProgressiveNeedsBe::default(),
            "We're using it today.",
        );
    }
    #[test]
    fn you_have_using() {
        assert_suggestion_result(
            "You have using it today.",
            ProgressiveNeedsBe::default(),
            "You're using it today.",
        );
    }
    #[test]
    fn they_have_using() {
        assert_suggestion_result(
            "They have using it today.",
            ProgressiveNeedsBe::default(),
            "They're using it today.",
        );
    }

    // Both-suggestion checks
    #[test]
    fn both_suggestions_ive_working() {
        assert_good_and_bad_suggestions(
            "I've working today.",
            ProgressiveNeedsBe::default(),
            &["I'm working today.", "I've been working today."],
            &[],
        );
    }
    #[test]
    fn both_suggestions_we_have_reading() {
        assert_good_and_bad_suggestions(
            "We have reading it today.",
            ProgressiveNeedsBe::default(),
            &["We're reading it today.", "We have been reading it today."],
            &[],
        );
    }
    #[test]
    fn both_suggestions_youve_reading() {
        assert_good_and_bad_suggestions(
            "You've reading today.",
            ProgressiveNeedsBe::default(),
            &["You're reading today.", "You've been reading today."],
            &[],
        );
    }
    #[test]
    fn both_suggestions_they_have_writing() {
        assert_good_and_bad_suggestions(
            "They have writing today.",
            ProgressiveNeedsBe::default(),
            &["They're writing today.", "They have been writing today."],
            &[],
        );
    }

    // Non-match and allowed-form checks
    fn no_match_punctuation_contracted() {
        assert_lint_count("I've, working today.", ProgressiveNeedsBe::default(), 0);
    }
    #[test]
    fn no_match_punctuation_non_contracted() {
        assert_lint_count("I have, working today.", ProgressiveNeedsBe::default(), 0);
    }
    #[test]
    fn no_match_adverb_interruption() {
        assert_lint_count(
            "I have quickly working today.",
            ProgressiveNeedsBe::default(),
            0,
        );
    }
    #[test]
    fn allowed_contracted_have_been() {
        assert_lint_count(
            "You've been studying today.",
            ProgressiveNeedsBe::default(),
            0,
        );
    }
    #[test]
    fn allowed_non_contracted_have_been() {
        assert_lint_count(
            "You have been studying today.",
            ProgressiveNeedsBe::default(),
            0,
        );
    }
    #[test]
    fn allowed_they_have_been() {
        assert_lint_count(
            "They have been testing today.",
            ProgressiveNeedsBe::default(),
            0,
        );
    }
    #[test]
    fn allowed_theyve_been() {
        assert_lint_count(
            "They've been testing today.",
            ProgressiveNeedsBe::default(),
            0,
        );
    }

    #[test]
    fn capitalization_variants_non_contracted() {
        assert_suggestion_result(
            "WE HAVE working today.",
            ProgressiveNeedsBe::default(),
            "WE'RE working today.",
        );
    }
    #[test]
    fn newline_variants_non_contracted() {
        assert_suggestion_result(
            "We have\nworking on it today.",
            ProgressiveNeedsBe::default(),
            "We're\nworking on it today.",
        );
    }

    //////////

    #[test]
    #[ignore = "Handling the progressive `being` will need a special case"]
    fn test_ive_being() {
        assert_good_and_bad_suggestions(
            "I've being playing with languages.toml",
            ProgressiveNeedsBe::default(),
            &[
                "I've been playing with languages.toml",
                "I'm playing with languages.toml",
            ],
            &[],
        );
    }

    #[test]
    fn test_ive_doing_no_apostrophe() {
        assert_suggestion_result(
            "Ive always seen the variables and debug into it, and thats what ive doing.",
            ProgressiveNeedsBe::default(),
            "Ive always seen the variables and debug into it, and thats what i'm doing.",
        );
    }

    #[test]
    fn test_ive_looking_no_apostrophe() {
        assert_suggestion_result(
            "Ive looking for a way to get temperature and humidity for all of our rooms within for a reasonable price in Germany.",
            ProgressiveNeedsBe::default(),
            "I'm looking for a way to get temperature and humidity for all of our rooms within for a reasonable price in Germany.",
        );
    }

    #[test]
    #[ignore = "Handling the progressive `being` will need a special case"]
    fn test_youve_being() {
        assert_suggestion_result(
            "Thanks for all the work you've being doing for this project btw!",
            ProgressiveNeedsBe::default(),
            "Thanks for all the work you're doing for this project btw!",
        );
    }

    #[test]
    fn test_theyve_doing() {
        assert_suggestion_result(
            "it’s also kind of implied users read the documentation or generally have a sense of what they’ve doing and what could go wrong",
            ProgressiveNeedsBe::default(),
            "it’s also kind of implied users read the documentation or generally have a sense of what they're doing and what could go wrong",
        );
    }
}



================================================
FILE: harper-core/src/linting/pronoun_are.rs
================================================
use crate::linting::expr_linter::Chunk;
use crate::{
    Token, TokenStringExt,
    expr::{Expr, SequenceExpr},
    linting::{ExprLinter, Lint, LintKind, Suggestion},
};

/// Corrects the shorthand `r` after plural first- and second-person pronouns.
pub struct PronounAre {
    expr: Box<dyn Expr>,
}

impl Default for PronounAre {
    fn default() -> Self {
        let expr = SequenceExpr::default()
            .then_kind_where(|kind| {
                kind.is_pronoun()
                    && kind.is_subject_pronoun()
                    && (kind.is_second_person_pronoun()
                        || kind.is_first_person_plural_pronoun()
                        || kind.is_third_person_plural_pronoun())
            })
            .t_ws()
            .t_aco("r");

        Self {
            expr: Box::new(expr),
        }
    }
}

impl ExprLinter for PronounAre {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, tokens: &[Token], source: &[char]) -> Option<Lint> {
        let span = tokens.span()?;
        let pronoun = tokens.first()?;
        let gap = tokens.get(1)?;
        let letter = tokens.get(2)?;

        let pronoun_chars = pronoun.span.get_content(source);
        let gap_chars = gap.span.get_content(source);
        let letter_chars = letter.span.get_content(source);

        let all_pronoun_letters_uppercase = pronoun_chars
            .iter()
            .filter(|c| c.is_alphabetic())
            .all(|c| c.is_uppercase());
        let letter_has_uppercase = letter_chars.iter().any(|c| c.is_uppercase());
        let uppercase_suffix = letter_has_uppercase || all_pronoun_letters_uppercase;

        let are_suffix: Vec<char> = if uppercase_suffix {
            vec!['A', 'R', 'E']
        } else {
            vec!['a', 'r', 'e']
        };

        let re_suffix: Vec<char> = if uppercase_suffix {
            vec!['R', 'E']
        } else {
            vec!['r', 'e']
        };

        let mut with_are = pronoun_chars.to_vec();
        with_are.extend_from_slice(gap_chars);
        with_are.extend(are_suffix);

        let mut with_contraction = pronoun_chars.to_vec();
        with_contraction.push('\'');
        with_contraction.extend(re_suffix);

        Some(Lint {
            span,
            lint_kind: LintKind::WordChoice,
            suggestions: vec![
                Suggestion::ReplaceWith(with_are),
                Suggestion::ReplaceWith(with_contraction),
            ],
            message: "Use the full verb or the contraction after this pronoun.".to_owned(),
            priority: 40,
        })
    }

    fn description(&self) -> &str {
        "Spots the letter `r` used in place of `are` or `you're` after plural first- or second-person pronouns."
    }
}

#[cfg(test)]
mod tests {
    use super::PronounAre;
    use crate::linting::tests::{
        assert_lint_count, assert_nth_suggestion_result, assert_suggestion_result,
    };

    #[test]
    fn fixes_you_r() {
        assert_suggestion_result(
            "You r absolutely right.",
            PronounAre::default(),
            "You are absolutely right.",
        );
    }

    #[test]
    fn offers_contraction_option() {
        assert_nth_suggestion_result(
            "You r absolutely right.",
            PronounAre::default(),
            "You're absolutely right.",
            1,
        );
    }

    #[test]
    fn keeps_uppercase_pronoun() {
        assert_suggestion_result(
            "YOU r welcome here.",
            PronounAre::default(),
            "YOU ARE welcome here.",
        );
    }

    #[test]
    fn fixes_they_r_with_comma() {
        assert_suggestion_result(
            "They r, of course, arriving tomorrow.",
            PronounAre::default(),
            "They are, of course, arriving tomorrow.",
        );
    }

    #[test]
    fn fixes_we_r_lowercase() {
        assert_suggestion_result(
            "we r ready now.",
            PronounAre::default(),
            "we are ready now.",
        );
    }

    #[test]
    fn fixes_they_r_sentence_start() {
        assert_suggestion_result(
            "They r planning ahead.",
            PronounAre::default(),
            "They are planning ahead.",
        );
    }

    #[test]
    fn fixes_lowercase_sentence() {
        assert_suggestion_result(
            "they r late again.",
            PronounAre::default(),
            "they are late again.",
        );
    }

    #[test]
    fn handles_line_break() {
        assert_suggestion_result(
            "We r\nready to go.",
            PronounAre::default(),
            "We are\nready to go.",
        );
    }

    #[test]
    fn does_not_flag_contraction() {
        assert_lint_count("You're looking great.", PronounAre::default(), 0);
    }

    #[test]
    fn does_not_flag_full_form() {
        assert_lint_count("They are excited about it.", PronounAre::default(), 0);
    }

    #[test]
    fn ignores_similar_word() {
        assert_lint_count("Your results impressed everyone.", PronounAre::default(), 0);
    }
}



================================================
FILE: harper-core/src/linting/pronoun_inflection_be.rs
================================================
use harper_brill::UPOS;

use crate::expr::{All, AnchorStart, Expr, ExprMap, SequenceExpr};
use crate::patterns::{NominalPhrase, UPOSSet};
use crate::{Lrc, Token, TokenKind, TokenStringExt};

use super::Suggestion;
use super::{ExprLinter, Lint, LintKind};
use crate::linting::expr_linter::Chunk;

pub struct PronounInflectionBe {
    expr: Box<dyn Expr>,
    map: Lrc<ExprMap<&'static str>>,
}

impl PronounInflectionBe {
    pub fn new() -> Self {
        let mod_term = Lrc::new(
            SequenceExpr::default()
                .t_ws()
                .then(UPOSSet::new(&[UPOS::ADJ, UPOS::ADV])),
        );

        let mut map = ExprMap::default();

        let are = SequenceExpr::default()
            .then_third_person_singular_pronoun()
            .then_optional(mod_term.clone())
            .t_ws()
            .t_aco("are")
            .t_any()
            .then_unless(NominalPhrase);
        map.insert(are, "is");

        let are_at_start = SequenceExpr::default()
            .then(AnchorStart)
            .then_third_person_singular_pronoun()
            .then_optional(mod_term.clone())
            .t_ws()
            .t_aco("are")
            .t_any()
            .t_any();
        map.insert(are_at_start, "is");

        let arent = SequenceExpr::default()
            .then_third_person_singular_pronoun()
            .then_optional(mod_term.clone())
            .t_ws()
            .t_aco("aren't")
            .t_any()
            .t_any();
        map.insert(arent, "isn't");

        let is = SequenceExpr::default()
            .then_kind_where(|kind| {
                kind.as_word()
                    .as_ref()
                    .and_then(|m| m.as_ref().and_then(|m| m.np_member))
                    .unwrap_or_default()
            })
            .then_whitespace()
            .then_third_person_plural_pronoun()
            .then_optional(mod_term.clone())
            .t_ws()
            .t_aco("is")
            .t_any()
            .t_any();
        map.insert(is, "are");

        let is_at_start = SequenceExpr::default()
            .then(AnchorStart)
            .then_third_person_plural_pronoun()
            .then_optional(mod_term.clone())
            .t_ws()
            .t_aco("is")
            .t_any()
            .t_any();
        map.insert(is_at_start, "are");

        let isnt = SequenceExpr::default()
            .then_third_person_plural_pronoun()
            .then_optional(mod_term.clone())
            .t_ws()
            .t_aco("isn't")
            .t_any()
            .t_any();
        map.insert(isnt, "aren't");

        let was = SequenceExpr::default()
            .then_first_person_plural_pronoun()
            .then_optional(mod_term.clone())
            .t_ws()
            .t_aco("was")
            .t_any()
            .t_any();
        map.insert(was, "were");

        // Special case for second and third-person
        let was_third = SequenceExpr::default()
            .then(AnchorStart)
            .then_kind_either(
                TokenKind::is_third_person_plural_pronoun,
                TokenKind::is_second_person_pronoun,
            )
            .then_optional(mod_term.clone())
            .t_ws()
            .t_aco("was")
            .t_any()
            .t_any();
        map.insert(was_third, "were");

        let were = SequenceExpr::default()
            .then(AnchorStart)
            .then_kind_either(
                TokenKind::is_first_person_singular_pronoun,
                TokenKind::is_third_person_singular_pronoun,
            )
            .then_optional(mod_term.clone())
            .t_ws()
            .t_aco("were")
            .t_any()
            .t_any();

        map.insert(were, "was");

        let map = Lrc::new(map);

        let mut all = All::default();
        all.add(map.clone());
        all.add(|tok: &Token, _: &[char]| tok.kind.is_upos(UPOS::PRON));

        Self {
            expr: Box::new(all),
            map,
        }
    }
}

impl Default for PronounInflectionBe {
    fn default() -> Self {
        Self::new()
    }
}

impl ExprLinter for PronounInflectionBe {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], source: &[char]) -> Option<Lint> {
        let span = matched_tokens.get_rel(-3)?.span;

        // Determine the correct inflection of "be".
        let correct = self.map.lookup(0, matched_tokens, source)?;

        Some(Lint {
            span,
            lint_kind: LintKind::Agreement,
            suggestions: vec![Suggestion::replace_with_match_case_str(
                correct,
                span.get_content(source),
            )],
            message: "Make the verb agree with its subject.".to_owned(),
            priority: 30,
        })
    }
    fn description(&self) -> &str {
        "Checks subject–verb agreement for the verb `be`. Third-person singular \
         pronouns (`he`, `she`, `it`) require the singular form `is`, while the \
         plural pronoun `they` takes `are`. The linter flags mismatches such as \
         `He are` or `They is` and offers the correct concord."
    }
}

#[cfg(test)]
mod tests {
    use crate::linting::tests::{assert_lint_count, assert_no_lints, assert_suggestion_result};

    use super::PronounInflectionBe;

    #[test]
    fn corrects_he_are() {
        assert_suggestion_result(
            "He are my best friend.",
            PronounInflectionBe::default(),
            "He is my best friend.",
        );
    }

    #[test]
    fn corrects_she_are() {
        assert_suggestion_result(
            "She are my best friend.",
            PronounInflectionBe::default(),
            "She is my best friend.",
        );
    }

    #[test]
    fn corrects_they_is() {
        assert_suggestion_result(
            "They is my best friend.",
            PronounInflectionBe::default(),
            "They are my best friend.",
        );
    }

    #[test]
    fn allows_they_are() {
        assert_lint_count(
            "They are my best friend.",
            PronounInflectionBe::default(),
            0,
        );
    }

    #[test]
    fn corrects_it_are() {
        assert_suggestion_result(
            "It are on the table.",
            PronounInflectionBe::default(),
            "It is on the table.",
        );
    }

    #[test]
    fn corrects_he_are_negation() {
        assert_suggestion_result(
            "He are not amused.",
            PronounInflectionBe::default(),
            "He is not amused.",
        );
    }

    #[test]
    fn corrects_she_are_progressive() {
        assert_suggestion_result(
            "She are going to win.",
            PronounInflectionBe::default(),
            "She is going to win.",
        );
    }

    #[test]
    fn corrects_they_is_negation() {
        assert_suggestion_result(
            "They is not ready.",
            PronounInflectionBe::default(),
            "They are not ready.",
        );
    }

    #[test]
    fn corrects_they_is_progressive() {
        assert_suggestion_result(
            "They is planning a trip.",
            PronounInflectionBe::default(),
            "They are planning a trip.",
        );
    }

    #[test]
    fn allows_he_is() {
        assert_lint_count("He is my best friend.", PronounInflectionBe::default(), 0);
    }

    #[test]
    fn allows_she_is_lowercase() {
        assert_lint_count("she is excited to go.", PronounInflectionBe::default(), 0);
    }

    #[test]
    fn allows_it_is() {
        assert_lint_count("It is what it is.", PronounInflectionBe::default(), 0);
    }

    #[test]
    fn allows_they_are_negation() {
        assert_lint_count(
            "They are not interested.",
            PronounInflectionBe::default(),
            0,
        );
    }

    #[test]
    fn allows_they_were() {
        assert_lint_count("They were already here.", PronounInflectionBe::default(), 0);
    }

    #[test]
    fn allows_asdf_is() {
        assert_lint_count("asdf is not a word", PronounInflectionBe::default(), 0);
    }

    #[test]
    fn no_subject() {
        assert_lint_count("is set", PronounInflectionBe::default(), 0);
    }

    #[test]
    fn corrects_i_were() {
        assert_suggestion_result(
            "I were the best player on the field.",
            PronounInflectionBe::default(),
            "I was the best player on the field.",
        );
    }

    #[test]
    fn corrects_we_was() {
        assert_suggestion_result(
            "We was the best players on the field.",
            PronounInflectionBe::default(),
            "We were the best players on the field.",
        );
    }

    #[test]
    fn corrects_you_was() {
        assert_suggestion_result(
            "You was my best friend.",
            PronounInflectionBe::default(),
            "You were my best friend.",
        );
    }

    #[test]
    fn allows_you_were() {
        assert_lint_count(
            "You were my best friend.",
            PronounInflectionBe::default(),
            0,
        );
    }

    #[test]
    fn corrects_he_were() {
        assert_suggestion_result(
            "He were late.",
            PronounInflectionBe::default(),
            "He was late.",
        );
    }

    #[test]
    fn corrects_they_was() {
        assert_suggestion_result(
            "They was on time.",
            PronounInflectionBe::default(),
            "They were on time.",
        );
    }

    #[test]
    fn allows_he_was() {
        assert_lint_count("He was here.", PronounInflectionBe::default(), 0);
    }

    #[test]
    fn allows_we_were() {
        assert_lint_count("We were excited.", PronounInflectionBe::default(), 0);
    }

    #[test]
    fn corrects_he_arent() {
        assert_suggestion_result(
            "He aren't ready.",
            PronounInflectionBe::default(),
            "He isn't ready.",
        );
    }

    #[test]
    fn corrects_they_isnt() {
        assert_suggestion_result(
            "They isn't coming.",
            PronounInflectionBe::default(),
            "They aren't coming.",
        );
    }

    #[test]
    fn allows_he_isnt() {
        assert_lint_count("He isn't ready.", PronounInflectionBe::default(), 0);
    }

    #[test]
    fn allows_they_arent() {
        assert_lint_count("They aren't coming.", PronounInflectionBe::default(), 0);
    }

    #[test]
    fn corrects_she_really_are() {
        assert_suggestion_result(
            "She really are talented.",
            PronounInflectionBe::default(),
            "She really is talented.",
        );
    }

    #[test]
    fn corrects_they_often_is() {
        assert_suggestion_result(
            "They often is late.",
            PronounInflectionBe::default(),
            "They often are late.",
        );
    }

    #[test]
    fn corrects_because_he_are() {
        assert_suggestion_result(
            "because he are tired.",
            PronounInflectionBe::default(),
            "because he is tired.",
        );
    }

    #[test]
    fn allow_behind_him() {
        assert_no_lints(
            "Behind him are new shadows.",
            PronounInflectionBe::default(),
        );
    }

    #[test]
    fn issue_1682() {
        assert_no_lints(
            "Understanding them is significant",
            PronounInflectionBe::default(),
        );
    }
}



================================================
FILE: harper-core/src/linting/pronoun_knew.rs
================================================
use harper_brill::UPOS;

use crate::expr::Expr;
use crate::expr::LongestMatchOf;
use crate::expr::SequenceExpr;
use crate::linting::expr_linter::Chunk;
use crate::{
    Token,
    linting::{ExprLinter, Lint, LintKind, Suggestion},
    patterns::WordSet,
};

pub struct PronounKnew {
    expr: Box<dyn Expr>,
}

trait PronounKnewExt {
    fn then_pronoun(self) -> Self;
}

impl Default for PronounKnew {
    fn default() -> Self {
        // The pronoun that would occur before a verb would be a subject pronoun.
        // But "its" commonly occurs before "new" and is a possessive pronoun. (Much more commonly a determiner)
        // Since "his" and "her" are possessive and object pronouns respectively, we ignore them too.
        let pronoun_pattern = |tok: &Token, source: &[char]| {
            if !tok.kind.is_upos(UPOS::PRON) {
                return false;
            }

            if tok.kind.is_possessive_determiner() || !tok.kind.is_pronoun() {
                return false;
            }

            let pronorm = tok.span.get_content_string(source).to_lowercase();
            let excluded = ["every", "something", "nothing"];
            !excluded.contains(&&*pronorm)
        };

        let pronoun_then_new = SequenceExpr::default()
            .then(pronoun_pattern)
            .then_whitespace()
            .then_any_capitalization_of("new");

        let pronoun_adverb_then_new = SequenceExpr::default()
            .then(pronoun_pattern)
            .then_whitespace()
            .then(WordSet::new(&["always", "never", "also", "often"]))
            .then_whitespace()
            .then_any_capitalization_of("new");

        let combined_pattern = LongestMatchOf::new(vec![
            Box::new(pronoun_then_new),
            Box::new(pronoun_adverb_then_new),
        ]);

        Self {
            expr: Box::new(combined_pattern),
        }
    }
}

impl ExprLinter for PronounKnew {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, tokens: &[Token], source: &[char]) -> Option<Lint> {
        let typo_token = tokens.last()?;
        let typo_span = typo_token.span;
        let typo_text = typo_span.get_content(source);

        Some(Lint {
            span: typo_span,
            lint_kind: LintKind::WordChoice,
            suggestions: vec![Suggestion::replace_with_match_case(
                "knew".chars().collect(),
                typo_text,
            )],
            message: "Did you mean “knew” (the past tense of “know”)?".to_string(),
            priority: 31,
        })
    }

    fn description(&self) -> &str {
        "Detects when “new” following a pronoun (optionally with an adverb) is a typo for the past tense “knew.”"
    }
}

#[cfg(test)]
mod tests {
    use super::PronounKnew;
    use crate::linting::tests::{assert_lint_count, assert_no_lints, assert_suggestion_result};

    #[test]
    fn simple_pronoun_new() {
        assert_suggestion_result(
            "I new you would say that.",
            PronounKnew::default(),
            "I knew you would say that.",
        );
    }

    #[test]
    fn with_adverb() {
        assert_suggestion_result(
            "She often new the answer.",
            PronounKnew::default(),
            "She often knew the answer.",
        );
    }

    #[test]
    fn does_not_flag_without_pronoun() {
        assert_lint_count("The software is new.", PronounKnew::default(), 0);
    }

    #[test]
    fn does_not_flag_other_context() {
        assert_lint_count("They called it \"new\".", PronounKnew::default(), 0);
    }

    #[test]
    fn does_not_flag_with_its() {
        assert_lint_count(
            "In 2015, the US was paying on average around 2% for its new issuance bonds.",
            PronounKnew::default(),
            0,
        );
    }

    #[test]
    fn does_not_flag_with_his() {
        assert_lint_count("His new car is fast.", PronounKnew::default(), 0);
    }

    #[test]
    fn does_not_flag_with_her() {
        assert_lint_count("Her new car is fast.", PronounKnew::default(), 0);
    }

    #[test]
    fn does_not_flag_with_nothing_1298() {
        assert_lint_count("This is nothing new.", PronounKnew::default(), 0);
    }

    #[test]
    fn issue_1381_tricks() {
        assert_lint_count("To learn some new tricks.", PronounKnew::default(), 0);
    }

    #[test]
    fn issue_1381_template() {
        assert_lint_count(
            "Let's build this new template function.",
            PronounKnew::default(),
            0,
        );
    }

    #[test]
    fn issue_1381_file() {
        assert_lint_count(
            "Move the function definition inside of that new file.",
            PronounKnew::default(),
            0,
        );
    }

    #[test]
    fn fixes_i_knew_what() {
        assert_suggestion_result(
            "I new what to do.",
            PronounKnew::default(),
            "I knew what to do.",
        );
    }

    #[test]
    fn fixes_she_knew_what() {
        assert_suggestion_result(
            "She new what to do.",
            PronounKnew::default(),
            "She knew what to do.",
        );
    }

    #[test]
    fn flags_she_new_danger() {
        assert_lint_count("She new danger lurked nearby.", PronounKnew::default(), 1);
    }

    #[test]
    fn allows_issue_1518() {
        assert_no_lints("If you're new to GitHub, welcome.", PronounKnew::default());
    }
}



================================================
FILE: harper-core/src/linting/pronoun_verb_agreement.rs
================================================
use crate::{
    CharStringExt, Lint, Token, TokenKind,
    expr::{Expr, FirstMatchOf, SequenceExpr},
    linting::{ExprLinter, LintKind, Suggestion, expr_linter::Chunk},
    spell::Dictionary,
};

static NON_MODAL_AUX: &[&str] = &[
    "do", "don't", "does", "doesn't", "have", "has", "haven't", "hasn't", "dont", "doesnt",
    "havent", "hasnt",
];
static IRREGULAR: &[(&str, &str)] = &[("don't", "doesn't"), ("have", "has"), ("haven't", "hasn't")];
static SUBJUNCTIVE: &[&str] = &[
    // "if" and "that" can take the subjunctive mood: "if he go", "that he go" - as in the US constitution
    // "if" TODO: "if" is more complicated to support than "that"
    "that",
    // Verbs that take the subjunctive mood can omit the "that":
    "demanded",
    "demanding",
    "insisted",
    "insisting",
    "recommended",
    "recommending",
    "requested",
    "requesting",
    "suggested",
    "suggesting",
];
static DITRANSITIVE: &[&str] = &[
    "give", "gave", "given", "gives", "giving", "lose", "lost", "loses", "losing",
];

pub struct PronounVerbAgreement<D> {
    expr: Box<dyn Expr>,
    dict: D,
}

impl<D> PronounVerbAgreement<D>
where
    D: Dictionary,
{
    pub fn new(dict: D) -> Self {
        // TODO: allowing "you" leads to false positives:
        // "8 years to give you rewards", "all I can do is give you examples"
        let non_3p_sing_pres_pron_with_3p_sing_pres_verb = SequenceExpr::default()
            .then_kind_both_but_not(
                (
                    TokenKind::is_personal_pronoun,
                    TokenKind::is_subject_pronoun,
                ),
                TokenKind::is_third_person_singular_pronoun,
            )
            .t_ws()
            // NOTE: allowing verbs that are also nouns leads to false positives:
            // "Are they colors or colours?"
            // "8 years to give you rewards"
            // "all I can do is give you examples"
            .then_verb_third_person_singular_present_form();

        // NOTE: But excluding them causes many more false positives:
        // boxes, does, drops, flies, gets, goes, likes, site, wakes
        // .then_kind_where(|k| k.is_verb_third_person_singular_present_form() && !k.is_plural_noun());

        let third_person_sing_pres_pron = |t: &Token, _: &[char]| {
            t.kind.is_subject_pronoun()
                && !t.kind.is_object_pronoun()
                && t.kind.is_personal_pronoun()
                && t.kind.is_third_person_singular_pronoun()
                && !t.kind.is_plural_pronoun()
        };

        let verb_lemma = |t: &Token, src: &[char]| {
            t.kind.is_verb_lemma()
                && !t.kind.is_verb_third_person_singular_present_form()
                && !t.kind.is_verb_simple_past_form() // eg. not "put"
                && !t.kind.is_adverb() // eg. not "even"
                && !t.kind.is_conjunction() // "and"
                && (!t.kind.is_auxiliary_verb() // "I go"≠"he goes" but "I can"="he can"
                // We don't want modals because they don't inflect, but we want the other auxiliaries.
                || t.span.get_content(src).eq_any_ignore_ascii_case_str(NON_MODAL_AUX))
        };

        Self {
            expr: Box::new(FirstMatchOf::new(vec![
                // One Expr for the "I walks" type:
                Box::new(non_3p_sing_pres_pron_with_3p_sing_pres_verb),
                // Two Expr's for the "he walk" type:
                Box::new(
                    SequenceExpr::with(third_person_sing_pres_pron)
                        .t_ws()
                        .then(verb_lemma),
                ),
                Box::new(SequenceExpr::aco("it").t_ws().t_aco("don't")),
            ])),
            dict,
        }
    }

    fn third_person_singular_present_to_lemma(&self, form: &[char]) -> Vec<Vec<char>> {
        let mut words: Vec<Vec<char>> = Vec::new();

        // -s
        if form.ends_with_ignore_ascii_case_chars(&['s']) {
            words.push(form[0..form.len() - 1].to_vec());

            // -es
            if form.ends_with_ignore_ascii_case_chars(&['e', 's']) {
                words.push(form[0..form.len() - 2].to_vec());

                // -ies -> -y
                if form.ends_with_ignore_ascii_case_chars(&['i', 'e', 's']) {
                    words.push(
                        format!("{}y", &form[0..form.len() - 3].iter().collect::<String>())
                            .chars()
                            .collect(),
                    );
                }
            }
        }

        if let Some((lemma, _)) = IRREGULAR
            .iter()
            .find(|(_, f)| form.eq_ignore_ascii_case_str(f))
        {
            words.push(lemma.chars().collect::<Vec<char>>());
        }

        words
            .iter()
            .filter(|&w| {
                self.dict
                    .get_word_metadata(w)
                    .is_some_and(|md| md.is_verb_lemma())
            })
            .map(|w| w.to_vec())
            .collect()
    }

    fn lemma_to_third_person_singular_present(&self, input: &str) -> Vec<Vec<char>> {
        let mut words: Vec<Vec<char>> = Vec::new();

        words.push(format!("{input}s").chars().collect());
        words.push(format!("{input}es").chars().collect());

        if input.ends_with("y") {
            words.push(
                format!("{}ies", &input[0..input.len() - 1])
                    .chars()
                    .collect(),
            );
        }

        if let Some((_, form)) = IRREGULAR
            .iter()
            .find(|(lemma, _)| input.eq_ignore_ascii_case(lemma))
        {
            words.push(form.chars().collect());
        }

        words
            .iter()
            .filter(|&w| {
                self.dict
                    .get_word_metadata(w)
                    .is_some_and(|md| md.is_verb_third_person_singular_present_form())
            })
            .map(|w| w.to_vec())
            .collect()
    }
}

impl<D> ExprLinter for PronounVerbAgreement<D>
where
    D: Dictionary,
{
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint_with_context(
        &self,
        toks: &[Token],
        src: &[char],
        ctx: Option<(&[Token], &[Token])>,
    ) -> Option<Lint> {
        let pron_tok = &toks[0];
        let is_3psg = pron_tok.kind.is_third_person_singular_pronoun();

        let verb_tok = toks.last()?;

        if let Some((before, _)) = ctx
            && let [.., prev_word_tok, ws_tok] = before
            && ws_tok.kind.is_whitespace()
        {
            let prev_word = prev_word_tok.span.get_content(src);
            let is_exempt = if is_3psg {
                prev_word_tok.kind.is_auxiliary_verb()
                    || prev_word.eq_any_ignore_ascii_case_str(SUBJUNCTIVE)
            } else if pron_tok.kind.is_subject_pronoun() {
                // Clause structure: (... in you) is ... ≠ you is
                // Look for "true" prepositions, not ones that are more like adverbial particles
                prev_word_tok.kind.is_preposition() && !prev_word.eq_ignore_ascii_case_str("up")
                    // When the verb is ditransitive, the pronoun is object case, the verb position is actually a noun
                    || (prev_word.eq_any_ignore_ascii_case_str(DITRANSITIVE) && verb_tok.kind.is_noun())
            } else {
                false
            };

            if is_exempt {
                return None;
            }
        }

        let verb_span = verb_tok.span;
        let verb_chars = verb_tok.span.get_content(src);
        let verb_str = verb_tok.span.get_content_string(src);

        let suggs = if is_3psg {
            self.lemma_to_third_person_singular_present(&verb_str)
        } else {
            self.third_person_singular_present_to_lemma(verb_chars)
        };

        let suggestions = suggs
            .into_iter()
            .map(|s| Suggestion::replace_with_match_case(s, verb_chars))
            .collect();

        Some(Lint {
            span: verb_span,
            lint_kind: LintKind::Agreement,
            suggestions,
            message: "The form of the verb must agree in grammatical number with the pronoun."
                .to_string(),
            ..Default::default()
        })
    }

    fn description(&self) -> &str {
        "Ensures pronouns agree with their verbs."
    }
}

#[cfg(test)]
mod lints {
    use super::PronounVerbAgreement;
    use crate::linting::tests::{
        assert_no_lints, assert_suggestion_result, assert_top3_suggestion_result,
    };
    use crate::spell::FstDictionary;

    // Expected to be fixed, but there are exceptions

    #[test]
    fn issue_233_1() {
        assert_suggestion_result(
            "I likes this place.",
            PronounVerbAgreement::new(FstDictionary::curated()),
            "I like this place.",
        );
    }

    #[test]
    fn issue_233_2() {
        assert_suggestion_result(
            "I sits under the AC.",
            PronounVerbAgreement::new(FstDictionary::curated()),
            "I sit under the AC.",
        );
    }

    #[test]
    #[ignore = "because 'like' is an adjective as well as a verb."]
    fn issue_233_1_reverse() {
        assert_suggestion_result(
            "He like this place.",
            PronounVerbAgreement::new(FstDictionary::curated()),
            "He likes this place.",
        );
    }

    #[test]
    fn why_we_cant_flag_like_yet() {
        assert_no_lints(
            "What is he like?",
            PronounVerbAgreement::new(FstDictionary::curated()),
        );
    }

    #[test]
    fn issue_233_2_reverse() {
        assert_top3_suggestion_result(
            "She sit under the AC.",
            PronounVerbAgreement::new(FstDictionary::curated()),
            "She sits under the AC.",
        );
    }

    #[test]
    fn dont_flag_correct_agreement() {
        assert_no_lints(
            "He likes this place. I sit under the AC.",
            PronounVerbAgreement::new(FstDictionary::curated()),
        );
    }

    // Every pronoun systematically

    // Expected to get corrected

    #[test]
    fn fixes_i() {
        assert_suggestion_result(
            "I wakes up.",
            PronounVerbAgreement::new(FstDictionary::curated()),
            "I wake up.",
        );
    }

    #[test]
    fn fixes_we() {
        assert_suggestion_result(
            "We gets dressed.",
            PronounVerbAgreement::new(FstDictionary::curated()),
            "We get dressed.",
        );
    }

    #[test]
    fn fixes_you() {
        assert_suggestion_result(
            "You drops off the kids.",
            PronounVerbAgreement::new(FstDictionary::curated()),
            "You drop off the kids.",
        );
    }

    #[test]
    fn fixes_he() {
        assert_suggestion_result(
            "He work hard.",
            PronounVerbAgreement::new(FstDictionary::curated()),
            "He works hard.",
        );
    }

    #[test]
    fn fixes_she() {
        assert_suggestion_result(
            "She study hard.",
            PronounVerbAgreement::new(FstDictionary::curated()),
            "She studies hard.",
        );
    }

    #[test]
    #[ignore = "Becasue 'it' is also object case. Eg. 'watch it break down'"]
    fn we_cant_fix_it_yet() {
        assert_suggestion_result(
            "It break down.",
            PronounVerbAgreement::new(FstDictionary::curated()),
            "It breaks down.",
        );
    }

    #[test]
    fn why_we_cant_fix_it_yet() {
        assert_no_lints(
            "I heard it break down.",
            PronounVerbAgreement::new(FstDictionary::curated()),
        );
    }

    #[test]
    fn fixes_they() {
        assert_suggestion_result(
            "They repairs it.",
            PronounVerbAgreement::new(FstDictionary::curated()),
            "They repair it.",
        )
    }

    // Correct phrases that are expected not to get corrected

    #[test]
    fn dont_flag_i() {
        assert_no_lints("I eat", PronounVerbAgreement::new(FstDictionary::curated()));
    }

    #[test]
    fn dont_flag_we() {
        assert_no_lints(
            "We drink",
            PronounVerbAgreement::new(FstDictionary::curated()),
        );
    }

    #[test]
    fn dont_flag_you() {
        assert_no_lints(
            "You walk",
            PronounVerbAgreement::new(FstDictionary::curated()),
        );
    }

    #[test]
    fn dont_flag_he() {
        assert_no_lints(
            "He runs",
            PronounVerbAgreement::new(FstDictionary::curated()),
        );
    }

    #[test]
    fn dont_flag_she() {
        assert_no_lints(
            "She swims",
            PronounVerbAgreement::new(FstDictionary::curated()),
        );
    }

    #[test]
    fn dont_flag_it() {
        assert_no_lints(
            "It works!",
            PronounVerbAgreement::new(FstDictionary::curated()),
        );
    }

    #[test]
    fn dont_flag_they() {
        assert_no_lints(
            "They finish",
            PronounVerbAgreement::new(FstDictionary::curated()),
        );
    }

    // Ceck changing verb endings

    // -ies ↔ -y
    #[test]
    fn fix_flies() {
        assert_suggestion_result(
            "I flies",
            PronounVerbAgreement::new(FstDictionary::curated()),
            "I fly",
        );
    }
    #[test]
    fn fix_cry() {
        assert_suggestion_result(
            "He cry",
            PronounVerbAgreement::new(FstDictionary::curated()),
            "He cries",
        );
    }

    // -o ↔ -oes
    #[test]
    fn fix_go() {
        assert_suggestion_result(
            "She go",
            PronounVerbAgreement::new(FstDictionary::curated()),
            "She goes",
        );
    }
    #[test]
    fn fix_goes() {
        assert_suggestion_result(
            "They goes",
            PronounVerbAgreement::new(FstDictionary::curated()),
            "They go",
        );
    }

    // Check irregular changes

    // has ↔ have
    #[test]
    fn fix_has() {
        assert_suggestion_result(
            "You has",
            PronounVerbAgreement::new(FstDictionary::curated()),
            "You have",
        );
    }
    #[test]
    fn fix_have() {
        assert_suggestion_result(
            "She have",
            PronounVerbAgreement::new(FstDictionary::curated()),
            "She has",
        );
    }

    // hasn't ↔ haven't
    #[test]
    fn fix_hasnt() {
        assert_suggestion_result(
            "You hasn't",
            PronounVerbAgreement::new(FstDictionary::curated()),
            "You haven't",
        );
    }
    #[test]
    fn fix_havent() {
        assert_suggestion_result(
            "He haven't",
            PronounVerbAgreement::new(FstDictionary::curated()),
            "He hasn't",
        );
    }

    // -es
    #[test]
    fn fix_box() {
        assert_suggestion_result(
            "He box",
            PronounVerbAgreement::new(FstDictionary::curated()),
            "He boxes",
        );
    }
    #[test]
    fn fix_boxes() {
        assert_suggestion_result(
            "You boxes",
            PronounVerbAgreement::new(FstDictionary::curated()),
            "You box",
        );
    }

    // TODO: Are there any double consonant endings to change?
    // TODO: Are there any f ↔ v endings to change?

    // Negative contractions

    // doesn't ↔ don't
    #[test]
    fn fix_doesnt() {
        assert_suggestion_result(
            "We doesn't",
            PronounVerbAgreement::new(FstDictionary::curated()),
            "We don't",
        );
    }
    #[test]
    // Note: This requires a dedicated branch of the `[Expr]`
    fn fix_dont() {
        assert_suggestion_result(
            "It don't",
            PronounVerbAgreement::new(FstDictionary::curated()),
            "It doesn't",
        );
    }

    // Does do ↔ does behave differently to box ↔ boxes due to being an auxiliary verb?
    #[test]
    fn fix_do() {
        assert_suggestion_result(
            "He do",
            PronounVerbAgreement::new(FstDictionary::curated()),
            "He does",
        );
    }
    #[test]
    fn fix_does() {
        assert_suggestion_result(
            "You does",
            PronounVerbAgreement::new(FstDictionary::curated()),
            "You do",
        );
    }

    // False positives found by Elijah

    #[test]
    fn false_positive_she_consider() {
        assert_no_lints(
            "On April 10th, I suggested she consider a smaller, more intimate gathering.",
            PronounVerbAgreement::new(FstDictionary::curated()),
        );
    }

    #[test]
    fn false_positive_she_sell() {
        assert_no_lints(
            "I suggested she sell it and use the proceeds to help with her relocation expenses, or perhaps rent a similar camera while in Barcelona.",
            PronounVerbAgreement::new(FstDictionary::curated()),
        );
    }

    #[test]
    fn false_positive_she_rent() {
        assert_no_lints(
            "I suggested she sell it and use the proceeds to help with her relocation expenses, or perhaps rent a similar camera while in Barcelona.",
            PronounVerbAgreement::new(FstDictionary::curated()),
        );
    }

    #[test]
    fn false_positive_he_donned() {
        assert_no_lints(
            "He donned his heavy oilskins and descended the winding staircase, his boots echoing in the hollow tower.",
            PronounVerbAgreement::new(FstDictionary::curated()),
        );
    }

    #[test]
    fn false_positive_he_cannot() {
        assert_no_lints(
            "Surely, he cannot offer the same sum as the developers.",
            PronounVerbAgreement::new(FstDictionary::curated()),
        );
    }

    #[test]
    fn false_positive_insisting_she_return() {
        assert_no_lints(
            "Am I the asshole for insisting she return the dress?",
            PronounVerbAgreement::new(FstDictionary::curated()),
        );
    }

    #[test]
    fn false_positive_pride_in_you_is() {
        assert_no_lints(
            "It’s also important to recognize that your family's pride in you is a genuine reflection of your value.",
            PronounVerbAgreement::new(FstDictionary::curated()),
        );
    }

    #[test]
    fn false_positive_she_sought() {
        assert_no_lints(
            "She sought out Mrs. Hawthorne, the village’s oldest resident, a woman known for her vast knowledge of local history and her unsettlingly accurate intuition.",
            PronounVerbAgreement::new(FstDictionary::curated()),
        );
    }

    #[test]
    fn false_positive_lose_you_points() {
        assert_no_lints(
            "I admire your dedication to consistently drafting players who are actively trying to lose you points.",
            PronounVerbAgreement::new(FstDictionary::curated()),
        );
    }

    #[test]
    fn false_positive_she_hung_up() {
        assert_no_lints(
            "When I reiterated the conditions I'd previously set, she hung up on me.",
            PronounVerbAgreement::new(FstDictionary::curated()),
        );
    }
}



================================================
FILE: harper-core/src/linting/proper_noun_capitalization_linters.rs
================================================
use crate::expr::{Expr, ExprMap, FixedPhrase};
use hashbrown::HashMap;
use serde::{Deserialize, Serialize};

use super::{ExprLinter, LintGroup};
use super::{Lint, LintKind, Suggestion};
use crate::Document;
use crate::linting::expr_linter::Chunk;
use crate::parsers::PlainEnglish;
use crate::spell::Dictionary;
use crate::{Token, TokenStringExt};
use std::sync::Arc;

/// A linter that corrects the capitalization of multi-word proper nouns.
/// They are corrected to a "canonical capitalization" provided at construction.
///
/// If you would like to add a proper noun to Harper, see `proper_noun_rules.json`.
pub struct ProperNounCapitalizationLinter<D: Dictionary + 'static> {
    pattern_map: ExprMap<Document>,
    description: String,
    dictionary: Arc<D>,
}

impl<D: Dictionary + 'static> ProperNounCapitalizationLinter<D> {
    /// Create a linter that corrects the capitalization of phrases provided.
    pub fn new_strs(
        canonical_versions: impl IntoIterator<Item = impl AsRef<str>>,
        description: impl ToString,
        dictionary: D,
    ) -> Self {
        let dictionary = Arc::new(dictionary);

        let mut expr_map = ExprMap::default();

        for can_vers in canonical_versions {
            let doc = Document::new_basic_tokenize(can_vers.as_ref(), &PlainEnglish);

            let expr = FixedPhrase::from_document(&doc);

            expr_map.insert(expr, doc);
        }

        Self {
            pattern_map: expr_map,
            dictionary: dictionary.clone(),
            description: description.to_string(),
        }
    }
}

impl<D: Dictionary + 'static> ExprLinter for ProperNounCapitalizationLinter<D> {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        &self.pattern_map
    }

    fn match_to_lint(&self, matched_tokens: &[Token], source: &[char]) -> Option<Lint> {
        let canonical_case = self.pattern_map.lookup(0, matched_tokens, source).unwrap();

        let mut broken = false;

        for (err_token, correct_token) in matched_tokens.iter().zip(canonical_case.fat_tokens()) {
            let err_chars = err_token.span.get_content(source);
            if err_chars != correct_token.content {
                broken = true;
                break;
            }
        }

        if !broken {
            return None;
        }

        Some(Lint {
            span: matched_tokens.span()?,
            lint_kind: LintKind::Capitalization,
            suggestions: vec![Suggestion::ReplaceWith(
                canonical_case.get_source().to_vec(),
            )],
            message: self.description.to_string(),
            priority: 31,
        })
    }

    fn description(&self) -> &str {
        self.description.as_str()
    }
}

#[derive(Serialize, Deserialize)]
struct RuleEntry {
    canonical: Vec<String>,
    description: String,
}

/// For the time being, this panics on invalid JSON.
/// Do not use with user provided JSON.
fn lint_group_from_json(json: &str, dictionary: Arc<impl Dictionary + 'static>) -> LintGroup {
    let mut group = LintGroup::empty();

    let rules: HashMap<String, RuleEntry> = serde_json::from_str(json).unwrap();

    for (key, rule) in rules.into_iter() {
        group.add_chunk_expr_linter(
            key,
            Box::new(ProperNounCapitalizationLinter::new_strs(
                rule.canonical,
                rule.description,
                dictionary.clone(),
            )),
        );
    }

    group.set_all_rules_to(Some(true));

    group
}

pub fn lint_group(dictionary: Arc<impl Dictionary + 'static>) -> LintGroup {
    lint_group_from_json(include_str!("../../proper_noun_rules.json"), dictionary)
}

#[cfg(test)]
mod tests {
    use super::lint_group;
    use crate::linting::tests::{assert_lint_count, assert_suggestion_result};
    use crate::spell::FstDictionary;

    #[test]
    fn americas_lowercase() {
        assert_suggestion_result(
            "south america",
            lint_group(FstDictionary::curated()),
            "South America",
        );
        assert_suggestion_result(
            "north america",
            lint_group(FstDictionary::curated()),
            "North America",
        );
    }

    #[test]
    fn americas_uppercase() {
        assert_suggestion_result(
            "SOUTH AMERICA",
            lint_group(FstDictionary::curated()),
            "South America",
        );
        assert_suggestion_result(
            "NORTH AMERICA",
            lint_group(FstDictionary::curated()),
            "North America",
        );
    }

    #[test]
    fn americas_allow_correct() {
        assert_lint_count("South America", lint_group(FstDictionary::curated()), 0);
        assert_lint_count("North America", lint_group(FstDictionary::curated()), 0);
    }

    #[test]
    fn issue_798() {
        assert_suggestion_result(
            "The United states is a big country.",
            lint_group(FstDictionary::curated()),
            "The United States is a big country.",
        );
    }

    #[test]
    fn united_nations_uppercase() {
        assert_suggestion_result(
            "UNITED NATIONS",
            lint_group(FstDictionary::curated()),
            "United Nations",
        );
    }

    #[test]
    fn united_arab_emirates_lowercase() {
        assert_suggestion_result(
            "UNITED ARAB EMIRATES",
            lint_group(FstDictionary::curated()),
            "United Arab Emirates",
        );
    }

    #[test]
    fn united_nations_allow_correct() {
        assert_lint_count("United Nations", lint_group(FstDictionary::curated()), 0);
    }

    #[test]
    fn meta_allow_correct() {
        assert_lint_count("Meta Quest", lint_group(FstDictionary::curated()), 0);
    }

    #[test]
    fn microsoft_lowercase() {
        assert_suggestion_result(
            "microsoft visual studio",
            lint_group(FstDictionary::curated()),
            "Microsoft Visual Studio",
        );
    }

    #[test]
    fn microsoft_first_word_is_correct() {
        assert_suggestion_result(
            "Microsoft visual studio",
            lint_group(FstDictionary::curated()),
            "Microsoft Visual Studio",
        );
    }

    #[test]
    fn test_atlantic_ocean_lowercase() {
        let dictionary = FstDictionary::curated();
        assert_suggestion_result("atlantic ocean", lint_group(dictionary), "Atlantic Ocean");
    }

    #[test]
    fn test_pacific_ocean_lowercase() {
        let dictionary = FstDictionary::curated();
        assert_suggestion_result("pacific ocean", lint_group(dictionary), "Pacific Ocean");
    }

    #[test]
    fn test_indian_ocean_lowercase() {
        let dictionary = FstDictionary::curated();
        assert_suggestion_result("indian ocean", lint_group(dictionary), "Indian Ocean");
    }

    #[test]
    fn test_southern_ocean_lowercase() {
        let dictionary = FstDictionary::curated();
        assert_suggestion_result("southern ocean", lint_group(dictionary), "Southern Ocean");
    }

    #[test]
    fn test_arctic_ocean_lowercase() {
        let dictionary = FstDictionary::curated();
        assert_suggestion_result("arctic ocean", lint_group(dictionary), "Arctic Ocean");
    }

    #[test]
    fn test_mediterranean_sea_lowercase() {
        let dictionary = FstDictionary::curated();
        assert_suggestion_result(
            "mediterranean sea",
            lint_group(dictionary),
            "Mediterranean Sea",
        );
    }

    #[test]
    fn test_caribbean_sea_lowercase() {
        let dictionary = FstDictionary::curated();
        assert_suggestion_result("caribbean sea", lint_group(dictionary), "Caribbean Sea");
    }

    #[test]
    fn test_south_china_sea_lowercase() {
        let dictionary = FstDictionary::curated();
        assert_suggestion_result("south china sea", lint_group(dictionary), "South China Sea");
    }

    #[test]
    fn test_atlantic_ocean_correct() {
        let dictionary = FstDictionary::curated();
        assert_lint_count("Atlantic Ocean", lint_group(dictionary), 0);
    }

    #[test]
    fn test_pacific_ocean_correct() {
        let dictionary = FstDictionary::curated();
        assert_lint_count("Pacific Ocean", lint_group(dictionary), 0);
    }

    #[test]
    fn test_indian_ocean_correct() {
        let dictionary = FstDictionary::curated();
        assert_lint_count("Indian Ocean", lint_group(dictionary), 0);
    }

    #[test]
    fn test_mediterranean_sea_correct() {
        let dictionary = FstDictionary::curated();
        assert_lint_count("Mediterranean Sea", lint_group(dictionary), 0);
    }

    #[test]
    fn test_south_china_sea_correct() {
        let dictionary = FstDictionary::curated();
        assert_lint_count("South China Sea", lint_group(dictionary), 0);
    }

    #[test]
    fn day_one_in_sentence() {
        assert_suggestion_result(
            "I love day one. It is the best journaling app.",
            lint_group(FstDictionary::curated()),
            "I love Day One. It is the best journaling app.",
        );
    }

    #[test]
    fn gilded_age_in_sentence() {
        assert_suggestion_result(
            "Mani-Chess Destiny is a JavaScript based computer game built off of chess, but in the style of the gilded age.",
            lint_group(FstDictionary::curated()),
            "Mani-Chess Destiny is a JavaScript based computer game built off of chess, but in the style of the Gilded Age.",
        );
    }
}



================================================
FILE: harper-core/src/linting/quantifier_needs_of.rs
================================================
use crate::Token;
use crate::expr::{Expr, SequenceExpr};
use crate::patterns::WordSet;

use super::{ExprLinter, Lint, LintKind, Suggestion};
use crate::linting::expr_linter::Chunk;

/// Flags phrases like `a couple months` → should be `a couple **of** months`.
pub struct QuantifierNeedsOf {
    expr: Box<dyn Expr>,
}

impl Default for QuantifierNeedsOf {
    fn default() -> Self {
        let expr = SequenceExpr::default()
            .then_indefinite_article()
            .t_ws()
            .then(WordSet::new(&["couple", "lot"]))
            .t_ws()
            .then_plural_nominal();

        Self {
            expr: Box::new(expr),
        }
    }
}

impl ExprLinter for QuantifierNeedsOf {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], _source: &[char]) -> Option<Lint> {
        Some(Lint {
            span: matched_tokens.get(2)?.span,
            lint_kind: LintKind::Miscellaneous,
            suggestions: vec![Suggestion::InsertAfter(" of".chars().collect())],
            message: "Add `of` in this quantity phrase.".to_owned(),
            priority: 32,
        })
    }

    fn description(&self) -> &'static str {
        "Detects missing `of` after the quantifier “a couple” when it precedes a plural noun"
    }
}

#[cfg(test)]
mod tests {
    use crate::linting::tests::assert_suggestion_result;

    use super::QuantifierNeedsOf;

    #[test]
    fn fixes_a_couple_months() {
        assert_suggestion_result(
            "A couple months ago...",
            QuantifierNeedsOf::default(),
            "A couple of months ago...",
        );
    }

    #[test]
    fn fixes_a_couple_weeks() {
        assert_suggestion_result(
            "A couple weeks ago...",
            QuantifierNeedsOf::default(),
            "A couple of weeks ago...",
        );
    }

    #[test]
    fn fixes_a_couple_days() {
        assert_suggestion_result(
            "A couple days ago...",
            QuantifierNeedsOf::default(),
            "A couple of days ago...",
        );
    }

    #[test]
    fn fixes_a_couple_seconds() {
        assert_suggestion_result(
            "A couple seconds ago...",
            QuantifierNeedsOf::default(),
            "A couple of seconds ago...",
        );
    }

    #[test]
    fn fixes_a_couple_minutes() {
        assert_suggestion_result(
            "A couple minutes ago...",
            QuantifierNeedsOf::default(),
            "A couple of minutes ago...",
        );
    }

    #[test]
    fn fixes_a_couple_houses() {
        assert_suggestion_result(
            "A couple houses ago...",
            QuantifierNeedsOf::default(),
            "A couple of houses ago...",
        );
    }

    #[test]
    fn fixes_a_couple_centuries() {
        assert_suggestion_result(
            "A couple centuries ago...",
            QuantifierNeedsOf::default(),
            "A couple of centuries ago...",
        );
    }

    #[test]
    fn fixes_a_couple_people() {
        assert_suggestion_result(
            "I saw a couple people walk by a few minutes ago.",
            QuantifierNeedsOf::default(),
            "I saw a couple of people walk by a few minutes ago.",
        );
    }
}



================================================
FILE: harper-core/src/linting/quantifier_numeral_conflict.rs
================================================
use crate::expr::{All, Expr, SequenceExpr, SpelledNumberExpr};
use crate::linting::expr_linter::Chunk;
use crate::linting::{ExprLinter, LintKind, Suggestion};
use crate::patterns::{NominalPhrase, WordSet};
use crate::token_string_ext::TokenStringExt;
use crate::{CharStringExt, Lint, Token};

pub struct QuantifierNumeralConflict {
    expr: Box<dyn Expr>,
}

impl Default for QuantifierNumeralConflict {
    fn default() -> Self {
        Self {
            expr: Box::new(All::new(vec![
                Box::new(
                    SequenceExpr::default()
                        .then_quantifier()
                        .t_ws()
                        .then_longest_of(vec![
                            Box::new(SpelledNumberExpr),
                            Box::new(SequenceExpr::default().then_cardinal_number()),
                        ]),
                ),
                Box::new(
                    SequenceExpr::default().then_unless(SequenceExpr::any_of(vec![
                        Box::new(WordSet::new(&["all", "any", "every", "no"])),
                        Box::new(
                            SequenceExpr::word_set(&["each", "some"])
                                .t_ws()
                                .t_aco("one"),
                        ),
                    ])),
                ),
            ])),
        }
    }
}

impl ExprLinter for QuantifierNumeralConflict {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint_with_context(
        &self,
        toks: &[Token],
        src: &[char],
        ctx: Option<(&[Token], &[Token])>,
    ) -> Option<Lint> {
        // If there's a hyphen straight after the number it's probably part of a compound
        if let Some((_, [next_tok, ..])) = ctx
            && next_tok.kind.is_hyphen()
        {
            return None;
        }

        let qtok = toks.first().unwrap();
        let quant = qtok.span.get_content_string(src);

        // Handle special cases for "least", "most", "each", and "both"
        match quant.to_ascii_lowercase().as_str() {
            "least" | "most" => {
                if let Some((previous, _)) = ctx
                    && let [.., prev_word, prev_space] = previous
                    && prev_space.kind.is_whitespace()
                    && prev_word.kind.is_word()
                    && prev_word
                        .span
                        .get_content(src)
                        .eq_ignore_ascii_case_chars(&['a', 't'])
                {
                    return None;
                }
            }

            "each" => {
                return Some(Lint {
                    span: qtok.span,
                    lint_kind: LintKind::Usage,
                    suggestions: vec![Suggestion::replace_with_match_case(
                        "every".chars().collect(),
                        qtok.span.get_content(src),
                    )],
                    message: "Use 'every' instead of 'each' before a number.".to_owned(),
                    ..Default::default()
                });
            }

            "both" => {
                if let Some((_, following)) = ctx
                    && let Some(noun_phrase_span) = NominalPhrase.run(1, following, src)
                    && let [ws, conj, ..] = following.get(noun_phrase_span.end..).unwrap_or(&[])
                    && ws.kind.is_whitespace()
                    && conj.kind.is_conjunction()
                    && conj
                        .span
                        .get_content_string(src)
                        .eq_ignore_ascii_case("and")
                {
                    return None;
                }
            }

            _ => {} // Continue with the default case
        }

        Some(Lint {
            span: toks.span()?,
            lint_kind: LintKind::Grammar,
            suggestions: vec![],
            message: format!("The word '{quant}' should not be used before a number."),
            ..Default::default()
        })
    }

    fn description(&self) -> &'static str {
        "Detects quantifier-numeral conflicts"
    }
}

#[cfg(test)]
mod tests {
    use crate::linting::tests::{assert_lint_count, assert_no_lints, assert_suggestion_result};

    use super::QuantifierNumeralConflict;

    #[test]
    fn flag_several_two() {
        assert_lint_count(
            "A few minutes ago, there was an outage due to several two hosts being down at the same time.",
            QuantifierNumeralConflict::default(),
            1,
        );
    }

    #[test]
    fn dont_flag_at_least() {
        assert_no_lints(
            "Serving a company that encourages the \"996\" work schedule usually means working for at least 60 hours per week.",
            QuantifierNumeralConflict::default(),
        );
    }

    #[test]
    fn dont_flag_at_most() {
        assert_no_lints(
            "But don't worry, the second machine takes at most 3 years.",
            QuantifierNumeralConflict::default(),
        );
    }

    #[test]
    fn dont_flag_both_32_bit_and_64_bit() {
        assert_no_lints(
            "Both 32 bit and 64 bit architectures are supported.",
            QuantifierNumeralConflict::default(),
        );
    }

    #[test]
    fn dont_flag_more_1_click() {
        assert_no_lints(
            "For more 1-click cloud deployments, see [Cloud Deployment",
            QuantifierNumeralConflict::default(),
        );
    }

    #[test]
    fn correct_each_2() {
        assert_suggestion_result(
            "OSSEC by default run rootkit check each 2 hours.",
            QuantifierNumeralConflict::default(),
            "OSSEC by default run rootkit check every 2 hours.",
        );
    }

    #[test]
    fn ignore_no_two_adjacent_characters_2486() {
        assert_no_lints(
            "No two adjacent characters are the same.",
            QuantifierNumeralConflict::default(),
        );
    }
}



================================================
FILE: harper-core/src/linting/quite_quiet.rs
================================================
use crate::expr::{Expr, FirstMatchOf, SequenceExpr};
use crate::linting::expr_linter::Chunk;
use crate::linting::{ExprLinter, Lint, LintKind, Suggestion};
use crate::{CharStringExt, Token, TokenKind, TokenStringExt};

pub struct QuiteQuiet {
    expr: Box<dyn Expr>,
}

impl Default for QuiteQuiet {
    fn default() -> Self {
        let quiet_word = SequenceExpr::default()
            .t_aco("quiet")
            .t_ws()
            .then_kind_any_but_not_except(
                &[
                    TokenKind::is_adjective,
                    TokenKind::is_adverb,
                    TokenKind::is_verb,
                ] as &[_],
                TokenKind::is_noun,
                &["here", "up"],
            );

        let negative_contraction_quiet = SequenceExpr::default()
            .then(|tok: &Token, src: &[char]| {
                if !tok.kind.is_verb() || !tok.kind.is_apostrophized() {
                    return false;
                }
                tok.span
                    .get_content(src)
                    .ends_with_any_ignore_ascii_case_chars(&[&['n', '\'', 't'], &['n', '’', 't']])
            })
            .t_ws()
            .t_aco("quiet");

        let adverb_quite = SequenceExpr::default()
            .then_kind_except(
                TokenKind::is_adverb,
                &["actually", "never", "not", "really", "generally"],
            )
            .t_ws()
            .t_aco("quite");

        Self {
            expr: Box::new(FirstMatchOf::new(vec![
                Box::new(quiet_word),
                Box::new(negative_contraction_quiet),
                Box::new(adverb_quite),
            ])),
        }
    }
}

impl ExprLinter for QuiteQuiet {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, toks: &[Token], src: &[char]) -> Option<Lint> {
        let text = toks.span()?.get_content_string(src).to_lowercase();

        if text.ends_with("quite") {
            let quite_span = toks.last()?.span;

            return Some(Lint {
                span: quite_span,
                lint_kind: LintKind::Typo,
                suggestions: vec![Suggestion::replace_with_match_case(
                    "quiet".chars().collect(),
                    quite_span.get_content(src),
                )],
                message: "‘Quite’ might be a typo here. It means ‘rather’ but you might be trying to say ‘quiet’ (not noisy).".to_string(),
                priority: 63,
            });
        } else if text.starts_with("quiet") {
            let quiet_span = toks.first()?.span;

            return Some(Lint {
                span: quiet_span,
                lint_kind: LintKind::Typo,
                suggestions: vec![Suggestion::replace_with_match_case(
                    "quite".chars().collect(),
                    quiet_span.get_content(src),
                )],
                message: "‘Quiet’ might be a typo here. It means ‘not noisy’ but you might be trying to say ‘quite’ (rather).".to_string(),
                priority: 63,
            });
        } else if text.ends_with("quiet") {
            let quiet_span = toks.last()?.span;

            return Some(Lint {
                span: quiet_span,
                lint_kind: LintKind::Typo,
                suggestions: vec![Suggestion::replace_with_match_case(
                    "quite".chars().collect(),
                    quiet_span.get_content(src),
                )],
                message: "‘Quiet’ might be a typo here. It means ‘not noisy’ but you might be trying to say ‘quite’ (rather).".to_string(),
                priority: 63,
            });
        }

        None
    }

    fn description(&self) -> &str {
        "Helps distinguish between ‘quiet’ (making ‘little noise’) and ‘quite’ (meaning ‘rather’)."
    }
}

#[cfg(test)]
mod tests {
    use super::QuiteQuiet;
    use crate::linting::tests::{assert_lint_count, assert_no_lints, assert_suggestion_result};

    #[test]
    fn fix_quiet_adverb() {
        assert_suggestion_result(
            "Rendering videos 145 frames, with lightx loras for 2.1 i experience reboots quiet often.",
            QuiteQuiet::default(),
            "Rendering videos 145 frames, with lightx loras for 2.1 i experience reboots quite often.",
        );
    }

    #[test]
    fn fix_quiet_adjective() {
        assert_suggestion_result(
            "... has been already reported multiple times and I find it quiet dumb that it still exists",
            QuiteQuiet::default(),
            "... has been already reported multiple times and I find it quite dumb that it still exists",
        );
    }

    #[test]
    fn fix_very_quite() {
        assert_suggestion_result(
            "It's very quite here at night.",
            QuiteQuiet::default(),
            "It's very quiet here at night.",
        );
    }

    #[test]
    fn fix_doesnt_quiet() {
        assert_suggestion_result("doesn't quiet", QuiteQuiet::default(), "doesn't quite");
    }

    #[test]
    fn fix_doesnt_quiet_typographical_apostrophe() {
        assert_suggestion_result("doesn’t quiet", QuiteQuiet::default(), "doesn’t quite");
    }

    #[test]
    fn fix_doesnt_quiet_in_context() {
        assert_suggestion_result(
            "When we got the car back into the workshop, we actually managed to get it running and driving, but it doesn't quiet run right, and doesn't really let me rev it.",
            QuiteQuiet::default(),
            "When we got the car back into the workshop, we actually managed to get it running and driving, but it doesn't quite run right, and doesn't really let me rev it.",
        );
    }

    #[test]
    fn dont_flag_quiet_light() {
        assert_lint_count("The quiet lights in the houses", QuiteQuiet::default(), 0);
    }

    #[test]
    fn dont_flag_quiet_till() {
        assert_lint_count(
            "You’d better try and sit quiet till morning.",
            QuiteQuiet::default(),
            0,
        );
    }

    #[test]
    fn fix_cant_quiet() {
        assert_suggestion_result(
            "I can't quiet read it",
            QuiteQuiet::default(),
            "I can't quite read it",
        );
    }

    #[test]
    fn fix_wont_quiet() {
        assert_suggestion_result(
            "It won't quiet fit",
            QuiteQuiet::default(),
            "It won't quite fit",
        );
    }

    #[test]
    fn fix_couldnt_quiet() {
        assert_suggestion_result(
            "I couldn't quiet understand everything",
            QuiteQuiet::default(),
            "I couldn't quite understand everything",
        );
    }

    #[test]
    fn fix_but_its_not_quite_clear_1956() {
        assert_no_lints("But it's not quite clear", QuiteQuiet::default());
    }

    #[test]
    fn dont_flag_adv_quite_1971() {
        assert_no_lints(
            "It’s actually quite smart. It’s really quite smart. The proof is actually quite neat. Actually really quite simple. It’s actually quite strong. The Sneetches got really quite smart on that day.",
            QuiteQuiet::default(),
        );
    }

    #[test]
    fn issue_2003() {
        assert_no_lints(
            "The namespaces are generally quite short",
            QuiteQuiet::default(),
        );
    }
}



================================================
FILE: harper-core/src/linting/quote_spacing.rs
================================================
use crate::expr::{ExprExt, SequenceExpr};
use crate::linting::LintKind;
use crate::{Document, TokenStringExt};

use super::{Lint, Linter};

pub struct QuoteSpacing {
    expr: SequenceExpr,
}

impl QuoteSpacing {
    pub fn new() -> Self {
        Self {
            expr: SequenceExpr::default()
                .then_any_word()
                .then_quote()
                .then_any_word(),
        }
    }
}

impl Default for QuoteSpacing {
    fn default() -> Self {
        Self::new()
    }
}

impl Linter for QuoteSpacing {
    fn lint(&mut self, document: &Document) -> Vec<Lint> {
        let mut lints = Vec::new();

        for m in self.expr.iter_matches_in_doc(document) {
            let matched_tokens = m.get_content(document.get_tokens());

            let Some(span) = matched_tokens.span() else {
                continue;
            };

            lints.push(Lint {
                span,
                lint_kind: LintKind::Formatting,
                suggestions: vec![],
                message: "A quote must be preceded or succeeded by a space.".to_owned(),
                priority: 31,
            })
        }

        lints
    }

    fn description(&self) -> &str {
        "Checks that quotation marks are preceded or succeeded by whitespace."
    }
}

#[cfg(test)]
mod tests {
    use super::QuoteSpacing;
    use crate::linting::tests::{assert_lint_count, assert_no_lints};

    #[test]
    fn flags_missing_space_before_quote() {
        assert_lint_count("He said\"hello\" to me.", QuoteSpacing::default(), 1);
    }

    #[test]
    fn flags_missing_space_after_quote() {
        assert_lint_count(
            "She whispered \"hurry\"and left.",
            QuoteSpacing::default(),
            1,
        );
    }

    #[test]
    fn allows_quotes_with_spacing() {
        assert_no_lints("They shouted \"charge\" together.", QuoteSpacing::default());
    }

    #[test]
    fn allows_quotes_at_end_of_sentence() {
        assert_no_lints("They shouted \"charge.\"", QuoteSpacing::default());
    }
}



================================================
FILE: harper-core/src/linting/redundant_acronyms.rs
================================================
use crate::{
    CharStringExt, Token,
    expr::{Expr, FirstMatchOf, SequenceExpr},
    linting::{ExprLinter, Lint, LintKind, Suggestion, expr_linter::Chunk},
    patterns::Word,
    token_string_ext::TokenStringExt,
};

// (acronym, first_words, last_word)
const ACRONYMS: &[(&str, &[&str], &str)] = &[
    ("ATM", &["automated teller", "automatic teller"], "machine"),
    ("GUI", &["graphical user"], "interface"),
    ("LCD", &["liquid crystal"], "display"),
    // Note: "pin number" (not capitalized) is used to refer to GPIO pins etc.
    ("PIN", &["personal identification"], "number"),
    ("TUI", &["text-based user", "terminal user"], "interface"),
    ("UI", &["user"], "interface"),
    ("VIN", &["vehicle identification"], "number"),
];

pub struct RedundantAcronyms {
    expr: Box<dyn Expr>,
}

impl Default for RedundantAcronyms {
    fn default() -> Self {
        let exprs: Vec<Box<dyn Expr>> = ACRONYMS
            .iter()
            .map(|&(acronym, _, last_str)| {
                let last_string = last_str.to_string();
                Box::new(SequenceExpr::aco(acronym).t_ws().then_any_of(vec![
                    Box::new(Word::new(last_str)),
                    Box::new(move |t: &Token, src: &[char]| {
                        t.span
                            .get_content(src)
                            .eq_ignore_ascii_case_str(&format!("{last_string}s"))
                    }),
                ])) as Box<dyn Expr>
            })
            .collect();

        Self {
            expr: Box::new(FirstMatchOf::new(exprs)),
        }
    }
}

impl ExprLinter for RedundantAcronyms {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, toks: &[Token], src: &[char]) -> Option<Lint> {
        let last_word_span = toks.last()?.span;
        let last_word_chars = last_word_span.get_content(src);
        let acronym_str = toks.first()?.span.get_content_string(src);

        // "pin number" (lowercase) is used to refer to the pins on microchips, etc.
        if acronym_str.eq_ignore_ascii_case("PIN") && acronym_str != "PIN" {
            return None;
        }

        let (_, middle_words, _) = ACRONYMS
            .iter()
            .find(|(a, _, _)| (*a).eq_ignore_ascii_case(&acronym_str))?;

        let is_all_caps = last_word_chars
            .iter()
            .all(|c| c.is_ascii_alphabetic() && c.is_ascii_uppercase());

        let plural_ending = last_word_chars
            .last()
            .filter(|&&c| c.eq_ignore_ascii_case(&'s'))
            .map(|c| c.to_string())
            .unwrap_or_default();

        let suggestions: Vec<Suggestion> = std::iter::once(Suggestion::ReplaceWith(
            format!("{acronym_str}{plural_ending}").chars().collect(),
        ))
        .chain(middle_words.iter().map(|mw| {
            let middle_words = if is_all_caps {
                mw.to_ascii_uppercase()
            } else {
                mw.to_string()
            };
            Suggestion::ReplaceWith(
                format!("{middle_words} {}", last_word_span.get_content_string(src))
                    .chars()
                    .collect(),
            )
        }))
        .collect();

        Some(Lint {
        span: toks.span()?,
        lint_kind: LintKind::Redundancy,
        suggestions,
        message: "The acronym's last letter already stands for the last word. Use just the acronym or the full phrase.".to_string(),
        ..Default::default()
    })
    }

    fn description(&self) -> &str {
        "Identifies redundant acronyms where the last word repeats the last letter's meaning (e.g., `ATM machine` → `ATM` or `automated teller machine`)."
    }
}

#[cfg(test)]
mod tests {
    use super::RedundantAcronyms;
    use crate::linting::tests::{assert_good_and_bad_suggestions, assert_no_lints};

    #[test]
    fn test_made_up() {
        assert_good_and_bad_suggestions(
            "I forgot my PIN number!",
            RedundantAcronyms::default(),
            &[
                "I forgot my PIN!",
                "I forgot my personal identification number!",
            ],
            &[],
        );
    }

    #[test]
    fn test_all_caps_singular() {
        assert_good_and_bad_suggestions(
            "CAN TWO CARS HAVE THE SAME VIN NUMBER?",
            RedundantAcronyms::default(),
            &[
                "CAN TWO CARS HAVE THE SAME VIN?",
                "CAN TWO CARS HAVE THE SAME VEHICLE IDENTIFICATION NUMBER?",
            ],
            &[],
        );
    }

    #[test]
    fn test_all_caps_plural() {
        assert_good_and_bad_suggestions(
            "THESE ATM MACHINES ALL HAVE HIGH FEES!",
            RedundantAcronyms::default(),
            &[
                "THESE ATMS ALL HAVE HIGH FEES!",
                "THESE AUTOMATED TELLER MACHINES ALL HAVE HIGH FEES!",
            ],
            &[],
        );
    }

    #[test]
    fn test_all_lowercase_singular() {
        assert_good_and_bad_suggestions(
            "the atm machine at my card",
            RedundantAcronyms::default(),
            &[
                "the atm at my card",
                "the automated teller machine at my card",
            ],
            &[],
        );
    }

    #[test]
    fn test_all_lowercase_plural() {
        assert_good_and_bad_suggestions(
            "gui interfaces were sooo trendy in 1984!",
            RedundantAcronyms::default(),
            &[
                "guis were sooo trendy in 1984!",
                "graphical user interfaces were sooo trendy in 1984!",
            ],
            &[],
        );
    }

    #[test]
    fn correct_atm_machine() {
        assert_good_and_bad_suggestions(
            "Developed an ATM machine application for Raspberry Pi",
            RedundantAcronyms::default(),
            &[
                "Developed an ATM application for Raspberry Pi",
                "Developed an automatic teller machine application for Raspberry Pi",
                "Developed an automated teller machine application for Raspberry Pi",
            ],
            &[],
        );
    }

    #[test]
    fn correct_atm_machines() {
        assert_good_and_bad_suggestions(
            "ATM machines allow 4 or 6 digit PIN codes",
            RedundantAcronyms::default(),
            &[
                "ATMs allow 4 or 6 digit PIN codes",
                "automated teller machines allow 4 or 6 digit PIN codes",
                "automatic teller machines allow 4 or 6 digit PIN codes",
            ],
            &[],
        );
    }

    #[test]
    fn correct_gui_interface() {
        assert_good_and_bad_suggestions(
            "This project develops using java language with GUI interface.",
            RedundantAcronyms::default(),
            &[
                "This project develops using java language with GUI.",
                "This project develops using java language with graphical user interface.",
            ],
            &[],
        );
    }

    #[test]
    fn correct_gui_interfaces() {
        assert_good_and_bad_suggestions(
            "In non-crafting GUI interfaces, such as a mod's own recipe tree, the shortcut key cannot be used to view item usage or crafting methods.",
            RedundantAcronyms::default(),
            &[
                "In non-crafting GUIs, such as a mod's own recipe tree, the shortcut key cannot be used to view item usage or crafting methods.",
                "In non-crafting graphical user interfaces, such as a mod's own recipe tree, the shortcut key cannot be used to view item usage or crafting methods.",
            ],
            &[],
        );
    }

    #[test]
    fn correct_lcd_display() {
        assert_good_and_bad_suggestions(
            "This function accepts I2C shield address for LCD display, number of columns, rows and dot size",
            RedundantAcronyms::default(),
            &[
                "This function accepts I2C shield address for LCD, number of columns, rows and dot size",
                "This function accepts I2C shield address for liquid crystal display, number of columns, rows and dot size",
            ],
            &[],
        );
    }

    #[test]
    fn correct_lcd_displays() {
        assert_good_and_bad_suggestions(
            "ScreenUi makes it easy to build simple or complex character based user interfaces on small LCD displays like those commonly used with Arduinos.",
            RedundantAcronyms::default(),
            &[
                "ScreenUi makes it easy to build simple or complex character based user interfaces on small LCDs like those commonly used with Arduinos.",
                "ScreenUi makes it easy to build simple or complex character based user interfaces on small liquid crystal displays like those commonly used with Arduinos.",
            ],
            &[],
        );
    }

    #[test]
    fn correct_pin_numbers_caps() {
        assert_good_and_bad_suggestions(
            "Randomly generating PIN numbers for ATM access.",
            RedundantAcronyms::default(),
            &[
                "Randomly generating PINs for ATM access.",
                "Randomly generating personal identification numbers for ATM access.",
            ],
            &[],
        );
    }

    #[test]
    fn correct_pin_number_all_caps() {
        assert_good_and_bad_suggestions(
            "DON'T LET ANYONE SEE YOUR PIN NUMBER",
            RedundantAcronyms::default(),
            &[
                "DON'T LET ANYONE SEE YOUR PIN",
                "DON'T LET ANYONE SEE YOUR PERSONAL IDENTIFICATION NUMBER",
            ],
            &[],
        );
    }

    #[test]
    fn dont_correct_pin_number_lowercase() {
        assert_no_lints(
            "GPIO 26 (pin 37) on the Pi4 is mapped to pin nummer GPIO 425 on the pi5",
            RedundantAcronyms::default(),
        );
    }

    #[test]
    fn dont_correct_pin_number_titlecase() {
        assert_no_lints(
            "Pin Number Match Project in Javascript.",
            RedundantAcronyms::default(),
        )
    }

    #[test]
    fn correct_tui_interface() {
        assert_good_and_bad_suggestions(
            "Could a history search TUI interface be added for xonsh?",
            RedundantAcronyms::default(),
            &[
                "Could a history search TUI be added for xonsh?",
                "Could a history search text-based user interface be added for xonsh?",
                "Could a history search terminal user interface be added for xonsh?",
            ],
            &[],
        );
    }

    #[test]
    fn correct_ui_interface() {
        assert_good_and_bad_suggestions(
            "call ESPUI.begin(\"Some Title\"); to start the UI interface",
            RedundantAcronyms::default(),
            &[
                "call ESPUI.begin(\"Some Title\"); to start the UI",
                "call ESPUI.begin(\"Some Title\"); to start the user interface",
            ],
            &[],
        );
    }

    #[test]
    fn correct_vin_numbers() {
        assert_good_and_bad_suggestions(
            "That was actually accurate in decoding the VIN numbers but it costed me a 1000 USD.",
            RedundantAcronyms::default(),
            &[
                "That was actually accurate in decoding the VINs but it costed me a 1000 USD.",
                "That was actually accurate in decoding the vehicle identification numbers but it costed me a 1000 USD.",
            ],
            &[],
        );
    }

    #[test]
    fn correct_vin_number() {
        assert_good_and_bad_suggestions(
            "we have implemented verification algorithms, which ensure that VIN number received is correct",
            RedundantAcronyms::default(),
            &[
                "we have implemented verification algorithms, which ensure that VIN received is correct",
                "we have implemented verification algorithms, which ensure that vehicle identification number received is correct",
            ],
            &[],
        );
    }
}



================================================
FILE: harper-core/src/linting/redundant_additive_adverbs.rs
================================================
use crate::linting::expr_linter::Chunk;
use crate::{
    Lrc, Token, TokenStringExt,
    expr::{Expr, FirstMatchOf, FixedPhrase, SequenceExpr},
    linting::{ExprLinter, Lint, LintKind, Suggestion},
    patterns::WordSet,
};

pub struct RedundantAdditiveAdverbs {
    expr: Box<dyn Expr>,
}

impl Default for RedundantAdditiveAdverbs {
    fn default() -> Self {
        let also_too = WordSet::new(&["also", "too"]);
        let as_well = FixedPhrase::from_phrase("as well");

        let additive_adverb = Lrc::new(FirstMatchOf::new(vec![
            Box::new(also_too),
            Box::new(as_well),
        ]));

        let multiple_additive_adverbs = SequenceExpr::default()
            .then(additive_adverb.clone())
            .then_one_or_more(
                SequenceExpr::default()
                    .then_whitespace()
                    .then(additive_adverb.clone()),
            )
            .then_optional(SequenceExpr::default().then_whitespace().t_aco("as"));

        Self {
            expr: Box::new(multiple_additive_adverbs),
        }
    }
}

impl ExprLinter for RedundantAdditiveAdverbs {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, toks: &[Token], src: &[char]) -> Option<Lint> {
        let phrase_string = toks.span()?.get_content_string(src).to_lowercase();

        // Rule out `also too` as in `This is also too slow`.
        if phrase_string.eq("also too") {
            return None;
        }

        let mut toks = toks;

        // Check for the `as well as` false positive at the end
        if phrase_string.ends_with(" as well as") {
            // three word tokens and three whitespace tokens
            if toks.len() >= 6 {
                toks = &toks[..toks.len() - 6];
            }
        }

        let mut additive_adverbs: Vec<&[char]> = vec![];

        for word in toks
            .iter()
            .filter(|tok| tok.kind.is_word())
            .map(|tok| tok.span.get_content(src))
            .collect::<Vec<_>>()
        {
            let term: &[char] = match word {
                ['a', 's'] | ['w', 'e', 'l', 'l'] => &['a', 's', ' ', 'w', 'e', 'l', 'l'],
                _ => word,
            };
            if !additive_adverbs.contains(&term) {
                additive_adverbs.push(term);
            }
        }

        // Because of the possible `as well as` false positive, we might only have one additive adverb left.
        if additive_adverbs.len() < 2 {
            return None;
        }

        let suggestions = additive_adverbs
            .iter()
            .filter_map(|adverb| {
                Some(Suggestion::replace_with_match_case(
                    adverb.to_vec(),
                    toks.span()?.get_content(src),
                ))
            })
            .collect::<Vec<_>>();

        let message = format!(
            "Use just one of `{}`.",
            additive_adverbs
                .iter()
                .map(|s| s.iter().collect::<String>())
                .collect::<Vec<_>>()
                .join("` or `")
        );

        Some(Lint {
            span: toks.span()?,
            lint_kind: LintKind::Redundancy,
            suggestions,
            message,
            priority: 31,
        })
    }

    fn description(&self) -> &'static str {
        "Detects redundant additive adverbs."
    }
}

#[cfg(test)]
mod tests {
    use super::RedundantAdditiveAdverbs;
    use crate::linting::tests::{assert_lint_count, assert_top3_suggestion_result};

    // Basic unit tests

    #[test]
    fn flag_as_well_too() {
        assert_top3_suggestion_result(
            "Yeah, we definitely miss him on this episode here, but you could probably get him on a podcast that's more focused on what Equinix is doing as well too, specifically.",
            RedundantAdditiveAdverbs::default(),
            "Yeah, we definitely miss him on this episode here, but you could probably get him on a podcast that's more focused on what Equinix is doing as well, specifically.",
        );
    }

    #[test]
    fn flag_too_also() {
        assert_top3_suggestion_result(
            "The #1 uptime service with many servers and is easy to setup. It is free too also.",
            RedundantAdditiveAdverbs::default(),
            "The #1 uptime service with many servers and is easy to setup. It is free also.",
        );
    }

    #[test]
    fn dont_flag_also_too() {
        assert_lint_count(
            "The version update is also too slow.",
            RedundantAdditiveAdverbs::default(),
            0,
        );
    }

    #[test]
    fn dont_flag_also_as_well_as() {
        assert_lint_count(
            "Believe there are stable packages in the readme also as well as a link to an old version of forge in the ...",
            RedundantAdditiveAdverbs::default(),
            0,
        );
    }

    #[test]
    fn do_flag_too_also_as_well_as() {
        assert_lint_count(
            "What would happen with a sentence that included too also as well as?",
            RedundantAdditiveAdverbs::default(),
            1,
        );
    }

    #[test]
    fn flag_too_as_well() {
        assert_top3_suggestion_result(
            "Module name itself was changed too as well.",
            RedundantAdditiveAdverbs::default(),
            "Module name itself was changed as well.",
        );
    }
}



================================================
FILE: harper-core/src/linting/regionalisms.rs
================================================
use crate::{
    Dialect::{self, American, Australian, British, Canadian, Indian},
    Token, TokenStringExt,
    expr::{Expr, FirstMatchOf, FixedPhrase},
    linting::{Lint, LintKind, Suggestion},
};

use super::ExprLinter;
use crate::linting::expr_linter::Chunk;

#[derive(PartialEq)]
enum CanFlag {
    /// Flag this term as a regionalism that should be suggested against
    Flag,
    /// Don't flag this term because it's universally understood across dialects
    UniversalTerm,
    /// Don't flag this term because it has other common meanings that could cause false positives
    HasOtherMeanings,
}

use CanFlag::*;

/// Represents a unique concept that has different regional terms across English dialects.
/// Each is named by an alphabetical concatenation of the terms that refer to the same concept.
/// This allows us to suggest appropriate regional alternatives when a term from another dialect is detected.
#[derive(PartialEq)]
enum Concept {
    AubergineBrinjalEggplant,
    AuberginesBrinjalsEggplants,
    BharatIndia,
    // BiscuitCookie - biscuit names different foods in UK/Aus vs US; cookie has other meanings
    // BiscuitCracker - cracker also has other meanings
    BloodNoseNosebleed,
    BritBritisher,
    BritsBritishers,
    BumBagFannyPack,
    BurglarizeBurgle,
    CampervanRv,
    CaravanTrailer,
    CatsupKetchupTomatoSauce,
    CellPhoneMobilePhone,
    CoolboxCoolerEsky,
    ChipsCrisps,
    CilantroCoriander,
    Crore,
    Crores,
    DiaperNappy,
    DoonaDuvet,
    DummyPacifier,
    FaucetTap,
    FlashlightTorch,
    FootballSoccer,
    FootpathPavementSidewalk,
    GasolinePetrol,
    GasStationPetrolStationServiceStation,
    // HooverVacuumCleaner - Hoover is also a surname and vacuum cleaner is universal.
    JumperSweater,
    Lakh,
    Lakhs,
    LightBulbLightGlobe,
    LorryTruck,
    MotorhomeRv,
    PhotocopierXerox,
    PhotocopyXerox,
    PickupUte,
    PramStroller,
    Prepone,
    SpannerWrench,
    StationWagonEstate,
    UpdateUpdation,
    UpdatesUpdations,
    WindscreenWindshield,
}

use Concept::*;

/// Represents a single entry in our regional terms database
struct Term<'a> {
    /// The term (e.g., "light globe", "sidewalk")
    term: &'a str,
    /// Whether to flag this term or only suggest it.
    /// We don't want to flag universal terms just because they have a regional synonym.
    /// We also don't want to flag terms that are common in other senses.
    flag: CanFlag,
    /// The dialect(s) this term is associated with.
    dialects: &'a [Dialect],
    /// The concept this term is associated with.
    /// Named by concatenating all the associated terms in alphabetical order.
    concept: Concept,
}

const REGIONAL_TERMS: &[Term<'_>] = &[
    Term {
        term: "aubergine",
        flag: Flag,
        dialects: &[British],
        concept: AubergineBrinjalEggplant,
    },
    Term {
        term: "aubergines",
        flag: Flag,
        dialects: &[British],
        concept: AuberginesBrinjalsEggplants,
    },
    Term {
        term: "Bharat",
        flag: Flag,
        dialects: &[Indian],
        concept: BharatIndia,
    },
    Term {
        term: "brinjal",
        flag: Flag,
        dialects: &[Indian],
        concept: AubergineBrinjalEggplant,
    },
    Term {
        term: "brinjals",
        flag: Flag,
        dialects: &[Indian],
        concept: AuberginesBrinjalsEggplants,
    },
    Term {
        term: "Brit",
        flag: UniversalTerm,
        dialects: &[American, Australian, British, Canadian],
        concept: BritBritisher,
    },
    Term {
        term: "Brits",
        flag: UniversalTerm,
        dialects: &[American, Australian, British, Canadian],
        concept: BritsBritishers,
    },
    Term {
        term: "Britisher",
        flag: Flag,
        dialects: &[Indian],
        concept: BritBritisher,
    },
    Term {
        term: "Britishers",
        flag: Flag,
        dialects: &[Indian],
        concept: BritsBritishers,
    },
    Term {
        term: "blood nose",
        flag: Flag,
        dialects: &[Australian],
        concept: BloodNoseNosebleed,
    },
    Term {
        term: "bum bag",
        flag: Flag,
        dialects: &[Australian],
        concept: BumBagFannyPack,
    },
    Term {
        term: "burglarize",
        flag: Flag,
        dialects: &[American],
        concept: BurglarizeBurgle,
    },
    Term {
        term: "burgle",
        flag: Flag,
        dialects: &[British],
        concept: BurglarizeBurgle,
    },
    Term {
        term: "campervan",
        flag: Flag,
        dialects: &[Australian, British],
        concept: CampervanRv,
    },
    Term {
        term: "caravan",
        flag: UniversalTerm,
        dialects: &[Australian, British],
        concept: CaravanTrailer,
    },
    Term {
        term: "catsup",
        flag: Flag,
        dialects: &[American],
        concept: CatsupKetchupTomatoSauce,
    },
    Term {
        term: "cellphone",
        flag: Flag,
        dialects: &[American],
        concept: CellPhoneMobilePhone,
    },
    Term {
        term: "chips",
        flag: UniversalTerm,
        dialects: &[American, Australian],
        concept: ChipsCrisps,
    },
    Term {
        term: "cilantro",
        flag: Flag,
        dialects: &[American],
        concept: CilantroCoriander,
    },
    Term {
        term: "coolbox",
        flag: Flag,
        dialects: &[British],
        concept: CoolboxCoolerEsky,
    },
    Term {
        term: "cooler",
        flag: HasOtherMeanings,
        dialects: &[American, Canadian],
        concept: CoolboxCoolerEsky,
    },
    Term {
        term: "coriander",
        flag: Flag,
        dialects: &[Australian, British],
        concept: CilantroCoriander,
    },
    Term {
        term: "crisps",
        flag: Flag,
        dialects: &[British],
        concept: ChipsCrisps,
    },
    Term {
        term: "crore",
        flag: Flag,
        dialects: &[Indian],
        concept: Crore,
    },
    Term {
        term: "crores",
        flag: Flag,
        dialects: &[Indian],
        concept: Crores,
    },
    Term {
        term: "diaper",
        flag: Flag,
        dialects: &[American, Canadian],
        concept: DiaperNappy,
    },
    Term {
        term: "doona",
        flag: Flag,
        dialects: &[Australian],
        concept: DoonaDuvet,
    },
    Term {
        term: "dummy",
        flag: HasOtherMeanings,
        dialects: &[Australian],
        concept: DummyPacifier,
    },
    Term {
        term: "duvet",
        flag: Flag,
        dialects: &[Australian],
        concept: DoonaDuvet,
    },
    Term {
        term: "eggplant",
        flag: Flag,
        dialects: &[American, Australian],
        concept: AubergineBrinjalEggplant,
    },
    Term {
        term: "eggplants",
        flag: Flag,
        dialects: &[American, Australian],
        concept: AuberginesBrinjalsEggplants,
    },
    Term {
        term: "esky",
        flag: Flag,
        dialects: &[Australian],
        concept: CoolboxCoolerEsky,
    },
    Term {
        term: "estate",
        flag: HasOtherMeanings,
        dialects: &[British],
        concept: StationWagonEstate,
    },
    Term {
        term: "fanny pack",
        flag: Flag,
        dialects: &[American, Canadian],
        concept: BumBagFannyPack,
    },
    Term {
        term: "faucet",
        flag: Flag,
        dialects: &[American],
        concept: FaucetTap,
    },
    Term {
        term: "flashlight",
        flag: Flag,
        dialects: &[American, Canadian],
        concept: FlashlightTorch,
    },
    Term {
        term: "football",
        flag: HasOtherMeanings,
        dialects: &[British],
        concept: FootballSoccer,
    },
    Term {
        term: "footpath",
        flag: Flag,
        dialects: &[Australian],
        concept: FootpathPavementSidewalk,
    },
    Term {
        term: "gas",
        flag: HasOtherMeanings,
        dialects: &[American, Canadian],
        concept: GasolinePetrol,
    },
    Term {
        term: "gas station",
        flag: Flag,
        dialects: &[American, Canadian],
        concept: GasStationPetrolStationServiceStation,
    },
    Term {
        term: "gasoline",
        flag: Flag,
        dialects: &[American],
        concept: GasolinePetrol,
    },
    Term {
        term: "India",
        flag: UniversalTerm,
        dialects: &[American, Australian, British, Canadian, Indian],
        concept: BharatIndia,
    },
    Term {
        term: "jumper",
        flag: HasOtherMeanings,
        dialects: &[Australian],
        concept: JumperSweater,
    },
    Term {
        term: "ketchup",
        flag: Flag,
        dialects: &[American, Canadian],
        concept: CatsupKetchupTomatoSauce,
    },
    Term {
        term: "lakh",
        flag: Flag,
        dialects: &[Indian],
        concept: Lakh,
    },
    Term {
        term: "lakhs",
        flag: Flag,
        dialects: &[Indian],
        concept: Lakhs,
    },
    Term {
        term: "light bulb",
        flag: UniversalTerm,
        dialects: &[American, Australian, British, Canadian],
        concept: LightBulbLightGlobe,
    },
    Term {
        term: "light globe",
        flag: Flag,
        dialects: &[Australian],
        concept: LightBulbLightGlobe,
    },
    Term {
        term: "lorry",
        flag: Flag,
        dialects: &[British],
        concept: LorryTruck,
    },
    Term {
        term: "mobile phone",
        flag: Flag,
        dialects: &[Australian, British],
        concept: CellPhoneMobilePhone,
    },
    Term {
        term: "motorhome",
        flag: Flag,
        dialects: &[Australian, British],
        concept: MotorhomeRv,
    },
    Term {
        term: "nappy",
        flag: Flag,
        dialects: &[Australian, British],
        concept: DiaperNappy,
    },
    Term {
        term: "nosebleed",
        flag: UniversalTerm,
        dialects: &[American, Australian, British, Canadian],
        concept: BloodNoseNosebleed,
    },
    Term {
        term: "pacifier",
        flag: Flag,
        dialects: &[American],
        concept: DummyPacifier,
    },
    Term {
        term: "pavement",
        flag: HasOtherMeanings,
        dialects: &[British],
        concept: FootpathPavementSidewalk,
    },
    Term {
        term: "petrol",
        flag: Flag,
        dialects: &[Australian, British],
        concept: GasolinePetrol,
    },
    Term {
        term: "petrol station",
        flag: Flag,
        dialects: &[Australian, British],
        concept: GasStationPetrolStationServiceStation,
    },
    Term {
        term: "photocopier",
        flag: Flag,
        dialects: &[Australian, British, Canadian],
        concept: PhotocopierXerox,
    },
    Term {
        term: "photocopy",
        flag: Flag,
        dialects: &[Australian, British, Canadian],
        concept: PhotocopyXerox,
    },
    Term {
        term: "pickup truck",
        flag: Flag,
        dialects: &[American],
        concept: PickupUte,
    },
    Term {
        term: "pram",
        flag: Flag,
        dialects: &[Australian, British],
        concept: PramStroller,
    },
    Term {
        term: "prepone",
        flag: Flag,
        dialects: &[Indian],
        concept: Prepone,
    },
    Term {
        // Must be normalized to lowercase
        term: "rv",
        flag: Flag,
        dialects: &[American],
        concept: CampervanRv,
    },
    Term {
        term: "rv",
        flag: Flag,
        dialects: &[American],
        concept: MotorhomeRv,
    },
    Term {
        term: "sidewalk",
        flag: Flag,
        dialects: &[American, Canadian],
        concept: FootpathPavementSidewalk,
    },
    Term {
        term: "soccer",
        flag: Flag,
        dialects: &[American, Australian],
        concept: FootballSoccer,
    },
    Term {
        term: "spanner",
        flag: Flag,
        dialects: &[Australian, British],
        concept: SpannerWrench,
    },
    Term {
        term: "station wagon",
        flag: Flag,
        dialects: &[American, Australian],
        concept: StationWagonEstate,
    },
    Term {
        term: "stroller",
        flag: Flag,
        dialects: &[American, Australian],
        concept: PramStroller,
    },
    Term {
        term: "sweater",
        flag: Flag,
        dialects: &[American],
        concept: JumperSweater,
    },
    Term {
        term: "tap",
        flag: HasOtherMeanings,
        dialects: &[Australian, British],
        concept: FaucetTap,
    },
    Term {
        term: "tomato sauce",
        flag: HasOtherMeanings,
        dialects: &[Australian],
        concept: CatsupKetchupTomatoSauce,
    },
    Term {
        term: "torch",
        flag: HasOtherMeanings,
        dialects: &[Australian, British],
        concept: FlashlightTorch,
    },
    Term {
        term: "trailer",
        flag: HasOtherMeanings,
        dialects: &[American],
        concept: CaravanTrailer,
    },
    Term {
        term: "truck",
        flag: HasOtherMeanings,
        dialects: &[American, Australian, Canadian],
        concept: LorryTruck,
    },
    Term {
        term: "update",
        flag: UniversalTerm,
        dialects: &[American, Australian, British, Canadian],
        concept: UpdateUpdation,
    },
    Term {
        term: "updates",
        flag: UniversalTerm,
        dialects: &[American, Australian, British, Canadian],
        concept: UpdateUpdation,
    },
    Term {
        term: "updation",
        flag: Flag,
        dialects: &[Indian],
        concept: UpdateUpdation,
    },
    Term {
        term: "updations",
        flag: Flag,
        dialects: &[Indian],
        concept: UpdatesUpdations,
    },
    Term {
        term: "ute",
        flag: Flag,
        dialects: &[Australian],
        concept: PickupUte,
    },
    Term {
        term: "xerox",
        dialects: &[American],
        flag: Flag,
        concept: PhotocopierXerox,
    },
    Term {
        term: "xerox",
        flag: Flag,
        dialects: &[American],
        concept: PhotocopyXerox,
    },
    Term {
        term: "wrench",
        flag: Flag,
        dialects: &[American],
        concept: SpannerWrench,
    },
    Term {
        term: "windscreen",
        flag: Flag,
        dialects: &[British, Australian],
        concept: WindscreenWindshield,
    },
    Term {
        term: "windshield",
        flag: Flag,
        dialects: &[American, Canadian],
        concept: WindscreenWindshield,
    },
];

pub struct Regionalisms {
    expr: Box<dyn Expr>,
    dialect: Dialect,
}

impl Regionalisms {
    pub fn new(dialect: Dialect) -> Self {
        let terms: Vec<Box<dyn Expr>> = REGIONAL_TERMS
            .iter()
            .filter(|row| row.flag == Flag)
            .map(|row| Box::new(FixedPhrase::from_phrase(row.term)) as Box<dyn Expr>)
            .collect();

        Self {
            expr: Box::new(FirstMatchOf::new(terms)),
            dialect,
        }
    }
}

impl ExprLinter for Regionalisms {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, toks: &[Token], src: &[char]) -> Option<Lint> {
        let span = toks.span()?;
        let flagged_term_chars = span.get_content(src);
        let flagged_term_string = span.get_content_string(src).to_lowercase();

        let linter_dialect = self.dialect;

        // If this term is used in the linter dialect, then we don't want to lint it.
        if REGIONAL_TERMS
            .iter()
            .any(|row| row.term == flagged_term_string && row.dialects.contains(&linter_dialect))
        {
            return None;
        }

        let concept = match REGIONAL_TERMS
            .iter()
            .find(|row| row.term == flagged_term_string)
        {
            Some(term) => &term.concept,
            None => return None, // No matching term found, so nothing to lint
        };

        let other_terms = REGIONAL_TERMS
            .iter()
            .filter(|row| row.concept == *concept)
            .filter_map(|row| {
                if row.dialects.contains(&linter_dialect) {
                    Some(&row.term)
                } else {
                    None
                }
            })
            .collect::<Vec<_>>();

        let suggestions = other_terms
            .iter()
            .map(|term| Suggestion::replace_with_match_case_str(term, flagged_term_chars))
            .collect::<Vec<_>>();

        let message = if other_terms.len() == 1 {
            format!(
                "`{flagged_term_string}` isn't used in {linter_dialect} English. Use `{}` instead.",
                other_terms[0]
            )
        } else {
            format!("`{flagged_term_string}` isn't used in {linter_dialect} English.")
        };

        Some(Lint {
            span,
            lint_kind: LintKind::Regionalism,
            suggestions,
            message,
            priority: 64,
        })
    }

    fn description(&self) -> &str {
        "Regionalisms"
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::linting::tests::{
        assert_lint_count, assert_suggestion_result, assert_top3_suggestion_result,
    };

    #[test]
    fn uk_to_us_food() {
        assert_top3_suggestion_result(
            "I can't eat aubergine or coriander, so I'll just have a bag of crisps.",
            Regionalisms::new(Dialect::American),
            "I can't eat eggplant or cilantro, so I'll just have a bag of chips.",
        );
    }

    #[test]
    fn au_to_us_phone() {
        assert_top3_suggestion_result(
            "I dropped my mobile phone in the esky and now it's covered in tomato sauce.",
            Regionalisms::new(Dialect::American),
            // Tomato sauce is valid in American English, it just means pasta sauce rather than ketchup.
            "I dropped my cellphone in the cooler and now it's covered in tomato sauce.",
        )
    }

    #[test]
    fn au_to_uk_cars() {
        assert_top3_suggestion_result(
            "Drive the station wagon onto the footpath and hand me that spanner.",
            Regionalisms::new(Dialect::British),
            "Drive the estate onto the pavement and hand me that spanner.",
        )
    }

    #[test]
    fn au_to_us_cars() {
        assert_top3_suggestion_result(
            "Drive the station wagon onto the footpath and hand me that spanner.",
            Regionalisms::new(Dialect::American),
            "Drive the station wagon onto the sidewalk and hand me that wrench.",
        )
    }

    #[test]
    fn us_to_au_baby() {
        assert_top3_suggestion_result(
            "Wash the pacifier under the faucet.",
            Regionalisms::new(Dialect::Australian),
            "Wash the dummy under the tap.",
        )
    }

    #[test]
    fn us_to_uk_fuel() {
        assert_top3_suggestion_result(
            "I needed more gasoline to drive the truck to the soccer match.",
            Regionalisms::new(Dialect::British),
            "I needed more petrol to drive the truck to the football match.",
        )
    }

    #[test]
    fn au_to_uk_light() {
        assert_top3_suggestion_result(
            "Can you sell me a light globe for this torch?",
            Regionalisms::new(Dialect::British),
            "Can you sell me a light bulb for this torch?",
        )
    }

    #[test]
    fn us_to_au_oops() {
        assert_top3_suggestion_result(
            "I spilled ketchup on my clean sweater.",
            Regionalisms::new(Dialect::Australian),
            "I spilled tomato sauce on my clean jumper.",
        )
    }

    #[test]
    fn caravan_doesnt_always_mean_trailer() {
        assert_lint_count(
            "A caravan (from Persian کاروان kârvân) is a group of people traveling together, often on a trade expedition. Caravans were used mainly in desert areas.",
            Regionalisms::new(Dialect::British),
            0,
        )
    }

    #[test]
    fn uk_to_us_windscreen() {
        assert_top3_suggestion_result(
            "Detect raindrops on vehicle windscreen by combining various region proposal algorithm with Convolutional Neural Network.",
            Regionalisms::new(Dialect::American),
            "Detect raindrops on vehicle windshield by combining various region proposal algorithm with Convolutional Neural Network.",
        )
    }

    #[test]
    fn au_to_uk_blood_nose() {
        assert_top3_suggestion_result(
            "Oh no! I got a blood nose.",
            Regionalisms::new(Dialect::British),
            "Oh no! I got a nosebleed.",
        )
    }

    #[test]
    fn in_to_non_in_updation() {
        assert_top3_suggestion_result(
            "Add apps to queue for updation or installation and resize it.",
            Regionalisms::new(Dialect::American),
            "Add apps to queue for update or installation and resize it.",
        )
    }

    #[test]
    fn dont_flag_update_or_updation_for_indian() {
        assert_lint_count(
            "Hey, the colab notebook which you have provided, required lot of updations, Can you pls update it.",
            Regionalisms::new(Dialect::Indian),
            0,
        )
    }

    #[test]
    fn flag_crore_and_lakh_for_non_indian() {
        assert_lint_count(
            "There are 100 lakhs in one crore.",
            Regionalisms::new(Dialect::American),
            2,
        )
    }

    #[test]
    fn dont_flag_lakh_or_crore_for_indian() {
        assert_lint_count(
            "There are 100 lakhs in one crore.",
            Regionalisms::new(Dialect::Indian),
            0,
        )
    }

    #[test]
    fn a_brinjal_is_an_aubergine() {
        assert_suggestion_result(
            "Is brinjal used in curries or chutneys?",
            Regionalisms::new(Dialect::British),
            "Is aubergine used in curries or chutneys?",
        );
    }

    #[test]
    fn a_brinjal_is_an_eggplant() {
        assert_suggestion_result(
            "Is brinjal used in curries or chutneys?",
            Regionalisms::new(Dialect::Australian),
            "Is eggplant used in curries or chutneys?",
        );
    }
}



================================================
FILE: harper-core/src/linting/repeated_words.rs
================================================
use super::{Lint, LintKind, Linter, Suggestion};
use crate::TokenStringExt;
use crate::char_string::char_string;
use crate::{CharString, CharStringExt, Document, Span};

#[derive(Debug, Clone)]
pub struct RepeatedWords {
    /// Words that we need to make sure are detected.
    /// We use a `Vec` since there aren't a whole lot of 'em.
    special_cases: Vec<CharString>,
}
impl RepeatedWords {
    pub fn new() -> Self {
        Self {
            special_cases: vec![char_string!("this")],
        }
    }

    fn is_special_case(&self, chars: &[char]) -> bool {
        let lower = chars.to_lower();

        self.special_cases
            .iter()
            .any(|v| v.as_slice() == lower.as_ref())
    }
}

impl Default for RepeatedWords {
    fn default() -> Self {
        Self::new()
    }
}

impl Linter for RepeatedWords {
    fn lint(&mut self, document: &Document) -> Vec<Lint> {
        let mut lints = Vec::new();

        for chunk in document.iter_chunks() {
            let mut iter = chunk.iter_word_indices().zip(chunk.iter_words()).peekable();

            while let (Some((idx_a, tok_a)), Some((idx_b, tok_b))) = (iter.next(), iter.peek()) {
                let word_a = document.get_span_content(&tok_a.span);
                let word_b = document.get_span_content(&tok_b.span);

                let prev_tok = document.get_token_offset(idx_a, -1);
                let next_tok = document.get_token_offset(*idx_b, 1);

                if prev_tok.is_some_and(|t| t.kind.is_hyphen())
                    || next_tok.is_some_and(|t| t.kind.is_hyphen())
                {
                    continue;
                }

                if (tok_a.kind.is_preposition()
                    || tok_a.kind.is_conjunction()
                    || !tok_a.kind.is_likely_homograph()
                    || self.is_special_case(word_a)
                    || tok_a.kind.is_adverb()
                    || tok_a.kind.is_determiner())
                    && word_a.to_lower() == word_b.to_lower()
                {
                    let intervening_tokens = &chunk[idx_a + 1..*idx_b];

                    if intervening_tokens.iter().any(|t| !t.kind.is_whitespace()) {
                        continue;
                    }

                    lints.push(Lint {
                        span: Span::new(tok_a.span.start, tok_b.span.end),
                        lint_kind: LintKind::Repetition,
                        suggestions: vec![Suggestion::ReplaceWith(
                            document.get_span_content(&tok_a.span).to_vec(),
                        )],
                        message: "Did you mean to repeat this word?".to_string(),
                        ..Default::default()
                    })
                }
            }
        }

        lints
    }

    fn description(&self) -> &'static str {
        "This rule looks for repetitions of words that are not homographs."
    }
}

#[cfg(test)]
mod tests {
    use crate::linting::tests::assert_suggestion_result;

    use super::super::tests::assert_lint_count;
    use super::RepeatedWords;

    #[test]
    fn catches_basic() {
        assert_lint_count("I wanted the the banana.", RepeatedWords::default(), 1)
    }

    #[test]
    fn does_not_lint_homographs_address() {
        assert_lint_count("To address address problems.", RepeatedWords::default(), 0);
    }

    #[test]
    fn does_not_lint_homographs_record() {
        assert_lint_count("To record record profits.", RepeatedWords::default(), 0);
    }

    #[test]
    fn issue_253() {
        assert_lint_count(
            "this paper shows that, while the method may be more accurate accurate, the turnout overestimate suggests that self-selection bias is not sufficiently reduced",
            RepeatedWords::default(),
            1,
        );
    }

    #[test]
    fn issue_333() {
        assert_suggestion_result(
            "This is is a test",
            RepeatedWords::default(),
            "This is a test",
        );
    }

    #[test]
    fn double_a() {
        assert_suggestion_result(
            "This is a a test",
            RepeatedWords::default(),
            "This is a test",
        );
    }

    #[test]
    fn double_and() {
        assert_suggestion_result(
            "And and this is also a test",
            RepeatedWords::default(),
            "And this is also a test",
        );
    }

    #[test]
    fn on_on_github() {
        assert_suggestion_result(
            "Take a look at the project on on GitHub.",
            RepeatedWords::default(),
            "Take a look at the project on GitHub.",
        );
    }

    #[test]
    fn as_as() {
        assert_suggestion_result(
            "he is as as hard as nails",
            RepeatedWords::default(),
            "he is as hard as nails",
        );
    }

    #[test]
    fn dont_flag_first_hyphenated() {
        assert_lint_count(
            "The driver-facing camera and microphone are only logged if you explicitly opt-in in settings.",
            RepeatedWords::default(),
            0,
        );
    }

    #[test]
    fn dont_flag_hyphenated_either_side() {
        assert_lint_count("foo-foo foo bar bar-bar", RepeatedWords::default(), 0);
    }
}



================================================
FILE: harper-core/src/linting/respond.rs
================================================
use std::sync::Arc;

use crate::Token;
use crate::expr::{Expr, ExprMap, SequenceExpr};
use crate::linting::expr_linter::Chunk;
use crate::linting::{ExprLinter, Lint, LintKind, Suggestion};
use crate::patterns::Word;

pub struct Respond {
    expr: Box<dyn Expr>,
    map: Arc<ExprMap<usize>>,
}

impl Default for Respond {
    fn default() -> Self {
        let mut map = ExprMap::default();

        let helper_verb = |tok: &Token, src: &[char]| {
            if tok.kind.is_auxiliary_verb() {
                return true;
            }

            if !tok.kind.is_verb() {
                return false;
            }

            let lower = tok.span.get_content_string(src).to_lowercase();
            matches!(
                lower.as_str(),
                "do" | "did" | "does" | "won't" | "don't" | "didn't" | "doesn't"
            )
        };

        map.insert(
            SequenceExpr::default()
                .then_nominal()
                .t_ws()
                .then(helper_verb)
                .t_ws()
                .then(Word::new("response")),
            4,
        );

        map.insert(
            SequenceExpr::default()
                .then_nominal()
                .t_ws()
                .then(helper_verb)
                .t_ws()
                .then_adverb()
                .t_ws()
                .then(Word::new("response")),
            6,
        );

        let map = Arc::new(map);

        Self {
            expr: Box::new(map.clone()),
            map,
        }
    }
}

impl ExprLinter for Respond {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], source: &[char]) -> Option<Lint> {
        let response_index = *self.map.lookup(0, matched_tokens, source)?;
        let response_token = matched_tokens.get(response_index)?;

        Some(Lint {
            span: response_token.span,
            lint_kind: LintKind::WordChoice,
            suggestions: vec![Suggestion::replace_with_match_case_str(
                "respond",
                response_token.span.get_content(source),
            )],
            message: "Use the verb `respond` here.".to_owned(),
            priority: 40,
        })
    }

    fn description(&self) -> &'static str {
        "Flags uses of the noun `response` where the verb `respond` is needed after an auxiliary."
    }
}

#[cfg(test)]
mod tests {
    use super::Respond;
    use crate::linting::tests::{assert_lint_count, assert_no_lints, assert_suggestion_result};

    #[test]
    fn fixes_will_response() {
        assert_suggestion_result(
            "He will response soon.",
            Respond::default(),
            "He will respond soon.",
        );
    }

    #[test]
    fn fixes_can_response() {
        assert_suggestion_result(
            "They can response to the survey.",
            Respond::default(),
            "They can respond to the survey.",
        );
    }

    #[test]
    fn fixes_did_not_response() {
        assert_suggestion_result(
            "I did not response yesterday.",
            Respond::default(),
            "I did not respond yesterday.",
        );
    }

    #[test]
    fn fixes_might_quickly_response() {
        assert_suggestion_result(
            "She might quickly response to feedback.",
            Respond::default(),
            "She might quickly respond to feedback.",
        );
    }

    #[test]
    fn fixes_wont_response() {
        assert_suggestion_result(
            "They won't response in time.",
            Respond::default(),
            "They won't respond in time.",
        );
    }

    #[test]
    fn fixes_would_response() {
        assert_suggestion_result(
            "We would response if we could.",
            Respond::default(),
            "We would respond if we could.",
        );
    }

    #[test]
    fn fixes_should_response() {
        assert_suggestion_result(
            "You should response politely.",
            Respond::default(),
            "You should respond politely.",
        );
    }

    #[test]
    fn does_not_flag_correct_respond() {
        assert_no_lints("Please respond when you can.", Respond::default());
    }

    #[test]
    fn does_not_flag_noun_use() {
        assert_no_lints("The response time was great.", Respond::default());
    }

    #[test]
    fn does_not_flag_question_subject() {
        assert_lint_count("Should response times be logged?", Respond::default(), 0);
    }

    #[test]
    fn does_not_flag_response_as_object() {
        assert_no_lints("I have no response for that.", Respond::default());
    }
}



================================================
FILE: harper-core/src/linting/right_click.rs
================================================
use std::sync::Arc;

use crate::{
    Token, TokenStringExt,
    expr::{Expr, ExprMap, SequenceExpr},
    linting::expr_linter::Chunk,
    linting::{ExprLinter, Lint, LintKind, Suggestion},
    patterns::DerivedFrom,
};

pub struct RightClick {
    expr: Box<dyn Expr>,
    map: Arc<ExprMap<usize>>,
}

impl Default for RightClick {
    fn default() -> Self {
        let mut map = ExprMap::default();

        map.insert(
            SequenceExpr::default()
                .then_word_set(&["right", "left", "middle"])
                .t_ws()
                .then(DerivedFrom::new_from_str("click")),
            0,
        );

        let map = Arc::new(map);

        Self {
            expr: Box::new(map.clone()),
            map,
        }
    }
}

impl ExprLinter for RightClick {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], source: &[char]) -> Option<Lint> {
        let start_idx = *self.map.lookup(0, matched_tokens, source)?;
        let click_idx = matched_tokens.len().checked_sub(1)?;
        let span = matched_tokens.get(start_idx..=click_idx)?.span()?;
        let template = span.get_content(source);

        let direction = matched_tokens.get(start_idx)?.span.get_content(source);
        let click = matched_tokens.get(click_idx)?.span.get_content(source);

        let replacement: Vec<char> = direction
            .iter()
            .copied()
            .chain(['-'])
            .chain(click.iter().copied())
            .collect();

        Some(Lint {
            span,
            lint_kind: LintKind::Punctuation,
            suggestions: vec![Suggestion::replace_with_match_case(replacement, template)],
            message: "Hyphenate this mouse command.".to_owned(),
            priority: 40,
        })
    }

    fn description(&self) -> &'static str {
        "Hyphenates right-click style mouse commands."
    }
}

#[cfg(test)]
mod tests {
    use super::RightClick;
    use crate::linting::tests::{assert_lint_count, assert_suggestion_result};

    #[test]
    fn hyphenates_basic_command() {
        assert_suggestion_result(
            "Right click the icon.",
            RightClick::default(),
            "Right-click the icon.",
        );
    }

    #[test]
    fn hyphenates_with_preposition() {
        assert_suggestion_result(
            "Please right click on the link.",
            RightClick::default(),
            "Please right-click on the link.",
        );
    }

    #[test]
    fn hyphenates_past_tense() {
        assert_suggestion_result(
            "They right clicked the submit button.",
            RightClick::default(),
            "They right-clicked the submit button.",
        );
    }

    #[test]
    fn hyphenates_gerund() {
        assert_suggestion_result(
            "Right clicking the item highlights it.",
            RightClick::default(),
            "Right-clicking the item highlights it.",
        );
    }

    #[test]
    fn hyphenates_plural_noun() {
        assert_suggestion_result(
            "Right clicks are tracked in the log.",
            RightClick::default(),
            "Right-clicks are tracked in the log.",
        );
    }

    #[test]
    fn hyphenates_all_caps() {
        assert_suggestion_result(
            "He RIGHT CLICKED the file.",
            RightClick::default(),
            "He RIGHT-CLICKED the file.",
        );
    }

    #[test]
    fn hyphenates_left_click() {
        assert_suggestion_result(
            "Left click the checkbox.",
            RightClick::default(),
            "Left-click the checkbox.",
        );
    }

    #[test]
    fn hyphenates_middle_click() {
        assert_suggestion_result(
            "Middle click to open in a new tab.",
            RightClick::default(),
            "Middle-click to open in a new tab.",
        );
    }

    #[test]
    fn allows_hyphenated_form() {
        assert_lint_count("Right-click the icon.", RightClick::default(), 0);
    }

    #[test]
    fn ignores_unrelated_right_and_click() {
        assert_lint_count(
            "Click the right button to continue.",
            RightClick::default(),
            0,
        );
    }
}



================================================
FILE: harper-core/src/linting/roller_skated.rs
================================================
use std::sync::Arc;

use crate::linting::expr_linter::Chunk;
use crate::{
    Token, TokenKind, TokenStringExt,
    expr::{AnchorStart, Expr, ExprMap, SequenceExpr},
    linting::{ExprLinter, Lint, LintKind, Suggestion},
};

/// Suggests hyphenating the past tense of `roller-skate`.
pub struct RollerSkated {
    expr: Box<dyn Expr>,
    map: Arc<ExprMap<usize>>,
}

impl RollerSkated {
    fn roller_pair() -> SequenceExpr {
        SequenceExpr::default()
            .t_aco("roller")
            .t_ws()
            .t_aco("skated")
    }
}

impl Default for RollerSkated {
    fn default() -> Self {
        let mut map = ExprMap::default();

        map.insert(
            SequenceExpr::default()
                .then_kind_is_but_is_not(
                    |kind| matches!(kind, TokenKind::Word(_)),
                    |kind| kind.is_determiner(),
                )
                .then_whitespace()
                .then_seq(Self::roller_pair()),
            2,
        );

        map.insert(
            SequenceExpr::default()
                .then_punctuation()
                .then_whitespace()
                .then_seq(Self::roller_pair()),
            2,
        );

        map.insert(
            SequenceExpr::default()
                .then_punctuation()
                .then_seq(Self::roller_pair()),
            1,
        );

        map.insert(
            SequenceExpr::default()
                .then(AnchorStart)
                .then_seq(Self::roller_pair()),
            0,
        );

        let map = Arc::new(map);

        Self {
            expr: Box::new(map.clone()),
            map,
        }
    }
}

impl ExprLinter for RollerSkated {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], source: &[char]) -> Option<Lint> {
        let roller_idx = *self.map.lookup(0, matched_tokens, source)?;
        let skated_idx = roller_idx.checked_add(2)?;
        let window = matched_tokens.get(roller_idx..=skated_idx)?;
        let span = window.span()?;
        let original = span.get_content(source);

        Some(Lint {
            span,
            lint_kind: LintKind::Punctuation,
            suggestions: vec![Suggestion::replace_with_match_case(
                "roller-skated".chars().collect(),
                original,
            )],
            message: "Hyphenate this verb as `roller-skated`.".to_owned(),
            priority: 40,
        })
    }

    fn description(&self) -> &'static str {
        "Encourages hyphenating the past tense of `roller-skate`."
    }
}

#[cfg(test)]
mod tests {
    use super::RollerSkated;
    use crate::linting::tests::{assert_lint_count, assert_suggestion_result};

    #[test]
    fn corrects_basic_sentence() {
        assert_suggestion_result(
            "He roller skated down the hill.",
            RollerSkated::default(),
            "He roller-skated down the hill.",
        );
    }

    #[test]
    fn corrects_with_adverb() {
        assert_suggestion_result(
            "They roller skated quickly around the rink.",
            RollerSkated::default(),
            "They roller-skated quickly around the rink.",
        );
    }

    #[test]
    fn corrects_with_auxiliary() {
        assert_suggestion_result(
            "She had roller skated there before.",
            RollerSkated::default(),
            "She had roller-skated there before.",
        );
    }

    #[test]
    fn corrects_with_contraction() {
        assert_suggestion_result(
            "They'd roller skated all night.",
            RollerSkated::default(),
            "They'd roller-skated all night.",
        );
    }

    #[test]
    fn corrects_caps() {
        assert_suggestion_result(
            "They ROLLER SKATED yesterday.",
            RollerSkated::default(),
            "They ROLLER-SKATED yesterday.",
        );
    }

    #[test]
    fn corrects_in_quotes() {
        assert_suggestion_result(
            "\"We roller skated together,\" she said.",
            RollerSkated::default(),
            "\"We roller-skated together,\" she said.",
        );
    }

    #[test]
    fn corrects_across_line_break() {
        assert_suggestion_result(
            "We\nroller skated whenever we could.",
            RollerSkated::default(),
            "We\nroller-skated whenever we could.",
        );
    }

    #[test]
    fn corrects_with_trailing_punctuation() {
        assert_suggestion_result(
            "He roller skated, laughed, and waved.",
            RollerSkated::default(),
            "He roller-skated, laughed, and waved.",
        );
    }

    #[test]
    fn corrects_without_space_after_punctuation() {
        assert_suggestion_result(
            "He roller skated,laughed, and waved.",
            RollerSkated::default(),
            "He roller-skated,laughed, and waved.",
        );
    }

    #[test]
    fn allows_hyphenated_form() {
        assert_lint_count("They roller-skated yesterday.", RollerSkated::default(), 0);
    }

    #[test]
    fn allows_subject_named_roller() {
        assert_lint_count(
            "The roller skated across the stage.",
            RollerSkated::default(),
            0,
        );
    }

    #[test]
    fn allows_other_compounds() {
        assert_lint_count(
            "Their roller skating routine impressed everyone.",
            RollerSkated::default(),
            0,
        );
    }
}



================================================
FILE: harper-core/src/linting/safe_to_save.rs
================================================
use harper_brill::UPOS;

use crate::expr::Expr;
use crate::expr::OwnedExprExt;
use crate::expr::SequenceExpr;
use crate::linting::expr_linter::Chunk;
use crate::patterns::{ModalVerb, UPOSSet, WordSet};
use crate::{
    Token,
    linting::{ExprLinter, Lint, LintKind, Suggestion},
};

pub struct SafeToSave {
    expr: Box<dyn Expr>,
}

impl Default for SafeToSave {
    fn default() -> Self {
        let with_adv = SequenceExpr::default()
            .then(ModalVerb::default())
            .then_whitespace()
            .then(UPOSSet::new(&[UPOS::ADV]))
            .then_whitespace()
            .t_aco("safe")
            .then_whitespace()
            .then_unless(WordSet::new(&["to"]));

        let without_adv = SequenceExpr::default()
            .then(ModalVerb::default())
            .then_whitespace()
            .t_aco("safe")
            .then_whitespace()
            .then_unless(WordSet::new(&["to"]));

        let pattern = with_adv.or_longest(without_adv);

        Self {
            expr: Box::new(pattern),
        }
    }
}

impl ExprLinter for SafeToSave {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, toks: &[Token], src: &[char]) -> Option<Lint> {
        let safe_idx = toks
            .iter()
            .position(|t| t.span.get_content_string(src).to_lowercase() == "safe")?;

        let safe_tok = &toks[safe_idx];

        Some(Lint {
            span: safe_tok.span,
            lint_kind: LintKind::WordChoice,
            suggestions: vec![Suggestion::ReplaceWith("save".chars().collect())],
            message: "The word `safe` is an adjective. Did you mean the verb `save`?".to_string(),
            priority: 57,
        })
    }

    fn description(&self) -> &str {
        "Detects `safe` (adjective) when `save` (verb) is intended after modal verbs like `could` or `should`."
    }
}

#[cfg(test)]
mod tests {
    use super::SafeToSave;
    use crate::linting::tests::{assert_no_lints, assert_suggestion_result};

    #[test]
    fn corrects_could_safe() {
        assert_suggestion_result(
            "He could safe my life.",
            SafeToSave::default(),
            "He could save my life.",
        );
    }

    #[test]
    fn corrects_should_safe() {
        assert_suggestion_result(
            "You should safe your work frequently.",
            SafeToSave::default(),
            "You should save your work frequently.",
        );
    }

    #[test]
    fn corrects_will_safe() {
        assert_suggestion_result(
            "This will safe you time.",
            SafeToSave::default(),
            "This will save you time.",
        );
    }

    #[test]
    fn corrects_would_safe() {
        assert_suggestion_result(
            "It would safe us money.",
            SafeToSave::default(),
            "It would save us money.",
        );
    }

    #[test]
    fn corrects_can_safe() {
        assert_suggestion_result(
            "You can safe the document now.",
            SafeToSave::default(),
            "You can save the document now.",
        );
    }

    #[test]
    fn corrects_might_safe() {
        assert_suggestion_result(
            "This might safe the company.",
            SafeToSave::default(),
            "This might save the company.",
        );
    }

    #[test]
    fn corrects_must_safe() {
        assert_suggestion_result(
            "We must safe our resources.",
            SafeToSave::default(),
            "We must save our resources.",
        );
    }

    #[test]
    fn corrects_may_safe() {
        assert_suggestion_result(
            "You may safe your progress here.",
            SafeToSave::default(),
            "You may save your progress here.",
        );
    }

    #[test]
    fn corrects_with_adverb() {
        assert_suggestion_result(
            "You should definitely safe your changes.",
            SafeToSave::default(),
            "You should definitely save your changes.",
        );
    }

    #[test]
    fn corrects_shall_safe() {
        assert_suggestion_result(
            "We shall safe the nation.",
            SafeToSave::default(),
            "We shall save the nation.",
        );
    }

    #[test]
    fn corrects_couldnt_safe() {
        assert_suggestion_result(
            "I couldn't safe the file.",
            SafeToSave::default(),
            "I couldn't save the file.",
        );
    }

    #[test]
    fn allows_safe_to_verb() {
        assert_no_lints("It is safe to assume.", SafeToSave::default());
    }

    #[test]
    fn allows_safe_noun() {
        assert_no_lints("Put the money in the safe today.", SafeToSave::default());
    }

    #[test]
    fn allows_correct_save() {
        assert_no_lints("You should save your work.", SafeToSave::default());
    }
}



================================================
FILE: harper-core/src/linting/save_to_safe.rs
================================================
use crate::expr::Expr;
use crate::expr::OwnedExprExt;
use crate::expr::SequenceExpr;
use crate::linting::expr_linter::Chunk;
use crate::{
    Token,
    linting::{ExprLinter, Lint, LintKind, Suggestion},
    patterns::{InflectionOfBe, Word},
};

pub struct SaveToSafe {
    expr: Box<dyn Expr>,
}

impl Default for SaveToSafe {
    fn default() -> Self {
        let pattern = SequenceExpr::default()
            .then(InflectionOfBe::new().or(Word::new("it")))
            .then_whitespace()
            .t_aco("save")
            .then_whitespace()
            .t_aco("to")
            .then_whitespace()
            .then_verb();
        Self {
            expr: Box::new(pattern),
        }
    }
}

impl ExprLinter for SaveToSafe {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, toks: &[Token], src: &[char]) -> Option<Lint> {
        let save_tok = &toks.get(2)?;
        let verb_tok = &toks.get(4)?;
        let verb = verb_tok.span.get_content_string(src).to_lowercase();
        Some(Lint {
            span: save_tok.span,
            lint_kind: LintKind::WordChoice,
            suggestions: vec![Suggestion::ReplaceWith("safe".chars().collect())],
            message: format!("Did you mean `safe to {verb}`?"),
            priority: 57,
        })
    }

    fn description(&self) -> &str {
        "Corrects `save to <verb>` to `safe to <verb>` after a form of `be`."
    }
}

#[cfg(test)]
mod tests {
    use super::SaveToSafe;
    use crate::linting::tests::{assert_lint_count, assert_suggestion_result};

    #[test]
    fn fix_ignore() {
        assert_suggestion_result(
            "It is save to ignore trivial code.",
            SaveToSafe::default(),
            "It is safe to ignore trivial code.",
        );
    }

    #[test]
    fn fix_travel() {
        assert_suggestion_result(
            "Is it save to travel abroad now?",
            SaveToSafe::default(),
            "Is it safe to travel abroad now?",
        );
    }

    #[test]
    fn ignore_correct() {
        assert_lint_count("It is safe to assume nothing.", SaveToSafe::default(), 0);
    }
}



================================================
FILE: harper-core/src/linting/semicolon_apostrophe.rs
================================================
use crate::linting::expr_linter::Chunk;
use crate::{
    Token, TokenStringExt,
    expr::{Expr, SequenceExpr},
    linting::{ExprLinter, Lint, LintKind, Suggestion},
    patterns::WordSet,
};

const CONTRACTION_AND_POSSESSIVE_ENDINGS: [&str; 7] = ["d", "ll", "m", "re", "s", "t", "ve"];

pub struct SemicolonApostrophe {
    expr: Box<dyn Expr>,
}

impl Default for SemicolonApostrophe {
    fn default() -> Self {
        Self {
            expr: Box::new(
                SequenceExpr::default()
                    .then_any_word()
                    .then_semicolon()
                    .then(WordSet::new(&CONTRACTION_AND_POSSESSIVE_ENDINGS)),
            ),
        }
    }
}

impl ExprLinter for SemicolonApostrophe {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, toks: &[Token], src: &[char]) -> Option<Lint> {
        let whole_span = toks.span()?;
        let base = &toks.first()?;
        let ending = &toks.last()?;

        let replacement_str = format!(
            "{}'{}",
            base.span.get_content_string(src).to_lowercase(),
            ending.span.get_content_string(src).to_lowercase()
        );

        let mut lettercase_template = base.span.get_content(src).to_vec();
        lettercase_template.extend_from_slice(ending.span.get_content(src));

        Some(Lint {
            span: whole_span,
            lint_kind: LintKind::Typo,
            suggestions: vec![Suggestion::replace_with_match_case(
                replacement_str.chars().collect(),
                &lettercase_template,
            )],
            message: format!("Did you mean `{replacement_str}`?"),
            priority: 57,
        })
    }

    fn description(&self) -> &str {
        "Corrects semicolons accidentally typed instead of apostrophes."
    }
}

#[cfg(test)]
mod tests {
    use super::SemicolonApostrophe;
    use crate::linting::tests::{assert_lint_count, assert_suggestion_result};

    #[test]
    fn fix_dont_with_semicolon_to_apostrophe() {
        assert_suggestion_result(
            "It's better if you don;t type like this.",
            SemicolonApostrophe::default(),
            "It's better if you don't type like this.",
        );
    }

    #[test]
    fn ignore_correct() {
        assert_lint_count("I don't doubt it.", SemicolonApostrophe::default(), 0);
    }

    #[test]
    fn fix_title_case() {
        assert_suggestion_result(
            "Don;t type like this.",
            SemicolonApostrophe::default(),
            "Don't type like this.",
        );
    }

    #[test]
    fn fix_all_caps() {
        assert_suggestion_result(
            "DON;T TRY THIS AT HOME.",
            SemicolonApostrophe::default(),
            "DON'T TRY THIS AT HOME.",
        );
    }

    #[test]
    #[ignore = "replace_with_match_case has a bug turning `I'll` into `I'LL`"]
    fn fix_ill_and_monkeys() {
        assert_suggestion_result(
            "Well I;ll be a monkey;s uncle!",
            SemicolonApostrophe::default(),
            "Well I'll be a monkey's uncle!",
        )
    }

    #[test]
    fn fix_other_contractions_and_possessives() {
        assert_suggestion_result(
            "Let;s see if we;ve fixed patrakov;s bug. Fun wasn;t it?",
            SemicolonApostrophe::default(),
            "Let's see if we've fixed patrakov's bug. Fun wasn't it?",
        )
    }

    #[test]
    fn corrects_ive_with_correct_capitalization() {
        assert_suggestion_result("I;ve", SemicolonApostrophe::default(), "I've");
    }
}



================================================
FILE: harper-core/src/linting/sentence_capitalization.rs
================================================
use super::Suggestion;
use super::{Lint, LintKind, Linter};
use crate::document::Document;
use crate::spell::Dictionary;
use crate::{Token, TokenKind, TokenStringExt};

pub struct SentenceCapitalization<T>
where
    T: Dictionary,
{
    dictionary: T,
}

impl<T: Dictionary> SentenceCapitalization<T> {
    pub fn new(dictionary: T) -> Self {
        Self { dictionary }
    }
}

impl<T: Dictionary> Linter for SentenceCapitalization<T> {
    /// A linter that checks to make sure the first word of each sentence is
    /// capitalized.
    fn lint(&mut self, document: &Document) -> Vec<Lint> {
        let mut lints = Vec::new();

        for paragraph in document.iter_paragraphs() {
            // Allows short, label-like comments in code.
            if paragraph.iter_sentences().count() == 1 {
                let only_sentence = paragraph.iter_sentences().next().unwrap();

                if !only_sentence
                    .iter_chunks()
                    .map(|c| c.iter_words().count())
                    .any(|c| c > 5)
                {
                    continue;
                }
            }

            for sentence in paragraph.iter_sentences() {
                if !is_full_sentence(sentence) {
                    continue;
                }

                if let Some(first_word) = sentence.first_non_whitespace() {
                    if !first_word.kind.is_word() {
                        continue;
                    }

                    let word_chars = document.get_span_content(&first_word.span);

                    if let Some(first_char) = word_chars.first()
                        && first_char.is_alphabetic()
                        && !first_char.is_uppercase()
                    {
                        if let Some(canonical_spelling) =
                            self.dictionary.get_correct_capitalization_of(word_chars)
                        {
                            // Skip if it's a proper noun or contains uppercase letters before a separator
                            if first_word.kind.is_proper_noun() {
                                continue;
                            }

                            // Check for uppercase letters in the rest of the word before any separators
                            if canonical_spelling
                                .iter()
                                .skip(1)
                                .take_while(|&c| !c.is_whitespace() && *c != '-' && *c != '\'')
                                .any(|&c| c.is_uppercase())
                            {
                                continue;
                            }
                        }

                        let target_span = first_word.span;
                        let mut replacement_chars =
                            document.get_span_content(&target_span).to_vec();
                        replacement_chars[0] = replacement_chars[0].to_ascii_uppercase();

                        lints.push(Lint {
                            span: target_span,
                            lint_kind: LintKind::Capitalization,
                            suggestions: vec![Suggestion::ReplaceWith(replacement_chars)],
                            priority: 31,
                            message: "This sentence does not start with a capital letter"
                                .to_string(),
                        });
                    }
                }
            }
        }

        lints
    }

    fn description(&self) -> &'static str {
        "The opening word of a sentence should almost always be capitalized."
    }
}

fn is_full_sentence(toks: &[Token]) -> bool {
    let mut has_nominal = false;
    let mut has_verb = false;

    for tok in toks {
        if let TokenKind::Word(Some(metadata)) = &tok.kind {
            if metadata.is_nominal() {
                has_nominal = true;
            }

            if metadata.is_verb() {
                has_verb = true;
            }
        }
    }

    has_nominal && has_verb
}

#[cfg(test)]
mod tests {
    use super::super::tests::assert_lint_count;
    use super::SentenceCapitalization;
    use crate::spell::FstDictionary;

    #[test]
    fn catches_basic() {
        assert_lint_count(
            "there is no way she is not guilty.",
            SentenceCapitalization::new(FstDictionary::curated()),
            1,
        )
    }

    #[test]
    fn no_period() {
        assert_lint_count(
            "there is no way she is not guilty",
            SentenceCapitalization::new(FstDictionary::curated()),
            1,
        )
    }

    #[test]
    fn two_sentence() {
        assert_lint_count(
            "i have complete conviction in this. she is absolutely guilty",
            SentenceCapitalization::new(FstDictionary::curated()),
            2,
        )
    }

    #[test]
    fn start_with_number() {
        assert_lint_count(
            "53 is the length of the longest word.",
            SentenceCapitalization::new(FstDictionary::curated()),
            0,
        );
    }

    #[test]
    fn ignores_unlintable() {
        assert_lint_count(
            "[`misspelled_word`] is assumed to be quite small (n < 100). ",
            SentenceCapitalization::new(FstDictionary::curated()),
            0,
        )
    }

    #[test]
    fn unfazed_unlintable() {
        assert_lint_count(
            "the linter should not be affected by `this` unlintable.",
            SentenceCapitalization::new(FstDictionary::curated()),
            1,
        )
    }

    #[test]
    fn unfazed_ellipsis() {
        assert_lint_count(
            "the linter should not be affected by... that ellipsis.",
            SentenceCapitalization::new(FstDictionary::curated()),
            1,
        )
    }

    #[test]
    fn unfazed_comma() {
        assert_lint_count(
            "the linter should not be affected by, that comma.",
            SentenceCapitalization::new(FstDictionary::curated()),
            1,
        )
    }

    #[test]
    fn issue_228_allows_labels() {
        assert_lint_count(
            "python lsp (fork of pyright)",
            SentenceCapitalization::new(FstDictionary::curated()),
            0,
        )
    }

    #[test]
    fn allow_camel_case_trademarks() {
        // Some words are marked as proper nouns in `dictionary.dict` but are lower camel case.
        assert_lint_count(
            "macOS 16 could be called something like Redwood or Shasta",
            SentenceCapitalization::new(FstDictionary::curated()),
            0,
        )
    }

    #[test]
    #[ignore = "This can't work because currently hyphens are not included in tokenized words\nalthough they are now permitted in `dictionary.dict`"]
    fn uppercase_unamerican_at_start() {
        assert_lint_count(
            "un-American starts with a lowercase letter and contains an uppercase letter, but is not a proper noun or trademark.",
            SentenceCapitalization::new(FstDictionary::curated()),
            1,
        )
    }

    #[test]
    fn allow_lowercase_proper_nouns() {
        // A very few words are marked as proper nouns even though they're all lowercase.
        // https://css-tricks.com/start-sentence-npm/
        assert_lint_count(
            concat!(
                "npm is the world's largest software registry. Open source developers from every ",
                "continent use npm to share and borrow packages, and many organizations use npm to ",
                "manage private development as well."
            ),
            SentenceCapitalization::new(FstDictionary::curated()),
            0,
        )
    }

    #[test]
    fn allow_lower_camel_case_non_proper_nouns() {
        // A very few words are not considered proper nouns but still start with a lowercase letter that shouldn't be uppercased at the start of a sentence.
        assert_lint_count(
            "mRNA is synthesized from the coding sequence of a gene during the transcriptional process.",
            SentenceCapitalization::new(FstDictionary::curated()),
            0,
        )
    }
}



================================================
FILE: harper-core/src/linting/shoot_oneself_in_the_foot.rs
================================================
use crate::{
    CharStringExt, Span, Token,
    expr::{Expr, ReflexivePronoun, SequenceExpr},
    linting::Suggestion,
    patterns::WordSet,
};

use super::{ExprLinter, Lint, LintKind};
use crate::linting::expr_linter::Chunk;

pub struct ShootOneselfInTheFoot {
    pattern: Box<dyn Expr>,
}

impl Default for ShootOneselfInTheFoot {
    fn default() -> Self {
        let verb_forms = WordSet::new(&["shoot", "shooting", "shoots", "shot", "shooted"]);

        let body_parts = WordSet::new(&["foot", "feet", "leg", "legs"]);

        let pattern = SequenceExpr::default()
            .then(verb_forms)
            .t_ws()
            .then(ReflexivePronoun::default())
            .t_ws()
            .then_preposition()
            .t_ws()
            .then_determiner()
            .t_ws()
            .then(body_parts);
        Self {
            pattern: Box::new(pattern),
        }
    }
}

impl ExprLinter for ShootOneselfInTheFoot {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.pattern.as_ref()
    }

    fn match_to_lint(&self, toks: &[Token], src: &[char]) -> Option<Lint> {
        let pron = &toks.get(2)?.span.get_content(src);
        let prep = &toks.get(4)?.span.get_content(src);
        let det = &toks.get(6)?.span.get_content(src);
        let body_part = &toks.get(8)?.span.get_content(src);

        let plural_pron = pron.ends_with_ignore_ascii_case_str("elves");
        let plural_foot = toks.get(8)?.kind.is_plural_noun();

        let is_in = prep.eq_ignore_ascii_case_str("in");
        let is_the = det.eq_ignore_ascii_case_str("the");
        let is_foot = body_part.eq_ignore_ascii_case_str("foot");

        let foot_ok = is_foot || (plural_pron && plural_foot);

        if is_in && is_the && foot_ok {
            return None;
        }

        let in_the_foot = Span::new(toks.get(4)?.span.start, toks.get(8)?.span.end);

        let mut suggestions = vec![Suggestion::replace_with_match_case_str(
            "in the foot",
            in_the_foot.get_content(src),
        )];

        if plural_pron {
            suggestions.push(Suggestion::replace_with_match_case_str(
                "in the feet",
                in_the_foot.get_content(src),
            ));
        }

        Some(Lint {
            span: in_the_foot,
            lint_kind: LintKind::Miscellaneous,
            suggestions,
            message: "The standard idiom is 'shoot oneself in the foot'.".to_string(),
            priority: 50,
        })
    }

    fn description(&self) -> &str {
        "Corrects nonstandard variants of 'shoot oneself in the foot'."
    }
}

#[cfg(test)]
mod tests {
    use super::ShootOneselfInTheFoot;
    use crate::linting::tests::{assert_lint_count, assert_suggestion_result};

    #[test]
    fn ignore_correct() {
        assert_lint_count(
            "Don't shoot yourself in the foot.",
            ShootOneselfInTheFoot::default(),
            0,
        );
    }

    #[test]
    fn ignore_title_case() {
        assert_lint_count(
            "Don't Shoot Yourself In The Foot.",
            ShootOneselfInTheFoot::default(),
            0,
        );
    }

    #[test]
    fn ignore_all_caps() {
        assert_lint_count(
            "DON'T SHOOT YOURSELF IN THE FOOT.",
            ShootOneselfInTheFoot::default(),
            0,
        );
    }

    #[test]
    fn fix_shoot_leg() {
        assert_suggestion_result(
            "I managed to shoot myself in the leg when using CF Workers deployment",
            ShootOneselfInTheFoot::default(),
            "I managed to shoot myself in the foot when using CF Workers deployment",
        );
    }

    #[test]
    fn fix_shoot_into_foot() {
        assert_suggestion_result(
            "Or should we keep them to prevent users from shooting themselves into the foot?",
            ShootOneselfInTheFoot::default(),
            "Or should we keep them to prevent users from shooting themselves in the foot?",
        );
    }

    #[test]
    fn fix_shoot_into_feet() {
        assert_suggestion_result(
            "(to prevent you from shooting yourself into the feet)",
            ShootOneselfInTheFoot::default(),
            "(to prevent you from shooting yourself in the foot)",
        );
    }

    #[test]
    fn ignore_themselves_foot() {
        assert_lint_count(
            "Thou shalt not make a rule that prevents C++ programmers from shooting themselves in the foot.",
            ShootOneselfInTheFoot::default(),
            0,
        );
    }

    #[test]
    fn ignore_ourselves_feet() {
        assert_lint_count(
            "It will help avoiding shooting ourselves in the feet.",
            ShootOneselfInTheFoot::default(),
            0,
        );
    }

    #[test]
    fn fix_a_foot() {
        assert_suggestion_result(
            "Shot ourselves in a foot, \"Wrong X-Request-Key\" error #589.",
            ShootOneselfInTheFoot::default(),
            "Shot ourselves in the foot, \"Wrong X-Request-Key\" error #589.",
        );
    }

    #[test]
    fn ignore_shoots_himself() {
        assert_suggestion_result(
            "the administrator shoots himself in the foot and then hops around",
            ShootOneselfInTheFoot::default(),
            "the administrator shoots himself in the foot and then hops around",
        );
    }

    #[test]
    fn ignore_shooting_oneself_in_the_foot() {
        assert_lint_count(
            "A historical document of shooting oneself in the foot, if you will.",
            ShootOneselfInTheFoot::default(),
            0,
        );
    }

    #[test]
    fn fix_oneself_in_a_foot() {
        assert_suggestion_result(
            "Forgetting to declare some variable local withing a function definition is a common way to shoot oneself in a foot",
            ShootOneselfInTheFoot::default(),
            "Forgetting to declare some variable local withing a function definition is a common way to shoot oneself in the foot",
        );
    }

    #[test]
    fn fix_oneself_in_the_feet() {
        assert_suggestion_result(
            "Forgetting to declare some variable local withing a function definition is a common way to shoot oneself in the feet",
            ShootOneselfInTheFoot::default(),
            "Forgetting to declare some variable local withing a function definition is a common way to shoot oneself in the foot",
        );
    }

    #[test]
    fn fix_oneself_into_the_leg() {
        assert_suggestion_result(
            "Forgetting to declare some variable local withing a function definition is a common way to shoot oneself into the foot",
            ShootOneselfInTheFoot::default(),
            "Forgetting to declare some variable local withing a function definition is a common way to shoot oneself in the foot",
        );
    }

    #[test]
    fn ignore_oneself_in_the_toes() {
        assert_lint_count(
            "Forgetting to declare some variable local withing a function definition is a common way to shoot oneself in the toes",
            ShootOneselfInTheFoot::default(),
            0,
        );
    }
}



================================================
FILE: harper-core/src/linting/simple_past_to_past_participle.rs
================================================
use crate::linting::expr_linter::Chunk;
use crate::{
    Token,
    expr::{All, Expr, FirstMatchOf, SequenceExpr},
    irregular_verbs::IrregularVerbs,
    linting::{ExprLinter, Lint, LintKind, Suggestion},
    patterns::{InflectionOfBe, WordSet},
};

/// Corrects simple past tense verbs to past participle after auxiliary verbs like "have" or "be".
pub struct SimplePastToPastParticiple {
    expr: Box<dyn Expr>,
}

impl Default for SimplePastToPastParticiple {
    fn default() -> Self {
        Self {
            expr: Box::new(All::new(vec![
                // positive: the general case
                Box::new(
                    SequenceExpr::default()
                        .then_any_of(vec![
                            // for perfect tenses
                            Box::new(WordSet::new(&["have", "had", "has", "having"])),
                            // for passive voice
                            Box::new(InflectionOfBe::default()),
                            // pronoun + have contractions
                            Box::new(WordSet::new(&[
                                "I've", "I'd", "we've", "we'd", "you've", "you'd", "he's", "he'd",
                                "she's", "she'd", "it's", "it'd", "they've", "they'd",
                            ])),
                            // pronoun + have contractions missing apostrophes
                            Box::new(WordSet::new(&[
                                "Ive", "Id", "weve", "wed", "youve", "youd", "hes", "hed", "shes",
                                "shed", "its", "itd", "theyve", "theyd",
                            ])),
                        ])
                        .t_ws()
                        .then_verb_simple_past_form(),
                ),
                // negative: exceptions
                Box::new(SequenceExpr::default().then_unless(FirstMatchOf::new(vec![
                        Box::new(
                            SequenceExpr::default()
                                .then(InflectionOfBe::default())
                                .t_any()
                                .t_aco("woke"),
                        ),
                        Box::new(
                            SequenceExpr::aco("id")
                                .t_any()
                                .then_word_set(&["came", "did", "went"]),
                        ),
                    ]))),
            ])),
        }
    }
}

impl ExprLinter for SimplePastToPastParticiple {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, toks: &[Token], src: &[char]) -> Option<Lint> {
        if toks.len() != 3 || !toks[1].kind.is_whitespace() || !toks[2].kind.is_verb() {
            return None;
        }

        let verb_tok = &toks[2];

        let simple_past = verb_tok.span.get_content_string(src);

        if let Some(past_participle) = IrregularVerbs::curated()
            .get_past_participle_for_preterite(&simple_past)
            .filter(|pp| pp != &simple_past)
        {
            let suggestions = vec![Suggestion::replace_with_match_case(
                past_participle.chars().collect(),
                verb_tok.span.get_content(src),
            )];

            let message = format!(
                "Use the past participle `{}` instead of `{}` when using compound tenses or passive voice.",
                past_participle, simple_past
            );

            Some(Lint {
                span: verb_tok.span,
                lint_kind: LintKind::Grammar,
                suggestions,
                message,
                ..Default::default()
            })
        } else {
            None
        }
    }

    fn description(&self) -> &str {
        "Corrects simple past tense verbs to past participle after auxiliary verbs like \"have\" or \"be\"."
    }
}

#[cfg(test)]
mod tests {
    use super::SimplePastToPastParticiple;
    use crate::linting::tests::{
        assert_no_lints, assert_suggestion_result, assert_top3_suggestion_result,
    };

    // "Be" and "have"

    #[test]
    fn correct_have_went() {
        assert_suggestion_result(
            "I have went into the btle.py file and added a print statement in _connect()",
            SimplePastToPastParticiple::default(),
            "I have gone into the btle.py file and added a print statement in _connect()",
        );
    }

    #[test]
    fn correct_had_went() {
        assert_top3_suggestion_result(
            "Not sure if TroLoos had went from Tasmota->minimal->Tasmota, or directly Minimal->Tasmota, but going ESPHome->Minimal->Tasmota is not possible",
            SimplePastToPastParticiple::default(),
            "Not sure if TroLoos had gone from Tasmota->minimal->Tasmota, or directly Minimal->Tasmota, but going ESPHome->Minimal->Tasmota is not possible",
        );
    }

    #[test]
    fn correct_having_went() {
        assert_suggestion_result(
            "Having went through the setup guidelines and picking react starter, running npm run watch results in an error",
            SimplePastToPastParticiple::default(),
            "Having gone through the setup guidelines and picking react starter, running npm run watch results in an error",
        );
    }

    #[test]
    fn correct_has_went() {
        assert_suggestion_result(
            "I would like to report that the package request which you are loading has went into maintenance mode.",
            SimplePastToPastParticiple::default(),
            "I would like to report that the package request which you are loading has gone into maintenance mode.",
        );
    }

    #[test]
    fn correct_have_wrote() {
        assert_suggestion_result(
            "and while people have wrote partial ImGuiStyle save and ...",
            SimplePastToPastParticiple::default(),
            "and while people have written partial ImGuiStyle save and ...",
        );
    }

    #[test]
    fn correct_has_came() {
        assert_suggestion_result(
            "and mail has came to a work account",
            SimplePastToPastParticiple::default(),
            "and mail has come to a work account",
        );
    }

    #[test]
    fn correct_have_took() {
        assert_suggestion_result(
            "The Keychain took longer than I'd like it to have took, but it still works",
            SimplePastToPastParticiple::default(),
            "The Keychain took longer than I'd like it to have taken, but it still works",
        );
    }

    #[test]
    fn correct_have_did() {
        assert_suggestion_result(
            "so I have did like below: cd ~/.pub-cache/hosted/pub.dev/",
            SimplePastToPastParticiple::default(),
            "so I have done like below: cd ~/.pub-cache/hosted/pub.dev/",
        );
    }

    #[test]
    fn correct_has_fell() {
        assert_suggestion_result(
            "ScopedHistory instance has fell out of scope ...",
            SimplePastToPastParticiple::default(),
            "ScopedHistory instance has fallen out of scope ...",
        );
    }

    #[test]
    fn correct_have_broke() {
        assert_suggestion_result(
            "PlanningEnitity to see the hard constraints that it may have broke",
            SimplePastToPastParticiple::default(),
            "PlanningEnitity to see the hard constraints that it may have broken",
        );
    }

    #[test]
    fn correct_had_began() {
        assert_top3_suggestion_result(
            "I had began learning Android App development since Aug 2021",
            SimplePastToPastParticiple::default(),
            "I had begun learning Android App development since Aug 2021",
        );
    }

    #[test]
    fn correct_have_gave() {
        assert_suggestion_result(
            "I'm not aware we have gave up SM75, why are you asking this?",
            SimplePastToPastParticiple::default(),
            "I'm not aware we have given up SM75, why are you asking this?",
        );
    }

    #[test]
    fn correct_have_saw() {
        assert_top3_suggestion_result(
            "I have saw that your paper has been accepted by JAIR",
            SimplePastToPastParticiple::default(),
            "I have seen that your paper has been accepted by JAIR",
        );
    }

    #[test]
    fn correct_have_spoke() {
        assert_suggestion_result(
            "so i may have spoke in error",
            SimplePastToPastParticiple::default(),
            "so i may have spoken in error",
        );
    }

    #[test]
    fn correct_has_became() {
        assert_suggestion_result(
            "but it has became failed after v2.6.1",
            SimplePastToPastParticiple::default(),
            "but it has become failed after v2.6.1",
        );
    }

    #[test]
    fn correct_have_knew() {
        assert_suggestion_result(
            "Oh, I have knew this. You can decrypted it in \"Assetstudio\".",
            SimplePastToPastParticiple::default(),
            "Oh, I have known this. You can decrypted it in \"Assetstudio\".",
        );
    }

    #[test]
    fn correct_have_drank() {
        assert_suggestion_result(
            "User should be able to see approximately how much water they have drank today",
            SimplePastToPastParticiple::default(),
            "User should be able to see approximately how much water they have drunk today",
        );
    }

    #[test]
    #[ignore = "'Woke' is also an adjective these days"]
    fn being_woke() {
        assert_suggestion_result(
            "and the containers will not being woke up until I execute a \"docker ps\"",
            SimplePastToPastParticiple::default(),
            "and the containers will not being woken up until I execute a \"docker ps\"",
        );
    }

    #[test]
    fn correct_has_flew() {
        assert_suggestion_result(
            "Well time has flew and I was quite busy but I remember this conversation so I am sharing this with you.",
            SimplePastToPastParticiple::default(),
            "Well time has flown and I was quite busy but I remember this conversation so I am sharing this with you.",
        );
    }

    #[test]
    fn correct_being_stole() {
        assert_suggestion_result(
            "any requests to obtain the hostname will return the hostname of the container being stole",
            SimplePastToPastParticiple::default(),
            "any requests to obtain the hostname will return the hostname of the container being stolen",
        );
    }

    #[test]
    fn correct_are_broke() {
        assert_suggestion_result(
            "They all worked wonderfully under 3.4.2 and all are broke under 3.5.1.",
            SimplePastToPastParticiple::default(),
            "They all worked wonderfully under 3.4.2 and all are broken under 3.5.1.",
        );
    }

    #[test]
    fn correct_were_gave() {
        assert_suggestion_result(
            "Some devices were gave up during a storm recently, but some are still the same as before.",
            SimplePastToPastParticiple::default(),
            "Some devices were given up during a storm recently, but some are still the same as before.",
        );
    }

    #[test]
    fn correct_be_saw() {
        assert_suggestion_result(
            "Currently, it's 14560/14550 for default mavlink RX/TX, which can be saw in wfb-cli .",
            SimplePastToPastParticiple::default(),
            "Currently, it's 14560/14550 for default mavlink RX/TX, which can be seen in wfb-cli .",
        );
    }

    #[test]
    fn correct_was_began() {
        assert_suggestion_result(
            "The initial intent, when v1alpha3 was began, was that almost all usages of InitConfiguration outside of kubeadm init code, could be easily replaced",
            SimplePastToPastParticiple::default(),
            "The initial intent, when v1alpha3 was begun, was that almost all usages of InitConfiguration outside of kubeadm init code, could be easily replaced",
        );
    }

    #[test]
    fn correct_was_gave() {
        assert_suggestion_result(
            "you will find the config file path was gave by -c argument",
            SimplePastToPastParticiple::default(),
            "you will find the config file path was given by -c argument",
        );
    }

    #[test]
    fn correct_be_began() {
        assert_suggestion_result(
            "Ticket requires something from design before it can be began.",
            SimplePastToPastParticiple::default(),
            "Ticket requires something from design before it can be begun.",
        );
    }

    #[test]
    fn correct_being_took() {
        assert_suggestion_result(
            "Dunno, I saw some old threads about port not being took into account in asw-sdk library but seems fixed on aws side.",
            SimplePastToPastParticiple::default(),
            "Dunno, I saw some old threads about port not being taken into account in asw-sdk library but seems fixed on aws side.",
        );
    }

    #[test]
    fn correct_are_took() {
        assert_suggestion_result(
            "In the example provided, TP53 and LMNB1 genes are took as seeds.",
            SimplePastToPastParticiple::default(),
            "In the example provided, TP53 and LMNB1 genes are taken as seeds.",
        );
    }

    // Contractions

    #[test]
    fn correct_ive_went() {
        assert_suggestion_result(
            "I've went through some tutorials and went back and forth with AI translating programs from one language to the other.",
            SimplePastToPastParticiple::default(),
            "I've gone through some tutorials and went back and forth with AI translating programs from one language to the other.",
        );
    }

    #[test]
    fn correct_ive_went_no_apostrophe() {
        assert_suggestion_result(
            "I've went thru all the steps to help fix this Virus issue and im locked up.",
            SimplePastToPastParticiple::default(),
            "I've gone thru all the steps to help fix this Virus issue and im locked up.",
        );
    }

    #[test]
    fn correct_id_did() {
        assert_suggestion_result(
            "I'd did a calibration after the FW update now.",
            SimplePastToPastParticiple::default(),
            "I'd done a calibration after the FW update now.",
        );
    }

    #[test]
    fn correct_weve_went() {
        assert_suggestion_result(
            "Thanks for the feedback, but the issue is no longer relevant since we've went with different approach.",
            SimplePastToPastParticiple::default(),
            "Thanks for the feedback, but the issue is no longer relevant since we've gone with different approach.",
        );
    }

    #[test]
    fn correct_wed_chose() {
        assert_suggestion_result(
            "whatever number we'd chose, only one tab will be allowed to run",
            SimplePastToPastParticiple::default(),
            "whatever number we'd chosen, only one tab will be allowed to run",
        );
    }

    #[test]
    fn correct_youve_wrote() {
        assert_suggestion_result(
            "I love this project, it's impressing how many refactoring you've wrote in a limited amount of time.",
            SimplePastToPastParticiple::default(),
            "I love this project, it's impressing how many refactoring you've written in a limited amount of time.",
        );
    }

    #[test]
    fn correct_youve_ran_no_apostrophe() {
        assert_suggestion_result(
            "after youve ran it, execute the file_mover.ps1 using powershell",
            SimplePastToPastParticiple::default(),
            "after youve run it, execute the file_mover.ps1 using powershell",
        );
    }

    #[test]
    fn correct_youd_wrote() {
        assert_suggestion_result(
            "When I saw you'd wrote a terminal emulator I had to try it and so far it's amazing.",
            SimplePastToPastParticiple::default(),
            "When I saw you'd written a terminal emulator I had to try it and so far it's amazing.",
        );
    }

    #[test]
    fn correct_its_broke() {
        assert_suggestion_result(
            "Not sure why it's broke for me but not for you.",
            SimplePastToPastParticiple::default(),
            "Not sure why it's broken for me but not for you.",
        );
    }

    #[test]
    fn correct_its_broke_no_apostrophe() {
        assert_suggestion_result(
            "Now its broke and won't do batch images (decoding error).",
            SimplePastToPastParticiple::default(),
            "Now its broken and won't do batch images (decoding error).",
        );
    }

    #[test]
    fn correct_theyve_broke() {
        assert_suggestion_result(
            "They've broke something again :D.",
            SimplePastToPastParticiple::default(),
            "They've broken something again :D.",
        );
    }

    #[test]
    fn correct_theyd_forgot() {
        assert_suggestion_result(
            "they found the process they'd forgot they were running",
            SimplePastToPastParticiple::default(),
            "they found the process they'd forgotten they were running",
        );
    }

    // Known exceptions

    #[test]
    fn dont_flag_being_woke() {
        assert_no_lints(
            "Being woke to gender discrimination is difficult",
            SimplePastToPastParticiple::default(),
        );
    }

    #[test]
    fn dont_flag_be_woke() {
        assert_no_lints(
            "So You Want To Be Woke. The path to becoming woke is hard",
            SimplePastToPastParticiple::default(),
        );
    }

    #[test]
    fn dont_flag_id_did() {
        assert_no_lints(
            "Prop id did not match.",
            SimplePastToPastParticiple::default(),
        );
    }

    #[test]
    fn dont_flag_id_came() {
        assert_no_lints(
            "I'm a longtime user of UniFi and site ID came around after my account was established.",
            SimplePastToPastParticiple::default(),
        );
    }

    #[test]
    fn dont_flag_id_went() {
        assert_no_lints(
            "Could not determine debug ID went away after cleaning the dist/ before the build, so that's unrelated.",
            SimplePastToPastParticiple::default(),
        );
    }
}



================================================
FILE: harper-core/src/linting/since_duration.rs
================================================
use crate::expr::{DurationExpr, Expr, SequenceExpr};
use crate::{CharStringExt, Token, TokenStringExt};

use super::{ExprLinter, Lint, LintKind, Suggestion};
use crate::linting::expr_linter::Chunk;

const AGO_VARIANTS: [&[char]; 3] = [&['a', 'g', 'o'], &['A', 'g', 'o'], &['A', 'G', 'O']];
const FOR_VARIANTS: [&[char]; 3] = [&['f', 'o', 'r'], &['F', 'o', 'r'], &['F', 'O', 'R']];

fn match_case_string<'a>(template: &[char], variants: [&'a [char]; 3]) -> &'a [char] {
    let c1 = template.first().copied().unwrap();
    let c2 = template.get(1).copied().unwrap_or(' ');
    if c1.is_uppercase() && c2.is_uppercase() {
        variants[2]
    } else if c1.is_uppercase() {
        variants[1]
    } else {
        variants[0]
    }
}

pub struct SinceDuration {
    expr: Box<dyn Expr>,
}

impl Default for SinceDuration {
    fn default() -> Self {
        Self {
            expr: Box::new(
                SequenceExpr::default()
                    .then_any_capitalization_of("since")
                    .then_whitespace()
                    .then(DurationExpr)
                    .then_optional(
                        SequenceExpr::default()
                            .t_ws()
                            .then_word_set(&["ago", "old"]),
                    ),
            ),
        }
    }
}

impl ExprLinter for SinceDuration {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, toks: &[Token], src: &[char]) -> Option<Lint> {
        let last = toks.last()?;
        if last
            .span
            .get_content(src)
            .eq_any_ignore_ascii_case_chars(&[&['a', 'g', 'o'], &['o', 'l', 'd']])
        {
            return None;
        }

        let since_duration_span = toks.span()?;

        let mut since_point_in_time = since_duration_span.get_content(src).to_vec();
        since_point_in_time.push(' ');
        let unit_template = toks.last()?.span.get_content(src);
        since_point_in_time.extend(
            match_case_string(unit_template, AGO_VARIANTS)
                .iter()
                .copied(),
        );
        let ago_suggestion = Suggestion::ReplaceWith(since_point_in_time);

        let duration = toks[1..].span()?.get_content(src);
        let since_template = toks.first()?.span.get_content(src);
        let mut for_duration = match_case_string(since_template, FOR_VARIANTS).to_vec();
        for_duration.extend(duration);
        let for_suggestion = Suggestion::ReplaceWith(for_duration);

        Some(Lint {
            span: since_duration_span,
            lint_kind: LintKind::Miscellaneous,
            suggestions: vec![for_suggestion, ago_suggestion],
            message: "For a duration, use 'for' instead of 'since'. Or for a point in time, add 'ago' at the end.".to_string(),
            priority: 50,
        })
    }

    fn description(&self) -> &str {
        "Detects the use of 'since' with a duration instead of a point in time."
    }
}

#[cfg(test)]
mod tests {
    use super::SinceDuration;
    use crate::linting::tests::{
        assert_lint_count, assert_no_lints, assert_top3_suggestion_result,
    };

    #[test]
    fn catches_spelled() {
        assert_lint_count(
            "I have been waiting since two hours.",
            SinceDuration::default(),
            1,
        );
    }

    #[test]
    fn permits_spelled_with_ago() {
        assert_no_lints(
            "I have been waiting since two hours ago.",
            SinceDuration::default(),
        );
    }

    #[test]
    fn catches_numerals() {
        assert_lint_count(
            "I have been waiting since 2 hours.",
            SinceDuration::default(),
            1,
        );
    }

    #[test]
    fn permits_numerals_with_ago() {
        assert_no_lints(
            "I have been waiting since 2 hours ago.",
            SinceDuration::default(),
        );
    }

    #[test]
    fn correct_without_issues() {
        assert_top3_suggestion_result(
            "I'm running v2.2.1 on bare metal (no docker, vm) since two weeks without issues.",
            SinceDuration::default(),
            "I'm running v2.2.1 on bare metal (no docker, vm) for two weeks without issues.",
        );
    }

    #[test]
    fn correct_anything_back() {
        assert_top3_suggestion_result(
            "I have not heard anything back since three months.",
            SinceDuration::default(),
            "I have not heard anything back for three months.",
        );
    }

    #[test]
    fn correct_get_done() {
        assert_top3_suggestion_result(
            "I am trying to get this done since two days, someone please help.",
            SinceDuration::default(),
            "I am trying to get this done for two days, someone please help.",
        );
    }

    #[test]
    fn correct_deprecated() {
        assert_top3_suggestion_result(
            "This project is now officially deprecated, since I worked with virtualabs on the next version of Mirage since three years now: an ecosystem of tools named WHAD.",
            SinceDuration::default(),
            "This project is now officially deprecated, since I worked with virtualabs on the next version of Mirage for three years now: an ecosystem of tools named WHAD.",
        );
    }

    #[test]
    fn correct_same() {
        assert_top3_suggestion_result(
            "Same! Since two days.",
            SinceDuration::default(),
            "Same! For two days.",
        );
    }

    #[test]
    fn correct_what_changed() {
        assert_top3_suggestion_result(
            "What changed since two weeks?",
            SinceDuration::default(),
            "What changed since two weeks ago?",
        );
    }

    #[test]
    fn correct_with_period() {
        assert_top3_suggestion_result(
            "I have been waiting since two hours.",
            SinceDuration::default(),
            "I have been waiting since two hours ago.",
        );
    }

    #[test]
    fn correct_with_exclamation() {
        assert_top3_suggestion_result(
            "I have been waiting since two hours!",
            SinceDuration::default(),
            "I have been waiting since two hours ago!",
        );
    }

    #[test]
    fn correct_with_question_mark() {
        assert_top3_suggestion_result(
            "Have you been waiting since two hours?",
            SinceDuration::default(),
            "Have you been waiting for two hours?",
        );
    }

    #[test]
    fn correct_with_comma() {
        assert_top3_suggestion_result(
            "Since two days, I have been trying to get this done.",
            SinceDuration::default(),
            "For two days, I have been trying to get this done.",
        );
    }

    #[test]
    fn correct_for_title_case() {
        assert_top3_suggestion_result(
            "Since 45 Minutes I See The Following Picture In The Terminal.",
            SinceDuration::default(),
            "For 45 Minutes I See The Following Picture In The Terminal.",
        );
    }

    #[test]
    fn correct_for_all_caps() {
        assert_top3_suggestion_result(
            "STOPPED SINCE 12 HOURS WITH EXIT CODE 0",
            SinceDuration::default(),
            "STOPPED FOR 12 HOURS WITH EXIT CODE 0",
        );
    }

    #[test]
    fn correct_ago_title_case() {
        assert_top3_suggestion_result(
            "It Is In Development Since Two Years.",
            SinceDuration::default(),
            "It Is In Development Since Two Years Ago.",
        );
    }

    #[test]
    fn correct_ago_all_caps() {
        assert_top3_suggestion_result(
            "BUG: SINCE 6 MONTHS UNLOAD CHECKPOINT",
            SinceDuration::default(),
            "BUG: SINCE 6 MONTHS AGO UNLOAD CHECKPOINT",
        );
    }

    #[test]
    #[ignore = "We can't yet handle modifiers like 'over'. Plus it doesn't work with 'ago'."]
    fn not_yet_handled() {
        assert_top3_suggestion_result(
            "It's an asked feature since over 9 years",
            SinceDuration::default(),
            "It's an asked feature for over 9 years.",
        );
    }

    #[test]
    #[ignore = "We can't yet handle modifiers like 'more than'. Plus it doesn't work with 'ago'."]
    fn not_yet_handled_2() {
        assert_top3_suggestion_result(
            "It's an asked feature since more than 9 years",
            SinceDuration::default(),
            "It's an asked feature for more than 9 years.",
        );
    }

    #[test]
    #[ignore = "We can't yet handle indefinite numbers."]
    fn not_yet_handled_3() {
        assert_top3_suggestion_result(
            "I use a Wacom Cintiq 27QHDT since several years on Linux",
            SinceDuration::default(),
            "I use a Wacom Cintiq 27QHDT for several years on Linux",
        );
    }

    #[test]
    fn ignore_since_years_old() {
        assert_no_lints(
            "I've been coding since 11 years old and I'm now 57",
            SinceDuration::default(),
        );
    }
}



================================================
FILE: harper-core/src/linting/single_be.rs
================================================
use crate::dict_word_metadata::VerbFormFlags;
use crate::linting::expr_linter::Chunk;
use crate::{
    Span, Token,
    expr::{Expr, SequenceExpr},
    linting::{ExprLinter, Lint, LintKind, Suggestion},
    patterns::{DerivedFrom, InflectionOfBe},
};

fn be_forms(token: &Token) -> Option<VerbFormFlags> {
    let metadata = token
        .kind
        .as_word()
        .and_then(|metadata| metadata.as_ref())?;
    let verb_data = metadata.verb.as_ref()?;

    verb_data.verb_forms
}

fn is_past_flag(forms: VerbFormFlags) -> bool {
    forms.intersects(VerbFormFlags::PAST | VerbFormFlags::PRETERITE)
}

fn looks_like_be_contraction(token: &Token, source: &[char]) -> bool {
    let Some(_) = token.kind.as_word() else {
        return false;
    };

    if token.kind.is_possessive_nominal() && token.kind.is_proper_noun() {
        return false;
    }

    let content = token.span.get_content(source);
    let Some(apostrophe_idx) = content.iter().rposition(|c| matches!(*c, '\'' | '’')) else {
        return false;
    };
    let base_slice = &content[..apostrophe_idx];
    if token.kind.is_possessive_nominal() && token.kind.is_proper_noun() {
        return false;
    }
    if base_slice
        .first()
        .is_some_and(|c| c.is_uppercase() && token.kind.is_nominal() && !token.kind.is_pronoun())
    {
        return false;
    }
    let base: Vec<char> = base_slice.iter().map(|c| c.to_ascii_lowercase()).collect();
    if base == ['l', 'e', 't'] {
        return false;
    }
    let suffix: Vec<char> = content[apostrophe_idx + 1..]
        .iter()
        .map(|c| c.to_ascii_lowercase())
        .collect();

    matches!(suffix.as_slice(), ['s'] | ['r', 'e'] | ['m']) && apostrophe_idx > 0
}

pub struct SingleBe {
    expr: Box<dyn Expr>,
}

impl Default for SingleBe {
    fn default() -> Self {
        fn be_like_expr() -> SequenceExpr {
            SequenceExpr::any_of(vec![
                Box::new(InflectionOfBe::new()),
                Box::new(DerivedFrom::new_from_str("be")),
                Box::new(looks_like_be_contraction),
            ])
        }

        let expr = SequenceExpr::default()
            .then(be_like_expr())
            .t_ws()
            .then(be_like_expr());

        Self {
            expr: Box::new(expr),
        }
    }
}

impl ExprLinter for SingleBe {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], source: &[char]) -> Option<Lint> {
        let first = matched_tokens.first()?;
        let second = matched_tokens.last()?;

        if first.kind.is_possessive_nominal() && first.kind.is_proper_noun() {
            return None;
        }
        if first.kind.is_possessive_nominal()
            && first
                .span
                .get_content(source)
                .first()
                .is_some_and(|c| c.is_uppercase())
        {
            return None;
        }

        let progressive_like = |tok: &Token| {
            be_forms(tok).map_or_else(
                || false,
                |forms| {
                    forms.intersects(VerbFormFlags::PROGRESSIVE | VerbFormFlags::PAST_PARTICIPLE)
                },
            )
        };
        if progressive_like(first) || progressive_like(second) {
            return None;
        }

        let first_is_past = be_forms(first)
            .map(is_past_flag)
            .unwrap_or_else(|| first.kind.is_verb_past_form());
        let second_is_past = be_forms(second)
            .map(is_past_flag)
            .unwrap_or_else(|| second.kind.is_verb_past_form());

        let first_chars = first.span.get_content(source);
        let base_before_apostrophe = first_chars
            .iter()
            .rposition(|c| matches!(*c, '\'' | '’'))
            .map(|idx| &first_chars[..idx]);

        if let Some(base) = base_before_apostrophe {
            let base_first_upper = base.first().is_some_and(|c| c.is_uppercase());
            let base_lower: Vec<char> = base.iter().map(|c| c.to_ascii_lowercase()).collect();
            let is_common_pronoun = matches!(
                base_lower.as_slice(),
                ['i']
                    | ['w', 'e']
                    | ['t', 'h', 'e', 'y']
                    | ['y', 'o', 'u']
                    | ['h', 'e']
                    | ['s', 'h', 'e']
                    | ['i', 't']
                    | ['t', 'h', 'a', 't']
                    | ['t', 'h', 'e', 'r', 'e']
            );

            if base_first_upper && !first.kind.is_pronoun() && !is_common_pronoun {
                return None;
            }
        }

        if first_is_past && second_is_past {
            return None;
        }

        let whitespace_start = matched_tokens.get(1)?.span.start;
        let second_be_end = second.span.end;

        Some(Lint {
            span: Span::new(whitespace_start, second_be_end),
            lint_kind: LintKind::Grammar,
            suggestions: vec![Suggestion::ReplaceWith(vec![])],
            message: "Drop the repeated verb form so only one instance of `be` remains.".to_owned(),
            priority: 31,
        })
    }

    fn description(&self) -> &'static str {
        "Removes adjacent duplicate inflections of `be`, including contracted forms followed by another `be` verb."
    }
}

#[cfg(test)]
mod tests {
    use crate::linting::tests::{assert_no_lints, assert_suggestion_result};

    use super::SingleBe;

    #[test]
    fn removes_double_is() {
        assert_suggestion_result(
            "The server is is slow.",
            SingleBe::default(),
            "The server is slow.",
        );
    }

    #[test]
    fn removes_is_are() {
        assert_suggestion_result(
            "This is are unusual.",
            SingleBe::default(),
            "This is unusual.",
        );
    }

    #[test]
    fn removes_are_were_mismatch() {
        assert_suggestion_result(
            "They are were excited.",
            SingleBe::default(),
            "They are excited.",
        );
    }

    #[test]
    fn removes_mismatched_pair() {
        assert_suggestion_result("That is was odd.", SingleBe::default(), "That is odd.");
    }

    #[test]
    fn handles_s_contraction() {
        assert_suggestion_result(
            "The error's are gone.",
            SingleBe::default(),
            "The error's gone.",
        );
    }

    #[test]
    fn handles_re_contraction() {
        assert_suggestion_result(
            "We're are ready to ship.",
            SingleBe::default(),
            "We're ready to ship.",
        );
    }

    #[test]
    fn handles_m_contraction() {
        assert_suggestion_result("I'm am aware.", SingleBe::default(), "I'm aware.");
    }

    #[test]
    fn handles_future_repetition() {
        assert_suggestion_result(
            "That will be be an issue.",
            SingleBe::default(),
            "That will be an issue.",
        );
    }

    #[test]
    fn skips_being_chain() {
        assert_no_lints("It's been being rebuilt for months.", SingleBe::default());
    }

    #[test]
    fn allows_simple_be_statement() {
        assert_no_lints("Let's be honest.", SingleBe::default());
    }

    #[test]
    fn allows_possessive_before_are() {
        assert_no_lints(
            "Stories like Mateo's are the heart of what we do.",
            SingleBe::default(),
        );
    }

    #[test]
    fn removes_across_newline() {
        assert_suggestion_result(
            "That is\nis tricky.",
            SingleBe::default(),
            "That is tricky.",
        );
    }

    #[test]
    fn ignores_separated_forms() {
        assert_no_lints("The server is not is down.", SingleBe::default());
    }

    #[test]
    fn ignores_single_be() {
        assert_no_lints("This is ready.", SingleBe::default());
    }
}



================================================
FILE: harper-core/src/linting/some_without_article.rs
================================================
use crate::linting::expr_linter::Chunk;
use crate::{
    Token, TokenStringExt,
    expr::{Expr, SequenceExpr},
    linting::{ExprLinter, Lint, LintKind, Suggestion},
};

pub struct SomeWithoutArticle {
    expr: Box<dyn Expr>,
}

impl Default for SomeWithoutArticle {
    fn default() -> Self {
        let expr = SequenceExpr::default()
            .then_any_capitalization_of("the")
            .t_ws()
            .then_any_capitalization_of("some");

        Self {
            expr: Box::new(expr),
        }
    }
}

impl ExprLinter for SomeWithoutArticle {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], source: &[char]) -> Option<Lint> {
        let span = matched_tokens.span()?;
        let template = span.get_content(source);
        let some_chars = matched_tokens.last()?.span.get_content(source);

        let suggestions = vec![
            Suggestion::ReplaceWith(some_chars.to_vec()),
            Suggestion::replace_with_match_case("the same".chars().collect(), template),
        ];

        Some(Lint {
            span,
            lint_kind: LintKind::WordChoice,
            message:
                "Use `some` on its own here, or switch to `the same` if that was the intention."
                    .to_owned(),
            suggestions,
            ..Default::default()
        })
    }

    fn description(&self) -> &'static str {
        "Detects the redundant article in front of `some` and suggests more natural phrasing."
    }
}

#[cfg(test)]
mod tests {
    use crate::linting::tests::{
        assert_lint_count, assert_nth_suggestion_result, assert_suggestion_result,
    };

    use super::SomeWithoutArticle;

    #[test]
    fn fixes_simple_lowercase() {
        assert_suggestion_result(
            "We interviewed the some candidates today.",
            SomeWithoutArticle::default(),
            "We interviewed some candidates today.",
        );
    }

    #[test]
    fn fixes_sentence_case() {
        assert_suggestion_result(
            "The Some volunteers arrived early.",
            SomeWithoutArticle::default(),
            "Some volunteers arrived early.",
        );
    }

    #[test]
    fn preserves_uppercase_block() {
        assert_suggestion_result(
            "THE SOME OPTIONS WERE LISTED.",
            SomeWithoutArticle::default(),
            "SOME OPTIONS WERE LISTED.",
        );
    }

    #[test]
    fn second_suggestion_produces_the_same() {
        assert_nth_suggestion_result(
            "We kept the some approach from last year.",
            SomeWithoutArticle::default(),
            "We kept the same approach from last year.",
            1,
        );
    }

    #[test]
    fn ignores_already_correct_some() {
        assert_lint_count(
            "We interviewed some candidates today.",
            SomeWithoutArticle::default(),
            0,
        );
    }

    #[test]
    fn ignores_the_same() {
        assert_lint_count(
            "We kept the same approach from last year.",
            SomeWithoutArticle::default(),
            0,
        );
    }

    #[test]
    fn ignores_the_something() {
        assert_lint_count(
            "We interviewed the something else entirely.",
            SomeWithoutArticle::default(),
            0,
        );
    }

    #[test]
    fn works_before_comma() {
        assert_suggestion_result(
            "They reviewed the some, then finalized the list.",
            SomeWithoutArticle::default(),
            "They reviewed some, then finalized the list.",
        );
    }

    #[test]
    fn works_before_possessive_noun() {
        assert_suggestion_result(
            "The report praised the some team's effort.",
            SomeWithoutArticle::default(),
            "The report praised some team's effort.",
        );
    }

    #[test]
    fn handles_line_break_spacing() {
        assert_suggestion_result(
            "We invited the some\nartists to perform.",
            SomeWithoutArticle::default(),
            "We invited some\nartists to perform.",
        );
    }
}



================================================
FILE: harper-core/src/linting/something_is.rs
================================================
use crate::expr::{Expr, SequenceExpr};
use crate::patterns::WordSet;
use crate::{Token, TokenKind};

use super::{ExprLinter, Lint, LintKind, Suggestion};
use crate::linting::expr_linter::Chunk;

pub struct SomethingIs {
    expr: Box<dyn Expr>,
}

impl Default for SomethingIs {
    fn default() -> Self {
        let forms = WordSet::new(&["somethings", "anythings", "everythings", "nothings"]);

        let expr = SequenceExpr::default()
            .then(forms)
            .t_ws()
            .then_optional(SequenceExpr::default().then_one_or_more_adverbs().t_ws())
            .then_kind_any(&[TokenKind::is_verb_progressive_form]);

        Self {
            expr: Box::new(expr),
        }
    }
}

impl ExprLinter for SomethingIs {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], source: &[char]) -> Option<Lint> {
        let offender = matched_tokens.first()?;
        let original = offender.span.get_content(source);
        let stem_len = original.len().checked_sub(1)?;
        let stem = original[..stem_len].to_vec();

        let mut contraction = stem.clone();
        contraction.extend(['\'', 's']);

        let mut expanded = stem;
        expanded.push(' ');
        expanded.extend(['i', 's']);

        Some(Lint {
            span: offender.span,
            lint_kind: LintKind::WordChoice,
            suggestions: vec![
                Suggestion::replace_with_match_case(contraction, original),
                Suggestion::replace_with_match_case(expanded, original),
            ],
            message: "Prefer the contraction or full `is` rather than pluralizing this pronoun."
                .into(),
            priority: 31,
        })
    }

    fn description(&self) -> &str {
        "Flags forms like `somethings` before progressive verbs and suggests using `something's` or `something is`."
    }
}

#[cfg(test)]
mod tests {
    use super::SomethingIs;
    use crate::linting::tests::{
        assert_lint_count, assert_no_lints, assert_nth_suggestion_result, assert_suggestion_result,
    };

    #[test]
    fn fixes_somethings_going() {
        assert_suggestion_result(
            "Somethings going well today.",
            SomethingIs::default(),
            "Something's going well today.",
        );
    }

    #[test]
    fn fixes_anythings_happening() {
        assert_suggestion_result(
            "Anythings happening tonight?",
            SomethingIs::default(),
            "Anything's happening tonight?",
        );
    }

    #[test]
    fn fixes_everythings_working() {
        assert_suggestion_result(
            "Everythings working smoothly.",
            SomethingIs::default(),
            "Everything's working smoothly.",
        );
    }

    #[test]
    fn fixes_nothings_changing() {
        assert_suggestion_result(
            "Nothings changing around here.",
            SomethingIs::default(),
            "Nothing's changing around here.",
        );
    }

    #[test]
    fn fixes_with_adverb() {
        assert_suggestion_result(
            "Somethings really happening now.",
            SomethingIs::default(),
            "Something's really happening now.",
        );
    }

    #[test]
    fn fixes_uppercase() {
        assert_suggestion_result(
            "SOMETHINGS HAPPENING NOW!",
            SomethingIs::default(),
            "SOMETHING'S HAPPENING NOW!",
        );
    }

    #[test]
    fn offers_is_expansion() {
        assert_nth_suggestion_result(
            "Somethings going wrong.",
            SomethingIs::default(),
            "Something is going wrong.",
            1,
        );
    }

    #[test]
    fn no_lint_when_contracted() {
        assert_no_lints("Something's going well today.", SomethingIs::default());
    }

    #[test]
    fn no_lint_when_plural_noun() {
        assert_lint_count(
            "Somethings in the attic kept us awake.",
            SomethingIs::default(),
            0,
        );
    }

    #[test]
    fn no_lint_at_sentence_end() {
        assert_no_lints("Somethings.", SomethingIs::default());
    }
}



================================================
FILE: harper-core/src/linting/somewhat_something.rs
================================================
use crate::Token;
use crate::expr::{Expr, SequenceExpr};

use super::{ExprLinter, Lint, LintKind, Suggestion};
use crate::linting::expr_linter::Chunk;

pub struct SomewhatSomething {
    expr: Box<dyn Expr>,
}

impl Default for SomewhatSomething {
    fn default() -> Self {
        let pattern = SequenceExpr::aco("somewhat")
            .then_whitespace()
            .t_aco("of")
            .then_whitespace()
            .t_aco("a");

        Self {
            expr: Box::new(pattern),
        }
    }
}

impl ExprLinter for SomewhatSomething {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], source: &[char]) -> Option<Lint> {
        let span = matched_tokens.first()?.span;
        let og = span.get_content(source);

        Some(Lint {
            span,
            lint_kind: LintKind::Style,
            suggestions: vec![Suggestion::replace_with_match_case_str("something", og)],
            message: "Consider using `something of a` in more formal writing.".to_owned(),
            priority: 63,
        })
    }

    fn description(&self) -> &'static str {
        "Flags the phrase `somewhat of a` in favor of `something of a`, which can be considered more traditional."
    }
}

#[cfg(test)]
mod tests {
    use crate::linting::tests::assert_suggestion_result;

    use super::SomewhatSomething;

    #[test]
    fn issue_414() {
        assert_suggestion_result(
            "This may be somewhat of a surprise.",
            SomewhatSomething::default(),
            "This may be something of a surprise.",
        );
    }

    #[test]
    fn flag_these() {
        assert_suggestion_result(
            "These are somewhat of a cult data structure.",
            SomewhatSomething::default(),
            "These are something of a cult data structure.",
        );
    }
}



================================================
FILE: harper-core/src/linting/soon_to_be.rs
================================================
use std::{ops::Range, sync::Arc};

use crate::{
    Token, TokenKind, TokenStringExt,
    expr::{Expr, ExprMap, SequenceExpr},
    linting::expr_linter::Chunk,
    linting::{ExprLinter, Lint, LintKind, Suggestion},
    patterns::NominalPhrase,
};

pub struct SoonToBe {
    expr: Box<dyn Expr>,
    map: Arc<ExprMap<Range<usize>>>,
}

impl Default for SoonToBe {
    fn default() -> Self {
        let mut map = ExprMap::default();

        let soon_to_be = || {
            SequenceExpr::default()
                .t_aco("soon")
                .t_ws()
                .t_aco("to")
                .t_ws()
                .t_aco("be")
        };

        let nominal_tail = || {
            SequenceExpr::optional(SequenceExpr::default().then_one_or_more_adverbs().t_ws())
                .then(NominalPhrase)
        };

        let hyphenated_number_modifier = || {
            SequenceExpr::default()
                .then_number()
                .then_hyphen()
                .then_nominal()
                .then_optional(SequenceExpr::default().then_hyphen().then_adjective())
                .t_ws()
                .then_nominal()
        };

        let hyphenated_compound = || {
            SequenceExpr::default()
                .then_kind_any(&[TokenKind::is_word_like as fn(&TokenKind) -> bool])
                .then_hyphen()
                .then_nominal()
        };

        let trailing_phrase = || {
            SequenceExpr::default().then_any_of(vec![
                Box::new(hyphenated_number_modifier()),
                Box::new(hyphenated_compound()),
                Box::new(nominal_tail()),
            ])
        };

        map.insert(
            SequenceExpr::default()
                .then_determiner()
                .t_ws()
                .then_seq(soon_to_be())
                .t_ws()
                .then_seq(trailing_phrase()),
            2..7,
        );

        map.insert(
            SequenceExpr::default()
                .then_seq(soon_to_be())
                .t_ws()
                .then_seq(trailing_phrase()),
            0..5,
        );

        let map = Arc::new(map);

        Self {
            expr: Box::new(map.clone()),
            map,
        }
    }
}

impl ExprLinter for SoonToBe {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], source: &[char]) -> Option<Lint> {
        let range = self.map.lookup(0, matched_tokens, source)?;
        let span = matched_tokens.get(range.start..range.end)?.span()?;
        let template = span.get_content(source);

        let mut nominal_found = false;
        for tok in matched_tokens.iter().skip(range.end) {
            if tok.kind.is_whitespace() || tok.kind.is_hyphen() {
                continue;
            }

            if tok.kind.is_punctuation() {
                break;
            }

            if tok.kind.is_nominal() {
                if tok.kind.is_preposition() {
                    continue;
                } else {
                    nominal_found = true;
                    break;
                }
            }
        }

        if !nominal_found {
            return None;
        }

        Some(Lint {
            span,
            lint_kind: LintKind::Miscellaneous,
            suggestions: vec![Suggestion::replace_with_match_case_str(
                "soon-to-be",
                template,
            )],
            message: "Use hyphens when `soon to be` modifies a noun.".to_owned(),
            priority: 31,
        })
    }

    fn description(&self) -> &'static str {
        "Hyphenates `soon-to-be` when it appears before a noun."
    }
}

#[cfg(test)]
mod tests {
    use super::SoonToBe;
    use crate::linting::tests::{assert_lint_count, assert_no_lints, assert_suggestion_result};

    #[test]
    fn hyphenates_possessive_phrase() {
        assert_suggestion_result(
            "We met his soon to be boss at lunch.",
            SoonToBe::default(),
            "We met his soon-to-be boss at lunch.",
        );
    }

    #[test]
    fn hyphenates_article_phrase() {
        assert_suggestion_result(
            "They toasted the soon to be couple.",
            SoonToBe::default(),
            "They toasted the soon-to-be couple.",
        );
    }

    #[test]
    fn hyphenates_sentence_start() {
        assert_suggestion_result(
            "Soon to be parents filled the classroom.",
            SoonToBe::default(),
            "Soon-to-be parents filled the classroom.",
        );
    }

    #[test]
    fn allows_existing_hyphens() {
        assert_no_lints("We met his soon-to-be boss yesterday.", SoonToBe::default());
    }

    #[test]
    fn keeps_non_adjectival_use() {
        assert_no_lints("The concert is soon to be over.", SoonToBe::default());
    }

    #[test]
    fn hyphenates_with_adverb() {
        assert_suggestion_result(
            "Our soon to be newly married friends visited.",
            SoonToBe::default(),
            "Our soon-to-be newly married friends visited.",
        );
    }

    #[test]
    fn hyphenates_hyphenated_number_phrase() {
        assert_suggestion_result(
            "Our soon to be 5-year-old son starts school.",
            SoonToBe::default(),
            "Our soon-to-be 5-year-old son starts school.",
        );
    }

    #[test]
    fn hyphenates_in_law_phrase() {
        assert_suggestion_result(
            "She thanked her soon to be in-laws for hosting.",
            SoonToBe::default(),
            "She thanked her soon-to-be in-laws for hosting.",
        );
    }

    #[test]
    fn hyphenates_future_event() {
        assert_suggestion_result(
            "We reserved space for our soon to be celebration.",
            SoonToBe::default(),
            "We reserved space for our soon-to-be celebration.",
        );
    }

    #[test]
    fn ignores_misaligned_verb_chain() {
        assert_lint_count(
            "They will soon to be moving overseas.",
            SoonToBe::default(),
            0,
        );
    }

    #[test]
    fn hyphenates_guest_example() {
        assert_suggestion_result(
            "I cooked for my soon to be guests.",
            SoonToBe::default(),
            "I cooked for my soon-to-be guests.",
        );
    }

    #[test]
    fn ignores_rearranged_phrase() {
        assert_no_lints("We hope to soon be home.", SoonToBe::default());
    }
}



================================================
FILE: harper-core/src/linting/sought_after.rs
================================================
use crate::expr::{Expr, SequenceExpr, SpaceOrHyphen};
use crate::{Token, TokenKind};

use super::{ExprLinter, Lint, LintKind, Suggestion};
use crate::linting::expr_linter::Chunk;

pub struct SoughtAfter {
    expr: Box<dyn Expr>,
}

impl Default for SoughtAfter {
    fn default() -> Self {
        let pattern = SequenceExpr::any_of(vec![
            Box::new(
                SequenceExpr::default()
                    .then_kind_except(TokenKind::is_adverb, &["always", "maybe", "not", "perhaps"]),
            ),
            Box::new(SequenceExpr::word_set(&[
                "abit", // Typo for "a bit"
                "are",  // may cause false positive, but few found so far.
                "bit",
                // "is" causes many false postivies and disambiguating looks tricky.
                // "maybe" causes many false postivies and disambiguating looks tricky.
                "of", "quiet", // Common typo for "quite".
            ])),
        ])
        .t_ws()
        .t_aco("sort")
        .then(SpaceOrHyphen)
        .t_aco("after");

        Self {
            expr: Box::new(pattern),
        }
    }
}

impl ExprLinter for SoughtAfter {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, toks: &[Token], src: &[char]) -> Option<Lint> {
        let span = toks[2].span;

        Some(Lint {
            span,
            lint_kind: LintKind::Eggcorn,
            suggestions: vec![Suggestion::replace_with_match_case_str(
                "sought",
                span.get_content(src),
            )],
            message: "The correct word in this context is `sought`.".to_owned(),
            priority: 63,
        })
    }

    fn description(&self) -> &'static str {
        "Correct `sort after` to `sought after`"
    }
}

#[cfg(test)]
mod tests {
    use crate::linting::tests::{assert_lint_count, assert_suggestion_result};

    use super::SoughtAfter;

    #[test]
    fn fix_abit_sort_after() {
        assert_suggestion_result(
            "Blue mountain buffalo no damage abit sort after,$120 ono.",
            SoughtAfter::default(),
            "Blue mountain buffalo no damage abit sought after,$120 ono.",
        );
    }

    #[test]
    fn dont_flag_always_sort_after() {
        assert_lint_count(
            "Always sort after converting your set into list objects",
            SoughtAfter::default(),
            0,
        );
    }

    #[test]
    fn fix_are_sort_after() {
        assert_suggestion_result(
            "Ux engineers are sort after, but it requires experience.",
            SoughtAfter::default(),
            "Ux engineers are sought after, but it requires experience.",
        )
    }

    #[test]
    fn fix_are_sort_after_hyphenated() {
        assert_suggestion_result(
            "optimistic people are sort-after for their life",
            SoughtAfter::default(),
            "optimistic people are sought-after for their life",
        );
    }

    #[test]
    fn fix_bit_sort_after() {
        assert_suggestion_result(
            "It's the early enduro model getting a bit sort after now",
            SoughtAfter::default(),
            "It's the early enduro model getting a bit sought after now",
        );
    }

    #[test]
    fn fix_extremely_sort_after() {
        assert_suggestion_result(
            "3 extremely sort after Pokémon trading cards.",
            SoughtAfter::default(),
            "3 extremely sought after Pokémon trading cards.",
        );
    }

    #[test]
    fn fix_fairly_sort_after() {
        assert_suggestion_result(
            "The ability for editors to add tables to pages is a fairly sort after piece of functionality",
            SoughtAfter::default(),
            "The ability for editors to add tables to pages is a fairly sought after piece of functionality",
        );
    }

    #[test]
    fn fix_highly_sort_after() {
        assert_suggestion_result(
            "Wrestlemania 2K adds three highly sort after features",
            SoughtAfter::default(),
            "Wrestlemania 2K adds three highly sought after features",
        );
    }

    #[test]
    fn fix_hugely_sort_after() {
        assert_suggestion_result(
            "Currently the hugely sort after and most highly prized variety is the electric neon blue Paraiba Tourmaline.",
            SoughtAfter::default(),
            "Currently the hugely sought after and most highly prized variety is the electric neon blue Paraiba Tourmaline.",
        );
    }

    #[test]
    fn fix_incredibly_sort_after() {
        assert_suggestion_result(
            "This is no surprise as it's been an incredibly sort after and top choice amongst outdoorists from all walks of life.",
            SoughtAfter::default(),
            "This is no surprise as it's been an incredibly sought after and top choice amongst outdoorists from all walks of life.",
        );
    }

    #[test]
    #[ignore = "'Is' is a bit more subtle to handle correctly"]
    fn fix_is_sort_after() {
        assert_suggestion_result(
            "White bait is sort after by many fisherman because they  are a delicacy.",
            SoughtAfter::default(),
            "White bait is sought after by many fisherman because they  are a delicacy.",
        );
    }

    #[test]
    fn dont_flag_is_sort_after() {
        assert_lint_count(
            "What I would do is sort after the union or join.",
            SoughtAfter::default(),
            0,
        );
    }

    #[test]
    fn fix_kinda_sort_after() {
        assert_suggestion_result(
            "If so is the US bond still kinda sort after as it's tied to USD (that's how I took OPs post).",
            SoughtAfter::default(),
            "If so is the US bond still kinda sought after as it's tied to USD (that's how I took OPs post).",
        );
    }

    #[test]
    fn dont_flag_maybe_sort_after() {
        assert_lint_count(
            "Or maybe sort after adding the index?",
            SoughtAfter::default(),
            0,
        );
    }

    #[test]
    fn fix_most_sort_after() {
        assert_suggestion_result(
            "This has got to be one of the most sort after solutions.",
            SoughtAfter::default(),
            "This has got to be one of the most sought after solutions.",
        );
    }

    #[test]
    fn fix_mostly_sort_after() {
        assert_suggestion_result(
            "What color and size is mostly sort after In ladies footwear",
            SoughtAfter::default(),
            "What color and size is mostly sought after In ladies footwear",
        );
    }

    #[test]
    fn fix_much_sort_after() {
        assert_suggestion_result(
            "Sending audio files is a much sort after feature in chat apps.",
            SoughtAfter::default(),
            "Sending audio files is a much sought after feature in chat apps.",
        );
    }

    #[test]
    fn dont_flag_not_sort_after() {
        assert_lint_count(
            "My issue is that it does not sort after the startyear",
            SoughtAfter::default(),
            0,
        );
    }

    // This part is occasionally sort after and if they were easily available I reckon you'd sell a few easily enough.
    #[test]
    fn fix_occasionally_sort_after() {
        assert_suggestion_result(
            "This part is occasionally sort after and if they were easily available I reckon you'd sell a few easily enough.",
            SoughtAfter::default(),
            "This part is occasionally sought after and if they were easily available I reckon you'd sell a few easily enough.",
        );
    }

    #[test]
    fn fix_of_sort_after() {
        assert_suggestion_result(
            "A couple of sort after casserole pots .",
            SoughtAfter::default(),
            "A couple of sought after casserole pots .",
        );
    }

    #[test]
    fn fix_often_sort_after() {
        assert_suggestion_result(
            "North American countries (ok, there are only two) often sort after the total amount of medals.",
            SoughtAfter::default(),
            "North American countries (ok, there are only two) often sought after the total amount of medals.",
        );
    }

    #[test]
    #[ignore = "'Perhaps' is a bit more subtle to handle correctly"]
    fn fix_perhaps_sort_after() {
        assert_suggestion_result(
            "Perhaps sort after guitar teachers could do a similar teaching tour to a few major cities",
            SoughtAfter::default(),
            "Perhaps sought after guitar teachers could do a similar teaching tour to a few major cities",
        );
    }

    #[test]
    fn dont_flat_perhaps_sort_after() {
        assert_lint_count(
            "min_Vround: perhaps sort after min_breadth.",
            SoughtAfter::default(),
            0,
        );
    }

    #[test]
    fn flag_pretty_sort_after() {
        assert_suggestion_result(
            "But just like jin and V, he is also pretty sort after",
            SoughtAfter::default(),
            "But just like jin and V, he is also pretty sought after",
        );
    }

    #[test]
    fn fix_quiet_sort_after_sic() {
        assert_suggestion_result(
            "MBA in Christ (deemed university) is quiet sort after in South India",
            SoughtAfter::default(),
            "MBA in Christ (deemed university) is quiet sought after in South India",
        );
    }

    // The university that i studied my MBBS from offers the course as well and it is quite sort after for the above said course.
    #[test]
    fn fix_quite_sort_after() {
        assert_suggestion_result(
            "The university that i studied my MBBS from offers the course as well and it is quite sort after for the above said course.",
            SoughtAfter::default(),
            "The university that i studied my MBBS from offers the course as well and it is quite sought after for the above said course.",
        );
    }

    #[test]
    fn fix_rather_sort_after() {
        assert_suggestion_result(
            "In a bid to satisfy an innate inquisitive hunger for a rather sort after phenomenon that only a few could precisely speak",
            SoughtAfter::default(),
            "In a bid to satisfy an innate inquisitive hunger for a rather sought after phenomenon that only a few could precisely speak",
        );
    }

    #[test]
    fn fix_really_sort_after() {
        assert_suggestion_result(
            "Creators - especially women in their 30s, 40s, 50s and 60s are really sort after.",
            SoughtAfter::default(),
            "Creators - especially women in their 30s, 40s, 50s and 60s are really sought after.",
        );
    }

    #[test]
    fn fix_sometimes_sort_after() {
        assert_suggestion_result(
            "the N15 1.6L gearbox is sometimes sort after for the micra",
            SoughtAfter::default(),
            "the N15 1.6L gearbox is sometimes sought after for the micra",
        );
    }

    #[test]
    fn fix_somewhat_sort_after() {
        assert_suggestion_result(
            "I know tri res boots used to be somewhat sort after, but not sure now!",
            SoughtAfter::default(),
            "I know tri res boots used to be somewhat sought after, but not sure now!",
        );
    }

    #[test]
    fn fix_strongly_sort_after() {
        assert_suggestion_result(
            "This eventually leads to the growth that is so strongly sort after.",
            SoughtAfter::default(),
            "This eventually leads to the growth that is so strongly sought after.",
        );
    }

    #[test]
    fn fix_vastly_sort_after() {
        assert_suggestion_result(
            "Hardie stuff no longer vastly sort after as it was years ago , hasn't been for decades.",
            SoughtAfter::default(),
            "Hardie stuff no longer vastly sought after as it was years ago , hasn't been for decades.",
        );
    }

    #[test]
    fn fix_very_sort_after() {
        assert_suggestion_result(
            "I could imagine, this functionality very sort after.",
            SoughtAfter::default(),
            "I could imagine, this functionality very sought after.",
        );
    }
}



================================================
FILE: harper-core/src/linting/spaces.rs
================================================
use super::{Lint, LintKind, Linter, Suggestion};
use crate::TokenStringExt;
use crate::{Document, Token, TokenKind};

#[derive(Debug, Default)]
pub struct Spaces;

impl Linter for Spaces {
    fn lint(&mut self, document: &Document) -> Vec<Lint> {
        let mut output = Vec::new();

        for sentence in document.iter_sentences() {
            for space_idx in sentence.iter_space_indices() {
                if space_idx == 0 {
                    continue;
                }

                let space = &sentence[space_idx];

                let TokenKind::Space(count) = space.kind else {
                    panic!("The space iterator should only return spaces.")
                };

                if count > 1 {
                    output.push(Lint {
                        span: space.span,
                        lint_kind: LintKind::Formatting,
                        suggestions: vec![Suggestion::ReplaceWith(vec![' '])],
                        message: format!(
                            "There are {count} spaces where there should be only one."
                        ),
                        priority: 15,
                    })
                }
            }

            if matches!(
                sentence,
                [
                    ..,
                    Token {
                        kind: TokenKind::Word(_),
                        ..
                    },
                    Token {
                        kind: TokenKind::Space(_),
                        ..
                    },
                    Token {
                        kind: TokenKind::Punctuation(_),
                        ..
                    }
                ]
            ) && let Some(space) = sentence.get_rel(-2)
            {
                output.push(Lint {
                    span: space.span,
                    lint_kind: LintKind::Formatting,
                    suggestions: vec![Suggestion::Remove],
                    message: "Unnecessary space at the end of the sentence.".to_string(),
                    priority: 63,
                })
            }
        }

        output
    }

    fn description(&self) -> &'static str {
        "Words should be separated by at most one space."
    }
}

#[cfg(test)]
mod tests {
    use super::Spaces;
    use crate::linting::tests::{assert_lint_count, assert_no_lints};

    #[test]
    fn detects_space_before_period() {
        let source = "There is a space at the end of this sentence .";

        assert_lint_count(source, Spaces, 1)
    }

    #[test]
    fn allows_period_without_space() {
        let source = "There isn't a space at the end of this sentence.";

        assert_lint_count(source, Spaces, 0)
    }

    #[test]
    fn ignores_french_spacing() {
        assert_no_lints(
            "This is a short sentence.  This is another short sentence.",
            Spaces,
        );
    }
}



================================================
FILE: harper-core/src/linting/spell_check.rs
================================================
use std::num::NonZero;

use lru::LruCache;
use smallvec::ToSmallVec;

use super::Suggestion;
use super::{Lint, LintKind, Linter};
use crate::document::Document;
use crate::spell::{Dictionary, suggest_correct_spelling};
use crate::{CharString, CharStringExt, Dialect, TokenStringExt};

pub struct SpellCheck<T>
where
    T: Dictionary,
{
    dictionary: T,
    suggestion_cache: LruCache<CharString, Vec<CharString>>,
    dialect: Dialect,
}

impl<T: Dictionary> SpellCheck<T> {
    pub fn new(dictionary: T, dialect: Dialect) -> Self {
        Self {
            dictionary,
            suggestion_cache: LruCache::new(NonZero::new(10000).unwrap()),
            dialect,
        }
    }

    const MAX_SUGGESTIONS: usize = 3;

    fn suggest_correct_spelling(&mut self, word: &[char]) -> Vec<CharString> {
        if let Some(hit) = self.suggestion_cache.get(word) {
            hit.clone()
        } else {
            let suggestions = self.uncached_suggest_correct_spelling(word);
            self.suggestion_cache.put(word.into(), suggestions.clone());
            suggestions
        }
    }
    fn uncached_suggest_correct_spelling(&self, word: &[char]) -> Vec<CharString> {
        // Back off until we find a match.
        for dist in 2..5 {
            let suggestions: Vec<CharString> =
                suggest_correct_spelling(word, 200, dist, &self.dictionary)
                    .into_iter()
                    .filter(|v| {
                        // Ignore entries outside the configured dialect
                        self.dictionary
                            .get_word_metadata(v)
                            .unwrap()
                            .dialects
                            .is_dialect_enabled(self.dialect)
                    })
                    .map(|v| v.to_smallvec())
                    .take(Self::MAX_SUGGESTIONS)
                    .collect();

            if !suggestions.is_empty() {
                return suggestions;
            }
        }

        // no suggestions found
        Vec::new()
    }
}

impl<T: Dictionary> Linter for SpellCheck<T> {
    fn lint(&mut self, document: &Document) -> Vec<Lint> {
        let mut lints = Vec::new();

        for word in document.iter_words() {
            let word_chars = document.get_span_content(&word.span);

            if let Some(metadata) = word.kind.as_word().unwrap()
                && metadata.dialects.is_dialect_enabled(self.dialect)
                && (self.dictionary.contains_exact_word(word_chars)
                    || self.dictionary.contains_exact_word(&word_chars.to_lower()))
            {
                continue;
            };

            let mut possibilities = self.suggest_correct_spelling(word_chars);

            // If the misspelled word is capitalized, capitalize the results too.
            if let Some(mis_f) = word_chars.first()
                && mis_f.is_uppercase()
            {
                for sug_f in possibilities.iter_mut().filter_map(|w| {
                    // Skip words that have uppercase chars in any position except the first.
                    // (For words with specific capitalization, like 'macOS')
                    w.iter()
                        .skip(1)
                        .all(|c| !c.is_uppercase())
                        .then_some(w.first_mut())
                        .flatten()
                }) {
                    *sug_f = sug_f.to_uppercase().next().unwrap();
                }
            }

            let suggestions: Vec<_> = possibilities
                .iter()
                .map(|sug| Suggestion::ReplaceWith(sug.to_vec()))
                .collect();

            // If there's only one suggestion, save the user a step in the GUI
            let message = if suggestions.len() == 1 {
                format!(
                    "Did you mean `{}`?",
                    possibilities.first().unwrap().iter().collect::<String>()
                )
            } else {
                format!(
                    "Did you mean to spell `{}` this way?",
                    document.get_span_content_str(&word.span)
                )
            };

            lints.push(Lint {
                span: word.span,
                lint_kind: LintKind::Spelling,
                suggestions,
                message,
                priority: 63,
            })
        }

        lints
    }

    fn description(&self) -> &'static str {
        "Looks and provides corrections for misspelled words."
    }
}

#[cfg(test)]
mod tests {
    use strum::IntoEnumIterator;

    use super::SpellCheck;
    use crate::dict_word_metadata::DialectFlags;
    use crate::linting::Linter;
    use crate::linting::tests::{assert_good_and_bad_suggestions, assert_no_lints};
    use crate::spell::{Dictionary, FstDictionary, MergedDictionary, MutableDictionary};
    use crate::{
        Dialect,
        linting::tests::{
            assert_lint_count, assert_suggestion_result, assert_top3_suggestion_result,
        },
    };
    use crate::{DictWordMetadata, Document};

    // Capitalization tests

    #[test]
    fn america_capitalized() {
        assert_suggestion_result(
            "The word america should be capitalized.",
            SpellCheck::new(FstDictionary::curated(), Dialect::American),
            "The word America should be capitalized.",
        );
    }

    // Dialect tests

    #[test]
    fn harper_automattic_capitalized() {
        assert_lint_count(
            "So should harper and automattic.",
            SpellCheck::new(FstDictionary::curated(), Dialect::American),
            2,
        );
    }

    #[test]
    fn american_color_in_british_dialect() {
        assert_lint_count(
            "Do you like the color?",
            SpellCheck::new(FstDictionary::curated(), Dialect::British),
            1,
        );
    }

    #[test]
    fn canadian_words_in_australian_dialect() {
        assert_lint_count(
            "Does your mom like yogourt?",
            SpellCheck::new(FstDictionary::curated(), Dialect::Australian),
            2,
        );
    }

    #[test]
    fn australian_words_in_canadian_dialect() {
        assert_lint_count(
            "We mine bauxite to make aluminium.",
            SpellCheck::new(FstDictionary::curated(), Dialect::Canadian),
            1,
        );
    }

    #[test]
    fn mum_and_mummy_not_just_commonwealth() {
        assert_lint_count(
            "Mum's the word about that Egyptian mummy.",
            SpellCheck::new(FstDictionary::curated(), Dialect::American),
            0,
        );
    }

    #[test]
    fn australian_verandah() {
        assert_lint_count(
            "Our house has a verandah.",
            SpellCheck::new(FstDictionary::curated(), Dialect::Australian),
            0,
        );
    }

    #[test]
    fn australian_verandah_in_american_dialect() {
        assert_lint_count(
            "Our house has a verandah.",
            SpellCheck::new(FstDictionary::curated(), Dialect::American),
            1,
        );
    }

    #[test]
    fn australian_verandah_in_british_dialect() {
        assert_lint_count(
            "Our house has a verandah.",
            SpellCheck::new(FstDictionary::curated(), Dialect::British),
            1,
        );
    }

    #[test]
    fn australian_verandah_in_canadian_dialect() {
        assert_lint_count(
            "Our house has a verandah.",
            SpellCheck::new(FstDictionary::curated(), Dialect::Canadian),
            1,
        );
    }

    #[test]
    fn mixing_australian_and_canadian_dialects() {
        assert_lint_count(
            "In summer we sit on the verandah and eat yogourt.",
            SpellCheck::new(FstDictionary::curated(), Dialect::Australian),
            1,
        );
    }

    #[test]
    fn mixing_canadian_and_australian_dialects() {
        assert_lint_count(
            "In summer we sit on the verandah and eat yogourt.",
            SpellCheck::new(FstDictionary::curated(), Dialect::Canadian),
            1,
        );
    }

    #[test]
    fn australian_and_canadian_spellings_that_are_not_american() {
        assert_lint_count(
            "In summer we sit on the verandah and eat yogourt.",
            SpellCheck::new(FstDictionary::curated(), Dialect::American),
            2,
        );
    }

    #[test]
    fn australian_and_canadian_spellings_that_are_not_british() {
        assert_lint_count(
            "In summer we sit on the verandah and eat yogourt.",
            SpellCheck::new(FstDictionary::curated(), Dialect::British),
            2,
        );
    }

    #[test]
    fn australian_labour_vs_labor() {
        assert_lint_count(
            "In Australia we write 'labour' but the political party is the 'Labor Party'.",
            SpellCheck::new(FstDictionary::curated(), Dialect::Australian),
            0,
        )
    }

    #[test]
    fn australian_words_flagged_for_american_english() {
        assert_lint_count(
            "There's an esky full of beers in the back of the ute.",
            SpellCheck::new(FstDictionary::curated(), Dialect::American),
            2,
        );
    }

    #[test]
    fn american_words_not_flagged_for_australian_english() {
        assert_lint_count(
            "In general, utes have unibody construction while pickups have frames.",
            SpellCheck::new(FstDictionary::curated(), Dialect::Australian),
            0,
        );
    }

    #[test]
    fn abandonware_correction() {
        assert_suggestion_result(
            "abanonedware",
            SpellCheck::new(FstDictionary::curated(), Dialect::Australian),
            "abandonware",
        );
    }

    // Unit tests for specific spellcheck corrections

    #[test]
    fn corrects_abandonedware_1131_1166() {
        // assert_suggestion_result(
        assert_top3_suggestion_result(
            "Abandonedware is abandoned. Do not bother submitting issues about the empty page bug. Author moved to greener pastures",
            SpellCheck::new(FstDictionary::curated(), Dialect::American),
            "Abandonware is abandoned. Do not bother submitting issues about the empty page bug. Author moved to greener pastures",
        );
    }

    #[test]
    fn afterwards_not_us() {
        assert_lint_count(
            "afterwards",
            SpellCheck::new(FstDictionary::curated(), Dialect::American),
            1,
        );
    }

    #[test]
    fn afterward_is_us() {
        assert_lint_count(
            "afterward",
            SpellCheck::new(FstDictionary::curated(), Dialect::American),
            0,
        );
    }

    #[test]
    fn afterward_not_au() {
        assert_lint_count(
            "afterward",
            SpellCheck::new(FstDictionary::curated(), Dialect::Australian),
            1,
        );
    }

    #[test]
    fn afterwards_is_au() {
        assert_lint_count(
            "afterwards",
            SpellCheck::new(FstDictionary::curated(), Dialect::Australian),
            0,
        );
    }

    #[test]
    fn afterward_not_ca() {
        assert_lint_count(
            "afterward",
            SpellCheck::new(FstDictionary::curated(), Dialect::Canadian),
            1,
        );
    }

    #[test]
    fn afterwards_is_ca() {
        assert_lint_count(
            "afterwards",
            SpellCheck::new(FstDictionary::curated(), Dialect::Canadian),
            0,
        );
    }

    #[test]
    fn afterward_not_uk() {
        assert_lint_count(
            "afterward",
            SpellCheck::new(FstDictionary::curated(), Dialect::British),
            1,
        );
    }

    #[test]
    fn afterwards_is_uk() {
        assert_lint_count(
            "afterwards",
            SpellCheck::new(FstDictionary::curated(), Dialect::British),
            0,
        );
    }

    #[test]
    fn corrects_hes() {
        assert_suggestion_result(
            "hes",
            SpellCheck::new(FstDictionary::curated(), Dialect::British),
            "he's",
        );
    }

    #[test]
    fn corrects_shes() {
        assert_suggestion_result(
            "shes",
            SpellCheck::new(FstDictionary::curated(), Dialect::British),
            "she's",
        );
    }

    #[test]
    fn issue_1876() {
        let user_dialect = Dialect::American;

        // Create a user dictionary with a word normally of another dialect in it.
        let mut user_dict = MutableDictionary::new();
        user_dict.append_word_str(
            "Calibre",
            DictWordMetadata {
                dialects: DialectFlags::from_dialect(user_dialect),
                ..Default::default()
            },
        );

        // Create a merged dictionary, using curated first.
        let mut merged_dict = MergedDictionary::new();
        merged_dict.add_dictionary(FstDictionary::curated());
        merged_dict.add_dictionary(std::sync::Arc::from(user_dict));
        assert!(merged_dict.contains_word_str("Calibre"));

        // No dialect issues should be found if the word from another dialect is in our user dictionary.
        assert_eq!(
            SpellCheck::new(merged_dict.clone(), user_dialect)
                .lint(&Document::new_markdown_default(
                    "I like to use the software Calibre.",
                    &merged_dict
                ))
                .len(),
            0,
            "Calibre is not part of the user's dialect!"
        );

        assert_eq!(
            SpellCheck::new(merged_dict.clone(), user_dialect)
                .lint(&Document::new_markdown_default(
                    "I like to use the spelling colour.",
                    &merged_dict
                ))
                .len(),
            1
        );
    }

    #[test]
    fn matt_is_allowed() {
        for dialect in Dialect::iter() {
            dbg!(dialect);
            assert_no_lints(
                "Matt is a great name.",
                SpellCheck::new(FstDictionary::curated(), dialect),
            );
        }
    }

    #[test]
    fn issue_2026() {
        assert_top3_suggestion_result(
            "'Tere' is supposed to be 'There'",
            SpellCheck::new(FstDictionary::curated(), Dialect::British),
            "'There' is supposed to be 'There'",
        );

        assert_top3_suggestion_result(
            "'fll' is supposed to be 'fill'",
            SpellCheck::new(FstDictionary::curated(), Dialect::British),
            "'fill' is supposed to be 'fill'",
        );
    }
    #[test]
    fn issue_2261() {
        assert_top3_suggestion_result(
            "Generaly",
            SpellCheck::new(FstDictionary::curated(), Dialect::British),
            "Generally",
        );
    }

    #[test]
    fn flag_prepone_in_non_indian_english() {
        assert_lint_count(
            "We had to prepone the meeting",
            SpellCheck::new(FstDictionary::curated(), Dialect::American),
            1,
        );
    }

    #[test]
    fn dont_flag_prepone_in_indian_english() {
        assert_no_lints(
            "We had to prepone the meeting",
            SpellCheck::new(FstDictionary::curated(), Dialect::Indian),
        );
    }

    #[test]
    fn dont_flag_pr() {
        assert_no_lints(
            "PR",
            SpellCheck::new(FstDictionary::curated(), Dialect::American),
        );
    }

    #[test]
    fn no_improper_suggestion_for_macos() {
        assert_good_and_bad_suggestions(
            "MacOS",
            SpellCheck::new(FstDictionary::curated(), Dialect::American),
            &["macOS"],
            &["MacOS"],
        );
    }
}



================================================
FILE: harper-core/src/linting/spelled_numbers.rs
================================================
use crate::linting::{LintKind, Linter, Suggestion};
use crate::{Document, Lint, Number, TokenStringExt};

/// Linter that checks to make sure small integers (< 10) are spelled
/// out.
#[derive(Default, Clone, Copy)]
pub struct SpelledNumbers;

impl Linter for SpelledNumbers {
    fn lint(&mut self, document: &Document) -> Vec<crate::Lint> {
        let mut lints = Vec::new();

        for number_tok in document.iter_numbers() {
            let Number {
                value,
                suffix: None,
                ..
            } = number_tok.kind.as_number().unwrap()
            else {
                continue;
            };
            let value: f64 = (*value).into();

            if (value - value.floor()).abs() < f64::EPSILON && value < 10. {
                lints.push(Lint {
                    span: number_tok.span,
                    lint_kind: LintKind::Readability,
                    suggestions: vec![Suggestion::ReplaceWith(
                        spell_out_number(value as u64).unwrap().chars().collect(),
                    )],
                    message: "Try to spell out numbers less than ten.".to_string(),
                    priority: 63,
                })
            }
        }

        lints
    }

    fn description(&self) -> &'static str {
        "Most style guides recommend that you spell out numbers less than ten."
    }
}

/// Converts a number to its spelled-out variant.
///
/// For example: 100 -> one hundred.
///
/// Works for numbers up to 999, but can be expanded to include more powers of 10.
fn spell_out_number(num: u64) -> Option<String> {
    if num > 999 {
        return None;
    }

    Some(match num {
        0 => "zero".to_string(),
        1 => "one".to_string(),
        2 => "two".to_string(),
        3 => "three".to_string(),
        4 => "four".to_string(),
        5 => "five".to_string(),
        6 => "six".to_string(),
        7 => "seven".to_string(),
        8 => "eight".to_string(),
        9 => "nine".to_string(),
        10 => "ten".to_string(),
        11 => "eleven".to_string(),
        12 => "twelve".to_string(),
        13 => "thirteen".to_string(),
        14 => "fourteen".to_string(),
        15 => "fifteen".to_string(),
        16 => "sixteen".to_string(),
        17 => "seventeen".to_string(),
        18 => "eighteen".to_string(),
        19 => "nineteen".to_string(),
        20 => "twenty".to_string(),
        30 => "thirty".to_string(),
        40 => "forty".to_string(),
        50 => "fifty".to_string(),
        60 => "sixty".to_string(),
        70 => "seventy".to_string(),
        80 => "eighty".to_string(),
        90 => "ninety".to_string(),
        hundred if hundred % 100 == 0 => {
            format!("{} hundred", spell_out_number(hundred / 100).unwrap())
        }
        _ => {
            let n = 10u64.pow((num as f32).log10() as u32);
            let parent = (num / n) * n; // truncate
            let child = num % n;

            format!(
                "{}{}{}",
                spell_out_number(parent).unwrap(),
                if num <= 99 { '-' } else { ' ' },
                spell_out_number(child).unwrap()
            )
        }
    })
}

#[cfg(test)]
mod tests {
    use crate::linting::tests::assert_suggestion_result;

    use super::{SpelledNumbers, spell_out_number};

    #[test]
    fn produces_zero() {
        assert_eq!(spell_out_number(0), Some("zero".to_string()))
    }

    #[test]
    fn produces_eighty_two() {
        assert_eq!(spell_out_number(82), Some("eighty-two".to_string()))
    }

    #[test]
    fn produces_nine_hundred_ninety_nine() {
        assert_eq!(
            spell_out_number(999),
            Some("nine hundred ninety-nine".to_string())
        )
    }

    #[test]
    fn corrects_nine() {
        assert_suggestion_result("There are 9 pigs.", SpelledNumbers, "There are nine pigs.");
    }

    #[test]
    fn does_not_correct_ten() {
        assert_suggestion_result("There are 10 pigs.", SpelledNumbers, "There are 10 pigs.");
    }

    /// Check that the algorithm won't stack overflow or return `None` for any numbers within the specified range.
    #[test]
    fn services_range() {
        for i in 0..1000 {
            spell_out_number(i).unwrap();
        }
    }
}



================================================
FILE: harper-core/src/linting/split_words.rs
================================================
use crate::spell::Dictionary;
use std::sync::Arc;

use crate::Token;
use crate::expr::Expr;
use crate::linting::{LintKind, Suggestion};
use crate::spell::{FstDictionary, TrieDictionary};

use super::{ExprLinter, Lint};
use crate::linting::expr_linter::Chunk;

pub struct SplitWords {
    dict: Arc<TrieDictionary<Arc<FstDictionary>>>,
    expr: Box<dyn Expr>,
}

impl SplitWords {
    pub fn new() -> Self {
        Self {
            dict: TrieDictionary::curated(),
            expr: Box::new(|tok: &Token, _: &[char]| tok.kind.is_word()),
        }
    }
}

impl Default for SplitWords {
    fn default() -> Self {
        Self::new()
    }
}

impl ExprLinter for SplitWords {
    type Unit = Chunk;

    fn description(&self) -> &str {
        "Finds missing spaces in improper compound words."
    }

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], source: &[char]) -> Option<Lint> {
        let word = &matched_tokens[0];

        // If it's a recognized word, we don't care about it.
        if word.kind.as_word().unwrap().is_some() {
            return None;
        }

        let chars = &word.span.get_content(source);
        // The word that starts the compound
        let candidates = self.dict.find_words_with_common_prefix(chars);

        for candidate in candidates {
            if candidate.len() >= chars.len() {
                continue;
            }

            let cand_meta = self.dict.get_word_metadata(&candidate).unwrap();
            if !cand_meta.common {
                continue;
            }

            // The potential word that completes the compound
            let remainder = &chars[candidate.len()..];
            if let Some(rem_meta) = self.dict.get_word_metadata(remainder)
                && rem_meta.common
            {
                let candidate_chars = candidate.as_ref();
                let mut suggestion = Vec::new();

                suggestion.extend(candidate_chars.iter());
                suggestion.push(' ');
                suggestion.extend(remainder.iter());

                let original_word: String = chars.iter().collect();
                let candidate_word: String = candidate_chars.iter().collect();
                let remainder_word: String = remainder.iter().collect();

                return Some(Lint {
                    span: word.span,
                    lint_kind: LintKind::Typo,
                    suggestions: vec![Suggestion::ReplaceWith(suggestion)],
                    message: format!(
                        "`{original_word}` should probably be written as `{candidate_word} {remainder_word}`."
                    ),
                    priority: 31,
                });
            }
        }

        None
    }
}

#[cfg(test)]
mod tests {
    use crate::linting::tests::{assert_no_lints, assert_suggestion_result};

    use super::SplitWords;

    #[test]
    fn issue_1905() {
        assert_suggestion_result(
            "I want to try this insteadof that.",
            SplitWords::default(),
            "I want to try this instead of that.",
        );
    }

    /// Same as above, but with the longer component word at the end.
    #[test]
    fn issue_1905_rev() {
        assert_suggestion_result(
            "I want to try thisinstead of that.",
            SplitWords::default(),
            "I want to try this instead of that.",
        );
    }

    #[test]
    fn split_common() {
        assert_suggestion_result(
            "This is notnot a problem.",
            SplitWords::default(),
            "This is not not a problem.",
        );
    }

    #[test]
    fn splits_multiple_compound_words() {
        assert_suggestion_result(
            "We stared intothe darkness and kindof panicked about sortof everything.",
            SplitWords::default(),
            "We stared into the darkness and kind of panicked about sort of everything.",
        );
    }

    #[test]
    fn splits_word_with_longer_prefix() {
        assert_suggestion_result(
            "The astronauts waited on the landingpad for hours.",
            SplitWords::default(),
            "The astronauts waited on the landing pad for hours.",
        );
    }

    #[test]
    fn splits_before_punctuation() {
        assert_suggestion_result(
            "This was kindof, actually, hilarious.",
            SplitWords::default(),
            "This was kind of, actually, hilarious.",
        );
    }

    #[test]
    fn ignores_known_compound_words() {
        assert_no_lints("Someone left early.", SplitWords::default());
    }

    #[test]
    fn ignores_prefix_without_valid_remainder() {
        assert_no_lints("The monkeyxyz escaped unnoticed.", SplitWords::default());
    }
}



================================================
FILE: harper-core/src/linting/subject_pronoun.rs
================================================
use crate::expr::{AnchorStart, Expr, SequenceExpr};
use crate::{Token, TokenStringExt};

use super::expr_linter::Chunk;
use super::{ExprLinter, Lint, LintKind, Suggestion};

pub struct SubjectPronoun {
    expr: Box<dyn Expr>,
}

impl Default for SubjectPronoun {
    fn default() -> Self {
        let expr = SequenceExpr::default()
            .then(AnchorStart)
            .t_aco("me")
            .t_ws()
            .t_aco("and")
            .t_ws()
            .then_proper_noun();

        Self {
            expr: Box::new(expr),
        }
    }
}

impl ExprLinter for SubjectPronoun {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], source: &[char]) -> Option<Lint> {
        let span = matched_tokens.span()?;

        let mut suggestion_chars = Vec::new();
        suggestion_chars.extend_from_slice(matched_tokens.last()?.span.get_content(source));
        suggestion_chars.extend(" and I".chars());

        Some(Lint {
            span,
            lint_kind: LintKind::Grammar,
            suggestions: vec![Suggestion::ReplaceWith(suggestion_chars)],
            message: "Put the other person first and use `I` in this compound subject.".to_owned(),
            priority: 31,
        })
    }

    fn description(&self) -> &'static str {
        "Fixes sentences that start with `me and X` by putting the proper noun first and using `I`."
    }
}

fn append_token_chars(chars: &mut Vec<char>, token: &Token, source: &[char]) {
    chars.extend(token.span.get_content(source).iter().copied());
}

fn append_tokens_chars(chars: &mut Vec<char>, tokens: &[Token], source: &[char]) {
    for token in tokens {
        append_token_chars(chars, token, source);
    }
}

#[cfg(test)]
mod tests {
    use super::SubjectPronoun;
    use crate::linting::tests::assert_suggestion_result;

    #[test]
    fn alex_ladder() {
        assert_suggestion_result(
            "Me and Alex carried the huge ladder.",
            SubjectPronoun::default(),
            "Alex and I carried the huge ladder.",
        );
    }

    #[test]
    fn jordan_lamp() {
        assert_suggestion_result(
            "Me and Jordan fixed the broken lamp.",
            SubjectPronoun::default(),
            "Jordan and I fixed the broken lamp.",
        );
    }

    #[test]
    fn taylor_crate() {
        assert_suggestion_result(
            "Me and Taylor opened the dusty crate.",
            SubjectPronoun::default(),
            "Taylor and I opened the dusty crate.",
        );
    }

    #[test]
    fn kayla_dog() {
        assert_suggestion_result(
            "Me and Kayla chased the noisy dog.",
            SubjectPronoun::default(),
            "Kayla and I chased the noisy dog.",
        );
    }

    #[test]
    fn madison_yard() {
        assert_suggestion_result(
            "Me and Madison painted the small yard shed.",
            SubjectPronoun::default(),
            "Madison and I painted the small yard shed.",
        );
    }

    #[test]
    fn avery_tree() {
        assert_suggestion_result(
            "Me and Avery climbed the old tree.",
            SubjectPronoun::default(),
            "Avery and I climbed the old tree.",
        );
    }

    #[test]
    fn blake_room() {
        assert_suggestion_result(
            "Me and Blake cleaned the crowded room.",
            SubjectPronoun::default(),
            "Blake and I cleaned the crowded room.",
        );
    }

    #[test]
    fn riley_train() {
        assert_suggestion_result(
            "Me and Riley watched the slow train go by.",
            SubjectPronoun::default(),
            "Riley and I watched the slow train go by.",
        );
    }

    #[test]
    fn cameron_door() {
        assert_suggestion_result(
            "Me and Cameron fixed the loose door hinge.",
            SubjectPronoun::default(),
            "Cameron and I fixed the loose door hinge.",
        );
    }

    #[test]
    fn jamie_bag() {
        assert_suggestion_result(
            "Me and Jamie carried the heavy shopping bag.",
            SubjectPronoun::default(),
            "Jamie and I carried the heavy shopping bag.",
        );
    }
}



================================================
FILE: harper-core/src/linting/suggestion.rs
================================================
use std::{borrow::Borrow, fmt::Display};

use is_macro::Is;
use serde::{Deserialize, Serialize};

use crate::{Span, case};

/// A suggested edit that could resolve a [`Lint`](super::Lint).
#[derive(Debug, Clone, Serialize, Deserialize, Is, PartialEq, Eq, Hash)]
pub enum Suggestion {
    /// Replace the offending text with a specific character sequence.
    ReplaceWith(Vec<char>),
    /// Insert the provided characters _after_ the offending text.
    InsertAfter(Vec<char>),
    /// Remove the offending text.
    Remove,
}

impl Suggestion {
    /// Variant of [`Self::replace_with_match_case`] that accepts a static string.
    pub fn replace_with_match_case_str(
        value: &str,
        template: impl IntoIterator<Item = impl Borrow<char>>,
    ) -> Self {
        Self::replace_with_match_case(value.chars().collect(), template)
    }

    /// Construct an instance of [`Self::ReplaceWith`], but make the content match the case of the
    /// provided template.
    ///
    /// For example, if we want to replace "You're" with "You are", we can provide "you are" and
    /// "You're".
    pub fn replace_with_match_case(
        value: Vec<char>,
        template: impl IntoIterator<Item = impl Borrow<char>>,
    ) -> Self {
        Self::ReplaceWith(case::copy_casing(template, value).to_vec())
    }

    /// Apply a suggestion to a given text.
    pub fn apply(&self, span: Span<char>, source: &mut Vec<char>) {
        match self {
            Self::ReplaceWith(chars) => {
                // Avoid allocation if possible
                if chars.len() == span.len() {
                    for (index, c) in chars.iter().enumerate() {
                        source[index + span.start] = *c
                    }
                } else {
                    let popped = source.split_off(span.start);

                    source.extend(chars);
                    source.extend(popped.into_iter().skip(span.len()));
                }
            }
            Self::Remove => {
                for i in span.end..source.len() {
                    source[i - span.len()] = source[i];
                }

                source.truncate(source.len() - span.len());
            }
            Self::InsertAfter(chars) => {
                let popped = source.split_off(span.end);
                source.extend(chars);
                source.extend(popped);
            }
        }
    }
}

impl Display for Suggestion {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            Suggestion::ReplaceWith(with) => {
                write!(f, "Replace with: “{}”", with.iter().collect::<String>())
            }
            Suggestion::InsertAfter(with) => {
                write!(f, "Insert “{}”", with.iter().collect::<String>())
            }
            Suggestion::Remove => write!(f, "Remove error"),
        }
    }
}

pub trait SuggestionCollectionExt {
    fn to_replace_suggestions(
        self,
        case_template: impl IntoIterator<Item = impl Borrow<char>> + Clone,
    ) -> impl Iterator<Item = Suggestion>;
}

impl<I, T> SuggestionCollectionExt for I
where
    I: IntoIterator<Item = T>,
    T: AsRef<str>,
{
    fn to_replace_suggestions(
        self,
        case_template: impl IntoIterator<Item = impl Borrow<char>> + Clone,
    ) -> impl Iterator<Item = Suggestion> {
        self.into_iter().map(move |s| {
            Suggestion::replace_with_match_case_str(s.as_ref(), case_template.clone())
        })
    }
}

#[cfg(test)]
mod tests {
    use crate::Span;

    use super::Suggestion;

    #[test]
    fn insert_comma_after() {
        let source = "This is a test";
        let mut source_chars = source.chars().collect();
        let sug = Suggestion::InsertAfter(vec![',']);
        sug.apply(Span::new(0, 4), &mut source_chars);

        assert_eq!(source_chars, "This, is a test".chars().collect::<Vec<_>>());
    }

    #[test]
    fn suggestion_your_match_case() {
        let template: Vec<_> = "You're".chars().collect();
        let value: Vec<_> = "you are".chars().collect();

        let correct = "You are".chars().collect();

        assert_eq!(
            Suggestion::replace_with_match_case(value, &template),
            Suggestion::ReplaceWith(correct)
        )
    }

    #[test]
    fn issue_1065() {
        let template: Vec<_> = "Stack Overflow".chars().collect();
        let value: Vec<_> = "stackoverflow".chars().collect();

        let correct = "StackOverflow".chars().collect();

        assert_eq!(
            Suggestion::replace_with_match_case(value, &template),
            Suggestion::ReplaceWith(correct)
        )
    }
}



================================================
FILE: harper-core/src/linting/take_a_look_to.rs
================================================
use crate::{
    CharStringExt, Lint, Token,
    expr::{Expr, SequenceExpr},
    linting::{ExprLinter, LintKind, Suggestion, expr_linter::Chunk},
    patterns::WordSet,
};

static TAKE_FORMS: &[&str] = &["take", "took", "taken", "takes", "taking"];
static HAVE_FORMS: &[&str] = &["have", "had", "has", "having"];

pub struct TakeALookTo {
    pub expr: Box<dyn Expr>,
}

impl Default for TakeALookTo {
    fn default() -> Self {
        Self {
            expr: Box::new(
                SequenceExpr::any_of(vec![
                    Box::new(WordSet::new(TAKE_FORMS)),
                    Box::new(WordSet::new(HAVE_FORMS)),
                ])
                .t_ws()
                .t_aco("a")
                .t_ws()
                .t_aco("look")
                .t_ws()
                .t_aco("to"),
            ),
        }
    }
}

impl ExprLinter for TakeALookTo {
    type Unit = Chunk;

    fn description(&self) -> &str {
        "Corrects `take a look to`/`have a look to` to correctly use `at`."
    }

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint_with_context(
        &self,
        toks: &[Token],
        src: &[char],
        ctx: Option<(&[Token], &[Token])>,
    ) -> Option<Lint> {
        let next_word_tok =
            ctx.and_then(|(_, after)| after.get(..2))
                .and_then(|tokens| match tokens {
                    [ws, next, ..] if ws.kind.is_whitespace() => Some(next),
                    _ => None,
                });

        // Exception 1. Have/take a look to see if everything is ok
        if next_word_tok.is_some_and(|nw| nw.kind.is_verb_lemma()) {
            return None;
        }

        // Exception 2. It has a look to it that I don't like
        if next_word_tok.is_some_and(|xyz| xyz.span.get_content(src).eq_ignore_ascii_case_str("it"))
            && toks.first().is_some_and(|tok| {
                tok.span
                    .get_content(src)
                    .eq_any_ignore_ascii_case_str(HAVE_FORMS)
            })
        {
            return None;
        }

        let to_span = toks.last()?.span;

        Some(Lint {
            lint_kind: LintKind::Usage,
            span: to_span,
            suggestions: vec![Suggestion::replace_with_match_case(
                vec!['a', 't'],
                to_span.get_content(src),
            )],
            message: "This phrase uses `to` rather than `at`".to_string(),
            ..Default::default()
        })
    }
}

#[cfg(test)]
mod tests {
    use super::TakeALookTo;
    use crate::linting::tests::{assert_no_lints, assert_suggestion_result};

    #[test]
    fn take_a_look_to_a_new() {
        assert_suggestion_result(
            "Hello, I am Drago and in this video we're going to take a look to a new AI CLI and VS Code extension tool",
            TakeALookTo::default(),
            "Hello, I am Drago and in this video we're going to take a look at a new AI CLI and VS Code extension tool",
        );
    }

    #[test]
    fn have_a_look_to_url() {
        assert_suggestion_result(
            "If you haven't yet, please have a look to https://docs.conan.io/2/devops/devops_local_recipes_index.html",
            TakeALookTo::default(),
            "If you haven't yet, please have a look at https://docs.conan.io/2/devops/devops_local_recipes_index.html",
        );
    }

    #[test]
    fn having_a_look_to_mode() {
        assert_suggestion_result(
            "Having a look to mode and overScaleMode , I see they are scriptable",
            TakeALookTo::default(),
            "Having a look at mode and overScaleMode , I see they are scriptable",
        );
    }

    #[test]
    fn taking_a_look_to_this() {
        assert_suggestion_result(
            "after taking a look to this issue and making some test I figure out that it likely to be an error",
            TakeALookTo::default(),
            "after taking a look at this issue and making some test I figure out that it likely to be an error",
        );
    }

    #[test]
    fn have_had_a_look_to_your() {
        assert_suggestion_result(
            "I have had a look to your conanfile.py and it is strange that it fails.",
            TakeALookTo::default(),
            "I have had a look at your conanfile.py and it is strange that it fails.",
        );
    }

    #[test]
    fn took_a_look_to_both() {
        assert_suggestion_result(
            "Since I have some knowledge in programing I took a look to both codes (LK and XCS)",
            TakeALookTo::default(),
            "Since I have some knowledge in programing I took a look at both codes (LK and XCS)",
        );
    }

    #[test]
    fn taken_a_look_to_that() {
        assert_suggestion_result(
            "Yeah I've taken a look to that, but I really need to use classes on this one",
            TakeALookTo::default(),
            "Yeah I've taken a look at that, but I really need to use classes on this one",
        );
    }

    #[test]
    fn takes_a_look_to_the() {
        assert_suggestion_result(
            "basically, it takes a look to the signing request",
            TakeALookTo::default(),
            "basically, it takes a look at the signing request",
        );
    }

    // Make sure we avoid potential false positives

    #[test]
    fn dont_flag_have_a_look_to_see_if() {
        assert_no_lints(
            "@budarin can you have a look to see if it addresses your concerns?",
            TakeALookTo::default(),
        );
    }

    #[test]
    fn dont_flag_taking_a_look_to_decide() {
        assert_no_lints(
            "Would be worth taking a look to decide which way to go.",
            TakeALookTo::default(),
        );
    }

    #[test]
    fn dont_flag_takes_a_look_to_see() {
        assert_no_lints(
            "It attempts to open the URL in a new window and then after 2s it takes a look to see if it can read the location.",
            TakeALookTo::default(),
        );
    }

    #[test]
    fn dont_flag_has_a_look_to_it() {
        assert_no_lints(
            "The ecosystem's UI certainly has a look to it but inside of your app you could implement a different look as long as it's consistent.",
            TakeALookTo::default(),
        );
    }

    #[test]
    fn but_dont_ignore_takes_a_look_to_it() {
        assert_suggestion_result(
            "When he gets back I hope he takes a look to it",
            TakeALookTo::default(),
            "When he gets back I hope he takes a look at it",
        );
    }
}



================================================
FILE: harper-core/src/linting/take_medicine.rs
================================================
use crate::{
    Token,
    expr::{Expr, OwnedExprExt, SequenceExpr},
    linting::expr_linter::Chunk,
    linting::{ExprLinter, Lint, LintKind, Suggestion},
    patterns::DerivedFrom,
};

pub struct TakeMedicine {
    expr: Box<dyn Expr>,
}

impl Default for TakeMedicine {
    fn default() -> Self {
        let eat_verb = DerivedFrom::new_from_str("eat")
            .or(DerivedFrom::new_from_str("eats"))
            .or(DerivedFrom::new_from_str("ate"))
            .or(DerivedFrom::new_from_str("eating"))
            .or(DerivedFrom::new_from_str("eaten"));

        let medication = DerivedFrom::new_from_str("antibiotic")
            .or(DerivedFrom::new_from_str("medicine"))
            .or(DerivedFrom::new_from_str("medication"))
            .or(DerivedFrom::new_from_str("pill"))
            .or(DerivedFrom::new_from_str("tablet"))
            .or(DerivedFrom::new_from_str("aspirin"))
            .or(DerivedFrom::new_from_str("paracetamol"));

        let modifiers = SequenceExpr::default()
            .then_any_of(vec![
                Box::new(SequenceExpr::default().then_determiner()),
                Box::new(SequenceExpr::default().then_possessive_determiner()),
                Box::new(SequenceExpr::default().then_quantifier()),
            ])
            .t_ws();

        let adjectives = SequenceExpr::default().then_one_or_more_adjectives().t_ws();

        let pattern = SequenceExpr::default()
            .then(eat_verb)
            .t_ws()
            .then_optional(modifiers)
            .then_optional(adjectives)
            .then(medication);

        Self {
            expr: Box::new(pattern),
        }
    }
}

fn replacement_for(
    verb: &Token,
    source: &[char],
    base: &str,
    third_person: &str,
    past: &str,
    past_participle: &str,
    progressive: &str,
) -> Suggestion {
    let replacement = if verb.kind.is_verb_progressive_form() {
        progressive
    } else if verb.kind.is_verb_third_person_singular_present_form() {
        third_person
    } else if verb.kind.is_verb_past_participle_form() && !verb.kind.is_verb_simple_past_form() {
        past_participle
    } else if verb.kind.is_verb_simple_past_form() {
        past
    } else {
        base
    };

    Suggestion::replace_with_match_case(
        replacement.chars().collect(),
        verb.span.get_content(source),
    )
}

impl ExprLinter for TakeMedicine {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], source: &[char]) -> Option<Lint> {
        let verb = matched_tokens.first()?;
        let span = verb.span;

        let suggestions = vec![
            replacement_for(verb, source, "take", "takes", "took", "taken", "taking"),
            replacement_for(
                verb,
                source,
                "swallow",
                "swallows",
                "swallowed",
                "swallowed",
                "swallowing",
            ),
        ];

        Some(Lint {
            span,
            lint_kind: LintKind::Usage,
            suggestions,
            message: "Use a verb like `take` or `swallow` with medicine instead of `eat`."
                .to_string(),
            priority: 63,
        })
    }

    fn description(&self) -> &'static str {
        "Encourages pairing medicine-related nouns with verbs like `take` or `swallow` instead of `eat`."
    }
}

#[cfg(test)]
mod tests {
    use super::TakeMedicine;
    use crate::linting::tests::{
        assert_lint_count, assert_nth_suggestion_result, assert_suggestion_result,
    };

    #[test]
    fn swaps_ate_antibiotics() {
        assert_suggestion_result(
            "I ate antibiotics for a week.",
            TakeMedicine::default(),
            "I took antibiotics for a week.",
        );
    }

    #[test]
    fn swaps_eat_medicine() {
        assert_suggestion_result(
            "You should eat the medicine now.",
            TakeMedicine::default(),
            "You should take the medicine now.",
        );
    }

    #[test]
    fn swaps_eats_medication() {
        assert_suggestion_result(
            "She eats medication daily.",
            TakeMedicine::default(),
            "She takes medication daily.",
        );
    }

    #[test]
    fn swaps_eating_medicines() {
        assert_suggestion_result(
            "Are you eating medicines for that illness?",
            TakeMedicine::default(),
            "Are you taking medicines for that illness?",
        );
    }

    #[test]
    fn swaps_eaten_medication() {
        assert_suggestion_result(
            "He has eaten medication already.",
            TakeMedicine::default(),
            "He has taken medication already.",
        );
    }

    #[test]
    fn swaps_eat_pills() {
        assert_suggestion_result(
            "He ate the pills without water.",
            TakeMedicine::default(),
            "He took the pills without water.",
        );
    }

    #[test]
    fn swaps_eating_paracetamol() {
        assert_suggestion_result(
            "She is eating paracetamol for her headache.",
            TakeMedicine::default(),
            "She is taking paracetamol for her headache.",
        );
    }

    #[test]
    fn handles_possessive_modifier() {
        assert_suggestion_result(
            "Please eat my antibiotics.",
            TakeMedicine::default(),
            "Please take my antibiotics.",
        );
    }

    #[test]
    fn handles_adjectives() {
        assert_suggestion_result(
            "They ate the prescribed antibiotics.",
            TakeMedicine::default(),
            "They took the prescribed antibiotics.",
        );
    }

    #[test]
    fn supports_uppercase() {
        assert_suggestion_result(
            "Eat antibiotics with water.",
            TakeMedicine::default(),
            "Take antibiotics with water.",
        );
    }

    #[test]
    fn offers_swallow_alternative() {
        assert_nth_suggestion_result(
            "He ate the medication without water.",
            TakeMedicine::default(),
            "He swallowed the medication without water.",
            1,
        );
    }

    #[test]
    fn ignores_correct_usage() {
        assert_lint_count(
            "She took antibiotics last winter.",
            TakeMedicine::default(),
            0,
        );
    }

    #[test]
    fn ignores_unrelated_eat() {
        assert_lint_count(
            "They ate dinner after taking medicine.",
            TakeMedicine::default(),
            0,
        );
    }
}



================================================
FILE: harper-core/src/linting/take_serious.rs
================================================
use crate::linting::expr_linter::Chunk;
use crate::{
    Token, TokenStringExt,
    expr::{Expr, SequenceExpr},
    linting::{ExprLinter, Lint, LintKind, Suggestion},
    patterns::{NominalPhrase, WordSet},
};

/// Linter that corrects "take X serious" to "take X seriously".
///
/// This linter identifies and corrects the common mistake of using the adjective "serious"
/// instead of the adverb "seriously" in phrases like "take it serious".
pub struct TakeSerious {
    expr: Box<dyn Expr>,
}

impl Default for TakeSerious {
    /// Creates a new `TakeSerious` instance with the default pattern.
    ///
    /// The pattern matches:
    /// - Any form of "take" (take/takes/taking/took/taken)
    /// - Followed by a nominal phrase
    /// - Ending with "serious"
    fn default() -> Self {
        let pattern = SequenceExpr::default()
            .then(WordSet::new(&["take", "taken", "takes", "taking", "took"]))
            .t_ws()
            .then(NominalPhrase)
            .t_ws()
            .t_aco("serious");

        Self {
            expr: Box::new(pattern),
        }
    }
}

impl ExprLinter for TakeSerious {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], source: &[char]) -> Option<Lint> {
        let whole_phrase_span = matched_tokens.span()?;
        let all_but_last_token = matched_tokens[..matched_tokens.len() - 1].span()?;

        let mut sugg_value = all_but_last_token.get_content(source).to_vec();
        sugg_value.extend_from_slice(&['s', 'e', 'r', 'i', 'o', 'u', 's', 'l', 'y']);

        let sugg_template = whole_phrase_span.get_content(source);

        let suggestions = vec![Suggestion::replace_with_match_case(
            sugg_value,
            sugg_template,
        )];

        Some(Lint {
            span: whole_phrase_span,
            lint_kind: LintKind::WordChoice,
            suggestions,
            message: "Take seriously".to_string(),
            priority: 63,
        })
    }

    fn description(&self) -> &'static str {
        "Ensures the correct use of the adverb `seriously` instead of the adjective `serious` in phrases like `take it seriously`."
    }
}

#[cfg(test)]
mod tests {
    use crate::linting::tests::assert_suggestion_result;

    use super::TakeSerious;

    #[test]
    fn take_it() {
        assert_suggestion_result(
            "I take it serious.",
            TakeSerious::default(),
            "I take it seriously.",
        );
    }

    #[test]
    #[ignore = "'This' and 'that', which can be determiners and pronouns, are not handled properly by `NominalPhrase`"]
    fn take_this() {
        assert_suggestion_result(
            "What's more important is, that it's impossible to actually take this serious when ...",
            TakeSerious::default(),
            "What's more important is, that it's impossible to actually take this seriously when ...",
        );
    }

    #[test]
    fn not_take_security() {
        assert_suggestion_result(
            "When you say someone does not take security serious you are being judgemental / destructive.",
            TakeSerious::default(),
            "When you say someone does not take security seriously you are being judgemental / destructive.",
        );
    }

    #[test]
    fn we_take_security() {
        assert_suggestion_result(
            "We take security serious.",
            TakeSerious::default(),
            "We take security seriously.",
        );
    }

    #[test]
    fn take_me() {
        assert_suggestion_result(
            "Yeah , don't take me serious , i do this as a hobby - jusspatel.",
            TakeSerious::default(),
            "Yeah , don't take me seriously , i do this as a hobby - jusspatel.",
        );
    }

    #[test]
    #[ignore = "Passive voice and adverbs are not yet supported"]
    fn taken_adv() {
        assert_suggestion_result(
            "This is not meant to be taken overly serious",
            TakeSerious::default(),
            "This is not meant to be taken overly seriously",
        );
    }

    #[test]
    fn takes_these_numbers() {
        assert_suggestion_result(
            "if a program actually takes these numbers serious the results could be catastrophic.",
            TakeSerious::default(),
            "if a program actually takes these numbers seriously the results could be catastrophic.",
        );
    }

    #[test]
    #[ignore = "'No one' is not handled properly by `NominalPhrase`"]
    fn takes_bf() {
        assert_suggestion_result(
            "And obviously no one takes brainfuck serious as a language.",
            TakeSerious::default(),
            "And obviously no one takes brainfuck seriously as a language.",
        );
    }

    #[test]
    #[ignore = "Adverbs are not yet supported"]
    fn taken_very() {
        assert_suggestion_result(
            "Hmm flaky soldering iron is something that must be taken very serious.",
            TakeSerious::default(),
            "Hmm flaky soldering iron is something that must be taken very seriously.",
        );
    }
}



================================================
FILE: harper-core/src/linting/that_than.rs
================================================
use crate::linting::expr_linter::Chunk;
use crate::{
    Token, TokenKind,
    expr::{Expr, SequenceExpr},
    linting::{ExprLinter, Lint, LintKind, Suggestion},
};

pub struct ThatThan {
    expr: Box<dyn Expr>,
}

impl Default for ThatThan {
    fn default() -> Self {
        let adjective_er_that_nextword = SequenceExpr::default()
            .then_kind_except(
                TokenKind::is_comparative_adjective,
                &["better", "later", "number"],
            )
            .t_ws()
            .t_aco("that")
            .t_ws()
            .then_word_except(&["way"]);

        Self {
            expr: Box::new(adjective_er_that_nextword),
        }
    }
}

impl ExprLinter for ThatThan {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, toks: &[Token], src: &[char]) -> Option<Lint> {
        if toks.len() != 5 {
            return None;
        }

        let that_tok = &toks[2];

        Some(Lint {
            span: that_tok.span,
            lint_kind: LintKind::Typo,
            suggestions: vec![Suggestion::replace_with_match_case_str(
                "than",
                that_tok.span.get_content(src),
            )],
            message: "This looks like a comparison that should use `than` rather than `that`."
                .to_string(),
            priority: 31,
        })
    }

    fn description(&self) -> &'static str {
        "Corrects the typo `that` to `than` in comparisons."
    }
}

#[cfg(test)]
mod tests {
    use super::ThatThan;
    use crate::linting::tests::{assert_lint_count, assert_suggestion_result};

    // adj-er that

    #[test]
    fn fix_slower_that() {
        assert_suggestion_result(
            "Local installed PHAR 5x times slower that the same PHAR installed globally",
            ThatThan::default(),
            "Local installed PHAR 5x times slower than the same PHAR installed globally",
        );
    }

    #[test]
    fn dont_flag_more_that() {
        assert_lint_count(
            "so it's probably more that Croatian had an easier test",
            ThatThan::default(),
            0,
        );
    }

    #[test]
    fn dont_flag_easier_that_way() {
        assert_lint_count(
            "Given svelte now has signals, it might actually be easier that way.",
            ThatThan::default(),
            0,
        );
    }

    #[test]
    fn dont_flag_better_that() {
        assert_lint_count(
            "So I am wondering if its better that I run SCENIC+ once on the integrated dataset or 3 times on the individual datasets",
            ThatThan::default(),
            0,
        );
    }

    #[test]
    #[ignore = "not handled because 'better' results in false positives"]
    fn fix_better_that() {
        assert_suggestion_result(
            "Examples of how different cards perform far better that others.",
            ThatThan::default(),
            "Examples of how different cards perform far better than others.",
        );
    }

    #[test]
    fn fix_smaller_that() {
        assert_suggestion_result(
            "When the resulting part is smaller that the build plate, it gets re-arranged.",
            ThatThan::default(),
            "When the resulting part is smaller than the build plate, it gets re-arranged.",
        );
    }

    #[test]
    #[ignore = "not handled because 'bigger' results in false positives"]
    fn cant_flag_bigger_that() {
        assert_suggestion_result(
            "Enable bigger that 1024*768 window for world builder.",
            ThatThan::default(),
            "Enable bigger than 1024*768 window for world builder.",
        );
    }

    #[test]
    fn fix_longer_that() {
        assert_suggestion_result(
            "Window list in CodeBrowser can be longer that screen height.",
            ThatThan::default(),
            "Window list in CodeBrowser can be longer than screen height.",
        );
    }

    #[test]
    #[ignore = "'less that' also occurs in false positives"]
    fn fix_less_that() {
        assert_suggestion_result(
            "Collector Not collecting metrics if the collection interval is less that the metric generation interval.",
            ThatThan::default(),
            "Collector Not collecting metrics if the collection interval is less than the metric generation interval.",
        );
    }

    #[test]
    fn fix_faster_that() {
        assert_suggestion_result(
            "with the general case performing approximately 4x faster that a Vec based implementation",
            ThatThan::default(),
            "with the general case performing approximately 4x faster than a Vec based implementation",
        );
    }

    #[test]
    fn fix_taller_that() {
        assert_suggestion_result(
            "Notice that people we've already placed are not taller that the current person.",
            ThatThan::default(),
            "Notice that people we've already placed are not taller than the current person.",
        );
    }

    #[test]

    fn dont_fix_faster_that_way() {
        assert_lint_count(
            "You will get an answer quicker that way!",
            ThatThan::default(),
            0,
        )
    }

    #[test]
    fn dont_fix_lighter_that() {
        assert_lint_count(
            "This is the code for Seed-Studio-based timer and desk lighter that I built as a gift for a good friend.",
            ThatThan::default(),
            0,
        )
    }

    // more/less adj that

    #[test]
    fn dont_flag_more_explicit_that() {
        assert_lint_count(
            "make it more explicit that those files are auto ...",
            ThatThan::default(),
            0,
        );
    }

    #[test]
    fn dont_flag_more_clear_that() {
        assert_lint_count(
            "Make it more clear that users need to download the VS tooling installer for .NET Core in VS.",
            ThatThan::default(),
            0,
        );
    }

    // False positives from The Great Gatsby

    #[test]
    fn dont_flag_i_gathered_later_that() {
        assert_lint_count(
            "and I gathered later that he was a photographer",
            ThatThan::default(),
            0,
        );
    }

    #[test]
    fn dont_flag_its_better_that() {
        assert_lint_count(
            "It’s better that the shock should all come at once.",
            ThatThan::default(),
            0,
        )
    }

    #[test]
    fn dont_flag_number_that_1663() {
        assert_lint_count(
            " 455 │ `MAJOR.MINOR.PATCH` version number that increments with:",
            ThatThan::default(),
            0,
        )
    }
}



================================================
FILE: harper-core/src/linting/that_which.rs
================================================
use crate::expr::Expr;
use crate::expr::SequenceExpr;
use crate::expr::WordExprGroup;
use itertools::Itertools;

use crate::{Lrc, Token, TokenStringExt};

use super::{ExprLinter, Lint, LintKind, Suggestion};
use crate::linting::expr_linter::Chunk;

pub struct ThatWhich {
    expr: Box<dyn Expr>,
}

impl Default for ThatWhich {
    fn default() -> Self {
        let mut pattern = WordExprGroup::default();

        let matching_pattern = Lrc::new(
            SequenceExpr::default()
                .then_any_capitalization_of("that")
                .then_whitespace()
                .then_any_capitalization_of("that"),
        );

        pattern.add("that", matching_pattern.clone());
        pattern.add("That", matching_pattern);

        Self {
            expr: Box::new(pattern),
        }
    }
}

impl ExprLinter for ThatWhich {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], source: &[char]) -> Option<Lint> {
        let suggestion = format!(
            "{} which",
            matched_tokens[0]
                .span
                .get_content(source)
                .iter()
                .collect::<String>()
        )
        .chars()
        .collect_vec();

        Some(Lint {
            span: matched_tokens.span()?,
            lint_kind: LintKind::Repetition,
            suggestions: vec![Suggestion::ReplaceWith(suggestion)],
            message: "“that that” sometimes means “that which”, which is clearer.".to_string(),
            priority: 126,
        })
    }

    fn description(&self) -> &'static str {
        "Repeating the word \"that\" is often redundant. The phrase `that which` is easier to read."
    }
}

#[cfg(test)]
mod tests {
    use super::super::tests::assert_lint_count;
    use super::ThatWhich;

    #[test]
    fn catches_lowercase() {
        assert_lint_count(
            "To reiterate, that that is cool is not uncool.",
            ThatWhich::default(),
            1,
        );
    }

    #[test]
    fn catches_different_cases() {
        assert_lint_count("That that is cool is not uncool.", ThatWhich::default(), 1);
    }

    #[test]
    fn likes_correction() {
        assert_lint_count(
            "To reiterate, that which is cool is not uncool.",
            ThatWhich::default(),
            0,
        );
    }
}



================================================
FILE: harper-core/src/linting/the_how_why.rs
================================================
use crate::expr::Expr;
use crate::expr::FirstMatchOf;
use crate::expr::SequenceExpr;
use crate::linting::expr_linter::Chunk;
use crate::{
    Token, TokenStringExt,
    linting::{ExprLinter, Lint, LintKind, Suggestion},
};

/// Suggests removing `the` when followed by how/why/who/when/what,
/// skipping cases like `how to` and `who's who`.
pub struct TheHowWhy {
    expr: FirstMatchOf,
}

impl Default for TheHowWhy {
    fn default() -> Self {
        let the_how = SequenceExpr::default()
            .t_aco("the")
            .then_whitespace()
            .t_aco("how")
            .then_unless(SequenceExpr::default().then_whitespace().t_aco("to"));

        let the_who = SequenceExpr::default()
            .t_aco("the")
            .then_whitespace()
            .t_aco("who")
            .then_unless(
                SequenceExpr::default()
                    .then_whitespace()
                    .t_aco("'s")
                    .then_whitespace()
                    .t_aco("who"),
            );

        let the_why = SequenceExpr::default()
            .t_aco("the")
            .then_whitespace()
            .t_aco("why");

        let the_when = SequenceExpr::default()
            .t_aco("the")
            .then_whitespace()
            .t_aco("when");

        let the_what = SequenceExpr::default()
            .t_aco("the")
            .then_whitespace()
            .t_aco("what");

        let expr = FirstMatchOf::new(vec![
            Box::new(the_how),
            Box::new(the_who),
            Box::new(the_why),
            Box::new(the_when),
            Box::new(the_what),
        ]);

        Self { expr }
    }
}

impl ExprLinter for TheHowWhy {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        &self.expr
    }

    fn match_to_lint(&self, matched_tokens: &[Token], source: &[char]) -> Option<Lint> {
        let the_token_span = matched_tokens[0..2].span()?;
        let question_word_token = matched_tokens.get(2)?;
        let question_word = question_word_token.span.get_content(source);

        Some(Lint {
            span: the_token_span,
            lint_kind: LintKind::Miscellaneous,
            message: format!(
                "Remove `the` before `{}`. In most contexts, `{}` alone is clearer.",
                question_word.iter().collect::<String>(),
                question_word.iter().collect::<String>()
            ),
            suggestions: vec![Suggestion::Remove],
            priority: 31,
        })
    }

    fn description(&self) -> &str {
        "Removes the extra `the` from expressions like `the how`, skipping `how to` and `who's who`."
    }
}

#[cfg(test)]
mod tests {
    use super::TheHowWhy;
    use crate::linting::tests::{assert_lint_count, assert_suggestion_result};

    #[test]
    fn basic_the_how() {
        assert_suggestion_result(
            "This is the how it all started.",
            TheHowWhy::default(),
            "This is how it all started.",
        );
    }

    #[test]
    fn the_why() {
        assert_suggestion_result(
            "The important part is the why it matters.",
            TheHowWhy::default(),
            "The important part is why it matters.",
        );
    }

    #[test]
    fn skip_how_to() {
        assert_lint_count(
            "I'd like to explain the how to install this properly.",
            TheHowWhy::default(),
            0,
        );
    }

    #[test]
    fn skip_whos_who() {
        assert_lint_count(
            "We covered the who's who of corporate leadership last time.",
            TheHowWhy::default(),
            0,
        );
    }

    #[test]
    fn the_who() {
        assert_suggestion_result(
            "We must identify the who is responsible.",
            TheHowWhy::default(),
            "We must identify who is responsible.",
        );
    }

    #[test]
    fn the_when() {
        assert_suggestion_result(
            "He outlined the when the new phase will start.",
            TheHowWhy::default(),
            "He outlined when the new phase will start.",
        );
    }

    #[test]
    fn the_what() {
        assert_suggestion_result(
            "The presentation clarifies the what we intend to build.",
            TheHowWhy::default(),
            "The presentation clarifies what we intend to build.",
        );
    }

    #[test]
    fn no_false_positive() {
        assert_lint_count(
            "These tips examine the how to fix your code quickly, plus the what's next.",
            TheHowWhy::default(),
            0,
        );
    }
}



================================================
FILE: harper-core/src/linting/the_my.rs
================================================
use super::{ExprLinter, Lint, LintKind, Suggestion};
use crate::expr::Expr;
use crate::expr::FirstMatchOf;
use crate::expr::SequenceExpr;
use crate::linting::expr_linter::Chunk;
use crate::{
    CharStringExt, Token, TokenStringExt,
    patterns::{Word, WordSet},
};

pub struct TheMy {
    expr: Box<dyn Expr>,
}

impl Default for TheMy {
    fn default() -> Self {
        let the = Word::new("the");
        let any_possessive = WordSet::new(&["my", "your", "his", "her", "its", "our", "their"]);

        let the_poss = SequenceExpr::default()
            .then(the.clone())
            .then_whitespace()
            .then(any_possessive.clone());

        let poss_the = SequenceExpr::default()
            .then(any_possessive)
            .then_whitespace()
            .then(the);

        Self {
            expr: Box::new(FirstMatchOf::new(vec![
                Box::new(the_poss),
                Box::new(poss_the),
            ])),
        }
    }
}

impl ExprLinter for TheMy {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], source: &[char]) -> Option<Lint> {
        let span = matched_tokens.span().unwrap();
        let span_content = span.get_content(source);

        let first_word = matched_tokens[0].span.get_content(source);
        let second_word = matched_tokens[2].span.get_content(source);

        let first_word_string: String = first_word.to_string();

        let possessive = if first_word_string.eq_ignore_ascii_case("the") {
            second_word
        } else {
            first_word
        };

        // Don't flag "the My" or "my The" since they could be titles of things
        if second_word[0].is_uppercase() {
            return None;
        }

        // Don't flag "her the" since her is also the object case pronoun: "give her the book"
        if first_word_string.eq_ignore_ascii_case("her") {
            return None;
        }

        let suggestions = vec![
            Suggestion::replace_with_match_case(possessive.to_vec(), span_content),
            Suggestion::replace_with_match_case("the".chars().collect(), span_content),
        ];

        Some(Lint {
            span,
            lint_kind: LintKind::Repetition,
            suggestions,
            message: "Use either the definite article 'the' or the possessive. Using both together is ungrammatical in English.".to_owned(),
            priority: 127,
        })
    }

    fn description(&self) -> &'static str {
        "Flags the definite article used together with a possessive."
    }
}

#[cfg(test)]
mod tests {
    use super::TheMy;
    use crate::linting::tests::{
        assert_lint_count, assert_nth_suggestion_result, assert_suggestion_result,
    };

    #[test]
    fn correct_the_my_atomic_lowercase() {
        assert_suggestion_result("the my", TheMy::default(), "my");
    }

    #[test]
    fn correct_the_my_atomic_2nd_suggestion() {
        assert_nth_suggestion_result("the my", TheMy::default(), "the", 1);
    }

    #[test]
    fn correct_the_my_atomic_uppercase() {
        assert_suggestion_result("The my", TheMy::default(), "My");
    }

    #[test]
    fn correct_my_the_atomic_lowercase() {
        assert_suggestion_result("my the", TheMy::default(), "my");
    }

    #[test]
    fn correct_my_the_atomic_2nd_suggestion() {
        assert_nth_suggestion_result("my the", TheMy::default(), "the", 1);
    }

    #[test]
    fn correct_my_the_atomic_uppercase() {
        assert_suggestion_result("My the", TheMy::default(), "My");
    }

    #[test]
    fn dont_correct_capitalized_possessive() {
        assert_lint_count("For some time the My Projects personal page was \"sluggish\" or took some time to generate the miniature depicting the project, now it seems completely stuck ...
", TheMy::default(), 0);
    }

    #[test]
    fn correct_the_my_github() {
        assert_suggestion_result(
            "When I try to configure the my react-native app to support koltin file, this library gives these errors",
            TheMy::default(),
            "When I try to configure my react-native app to support koltin file, this library gives these errors",
        );
    }

    #[test]
    fn correct_the_our_github() {
        assert_suggestion_result(
            "Source codes of the our paper titled \"Multi-level Textual-Visual Alignment and Fusion Network for Multimodal Aspect-based Sentiment Analysis\"",
            TheMy::default(),
            "Source codes of our paper titled \"Multi-level Textual-Visual Alignment and Fusion Network for Multimodal Aspect-based Sentiment Analysis\"",
        );
    }

    #[test]
    fn correct_the_their_github() {
        assert_suggestion_result(
            "the slider cannot render when i use again the their component on NextJS app",
            TheMy::default(),
            "the slider cannot render when i use again their component on NextJS app",
        );
    }

    #[test]
    fn correct_your_the_github() {
        assert_suggestion_result(
            "This plugin allows you to view your the information about order and customer from your spree store on zendesk",
            TheMy::default(),
            "This plugin allows you to view your information about order and customer from your spree store on zendesk",
        );
    }

    #[test]
    fn correct_my_the_github() {
        assert_suggestion_result(
            "Scripts used my the project to collect, process and store social media data from a number of sources",
            TheMy::default(),
            "Scripts used my project to collect, process and store social media data from a number of sources",
        );
    }

    #[test]
    fn dont_correct_the_your_github() {
        assert_lint_count(
            "What exactly is the sort order of list names on the Your Stars page?",
            TheMy::default(),
            0,
        );
    }

    #[test]
    fn dont_correct_my_the_github() {
        assert_lint_count(
            "My The Frame TV is not pulling information properly",
            TheMy::default(),
            0,
        )
    }

    #[test]
    fn correct_our_the_github() {
        assert_suggestion_result(
            "Companion Repository to our the whitepaper \"Towards Reliable and Scalable Linux Kernel CVE Attribution in Automated Static Firmware Analyses\"",
            TheMy::default(),
            "Companion Repository to our whitepaper \"Towards Reliable and Scalable Linux Kernel CVE Attribution in Automated Static Firmware Analyses\"",
        )
    }

    #[test]
    fn correct_their_the_github() {
        assert_suggestion_result(
            "Types exported by @_exported remember only their the original module",
            TheMy::default(),
            "Types exported by @_exported remember only their original module",
        )
    }

    #[test]
    fn dont_correct_her_the_github() {
        assert_lint_count(
            "Create an admin role for boba-tan and give her the GoreMaster role only in !gore",
            TheMy::default(),
            0,
        )
    }

    #[test]
    fn correct_the_his_github() {
        assert_suggestion_result(
            "Allows the user to specify the his last name.",
            TheMy::default(),
            "Allows the user to specify his last name.",
        )
    }

    #[test]
    fn correct_his_the_github() {
        assert_suggestion_result(
            "One interesting creation was his the Schelling segregation model",
            TheMy::default(),
            "One interesting creation was his Schelling segregation model",
        )
    }

    #[test]
    fn correct_the_her_github() {
        assert_suggestion_result(
            "In memory of the occasion when our Queen Victoria graciously came to see our Island, and the her Royal Consort Albert landed at Ramsey",
            TheMy::default(),
            "In memory of the occasion when our Queen Victoria graciously came to see our Island, and her Royal Consort Albert landed at Ramsey",
        )
    }
}



================================================
FILE: harper-core/src/linting/the_proper_noun_possessive.rs
================================================
use crate::{
    CharStringExt, Lint, Token, TokenStringExt,
    expr::{Expr, SequenceExpr},
    linting::{ExprLinter, LintKind, Suggestion, expr_linter::Chunk},
};

pub struct TheProperNounPossessive {
    expr: Box<dyn Expr>,
}

impl Default for TheProperNounPossessive {
    fn default() -> Self {
        Self {
            expr: Box::new(
                SequenceExpr::aco("the")
                    .t_ws()
                    .then(|t: &Token, s: &[char]| {
                        // TODO: should use `k.is_proper_noun()` when #2327 is fixed
                        // TODO: should use `k.is_common_noun()` which doesn't exist yet
                        t.kind.is_possessive_noun()
                            && t.kind.is_titlecase()
                            && !t.kind.is_lowercase()
                            && !t
                                .span
                                .get_content(s)
                                .eq_any_ignore_ascii_case_str(&["internet's", "internet’s"])
                    }),
            ),
        }
    }
}

impl ExprLinter for TheProperNounPossessive {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, toks: &[Token], _: &[char]) -> Option<Lint> {
        Some(Lint {
            span: toks[..2].span()?,
            lint_kind: LintKind::Redundancy,
            suggestions: vec![Suggestion::Remove],
            message:
                "The definite article `the` is redundant before a proper noun in the possessive."
                    .to_string(),
            ..Default::default()
        })
    }

    fn description(&self) -> &str {
        "Checks for redundant `the` before possessive proper noun such as `The London's population`."
    }
}

#[cfg(test)]
mod tests {
    use crate::linting::{
        tests::{assert_no_lints, assert_suggestion_result},
        the_proper_noun_possessive::TheProperNounPossessive,
    };

    #[test]
    fn fix_the_putins_war() {
        assert_suggestion_result(
            "The Putin's war",
            TheProperNounPossessive::default(),
            "Putin's war",
        );
    }

    #[test]
    fn fix_the_londons_population() {
        assert_suggestion_result(
            "The London's population.",
            TheProperNounPossessive::default(),
            "London's population.",
        )
    }

    #[test]
    fn dont_flag_common_noun_in_titlecase() {
        assert_no_lints("The Dog's Dinner", TheProperNounPossessive::default())
    }

    #[test]
    #[ignore = "Can't currently do this due to issue #???"]
    fn fix_proper_noun_stylized_to_begin_lowercase() {
        assert_suggestion_result(
            "The macOS's Finder",
            TheProperNounPossessive::default(),
            "macOS's Finder",
        );
    }

    #[test]
    fn fix_even_when_capitalisation_omitted() {
        assert_suggestion_result(
            "the egypt's pyramids",
            TheProperNounPossessive::default(),
            "egypt's pyramids",
        )
    }

    #[test]
    fn dont_flag_proper_noun_thats_also_common_noun() {
        assert_no_lints("the china's broken", TheProperNounPossessive::default());
    }

    #[test]
    fn dont_flag_the_internets() {
        assert_no_lints(
            "The internet's most popular icon toolkit has been redesigned",
            TheProperNounPossessive::default(),
        );
    }

    #[test]
    fn dont_flag_the_internets_curly_apostrophe() {
        assert_no_lints(
            "The internet’s most popular icon toolkit has been redesigned",
            TheProperNounPossessive::default(),
        );
    }
}



================================================
FILE: harper-core/src/linting/then_than.rs
================================================
use super::{ExprLinter, Lint, LintKind};
use crate::expr::{All, Expr, FirstMatchOf, FixedPhrase, SequenceExpr};
use crate::linting::Suggestion;
use crate::linting::expr_linter::Chunk;
use crate::patterns::{Invert, Word, WordSet};
use crate::{CharStringExt, Token, TokenKind};

/// Corrects the misuse of `then` to `than`.
pub struct ThenThan {
    expr: Box<dyn Expr>,
}

impl ThenThan {
    pub fn new() -> Self {
        let comparison = All::new(vec![
            Box::new(FirstMatchOf::new(vec![
                // Comparative form of adjective
                Box::new(
                    SequenceExpr::default()
                        .then(Box::new(|tok: &Token, source: &[char]| {
                            is_comparative(tok, source)
                        }))
                        .t_ws()
                        .t_aco("then")
                        .t_ws()
                        .then_unless(Word::new("that")),
                ),
                // Positive form of adjective following "more" or "less"
                Box::new(
                    SequenceExpr::default()
                        .then(WordSet::new(&["more", "less"]))
                        .t_ws()
                        .then_kind_either(TokenKind::is_adjective, TokenKind::is_adverb)
                        .t_ws()
                        .t_aco("then")
                        .t_ws()
                        .then_unless(Word::new("that")),
                ),
            ])),
            // Exceptions to the rule.
            Box::new(Invert::new(WordSet::new(&["back", "this", "so", "but"]))),
        ]);

        Self {
            expr: Box::new(FirstMatchOf::new(vec![
                Box::new(comparison),
                Box::new(FixedPhrase::from_phrase("easier said then done")),
                Box::new(FixedPhrase::from_phrase("now and than")),
                Box::new(FixedPhrase::from_phrase("other then")),
                Box::new(FixedPhrase::from_phrase("rather then")),
                Box::new(FixedPhrase::from_phrase("than again")),
                Box::new(FixedPhrase::from_phrase("until than")),
            ])),
        }
    }
}

fn is_comparative(tok: &Token, source: &[char]) -> bool {
    tok.kind.is_comparative_adjective()
        || tok
            .span
            .get_content(source)
            .eq_any_ignore_ascii_case_chars(&[&['l', 'e', 's', 's'], &['m', 'o', 'r', 'e']])
}

impl Default for ThenThan {
    fn default() -> Self {
        Self::new()
    }
}

impl ExprLinter for ThenThan {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], source: &[char]) -> Option<Lint> {
        let mut thans_and_thens = matched_tokens.iter().filter(|tok| {
            tok.span
                .get_content(source)
                .eq_any_ignore_ascii_case_chars(&[&['t', 'h', 'a', 'n'], &['t', 'h', 'e', 'n']])
        });

        // Get the first match and ensure there's exactly one
        let span = match (thans_and_thens.next(), thans_and_thens.next()) {
            (Some(token), None) => token.span,
            _ => return None,
        };

        let offending_text = span.get_content(source);

        let new_text = if offending_text.eq_ignore_ascii_case_chars(&['t', 'h', 'e', 'n']) {
            "than"
        } else {
            "then"
        };

        Some(Lint {
            span,
            lint_kind: LintKind::Miscellaneous,
            suggestions: vec![Suggestion::replace_with_match_case(
                new_text.chars().collect(),
                offending_text,
            )],
            message: format!("Did you mean `{new_text}`?"),
            priority: 31,
        })
    }
    fn description(&self) -> &'static str {
        "Corrects mixing up `then` and `than`."
    }
}

#[cfg(test)]
mod tests {
    use super::ThenThan;
    use crate::linting::tests::{assert_lint_count, assert_suggestion_result};

    #[test]
    fn allows_back_then() {
        assert_lint_count("I was a gross kid back then.", ThenThan::default(), 0);
    }

    #[test]
    fn catches_shorter_then() {
        assert_suggestion_result(
            "One was shorter then the other.",
            ThenThan::default(),
            "One was shorter than the other.",
        );
    }

    #[test]
    fn catches_better_then() {
        assert_suggestion_result(
            "One was better then the other.",
            ThenThan::default(),
            "One was better than the other.",
        );
    }

    #[test]
    fn catches_longer_then() {
        assert_suggestion_result(
            "One was longer then the other.",
            ThenThan::default(),
            "One was longer than the other.",
        );
    }

    #[test]
    fn catches_less_then() {
        assert_suggestion_result(
            "I eat less then you.",
            ThenThan::default(),
            "I eat less than you.",
        );
    }

    #[test]
    fn catches_more_then() {
        assert_suggestion_result(
            "I eat more then you.",
            ThenThan::default(),
            "I eat more than you.",
        );
    }

    #[test]
    fn stronger_should_change() {
        assert_suggestion_result(
            "a chain is no stronger then its weakest link",
            ThenThan::default(),
            "a chain is no stronger than its weakest link",
        );
    }

    #[test]
    fn half_a_loaf_should_change() {
        assert_suggestion_result(
            "half a loaf is better then no bread",
            ThenThan::default(),
            "half a loaf is better than no bread",
        );
    }

    #[test]
    fn then_everyone_clapped_should_be_allowed() {
        assert_lint_count("and then everyone clapped", ThenThan::default(), 0);
    }

    #[test]
    fn crazier_than_rat_should_change() {
        assert_suggestion_result(
            "crazier then a shithouse rat",
            ThenThan::default(),
            "crazier than a shithouse rat",
        );
    }

    #[test]
    fn poke_in_eye_should_change() {
        assert_suggestion_result(
            "better then a poke in the eye with a sharp stick",
            ThenThan::default(),
            "better than a poke in the eye with a sharp stick",
        );
    }

    #[test]
    fn other_then_should_change() {
        assert_suggestion_result(
            "There was no one other then us at the campsite.",
            ThenThan::default(),
            "There was no one other than us at the campsite.",
        );
    }

    #[test]
    fn allows_and_then() {
        assert_lint_count("And then we left.", ThenThan::default(), 0);
    }

    #[test]
    fn allows_this_then() {
        assert_lint_count("Do this then that.", ThenThan::default(), 0);
    }

    #[test]
    fn allows_issue_720() {
        assert_lint_count(
            "And if just one of those is set incorrectly or it has the tiniest bit of dirt inside then that will wreak havoc with the engine's running ability.",
            ThenThan::default(),
            0,
        );
        assert_lint_count("So let's check it out then.", ThenThan::default(), 0);
        assert_lint_count(
            "And if just the tiniest bit of dirt gets inside then that will wreak havoc.",
            ThenThan::default(),
            0,
        );

        assert_lint_count(
            "He was always a top student in school but then his argument is that grades don't define intelligence.",
            ThenThan::default(),
            0,
        );
    }

    #[test]
    fn allows_issue_744() {
        assert_lint_count(
            "So then after talking about how he would, he didn't.",
            ThenThan::default(),
            0,
        );
    }

    #[test]
    fn issue_720_school_but_then_his() {
        assert_lint_count(
            "She loved the atmosphere of the school but then his argument is that it lacks proper resources for students.",
            ThenThan::default(),
            0,
        );
        assert_lint_count(
            "The teacher praised the efforts of the school but then his argument is that the curriculum needs to be updated.",
            ThenThan::default(),
            0,
        );
        assert_lint_count(
            "They were excited about the new program at school but then his argument is that it won't be effective without proper training.",
            ThenThan::default(),
            0,
        );
        assert_lint_count(
            "The community supported the school but then his argument is that funding is still a major issue.",
            ThenThan::default(),
            0,
        );
    }

    #[test]
    fn issue_720_so_then_these_resistors() {
        assert_lint_count(
            "So then these resistors are connected up in parallel to reduce the overall resistance.",
            ThenThan::default(),
            0,
        );
        assert_lint_count(
            "So then these resistors are connected up to ensure the current flows properly.",
            ThenThan::default(),
            0,
        );
        assert_lint_count(
            "So then these resistors are connected up to achieve the desired voltage drop.",
            ThenThan::default(),
            0,
        );
        assert_lint_count(
            "So then these resistors are connected up to demonstrate the principles of series and parallel circuits.",
            ThenThan::default(),
            0,
        );
        assert_lint_count(
            "So then these resistors are connected up to optimize the circuit's performance.",
            ThenThan::default(),
            0,
        );
    }

    #[test]
    fn issue_720_yes_so_then_sorry() {
        assert_lint_count(
            "Yes so then sorry you didn't receive the memo about the meeting changes.",
            ThenThan::default(),
            0,
        );
        assert_lint_count(
            "Yes so then sorry you had to wait so long for a response from our team.",
            ThenThan::default(),
            0,
        );
        assert_lint_count(
            "Yes so then sorry you felt left out during the discussion; we value your input.",
            ThenThan::default(),
            0,
        );
        assert_lint_count(
            "Yes so then sorry you missed the deadline; we can discuss an extension.",
            ThenThan::default(),
            0,
        );
        assert_lint_count(
            "Yes so then sorry you encountered issues with the software; let me help you troubleshoot.",
            ThenThan::default(),
            0,
        );
    }

    #[test]
    fn more_talented_then_her_issue_720() {
        assert_suggestion_result(
            "He was more talented then her at writing code.",
            ThenThan::default(),
            "He was more talented than her at writing code.",
        );
    }

    #[test]
    fn simpler_then_hers_issue_720() {
        assert_suggestion_result(
            "The design was simpler then hers in layout and color scheme.",
            ThenThan::default(),
            "The design was simpler than hers in layout and color scheme.",
        );
    }

    #[test]
    fn earlier_then_him_issue_720() {
        assert_suggestion_result(
            "We arrived earlier then him at the event.",
            ThenThan::default(),
            "We arrived earlier than him at the event.",
        );
    }

    #[test]
    fn more_robust_then_his_issue_720() {
        assert_suggestion_result(
            "This approach is more robust then his for handling edge cases.",
            ThenThan::default(),
            "This approach is more robust than his for handling edge cases.",
        );
    }

    #[test]
    fn patch_more_recently_then_last_week_issue_720() {
        assert_suggestion_result(
            "We submitted the patch more recently then last week, so they should have it already.",
            ThenThan::default(),
            "We submitted the patch more recently than last week, so they should have it already.",
        );
    }

    #[test]
    fn allows_well_then() {
        assert_lint_count(
            "Well then we're just going to raise all of these taxes",
            ThenThan::default(),
            0,
        );
    }

    #[test]
    fn allows_nervous_then() {
        assert_lint_count(
            "I think both of us were getting nervous then because the system would have automatically aborted.",
            ThenThan::default(),
            0,
        );
    }

    #[test]
    fn flags_stupider_then_and_more_and_less_stupid_then() {
        assert_lint_count(
            "He was stupider then her but she was more stupid then some. Then again he was less stupid then some too.",
            ThenThan::default(),
            3,
        );
    }

    #[test]
    fn patch_worse_then() {
        assert_suggestion_result(
            "He was worse then her at writing code.",
            ThenThan::default(),
            "He was worse than her at writing code.",
        );
    }

    #[test]
    fn patch_rather_then() {
        assert_suggestion_result(
            "If copy-paste has to be prevented, I'd prefer it if paste rather then copy would be disabled",
            ThenThan::default(),
            "If copy-paste has to be prevented, I'd prefer it if paste rather than copy would be disabled",
        );
    }

    #[test]
    fn patch_easier_said_then_done() {
        assert_suggestion_result(
            "This is currently easier said then done because you cannot press Ctrl+A in the debug console",
            ThenThan::default(),
            "This is currently easier said than done because you cannot press Ctrl+A in the debug console",
        );
    }

    #[test]
    fn patch_every_now_and_than() {
        assert_suggestion_result(
            "I was testing every now and than after an upgrade on the home assistant plugin.",
            ThenThan::default(),
            "I was testing every now and then after an upgrade on the home assistant plugin.",
        );
    }

    #[test]
    fn patch_until_than() {
        assert_suggestion_result(
            "For the case anyone else ever hits this and the problem is not solved until than, this is a working workaround for the problem",
            ThenThan::default(),
            "For the case anyone else ever hits this and the problem is not solved until then, this is a working workaround for the problem",
        );
    }

    #[test]
    fn patch_now_and_than() {
        assert_suggestion_result(
            "sounds good if golang-set becomes an issue between now and than…just let me know!",
            ThenThan::default(),
            "sounds good if golang-set becomes an issue between now and then…just let me know!",
        );
    }
}



================================================
FILE: harper-core/src/linting/theres.rs
================================================
use crate::linting::expr_linter::Chunk;
use crate::{
    Token, TokenKind,
    expr::SequenceExpr,
    linting::{ExprLinter, Lint, LintKind, Suggestion},
};

pub struct Theres {
    expr: Box<dyn crate::expr::Expr>,
}

impl Default for Theres {
    fn default() -> Self {
        let expr = SequenceExpr::aco("their's").t_ws().then_kind_any_or_words(
            &[TokenKind::is_determiner, TokenKind::is_quantifier] as &[_],
            &["no", "enough"],
        );

        Self {
            expr: Box::new(expr),
        }
    }
}

impl ExprLinter for Theres {
    type Unit = Chunk;

    fn expr(&self) -> &dyn crate::expr::Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, tokens: &[Token], source: &[char]) -> Option<Lint> {
        let offender = tokens.first()?;
        let span = offender.span;
        let template = span.get_content(source);

        Some(Lint {
            span,
            lint_kind: LintKind::WordChoice,
            suggestions: vec![Suggestion::replace_with_match_case_str("there's", template)],
            message: "Use `there's`—the contraction of “there is”—for this construction.".into(),
            priority: 31,
        })
    }

    fn description(&self) -> &str {
        "Replaces the mistaken possessive `their's` before a determiner with the contraction `there's`."
    }
}

#[cfg(test)]
mod tests {
    use super::Theres;
    use crate::linting::tests::{assert_lint_count, assert_suggestion_result};

    #[test]
    fn corrects_lowercase_before_the() {
        assert_suggestion_result(
            "We realized their's the clue we missed.",
            Theres::default(),
            "We realized there's the clue we missed.",
        );
    }

    #[test]
    fn corrects_sentence_start() {
        assert_suggestion_result(
            "Their's the solution on the table.",
            Theres::default(),
            "There's the solution on the table.",
        );
    }

    #[test]
    fn corrects_before_no() {
        assert_suggestion_result(
            "I promise their's no extra charge.",
            Theres::default(),
            "I promise there's no extra charge.",
        );
    }

    #[test]
    fn corrects_before_an() {
        assert_suggestion_result(
            "I suspect their's an error in the log.",
            Theres::default(),
            "I suspect there's an error in the log.",
        );
    }

    #[test]
    fn corrects_before_a() {
        assert_suggestion_result(
            "Maybe their's a better route available.",
            Theres::default(),
            "Maybe there's a better route available.",
        );
    }

    #[test]
    fn corrects_before_another() {
        assert_suggestion_result(
            "Their's another round after this.",
            Theres::default(),
            "There's another round after this.",
        );
    }

    #[test]
    fn corrects_before_enough() {
        assert_suggestion_result(
            "Their's enough context in the report.",
            Theres::default(),
            "There's enough context in the report.",
        );
    }

    #[test]
    fn allows_possessive_pronoun_form() {
        assert_lint_count("Theirs is the final draft.", Theres::default(), 0);
    }

    #[test]
    fn ignores_without_determiner_afterward() {
        assert_lint_count("I think their's better already.", Theres::default(), 0);
    }

    #[test]
    fn ignores_correct_contraction() {
        assert_lint_count("There's a bright sign ahead.", Theres::default(), 0);
    }
}



================================================
FILE: harper-core/src/linting/theses_these.rs
================================================
use super::{ExprLinter, Lint, LintKind, Suggestion};
use crate::Token;
use crate::expr::{Expr, SequenceExpr};
use crate::linting::expr_linter::Chunk;
use crate::patterns::UPOSSet;
use harper_brill::UPOS;

pub struct ThesesThese {
    expr: Box<dyn Expr>,
}

impl Default for ThesesThese {
    fn default() -> Self {
        let expr = SequenceExpr::default()
            .t_aco("theses")
            .t_ws()
            .then(UPOSSet::new(&[UPOS::NOUN, UPOS::PROPN]));

        Self {
            expr: Box::new(expr),
        }
    }
}

impl ExprLinter for ThesesThese {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], source: &[char]) -> Option<Lint> {
        let theses_token = matched_tokens.first()?;

        let content = theses_token.span.get_content(source);

        let suggestions = vec![Suggestion::replace_with_match_case_str("these", content)];

        Some(Lint {
            span: theses_token.span,
            lint_kind: LintKind::Spelling,
            suggestions,
            message: "Did you mean `these`?".to_string(),
            priority: 1,
        })
    }

    fn description(&self) -> &'static str {
        "Corrects the common misspelling of `these` as `theses`."
    }
}

#[cfg(test)]
mod tests {
    use crate::linting::tests::{assert_lint_count, assert_no_lints, assert_suggestion_result};

    use super::ThesesThese;

    #[test]
    fn corrects_theses_scenes() {
        assert_suggestion_result(
            "Are theses scenes from a novel?",
            ThesesThese::default(),
            "Are these scenes from a novel?",
        );
    }

    #[test]
    fn corrects_theses_days() {
        assert_suggestion_result(
            "That's why the two countries look as they do theses days.",
            ThesesThese::default(),
            "That's why the two countries look as they do these days.",
        );
    }

    #[test]
    fn allows_correct_theses() {
        assert_no_lints(
            "There are universities that are dedicated just to this field, thousands of people doing theses on Picasso, for example.",
            ThesesThese::default(),
        );
    }

    #[test]
    fn allows_theses_followed_by_verb() {
        assert_no_lints(
            "Theses are the times that try men's souls.",
            ThesesThese::default(),
        );
    }

    #[test]
    fn works_with_capitalization() {
        assert_suggestion_result(
            "THESES BOOKS ARE GREAT.",
            ThesesThese::default(),
            "THESE BOOKS ARE GREAT.",
        );
    }

    #[test]
    fn works_with_mixed_capitalization() {
        assert_suggestion_result(
            "Theses Books Are My Favorite.",
            ThesesThese::default(),
            "These Books Are My Favorite.",
        );
    }

    #[test]
    fn simple_case() {
        assert_suggestion_result(
            "I like theses apples.",
            ThesesThese::default(),
            "I like these apples.",
        );
    }

    #[test]
    fn with_punctuation() {
        assert_no_lints("Are theses, books good?", ThesesThese::default());
    }

    #[test]
    fn in_the_middle_of_sentence() {
        assert_suggestion_result(
            "I saw theses movies yesterday.",
            ThesesThese::default(),
            "I saw these movies yesterday.",
        );
    }

    #[test]
    fn another_example() {
        assert_lint_count("I have theses books.", ThesesThese::default(), 1);
    }

    #[test]
    fn allows_band_name() {
        assert_no_lints("Theses are a great band.", ThesesThese::default());
    }

    #[test]
    fn does_not_correct_valid_theses() {
        assert_no_lints(
            "She wrote multiple theses on the topic.",
            ThesesThese::default(),
        );
    }
}



================================================
FILE: harper-core/src/linting/thing_think.rs
================================================
use crate::linting::expr_linter::Chunk;
use crate::{
    Token,
    expr::{Expr, FirstMatchOf, FixedPhrase, SequenceExpr},
    linting::{ExprLinter, Lint, LintKind, Suggestion},
    patterns::WordSet,
};

/// Corrects the typo "thing" for "think".
pub struct ThingThink {
    expr: Box<dyn Expr>,
}

impl Default for ThingThink {
    fn default() -> Self {
        let subject_pronouns = WordSet::new(&["I", "you", "we", "they"]);
        let indefinite_pronouns = FirstMatchOf::new(vec![
            Box::new(WordSet::new(&[
                "anybody",
                "anyone",
                "everybody",
                "everyone",
            ])),
            // "Any one thing", "every one thing", "any body thing" cause false positives.
            Box::new(FixedPhrase::from_phrase("every body")),
        ]);
        let pronoun = FirstMatchOf::new(vec![
            Box::new(subject_pronouns),
            Box::new(indefinite_pronouns),
        ]);

        let verb_to = SequenceExpr::default()
            .then(WordSet::new(&[
                "have", "had", "has", "having", "need", "needed", "needs", "needing", "want",
                "wanted", "wants", "wanting", "try", "tried", "tries", "trying",
            ]))
            .t_ws()
            .t_aco("to");

        let modal = WordSet::new(&[
            "can",
            "cannot",
            "can't",
            "could",
            "couldn't",
            "may",
            "might",
            "mightn't",
            "must",
            "mustn't",
            "shall",
            "shan't",
            "should",
            "shouldn't",
            "will",
            "won't",
        ]);

        let adverb_of_frequency =
            WordSet::new(&["always", "sometimes", "often", "usually", "never"]);

        let pre_context = FirstMatchOf::new(vec![
            Box::new(pronoun),
            Box::new(verb_to),
            Box::new(modal),
            Box::new(adverb_of_frequency),
        ]);

        let pattern = SequenceExpr::default()
            .then(pre_context)
            .t_ws()
            .t_aco("thing");

        Self {
            expr: Box::new(pattern),
        }
    }
}

impl ExprLinter for ThingThink {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, toks: &[Token], src: &[char]) -> Option<Lint> {
        let thing_span = toks.last()?.span;

        Some(Lint {
            span: thing_span,
            lint_kind: LintKind::Typo,
            suggestions: vec![Suggestion::replace_with_match_case(
                ['t', 'h', 'i', 'n', 'k'].to_vec(),
                thing_span.get_content(src),
            )],
            message: "Did you mean `think`?".to_owned(),
            priority: 31,
        })
    }

    fn description(&self) -> &'static str {
        "Corrects the typo `thing` when it should be `think`."
    }
}

#[cfg(test)]
mod tests {
    use super::ThingThink;
    use crate::linting::tests::assert_suggestion_result;

    // Pronouns

    #[test]
    fn fix_you_thing() {
        assert_suggestion_result(
            "Whad do you thing about tinygo?",
            ThingThink::default(),
            "Whad do you think about tinygo?",
        );
    }

    #[test]
    fn fix_i_thing() {
        assert_suggestion_result(
            "bcz i thing hugging face embeddings and models are very complex",
            ThingThink::default(),
            "bcz i think hugging face embeddings and models are very complex",
        );
    }

    #[test]
    fn fix_we_thing() {
        assert_suggestion_result(
            "which information we thing to be missing",
            ThingThink::default(),
            "which information we think to be missing",
        );
    }

    #[test]
    fn fix_they_thing() {
        assert_suggestion_result(
            "they thing something is a good idea",
            ThingThink::default(),
            "they think something is a good idea",
        );
    }

    #[test]
    fn fix_everyone_thing() {
        assert_suggestion_result(
            "What does everyone thing here?",
            ThingThink::default(),
            "What does everyone think here?",
        );
    }

    #[test]
    fn fix_anyone_thing() {
        assert_suggestion_result(
            "Can anyone thing of a (reasonable) way to align them such that the 'a's in all 4 words will be in (more or less) the same vertical position?",
            ThingThink::default(),
            "Can anyone think of a (reasonable) way to align them such that the 'a's in all 4 words will be in (more or less) the same vertical position?",
        );
    }

    #[test]
    fn fix_anybody_thing() {
        assert_suggestion_result(
            "If anybody thing there is an issue in Karma, please re-open.",
            ThingThink::default(),
            "If anybody think there is an issue in Karma, please re-open.",
        );
    }

    #[test]
    fn fix_every_body_thing() {
        assert_suggestion_result(
            "What does every body thing I should do with my Randy Johnson rookie card.",
            ThingThink::default(),
            "What does every body think I should do with my Randy Johnson rookie card.",
        );
    }

    // Verb to

    #[test]
    fn fix_have_to_thing() {
        assert_suggestion_result(
            "I always have to thing what button does what action.",
            ThingThink::default(),
            "I always have to think what button does what action.",
        );
    }

    #[test]
    fn fix_need_to_thing() {
        assert_suggestion_result(
            "No need to thing about the REGEX.",
            ThingThink::default(),
            "No need to think about the REGEX.",
        );
    }

    #[test]
    fn fix_want_to_thing() {
        assert_suggestion_result(
            "maybe you want to thing of this also as a feature enhancement.",
            ThingThink::default(),
            "maybe you want to think of this also as a feature enhancement.",
        );
    }

    #[test]
    fn fix_having_to_thing() {
        assert_suggestion_result(
            "it has saved me personally hours in combined time not having to thing about whether something is in seconds or milliseconds",
            ThingThink::default(),
            "it has saved me personally hours in combined time not having to think about whether something is in seconds or milliseconds",
        );
    }

    #[test]
    fn fix_needs_to() {
        assert_suggestion_result(
            "When implementing any functionality once needs to thing aboiut how it is going to be used.",
            ThingThink::default(),
            "When implementing any functionality once needs to think aboiut how it is going to be used.",
        );
    }

    #[test]
    fn fix_needed_to() {
        assert_suggestion_result(
            "Even in that case we needed to thing about the syntax so that we wouldn't need to change existing syntax",
            ThingThink::default(),
            "Even in that case we needed to think about the syntax so that we wouldn't need to change existing syntax",
        );
    }

    #[test]
    fn fix_had_to() {
        assert_suggestion_result(
            "I had to thing in ways of making people more interested in it",
            ThingThink::default(),
            "I had to think in ways of making people more interested in it",
        );
    }

    #[test]
    fn fix_trying_to_thing() {
        assert_suggestion_result(
            "Here I'm trying to thing about the following questions:",
            ThingThink::default(),
            "Here I'm trying to think about the following questions:",
        );
    }

    // Modal verbs

    #[test]
    fn fix_can_thing() {
        assert_suggestion_result(
            "The exe file dosen't work allways, because antivirus can thing it is a virus.",
            ThingThink::default(),
            "The exe file dosen't work allways, because antivirus can think it is a virus.",
        );
    }

    #[test]
    fn fix_could_thing() {
        assert_suggestion_result(
            "\"doesNotReturnSameInstanceWhenCalledMultipleTimes\" is a terrible name, but the only one i could thing of immediately.",
            ThingThink::default(),
            "\"doesNotReturnSameInstanceWhenCalledMultipleTimes\" is a terrible name, but the only one i could think of immediately.",
        );
    }

    #[test]
    fn fix_might_thing() {
        assert_suggestion_result(
            "Consider what a reader might thing when reading a switch",
            ThingThink::default(),
            "Consider what a reader might think when reading a switch",
        );
    }

    #[test]
    fn fix_should_thing() {
        assert_suggestion_result(
            "And we should thing to add a flag so the user could decide if internal top level extension functions are ok or not.",
            ThingThink::default(),
            "And we should think to add a flag so the user could decide if internal top level extension functions are ok or not.",
        );
    }

    #[test]
    fn fix_may_thing() {
        assert_suggestion_result(
            "It is easier than you may thing to run both bands with hostapd.",
            ThingThink::default(),
            "It is easier than you may think to run both bands with hostapd.",
        );
    }

    #[test]
    fn fix_cannot_thing() {
        assert_suggestion_result(
            "I cannot thing of a simple way to implement compensation of a change in Fnco.",
            ThingThink::default(),
            "I cannot think of a simple way to implement compensation of a change in Fnco.",
        );
    }

    #[test]
    fn fix_will_thing() {
        assert_suggestion_result(
            "So user will thing that delete operation is fine but its not this code deletes the wrong page and make one extra page which wrong.",
            ThingThink::default(),
            "So user will think that delete operation is fine but its not this code deletes the wrong page and make one extra page which wrong.",
        );
    }

    #[test]
    fn fix_cant_thing() {
        assert_suggestion_result(
            "can't thing of another place, which could have such effect",
            ThingThink::default(),
            "can't think of another place, which could have such effect",
        );
    }

    #[test]
    fn fix_couldnt_thing() {
        assert_suggestion_result(
            "I couldn't thing about a better title, but I run into problems since the new dplyr release.",
            ThingThink::default(),
            "I couldn't think about a better title, but I run into problems since the new dplyr release.",
        );
    }

    #[test]
    fn fix_shouldnt_thing() {
        assert_suggestion_result(
            "When dealing with a multi-tenanted system, users shouldn't thing about 'Databases', they should think about Tenants.",
            ThingThink::default(),
            "When dealing with a multi-tenanted system, users shouldn't think about 'Databases', they should think about Tenants.",
        );
    }

    #[test]
    fn fix_wont_thing() {
        assert_suggestion_result(
            "I think you need to use an io.Pipe so the Go HTTP Request won't thing the buf has been fulling read.",
            ThingThink::default(),
            "I think you need to use an io.Pipe so the Go HTTP Request won't think the buf has been fulling read.",
        );
    }

    // Adverb of frequency

    #[test]
    fn fix_always_thing() {
        assert_suggestion_result(
            "one should always thing of whether the efforts are better targeted to the improvement",
            ThingThink::default(),
            "one should always think of whether the efforts are better targeted to the improvement",
        );
    }

    #[test]
    fn fix_sometimes_thing() {
        assert_suggestion_result(
            "One thing that I sometimes thing would be nice is if I could make different instances",
            ThingThink::default(),
            "One thing that I sometimes think would be nice is if I could make different instances",
        );
    }

    #[test]
    fn fix_often_thing() {
        assert_suggestion_result(
            "When working with workflows on many forms I often thing I need to do the same over and over",
            ThingThink::default(),
            "When working with workflows on many forms I often think I need to do the same over and over",
        );
    }

    #[test]
    fn fix_never_thing() {
        assert_suggestion_result(
            "just use UUIDv7 and never thing about those details again",
            ThingThink::default(),
            "just use UUIDv7 and never think about those details again",
        );
    }

    #[test]
    fn fix_usually_thing() {
        assert_suggestion_result(
            "And the order of that relationship might be reversed from what one might usually thing.",
            ThingThink::default(),
            "And the order of that relationship might be reversed from what one might usually think.",
        );
    }
}



================================================
FILE: harper-core/src/linting/this_type_of_thing.rs
================================================
use crate::{
    CharStringExt, Lint, Token,
    expr::{Expr, SequenceExpr},
    linting::{ExprLinter, LintKind, Suggestion, expr_linter::Chunk},
    patterns::WordSet,
};

pub struct ThisTypeOfThing {
    expr: Box<dyn Expr>,
}

impl Default for ThisTypeOfThing {
    fn default() -> Self {
        Self {
            expr: Box::new(
                SequenceExpr::word_set(&["this", "these", "that", "those"])
                    .t_ws()
                    .then(
                        SequenceExpr::word_set(&[
                            "kind", "kinds", "sort", "sorts", "type", "types",
                        ])
                        .t_ws(),
                    )
                    .then(SequenceExpr::aco("of").t_ws())
                    .then_any_of(vec![
                        // "thing" is common in this construction and won't be part of a compound noun.
                        Box::new(WordSet::new(&["thing", "things"])),
                        // Other singular nouns may be part of hard-to-determine compound nouns, but plural nouns won't.
                        Box::new(
                            SequenceExpr::default()
                                .then_kind_where(|k| k.is_plural_noun() && !k.is_singular_noun()),
                        ),
                    ]),
            ),
        }
    }
}

impl ExprLinter for ThisTypeOfThing {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn description(&self) -> &str {
        "Checks that the parts of `this/these type(s) of thing(s)` agree in grammatical number"
    }

    fn match_to_lint(&self, toks: &[Token], src: &[char]) -> Option<Lint> {
        #[derive(PartialEq)]
        enum Num {
            Sg,
            Pl,
        }

        let (det_tok, type_tok, thing_tok) = (toks.first()?, toks.get(2)?, toks.last()?);
        let (type_kind, thing_kind) = (&type_tok.kind, &thing_tok.kind);
        let (det_span, type_span) = (det_tok.span, type_tok.span);
        let (det_chars, type_chars) = (det_span.get_content(src), type_span.get_content(src));
        let (det_num, type_num, thing_num) = (
            if det_chars.eq_any_ignore_ascii_case_str(&["this", "that"]) {
                Num::Sg
            } else {
                Num::Pl
            },
            if type_kind.is_plural_noun() {
                Num::Pl
            } else {
                Num::Sg
            },
            if thing_kind.is_plural_noun() {
                Num::Pl
            } else {
                Num::Sg
            },
        );
        if det_num == type_num && type_num == thing_num {
            return None;
        };

        enum Deixis {
            Proximal,
            Distal,
        }
        let deixis = if det_chars.eq_any_ignore_ascii_case_str(&["this", "these"]) {
            Deixis::Proximal
        } else {
            Deixis::Distal
        };

        enum Specie {
            Kind,
            Sort,
            Type,
        }
        let specie = match type_chars.first()? {
            'k' | 'K' => Specie::Kind,
            's' | 'S' => Specie::Sort,
            't' | 'T' => Specie::Type,
            _ => return None,
        };

        // Due to the logic above, when we get here we either have 1 singular and 2 plurals or 2 plurals and 1 singular.
        // Meaning one of the three varying words does not agree in number with the other two.
        let bad_tok = match (&det_num, &type_num, &thing_num) {
            (Num::Sg, Num::Sg, Num::Pl) => thing_tok,
            (Num::Sg, Num::Pl, Num::Sg) => type_tok,
            (Num::Sg, Num::Pl, Num::Pl) => det_tok,
            (Num::Pl, Num::Sg, Num::Sg) => det_tok,
            (Num::Pl, Num::Sg, Num::Pl) => type_tok,
            (Num::Pl, Num::Pl, Num::Sg) => thing_tok,
            _ => return None,
        };

        Some(Lint {
            span: bad_tok.span,
            lint_kind: LintKind::Agreement,
            suggestions: vec![Suggestion::replace_with_match_case(
                if bad_tok == det_tok {
                    match (det_num, deixis) {
                        (Num::Sg, Deixis::Proximal) => "these",
                        (Num::Sg, Deixis::Distal) => "those",
                        (Num::Pl, Deixis::Proximal) => "this",
                        (Num::Pl, Deixis::Distal) => "that",
                    }
                } else if bad_tok == type_tok {
                    match (type_num, specie) {
                        (Num::Sg, Specie::Kind) => "kinds",
                        (Num::Pl, Specie::Kind) => "kind",
                        (Num::Sg, Specie::Sort) => "sorts",
                        (Num::Pl, Specie::Sort) => "sort",
                        (Num::Sg, Specie::Type) => "types",
                        (Num::Pl, Specie::Type) => "type",
                    }
                } else if bad_tok == thing_tok {
                    match thing_num {
                        Num::Sg => "things",
                        Num::Pl => "thing",
                    }
                } else {
                    return None;
                }
                .chars()
                .collect(),
                bad_tok.span.get_content(src),
            )],
            message: "The grammatical number of the determiner and the two nouns must agree."
                .to_string(),
            ..Default::default()
        })
    }
}

#[cfg(test)]
mod tests {
    use crate::linting::{tests::assert_suggestion_result, this_type_of_thing::ThisTypeOfThing};

    #[test]
    fn fix_that_kind_of_things() {
        assert_suggestion_result(
            "it's specific to TypeScript and not Go nor Python can do that kind of things",
            ThisTypeOfThing::default(),
            "it's specific to TypeScript and not Go nor Python can do that kind of thing",
        );
    }

    #[test]
    fn fix_that_sort_of_things() {
        assert_suggestion_result(
            "there isn't a trivial stb-like ready-to-use C++ library to do that sort of things",
            ThisTypeOfThing::default(),
            "there isn't a trivial stb-like ready-to-use C++ library to do that sort of thing",
        );
    }

    #[test]
    fn fix_these_kind_of_things() {
        assert_suggestion_result(
            "For these kind of things, I think it would be great to have a user-defined field which can be used to search for files.",
            ThisTypeOfThing::default(),
            "For these kinds of things, I think it would be great to have a user-defined field which can be used to search for files.",
        );
    }

    #[test]
    fn fix_these_sort_of_thing() {
        assert_suggestion_result(
            "People from npm actually get death threats for these sort of thing",
            ThisTypeOfThing::default(),
            "People from npm actually get death threats for this sort of thing",
        );
    }

    #[test]
    fn fix_these_sort_of_things() {
        assert_suggestion_result(
            "I suppose doing these sort of things should be legal",
            ThisTypeOfThing::default(),
            "I suppose doing these sorts of things should be legal",
        );
    }

    #[test]
    fn fix_these_sorts_of_thing() {
        assert_suggestion_result(
            "What I would like to understand is what the syntactic structure is for these sorts of things.",
            ThisTypeOfThing::default(),
            "What I would like to understand is what the syntactic structure is for these sorts of things.",
        );
    }

    #[test]
    fn fix_these_type_of_things() {
        assert_suggestion_result(
            "You can use the Symfony validator to validate these type of things easily.",
            ThisTypeOfThing::default(),
            "You can use the Symfony validator to validate these types of things easily.",
        );
    }

    #[test]
    fn fix_this_kind_of_things() {
        assert_suggestion_result(
            "this kind of things could exists in languages like Haskell which supports higher kinded types",
            ThisTypeOfThing::default(),
            "this kind of thing could exists in languages like Haskell which supports higher kinded types",
        );
    }

    #[test]
    fn fix_this_sort_of_things() {
        assert_suggestion_result(
            "I have heard this sort of things happening in the movie industry but it's appalling that it happens in the business world too",
            ThisTypeOfThing::default(),
            "I have heard this sort of thing happening in the movie industry but it's appalling that it happens in the business world too",
        );
    }

    #[test]
    fn fix_this_type_of_things() {
        assert_suggestion_result(
            "how to handle this type of things",
            ThisTypeOfThing::default(),
            "how to handle this type of thing",
        );
    }

    #[test]
    fn fix_those_kind_of_things() {
        assert_suggestion_result(
            "uh, so I was playing both of those kind of things",
            ThisTypeOfThing::default(),
            "uh, so I was playing both of those kinds of things",
        );
    }
}



================================================
FILE: harper-core/src/linting/though_thought.rs
================================================
use crate::expr::{Expr, SequenceExpr};
use crate::linting::expr_linter::Chunk;
use crate::linting::expr_linter::find_the_only_token_matching;
use crate::linting::{ExprLinter, Lint, LintKind, Suggestion};
use crate::{CharStringExt, Token, TokenKind};

pub struct ThoughThought {
    expr: Box<dyn Expr>,
}

impl Default for ThoughThought {
    fn default() -> Self {
        Self {
            expr: Box::new(
                SequenceExpr::default()
                    .then_kind_is_but_is_not(
                        TokenKind::is_subject_pronoun,
                        TokenKind::is_object_pronoun,
                    )
                    .t_ws()
                    .t_aco("though")
                    .t_ws()
                    .then_any_of(vec![
                        Box::new(SequenceExpr::default().then_subject_pronoun()),
                        Box::new(SequenceExpr::aco("that")),
                    ]),
            ),
        }
    }
}

impl ExprLinter for ThoughThought {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, toks: &[Token], src: &[char]) -> Option<Lint> {
        let tok = find_the_only_token_matching(toks, src, |tok, src| {
            tok.span
                .get_content(src)
                .eq_ignore_ascii_case_chars(&['t', 'h', 'o', 'u', 'g', 'h'])
        })?;

        Some(Lint {
            span: tok.span,
            lint_kind: LintKind::Typo,
            suggestions: vec![Suggestion::replace_with_match_case_str(
                "thought",
                tok.span.get_content(src),
            )],
            message: "Is this a typo for `thought`?".to_string(),
            ..Default::default()
        })
    }

    fn description(&self) -> &'static str {
        "Corrects `though` when it's a typo for `thought`."
    }
}

#[cfg(test)]
mod tests {
    use super::ThoughThought;
    use crate::linting::tests::{assert_no_lints, assert_suggestion_result};

    #[test]
    fn fix_i_though_i() {
        assert_suggestion_result(
            "Looking at those I though I had to draw imgui into separate renderpass",
            ThoughThought::default(),
            "Looking at those I thought I had to draw imgui into separate renderpass",
        );
    }

    #[test]
    fn fix_i_though_it() {
        assert_suggestion_result(
            "and I though it was a shame because the data it provides can be ...",
            ThoughThought::default(),
            "and I thought it was a shame because the data it provides can be ...",
        );
    }

    #[test]
    fn fix_i_though_that() {
        assert_suggestion_result(
            "I though that there may be other solutions as in other here",
            ThoughThought::default(),
            "I thought that there may be other solutions as in other here",
        );
    }

    #[test]
    fn fix_i_though_they() {
        assert_suggestion_result(
            "path parsin error ( i though they were extincted )",
            ThoughThought::default(),
            "path parsin error ( i thought they were extincted )",
        );
    }

    #[test]
    fn fix_i_though_we() {
        assert_suggestion_result(
            "and that way I though we need something universial",
            ThoughThought::default(),
            "and that way I thought we need something universial",
        );
    }

    #[test]
    fn fix_i_though_you() {
        assert_suggestion_result(
            "I though you resolved the issue, so I updated my version",
            ThoughThought::default(),
            "I thought you resolved the issue, so I updated my version",
        );
    }

    #[test]
    fn dont_flag_it_though_i() {
        assert_no_lints(
            "am including it though i believe it's nto the case because before this",
            ThoughThought::default(),
        );
    }

    #[test]
    fn dont_flag_it_though_it() {
        assert_no_lints(
            "Prisma works with it though it is not officially supported by Prisma yet.",
            ThoughThought::default(),
        );
    }

    #[test]
    #[ignore = "TODO: Can't check because `it` is both subject and object"]
    fn fix_you_though_it() {
        assert_suggestion_result(
            "it may reveal that the bug is not where you though it was",
            ThoughThought::default(),
            "it may reveal that the bug is not where you thought it was",
        );
    }

    #[test]
    fn dont_flag_you_though_that_1() {
        // Ambiguous: "I can tell you, though, that a project..." vs "I can tell (that) you thought that a project..."
        assert_no_lints(
            "I can tell you though that a project not using headers at all will likely be compiling much faster.",
            ThoughThought::default(),
        );
    }

    #[test]
    fn dont_flag_you_though_that_2() {
        assert_no_lints(
            "I agree with you though that 2D lat/lon grids are unnecessarily confusing",
            ThoughThought::default(),
        );
    }
}



================================================
FILE: harper-core/src/linting/throw_away.rs
================================================
use crate::linting::expr_linter::Chunk;
use crate::{
    Token,
    expr::{Expr, SequenceExpr},
    linting::{ExprLinter, Lint, LintKind, Suggestion},
};

pub struct ThrowAway {
    expr: Box<dyn Expr>,
}

impl Default for ThrowAway {
    fn default() -> Self {
        let expr = SequenceExpr::default()
            .t_aco("through")
            .t_ws()
            .t_aco("away");

        Self {
            expr: Box::new(expr),
        }
    }
}

impl ExprLinter for ThrowAway {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], source: &[char]) -> Option<Lint> {
        let typo = matched_tokens.first()?;
        let original = typo.span.get_content(source);

        Some(Lint {
            span: typo.span,
            lint_kind: LintKind::Typo,
            suggestions: vec![
                Suggestion::replace_with_match_case_str("throw", original),
                Suggestion::replace_with_match_case_str("threw", original),
            ],
            message: "Use `throw away` or `threw away`, depending on the tense you need."
                .to_string(),
            priority: 60,
        })
    }

    fn description(&self) -> &str {
        "Finds the typo `through away` and suggests `throw away` or `threw away` instead."
    }
}

#[cfg(test)]
mod tests {
    use super::ThrowAway;
    use crate::linting::tests::{
        assert_lint_count, assert_no_lints, assert_nth_suggestion_result, assert_suggestion_result,
    };

    #[test]
    fn corrects_simple_case() {
        assert_suggestion_result(
            "We through away the old code.",
            ThrowAway::default(),
            "We throw away the old code.",
        );
    }

    #[test]
    fn offers_past_tense_option() {
        assert_nth_suggestion_result(
            "We through away the old code.",
            ThrowAway::default(),
            "We threw away the old code.",
            1,
        );
    }

    #[test]
    fn corrects_sentence_start_capital() {
        assert_suggestion_result(
            "Through away this document when you're done.",
            ThrowAway::default(),
            "Throw away this document when you're done.",
        );
    }

    #[test]
    fn corrects_all_caps_instance() {
        assert_suggestion_result(
            "Please THROUGH AWAY THE TRASH.",
            ThrowAway::default(),
            "Please THROW AWAY THE TRASH.",
        );
    }

    #[test]
    fn corrects_with_extra_whitespace() {
        assert_suggestion_result(
            "We through  away the leftovers.",
            ThrowAway::default(),
            "We throw  away the leftovers.",
        );
    }

    #[test]
    fn does_not_flag_throw_away() {
        assert_no_lints(
            "They throw away the packaging every time.",
            ThrowAway::default(),
        );
    }

    #[test]
    fn does_not_flag_through_tunnel() {
        assert_no_lints(
            "They walked through the tunnel away from danger.",
            ThrowAway::default(),
        );
    }

    #[test]
    fn flags_multiple_occurrences() {
        assert_lint_count(
            "We through away the forks and through away the spoons.",
            ThrowAway::default(),
            2,
        );
    }

    #[test]
    fn does_not_flag_thorough() {
        assert_no_lints(
            "She gave the room a thorough, away-from-home cleaning.",
            ThrowAway::default(),
        );
    }

    #[test]
    fn corrects_with_contraction() {
        assert_suggestion_result(
            "Don't through away your shot.",
            ThrowAway::default(),
            "Don't throw away your shot.",
        );
    }

    #[test]
    fn does_not_flag_spread_words() {
        assert_no_lints(
            "They pushed through as the crowd moved away.",
            ThrowAway::default(),
        );
    }
}



================================================
FILE: harper-core/src/linting/throw_rubbish.rs
================================================
use std::sync::LazyLock;

use super::{Lint, LintKind, Linter};
use crate::{Document, Span, TokenStringExt, linting::Suggestion};
use hashbrown::HashSet;

static THROW: LazyLock<HashSet<&'static str>> =
    LazyLock::new(|| HashSet::from(["throw", "throws", "threw", "thrown", "throwing"]));

static JUNK: LazyLock<HashSet<&'static str>> =
    LazyLock::new(|| HashSet::from(["rubbish", "trash", "garbage", "junk"]));

static ADV_PREP: LazyLock<HashSet<&'static str>> = LazyLock::new(|| {
    HashSet::from([
        // adverbs
        "away",
        "out",
        "back",
        "everywhere",
        // prepositions
        "in",
        "into",
        "at",
        "on",
    ])
});

#[derive(Debug, Default)]
pub struct ThrowRubbish;

impl Linter for ThrowRubbish {
    fn lint(&mut self, document: &Document) -> Vec<Lint> {
        let mut lints = Vec::new();

        for chunk in document.iter_chunks() {
            for verb_i in chunk.iter_verb_indices() {
                let verb_token = &chunk[verb_i];
                let verb_str = document
                    .get_span_content_str(&verb_token.span)
                    .to_lowercase();

                if !THROW.contains(verb_str.as_str()) {
                    continue;
                }

                let chunk_rest = &chunk[verb_i + 1..];
                let mut adv_prep_seen = false;
                let mut junk_seen = false;
                let mut last_i = None;

                for (rest_i, token) in chunk_rest.iter().enumerate() {
                    let chunk_i = verb_i + rest_i + 1;
                    let token_str = document.get_span_content_str(&token.span).to_lowercase();

                    if ADV_PREP.contains(token_str.as_str()) {
                        adv_prep_seen = true;
                        last_i = Some(chunk_i);
                        if junk_seen {
                            break;
                        }
                    }
                    if JUNK.contains(token_str.as_str()) {
                        // Check if this is being used as a qualifier for another noun
                        // by looking at the next token after any whitespace
                        if let Some(next_token) = document.get_next_word_from_offset(chunk_i, 1)
                            && next_token.kind.is_noun()
                            && !is_progressive_verb_form(document, next_token)
                        {
                            continue; // Skip if it's being used as an adjective
                        }
                        junk_seen = true;
                        last_i = Some(chunk_i);
                        if adv_prep_seen {
                            break;
                        }
                    }
                }

                if junk_seen && !adv_prep_seen {
                    let span = Span::new(chunk[verb_i].span.start, chunk[last_i.unwrap()].span.end);

                    let verb = document.get_span_content_str(&chunk[verb_i].span);

                    let rest = document.get_span_content_str(&Span::new(
                        chunk[verb_i].span.end,
                        chunk[last_i.unwrap()].span.end,
                    ));

                    // Generate all possible suggestions
                    let suggestions = ["away", "out"]
                        .iter()
                        .flat_map(|adv| {
                            [format!("{verb} {adv}{rest}"), format!("{verb}{rest} {adv}")]
                        })
                        .map(|sugg| Suggestion::ReplaceWith(sugg.chars().collect()))
                        .collect();

                    lints.push(Lint {
                        span,
                        lint_kind: LintKind::Miscellaneous,
                        suggestions,
                        message: "To dispose of rubbish we don't just throw it, we throw it away"
                            .to_string(),
                        priority: 63,
                    });
                }
            }
        }

        lints
    }

    fn description(&self) -> &str {
        "Checks for throwing rubbish rather than throwing it away."
    }
}

// TODO replace this when we have proper support for progressive verb form in metadata
fn is_progressive_verb_form(document: &Document, token: &crate::Token) -> bool {
    token.kind.is_verb_progressive_form()
        && document
            .get_span_content_str(&token.span)
            .to_lowercase()
            .ends_with("ing")
}

#[cfg(test)]
mod tests {
    use super::ThrowRubbish;
    use crate::linting::tests::{assert_lint_count, assert_top3_suggestion_result};

    // Test correct patterns (should not trigger lint)
    #[test]
    fn allow_throw_away_rubbish() {
        assert_lint_count("Throw away the rubbish", ThrowRubbish, 0);
    }

    #[test]
    fn allow_throws_garbage_away() {
        assert_lint_count("He throws garbage away", ThrowRubbish, 0);
    }

    #[test]
    fn allow_threw_out_trash() {
        assert_lint_count("I threw out the trash", ThrowRubbish, 0);
    }

    #[test]
    fn allow_throw_junk_into() {
        assert_lint_count("Throw that junk into the bin!", ThrowRubbish, 0);
    }

    // Test incorrect patterns (should trigger lint)
    #[test]
    fn reject_throw_garbage() {
        assert_lint_count("You should throw garbage", ThrowRubbish, 1);
    }

    #[test]
    fn reject_throwing_rubbish() {
        assert_lint_count("Throwing rubbish is not a good idea", ThrowRubbish, 1);
    }

    // Test suggestions
    #[test]
    fn correct_thrown_some_trash() {
        assert_top3_suggestion_result(
            "I've thrown some trash",
            ThrowRubbish,
            "I've thrown some trash away",
        );
    }

    #[test]
    fn correct_throws_garbage() {
        assert_top3_suggestion_result(
            "That guy just throws his garbage",
            ThrowRubbish,
            "That guy just throws out his garbage",
        );
    }

    // Test edge cases
    #[test]
    fn ignore_throw_ball() {
        assert_lint_count("Can you throw the ball?", ThrowRubbish, 0);
    }

    // Sentences from GitHub
    #[test]
    fn correct_come_close_to_throw_trash() {
        assert_top3_suggestion_result(
            "Smart Dustbin is a trash bin that automatically opens when you come close to throw trash.",
            ThrowRubbish,
            "Smart Dustbin is a trash bin that automatically opens when you come close to throw away trash.",
        );
    }

    #[test]
    fn correct_thrown_rubbish() {
        assert_top3_suggestion_result(
            "Add a script that draws the bin behind thrown rubbish.",
            ThrowRubbish,
            "Add a script that draws the bin behind thrown away rubbish.",
        );
    }

    #[test]
    #[ignore = "`on` doesn't go with `throw` but with `daily basis`"]
    fn correct_encourage_people_to_throw_trash() {
        assert_top3_suggestion_result(
            "The app main goal is to encourage people to throw trash they can found on a daily basis.",
            ThrowRubbish,
            "The app main goal is to encourage people to throw away trash they can found on a daily basis.",
        );
    }

    #[test]
    fn correct_a_person_throwing_trash() {
        assert_top3_suggestion_result(
            "I think personally the icons look okay, aside from the clear prompt one, as it's currently accented on a person throwing trash.",
            ThrowRubbish,
            "I think personally the icons look okay, aside from the clear prompt one, as it's currently accented on a person throwing away trash.",
        );
    }

    #[test]
    fn allow_at_and_back() {
        assert_lint_count(
            "Throw garbage at a program, it will throw garbage back.",
            ThrowRubbish,
            0,
        );
    }

    #[test]
    fn correct_responsibly_throw_trash() {
        assert_top3_suggestion_result(
            "Reward system for people responsibly throwing trash saving the environment.",
            ThrowRubbish,
            "Reward system for people responsibly throwing away trash saving the environment.",
        );
    }

    // False positive when "rubbish" is a qualifier for another word
    #[test]
    fn dont_flag_throws_junk_errors() {
        assert_lint_count(
            "Experimental init throws junk errors, Ignore.",
            ThrowRubbish,
            0,
        );
    }

    #[test]
    fn dont_flag_throwing_garbage_data() {
        assert_lint_count(
            "I can resolve this in various ways, such as by not throwing garbage data at Typesense",
            ThrowRubbish,
            0,
        );
    }

    #[test]
    fn dont_flag_throwing_garbage_value() {
        assert_lint_count("Fix Spill tree Throwing garbage value", ThrowRubbish, 0);
    }

    #[test]
    fn correct_threw_trash_properly() {
        assert_top3_suggestion_result(
            "we want to know which student threw trash properly so that we can reward that student",
            ThrowRubbish,
            "we want to know which student threw away trash properly so that we can reward that student",
        );
    }

    #[test]
    fn dont_flag_throw_junk_bytes() {
        assert_lint_count(
            "the most efficient way to enforce the buffer size and throw junk bytes is to have a local (to the reception function) buffer",
            ThrowRubbish,
            0,
        );
    }

    #[test]
    fn dont_flag_throw_trash_everywhere() {
        assert_lint_count(
            "People throw trash everywhere and this tendency is very harmful.",
            ThrowRubbish,
            0,
        );
    }

    #[test]
    fn dont_flag_throws_garbage_comments() {
        assert_lint_count(
            "We dont need guys that throws garbage comments based on theyr lack of knowledge.",
            ThrowRubbish,
            0,
        );
    }

    #[test]
    fn dont_flag_trash_can_be_thrown_into_the_trash() {
        assert_lint_count(
            "Trash balls generated during cutting can be thrown into the trash",
            ThrowRubbish,
            0,
        );
    }

    #[test]
    fn correct_throwing_rubbish() {
        assert_top3_suggestion_result(
            "Admiring paintings, throwing rubbish, greeting.",
            ThrowRubbish,
            "Admiring paintings, throwing away rubbish, greeting.",
        );
    }
}



================================================
FILE: harper-core/src/linting/to_adverb.rs
================================================
use harper_brill::UPOS;

use crate::expr::{Expr, OwnedExprExt, SequenceExpr};
use crate::patterns::{UPOSSet, WordSet};
use crate::{Span, Token};

use super::{ExprLinter, Lint, LintKind, Suggestion};
use crate::linting::expr_linter::Chunk;

const AMBIGUOUS_ADVERBS: &[&str] = &["just", "not"];

pub struct ToAdverb {
    expr: Box<dyn Expr>,
}

impl Default for ToAdverb {
    fn default() -> Self {
        let expr = SequenceExpr::default()
            .t_aco("to")
            .t_ws()
            .then(UPOSSet::new(&[UPOS::ADV]).or(WordSet::new(AMBIGUOUS_ADVERBS)))
            .t_ws()
            .t_aco("to")
            .t_ws()
            .then_verb();

        Self {
            expr: Box::new(expr),
        }
    }
}

impl ExprLinter for ToAdverb {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, tokens: &[Token], source: &[char]) -> Option<Lint> {
        let first_to = tokens.first()?;
        let second_to_idx = 4;
        let second_to = tokens.get(second_to_idx)?;

        let adverb_idx = 2;

        let adverb = tokens.get(adverb_idx)?;

        let span = Span::new(first_to.span.start, second_to.span.end);
        let keep_first_variant = source[first_to.span.start..adverb.span.end].to_vec();
        let drop_first_variant = source[adverb.span.start..second_to.span.end].to_vec();

        if keep_first_variant.is_empty() || drop_first_variant.is_empty() {
            return None;
        }

        Some(Lint {
            span,
            lint_kind: LintKind::Miscellaneous,
            suggestions: vec![
                Suggestion::ReplaceWith(keep_first_variant),
                Suggestion::ReplaceWith(drop_first_variant),
            ],
            message: "Remove the repeated `to` in this infinitive.".to_owned(),
            priority: 40,
        })
    }

    fn description(&self) -> &'static str {
        "Flags duplicated `to` around certain adverbs (e.g. `to never to`) and offers fixes that keep only one `to`."
    }
}

#[cfg(test)]
mod tests {
    use super::ToAdverb;
    use crate::linting::tests::{
        assert_lint_count, assert_nth_suggestion_result, assert_suggestion_count,
        assert_suggestion_result,
    };

    #[test]
    fn corrects_to_never_to() {
        assert_suggestion_result(
            "Tom has decided to never to do that again.",
            ToAdverb::default(),
            "Tom has decided to never do that again.",
        );
    }

    #[test]
    fn alternative_moves_adverb() {
        assert_nth_suggestion_result(
            "Tom has decided to never to do that again.",
            ToAdverb::default(),
            "Tom has decided never to do that again.",
            1,
        );
    }

    #[test]
    fn corrects_to_maybe_to() {
        assert_suggestion_result(
            "The next step is to maybe to take a language class.",
            ToAdverb::default(),
            "The next step is to maybe take a language class.",
        );
    }

    #[test]
    fn corrects_to_not_to() {
        assert_suggestion_result(
            "He tells the monitor to not to collect anything.",
            ToAdverb::default(),
            "He tells the monitor to not collect anything.",
        );
    }

    #[test]
    fn corrects_to_just_to() {
        assert_suggestion_result(
            "She told me to just to keep the peace.",
            ToAdverb::default(),
            "She told me to just keep the peace.",
        );
    }

    #[test]
    fn corrects_to_really_to() {
        assert_suggestion_result(
            "They plan to really to push the release.",
            ToAdverb::default(),
            "They plan to really push the release.",
        );
    }

    #[test]
    fn offers_two_suggestions() {
        assert_suggestion_count(
            "He agreed to probably to lead the effort.",
            ToAdverb::default(),
            2,
        );
    }

    #[test]
    fn allows_single_to_with_adverb() {
        assert_lint_count("He wants to always win the match.", ToAdverb::default(), 0);
    }

    #[test]
    fn corrects_to_quickly_to() {
        assert_suggestion_result(
            "They hoped to quickly to solve it.",
            ToAdverb::default(),
            "They hoped to quickly solve it.",
        );
    }

    #[test]
    fn ignores_missing_verb_after_second_to() {
        assert_lint_count("We tried to eventually to.", ToAdverb::default(), 0);
    }

    #[test]
    fn handles_capitalized_to() {
        assert_suggestion_result(
            "To Always to succeed is the goal.",
            ToAdverb::default(),
            "To Always succeed is the goal.",
        );
    }
}



================================================
FILE: harper-core/src/linting/touristic.rs
================================================
use crate::linting::expr_linter::Chunk;
use crate::{
    Token, TokenStringExt,
    expr::{Expr, LongestMatchOf, SequenceExpr},
    linting::{ExprLinter, Lint, LintKind, Suggestion},
};

#[derive(Debug, Clone, Copy, PartialEq, Eq, Default)]
pub enum SuggestionPreference {
    /// Explicitly allow this suggestion
    Allow,
    /// Explicitly deny this suggestion
    Deny,
    /// Not explicitly allowed or denied
    #[default]
    Neutral,
}

use SuggestionPreference::*;

pub struct Touristic {
    expr: Box<dyn crate::expr::Expr>,
}

// "touristy" doesn't sound natural with these words
const BLACKLIST: &[&str] = &[
    "app",
    "apps",
    "data",
    "content",
    "establishment",
    "establishments",
    "info",
    "information",
    "interest",
    "platform",
    "platforms",
    "service",
    "services",
];

// "touristy" sounds natural with these words
const WHITELIST: &[&str] = &[
    "activity",
    "activities",
    "area",
    "areas",
    "destination",
    "destinations",
    "location",
    "locations",
    "place",
    "places",
    "route",
    "routes",
    "spot",
    "spots",
];

impl Default for Touristic {
    fn default() -> Self {
        let with_prev_and_next_word = SequenceExpr::default()
            .then_any_word()
            .t_ws()
            .t_aco("touristic")
            .t_ws()
            .then_any_word();

        let with_prev_word = SequenceExpr::default()
            .then_any_word()
            .t_ws()
            .t_aco("touristic");

        let with_next_word = SequenceExpr::default()
            .t_aco("touristic")
            .t_ws()
            .then_any_word();

        let pattern = LongestMatchOf::new(vec![
            Box::new(with_prev_and_next_word),
            Box::new(with_prev_word),
            Box::new(with_next_word),
            Box::new(SequenceExpr::default().t_aco("touristic")),
        ]);

        Self {
            expr: Box::new(pattern),
        }
    }
}

impl ExprLinter for Touristic {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, toks: &[Token], src: &[char]) -> Option<Lint> {
        let tok_span_content_string = toks.span()?.get_content_string(src);
        let tok_span_content_string = tok_span_content_string.to_lowercase();

        let mut touristy_pref = Neutral;
        let mut noun_forms_pref = Neutral;

        let span_number = match (
            toks.len(),
            tok_span_content_string.starts_with("touristic "),
            tok_span_content_string.ends_with(" touristic"),
        ) {
            (1, _, _) => {
                noun_forms_pref = Allow;
                touristy_pref = Allow;
                0
            }
            (3, true, false) => {
                let next_word = toks[2].span.get_content_string(src);
                let next_kind = &toks[2].kind;

                if next_kind.is_noun() {
                    if WHITELIST.contains(&next_word.as_str()) {
                        touristy_pref = Allow;
                    }
                    if BLACKLIST.contains(&next_word.as_str()) {
                        touristy_pref = Deny;
                    }
                }
                0
            }
            (3, false, true) => {
                let prev_kind = &toks[0].kind;
                noun_forms_pref = if prev_kind.is_adjective() || prev_kind.is_linking_verb() {
                    Deny
                } else {
                    Allow
                };
                2
            }
            (5, _, _) => {
                let _prev_word = toks[0].span.get_content_string(src).to_lowercase();
                let prev_kind = &toks[0].kind;
                let next_word = toks[4].span.get_content_string(src).to_lowercase();
                let next_kind = &toks[4].kind;

                if prev_kind.is_adverb() {
                    noun_forms_pref = Deny;
                }

                if next_kind.is_noun() {
                    if WHITELIST.contains(&next_word.as_str()) {
                        touristy_pref = Allow;
                    }
                    if BLACKLIST.contains(&next_word.as_str()) {
                        touristy_pref = Deny;
                    }
                }

                if next_kind.is_adjective() && !next_kind.is_noun() {
                    noun_forms_pref = Deny;
                    touristy_pref = Allow;
                }
                2
            }
            _ => return None,
        };

        let mut suggested = Vec::new();
        if noun_forms_pref != Deny {
            suggested.push("tourist");
            suggested.push("tourism");
        }
        if touristy_pref != Deny {
            suggested.push("touristy");
        }

        let span = toks[span_number].span;
        Some(Lint {
            span,
            lint_kind: LintKind::WordChoice,
            suggestions: suggested
                .into_iter()
                .map(|s| Suggestion::replace_with_match_case_str(s, span.get_content(src)))
                .collect(),
            message: "The word `touristic` is rarely used by native speakers.".to_string(),
            priority: 31,
        })
    }

    fn description(&self) -> &'static str {
        "Suggests replacing the uncommon word `touristic` with `tourist`, `tourism`, and/or `touristy`."
    }
}

#[cfg(test)]
mod tests {
    use super::Touristic;
    use crate::linting::tests::assert_good_and_bad_suggestions;

    #[test]
    fn fixes_touristic_alone() {
        assert_good_and_bad_suggestions(
            "touristic",
            Touristic::default(),
            &["tourist", "tourism", "touristy"],
            &[],
        );
    }

    #[test]
    fn fixes_very_t() {
        assert_good_and_bad_suggestions(
            "very touristic",
            Touristic::default(),
            &["very touristy"],
            &["very tourist", "very tourism"],
        );
    }

    #[test]
    fn fixes_t_location_good_and_bad() {
        assert_good_and_bad_suggestions(
            "touristic location",
            Touristic::default(),
            &["tourist location", "tourism location", "touristy location"],
            &[],
        );
    }

    #[test]
    fn fixes_is_t() {
        assert_good_and_bad_suggestions(
            "That place is touristic",
            Touristic::default(),
            &["That place is touristy"],
            &["That place is tourist", "That place is tourism"],
        );
    }

    #[test]
    fn fixes_t_information() {
        assert_good_and_bad_suggestions(
            "The AI Touristic Information Tool for Liquid Galaxy is a Flutter-based Android tablet application that simplifies and enhances travel planning.",
            Touristic::default(),
            &[
                "The AI Tourist Information Tool for Liquid Galaxy is a Flutter-based Android tablet application that simplifies and enhances travel planning.",
                "The AI Tourism Information Tool for Liquid Galaxy is a Flutter-based Android tablet application that simplifies and enhances travel planning.",
            ],
            &[
                "The AI Touristy Information Tool for Liquid Galaxy is a Flutter-based Android tablet application that simplifies and enhances travel planning.",
            ],
        );
    }

    #[test]
    fn fixes_t_data() {
        assert_good_and_bad_suggestions(
            "Official API to access Apidae touristic data.",
            Touristic::default(),
            &[
                "Official API to access Apidae tourist data.",
                "Official API to access Apidae tourism data.",
            ],
            &["Official API to access Apidae touristy data."],
        );
    }

    #[test]
    fn corrects_t_information_2() {
        assert_good_and_bad_suggestions(
            "Oppidums is open source app that provide cultural, historical and touristic information on different cities.",
            Touristic::default(),
            &[
                "Oppidums is open source app that provide cultural, historical and tourist information on different cities.",
                "Oppidums is open source app that provide cultural, historical and tourism information on different cities.",
            ],
            &[
                "Oppidums is open source app that provide cultural, historical and touristy information on different cities.",
            ],
        );
    }

    #[test]
    fn corrects_very_t_spot() {
        assert_good_and_bad_suggestions(
            "The destination is a very touristic spot, many people visit this place at the weekend.",
            Touristic::default(),
            &[
                "The destination is a very touristy spot, many people visit this place at the weekend.",
            ],
            &[
                "The destination is a very tourist spot, many people visit this place at the weekend.",
                "The destination is a very tourism spot, many people visit this place at the weekend.",
            ],
        );
    }

    #[test]
    #[ignore = "Checks previous word but results depend on the next word"]
    fn fixes_t_platform() {
        assert_good_and_bad_suggestions(
            "Incuti is touristic platform for African destinations.",
            Touristic::default(),
            &[
                "Incuti is tourist platform for African destinations.",
                "Incuti is tourism platform for African destinations.",
            ],
            &["Incuti is touristy platform for African destinations."],
        );
    }

    #[test]
    fn fixes_t_service_providers() {
        assert_good_and_bad_suggestions(
            "Onlim API is a tool that touristic service providers utilize to generate social media posts by injecting data about their offers into some templates.",
            Touristic::default(),
            &[
                "Onlim API is a tool that tourist service providers utilize to generate social media posts by injecting data about their offers into some templates.",
                "Onlim API is a tool that tourism service providers utilize to generate social media posts by injecting data about their offers into some templates.",
            ],
            &[
                "Onlim API is a tool that touristy service providers utilize to generate social media posts by injecting data about their offers into some templates.",
            ],
        );
    }

    #[test]
    fn fixes_are_t_areas() {
        assert_good_and_bad_suggestions(
            "We can determine that most of the busier areas are touristic areas, which in return helps with the high demand for the shared bikes.",
            Touristic::default(),
            &[
                "We can determine that most of the busier areas are tourist areas, which in return helps with the high demand for the shared bikes.",
                "We can determine that most of the busier areas are tourism areas, which in return helps with the high demand for the shared bikes.",
                "We can determine that most of the busier areas are touristy areas, which in return helps with the high demand for the shared bikes.",
            ],
            &[],
        );
    }

    #[test]
    fn fixes_very_t_area() {
        assert_good_and_bad_suggestions(
            "This is Manhattan, a very popular, very touristic area of New York.",
            Touristic::default(),
            &["This is Manhattan, a very popular, very touristy area of New York."],
            &[
                "This is Manhattan, a very popular, very tourist area of New York.",
                "This is Manhattan, a very popular, very tourism area of New York.",
            ],
        );
    }

    #[test]
    fn fixes_for_t_photographic() {
        assert_good_and_bad_suggestions(
            "Python implementation of my clustering-based recommendation system for touristic photographic spots.",
            Touristic::default(),
            &[
                "Python implementation of my clustering-based recommendation system for touristy photographic spots.",
            ],
            &[
                "Python implementation of my clustering-based recommendation system for tourist photographic spots.",
                "Python implementation of my clustering-based recommendation system for tourism photographic spots.",
            ],
        );
    }

    #[test]
    fn fixes_czech_t_routes() {
        assert_good_and_bad_suggestions(
            "Management and Control Application for Czech Touristic Routes in OSM.",
            Touristic::default(),
            &[
                "Management and Control Application for Czech Tourist Routes in OSM.",
                "Management and Control Application for Czech Tourism Routes in OSM.",
                "Management and Control Application for Czech Touristy Routes in OSM.",
            ],
            &[],
        );
    }

    #[test]
    fn fixes_promote_t_activities() {
        assert_good_and_bad_suggestions(
            "Application to promote touristic activities in Valencia.",
            Touristic::default(),
            &[
                "Application to promote tourist activities in Valencia.",
                "Application to promote tourism activities in Valencia.",
                "Application to promote touristy activities in Valencia.",
            ],
            &[],
        );
    }

    #[test]
    fn fixes_a_t_flutter() {
        assert_good_and_bad_suggestions(
            "A Touristic Flutter App.",
            Touristic::default(),
            &["A Tourist Flutter App.", "A Tourism Flutter App."],
            &[
                // "app" would be fine in the blacklist, but "Flutter" would be going too far
                // "A Touristy Flutter App.",
            ],
        );
    }

    #[test]
    fn fixes_of_t_interest() {
        assert_good_and_bad_suggestions(
            "ARCHEO: a python lib for sound event detection in areas of touristic Interest.",
            Touristic::default(),
            &[
                "ARCHEO: a python lib for sound event detection in areas of tourist Interest.",
                "ARCHEO: a python lib for sound event detection in areas of tourism Interest.",
            ],
            &["ARCHEO: a python lib for sound event detection in areas of touristy Interest."],
        );
    }

    #[test]
    fn fixes_t_establishments() {
        assert_good_and_bad_suggestions(
            "Touristic establishments by EUROSTAT NUTS regions.",
            Touristic::default(),
            &[
                "Tourist establishments by EUROSTAT NUTS regions.",
                "Tourism establishments by EUROSTAT NUTS regions.",
            ],
            &["Touristy establishments by EUROSTAT NUTS regions."],
        );
    }
}



================================================
FILE: harper-core/src/linting/transposed_space.rs
================================================
use crate::{
    Lint, Token, TokenStringExt,
    expr::{Expr, FirstMatchOf, SequenceExpr},
    linting::{ExprLinter, LintKind, Suggestion, expr_linter::Chunk},
    spell::Dictionary,
};

pub struct TransposedSpace<D: Dictionary + 'static> {
    expr: Box<dyn Expr>,
    dict: D,
}

impl<D: Dictionary + 'static> TransposedSpace<D> {
    pub fn new(dict: D) -> Self {
        Self {
            expr: Box::new(FirstMatchOf::new(vec![Box::new(
                SequenceExpr::default().then_oov().t_ws().then_oov(),
            )])),
            dict,
        }
    }

    pub fn sensitive(dict: D) -> Self {
        Self {
            expr: Box::new(FirstMatchOf::new(vec![
                Box::new(SequenceExpr::default().then_oov().t_ws().then_any_word()),
                Box::new(SequenceExpr::default().then_any_word().t_ws().then_oov()),
                Box::new(SequenceExpr::default().then_oov().t_ws().then_oov()),
            ])),
            dict,
        }
    }
}

fn keep_unique(values: &mut Vec<String>, word1: &[char], word2: &[char]) {
    let value = format!(
        "{} {}",
        word1.iter().collect::<String>(),
        word2.iter().collect::<String>()
    );
    if !values.contains(&value) {
        values.push(value);
    }
}

impl<D: Dictionary + 'static> ExprLinter for TransposedSpace<D> {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, toks: &[Token], src: &[char]) -> Option<Lint> {
        let toks_span = toks.span()?;

        // "thec" "at" / "th ecat"
        let word1 = toks.first()?.span.get_content(src);
        let word2 = toks.last()?.span.get_content(src);

        // "thec" -> "the c"
        let w1_start = &word1[..word1.len() - 1];
        let w1_last = word1.iter().last()?;

        // "ecat" -> "e cat"
        let w2_first = word2.first()?;
        let w2_end = &word2[1..];

        // "c" + "at" -> "cat"
        let mut w1_last_plus_w2 = word2.to_vec();
        w1_last_plus_w2.insert(0, *w1_last);

        // "th" + "e" -> "the"
        let mut w1_plus_w2_first = word1.to_vec();
        w1_plus_w2_first.push(*w2_first);

        let mut values = vec![];

        // "thec" "at" -> "the cat"
        if self.dict.contains_word(w1_start) && self.dict.contains_word(&w1_last_plus_w2) {
            let maybe_canon_w2 = self.dict.get_correct_capitalization_of(&w1_last_plus_w2);
            if let Some(canon_w1) = self.dict.get_correct_capitalization_of(w1_start) {
                if let Some(canon_w2) = maybe_canon_w2 {
                    keep_unique(&mut values, canon_w1, canon_w2);
                } else {
                    keep_unique(&mut values, canon_w1, &w1_last_plus_w2);
                }
            } else if let Some(canon_w2) = maybe_canon_w2 {
                keep_unique(&mut values, w1_start, canon_w2);
            }

            keep_unique(&mut values, w1_start, &w1_last_plus_w2);
        }

        // "th" "ecat" -> "the cat"
        if self.dict.contains_word(&w1_plus_w2_first) && self.dict.contains_word(w2_end) {
            let maybe_canon_w2 = self.dict.get_correct_capitalization_of(w2_end);
            if let Some(canon_w1) = self.dict.get_correct_capitalization_of(&w1_plus_w2_first) {
                if let Some(canon_w2) = maybe_canon_w2 {
                    keep_unique(&mut values, canon_w1, canon_w2);
                } else {
                    keep_unique(&mut values, canon_w1, w2_end);
                }
            } else if let Some(canon_w2) = maybe_canon_w2 {
                keep_unique(&mut values, &w1_plus_w2_first, canon_w2);
            }

            keep_unique(&mut values, &w1_plus_w2_first, w2_end);
        }

        if values.is_empty() {
            return None;
        }

        let suggestions = values
            .iter()
            .map(|value| {
                Suggestion::replace_with_match_case(
                    value.chars().collect(),
                    toks_span.get_content(src),
                )
            })
            .collect();

        Some(Lint {
            span: toks_span,
            lint_kind: LintKind::Typo,
            suggestions,
            message: format!(
                "Is the space between `{}` and `{}` one character out of place?",
                word1.iter().collect::<String>(),
                word2.iter().collect::<String>()
            ),
            ..Default::default()
        })
    }

    fn description(&self) -> &str {
        "Looks for a space one character too early or too late between words."
    }
}

#[cfg(test)]
mod tests {
    use super::TransposedSpace;
    use crate::{linting::tests::assert_suggestion_result, spell::FstDictionary};

    #[test]
    fn space_too_early() {
        assert_suggestion_result(
            "Th ecat sat on the mat.",
            TransposedSpace::sensitive(FstDictionary::curated()),
            "The cat sat on the mat.",
        );
    }

    #[test]
    fn space_too_late() {
        assert_suggestion_result(
            "Thec at sat on the mat.",
            TransposedSpace::sensitive(FstDictionary::curated()),
            "The cat sat on the mat.",
        );
    }

    #[test]
    fn test_early() {
        assert_suggestion_result(
            "Sometimes the spac eis one character early.",
            TransposedSpace::new(FstDictionary::curated()),
            "Sometimes the space is one character early.",
        );
    }
    #[test]
    fn test_late() {
        assert_suggestion_result(
            "Ands ometimes the space is a character late.",
            TransposedSpace::new(FstDictionary::curated()),
            "And sometimes the space is a character late.",
        );
    }
}



================================================
FILE: harper-core/src/linting/try_ones_hand_at.rs
================================================
use crate::{
    Lint, Token,
    expr::{Expr, SequenceExpr},
    linting::{ExprLinter, LintKind, Suggestion, expr_linter::Chunk},
};

pub struct TryOnesHandAt {
    expr: Box<dyn Expr>,
}

impl Default for TryOnesHandAt {
    fn default() -> Self {
        Self {
            expr: Box::new(
                SequenceExpr::word_set(&["try", "tried", "tries", "trying"])
                    .t_ws()
                    .then_possessive_determiner()
                    .t_ws()
                    .t_aco("hands")
                    .t_ws()
                    .t_aco("at"),
            ),
        }
    }
}

impl ExprLinter for TryOnesHandAt {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, toks: &[Token], src: &[char]) -> Option<Lint> {
        let hands_idx = 4;
        let hands_tok = toks.get(hands_idx)?;
        let hands_span = hands_tok.span;
        let hands_chars = hands_span.get_content(src);

        Some(Lint {
            span: hands_span,
            lint_kind: LintKind::Usage,
            suggestions: vec![Suggestion::replace_with_match_case(
                vec!['h', 'a', 'n', 'd'],
                hands_chars,
            )],
            message: "This idiom uses the singular `hand`.".to_string(),
            ..Default::default()
        })
    }

    fn description(&self) -> &str {
        "Corrects `try one's hands at` to `try one's hand at`."
    }
}

#[cfg(test)]
mod tests {
    use super::TryOnesHandAt;
    use crate::linting::tests::assert_suggestion_result;

    #[test]
    fn fix_tried_my() {
        assert_suggestion_result(
            "I tried my hands at a little test to see how different parameters I get for the same deck and the same material.",
            TryOnesHandAt::default(),
            "I tried my hand at a little test to see how different parameters I get for the same deck and the same material.",
        )
    }

    #[test]
    fn fix_tried_their() {
        assert_suggestion_result(
            "If there isn't any obvious reason why no one has tried their hands at it yet, I might try implementing it.",
            TryOnesHandAt::default(),
            "If there isn't any obvious reason why no one has tried their hand at it yet, I might try implementing it.",
        )
    }

    #[test]
    fn fix_tries_his() {
        assert_suggestion_result(
            "A fellow programmer from India who tries his hands at everything he can.",
            TryOnesHandAt::default(),
            "A fellow programmer from India who tries his hand at everything he can.",
        )
    }

    #[test]
    fn fix_try_my() {
        assert_suggestion_result(
            "I am happy to try my hands at implementing one, but not being that proficient in C/C++ need some guidance on where to start.",
            TryOnesHandAt::default(),
            "I am happy to try my hand at implementing one, but not being that proficient in C/C++ need some guidance on where to start.",
        )
    }

    #[test]
    fn fix_try_our() {
        assert_suggestion_result(
            "One way to make some of the requirements for this more concrete is to try our hands at implementing a language server.",
            TryOnesHandAt::default(),
            "One way to make some of the requirements for this more concrete is to try our hand at implementing a language server.",
        )
    }

    #[test]
    fn fix_try_their() {
        assert_suggestion_result(
            "At the end the user will be able to create a list of decimal numbers to try their hands at the Diagonal Argument on their own.",
            TryOnesHandAt::default(),
            "At the end the user will be able to create a list of decimal numbers to try their hand at the Diagonal Argument on their own.",
        )
    }

    #[test]
    fn fix_try_your() {
        assert_suggestion_result(
            "You'll likely need to try your hands at a bit of Lua to make it work.",
            TryOnesHandAt::default(),
            "You'll likely need to try your hand at a bit of Lua to make it work.",
        )
    }

    #[test]
    fn fix_trying_my() {
        assert_suggestion_result(
            "I wouldn't mind trying my hands at a PR if the solution would be accepted.",
            TryOnesHandAt::default(),
            "I wouldn't mind trying my hand at a PR if the solution would be accepted.",
        )
    }
}



================================================
FILE: harper-core/src/linting/unclosed_quotes.rs
================================================
use super::{Lint, LintKind, Linter};
use crate::document::Document;
use crate::{Punctuation, Quote, TokenKind};

#[derive(Debug, Clone, Copy, Default)]
pub struct UnclosedQuotes;

impl Linter for UnclosedQuotes {
    fn lint(&mut self, document: &Document) -> Vec<Lint> {
        let mut lints = Vec::new();

        // TODO: Try zipping quote positions
        for token in document.tokens() {
            if let TokenKind::Punctuation(Punctuation::Quote(Quote { twin_loc: None })) = token.kind
            {
                lints.push(Lint {
                    span: token.span,
                    lint_kind: LintKind::Formatting,
                    suggestions: vec![],
                    message: "This quote has no termination.".to_string(),
                    priority: 255,
                })
            }
        }

        lints
    }

    fn description(&self) -> &'static str {
        "Quotation marks should always be closed. Unpaired quotation marks are a hallmark of sloppy work."
    }
}



================================================
FILE: harper-core/src/linting/update_place_names.rs
================================================
use crate::expr::{Expr, FixedPhrase, LongestMatchOf};
use crate::linting::expr_linter::Chunk;
use crate::linting::{ExprLinter, LintKind, Suggestion};
use crate::{Lint, Token, TokenStringExt};

type PlaceNameMappings<'a> = &'a [((i16, &'a str), &'a [&'a str])];

pub struct UpdatePlaceNames<'a> {
    expr: Box<dyn Expr>,
    place_name_mappings: PlaceNameMappings<'a>,
}

impl<'a> Default for UpdatePlaceNames<'a> {
    fn default() -> Self {
        let place_name_mappings: PlaceNameMappings<'a> = &[
            // // Africa
            ((1984, "Burkina Faso"), &["Upper Volta"]),
            ((1985, "Côte d'Ivoire"), &["Ivory Coast"]), // TODO: Can we recommend Cote d'Ivoire as well?
            ((2018, "Eswatini"), &["Swaziland"]),
            // ((1995, "Janjanbureh"), &["Georgetown"]), // Too many places named Georgetown / George Town
            // Australia
            ((1993, "Kata Tjuta"), &["The Olgas"]), // TODO: Can we recommend the spelling with the underscore letter(s) as well?
            ((1993, "Uluru"), &["Ayers Rock"]), // TODO: Can we recommend the spelling with the underscore letter as well?
            // Central Asia
            ((1961, "Dushanbe"), &["Stalinabad"]),
            // East Asia
            ((1979, "Beijing"), &["Peking"]),
            ((0, "Guangzhou"), &["Canton"]),
            ((1945, "Taiwan"), &["Formosa"]),
            ((1991, "Ulaanbaatar"), &["Ulan Bator"]),
            // Europe (and nearby)
            ((2016, "Czechia"), &["Czech Republic"]),
            ((1945, "Gdańsk"), &["Danzig"]), // TODO: Can we recommend Gdansk as well?
            ((1992, "Podgorica"), &["Titograd"]),
            ((1936, "Tbilisi"), &["Tiflis"]),
            ((2022, "Türkiye"), &["Turkey"]), // TODO: Can we recommend Turkiye as well?
            // India
            ((2006, "Bengaluru"), &["Bangalore"]),
            ((1996, "Chennai"), &["Madras"]),
            ((2007, "Kochi"), &["Cochin"]),
            ((2001, "Kolkata"), &["Calcutta"]),
            ((1995, "Mumbai"), &["Bombay"]),
            ((2014, "Mysuru"), &["Mysore"]),
            ((2006, "Puducherry"), &["Pondicherry"]),
            ((1978, "Pune"), &["Poona"]),
            ((1991, "Thiruvananthapuram"), &["Trivandrum"]),
            // Latin America
            ((2013, "CDMX"), &["DF"]),
            // Pacific Island nations
            ((1997, "Samoa"), &["Western Samoa"]),
            ((1980, "Vanuatu"), &["New Hebrides"]),
            // Russia
            ((1946, "Kaliningrad"), &["Königsberg"]), // TODO: can we handle Konigsberg and Koenigsberg?
            ((1991, "Saint Petersburg"), &["Leningrad", "Petrograd"]), // TODO: can we add St. Petersburg?
            ((1961, "Volgograd"), &["Stalingrad"]),
            // South Asia
            ((2000, "Busan"), &["Pusan"]),
            ((2018, "Chattogram"), &["Chittagong"]),
            ((1982, "Dhaka"), &["Dacca"]),
            ((1972, "Sri Lanka"), &["Ceylon"]),
            // Southeast Asia
            ((1989, "Cambodia"), &["Kampuchea"]),
            ((1976, "Ho Chi Minh City"), &["Saigon"]),
            ((2017, "Melaka"), &["Malacca"]),
            ((1989, "Myanmar"), &["Burma"]),
            ((1939, "Thailand"), &["Siam"]),
            ((2002, "Timor-Leste"), &["East Timor"]),
            ((1989, "Yangon"), &["Rangoon"]),
            // Ukraine
            ((1992, "Kharkiv"), &["Kharkov"]),
            ((1992, "Kyiv"), &["Kiev"]),
            ((1992, "Luhansk"), &["Lugansk"]),
            ((1992, "Lviv"), &["Lvov"]),
            ((1992, "Odesa"), &["Odessa"]),
            ((1992, "Vinnytsia"), &["Vinnitsa"]),
            ((1992, "Zaporizhzhia"), &["Zaporozhye"]),
        ];

        let expr = LongestMatchOf::new(
            place_name_mappings
                .iter()
                .flat_map(|(_, old_names)| old_names.iter())
                .map(|old_name| Box::new(FixedPhrase::from_phrase(old_name)) as Box<dyn Expr>)
                .collect(),
        );

        Self::new(Box::new(expr), place_name_mappings)
    }
}

impl<'a> UpdatePlaceNames<'a> {
    pub fn new(expr: Box<dyn Expr>, place_name_mappings: PlaceNameMappings<'a>) -> Self {
        Self {
            expr,
            place_name_mappings,
        }
    }
}

impl<'a> ExprLinter for UpdatePlaceNames<'a> {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, toks: &[Token], src: &[char]) -> Option<Lint> {
        let old_name = toks.span()?.get_content_string(src);
        let (year, new_name) =
            self.place_name_mappings
                .iter()
                .find_map(|((year, new_name), old_names)| {
                    old_names
                        .iter()
                        .any(|n| n == &old_name)
                        .then_some((year, *new_name))
                })?;

        let suggestions = vec![Suggestion::ReplaceWith(new_name.chars().collect())];

        let message = match year {
            1.. => format!("This place has been officially known as '{new_name}' since {year}"),
            _ => format!("This place is now officially known as '{new_name}'"),
        };

        Some(Lint {
            span: toks.span()?,
            lint_kind: LintKind::WordChoice,
            suggestions,
            message,
            priority: 31,
        })
    }

    fn description(&self) -> &str {
        "This rule looks for deprecated place names and offers to update them."
    }
}

#[cfg(test)]
mod tests {
    use crate::linting::{
        tests::{assert_lint_count, assert_suggestion_result},
        update_place_names::UpdatePlaceNames,
    };

    #[test]
    fn update_single_word_name_alone() {
        assert_suggestion_result("Bombay", UpdatePlaceNames::default(), "Mumbai");
    }

    #[test]
    fn update_single_word_name_after_space() {
        assert_suggestion_result(" Bombay", UpdatePlaceNames::default(), " Mumbai");
    }

    #[test]
    fn update_single_word_name_after_punctuation() {
        assert_suggestion_result(";Bombay", UpdatePlaceNames::default(), ";Mumbai");
    }

    #[test]
    fn update_two_word_name_to_single_word_alone() {
        assert_suggestion_result("Ayers Rock", UpdatePlaceNames::default(), "Uluru");
    }

    #[test]
    fn update_two_word_name_to_single_word_after_space() {
        assert_suggestion_result(" Ayers Rock", UpdatePlaceNames::default(), " Uluru");
    }

    #[test]
    fn update_two_word_name_to_single_word_after_punctuation() {
        assert_suggestion_result(";Ayers Rock", UpdatePlaceNames::default(), ";Uluru");
    }

    #[test]
    fn update_single_word_name_to_multi_word_name_alone() {
        assert_suggestion_result("Saigon", UpdatePlaceNames::default(), "Ho Chi Minh City");
    }

    #[test]
    fn update_two_word_name_to_two_word_name_alone() {
        assert_suggestion_result("The Olgas", UpdatePlaceNames::default(), "Kata Tjuta");
    }

    #[test]
    fn dont_flag_multiword_name_with_non_space() {
        assert_lint_count("The, Olgas", UpdatePlaceNames::default(), 0);
    }

    #[test]
    fn dont_flag_multiword_name_with_hyphen() {
        assert_lint_count("The-Olgas", UpdatePlaceNames::default(), 0);
    }

    // TODO: when both old and new names contain whitespace we don't copy the whitespace
    #[test]
    #[ignore = "tabs not supported as whitespace?"]
    fn flag_multiword_name_with_tabs() {
        assert_lint_count("The\tOlgas", UpdatePlaceNames::default(), 1);
    }

    // TODO: when both old and new names contain whitespace we don't copy the whitespace
    #[test]
    #[ignore = "newlines not supported as whitespace?"]
    fn flag_multiword_name_with_newline() {
        assert_lint_count("The\nOlgas", UpdatePlaceNames::default(), 1);
    }

    #[test]
    fn update_two_word_name_to_single_word_at_end_of_sentence() {
        assert_suggestion_result(
            "It's dangerous to climb Ayers Rock.",
            UpdatePlaceNames::default(),
            "It's dangerous to climb Uluru.",
        );
    }

    #[test]
    fn update_two_word_name_to_single_word_at_start_of_sentence() {
        assert_suggestion_result(
            "Ayers Rock is dangerous to climb.",
            UpdatePlaceNames::default(),
            "Uluru is dangerous to climb.",
        );
    }

    #[test]
    fn update_first_old_name() {
        assert_suggestion_result("Leningrad", UpdatePlaceNames::default(), "Saint Petersburg");
    }

    #[test]
    fn update_second_old_name() {
        assert_suggestion_result(
            "Have you ever been to Petrograd before?",
            UpdatePlaceNames::default(),
            "Have you ever been to Saint Petersburg before?",
        );
    }

    #[test]
    fn update_two_word_name_with_two_word_name() {
        assert_suggestion_result(
            "Upper Volta is in Africa.",
            UpdatePlaceNames::default(),
            "Burkina Faso is in Africa.",
        )
    }

    // NOTE: Can't handle place names with obligatory or compulsory "The" perfectly.
    #[test]
    fn update_to_name_with_punctuation() {
        assert_suggestion_result(
            "I've never been to Ivory Coast.",
            UpdatePlaceNames::default(),
            "I've never been to Côte d'Ivoire.",
        )
    }
}



================================================
FILE: harper-core/src/linting/use_title_case.rs
================================================
use crate::{Document, TokenStringExt, spell::Dictionary, title_case::try_make_title_case};

use super::{Lint, LintKind, Linter, Suggestion};

pub struct UseTitleCase<D: Dictionary + 'static> {
    dict: D,
}

impl<D: Dictionary + 'static> UseTitleCase<D> {
    pub fn new(dict: D) -> Self {
        Self { dict }
    }
}

impl<D: Dictionary + 'static> Linter for UseTitleCase<D> {
    fn lint(&mut self, document: &Document) -> Vec<Lint> {
        let mut lints = Vec::new();

        for heading in document.iter_headings() {
            let Some(span) = heading.span() else {
                continue;
            };

            if let Some(title_case) =
                try_make_title_case(heading, document.get_source(), &self.dict)
            {
                lints.push(Lint {
                    span,
                    lint_kind: LintKind::Capitalization,
                    suggestions: vec![Suggestion::ReplaceWith(title_case)],
                    message: "Try to use title case in headings.".to_owned(),
                    priority: 127,
                });
            }
        }

        lints
    }

    fn description(&self) -> &str {
        "Prompts you to use title case in relevant headings."
    }
}

#[cfg(test)]
mod tests {
    use crate::linting::tests::assert_suggestion_result;
    use crate::spell::FstDictionary;

    use super::UseTitleCase;

    #[test]
    fn simple_correction() {
        assert_suggestion_result(
            "# This is a title",
            UseTitleCase::new(FstDictionary::curated()),
            "# This Is a Title",
        );
    }

    #[test]
    fn double_correction() {
        assert_suggestion_result(
            "# This is a title\n\n## This is a subtitle",
            UseTitleCase::new(FstDictionary::curated()),
            "# This Is a Title\n\n## This Is a Subtitle",
        );
    }
}



================================================
FILE: harper-core/src/linting/verb_to_adjective.rs
================================================
use harper_brill::UPOS;

use crate::expr::All;
use crate::expr::Expr;
use crate::expr::SequenceExpr;
use crate::patterns::UPOSSet;
use crate::patterns::WordSet;
use crate::{Token, TokenStringExt};

use super::{ExprLinter, Lint, LintKind};
use crate::linting::expr_linter::Chunk;

pub struct VerbToAdjective {
    expr: Box<dyn Expr>,
}

impl Default for VerbToAdjective {
    fn default() -> Self {
        let expr = SequenceExpr::default()
            .then(WordSet::new(&["the", "a", "an"]))
            .t_ws()
            .then_kind_where(|kind| {
                (kind.is_verb()
                    && !kind.is_verb_past_form()
                    && !kind.is_adjective()
                    && !kind.is_noun())
                    || kind.is_degree_adverb()
            })
            .t_ws()
            .then(UPOSSet::new(&[UPOS::NOUN, UPOS::PROPN]));

        let exceptions = SequenceExpr::anything()
            .t_any()
            .then_unless(WordSet::new(&["very"]));

        Self {
            expr: Box::new(All::new(vec![Box::new(expr), Box::new(exceptions)])),
        }
    }
}

impl ExprLinter for VerbToAdjective {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], _source: &[char]) -> Option<Lint> {
        Some(Lint {
            span: matched_tokens.span()?,
            lint_kind: LintKind::Typo,
            suggestions: vec![],
            message: "Did you intend to use an adjective here?".to_owned(),
            priority: 31,
        })
    }

    fn description(&self) -> &'static str {
        "Looks for situations where a verb was written where an adjective is often intended."
    }
}

#[cfg(test)]
mod tests {
    use crate::linting::tests::{assert_lint_count, assert_no_lints};

    use super::VerbToAdjective;

    #[test]
    fn fully_accounting() {
        assert_lint_count(
            "By scheduling time to do a fully accounting of where your CPU cycles are going, you can preemptively save yourself (and your contributors) a lot of time.",
            VerbToAdjective::default(),
            1,
        );
    }

    #[test]
    fn new_car_is_valid() {
        assert_no_lints("I really like my new car.", VerbToAdjective::default());
    }

    #[test]
    fn new_sentence_is_valid() {
        assert_no_lints(
            "I want you to write a new sentence for me.",
            VerbToAdjective::default(),
        );
    }

    #[test]
    fn correct_term_is_valid() {
        assert_no_lints(
            "Ensure the correct term is used for individuals residing abroad.",
            VerbToAdjective::default(),
        );
    }

    #[test]
    fn causes_amazement_is_valid() {
        assert_no_lints(
            "It is something that causes amazement.",
            VerbToAdjective::default(),
        );
    }

    #[test]
    fn correct_auxiliary_is_valid() {
        assert_no_lints(
            "Can you suggest a correct auxiliary?",
            VerbToAdjective::default(),
        );
    }

    #[test]
    fn submitted_form_data_is_valid() {
        assert_no_lints(
            "This is the email address that will receive the submitted form data.",
            VerbToAdjective::default(),
        );
    }

    #[test]
    fn the_unexplored_territories_is_valid() {
        assert_no_lints(
            "Not the unexplored territories, ripe for discovery, but the areas actively erased, obscured, or simply deemed unworthy of representation?",
            VerbToAdjective::default(),
        );
    }
}



================================================
FILE: harper-core/src/linting/very_unique.rs
================================================
use crate::linting::expr_linter::Chunk;
use crate::{
    Token, TokenStringExt,
    expr::{Expr, SequenceExpr},
    linting::{ExprLinter, Lint, LintKind, Suggestion},
    patterns::WordSet,
};

pub struct VeryUnique {
    expr: Box<dyn Expr>,
}

impl Default for VeryUnique {
    fn default() -> Self {
        Self {
            expr: Box::new(
                SequenceExpr::default()
                    .then(WordSet::new(&[
                        "fairly", "pretty", "rather", "quite", "somewhat", "very",
                    ]))
                    .t_ws()
                    .t_aco("unique"),
            ),
        }
    }
}

impl ExprLinter for VeryUnique {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, toks: &[Token], src: &[char]) -> Option<Lint> {
        let very_unique_span = toks.span()?;
        let very_unique_chars = very_unique_span.get_content(src);
        let qualifier_tok = &toks.first()?;
        let qualifier_str = qualifier_tok.span.get_content_string(src);

        let adjectives = ["special", "rare", "unusual"];

        let suggestions = adjectives
            .iter()
            .map(|adj| {
                Suggestion::replace_with_match_case(
                    format!("{qualifier_str} {adj}").chars().collect(),
                    very_unique_chars,
                )
            })
            .chain(std::iter::once(Suggestion::replace_with_match_case(
                "unique".chars().collect(),
                very_unique_chars,
            )))
            .collect::<Vec<_>>();

        Some(Lint {
            span: very_unique_span,
            lint_kind: LintKind::WordChoice,
            suggestions,
            message: "`Unique` is absolute, so consider using `unique` alone or a more precise adjective such as `special`, `rare`, or `unusual`.".to_string(),
            priority: 57,
        })
    }

    fn description(&self) -> &str {
        "Flags phrases like `very unique`, `pretty unique`, etc., and suggests using `unique` alone or a more precise adjective such as `special`, `rare`, or `unusual`."
    }
}

#[cfg(test)]
mod tests {
    use super::VeryUnique;
    use crate::linting::tests::{assert_good_and_bad_suggestions, assert_top3_suggestion_result};

    #[test]
    fn fix_very_unique() {
        assert_good_and_bad_suggestions(
            "I'm not sure whether Llama Stack or ollama are generating the chat completion ids, but they are not very unique.",
            VeryUnique::default(),
            &[
                "I'm not sure whether Llama Stack or ollama are generating the chat completion ids, but they are not unique.",
            ],
            &[],
        );
    }

    #[test]
    fn fix_pretty_unique() {
        assert_top3_suggestion_result(
            "Numerous accounts with my exact full name/surname (which is pretty unique) has been created (most recently).",
            VeryUnique::default(),
            "Numerous accounts with my exact full name/surname (which is pretty rare) has been created (most recently).",
        );
    }

    #[test]
    fn fix_fairly_unique() {
        assert_good_and_bad_suggestions(
            "In browsers, the first chars are obtained from the user agent string (which is fairly unique), and the supported mimeTypes",
            VeryUnique::default(),
            &[
                "In browsers, the first chars are obtained from the user agent string (which is unique), and the supported mimeTypes",
            ],
            &[],
        );
    }

    #[test]
    fn fix_somewhat_unique() {
        assert_top3_suggestion_result(
            "A new pack of somewhat unique upgrades for R.E.P.O.!",
            VeryUnique::default(),
            "A new pack of somewhat unusual upgrades for R.E.P.O.!",
        );
    }

    #[test]
    fn fix_quite_unique() {
        assert_good_and_bad_suggestions(
            "Now I understand that this is quite unique to insta and if it's not useful I am also going to investigate alternatives",
            VeryUnique::default(),
            &[
                "Now I understand that this is unique to insta and if it's not useful I am also going to investigate alternatives",
            ],
            &[],
        );
    }

    #[test]
    fn fix_rather_unique() {
        assert_top3_suggestion_result(
            "I regret using the Vue compiler because the resulting AST is rather unique.",
            VeryUnique::default(),
            "I regret using the Vue compiler because the resulting AST is rather unusual.",
        );
    }
}



================================================
FILE: harper-core/src/linting/vice_versa.rs
================================================
use crate::expr::{Expr, SequenceExpr};
use crate::linting::expr_linter::Chunk;
use crate::linting::{ExprLinter, Lint, LintKind, Suggestion};
use crate::{Token, TokenStringExt};

fn matches_hyphen(token: &Token, _source: &[char]) -> bool {
    token.kind.is_hyphen()
}

fn replacement_for(template: &[char]) -> Vec<char> {
    let mut replacement = "vice versa".chars().collect::<Vec<_>>();

    let mut has_upper = false;
    let mut has_lower = false;
    let mut first_alpha_upper = None;

    for ch in template.iter().copied() {
        if !ch.is_alphabetic() {
            continue;
        }

        has_upper |= ch.is_uppercase();
        has_lower |= ch.is_lowercase();

        if first_alpha_upper.is_none() {
            first_alpha_upper = Some(ch.is_uppercase());
        }
    }

    if has_upper && !has_lower {
        for ch in replacement.iter_mut() {
            if ch.is_alphabetic() {
                *ch = ch.to_ascii_uppercase();
            }
        }

        return replacement;
    }

    if !has_upper {
        return replacement;
    }

    if first_alpha_upper.unwrap_or(false) {
        let mut capitalized_first = false;

        for ch in replacement.iter_mut() {
            if !ch.is_alphabetic() {
                continue;
            }

            if !capitalized_first {
                *ch = ch.to_ascii_uppercase();
                capitalized_first = true;
            } else {
                *ch = ch.to_ascii_lowercase();
            }
        }

        return replacement;
    }

    for ch in replacement.iter_mut() {
        if ch.is_alphabetic() {
            *ch = ch.to_ascii_lowercase();
        }
    }

    replacement
}

pub struct ViceVersa {
    expr: Box<dyn Expr>,
}

impl Default for ViceVersa {
    fn default() -> Self {
        let expr = SequenceExpr::word_set(&["vice", "vise"])
            .then(matches_hyphen)
            .then_optional(SequenceExpr::aco("a").then(matches_hyphen))
            .then(SequenceExpr::aco("versa"));

        Self {
            expr: Box::new(expr),
        }
    }
}

impl ExprLinter for ViceVersa {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], source: &[char]) -> Option<Lint> {
        let span = matched_tokens.span()?;
        let template = span.get_content(source);

        Some(Lint {
            span,
            lint_kind: LintKind::Punctuation,
            suggestions: vec![Suggestion::ReplaceWith(replacement_for(template))],
            message: "The expression \"vice versa\" is spelled without hyphens.".to_owned(),
            priority: 60,
        })
    }

    fn description(&self) -> &str {
        "Recommends writing ‘vice versa’ without hyphens."
    }
}

#[cfg(test)]
mod tests {
    use super::ViceVersa;
    use crate::linting::tests::{assert_lint_count, assert_suggestion_result};

    #[test]
    fn corrects_basic_hyphenated() {
        assert_suggestion_result(
            "We swapped the arguments vice-versa this time.",
            ViceVersa::default(),
            "We swapped the arguments vice versa this time.",
        );
    }

    #[test]
    fn corrects_leading_capitalization() {
        assert_suggestion_result(
            "Vice-Versa, the movie, was interesting.",
            ViceVersa::default(),
            "Vice versa, the movie, was interesting.",
        );
    }

    #[test]
    fn corrects_all_caps() {
        assert_suggestion_result(
            "They agreed VICE-VERSA on the clause.",
            ViceVersa::default(),
            "They agreed VICE VERSA on the clause.",
        );
    }

    #[test]
    fn corrects_with_extra_a() {
        assert_suggestion_result(
            "The logic works vice-a-versa as well.",
            ViceVersa::default(),
            "The logic works vice versa as well.",
        );
    }

    #[test]
    fn corrects_vise_variant() {
        assert_suggestion_result(
            "The rule applies vise-versa too.",
            ViceVersa::default(),
            "The rule applies vice versa too.",
        );
    }

    #[test]
    fn corrects_vise_extra_a_variant() {
        assert_suggestion_result(
            "The rule applies Vise-A-Versa too.",
            ViceVersa::default(),
            "The rule applies Vice versa too.",
        );
    }

    #[test]
    fn corrects_with_trailing_suffix() {
        assert_suggestion_result(
            "That was a vice-versa-like transformation.",
            ViceVersa::default(),
            "That was a vice versa-like transformation.",
        );
    }

    #[test]
    fn allows_correct_spelling() {
        assert_lint_count(
            "We swapped the arguments vice versa this time.",
            ViceVersa::default(),
            0,
        );
    }

    #[test]
    fn allows_sentence_case() {
        assert_lint_count(
            "Vice versa, the movie, was interesting.",
            ViceVersa::default(),
            0,
        );
    }

    #[test]
    fn does_not_flag_unrelated_words() {
        assert_lint_count(
            "Their service-versa mapping was custom.",
            ViceVersa::default(),
            0,
        );
    }
}



================================================
FILE: harper-core/src/linting/was_aloud.rs
================================================
use super::{ExprLinter, Lint, LintKind};
use crate::Token;
use crate::TokenStringExt;
use crate::expr::Expr;
use crate::expr::SequenceExpr;
use crate::linting::Suggestion;
use crate::linting::expr_linter::Chunk;
use crate::patterns::WordSet;

pub struct WasAloud {
    expr: Box<dyn Expr>,
}

impl Default for WasAloud {
    fn default() -> Self {
        let pattern = SequenceExpr::default()
            .then(WordSet::new(&["was", "were", "be", "been"]))
            .then_whitespace()
            .then_exact_word("aloud");

        Self {
            expr: Box::new(pattern),
        }
    }
}

impl ExprLinter for WasAloud {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], source: &[char]) -> Option<Lint> {
        let verb = matched_tokens[0].span.get_content_string(source);

        Some(Lint {
            span: matched_tokens.span()?,
            lint_kind: LintKind::WordChoice,
            suggestions: vec![Suggestion::replace_with_match_case(
                format!("{verb} allowed").chars().collect(),
                matched_tokens[0].span.get_content(source),
            )],
            message: format!("Did you mean `{verb} allowed`?"),
            priority: 31,
        })
    }

    fn description(&self) -> &'static str {
        "Ensures `was aloud` and `were aloud` are corrected to `was allowed` or `were allowed` when referring to permission."
    }
}

#[cfg(test)]
mod tests {
    use super::WasAloud;
    use crate::linting::tests::assert_suggestion_result;

    #[test]
    fn corrects_was_aloud() {
        assert_suggestion_result(
            "He was aloud to enter the room.",
            WasAloud::default(),
            "He was allowed to enter the room.",
        );
    }

    #[test]
    fn corrects_were_aloud() {
        assert_suggestion_result(
            "They were aloud to participate.",
            WasAloud::default(),
            "They were allowed to participate.",
        );
    }

    #[test]
    fn does_not_correct_proper_use_of_aloud() {
        assert_suggestion_result(
            "She read the passage aloud to the class.",
            WasAloud::default(),
            "She read the passage aloud to the class.",
        );
    }

    #[test]
    fn does_not_flag_unrelated_text() {
        assert_suggestion_result(
            "The concert was loud and exciting.",
            WasAloud::default(),
            "The concert was loud and exciting.",
        );
    }

    #[test]
    fn be_aloud() {
        assert_suggestion_result(
            "You may be aloud to enter the room.",
            WasAloud::default(),
            "You may be allowed to enter the room.",
        );
    }

    #[test]
    fn been_aloud() {
        assert_suggestion_result(
            "If I had been aloud to enter I would've jumped at the chance.",
            WasAloud::default(),
            "If I had been allowed to enter I would've jumped at the chance.",
        );
    }
}



================================================
FILE: harper-core/src/linting/way_too_adjective.rs
================================================
use harper_brill::UPOS;

use crate::Token;
use crate::expr::{All, Expr, OwnedExprExt, SequenceExpr};
use crate::patterns::{UPOSSet, WordSet};

use super::{ExprLinter, Lint, LintKind, Suggestion};
use crate::linting::expr_linter::Chunk;

pub struct WayTooAdjective {
    expr: Box<dyn Expr>,
}

impl Default for WayTooAdjective {
    fn default() -> Self {
        let base = SequenceExpr::default()
            .t_aco("way")
            .t_ws()
            .t_aco("to")
            .t_ws()
            .then(UPOSSet::new(&[UPOS::ADJ]).or(WordSet::new(&["much"])));

        let exceptions = SequenceExpr::anything()
            .t_any()
            .t_any()
            .t_any()
            .then(WordSet::new(&["surface", "return", "aqua"]));

        let expr = All::new(vec![
            Box::new(base),
            Box::new(SequenceExpr::default().then_unless(exceptions)),
        ]);

        Self {
            expr: Box::new(expr),
        }
    }
}

impl ExprLinter for WayTooAdjective {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, toks: &[Token], src: &[char]) -> Option<Lint> {
        let to_tok = toks.get(2)?;
        let span = to_tok.span;
        let original = span.get_content(src);

        Some(Lint {
            span,
            lint_kind: LintKind::Miscellaneous,
            suggestions: vec![Suggestion::replace_with_match_case(
                "too".chars().collect(),
                original,
            )],
            message: "Did you mean “too”?".into(),
            priority: 25,
        })
    }

    fn description(&self) -> &'static str {
        "Replaces the preposition `to` with the adverb `too` after `way` when followed by an \
         adjective (e.g. `way too fast`)"
    }
}

#[cfg(test)]
mod tests {
    use super::WayTooAdjective;
    use crate::linting::tests::{assert_lint_count, assert_suggestion_result};

    #[test]
    fn corrects_way_to_fast() {
        assert_suggestion_result(
            "You drive way to fast.",
            WayTooAdjective::default(),
            "You drive way too fast.",
        );
    }

    #[test]
    fn corrects_way_to_complicated() {
        assert_suggestion_result(
            "I think this would be way to complicated to implement.",
            WayTooAdjective::default(),
            "I think this would be way too complicated to implement.",
        );
    }

    #[test]
    fn corrects_way_to_much() {
        assert_suggestion_result(
            "…and ate way to much.",
            WayTooAdjective::default(),
            "…and ate way too much.",
        );
    }

    #[test]
    fn allows_fast_way_to_test() {
        assert_lint_count(
            "Fast way to test daily defence teams?",
            WayTooAdjective::default(),
            0,
        );
    }
}



================================================
FILE: harper-core/src/linting/well_educated.rs
================================================
use crate::{
    Token, TokenStringExt,
    expr::{Expr, SequenceExpr},
    patterns::{WhitespacePattern, WordSet},
};

use super::{ExprLinter, Lint, LintKind, Suggestion};
use crate::linting::expr_linter::Chunk;

pub struct WellEducated {
    expr: Box<dyn Expr>,
}

impl Default for WellEducated {
    fn default() -> Self {
        let combined = WordSet::new(&["good-educated"]);

        let separated = SequenceExpr::default()
            .t_aco("good")
            .then_optional(WhitespacePattern)
            .then_hyphen()
            .then_optional(WhitespacePattern)
            .t_aco("educated");

        let expr =
            SequenceExpr::default().then_any_of(vec![Box::new(combined), Box::new(separated)]);

        Self {
            expr: Box::new(expr),
        }
    }
}

impl ExprLinter for WellEducated {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], source: &[char]) -> Option<Lint> {
        let span = matched_tokens.span()?;
        let original = span.get_content(source);

        Some(Lint {
            span,
            lint_kind: LintKind::Miscellaneous,
            suggestions: vec![Suggestion::replace_with_match_case(
                "well-educated".chars().collect(),
                original,
            )],
            message: "Prefer `well-educated` for this compound.".into(),
            priority: 35,
        })
    }

    fn description(&self) -> &'static str {
        "Replaces `good-educated` with the accepted compound `well-educated`."
    }
}

#[cfg(test)]
mod tests {
    use super::WellEducated;
    use crate::linting::tests::{assert_lint_count, assert_suggestion_result};

    #[test]
    fn corrects_simple_sentence() {
        assert_suggestion_result(
            "She is good-educated.",
            WellEducated::default(),
            "She is well-educated.",
        );
    }

    #[test]
    fn corrects_in_clause() {
        assert_suggestion_result(
            "The panel found him good-educated and articulate.",
            WellEducated::default(),
            "The panel found him well-educated and articulate.",
        );
    }

    #[test]
    fn corrects_with_modifier() {
        assert_suggestion_result(
            "They considered her very good-educated for her age.",
            WellEducated::default(),
            "They considered her very well-educated for her age.",
        );
    }

    #[test]
    fn corrects_all_caps() {
        assert_suggestion_result(
            "Their mentors are GOOD-EDUCATED leaders.",
            WellEducated::default(),
            "Their mentors are WELL-EDUCATED leaders.",
        );
    }

    #[test]
    fn corrects_title_case() {
        assert_suggestion_result(
            "The report lauded Good-Educated Candidates.",
            WellEducated::default(),
            "The report lauded Well-Educated Candidates.",
        );
    }

    #[test]
    fn corrects_with_quotes() {
        assert_suggestion_result(
            "He called them \"good-educated\" professionals.",
            WellEducated::default(),
            "He called them \"well-educated\" professionals.",
        );
    }

    #[test]
    fn corrects_split_tokens() {
        assert_suggestion_result(
            "Their children are good - educated despite the odds.",
            WellEducated::default(),
            "Their children are well-educated despite the odds.",
        );
    }

    #[test]
    fn allows_well_educated() {
        assert_lint_count("She is well-educated.", WellEducated::default(), 0);
    }

    #[test]
    fn allows_good_education_phrase() {
        assert_lint_count(
            "They received a good education.",
            WellEducated::default(),
            0,
        );
    }

    #[test]
    fn allows_good_to_be_educated() {
        assert_lint_count(
            "It is good to be educated about local history.",
            WellEducated::default(),
            0,
        );
    }
}



================================================
FILE: harper-core/src/linting/whereas.rs
================================================
use crate::expr::Expr;
use crate::expr::SequenceExpr;
use crate::{Token, TokenStringExt};

use super::{ExprLinter, Lint, LintKind, Suggestion};
use crate::linting::expr_linter::Chunk;

pub struct Whereas {
    expr: Box<dyn Expr>,
}

impl Default for Whereas {
    fn default() -> Self {
        let pattern = SequenceExpr::default()
            .t_aco("where")
            .then_whitespace()
            .t_aco("as");

        Self {
            expr: Box::new(pattern),
        }
    }
}

impl ExprLinter for Whereas {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], source: &[char]) -> Option<Lint> {
        let span = matched_tokens.span()?;
        let orig_chars = span.get_content(source);

        Some(Lint {
            span,
            lint_kind: LintKind::WordChoice,
            suggestions: vec![Suggestion::replace_with_match_case(
                vec!['w', 'h', 'e', 'r', 'e', 'a', 's'],
                orig_chars,
            )],
            message: "`Whereas` is commonly mistaken for `where as`.".to_owned(),
            ..Default::default()
        })
    }

    fn description(&self) -> &'static str {
        "The Whereas rule is designed to identify instances where the phrase `where as` is used in text and suggests replacing it with the single word `whereas`."
    }
}

#[cfg(test)]
mod tests {
    use crate::linting::tests::assert_suggestion_result;

    use super::Whereas;

    #[test]
    fn where_as() {
        assert_suggestion_result(
            "Dogs love playing fetch, where as cats are more independent creatures.",
            Whereas::default(),
            "Dogs love playing fetch, whereas cats are more independent creatures.",
        );
    }
}



================================================
FILE: harper-core/src/linting/whom_subject_of_verb.rs
================================================
use crate::{
    CharStringExt, Lint, Token,
    expr::{Expr, SequenceExpr},
    linting::{ExprLinter, LintKind, Suggestion, expr_linter::Chunk},
    patterns::ModalVerb,
};

pub struct WhomSubjectOfVerb {
    expr: Box<dyn Expr>,
}

impl Default for WhomSubjectOfVerb {
    fn default() -> Self {
        Self {
            expr: Box::new(
                SequenceExpr::word_set(&["whom", "whomever", "whomsoever"])
                    .t_ws()
                    // .then_verb()
                    .then_any_of(vec![
                        Box::new(SequenceExpr::default().then_kind_where(|k| {
                            k.is_verb_third_person_singular_present_form()
                                || k.is_verb_simple_past_form()
                        })),
                        Box::new(ModalVerb::with_common_errors()),
                    ]),
            ),
        }
    }
}

impl ExprLinter for WhomSubjectOfVerb {
    type Unit = Chunk;

    fn description(&self) -> &str {
        "Detects whom and its variants used as the subject of a verb instead of who."
    }

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint_with_context(
        &self,
        toks: &[Token],
        src: &[char],
        ctx: Option<(&[Token], &[Token])>,
    ) -> Option<Lint> {
        if let Some((before, _)) = ctx
            && let [.., word, ws1, prep, ws2] = before
            && ws2.kind.is_whitespace()
            && prep
                .span
                .get_content(src)
                .eq_ignore_ascii_case_chars(&['o', 'f'])
            && ws1.kind.is_whitespace()
            && word.span.get_content(src).eq_ignore_ascii_case_str("many")
        {
            return None;
        }

        let whom_span = toks.first()?.span;
        let whom_chars = whom_span.get_content(src);

        let who_vec = [&whom_chars[..3], &whom_chars[4..]].concat();

        Some(Lint {
            span: whom_span,
            lint_kind: LintKind::Grammar,
            suggestions: vec![Suggestion::replace_with_match_case(who_vec, whom_chars)],
            message: "“Whom” is used for the object of a verb and “who” is used for the subject of a verb.".to_owned(),
            ..Default::default()
        })
    }
}

#[cfg(test)]
mod tests {
    use super::WhomSubjectOfVerb;
    use crate::linting::tests::{assert_lint_count, assert_no_lints, assert_suggestion_result};

    #[test]
    fn flag_whom_has() {
        assert_suggestion_result(
            "there is no course to whom has opened the most PRs",
            WhomSubjectOfVerb::default(),
            "there is no course to who has opened the most PRs",
        );
    }

    #[test]
    fn flag_whomever_wrote() {
        assert_suggestion_result(
            "To whomever wrote this course, I truly am not trying to be a jerk or ungrateful",
            WhomSubjectOfVerb::default(),
            "To whoever wrote this course, I truly am not trying to be a jerk or ungrateful",
        );
    }

    #[test]
    #[ignore = "wrong kind of error"]
    fn dont_flag_wrong_kind_of_error() {
        assert_lint_count(
            "self service ticket view is not showing to whom is the ticket assigned to",
            //   "self service ticket view is not showing to whom this ticket is assigned"
            //   "self service ticket view is not showing whom this ticket is assigned to"
            WhomSubjectOfVerb::default(),
            0,
        );
    }

    #[test]
    fn dont_flag_whom_can() {
        assert_suggestion_result(
            "Whom can of course build a helper, but that is only a workaround.",
            WhomSubjectOfVerb::default(),
            "Who can of course build a helper, but that is only a workaround.",
        );
    }

    #[test]
    fn flag_whomever_is() {
        assert_suggestion_result(
            "Whomever is making those harassing phone calls to me after I post something on Github - consider yourself put on notice.",
            WhomSubjectOfVerb::default(),
            "Whoever is making those harassing phone calls to me after I post something on Github - consider yourself put on notice.",
        );
    }

    #[test]
    fn flag_whom_is() {
        assert_suggestion_result(
            "I thought it might be good idea to address the topic of whom is \"allowed\" to merge.",
            WhomSubjectOfVerb::default(),
            "I thought it might be good idea to address the topic of who is \"allowed\" to merge.",
        );
    }

    #[test]
    fn flag_whomsoever_will() {
        assert_suggestion_result(
            "This is a quick record of my discoveries and solution for whomsoever will be fixing the issue.",
            WhomSubjectOfVerb::default(),
            "This is a quick record of my discoveries and solution for whosoever will be fixing the issue.",
        );
    }

    #[test]
    fn dont_flag_many_of_whom() {
        assert_no_lints(
            "it's far from straightforward for new users, many of whom will likely have a lot to learn",
            WhomSubjectOfVerb::default(),
        );
    }
}



================================================
FILE: harper-core/src/linting/widely_accepted.rs
================================================
use crate::expr::Expr;
use crate::expr::SequenceExpr;
use crate::linting::expr_linter::Chunk;
use crate::{
    Token,
    linting::{ExprLinter, Lint, LintKind, Suggestion},
    patterns::{Word, WordSet},
};

pub struct WidelyAccepted {
    expr: SequenceExpr,
}

impl Default for WidelyAccepted {
    fn default() -> Self {
        let expr = SequenceExpr::default()
            .then(Word::new("wide"))
            .then_whitespace()
            .then(WordSet::new(&["accepted", "acceptable", "used"]));

        Self { expr }
    }
}

impl ExprLinter for WidelyAccepted {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        &self.expr
    }

    fn match_to_lint(&self, matched_tokens: &[Token], source: &[char]) -> Option<Lint> {
        // We only need to replace the `wide` token with `widely`.
        let wide_token = matched_tokens.first()?;
        let wide_chars = wide_token.span.get_content(source);

        Some(Lint {
            span: wide_token.span,
            lint_kind: LintKind::Miscellaneous,
            message: "Use the adverb `widely` in this context. For example, `widely accepted` or `widely used` is standard usage."
                .to_owned(),
            suggestions: vec![Suggestion::replace_with_match_case_str("widely", wide_chars)],
            priority: 31,
        })
    }

    fn description(&self) -> &str {
        "Flags `wide accepted`, `wide acceptable`, or `wide used` and recommends switching `wide` to the adverb `widely`."
    }
}

#[cfg(test)]
mod tests {
    use super::WidelyAccepted;
    use crate::linting::tests::{assert_lint_count, assert_suggestion_result};

    #[test]
    fn wide_accepted_lowercase() {
        assert_suggestion_result(
            "It is wide accepted that exercise improves health.",
            WidelyAccepted::default(),
            "It is widely accepted that exercise improves health.",
        );
    }

    #[test]
    fn wide_acceptable_mixed_case() {
        assert_suggestion_result(
            "Wide acceptable standards are used in the design.",
            WidelyAccepted::default(),
            "Widely acceptable standards are used in the design.",
        );
    }

    #[test]
    fn widely_already_correct() {
        assert_lint_count(
            "It is widely accepted that sunlight is beneficial in moderation.",
            WidelyAccepted::default(),
            0,
        );
    }

    #[test]
    fn no_false_positive() {
        assert_lint_count(
            "The house had wide open windows during the renovation.",
            WidelyAccepted::default(),
            0,
        );
    }

    #[test]
    fn wide_accepted_in_long_text() {
        assert_suggestion_result(
            "This is an example paragraph, and it is wide accepted that these changes will improve performance. In fact, widely used frameworks have already adopted them.",
            WidelyAccepted::default(),
            "This is an example paragraph, and it is widely accepted that these changes will improve performance. In fact, widely used frameworks have already adopted them.",
        );
    }

    #[test]
    fn wide_twice_in_one_sentence() {
        assert_suggestion_result(
            "It is wide accepted and wide used by many professionals.",
            WidelyAccepted::default(),
            "It is widely accepted and widely used by many professionals.",
        );
    }
}



================================================
FILE: harper-core/src/linting/win_prize.rs
================================================
use crate::expr::SequenceExpr;
use crate::expr::{Expr, OwnedExprExt};
use crate::linting::expr_linter::Chunk;
use crate::{
    Lrc, Token,
    linting::{ExprLinter, Lint, LintKind, Suggestion},
    patterns::WordSet,
};

pub struct WinPrize {
    expr: Box<dyn Expr>,
}

impl Default for WinPrize {
    fn default() -> Self {
        let verbs = Lrc::new(WordSet::new(&["win", "wins", "won", "winning"]));
        let miss = Lrc::new(WordSet::new(&["price", "prices", "prise", "prises"]));

        let pattern = SequenceExpr::default()
            .then(verbs.clone())
            .then_whitespace()
            .then_determiner()
            .then_whitespace()
            .then(miss.clone())
            .or_longest(
                SequenceExpr::default()
                    .then(verbs)
                    .then_whitespace()
                    .then(miss),
            );

        Self {
            expr: Box::new(pattern),
        }
    }
}

impl ExprLinter for WinPrize {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, toks: &[Token], src: &[char]) -> Option<Lint> {
        let candidate = toks.last()?;
        let raw = candidate.span.get_content_string(src).to_lowercase();
        let repl = match raw.as_str() {
            "price" | "prise" => "prize",
            "prices" | "prises" => "prizes",
            _ => return None,
        };

        Some(Lint {
            span: candidate.span,
            lint_kind: LintKind::Miscellaneous,
            suggestions: vec![Suggestion::ReplaceWith(repl.chars().collect())],
            message: format!("Perhaps you meant `{repl}`, the word for an award."),
            priority: 50,
        })
    }

    fn description(&self) -> &str {
        "Catches the mix-up between `price`/`prise` and `prize` after the verb `win`."
    }
}

#[cfg(test)]
mod tests {
    use super::WinPrize;
    use crate::linting::tests::{
        assert_lint_count, assert_suggestion_result, assert_top3_suggestion_result,
    };

    #[test]
    fn fix_price_singular() {
        assert_suggestion_result(
            "Lena won a price in the coding marathon.",
            WinPrize::default(),
            "Lena won a prize in the coding marathon.",
        );
    }

    #[test]
    fn fix_price_plural() {
        assert_top3_suggestion_result(
            "Our team won the prices announced yesterday.",
            WinPrize::default(),
            "Our team won the prizes announced yesterday.",
        );
    }

    #[test]
    fn fix_prise_singular() {
        assert_suggestion_result(
            "He finally won the prise he'd dreamed of.",
            WinPrize::default(),
            "He finally won the prize he'd dreamed of.",
        );
    }

    #[test]
    fn fix_prise_plural() {
        assert_suggestion_result(
            "The inventors won several prises at the expo.",
            WinPrize::default(),
            "The inventors won several prizes at the expo.",
        );
    }

    #[test]
    fn ignore_correct_prize() {
        assert_lint_count(
            "Miranda won the grand prize last year.",
            WinPrize::default(),
            0,
        );
    }

    #[test]
    fn fix_no_det() {
        assert_suggestion_result("I won prices!", WinPrize::default(), "I won prizes!");
    }
}



================================================
FILE: harper-core/src/linting/wish_could.rs
================================================
use super::{Lint, LintKind, Suggestion};
use crate::Token;
use crate::expr::{Expr, SequenceExpr};
use crate::linting::{ExprLinter, expr_linter::Chunk};

pub struct WishCould {
    expr: Box<dyn Expr>,
}

impl Default for WishCould {
    fn default() -> Self {
        Self {
            expr: Box::new(
                SequenceExpr::word_set(&["wish", "wished", "wishes", "wishing"])
                    .t_ws()
                    .then_any_of(vec![
                        Box::new(SequenceExpr::default().then_subject_pronoun()),
                        Box::new(SequenceExpr::word_set(&[
                            // Elective existential indefinite pronouns
                            "anybody",
                            "anyone",
                            // Universal indefinite pronouns
                            "everybody",
                            "everyone",
                            // Negative indefinite pronouns (correct)
                            "nobody",
                            // Negative indefinite pronouns (incorrect)
                            "noone",
                            // Assertive existential indefinite pronouns
                            "somebody",
                            "someone",
                            // Demonstrative pronouns
                            "these",
                            "this",
                            "those",
                        ])),
                    ])
                    .t_ws()
                    .t_aco("can"),
            ),
        }
    }
}

impl ExprLinter for WishCould {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        &*self.expr
    }

    fn match_to_lint(&self, toks: &[Token], src: &[char]) -> Option<Lint> {
        let can_tok = toks.last()?;
        let can_span = can_tok.span;

        Some(Lint {
            span: can_span,
            lint_kind: LintKind::Grammar,
            suggestions: vec![Suggestion::replace_with_match_case_str(
                "could",
                can_span.get_content(src),
            )],
            message: "Use 'could' instead of 'can' after 'wish'.".to_string(),
            ..Default::default()
        })
    }

    fn description(&self) -> &str {
        "Checks for `can` being used after `wish` when it should be `could`."
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::linting::tests::assert_suggestion_result;

    #[test]
    fn flag_wish_we_can() {
        assert_suggestion_result(
            "i wish we can spend more time together",
            WishCould::default(),
            "i wish we could spend more time together",
        );
    }

    #[test]
    fn flag_wish_i_can() {
        assert_suggestion_result(
            "I wish I can finally forgive myself for all the things I am not.",
            WishCould::default(),
            "I wish I could finally forgive myself for all the things I am not.",
        );
    }

    #[test]
    fn flag_wish_you_can() {
        assert_suggestion_result(
            "I wish you can find your true love.",
            WishCould::default(),
            "I wish you could find your true love.",
        );
    }

    #[test]
    fn flag_wishes_they_can() {
        assert_suggestion_result(
            "What your Therapist wishes they can tell you.",
            WishCould::default(),
            "What your Therapist wishes they could tell you.",
        );
    }

    #[test]
    fn flag_wishing_someone_can() {
        assert_suggestion_result(
            "Forever wishing someone can point me in the right direction",
            WishCould::default(),
            "Forever wishing someone could point me in the right direction",
        );
    }

    #[test]
    fn flag_wish_they_can() {
        assert_suggestion_result(
            "I wish they can plant more trees on this road.",
            WishCould::default(),
            "I wish they could plant more trees on this road.",
        );
    }

    #[test]
    fn flag_wished_he_can() {
        assert_suggestion_result(
            "I just wished he can talk and tell me how he feels",
            WishCould::default(),
            "I just wished he could talk and tell me how he feels",
        );
    }

    #[test]
    fn wish_this_can() {
        assert_suggestion_result(
            "but I wish this can be fixed by Electron team",
            WishCould::default(),
            "but I wish this could be fixed by Electron team",
        )
    }

    #[test]
    fn wish_it_can() {
        assert_suggestion_result(
            "Wish it can be supported.",
            WishCould::default(),
            "Wish it could be supported.",
        )
    }

    #[test]
    fn wish_somebody_can() {
        assert_suggestion_result(
            "I wish somebody can fix this issue.",
            WishCould::default(),
            "I wish somebody could fix this issue.",
        )
    }
}



================================================
FILE: harper-core/src/linting/wordpress_dotcom.rs
================================================
use crate::{CharString, CharStringExt, TokenStringExt};

use super::{Lint, LintKind, Linter, Suggestion};

/// Make sure you properly capitalize `WordPress.com`.
#[derive(Default)]
pub struct WordPressDotcom;

impl Linter for WordPressDotcom {
    fn lint(&mut self, document: &crate::Document) -> Vec<Lint> {
        let correct: CharString = "WordPress.com".chars().collect();
        let correct_lower = correct.to_lower();
        let mut lints = Vec::new();

        for hostname in document.iter_hostnames() {
            let text = document.get_span_content(&hostname.span);

            if correct.as_slice() != text && text.to_lower() == correct_lower {
                lints.push(Lint {
                    span: hostname.span,
                    lint_kind: LintKind::Style,
                    suggestions: vec![Suggestion::ReplaceWith(correct.to_vec())],
                    message: "The WordPress hosting provider should be stylized as `WordPress.com`"
                        .to_owned(),
                    priority: 31,
                });
            }
        }

        lints
    }

    fn description(&self) -> &str {
        "Ensures correct capitalization of WordPress.com. This rule verifies that the official stylization of WordPress.com is used when referring to the hosting provider."
    }
}

#[cfg(test)]
mod tests {
    use crate::linting::tests::assert_suggestion_result;

    use super::WordPressDotcom;

    #[test]
    fn simple() {
        assert_suggestion_result("wordpress.com", WordPressDotcom, "WordPress.com");
    }

    #[test]
    fn sentence() {
        assert_suggestion_result(
            "wordpress.com is a great hosting provider",
            WordPressDotcom,
            "WordPress.com is a great hosting provider",
        );
    }
}



================================================
FILE: harper-core/src/linting/would_never_have.rs
================================================
use crate::linting::expr_linter::Chunk;
use crate::{
    Token,
    expr::{Expr, FixedPhrase, SequenceExpr},
    linting::{ExprLinter, Lint, LintKind, Suggestion},
    token_string_ext::TokenStringExt,
};

pub struct WouldNeverHave {
    expr: Box<dyn Expr>,
}

impl Default for WouldNeverHave {
    fn default() -> Self {
        let phrases = [
            "could have never",
            "could never have",
            "could've never",
            "couldve never",
            "would have never",
            "would never have",
            "would've never",
            "wouldve never",
        ];

        let expr: Vec<Box<dyn Expr>> = phrases
            .iter()
            .map(|&phrase| Box::new(FixedPhrase::from_phrase(phrase)) as Box<dyn Expr>)
            .collect();

        // TODO: verb should be perfect form ("done", "happened", etc.) when verb property changes are merged
        let expr = SequenceExpr::any_of(expr).then_whitespace().then_verb();

        Self {
            expr: Box::new(expr),
        }
    }
}

impl ExprLinter for WouldNeverHave {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, toks: &[Token], src: &[char]) -> Option<Lint> {
        let modal_have_toks = toks.first()?;
        let modal_have_chars = modal_have_toks.span.get_content(src);
        let modal_have_str = modal_have_toks.span.get_content_string(src).to_lowercase();

        let modal = if modal_have_str.starts_with("could") {
            "could"
        } else if modal_have_str.starts_with("would") {
            "would"
        } else {
            return None;
        };

        let is_contraction = modal_have_str.ends_with("ve");

        let new_phrasing = format!(
            "never {modal}{}",
            if is_contraction { "'ve" } else { " have" }
        );

        let suggestions = vec![Suggestion::replace_with_match_case(
            new_phrasing.chars().collect(),
            modal_have_chars,
        )];

        let message = format!("For a more standard style, consider using `{new_phrasing}`.");

        Some(Lint {
            span: toks[..toks.len() - 2].span()?,
            lint_kind: LintKind::Style,
            suggestions,
            message,
            ..Default::default()
        })
    }

    fn description(&self) -> &str {
        "Corrects `would/could have never` to `never would/could have`."
    }
}

#[cfg(test)]
mod tests {
    use super::WouldNeverHave;
    use crate::linting::tests::assert_suggestion_result;

    #[test]
    fn fix_could_have_never_been() {
        assert_suggestion_result(
            "Having a conversation would have never been easier with Ramen!",
            WouldNeverHave::default(),
            "Having a conversation never would have been easier with Ramen!",
        );
    }

    #[test]
    fn fix_would_have_never_come() {
        assert_suggestion_result(
            "This would have never come about without the help and encouragement of many people, too numerous to mention here.",
            WouldNeverHave::default(),
            "This never would have come about without the help and encouragement of many people, too numerous to mention here.",
        );
    }

    #[test]
    fn fix_would_have_never_find() {
        assert_suggestion_result(
            "Thanks for the help, think I would have never find it out alone.",
            WouldNeverHave::default(),
            "Thanks for the help, think I never would have find it out alone.",
        );
    }

    #[test]
    fn fix_all_caps() {
        assert_suggestion_result(
            "I WOULD'VE NEVER THOUGHT TO TEST ALL CAPS.",
            WouldNeverHave::default(),
            "I NEVER WOULD'VE THOUGHT TO TEST ALL CAPS.",
        );
    }

    #[test]
    #[ignore = "Fails due to the strange way replace_with_match_case works"]
    fn fix_title_case() {
        assert_suggestion_result(
            "I Would Never Have Thought To Test Title Case English.",
            WouldNeverHave::default(),
            "I Never Would Have Thought To Test Title Case English.",
        );
    }

    #[test]
    fn fix_could_never_have_worked() {
        assert_suggestion_result(
            "ft_quantile_discretizer could never have worked",
            WouldNeverHave::default(),
            "ft_quantile_discretizer never could have worked",
        );
    }

    #[test]
    fn fix_would_never_have_thought_of() {
        assert_suggestion_result(
            "We discover security flaws that your team would never have thought of.",
            WouldNeverHave::default(),
            "We discover security flaws that your team never would have thought of.",
        );
    }

    #[test]
    fn fix_wouldve_never_known_missing_apostrophe() {
        assert_suggestion_result(
            "We wouldve never known from the current api docs",
            WouldNeverHave::default(),
            "We never would've known from the current api docs",
        );
    }

    #[test]
    fn fix_wouldve_never_grokked() {
        assert_suggestion_result(
            "I would've never grokked that it's an issue in rollup.",
            WouldNeverHave::default(),
            "I never would've grokked that it's an issue in rollup.",
        );
    }

    #[test]
    fn fix_couldve_never_designed() {
        assert_suggestion_result(
            "Without my subscription I could've never designed this in such little time without it.",
            WouldNeverHave::default(),
            "Without my subscription I never could've designed this in such little time without it.",
        );
    }
}



================================================
FILE: harper-core/src/linting/compound_nouns/compound_noun_after_det_adj.rs
================================================
use crate::expr::All;
use crate::expr::Expr;
use crate::expr::MergeableWords;
use crate::expr::OwnedExprExt;
use crate::expr::SequenceExpr;
use crate::patterns::InflectionOfBe;
use crate::{CharStringExt, TokenStringExt, linting::ExprLinter};

use super::{Lint, LintKind, Suggestion, is_content_word, predicate};
use crate::linting::expr_linter::Chunk;

use crate::{Lrc, Token};

/// Two adjacent words separated by whitespace that if joined would be a valid noun.
pub struct CompoundNounAfterDetAdj {
    expr: Box<dyn Expr>,
    split_expr: Lrc<MergeableWords>,
}

// This heuristic identifies potential compound nouns by:
// 1. Looking for a determiner or adjective (e.g., "a", "big", "red")
// 2. Followed by two content words (not determiners, adverbs, or prepositions)
// 3. Finally, checking if the combination forms a noun in the dictionary
//    that is not also an adjective
impl Default for CompoundNounAfterDetAdj {
    fn default() -> Self {
        let context_expr = SequenceExpr::default()
            .then(|tok: &Token, src: &[char]| {
                tok.kind.is_determiner()
                    || (tok.kind.is_adjective()
                        && *tok.span.get_content(src).to_lower() != ['g', 'o'])
            })
            .t_ws()
            .then(is_content_word)
            .t_ws()
            .then(is_content_word.and_not(InflectionOfBe::default()));

        let split_expr = Lrc::new(MergeableWords::new(|meta_closed, meta_open| {
            predicate(meta_closed, meta_open)
        }));

        let mut expr = All::default();
        expr.add(context_expr);
        expr.add(SequenceExpr::anything().t_any().then(split_expr.clone()));

        Self {
            expr: Box::new(expr),
            split_expr,
        }
    }
}

impl ExprLinter for CompoundNounAfterDetAdj {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], source: &[char]) -> Option<Lint> {
        if matched_tokens
            .first()?
            .span
            .get_content(source)
            .eq_ignore_ascii_case_str("that")
        {
            return None;
        }

        let span = matched_tokens[2..].span()?;
        let orig = span.get_content(source);
        // If the pattern matched, this will not return `None`.
        let word =
            self.split_expr
                .get_merged_word(&matched_tokens[2], &matched_tokens[4], source)?;

        Some(Lint {
            span,
            lint_kind: LintKind::WordChoice,
            suggestions: vec![Suggestion::replace_with_match_case(word.to_vec(), orig)],
            message: format!(
                "Did you mean the closed compound noun “{}”?",
                word.to_string()
            ),
            priority: 63,
        })
    }

    fn description(&self) -> &str {
        "Detects compound nouns split by a space and suggests merging them when both parts form a valid noun. Has checks to avoid erroneous cases."
    }
}



================================================
FILE: harper-core/src/linting/compound_nouns/compound_noun_after_possessive.rs
================================================
use crate::expr::All;
use crate::expr::Expr;
use crate::expr::MergeableWords;
use crate::expr::SequenceExpr;
use crate::patterns::AnyPattern;
use crate::{CharStringExt, Lrc, TokenStringExt, linting::ExprLinter};

use super::{Lint, LintKind, Suggestion, is_content_word, predicate};
use crate::linting::expr_linter::Chunk;

use crate::Token;

/// Looks for closed compound nouns which can be condensed due to their position after a
/// possessive noun (which implies ownership).
/// See also:
/// harper-core/src/linting/lets_confusion/mod.rs
/// harper-core/src/linting/lets_confusion/let_us_redundancy.rs
/// harper-core/src/linting/lets_confusion/no_contraction_with_verb.rs
/// harper-core/src/linting/pronoun_contraction/should_contract.rs
pub struct CompoundNounAfterPossessive {
    expr: Box<dyn Expr>,
    split_pattern: Lrc<MergeableWords>,
}

impl Default for CompoundNounAfterPossessive {
    fn default() -> Self {
        let context_pattern = SequenceExpr::default()
            .then_possessive_nominal()
            .t_ws()
            .then(is_content_word)
            .t_ws()
            .then(is_content_word);

        let split_pattern = Lrc::new(MergeableWords::new(|meta_closed, meta_open| {
            predicate(meta_closed, meta_open)
        }));

        let mut pattern = All::default();

        pattern.add(context_pattern);
        pattern.add(
            SequenceExpr::default()
                .then(AnyPattern)
                .then(AnyPattern)
                .then(split_pattern.clone()),
        );

        Self {
            expr: Box::new(pattern),
            split_pattern,
        }
    }
}

impl ExprLinter for CompoundNounAfterPossessive {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], source: &[char]) -> Option<Lint> {
        // "Let's" can technically be a possessive noun (of a lease, or a let in tennis, etc.)
        // but in practice it's almost always a contraction of "let us" before a verb
        // or a mistake for "lets", the 3rd person singular present form of "to let".
        let word_apostrophe_s = matched_tokens[0]
            .span
            .get_content_string(source)
            .to_lowercase()
            .replace('’', "'");
        if word_apostrophe_s == "let's" || word_apostrophe_s == "that's" {
            return None;
        }
        let span = matched_tokens[2..].span()?;
        // If the pattern matched, this will not return `None`.
        let word =
            self.split_pattern
                .get_merged_word(&matched_tokens[2], &matched_tokens[4], source)?;

        Some(Lint {
            span,
            lint_kind: LintKind::WordChoice,
            suggestions: vec![Suggestion::ReplaceWith(word.to_vec())],
            message: format!(
                "The possessive noun implies ownership of the closed compound noun “{}”.",
                word.to_string()
            ),
            priority: 63,
        })
    }

    fn description(&self) -> &str {
        "Detects split compound nouns following a possessive noun and suggests merging them."
    }
}

#[cfg(test)]
mod tests {
    use super::CompoundNounAfterPossessive;
    use crate::linting::tests::assert_lint_count;

    #[test]
    fn lets_is_not_possessive() {
        assert_lint_count(
            "Let's check out this article.",
            CompoundNounAfterPossessive::default(),
            0,
        );
    }

    #[test]
    fn lets_is_not_possessive_typographic_apostrophe() {
        assert_lint_count(
            "“Let’s go on with the game,” the Queen said to Alice;",
            CompoundNounAfterPossessive::default(),
            0,
        )
    }

    #[test]
    fn thats_is_not_possessive() {
        assert_lint_count(
            "And you might not be thinking that that's a very big issue, but ...",
            CompoundNounAfterPossessive::default(),
            0,
        );
    }
}



================================================
FILE: harper-core/src/linting/compound_nouns/compound_noun_before_aux_verb.rs
================================================
use crate::expr::All;
use crate::expr::Expr;
use crate::expr::MergeableWords;
use crate::expr::SequenceExpr;
use crate::patterns::AnyPattern;
use crate::{CharStringExt, Lrc, TokenStringExt, linting::ExprLinter};

use super::{Lint, LintKind, Suggestion, is_content_word, predicate};

use crate::Token;
use crate::linting::expr_linter::Chunk;

/// Two adjacent words separated by whitespace that if joined would be a valid noun.
pub struct CompoundNounBeforeAuxVerb {
    expr: Box<dyn Expr>,
    split_pattern: Lrc<MergeableWords>,
}

impl Default for CompoundNounBeforeAuxVerb {
    fn default() -> Self {
        let context_pattern = SequenceExpr::default()
            .then(is_content_word)
            .t_ws()
            .then(is_content_word)
            .then_auxiliary_verb();

        let split_pattern = Lrc::new(MergeableWords::new(|meta_closed, meta_open| {
            predicate(meta_closed, meta_open)
        }));

        let mut expr = All::default();
        expr.add(context_pattern);
        expr.add(
            SequenceExpr::default()
                .then(split_pattern.clone())
                .then(AnyPattern)
                .then(AnyPattern),
        );

        Self {
            expr: Box::new(expr),
            split_pattern,
        }
    }
}

impl ExprLinter for CompoundNounBeforeAuxVerb {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], source: &[char]) -> Option<Lint> {
        let span = matched_tokens[0..3].span()?;
        let orig = span.get_content(source);
        // If the pattern matched, this will not return `None`.
        let word =
            self.split_pattern
                .get_merged_word(&matched_tokens[0], &matched_tokens[2], source)?;

        Some(Lint {
            span,
            lint_kind: LintKind::WordChoice,
            suggestions: vec![Suggestion::replace_with_match_case(word.to_vec(), orig)],
            message: format!(
                "The auxiliary verb “{}” implies the existence of the closed compound noun “{}”.",
                matched_tokens[4].span.get_content(source).to_string(),
                word.to_string()
            ),
            priority: 63,
        })
    }

    fn description(&self) -> &str {
        "Detects split compound nouns preceding an action and suggests merging them."
    }
}



================================================
FILE: harper-core/src/linting/compound_nouns/mod.rs
================================================
mod compound_noun_after_det_adj;
mod compound_noun_after_possessive;
mod compound_noun_before_aux_verb;

use super::{Lint, LintKind, Suggestion, merge_linters::merge_linters};
use crate::{CharStringExt, DictWordMetadata, Token};

// Helper function to check if a token is a content word (not a function word)
pub(crate) fn is_content_word(tok: &Token, src: &[char]) -> bool {
    let Some(Some(meta)) = tok.kind.as_word() else {
        return false;
    };

    tok.span.len() > 1
        && (meta.is_noun() || meta.is_adjective() || meta.is_verb() || meta.is_adverb())
        && !(meta.is_determiner() || meta.is_conjunction())
        && (!meta.preposition || tok.span.get_content(src).eq_ignore_ascii_case_str("bar"))
}

pub(crate) fn predicate(
    closed: Option<&DictWordMetadata>,
    open: Option<&DictWordMetadata>,
) -> bool {
    open.is_none() && closed.is_some_and(|m| m.is_noun() && !m.is_proper_noun())
}

use compound_noun_after_det_adj::CompoundNounAfterDetAdj;
use compound_noun_after_possessive::CompoundNounAfterPossessive;
use compound_noun_before_aux_verb::CompoundNounBeforeAuxVerb;

merge_linters!(CompoundNouns => CompoundNounAfterDetAdj, CompoundNounBeforeAuxVerb, CompoundNounAfterPossessive => "Detects compound nouns split by a space and suggests merging them when both parts form a valid noun." );

#[cfg(test)]
mod tests {
    use super::CompoundNouns;
    use crate::linting::tests::{assert_lint_count, assert_no_lints, assert_suggestion_result};

    #[test]
    fn web_cam() {
        let test_sentence = "The web cam captured a stunning image.";
        let expected = "The webcam captured a stunning image.";
        assert_suggestion_result(test_sentence, CompoundNouns::default(), expected);
    }

    #[test]
    fn note_book() {
        let test_sentence = "She always carries a note book to jot down ideas.";
        let expected = "She always carries a notebook to jot down ideas.";
        assert_suggestion_result(test_sentence, CompoundNouns::default(), expected);
    }

    #[test]
    fn mother_board() {
        let test_sentence = "After the upgrade, the mother board was replaced.";
        let expected = "After the upgrade, the motherboard was replaced.";
        assert_suggestion_result(test_sentence, CompoundNouns::default(), expected);
    }

    #[test]
    fn smart_phone() {
        let test_sentence = "He bought a new smart phone last week.";
        let expected = "He bought a new smartphone last week.";
        assert_suggestion_result(test_sentence, CompoundNouns::default(), expected);
    }

    #[test]
    fn firm_ware() {
        let test_sentence = "The device's firm ware was updated overnight.";
        let expected = "The device's firmware was updated overnight.";
        assert_suggestion_result(test_sentence, CompoundNouns::default(), expected);
    }

    #[test]
    fn back_plane() {
        let test_sentence = "A reliable back plane is essential for high-speed data transfer.";
        let expected = "A reliable backplane is essential for high-speed data transfer.";
        assert_suggestion_result(test_sentence, CompoundNouns::default(), expected);
    }

    #[test]
    fn spread_sheet() {
        let test_sentence = "The accountant reviewed the spread sheet carefully.";
        let expected = "The accountant reviewed the spreadsheet carefully.";
        assert_suggestion_result(test_sentence, CompoundNouns::default(), expected);
    }

    #[test]
    fn side_bar() {
        let test_sentence = "The website's side bar offers quick navigation links.";
        let expected = "The website's sidebar offers quick navigation links.";
        assert_suggestion_result(test_sentence, CompoundNouns::default(), expected);
    }

    #[test]
    fn back_pack() {
        let test_sentence = "I packed my books in my back pack before leaving.";
        let expected = "I packed my books in my backpack before leaving.";
        assert_suggestion_result(test_sentence, CompoundNouns::default(), expected);
    }

    #[test]
    fn cup_board() {
        let test_sentence = "She stored the dishes in the old cup board.";
        let expected = "She stored the dishes in the old cupboard.";
        assert_suggestion_result(test_sentence, CompoundNouns::default(), expected);
    }

    #[test]
    fn key_board() {
        let test_sentence = "My key board stopped working during the meeting.";
        let expected = "My keyboard stopped working during the meeting.";
        assert_suggestion_result(test_sentence, CompoundNouns::default(), expected);
    }

    #[test]
    fn touch_screen() {
        let test_sentence = "The device features a responsive touch screen.";
        let expected = "The device features a responsive touchscreen.";
        assert_suggestion_result(test_sentence, CompoundNouns::default(), expected);
    }

    #[test]
    fn head_set() {
        let test_sentence = "He bought a new head set for his workouts.";
        let expected = "He bought a new headset for his workouts.";
        assert_suggestion_result(test_sentence, CompoundNouns::default(), expected);
    }

    #[test]
    fn frame_work() {
        let test_sentence = "The frame work of the app was built with care.";
        let expected = "The framework of the app was built with care.";
        assert_suggestion_result(test_sentence, CompoundNouns::default(), expected);
    }

    #[test]
    fn touch_pad() {
        let test_sentence = "The touch pad on my laptop is very sensitive.";
        let expected = "The touchpad on my laptop is very sensitive.";
        assert_suggestion_result(test_sentence, CompoundNouns::default(), expected);
    }

    #[test]
    fn micro_processor() {
        let test_sentence = "This micro processor is among the fastest available.";
        let expected = "This microprocessor is among the fastest available.";
        assert_suggestion_result(test_sentence, CompoundNouns::default(), expected);
    }

    #[test]
    fn head_phone() {
        let test_sentence = "I lost my head phone at the gym.";
        let expected = "I lost my headphone at the gym.";
        assert_suggestion_result(test_sentence, CompoundNouns::default(), expected);
    }

    #[test]
    fn micro_services() {
        let test_sentence = "Our architecture now relies on micro services.";
        let expected = "Our architecture now relies on microservices.";
        assert_suggestion_result(test_sentence, CompoundNouns::default(), expected);
    }

    #[test]
    fn dash_board() {
        let test_sentence = "The dash board shows real-time analytics.";
        let expected = "The dashboard shows real-time analytics.";
        assert_suggestion_result(test_sentence, CompoundNouns::default(), expected);
    }

    #[test]
    fn site_map() {
        let test_sentence = "A site map is provided at the footer of the website.";
        let expected = "A sitemap is provided at the footer of the website.";
        assert_suggestion_result(test_sentence, CompoundNouns::default(), expected);
    }

    #[test]
    fn fire_wall() {
        let test_sentence = "A robust fire wall is essential for network security.";
        let expected = "A robust firewall is essential for network security.";
        assert_suggestion_result(test_sentence, CompoundNouns::default(), expected);
    }

    #[test]
    fn bit_stream() {
        let test_sentence = "The bit stream was interrupted during transmission.";
        let expected = "The bitstream was interrupted during transmission.";
        assert_suggestion_result(test_sentence, CompoundNouns::default(), expected);
    }

    #[test]
    fn block_chain() {
        let test_sentence = "The block chain is revolutionizing the financial sector.";
        let expected = "The blockchain is revolutionizing the financial sector.";
        assert_suggestion_result(test_sentence, CompoundNouns::default(), expected);
    }

    #[test]
    fn thumb_nail() {
        let test_sentence = "I saved the image as a thumb nail.";
        let expected = "I saved the image as a thumbnail.";
        assert_suggestion_result(test_sentence, CompoundNouns::default(), expected);
    }

    #[test]
    fn bath_room() {
        let test_sentence = "They remodeled the bath room entirely.";
        let expected = "They remodeled the bathroom entirely.";
        assert_suggestion_result(test_sentence, CompoundNouns::default(), expected);
    }

    #[test]
    #[ignore = "\"everyone\" is not a valid compound noun, it's a pronoun"]
    fn every_one() {
        let test_sentence = "Every one should have access to quality education.";
        let expected = "Everyone should have access to quality education.";
        assert_suggestion_result(test_sentence, CompoundNouns::default(), expected);
    }

    #[test]
    fn play_ground() {
        let test_sentence = "The kids spent the afternoon at the play ground.";
        let expected = "The kids spent the afternoon at the playground.";
        assert_suggestion_result(test_sentence, CompoundNouns::default(), expected);
    }

    #[test]
    fn run_way() {
        let test_sentence = "The airplane taxied along the run way.";
        let expected = "The airplane taxied along the runway.";
        assert_suggestion_result(test_sentence, CompoundNouns::default(), expected);
    }

    #[test]
    fn cyber_space() {
        let test_sentence = "Hackers roam the cyber space freely.";
        let expected = "Hackers roam the cyberspace freely.";
        assert_suggestion_result(test_sentence, CompoundNouns::default(), expected);
    }

    #[test]
    fn cyber_attack() {
        let test_sentence = "The network was hit by a cyber attack.";
        let expected = "The network was hit by a cyberattack.";
        assert_suggestion_result(test_sentence, CompoundNouns::default(), expected);
    }

    #[test]
    fn web_socket() {
        let test_sentence = "Real-time updates are sent via a web socket.";
        let expected = "Real-time updates are sent via a websocket.";
        assert_suggestion_result(test_sentence, CompoundNouns::default(), expected);
    }

    #[test]
    fn finger_print() {
        let test_sentence = "The detective collected a finger print as evidence.";
        let expected = "The detective collected a fingerprint as evidence.";
        assert_suggestion_result(test_sentence, CompoundNouns::default(), expected);
    }

    #[test]
    fn got_is_not_possessive() {
        assert_lint_count("I got here by car...", CompoundNouns::default(), 0);
    }

    #[test]
    fn allow_issue_662() {
        assert_lint_count(
            "They are as old as *modern* computers ",
            CompoundNouns::default(),
            0,
        );
    }

    #[test]
    fn allow_issue_661() {
        assert_lint_count("I may be wrong.", CompoundNouns::default(), 0);
    }

    #[test]
    fn allow_issue_704() {
        assert_lint_count(
            "Here are some ways to do that:",
            CompoundNouns::default(),
            0,
        );
    }

    #[test]
    fn allows_issue_721() {
        assert_lint_count(
            "So if you adjust any one of these adjusters that can have a negative or a positive effect.",
            CompoundNouns::default(),
            0,
        );
    }

    #[test]
    fn allows_678() {
        assert_lint_count(
            "they can't catch all the bugs.",
            CompoundNouns::default(),
            0,
        );
    }

    #[test]
    fn ina_not_suggested() {
        assert_lint_count(
            "past mistakes or a character in a looping reality facing personal challenges.",
            CompoundNouns::default(),
            0,
        );
    }

    #[test]
    fn allow_suppress_or() {
        assert_lint_count(
            "He must decide whether to suppress or coexist with his doppelgänger.",
            CompoundNouns::default(),
            0,
        );
    }

    #[test]
    fn allow_an_arm_and_a_leg() {
        assert_lint_count(
            "I have to pay an arm and a leg get a worker to come and be my assistant baker.",
            CompoundNouns::default(),
            0,
        );
    }

    #[test]
    fn allow_well_and_723() {
        assert_lint_count(
            "I understood very well and decided to go.",
            CompoundNouns::default(),
            0,
        );
    }

    #[test]
    fn allow_can_not() {
        assert_lint_count("Size can not be determined.", CompoundNouns::default(), 0);
    }

    #[test]
    fn dont_flag_lot_to() {
        assert_lint_count(
            "but you'd have to raise taxes a lot to do it.",
            CompoundNouns::default(),
            0,
        );
    }

    #[test]
    fn dont_flag_to_me() {
        assert_lint_count(
            "There's no massive damage to the rockers or anything that to me would indicate that like the whole front of the car was off",
            CompoundNouns::default(),
            0,
        );
    }

    #[test]
    fn allow_issue_1553() {
        assert_no_lints(
            "I'm not sure if there's anyone else that may be interested in more fine-grained control, but as it stands, having the domain level toggle is sufficient for me.",
            CompoundNouns::default(),
        );
    }

    #[test]
    fn allow_issue_1496() {
        assert_no_lints(
            "I am not able to respond to messages.",
            CompoundNouns::default(),
        );
    }

    #[test]
    fn allow_issue_1298() {
        assert_no_lints(
            "A series of tests that cover all possible cases.",
            CompoundNouns::default(),
        );
    }

    #[test]
    fn dont_flag_project_or() {
        assert_no_lints(
            "You can star or watch this project or follow author to get release notifications in time.",
            CompoundNouns::default(),
        );
    }
}



================================================
FILE: harper-core/src/linting/hop_hope/mod.rs
================================================
use super::merge_linters::merge_linters;

mod to_hop;
mod to_hope;
use to_hop::ToHop;
use to_hope::ToHope;

merge_linters!(HopHope => ToHop, ToHope => "Handles common errors involving `hop` and `hope`. Ensures `hop` is used correctly in phrases like `hop on a bus` while correcting mistaken uses of `hope` in contexts where `hop` is expected.");

#[cfg(test)]
mod tests {
    use super::HopHope;
    use crate::linting::tests::assert_suggestion_result;

    #[test]
    fn corrects_hop_to_hope() {
        assert_suggestion_result(
            "I hop we can clarify this soon.",
            HopHope::default(),
            "I hope we can clarify this soon.",
        );
    }

    #[test]
    fn does_not_correct_unrelated_use() {
        assert_suggestion_result(
            "I hop on one foot for fun.",
            HopHope::default(),
            "I hop on one foot for fun.",
        );
    }

    #[test]
    fn corrects_mixed_case_hop() {
        assert_suggestion_result(
            "I HoP we can find a solution.",
            HopHope::default(),
            "I HoPE we can find a solution.",
        );
    }

    #[test]
    fn corrects_hoping_on_call() {
        assert_suggestion_result(
            "I was hoping on a call to discuss this.",
            HopHope::default(),
            "I was hopping on a call to discuss this.",
        );
    }

    #[test]
    fn corrects_hoped_on_plane() {
        assert_suggestion_result(
            "She hoped on an airplane to visit family.",
            HopHope::default(),
            "She hopped on an airplane to visit family.",
        );
    }

    #[test]
    fn corrects_hope_on_bus() {
        assert_suggestion_result(
            "They hope on a bus every morning.",
            HopHope::default(),
            "They hop on a bus every morning.",
        );
    }

    #[test]
    fn does_not_correct_unrelated_context() {
        assert_suggestion_result(
            "I hope everything goes well with your project.",
            HopHope::default(),
            "I hope everything goes well with your project.",
        );
    }

    #[test]
    fn corrects_mixed_case() {
        assert_suggestion_result(
            "She HoPeD on a train to get home.",
            HopHope::default(),
            "She HoPpED on a train to get home.",
        );
    }
}



================================================
FILE: harper-core/src/linting/hop_hope/to_hop.rs
================================================
use super::super::{ExprLinter, Lint, LintKind};
use crate::expr::Expr;
use crate::expr::SequenceExpr;
use crate::linting::Suggestion;
use crate::linting::expr_linter::Chunk;
use crate::patterns::WordSet;
use crate::{CharString, CharStringExt};
use crate::{Token, char_string::char_string};

pub struct ToHop {
    expr: Box<dyn Expr>,
}

impl Default for ToHop {
    fn default() -> Self {
        let pattern = SequenceExpr::default()
            .then(WordSet::new(&["hoping", "hoped", "hope"]))
            .then_whitespace()
            .t_aco("on")
            .then_whitespace()
            .then_determiner()
            .then_whitespace()
            .then(WordSet::new(&["airplane", "plane", "bus", "call", "train"]));

        Self {
            expr: Box::new(pattern),
        }
    }
}

impl ToHop {
    fn to_correct(word: &str) -> Option<CharString> {
        Some(match word.to_lowercase().as_str() {
            "hoping" => char_string!("hopping"),
            "hoped" => char_string!("hopped"),
            "hope" => char_string!("hop"),
            _ => return None,
        })
    }
}

impl ExprLinter for ToHop {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], source: &[char]) -> Option<Lint> {
        let offending_word = &matched_tokens[0];
        let word_chars = offending_word.span.get_content(source);
        let word = word_chars.to_string();
        let correct = Self::to_correct(&word)?;

        Some(Lint {
            span: offending_word.span,
            lint_kind: LintKind::WordChoice,
            suggestions: vec![Suggestion::replace_with_match_case(
                correct.to_vec(),
                word_chars,
            )],
            message: format!(
                "Did you mean to use {word} instead of {} in this context?",
                correct.to_string()
            ),
            ..Default::default()
        })
    }

    fn description(&self) -> &'static str {
        "Detects incorrect usage of the words 'hoping,' 'hoped,' or 'hope' when referring to boarding or entering a mode of transportation. Suggests replacing them with the correct verb form such as 'hopping,' 'hopped,' or 'hop.'"
    }
}



================================================
FILE: harper-core/src/linting/hop_hope/to_hope.rs
================================================
use super::super::{ExprLinter, Lint, LintKind};
use crate::expr::Expr;
use crate::expr::SequenceExpr;
use crate::linting::Suggestion;
use crate::linting::expr_linter::Chunk;
use crate::patterns::WordSet;
use crate::{Token, char_string::char_string};

pub struct ToHope {
    expr: Box<dyn Expr>,
}

impl Default for ToHope {
    fn default() -> Self {
        let pattern = SequenceExpr::default()
            .then_nominal()
            .then_whitespace()
            .then(WordSet::new(&["hop", "hopped"]))
            .then_whitespace()
            .then_nominal();

        Self {
            expr: Box::new(pattern),
        }
    }
}

impl ExprLinter for ToHope {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], source: &[char]) -> Option<Lint> {
        let offending_word = &matched_tokens[2];
        let word_chars = offending_word.span.get_content(source);

        Some(Lint {
            span: offending_word.span,
            lint_kind: LintKind::WordChoice,
            suggestions: vec![Suggestion::replace_with_match_case(
                char_string!("hope").to_vec(),
                word_chars,
            )],
            message: "Did you mean to use 'hope' instead of 'hop' in this context?".to_string(),
            ..Default::default()
        })
    }

    fn description(&self) -> &'static str {
        "Detects incorrect use of 'hop' when the correct verb 'hope' should be used in a sentence."
    }
}



================================================
FILE: harper-core/src/linting/its_contraction/general.rs
================================================
use harper_brill::UPOS;

use crate::{
    Document, Token, TokenStringExt,
    expr::{All, Expr, ExprExt, OwnedExprExt, SequenceExpr},
    linting::{Lint, LintKind, Linter, Suggestion},
    patterns::{NominalPhrase, Pattern, UPOSSet, WordSet},
};

pub struct General {
    expr: Box<dyn Expr>,
}

impl Default for General {
    fn default() -> Self {
        let positive = SequenceExpr::default().t_aco("its").then_whitespace().then(
            UPOSSet::new(&[UPOS::VERB, UPOS::AUX, UPOS::DET, UPOS::PRON])
                .or(WordSet::new(&["because"])),
        );

        let exceptions = SequenceExpr::anything()
            .then_anything()
            .then(WordSet::new(&["own", "intended"]));

        let inverted = SequenceExpr::default().then_unless(exceptions);

        let expr = All::new(vec![Box::new(positive), Box::new(inverted)]).or_longest(
            SequenceExpr::aco("its")
                .t_ws()
                .then(UPOSSet::new(&[UPOS::ADJ]))
                .t_ws()
                .then(UPOSSet::new(&[UPOS::SCONJ, UPOS::PART])),
        );

        Self {
            expr: Box::new(expr),
        }
    }
}

impl Linter for General {
    fn lint(&mut self, document: &Document) -> Vec<Lint> {
        let mut lints = Vec::new();
        let source = document.get_source();

        for chunk in document.iter_chunks() {
            lints.extend(
                self.expr
                    .iter_matches(chunk, source)
                    .filter_map(|match_span| {
                        self.match_to_lint(&chunk[match_span.start..], source)
                    }),
            );
        }

        lints
    }

    fn description(&self) -> &str {
        "Detects the possessive `its` before `had`, `been`, or `got` and offers `it's` or `it has`."
    }
}

impl General {
    fn match_to_lint(&self, toks: &[Token], source: &[char]) -> Option<Lint> {
        let offender = toks.first()?;
        let offender_chars = offender.span.get_content(source);

        if toks.get(2)?.kind.is_upos(UPOS::VERB)
            && NominalPhrase.matches(&toks[2..], source).is_some()
        {
            return None;
        }

        Some(Lint {
            span: offender.span,
            lint_kind: LintKind::Punctuation,
            suggestions: vec![
                Suggestion::replace_with_match_case_str("it's", offender_chars),
                Suggestion::replace_with_match_case_str("it has", offender_chars),
            ],
            message: "Use `it's` (short for `it has` or `it is`) here, not the possessive `its`."
                .to_owned(),
            priority: 54,
        })
    }
}



================================================
FILE: harper-core/src/linting/its_contraction/mod.rs
================================================
use super::merge_linters::merge_linters;

mod general;
mod proper_noun;

use general::General;
use proper_noun::ProperNoun;

merge_linters!(
    ItsContraction => General, ProperNoun =>
    "Detects places where the possessive `its` should be the contraction `it's`, including before verbs/clauses and before proper nouns after opinion verbs."
);

#[cfg(test)]
mod tests {
    use super::ItsContraction;
    use crate::linting::tests::{assert_lint_count, assert_no_lints, assert_suggestion_result};

    #[test]
    fn fix_had() {
        assert_suggestion_result(
            "Its had an enormous effect.",
            ItsContraction::default(),
            "It's had an enormous effect.",
        );
    }

    #[test]
    fn fix_been() {
        assert_suggestion_result(
            "Its been months since we spoke.",
            ItsContraction::default(),
            "It's been months since we spoke.",
        );
    }

    #[test]
    fn fix_got() {
        assert_suggestion_result(
            "I think its got nothing to do with us.",
            ItsContraction::default(),
            "I think it's got nothing to do with us.",
        );
    }

    #[test]
    fn fixes_its_common() {
        assert_suggestion_result(
            "Its common for users to get frustrated.",
            ItsContraction::default(),
            "It's common for users to get frustrated.",
        );
    }

    #[test]
    fn ignore_correct_contraction() {
        assert_lint_count(
            "It's been a long year for everyone.",
            ItsContraction::default(),
            0,
        );
    }

    #[test]
    fn ignore_possessive() {
        assert_lint_count(
            "The company revised its policies last week.",
            ItsContraction::default(),
            0,
        );
    }

    #[test]
    fn ignore_coroutine() {
        assert_lint_count(
            "Launch each task within its own child coroutine.",
            ItsContraction::default(),
            0,
        );
    }

    #[test]
    fn issue_381() {
        assert_suggestion_result(
            "Its a nice day.",
            ItsContraction::default(),
            "It's a nice day.",
        );
    }

    #[test]
    fn ignore_nominal_progressive() {
        assert_lint_count(
            "The class preserves its existing properties.",
            ItsContraction::default(),
            0,
        );
    }

    #[test]
    #[ignore = "past participles are not always adjectives ('cared' for instance)"]
    fn ignore_nominal_perfect() {
        assert_lint_count(
            "The robot followed its predetermined route.",
            ItsContraction::default(),
            0,
        );
    }

    #[test]
    fn ignore_nominal_long() {
        assert_lint_count(
            "I think of its exploding marvelous spectacular output.",
            ItsContraction::default(),
            0,
        );
    }

    #[test]
    fn corrects_because() {
        assert_suggestion_result(
            "Its because they don't want to.",
            ItsContraction::default(),
            "It's because they don't want to.",
        );
    }

    #[test]
    fn corrects_its_hard() {
        assert_suggestion_result(
            "Its hard to believe that.",
            ItsContraction::default(),
            "It's hard to believe that.",
        );
    }

    #[test]
    fn corrects_its_easy() {
        assert_suggestion_result(
            "Its easy if you try.",
            ItsContraction::default(),
            "It's easy if you try.",
        );
    }

    #[test]
    fn corrects_its_a_picnic() {
        assert_suggestion_result(
            "Its a beautiful day for a picnic",
            ItsContraction::default(),
            "It's a beautiful day for a picnic",
        );
    }

    #[test]
    fn corrects_its_my() {
        assert_suggestion_result(
            "Its my favorite song.",
            ItsContraction::default(),
            "It's my favorite song.",
        );
    }

    #[test]
    fn allows_its_new() {
        assert_no_lints(
            "The company announced its new product line. ",
            ItsContraction::default(),
        );
    }

    #[test]
    fn allows_its_own_charm() {
        assert_no_lints("The house has its own charm. ", ItsContraction::default());
    }

    #[test]
    fn allows_its_victory() {
        assert_no_lints(
            "The team celebrated its victory. ",
            ItsContraction::default(),
        );
    }

    #[test]
    fn allows_its_history() {
        assert_no_lints(
            "The country is proud of its history. ",
            ItsContraction::default(),
        );
    }

    #[test]
    fn allows_its_secrets() {
        assert_no_lints(
            "The book contains its own secrets. ",
            ItsContraction::default(),
        );
    }

    #[test]
    fn corrects_think_google() {
        assert_suggestion_result(
            "I think its Google, not Microsoft.",
            ItsContraction::default(),
            "I think it's Google, not Microsoft.",
        );
    }

    #[test]
    fn corrects_hope_katie() {
        assert_suggestion_result(
            "I hope its Katie.",
            ItsContraction::default(),
            "I hope it's Katie.",
        );
    }

    #[test]
    fn corrects_guess_date() {
        assert_suggestion_result(
            "I guess its March 6.",
            ItsContraction::default(),
            "I guess it's March 6.",
        );
    }

    #[test]
    fn corrects_assume_john() {
        assert_suggestion_result(
            "We assume its John.",
            ItsContraction::default(),
            "We assume it's John.",
        );
    }

    #[test]
    fn corrects_doubt_tesla() {
        assert_suggestion_result(
            "They doubt its Tesla this year.",
            ItsContraction::default(),
            "They doubt it's Tesla this year.",
        );
    }

    #[test]
    fn handles_two_word_name() {
        assert_suggestion_result(
            "She thinks its New York.",
            ItsContraction::default(),
            "She thinks it's New York.",
        );
    }

    #[test]
    fn ignores_existing_contraction() {
        assert_lint_count("I think it's Google.", ItsContraction::default(), 0);
    }

    #[test]
    fn ignores_possessive_noun_after_name() {
        assert_lint_count(
            "I think its Google product launch.",
            ItsContraction::default(),
            0,
        );
    }

    #[test]
    fn ignores_without_opinion_verb() {
        assert_lint_count(
            "Its Google Pixel lineup is impressive.",
            ItsContraction::default(),
            0,
        );
    }

    #[test]
    fn ignores_common_noun_target() {
        assert_lint_count(
            "We hope its accuracy improves.",
            ItsContraction::default(),
            0,
        );
    }
}



================================================
FILE: harper-core/src/linting/its_contraction/proper_noun.rs
================================================
use std::ops::Range;
use std::sync::Arc;

use harper_brill::UPOS;

use crate::{
    Document, Token, TokenStringExt,
    expr::{Expr, ExprExt, ExprMap, OwnedExprExt, SequenceExpr},
    linting::{Lint, LintKind, Linter, Suggestion},
    patterns::{DerivedFrom, UPOSSet},
};

pub struct ProperNoun {
    expr: Box<dyn Expr>,
    map: Arc<ExprMap<Range<usize>>>,
}

impl Default for ProperNoun {
    fn default() -> Self {
        let mut map = ExprMap::default();

        let opinion_verbs = DerivedFrom::new_from_str("think")
            .or(DerivedFrom::new_from_str("hope"))
            .or(DerivedFrom::new_from_str("assume"))
            .or(DerivedFrom::new_from_str("doubt"))
            .or(DerivedFrom::new_from_str("guess"));

        let capitalized_word = |tok: &Token, src: &[char]| {
            tok.kind.is_word()
                && tok
                    .span
                    .get_content(src)
                    .first()
                    .map(|c| c.is_uppercase())
                    .unwrap_or(false)
        };

        let name_head = UPOSSet::new(&[UPOS::PROPN]).or(capitalized_word);

        let lookahead_word = SequenceExpr::default().t_ws().then_any_word();

        map.insert(
            SequenceExpr::default()
                .then(opinion_verbs)
                .t_ws()
                .t_aco("its")
                .t_ws()
                .then(name_head)
                .then_optional(lookahead_word),
            2..3,
        );

        let map = Arc::new(map);

        Self {
            expr: Box::new(map.clone()),
            map,
        }
    }
}

impl Linter for ProperNoun {
    fn lint(&mut self, document: &Document) -> Vec<Lint> {
        let mut lints = Vec::new();
        let source = document.get_source();

        for chunk in document.iter_chunks() {
            lints.extend(
                self.expr
                    .iter_matches(chunk, source)
                    .filter_map(|match_span| {
                        let matched = &chunk[match_span.start..match_span.end];
                        self.match_to_lint(matched, source)
                    }),
            );
        }

        lints
    }

    fn description(&self) -> &str {
        "Suggests the contraction `it's` after opinion verbs when it introduces a proper noun."
    }
}

impl ProperNoun {
    fn match_to_lint(&self, matched_tokens: &[Token], source: &[char]) -> Option<Lint> {
        if matched_tokens.len() >= 7
            && let Some(next_word) = matched_tokens.get(6)
        {
            let is_lowercase = next_word
                .span
                .get_content(source)
                .first()
                .map(|c| c.is_lowercase())
                .unwrap_or(false);

            if is_lowercase
                && (next_word.kind.is_upos(UPOS::NOUN) || next_word.kind.is_upos(UPOS::ADJ))
            {
                return None;
            }
        }

        let range = self.map.lookup(0, matched_tokens, source)?.clone();
        let offending = matched_tokens.get(range.start)?;
        let offender_text = offending.span.get_content(source);

        Some(Lint {
            span: offending.span,
            lint_kind: LintKind::Punctuation,
            suggestions: vec![Suggestion::replace_with_match_case_str(
                "it's",
                offender_text,
            )],
            message: "Use `it's` (short for \"it is\") before a proper noun in this construction."
                .to_owned(),
            priority: 31,
        })
    }
}



================================================
FILE: harper-core/src/linting/lets_confusion/let_us_redundancy.rs
================================================
use crate::expr::Expr;
use crate::expr::SequenceExpr;
use crate::{Token, TokenStringExt};

use crate::linting::expr_linter::Chunk;
use crate::linting::{ExprLinter, Lint, LintKind, Suggestion};

/// See also:
/// harper-core/src/linting/compound_nouns/implied_ownership_compound_nouns.rs
/// harper-core/src/linting/lets_confusion/mod.rs
/// harper-core/src/linting/lets_confusion/no_contraction_with_verb.rs
/// harper-core/src/linting/pronoun_contraction/should_contract.rs
pub struct LetUsRedundancy {
    expr: Box<dyn Expr>,
}

impl Default for LetUsRedundancy {
    fn default() -> Self {
        let pattern = SequenceExpr::aco("let's").then_whitespace().then_pronoun();

        Self {
            expr: Box::new(pattern),
        }
    }
}

impl ExprLinter for LetUsRedundancy {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], source: &[char]) -> Option<Lint> {
        let template = matched_tokens.span()?.get_content(source);
        let pronoun = matched_tokens.last()?.span.get_content_string(source);

        Some(Lint {
            span: matched_tokens.span()?,
            lint_kind: LintKind::Repetition,
            suggestions: vec![
                Suggestion::replace_with_match_case(
                    format!("lets {pronoun}").chars().collect(),
                    template,
                ),
                Suggestion::replace_with_match_case(
                    "let's".to_string().chars().collect(),
                    template,
                ),
            ],
            message: "`let's` stands for `let us`, so including another pronoun is redundant."
                .to_owned(),
            priority: 31,
        })
    }

    fn description(&self) -> &'static str {
        "Many are not aware that the contraction `let's` is short for `let us`. As a result, many will incorrectly use it before a pronoun, such as in the phrase `let's us do`."
    }
}



================================================
FILE: harper-core/src/linting/lets_confusion/mod.rs
================================================
mod let_us_redundancy;
mod no_contraction_with_verb;

use super::merge_linters::merge_linters;
use let_us_redundancy::LetUsRedundancy;
use no_contraction_with_verb::NoContractionWithVerb;

// See also:
// harper-core/src/linting/compound_nouns/implied_ownership_compound_nouns.rs
// harper-core/src/linting/lets_confusion/let_us_redundancy.rs
// harper-core/src/linting/lets_confusion/no_contraction_with_verb.rs
// harper-core/src/linting/pronoun_contraction/should_contract.rs
merge_linters!(LetsConfusion => LetUsRedundancy, NoContractionWithVerb => "It's often hard to determine where the subject should go with the word `let`. This rule attempts to find common errors with redundancy and contractions that may lead to confusion for readers.");

#[cfg(test)]
mod tests {
    use crate::linting::tests::{assert_lint_count, assert_suggestion_result};

    use super::LetsConfusion;

    #[test]
    fn walking() {
        assert_suggestion_result(
            "The crutch let's him walk.",
            LetsConfusion::default(),
            "The crutch lets him walk.",
        );
    }

    #[test]
    fn issue_426_us() {
        assert_suggestion_result("let's us do", LetsConfusion::default(), "lets us do");
    }

    #[test]
    fn issue_426_me() {
        assert_suggestion_result("let's me do", LetsConfusion::default(), "lets me do");
    }

    #[test]
    fn from_harper_docs() {
        assert_suggestion_result(
            "Often the longest and the shortest words are the most helpful, so lets push them first.",
            LetsConfusion::default(),
            "Often the longest and the shortest words are the most helpful, so let's push them first.",
        );
    }

    #[test]
    #[ignore = "\"play\" is also a noun so in a context like \"Sometimes the umpire lets play continue\""]
    fn issue_470_missing_apostrophe_play() {
        assert_suggestion_result("lets play", LetsConfusion::default(), "let's play");
    }

    #[test]
    #[ignore]
    fn issue_470_missing_subject_play() {
        assert_suggestion_result("let play", LetsConfusion::default(), "let's play");
    }

    #[test]
    fn issue_470_missing_apostrophe_proceed() {
        assert_suggestion_result("lets proceed", LetsConfusion::default(), "let's proceed");
    }

    #[test]
    fn issue_470_missing_subject_proceed() {
        assert_suggestion_result("let proceed", LetsConfusion::default(), "let's proceed");
    }

    #[test]
    fn issue_548() {
        assert_lint_count(
            "A simple web app that lets you fetch random issues.",
            LetsConfusion::default(),
            0,
        );
    }
}



================================================
FILE: harper-core/src/linting/lets_confusion/no_contraction_with_verb.rs
================================================
use crate::TokenKind;
use crate::expr::Expr;
use crate::expr::LongestMatchOf;
use crate::expr::SequenceExpr;
use crate::{
    Token,
    linting::{Lint, LintKind, Suggestion},
    patterns::WordSet,
};

use crate::linting::ExprLinter;
use crate::linting::expr_linter::Chunk;

/// See also:
/// harper-core/src/linting/compound_nouns/implied_ownership_compound_nouns.rs
/// harper-core/src/linting/lets_confusion/mod.rs
/// harper-core/src/linting/lets_confusion/let_us_redundancy.rs
/// harper-core/src/linting/pronoun_contraction/should_contract.rs
pub struct NoContractionWithVerb {
    expr: Box<dyn Expr>,
}

impl Default for NoContractionWithVerb {
    fn default() -> Self {
        // Only tests "let".
        let let_ws = SequenceExpr::default()
            .then(WordSet::new(&["lets", "let"]))
            .then_whitespace();

        let non_ing_verb = SequenceExpr::default().then_kind_is_but_isnt_any_of(
            TokenKind::is_verb,
            &[
                TokenKind::is_noun,
                TokenKind::is_adjective,
                TokenKind::is_verb_progressive_form,
            ] as &[_],
        );

        // Ambiguous word is a verb determined by heuristic of following word's part of speech
        // Tests the next two words after "let".
        let verb_due_to_following_pos = SequenceExpr::default()
            .then_verb()
            .then_whitespace()
            .then_kind_any(&[
                TokenKind::is_determiner,
                TokenKind::is_pronoun,
                TokenKind::is_conjunction,
            ] as &[_]);

        let let_then_verb = let_ws.then(LongestMatchOf::new(vec![
            Box::new(non_ing_verb),
            Box::new(verb_due_to_following_pos),
        ]));

        Self {
            expr: Box::new(let_then_verb),
        }
    }
}

impl ExprLinter for NoContractionWithVerb {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], source: &[char]) -> Option<Lint> {
        let (let_string, verb_string) = (
            matched_tokens[0].span.get_content_string(source),
            matched_tokens[2].span.get_content_string(source),
        );

        // "to let go" is a phrasal verb but "lets go" is quite a common mistake for "let's go"
        if let_string == "let" && verb_string == "go" {
            return None;
        }

        let problem_span = matched_tokens.first()?.span;
        let template = problem_span.get_content(source);

        Some(Lint {
            span: problem_span,
            lint_kind: LintKind::WordChoice,
            suggestions: vec![
                Suggestion::replace_with_match_case_str("let's", template),
                Suggestion::replace_with_match_case_str("let us", template),
            ],
            message: "To suggest an action, use 'let's' or 'let us'.".to_owned(),
            priority: 31,
        })
    }

    fn description(&self) -> &'static str {
        "Checks for `lets` meaning `permits` when the context is about suggesting an action."
    }
}

#[cfg(test)]
mod tests {
    use super::NoContractionWithVerb;
    use crate::linting::tests::{assert_lint_count, assert_suggestion_result};

    // Correct unambiguous verb

    #[test]
    fn fix_lets_inspect() {
        assert_suggestion_result(
            "In the end lets inspect with git-blame the results.",
            NoContractionWithVerb::default(),
            "In the end let's inspect with git-blame the results.",
        );
    }

    // False positives where verb is also a noun

    #[test]
    fn dont_flag_let_chance() {
        assert_lint_count("Let chance decide", NoContractionWithVerb::default(), 0);
    }

    #[test]
    fn dont_flag_let_time() {
        assert_lint_count(
            "Let time granularity be parametrized",
            NoContractionWithVerb::default(),
            0,
        );
    }

    #[test]
    fn dont_flag_lets_staff() {
        assert_lint_count(
            "A plugin that backs up player's inventories and lets staff restore them or export it as a shulker.",
            NoContractionWithVerb::default(),
            0,
        );
    }

    #[test]
    fn dont_flag_lets_time() {
        assert_lint_count(
            "This is very different than demo recording, which just simulates a network level connection and lets time move at its own rate.",
            NoContractionWithVerb::default(),
            0,
        );
    }

    #[test]
    fn dont_flag_lets_play() {
        assert_lint_count(
            "Sometimes the umpire lets play continue",
            NoContractionWithVerb::default(),
            0,
        );
    }

    // False positives where verb is a gerund/past participle

    #[test]
    fn dont_flag_let_sleeping() {
        assert_lint_count(
            "Let sleeping logs lie.",
            NoContractionWithVerb::default(),
            0,
        );
    }

    // False positives where verb is also an adjective

    #[test]
    fn dont_flag_let_processed() {
        assert_lint_count(
            "Let processed response be a new structure analogous to server auction response.",
            NoContractionWithVerb::default(),
            0,
        );
    }

    // Correct disambiguated noun/verb by following determiner

    #[test]
    fn corrects_lets_make_this() {
        assert_suggestion_result(
            "Lets make this joke repo into one of the best.",
            NoContractionWithVerb::default(),
            "Let's make this joke repo into one of the best.",
        );
    }

    // Correct disambiguated verb by following pronoun

    #[test]
    fn corrects_lets_mock_them() {
        assert_suggestion_result(
            "Then lets mock them using Module._load based mocker.",
            NoContractionWithVerb::default(),
            "Then let's mock them using Module._load based mocker.",
        );
    }

    // False positives / edge cases filed on GitHub

    #[test]
    fn dont_flag_let_us() {
        assert_lint_count("Let us do this.", NoContractionWithVerb::default(), 0);
    }

    #[test]
    fn dont_flag_let_go_1202() {
        assert_lint_count(
            "... until you hit your opponent, then let go and quickly retap",
            NoContractionWithVerb::default(),
            0,
        );
    }

    // False positive wrongly flagged by previous version of this linter

    #[test]
    fn dont_flag_let_in_and() {
        assert_lint_count(
            "Japanese is good enough to be let in and.",
            NoContractionWithVerb::default(),
            0,
        );
    }
}



================================================
FILE: harper-core/src/linting/mass_nouns/mass_plurals.rs
================================================
use hashbrown::HashSet;

use crate::linting::expr_linter::Chunk;
use crate::{
    CharStringExt, Token, TokenStringExt,
    expr::{All, Expr, FirstMatchOf, FixedPhrase, SequenceExpr},
    linting::{ExprLinter, Lint, LintKind, Suggestion},
    spell::Dictionary,
};

pub struct MassPlurals<D> {
    expr: Box<dyn Expr>,
    dict: D,
}

impl<D> MassPlurals<D>
where
    D: Dictionary,
{
    pub fn new(dict: D) -> Self {
        let oov = SequenceExpr::default().then_oov();
        let looks_plural = SequenceExpr::with(|tok: &Token, src: &[char]| {
            tok.span
                .get_content(src)
                .ends_with_ignore_ascii_case_chars(&['s'])
        });
        let oov_looks_plural = All::new(vec![Box::new(oov), Box::new(looks_plural)]);

        let phrases = FirstMatchOf::new(vec![
            Box::new(FixedPhrase::from_phrase("real estates")),
            Box::new(FixedPhrase::from_phrase("source codes")),
            Box::new(FixedPhrase::from_phrase("wear and tears")),
        ]);

        Self {
            expr: Box::new(FirstMatchOf::new(vec![
                Box::new(oov_looks_plural),
                Box::new(phrases),
            ])),
            dict,
        }
    }

    fn is_mass_noun_in_dictionary(&self, chars: &[char]) -> bool {
        self.dict
            .get_word_metadata(chars)
            .is_some_and(|wmd| wmd.is_mass_noun_only())
    }

    fn is_mass_noun_in_dictionary_str(&self, s: &str) -> bool {
        self.dict
            .get_word_metadata_str(s)
            .is_some_and(|wmd| wmd.is_mass_noun_only())
    }
}

impl<D> ExprLinter for MassPlurals<D>
where
    D: Dictionary,
{
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, toks: &[Token], src: &[char]) -> Option<Lint> {
        let invalid_plural_toks = toks;

        let mut valid_singulars: HashSet<Box<[char]>> = HashSet::new();

        if invalid_plural_toks.len() != 1 {
            // Multiple tokens means we matched a fixed phrase
            let phrase = invalid_plural_toks.span()?.get_content(src);
            valid_singulars.insert(phrase[..phrase.len() - 1].into());
        } else {
            let invalid_plural_tok = &invalid_plural_toks[0];
            // Not a fixed phrase, so it's a single word that's not in the dictionary and ends with -s
            let mut remaining_chars = invalid_plural_tok.span.get_content(src);

            // -s
            if remaining_chars.ends_with(&['s']) {
                remaining_chars = &remaining_chars[..remaining_chars.len() - 1];

                if self.is_mass_noun_in_dictionary(remaining_chars) {
                    valid_singulars.insert(remaining_chars.into());
                }

                // -es
                if remaining_chars.ends_with(&['e']) {
                    remaining_chars = &remaining_chars[..remaining_chars.len() - 1];

                    if self.is_mass_noun_in_dictionary(remaining_chars) {
                        valid_singulars.insert(remaining_chars.into());
                    }

                    // -ies -> -y
                    if remaining_chars.ends_with(&['i']) {
                        remaining_chars = &remaining_chars[..remaining_chars.len() - 1];

                        let y_singular = format!("{}y", remaining_chars.to_string());
                        if self.is_mass_noun_in_dictionary_str(&y_singular) {
                            let y_singular_chars: Box<[char]> =
                                y_singular.chars().collect::<Vec<char>>().into_boxed_slice();
                            valid_singulars.insert(y_singular_chars.clone());
                        }
                    }
                }
            }
        }

        if valid_singulars.is_empty() {
            return None;
        }

        let message = format!(
            "The {} `{}` is a mass noun and should not be pluralized.",
            if invalid_plural_toks.len() == 1 {
                "word"
            } else {
                "term"
            },
            valid_singulars
                .iter()
                .map(|s| s.to_string())
                .collect::<Vec<String>>()
                .join("`, `")
        );

        let span = invalid_plural_toks.span()?;

        let suggestions: Vec<Suggestion> = valid_singulars
            .iter()
            .map(|sing| {
                Suggestion::replace_with_match_case(sing.clone().into(), span.get_content(src))
            })
            .collect();

        Some(Lint {
            span,
            lint_kind: LintKind::Grammar,
            suggestions,
            message,
            ..Default::default()
        })
    }

    fn description(&self) -> &'static str {
        "Looks for plural forms of mass nouns that have no plural."
    }
}

#[cfg(test)]
mod tests {
    use crate::{
        linting::tests::{assert_lint_count, assert_suggestion_result},
        spell::FstDictionary,
    };

    use super::MassPlurals;

    #[test]
    fn flag_advicess() {
        assert_lint_count(
            "You gave me bad advices.",
            MassPlurals::new(FstDictionary::curated()),
            1,
        );
    }

    #[test]
    fn flag_source_codes_and_softwares() {
        assert_lint_count(
            "Do we have the source codes for these softwares?",
            MassPlurals::new(FstDictionary::curated()),
            2,
        );
    }

    #[test]
    fn flag_noun_ending_in_ies() {
        assert_lint_count(
            "Celibacies are better than sex.",
            MassPlurals::new(FstDictionary::curated()),
            1,
        );
    }

    #[test]
    fn flag_real_estates() {
        assert_lint_count(
            "Instead of giving any of her many luxury real estates or multi-million dollar fortune ...",
            MassPlurals::new(FstDictionary::curated()),
            1,
        );
    }

    #[test]
    fn flag_wear_and_tears() {
        assert_lint_count(
            "Transit costs were high in terms of time, finances, and vehicle wear and tears, which posed significant obstacles to international commerce",
            MassPlurals::new(FstDictionary::curated()),
            1,
        );
    }

    #[test]
    fn fix_wear_and_tears() {
        assert_suggestion_result(
            "Transit costs were high in terms of time, finances, and vehicle wear and tears, which posed significant obstacles to international commerce",
            MassPlurals::new(FstDictionary::curated()),
            "Transit costs were high in terms of time, finances, and vehicle wear and tear, which posed significant obstacles to international commerce",
        );
    }
}



================================================
FILE: harper-core/src/linting/mass_nouns/mod.rs
================================================
mod mass_plurals;
mod noun_countability;

use mass_plurals::MassPlurals;
use noun_countability::NounCountability;

use crate::{
    Document,
    linting::{Lint, Linter},
    remove_overlaps,
    spell::Dictionary,
};

pub struct MassNouns<D> {
    mass_plurals: MassPlurals<D>,
    noun_countability: NounCountability,
}

impl<D> MassNouns<D>
where
    D: Dictionary + Clone,
{
    pub fn new(dict: D) -> Self {
        Self {
            mass_plurals: MassPlurals::new(dict.clone()),
            noun_countability: NounCountability::default(),
        }
    }
}

impl<D> Linter for MassNouns<D>
where
    D: Dictionary,
{
    fn lint(&mut self, document: &Document) -> Vec<Lint> {
        let mut lints = Vec::new();

        lints.extend(self.mass_plurals.lint(document));
        lints.extend(self.noun_countability.lint(document));

        remove_overlaps(&mut lints);

        lints
    }

    fn description(&self) -> &'static str {
        "Detects mass nouns used as countable nouns."
    }
}

#[cfg(test)]
mod tests {
    use crate::{
        linting::tests::{assert_lint_count, assert_suggestion_result},
        spell::FstDictionary,
    };

    use super::MassNouns;

    #[test]
    fn flag_advices_and_an_advice() {
        assert_lint_count(
            "I asked for an advice and he gave me two advices!",
            MassNouns::new(FstDictionary::curated()),
            2,
        );
    }

    #[test]
    fn correct_a_luggage() {
        assert_suggestion_result(
            "I managed to pack all my clothing into one luggage.",
            MassNouns::new(FstDictionary::curated()),
            "I managed to pack all my clothing into one suitcase.",
        );
    }

    #[test]
    fn correct_clothings() {
        assert_suggestion_result(
            "I managed to pack all my clothings into one suitcase.",
            MassNouns::new(FstDictionary::curated()),
            "I managed to pack all my clothing into one suitcase.",
        );
    }
}



================================================
FILE: harper-core/src/linting/mass_nouns/noun_countability.rs
================================================
use crate::linting::expr_linter::Chunk;
use crate::{
    Lrc, Span, Token, TokenStringExt,
    expr::{Expr, FirstMatchOf, LongestMatchOf, SequenceExpr},
    linting::{ExprLinter, Lint, LintKind, Suggestion},
    patterns::{IndefiniteArticle, WordSet},
};

#[derive(Debug, Clone, Copy)]
pub enum Correction {
    // Drop the determiner or quantifier
    DropDQ,
    // Replace the determiner or quantifier with a string
    ReplaceDQWith(&'static str),
    // Insert a string between the determiner or quantifier and the mass noun
    InsertBetween(&'static str),
    // Replace the mass noun with a string
    ReplaceNounWith(&'static str),
}

use Correction::*;

pub struct NounCountability {
    expr: Box<dyn Expr>,
}

impl Default for NounCountability {
    fn default() -> Self {
        let quantifier = WordSet::new(&[
            "another", "both", "each", "every", "few", "fewer", "many", "multiple", "one",
            "several",
        ]);

        // A determiner or quantifier followed by a mass noun
        let detquant_mass = Lrc::new(
            SequenceExpr::default()
                .then(FirstMatchOf::new(vec![
                    Box::new(IndefiniteArticle::default()),
                    Box::new(quantifier),
                ]))
                .then_whitespace()
                .then_mass_noun_only(),
        );

        let detauant_mass_then_hyphen = Lrc::new(
            SequenceExpr::default()
                .then(detquant_mass.clone())
                .then_hyphen(),
        );

        let detquant_mass_following_context = Lrc::new(
            SequenceExpr::default()
                .then(detquant_mass.clone())
                .then_whitespace()
                // If we don't get the word, this won't be the longest match
                .then_any_word(),
        );

        Self {
            expr: Box::new(LongestMatchOf::new(vec![
                Box::new(detquant_mass),
                Box::new(detauant_mass_then_hyphen),
                Box::new(detquant_mass_following_context),
            ])),
        }
    }
}

impl ExprLinter for NounCountability {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, toks: &[Token], src: &[char]) -> Option<Lint> {
        let toks_chars = toks.span()?.get_content(src);

        // 4 tokens means the phrase was followed by a hyphen
        if toks.len() == 4 {
            return None;
        }
        // 3 tokens means the phrase was at the end of a chunk/sentence.
        // 5 tokens means the phrase was in the middle of a chunk/sentence.
        // If it's in the middle then we check if the next word token is a noun or OOV.
        // Since the last token of our phrase is the mass noun, this would make it part of a compound noun.
        if toks.len() == 5 && (toks.last()?.kind.is_noun() || toks.last()?.kind.is_oov()) {
            return None;
        }

        // the determiner or quantifier
        let dq = toks[0].span.get_content_string(src).to_lowercase();

        // the mass noun
        let noun = toks[2].span.get_content_string(src).to_lowercase();

        let synonym_corrections: &'static [Correction] = match (noun.as_str(), dq.as_str()) {
            ("advice", "a" | "an" | "another" | "each" | "every" | "one") => &[
                ReplaceNounWith("tip"),
                ReplaceNounWith("suggestion"),
                ReplaceNounWith("recommendation"),
            ],
            ("advice", "both" | "many" | "multiple" | "several") => &[
                ReplaceNounWith("tips"),
                ReplaceNounWith("suggestions"),
                ReplaceNounWith("recommendations"),
            ],
            ("clothing", "a" | "an" | "another" | "each" | "every" | "one") => {
                &[ReplaceNounWith("garment")]
            }
            ("clothing", "both" | "many" | "multiple" | "several") => {
                &[ReplaceNounWith("garments")]
            }
            ("luggage", "a" | "an" | "another" | "each" | "every" | "one") => {
                &[ReplaceNounWith("suitcase"), ReplaceNounWith("bag")]
            }
            ("luggage", "both" | "many" | "multiple" | "several") => {
                &[ReplaceNounWith("suitcases"), ReplaceNounWith("bags")]
            }
            ("punctuation", "a" | "an" | "another" | "each" | "every" | "one") => {
                &[ReplaceNounWith("punctuation mark")]
            }
            ("punctuation", "both" | "many" | "multiple" | "several") => {
                &[ReplaceNounWith("punctuation marks")]
            }
            ("software", "a") => &[
                ReplaceNounWith("program"),
                ReplaceNounWith("software package"),
                ReplaceNounWith("software tool"),
            ],
            ("software", "an" | "another" | "each" | "every" | "one") => &[
                ReplaceNounWith("app"),
                ReplaceNounWith("application"),
                ReplaceNounWith("program"),
                ReplaceNounWith("software package"),
                ReplaceNounWith("software tool"),
            ],
            ("software", "both" | "many" | "multiple" | "several") => &[
                ReplaceNounWith("apps"),
                ReplaceNounWith("applications"),
                ReplaceNounWith("programs"),
                ReplaceNounWith("software packages"),
                ReplaceNounWith("software tools"),
            ],
            _ => &[],
        };

        let no_piece = matches!(noun.as_str(), "punctuation" | "traffic");

        let basic_corrections: &'static [Correction] = match (dq.as_str(), no_piece) {
            ("a" | "an", true) => &[DropDQ, ReplaceDQWith("some")],
            ("a" | "an", false) => &[DropDQ, ReplaceDQWith("some"), ReplaceDQWith("a piece of")],
            ("another" | "each" | "every" | "one", true) => &[],
            ("another" | "each" | "every" | "one", false) => &[InsertBetween("piece of")],
            ("both" | "multiple" | "several", true) => &[],
            ("both" | "multiple" | "several", false) => &[InsertBetween("pieces of")],
            ("few", true) => &[ReplaceDQWith("little")],
            ("few", false) => &[ReplaceDQWith("little"), InsertBetween("pieces of")],
            ("fewer", true) => &[ReplaceDQWith("less")],
            ("fewer", false) => &[ReplaceDQWith("less"), InsertBetween("pieces of")],
            ("many", true) => &[ReplaceDQWith("much"), ReplaceDQWith("a lot of")],
            ("many", false) => &[
                ReplaceDQWith("much"),
                ReplaceDQWith("a lot of"),
                InsertBetween("pieces of"),
            ],
            _ => &[],
        };

        let mut suggestions = Vec::new();

        for correction in synonym_corrections {
            let parts = match correction {
                ReplaceNounWith(w) => &[&dq, *w],
                _ => return None,
            };
            suggestions.push(Suggestion::replace_with_match_case(
                parts.join(" ").chars().collect(),
                toks_chars,
            ));
        }

        suggestions.extend(basic_corrections.iter().map(|correction| {
            let parts: &[&str] = match correction {
                DropDQ => &[&noun],
                ReplaceDQWith(w) => &[w, &noun],
                InsertBetween(w) => &[&dq, w, &noun],
                ReplaceNounWith(w) => &[&dq, w],
            };
            Suggestion::replace_with_match_case(parts.join(" ").chars().collect(), toks_chars)
        }));

        Some(Lint {
            span: Span::new(toks[0].span.start, toks[2].span.end),
            lint_kind: LintKind::Agreement,
            suggestions,
            message: format!("`{noun}` is a mass noun."),
            priority: 31,
        })
    }

    fn description(&self) -> &'static str {
        "Correct mass nouns that are preceded by the wrong determiners or quantifiers."
    }
}

#[cfg(test)]
mod tests {
    use super::NounCountability;
    use crate::linting::tests::{assert_lint_count, assert_top3_suggestion_result};

    #[test]
    fn corrects_a() {
        assert_top3_suggestion_result(
            "If the unit turns out to be noisy, can I expect a firmware with phase ...",
            NounCountability::default(),
            "If the unit turns out to be noisy, can I expect some firmware with phase ...",
        );
    }

    #[test]
    #[ignore = "replace_with_match_case matches by index, not by lower vs title vs upper"]
    fn corrects_a_title_case() {
        assert_top3_suggestion_result(
            "Simple POC of a Ransomware.",
            NounCountability::default(),
            "Simple POC of a piece of Ransomware.",
        );
    }

    #[test]
    fn corrects_an() {
        assert_top3_suggestion_result(
            "The PlaySEM platform provides an infrastructure for playing and rendering sensory effects in multimedia applications.",
            NounCountability::default(),
            "The PlaySEM platform provides infrastructure for playing and rendering sensory effects in multimedia applications.",
        );
    }

    #[test]
    #[ignore = "replace_with_match_case matches by index, not by lower vs title vs upper"]
    fn corrects_an_title_case() {
        assert_top3_suggestion_result(
            "An Infrastructure for Integrated EDA.",
            NounCountability::default(),
            "Infrastructure for Integrated EDA.",
        );
    }

    #[test]
    fn corrects_another() {
        assert_top3_suggestion_result(
            "Another ransomware made by me for fun.",
            NounCountability::default(),
            "Another piece of ransomware made by me for fun.",
        );
    }

    #[test]
    fn corrects_both() {
        assert_top3_suggestion_result(
            "Make a terminal show both information of your CPU and GPU!",
            NounCountability::default(),
            "Make a terminal show both pieces of information of your CPU and GPU!",
        );
    }

    #[test]
    // "piece of traffic" sounds very weird
    fn can_correct_each_with_traffic() {
        assert_top3_suggestion_result(
            "Beside each traffic there is also a pedestrian traffic light.",
            NounCountability::default(),
            "Beside each traffic there is also a pedestrian traffic light.",
        );
    }

    #[test]
    fn corrects_every() {
        assert_top3_suggestion_result(
            "Capacitor plugin to get access to every info about the device software and hardware.",
            NounCountability::default(),
            "Capacitor plugin to get access to every piece of info about the device software and hardware.",
        );
    }

    #[test]
    fn corrects_few() {
        assert_top3_suggestion_result(
            "Displays a few information to help you rotating through your spells.",
            NounCountability::default(),
            "Displays a few pieces of information to help you rotating through your spells.",
        );
    }

    #[test]
    fn corrects_many() {
        assert_top3_suggestion_result(
            "It shows clearly how many information about objects you can get with old search ...",
            NounCountability::default(),
            "It shows clearly how much information about objects you can get with old search ...",
        );
    }

    #[test]
    fn corrects_one() {
        assert_top3_suggestion_result(
            "For example, it only makes sense to compare global protein q-value filtering in one software with that in another.",
            NounCountability::default(),
            "For example, it only makes sense to compare global protein q-value filtering in one application with that in another.",
        );
    }

    #[test]
    #[ignore = "'in' = noun because conflated with 'IN' (Indiana)"]
    fn corrects_several() {
        assert_top3_suggestion_result(
            "The program takes in input a single XML file and outputs several info in different files.",
            NounCountability::default(),
            "The program takes in input a single XML file and outputs several pieces of info in different files.",
        );
    }

    #[test]
    fn dont_correct_many_compound() {
        assert_lint_count(
            "Additionally, many software development platforms also provide access to a community of developers.",
            NounCountability::default(),
            0,
        );
    }

    #[test]
    #[ignore]
    fn dont_correct_first_do_correct_second() {
        assert_top3_suggestion_result(
            "A advice description is required for each advice.",
            NounCountability::default(),
            "A advice description is required for each piece of advice.",
        );
    }

    #[test]
    fn corrects_an_advice() {
        assert_top3_suggestion_result(
            "Origin will not always provide the right method when an advice is applied to a bridged method.",
            NounCountability::default(),
            "Origin will not always provide the right method when an tip is applied to a bridged method.",
        );
    }

    #[test]
    fn corrects_one_advice() {
        assert_top3_suggestion_result(
            "Is it possible to use more than one advice on the same method?",
            NounCountability::default(),
            "Is it possible to use more than one tip on the same method?",
        );
    }

    #[test]
    fn corrects_every_advice() {
        assert_top3_suggestion_result(
            "Ideally every advice would have a unique identifier.",
            NounCountability::default(),
            "Ideally every tip would have a unique identifier.",
        );
    }

    #[test]
    fn corrects_a_advice() {
        assert_top3_suggestion_result(
            "Hello! I need a advice.",
            NounCountability::default(),
            "Hello! I need a tip.",
        );
    }

    #[test]
    fn corrects_a_software() {
        assert_top3_suggestion_result(
            "HGroup-DIA, a software for analyzing multiple DIA data files.",
            NounCountability::default(),
            "HGroup-DIA, a software package for analyzing multiple DIA data files.",
        );
    }

    #[test]
    fn corrects_a_luggage() {
        assert_top3_suggestion_result(
            "A luggage with a little engine, sensors (gps, ultrasounds, etc...) and bluetooth connection that will follow you everywhere.",
            NounCountability::default(),
            "A suitcase with a little engine, sensors (gps, ultrasounds, etc...) and bluetooth connection that will follow you everywhere.",
        );
    }

    #[test]
    fn corrects_multiple_advice() {
        assert_top3_suggestion_result(
            "Update Advice API doc for event and data params, multiple advice.",
            NounCountability::default(),
            "Update Advice API doc for event and data params, multiple suggestions.",
        );
    }

    #[test]
    fn corrects_every_software() {
        assert_top3_suggestion_result(
            "Rewrite every software known to man in Rust.",
            NounCountability::default(),
            "Rewrite every application known to man in Rust.",
        );
    }

    #[test]
    fn corrects_each_furniture() {
        assert_top3_suggestion_result(
            "the position (x, y) and size (height, width, length) of each furniture",
            NounCountability::default(),
            "the position (x, y) and size (height, width, length) of each piece of furniture",
        );
    }

    #[test]
    fn corrects_one_clothing() {
        assert_top3_suggestion_result(
            "Each list element represents one clothing based on weather conditions.",
            NounCountability::default(),
            "Each list element represents one garment based on weather conditions.",
        );
    }

    #[test]
    fn dont_flag_compound_nouns() {
        assert_lint_count(
            "Fill in the blanks following the creation of each Furniture class instance.",
            NounCountability::default(),
            0,
        );
        assert_lint_count(
            "This project is a clothing shop that let users buy and pay for they purchases.",
            NounCountability::default(),
            0,
        );
        assert_lint_count(
            "Yet another software router.",
            NounCountability::default(),
            0,
        );
        assert_lint_count(
            "Calculate a rate for every software component.",
            NounCountability::default(),
            0,
        );
    }

    #[test]
    fn corrects_fewer() {
        assert_top3_suggestion_result(
            "Why do my packages have fewer information?",
            NounCountability::default(),
            "Why do my packages have less information?",
        );
    }

    #[test]
    fn dont_flag_fewer_in_compound_noun() {
        assert_lint_count(
            "Additionally, less traffic leads to fewer traffic jams, resulting in a more fluent, thus more efficient, trip.",
            NounCountability::default(),
            0,
        );
    }

    #[test]
    fn dont_flag_mass_noun_part_of_hyphenated_compound() {
        assert_lint_count(
            "Internally, we have a hardware-in-the-loop Jenkins test suite that builds and unit tests the various processes.",
            NounCountability::default(),
            0,
        );
    }

    #[test]
    fn corrects_punctuation() {
        assert_top3_suggestion_result(
            "Not in this form because it currently works with one punctuation with one letter either side.",
            NounCountability::default(),
            "Not in this form because it currently works with one punctuation mark with one letter either side.",
        );
    }
}



================================================
FILE: harper-core/src/linting/noun_verb_confusion/mod.rs
================================================
use super::merge_linters::merge_linters;

mod effect_affect;
mod noun_instead_of_verb;
mod verb_instead_of_noun;

// Common noun-verb pairs that are often confused
// See also [`NounInsteadOfVerb``]
pub(crate) const NOUN_VERB_PAIRS: &[(&str, &str)] = &[
    ("advice", "advise"),
    ("belief", "believe"),
    ("breath", "breathe"),
    ("effect", "affect"), // "Effect" is also a verb meaning "to bring about". "Affect" is a noun in psychology.
    ("emphasis", "emphasize"), // TODO how to handle "emphasise" as well as "emphasize"?
    ("intent", "intend"),
    // ("proof", "prove"),  // "Proof" is also a verb, a synonym of "proofread".
    ("weight", "weigh"),
    // Add more pairs here as needed
];

use noun_instead_of_verb::NounInsteadOfVerb;
use verb_instead_of_noun::VerbInsteadOfNoun;

merge_linters! {
    NounVerbConfusion =>
        NounInsteadOfVerb,
        VerbInsteadOfNoun
        => "Handles common confusions between related nouns and verbs (e.g., 'advice/advise', 'breath/breathe')"
}

#[cfg(test)]
mod tests {
    use super::NounVerbConfusion;
    use crate::linting::tests::{assert_lint_count, assert_no_lints, assert_suggestion_result};

    #[test]
    fn corrects_good_advise() {
        assert_suggestion_result("Good advise", NounVerbConfusion::default(), "Good advice");
    }

    #[test]
    fn corrects_bad_advise() {
        assert_suggestion_result(
            "I just wanted to bring attention to this because it stood out to me as potentially bad advise.",
            NounVerbConfusion::default(),
            "I just wanted to bring attention to this because it stood out to me as potentially bad advice.",
        );
    }

    #[test]
    fn dont_flag_correct_better_advise() {
        assert_lint_count(
            "Hello! I am an engineer at Plexon and am conducting tests with Kilosort4 so we can better advise our clients.",
            NounVerbConfusion::default(),
            0,
        );
    }

    #[test]
    #[ignore = "'better advise' can be correct as above, or a mistake like here"]
    fn correct_better_advise() {
        assert_suggestion_result(
            "Maybe this will be a decent idea, .or anybody has better advise :)",
            NounVerbConfusion::default(),
            "Maybe this will be a decent idea, .or anybody has better advice :)",
        );
    }

    #[test]
    fn dont_flag_correct_better_believe() {
        assert_lint_count(
            "You'd better believe this is bbedit-gist-maker.",
            NounVerbConfusion::default(),
            0,
        );
    }

    #[test]
    fn correct_strong_believe() {
        assert_suggestion_result(
            "cause my strong believe is that we must give any user to describe whether a post is meant factual",
            NounVerbConfusion::default(),
            "cause my strong belief is that we must give any user to describe whether a post is meant factual",
        );
    }

    #[test]
    fn correct_deep_breathe() {
        assert_suggestion_result(
            "Take deep breathe and Do it again!",
            NounVerbConfusion::default(),
            "Take deep breath and Do it again!",
        );
    }

    #[test]
    fn correct_bad_intend() {
        assert_suggestion_result(
            "What do you do if you only see slightly longer posts that may still be acceptable (and not bad intend from the poster)",
            NounVerbConfusion::default(),
            "What do you do if you only see slightly longer posts that may still be acceptable (and not bad intent from the poster)",
        );
    }

    #[test]
    fn corrects_belief_instead_of_verb() {
        assert_suggestion_result(
            "I belief in you.",
            NounVerbConfusion::default(),
            "I believe in you.",
        );
    }

    #[test]
    #[ignore = "`to` can't disambiguate since it's valid between verbs and nouns"]
    fn corrects_breath_instead_of_verb() {
        assert_suggestion_result(
            "Remember to breath deeply.",
            NounVerbConfusion::default(),
            "Remember to breathe deeply.",
        );
    }

    #[test]
    fn does_not_flag_correct_believe() {
        assert_lint_count("I believe in you.", NounVerbConfusion::default(), 0);
    }

    #[test]
    fn does_not_flag_correct_breath() {
        assert_lint_count("Take a deep breath.", NounVerbConfusion::default(), 0);
    }

    // real-world example unit tests

    #[test]
    fn fix_when_i_breath_you_breath() {
        assert_suggestion_result(
            "When I breath, you breath!",
            NounVerbConfusion::default(),
            "When I breathe, you breathe!",
        );
    }

    #[test]
    fn fix_weather_climate_and_the_air_we_breath() {
        assert_suggestion_result(
            "Weather Climate and the Air We Breath",
            NounVerbConfusion::default(),
            "Weather Climate and the Air We Breathe",
        );
    }

    #[test]
    fn fix_always_breath() {
        assert_suggestion_result(
            "breathing. remember to always breath.",
            NounVerbConfusion::default(),
            "breathing. remember to always breathe.",
        );
    }

    #[test]
    fn fix_never_breath_a_word() {
        assert_suggestion_result(
            "And never breath a word about your loss; If you can force your heart and nerve and sinew.",
            NounVerbConfusion::default(),
            "And never breathe a word about your loss; If you can force your heart and nerve and sinew.",
        );
    }

    #[test]
    fn fix_breath_for_seconds() {
        assert_suggestion_result(
            "Once turned on, the LED on the TX unit would breath for a few seconds, then go completely dead and not responding to objects in front of the sensors.",
            NounVerbConfusion::default(),
            "Once turned on, the LED on the TX unit would breathe for a few seconds, then go completely dead and not responding to objects in front of the sensors.",
        );
    }

    #[test]
    fn fix_breath_a_little_more_life() {
        assert_suggestion_result(
            "... up to 12% more performance, could breath a little more life into systems as old as Sandy Bridge.",
            NounVerbConfusion::default(),
            "... up to 12% more performance, could breathe a little more life into systems as old as Sandy Bridge.",
        );
    }

    #[test]
    fn fix_the_diversity_we_breath() {
        assert_suggestion_result(
            "The Diversity We Breath: Community Diversity",
            NounVerbConfusion::default(),
            "The Diversity We Breathe: Community Diversity",
        );
    }

    #[test]
    fn fix_belief() {
        assert_suggestion_result(
            "While I have no plans to return to aerospace I belief it gives me a unique perspective to many challenges.",
            NounVerbConfusion::default(),
            "While I have no plans to return to aerospace I believe it gives me a unique perspective to many challenges.",
        );
    }

    #[test]
    fn fix_we_belief() {
        assert_suggestion_result(
            "In contrast to other vendors in e-mobility, we belief that true transparency is only trustworthy if the entire process ...",
            NounVerbConfusion::default(),
            "In contrast to other vendors in e-mobility, we believe that true transparency is only trustworthy if the entire process ...",
        );
    }

    #[test]
    #[ignore = "`underwater` is a marginal noun so `breath underwater` matches the compound noun test."]
    fn fix_i_can_breath() {
        assert_suggestion_result(
            "Steps to reproduce Expected behaviour I can breath underwater.",
            NounVerbConfusion::default(),
            "Steps to reproduce Expected behaviour I can breathe underwater.",
        );
    }

    #[test]
    fn fix_caps_should_breath() {
        assert_suggestion_result(
            "CAPS 1 2 3 4 5 A B C D SHOULD BREATH A BIT MORE ?",
            NounVerbConfusion::default(),
            "CAPS 1 2 3 4 5 A B C D SHOULD BREATHE A BIT MORE ?",
        );
    }

    #[test]
    fn fix_can_you_advice_me() {
        assert_suggestion_result(
            "Can you advice me how to train?",
            NounVerbConfusion::default(),
            "Can you advise me how to train?",
        );
    }

    #[test]
    fn fix_we_can_advice_you() {
        assert_suggestion_result(
            "Feel free to share more details about your use case, so we can advice you specifically based on your case.",
            NounVerbConfusion::default(),
            "Feel free to share more details about your use case, so we can advise you specifically based on your case.",
        );
    }

    #[test]
    fn fix_would_advice_against() {
        assert_suggestion_result(
            "So that I would advice against using a spindle in laser mode.",
            NounVerbConfusion::default(),
            "So that I would advise against using a spindle in laser mode.",
        );
    }

    #[test]
    fn fix_advice_to_listen() {
        assert_suggestion_result(
            "The idea of this applicaton was inspired by Ray Dalio, who always advice to listen to people who know more than us by experience.",
            NounVerbConfusion::default(),
            "The idea of this applicaton was inspired by Ray Dalio, who always advise to listen to people who know more than us by experience.",
        );
    }

    #[test]
    #[ignore = "`You` is an object pronoun in this example. `It` is also both subject and object."]
    fn dont_fix_advice_on_that() {
        assert_lint_count(
            "I don't do table returning functions in my code so can't offer you advice on that.",
            NounVerbConfusion::default(),
            0,
        );
    }

    #[test]
    fn fix_advice_to_stick_with_openvscode() {
        assert_suggestion_result(
            "But unless you really need it, I would advice to stick with openvscode as there are nearly the same.",
            NounVerbConfusion::default(),
            "But unless you really need it, I would advise to stick with openvscode as there are nearly the same.",
        );
    }

    #[test]
    fn fix_advice_to_back_up_os_image() {
        assert_suggestion_result(
            "I would advice to back up all OS image before any update, because you could lose something what was working previously.",
            NounVerbConfusion::default(),
            "I would advise to back up all OS image before any update, because you could lose something what was working previously.",
        );
    }

    #[test]
    fn fix_advice_to_use_ms_store() {
        assert_suggestion_result(
            "I know we can always advice to use the MS store to download JASP instead",
            NounVerbConfusion::default(),
            "I know we can always advise to use the MS store to download JASP instead",
        );
    }

    #[test]
    fn fix_should_intent_be() {
        assert_suggestion_result(
            "Should intent be on the blocklist?",
            NounVerbConfusion::default(),
            "Should intent be on the blocklist?",
        );
    }

    #[test]
    fn fix_if_you_intent() {
        assert_suggestion_result(
            "If you intent to use a 64 bits machine, change line 74",
            NounVerbConfusion::default(),
            "If you intend to use a 64 bits machine, change line 74",
        );
    }

    #[test]
    fn fix_what_you_would_intent_to_do() {
        assert_suggestion_result(
            "May I ask what you would intent to do with such a feature?",
            NounVerbConfusion::default(),
            "May I ask what you would intend to do with such a feature?",
        );
    }

    #[test]
    fn dont_flag_intent_records() {
        assert_lint_count(
            "there are always intent records associated to the txns",
            NounVerbConfusion::default(),
            0,
        );
    }

    #[test]
    fn fix_did_you_always_intent_to() {
        assert_suggestion_result(
            "Did you always intent to fight malware? No.",
            NounVerbConfusion::default(),
            "Did you always intend to fight malware? No.",
        );
    }

    #[test]
    fn fix_we_recommend_you_create_a_new_issue_on_github_explaining_what_you_intent_to_do() {
        assert_suggestion_result(
            "... we recommend you create a new issue on github explaining what you intent to do.",
            NounVerbConfusion::default(),
            "... we recommend you create a new issue on github explaining what you intend to do.",
        );
    }

    #[test]
    fn fix_intent_to_use_non_imported_symbol() {
        assert_suggestion_result(
            "There's a warning reported for this code, saying that it may intent to use non-imported symbol",
            NounVerbConfusion::default(),
            "There's a warning reported for this code, saying that it may intend to use non-imported symbol",
        );
    }

    // tests for preceding "to"

    #[test]
    fn fix_to_emphasis_the() {
        assert_suggestion_result(
            "This one could be used in a dialog to emphasis the surprise.",
            NounVerbConfusion::default(),
            "This one could be used in a dialog to emphasize the surprise.",
        );
    }

    #[test]
    fn allow_to_emphasis_at_end() {
        assert_lint_count(
            "Changes literal underscores to emphasis",
            NounVerbConfusion::default(),
            0,
        );
    }

    #[test]
    fn allow_to_intent_adjective() {
        assert_lint_count(
            "Cleanup passing statistics to intent aware iterator",
            NounVerbConfusion::default(),
            0,
        );
    }

    #[test]
    fn fix_to_advice_a_class() {
        assert_suggestion_result(
            "How to advice a class that have been intercepted by another javaagent",
            NounVerbConfusion::default(),
            "How to advise a class that have been intercepted by another javaagent",
        );
    }

    #[test]
    fn fix_to_breath_some() {
        assert_suggestion_result(
            "You go to the balcony to breath some fresh air and look down at the things outside.",
            NounVerbConfusion::default(),
            "You go to the balcony to breathe some fresh air and look down at the things outside.",
        );
    }

    #[test]
    fn fix_to_emphasis_a() {
        assert_suggestion_result(
            "we'd like to emphasis a few points below",
            NounVerbConfusion::default(),
            "we'd like to emphasize a few points below",
        );
    }

    #[test]
    fn fix_to_advice_their() {
        assert_suggestion_result(
            "People who are managing this situation tend to advice their users to lock+unlock their screen",
            NounVerbConfusion::default(),
            "People who are managing this situation tend to advise their users to lock+unlock their screen",
        );
    }

    // affect vs. effect sentences gathered from user reports

    #[test]
    fn fix_positive_affect_on_small_businesses() {
        assert_suggestion_result(
            "The new law had a positive affect on small businesses.",
            NounVerbConfusion::default(),
            "The new law had a positive effect on small businesses.",
        );
    }

    #[test]
    fn fix_measured_the_affect_of_caffeine() {
        assert_suggestion_result(
            "We measured the affect of caffeine on reaction time.",
            NounVerbConfusion::default(),
            "We measured the effect of caffeine on reaction time.",
        );
    }

    #[test]
    fn fix_side_affects_included_nausea() {
        assert_suggestion_result(
            "The side affects included nausea and fatigue.",
            NounVerbConfusion::default(),
            "The side effects included nausea and fatigue.",
        );
    }

    #[test]
    fn fix_cause_and_affect_not_same() {
        assert_suggestion_result(
            "Cause and affect are not the same thing.",
            NounVerbConfusion::default(),
            "Cause and effect are not the same thing.",
        );
    }

    #[test]
    fn fix_change_will_have_an_affect_on_revenue() {
        assert_suggestion_result(
            "The change will have an affect on our revenue.",
            NounVerbConfusion::default(),
            "The change will have an effect on our revenue.",
        );
    }

    #[test]
    fn fix_medicine_took_affect_within_minutes() {
        assert_suggestion_result(
            "The medicine took affect within minutes.",
            NounVerbConfusion::default(),
            "The medicine took effect within minutes.",
        );
    }

    #[test]
    fn fix_policy_will_come_into_affect() {
        assert_suggestion_result(
            "The policy will come into affect on October 1.",
            NounVerbConfusion::default(),
            "The policy will come into effect on October 1.",
        );
    }

    #[test]
    fn fix_rules_are_now_in_affect() {
        assert_suggestion_result(
            "The rules are now in affect.",
            NounVerbConfusion::default(),
            "The rules are now in effect.",
        );
    }

    #[test]
    fn fix_with_immediate_affect_office_closed() {
        assert_suggestion_result(
            "With immediate affect, the office is closed.",
            NounVerbConfusion::default(),
            "With immediate effect, the office is closed.",
        );
    }

    #[test]
    fn fix_stunning_special_affects() {
        assert_suggestion_result(
            "The director used stunning special affects.",
            NounVerbConfusion::default(),
            "The director used stunning special effects.",
        );
    }

    #[test]
    fn fix_placebo_affect_can_be_powerful() {
        assert_suggestion_result(
            "The placebo affect can be powerful.",
            NounVerbConfusion::default(),
            "The placebo effect can be powerful.",
        );
    }

    #[test]
    fn fix_ripple_affect_across_market() {
        assert_suggestion_result(
            "We felt the ripple affect across the entire market.",
            NounVerbConfusion::default(),
            "We felt the ripple effect across the entire market.",
        );
    }

    #[test]
    fn fix_snowball_affect_amplified_problem() {
        assert_suggestion_result(
            "The snowball affect amplified the problem.",
            NounVerbConfusion::default(),
            "The snowball effect amplified the problem.",
        );
    }

    #[test]
    fn fix_knock_on_affect_throughout_team() {
        assert_suggestion_result(
            "That decision had a knock-on affect throughout the team.",
            NounVerbConfusion::default(),
            "That decision had a knock-on effect throughout the team.",
        );
    }

    #[test]
    fn fix_greenhouse_affect_warms_planet() {
        assert_suggestion_result(
            "The greenhouse affect warms the planet.",
            NounVerbConfusion::default(),
            "The greenhouse effect warms the planet.",
        );
    }

    #[test]
    fn fix_apology_had_little_affect() {
        assert_suggestion_result(
            "Her apology had little affect.",
            NounVerbConfusion::default(),
            "Her apology had little effect.",
        );
    }

    #[test]
    fn fix_settings_go_into_affect() {
        assert_suggestion_result(
            "The new settings go into affect after a restart.",
            NounVerbConfusion::default(),
            "The new settings go into effect after a restart.",
        );
    }

    #[test]
    fn fix_put_plan_into_affect() {
        assert_suggestion_result(
            "They put the new plan into affect last week.",
            NounVerbConfusion::default(),
            "They put the new plan into effect last week.",
        );
    }

    #[test]
    fn fix_contract_comes_into_affect() {
        assert_suggestion_result(
            "The contract comes into affect at midnight.",
            NounVerbConfusion::default(),
            "The contract comes into effect at midnight.",
        );
    }

    #[test]
    fn fix_warning_had_no_affect_on_behavior() {
        assert_suggestion_result(
            "The warning had no affect on his behavior.",
            NounVerbConfusion::default(),
            "The warning had no effect on his behavior.",
        );
    }

    #[test]
    fn fix_inflation_had_opposite_affect() {
        assert_suggestion_result(
            "Inflation had the opposite affect than expected.",
            NounVerbConfusion::default(),
            "Inflation had the opposite effect than expected.",
        );
    }

    #[test]
    fn fix_regulation_remains_in_affect() {
        assert_suggestion_result(
            "The regulation remains in affect until further notice.",
            NounVerbConfusion::default(),
            "The regulation remains in effect until further notice.",
        );
    }

    #[test]
    fn fix_app_changes_take_affect() {
        assert_suggestion_result(
            "The app changes take affect next week.",
            NounVerbConfusion::default(),
            "The app changes take effect next week.",
        );
    }

    #[test]
    fn fix_sound_affects_were_added() {
        assert_suggestion_result(
            "Sound affects were added in post.",
            NounVerbConfusion::default(),
            "Sound effects were added in post.",
        );
    }

    // Effect/affect-specific checks
    // `effect` mistakenly used as the verb `affect`.
    #[test]
    fn corrects_noun_subject_effects_object() {
        assert_suggestion_result(
            "System outages effect our customers.",
            NounVerbConfusion::default(),
            "System outages affect our customers.",
        );
    }

    #[test]
    fn corrects_effects_variant() {
        assert_suggestion_result(
            "This policy effects employee morale.",
            NounVerbConfusion::default(),
            "This policy affects employee morale.",
        );
    }

    #[test]
    fn ignores_effect_change_idiom() {
        assert_lint_count(
            "Leaders work to effect change in their communities.",
            NounVerbConfusion::default(),
            0,
        );
    }

    #[test]
    fn ignores_effect_noun_phrase() {
        assert_lint_count(
            "The effect your plan had was dramatic.",
            NounVerbConfusion::default(),
            0,
        );
    }

    #[test]
    fn ignores_effect_as_result_noun() {
        assert_lint_count(
            "The effect was immediate and obvious.",
            NounVerbConfusion::default(),
            0,
        );
    }

    #[test]
    fn ignores_to_effect_substitutions() {
        assert_lint_count(
            "or it may be desired to effect substitutions",
            NounVerbConfusion::default(),
            0,
        );
    }

    #[test]
    fn ignores_effect_followed_by_of_phrase() {
        assert_lint_count(
            "We measured the effect of caffeine on sleep.",
            NounVerbConfusion::default(),
            0,
        );
    }

    #[test]
    fn ignores_side_effects_usage() {
        assert_lint_count(
            "Side effects may include mild nausea.",
            NounVerbConfusion::default(),
            0,
        );
    }

    #[test]
    fn ignores_special_effects_phrase() {
        assert_lint_count(
            "She admired the special effects in the film.",
            NounVerbConfusion::default(),
            0,
        );
    }

    #[test]
    fn ignores_effect_in_cause_and_effect() {
        assert_lint_count(
            "The diagram explains cause and effect relationships.",
            NounVerbConfusion::default(),
            0,
        );
    }

    #[test]
    fn ignores_effects_with_pronoun_subject() {
        assert_lint_count(
            "Those effects were less severe than expected.",
            NounVerbConfusion::default(),
            0,
        );
    }

    #[test]
    fn corrects_tariff_effect_import_prices() {
        assert_suggestion_result(
            "The new tariff will effect import prices next quarter.",
            NounVerbConfusion::default(),
            "The new tariff will affect import prices next quarter.",
        );
    }

    #[test]
    fn corrects_droughts_effect_crop_yields() {
        assert_suggestion_result(
            "Prolonged droughts severely effect crop yields across the valley.",
            NounVerbConfusion::default(),
            "Prolonged droughts severely affect crop yields across the valley.",
        );
    }

    #[test]
    fn corrects_caffeine_effect_sleep() {
        assert_suggestion_result(
            "Caffeine can effect your sleep architecture.",
            NounVerbConfusion::default(),
            "Caffeine can affect your sleep architecture.",
        );
    }

    #[test]
    fn corrects_bug_effect_devices() {
        assert_suggestion_result(
            "The firmware bug doesn't effect older devices.",
            NounVerbConfusion::default(),
            "The firmware bug doesn't affect older devices.",
        );
    }

    #[test]
    fn corrects_sarcasm_effect_morale() {
        assert_suggestion_result(
            "Her sarcasm seemed to effect the team's morale.",
            NounVerbConfusion::default(),
            "Her sarcasm seemed to affect the team's morale.",
        );
    }

    #[test]
    fn corrects_outage_effect_timeline() {
        assert_suggestion_result(
            "How will this outage effect our deployment timeline?",
            NounVerbConfusion::default(),
            "How will this outage affect our deployment timeline?",
        );
    }

    #[test]
    fn corrects_temperatures_effect_battery() {
        assert_suggestion_result(
            "Cold temperatures drastically effect lithium-ion battery performance.",
            NounVerbConfusion::default(),
            "Cold temperatures drastically affect lithium-ion battery performance.",
        );
    }

    #[test]
    fn corrects_policy_effect_eligibility() {
        assert_suggestion_result(
            "The policy change could effect your eligibility for benefits.",
            NounVerbConfusion::default(),
            "The policy change could affect your eligibility for benefits.",
        );
    }

    #[test]
    fn corrects_variables_effect_results() {
        assert_suggestion_result(
            "These confounding variables may effect the study's results.",
            NounVerbConfusion::default(),
            "These confounding variables may affect the study's results.",
        );
    }

    #[test]
    fn corrects_fans_effect_concentration() {
        assert_suggestion_result(
            "The noisy HVAC fans constantly effect concentration in the lab.",
            NounVerbConfusion::default(),
            "The noisy HVAC fans constantly affect concentration in the lab.",
        );
    }

    #[test]
    fn corrects_hormones_effect_immunity() {
        assert_suggestion_result(
            "Stress hormones can effect immune response during recovery.",
            NounVerbConfusion::default(),
            "Stress hormones can affect immune response during recovery.",
        );
    }

    #[test]
    fn corrects_pacing_effect_engagement() {
        assert_suggestion_result(
            "The instructor's pacing tended to effect student engagement.",
            NounVerbConfusion::default(),
            "The instructor's pacing tended to affect student engagement.",
        );
    }

    #[test]
    fn corrects_humidity_effect_paint() {
        assert_suggestion_result(
            "Humidity levels directly effect paint curing time.",
            NounVerbConfusion::default(),
            "Humidity levels directly affect paint curing time.",
        );
    }

    #[test]
    fn corrects_exchange_effect_invoice() {
        assert_suggestion_result(
            "The exchange rate will surely effect the final invoice.",
            NounVerbConfusion::default(),
            "The exchange rate will surely affect the final invoice.",
        );
    }

    #[test]
    fn corrects_brightness_effect_contrast() {
        assert_suggestion_result(
            "Screen brightness settings can effect perceived contrast.",
            NounVerbConfusion::default(),
            "Screen brightness settings can affect perceived contrast.",
        );
    }

    #[test]
    fn corrects_medication_effect_him() {
        assert_suggestion_result(
            "The medication didn't effect him the way the doctor expected.",
            NounVerbConfusion::default(),
            "The medication didn't affect him the way the doctor expected.",
        );
    }

    #[test]
    fn corrects_payments_effect_credit() {
        assert_suggestion_result(
            "Late payments will negatively effect your credit score.",
            NounVerbConfusion::default(),
            "Late payments will negatively affect your credit score.",
        );
    }

    #[test]
    fn corrects_wording_effect_interpretation() {
        assert_suggestion_result(
            "Minor wording tweaks shouldn't effect the legal interpretation.",
            NounVerbConfusion::default(),
            "Minor wording tweaks shouldn't affect the legal interpretation.",
        );
    }

    #[test]
    fn corrects_traffic_effect_delivery() {
        assert_suggestion_result(
            "Traffic patterns often effect delivery windows downtown.",
            NounVerbConfusion::default(),
            "Traffic patterns often affect delivery windows downtown.",
        );
    }

    #[test]
    fn corrects_rumor_effect_confidence() {
        assert_suggestion_result(
            "The rumor started to effect investor confidence by noon.",
            NounVerbConfusion::default(),
            "The rumor started to affect investor confidence by noon.",
        );
    }

    #[test]
    fn corrects_allergies_effect_productivity() {
        assert_suggestion_result(
            "Seasonal allergies badly effect her productivity each April.",
            NounVerbConfusion::default(),
            "Seasonal allergies badly affect her productivity each April.",
        );
    }

    #[test]
    fn corrects_feedback_effect_roadmap() {
        assert_suggestion_result(
            "Your feedback won't immediately effect the roadmap.",
            NounVerbConfusion::default(),
            "Your feedback won't immediately affect the roadmap.",
        );
    }

    #[test]
    fn corrects_rules_effect_honeypot() {
        assert_suggestion_result(
            "I cant seem to get my additional rules to effect the honeypot",
            NounVerbConfusion::default(),
            "I cant seem to get my additional rules to affect the honeypot",
        );
    }

    #[test]
    fn corrects_bandwidth_effect_video() {
        assert_suggestion_result(
            "Fluctuating bandwidth can effect video call quality.",
            NounVerbConfusion::default(),
            "Fluctuating bandwidth can affect video call quality.",
        );
    }

    #[test]
    fn corrects_gradient_effect_sensor() {
        assert_suggestion_result(
            "The temperature gradient might effect the sensor's calibration.",
            NounVerbConfusion::default(),
            "The temperature gradient might affect the sensor's calibration.",
        );
    }

    #[test]
    fn corrects_delays_effect_satisfaction() {
        assert_suggestion_result(
            "Even tiny delays can effect user satisfaction metrics.",
            NounVerbConfusion::default(),
            "Even tiny delays can affect user satisfaction metrics.",
        );
    }

    #[test]
    fn corrects_architecture_effect_gps() {
        assert_suggestion_result(
            "The surrounding architecture can effect GPS accuracy.",
            NounVerbConfusion::default(),
            "The surrounding architecture can affect GPS accuracy.",
        );
    }

    #[test]
    fn corrects_lighting_effect_color() {
        assert_suggestion_result(
            "Lighting conditions strongly effect color perception.",
            NounVerbConfusion::default(),
            "Lighting conditions strongly affect color perception.",
        );
    }

    #[test]
    fn corrects_coach_effect_roles() {
        assert_suggestion_result(
            "The new coach's strategy will effect players' roles.",
            NounVerbConfusion::default(),
            "The new coach's strategy will affect players' roles.",
        );
    }

    #[test]
    fn corrects_overtraining_effect_reaction() {
        assert_suggestion_result(
            "Overtraining can effect reaction time and coordination.",
            NounVerbConfusion::default(),
            "Overtraining can affect reaction time and coordination.",
        );
    }

    #[test]
    fn corrects_label_effect_behavior() {
        assert_suggestion_result(
            "The warning label may effect how consumers use the product.",
            NounVerbConfusion::default(),
            "The warning label may affect how consumers use the product.",
        );
    }

    // `affect` mistakenly used as the noun `effect`.
    #[test]
    fn corrects_because_affect_is() {
        assert_suggestion_result(
            "I worry because affect is hidden.",
            NounVerbConfusion::default(),
            "I worry because effect is hidden.",
        );
    }

    #[test]
    fn ignores_psychology_usage() {
        assert_lint_count(
            "The patient's affect is flat.",
            NounVerbConfusion::default(),
            0,
        );
    }

    #[test]
    fn corrects_positive_affect_on() {
        assert_suggestion_result(
            "The new law had a positive affect on small businesses.",
            NounVerbConfusion::default(),
            "The new law had a positive effect on small businesses.",
        );
    }

    #[test]
    fn corrects_great_affect() {
        assert_suggestion_result(
            "badges that they provide to users to allow them to promote their projects to great affect",
            NounVerbConfusion::default(),
            "badges that they provide to users to allow them to promote their projects to great effect",
        );
    }

    #[test]
    fn corrects_affect_of() {
        assert_suggestion_result(
            "We measured the affect of caffeine on reaction time.",
            NounVerbConfusion::default(),
            "We measured the effect of caffeine on reaction time.",
        );
    }

    #[test]
    fn corrects_side_affects() {
        assert_suggestion_result(
            "The side affects included nausea and fatigue.",
            NounVerbConfusion::default(),
            "The side effects included nausea and fatigue.",
        );
    }

    #[test]
    fn corrects_cause_and_affect() {
        assert_suggestion_result(
            "Cause and affect are not the same thing.",
            NounVerbConfusion::default(),
            "Cause and effect are not the same thing.",
        );
    }

    #[test]
    fn corrects_have_an_affect_on() {
        assert_suggestion_result(
            "The change will have an affect on our revenue.",
            NounVerbConfusion::default(),
            "The change will have an effect on our revenue.",
        );
    }

    #[test]
    fn corrects_took_affect() {
        assert_suggestion_result(
            "The medicine took affect within minutes.",
            NounVerbConfusion::default(),
            "The medicine took effect within minutes.",
        );
    }

    #[test]
    fn corrects_come_into_affect() {
        assert_suggestion_result(
            "The policy will come into affect on October 1.",
            NounVerbConfusion::default(),
            "The policy will come into effect on October 1.",
        );
    }

    #[test]
    fn corrects_in_affect_sentence() {
        assert_suggestion_result(
            "The rules are now in affect.",
            NounVerbConfusion::default(),
            "The rules are now in effect.",
        );
    }

    #[test]
    fn corrects_with_immediate_affect() {
        assert_suggestion_result(
            "With immediate affect, the office is closed.",
            NounVerbConfusion::default(),
            "With immediate effect, the office is closed.",
        );
    }

    #[test]
    fn corrects_special_affects() {
        assert_suggestion_result(
            "The director used stunning special affects.",
            NounVerbConfusion::default(),
            "The director used stunning special effects.",
        );
    }

    #[test]
    fn corrects_placebo_affect() {
        assert_suggestion_result(
            "The placebo affect can be powerful.",
            NounVerbConfusion::default(),
            "The placebo effect can be powerful.",
        );
    }

    #[test]
    fn corrects_ripple_affect() {
        assert_suggestion_result(
            "We felt the ripple affect across the entire market.",
            NounVerbConfusion::default(),
            "We felt the ripple effect across the entire market.",
        );
    }

    #[test]
    fn corrects_snowball_affect() {
        assert_suggestion_result(
            "The snowball affect amplified the problem.",
            NounVerbConfusion::default(),
            "The snowball effect amplified the problem.",
        );
    }

    #[test]
    fn corrects_knock_on_affect() {
        assert_suggestion_result(
            "That decision had a knock-on affect throughout the team.",
            NounVerbConfusion::default(),
            "That decision had a knock-on effect throughout the team.",
        );
    }

    #[test]
    fn corrects_greenhouse_affect() {
        assert_suggestion_result(
            "The greenhouse affect warms the planet.",
            NounVerbConfusion::default(),
            "The greenhouse effect warms the planet.",
        );
    }

    #[test]
    fn corrects_little_affect() {
        assert_suggestion_result(
            "Her apology had little affect.",
            NounVerbConfusion::default(),
            "Her apology had little effect.",
        );
    }

    #[test]
    fn corrects_go_into_affect() {
        assert_suggestion_result(
            "The new settings go into affect after a restart.",
            NounVerbConfusion::default(),
            "The new settings go into effect after a restart.",
        );
    }

    #[test]
    fn corrects_put_plan_into_affect() {
        assert_suggestion_result(
            "They put the new plan into affect last week.",
            NounVerbConfusion::default(),
            "They put the new plan into effect last week.",
        );
    }

    #[test]
    fn corrects_contract_into_affect() {
        assert_suggestion_result(
            "The contract comes into affect at midnight.",
            NounVerbConfusion::default(),
            "The contract comes into effect at midnight.",
        );
    }

    #[test]
    fn corrects_no_affect_on_behavior() {
        assert_suggestion_result(
            "The warning had no affect on his behavior.",
            NounVerbConfusion::default(),
            "The warning had no effect on his behavior.",
        );
    }

    #[test]
    fn corrects_opposite_affect() {
        assert_suggestion_result(
            "Inflation had the opposite affect than expected.",
            NounVerbConfusion::default(),
            "Inflation had the opposite effect than expected.",
        );
    }

    #[test]
    fn corrects_remains_in_affect() {
        assert_suggestion_result(
            "The regulation remains in affect until further notice.",
            NounVerbConfusion::default(),
            "The regulation remains in effect until further notice.",
        );
    }

    #[test]
    fn corrects_take_affect_next_week() {
        assert_suggestion_result(
            "The app changes take affect next week.",
            NounVerbConfusion::default(),
            "The app changes take effect next week.",
        );
    }

    #[test]
    fn corrects_sound_affects() {
        assert_suggestion_result(
            "Sound affects were added in post.",
            NounVerbConfusion::default(),
            "Sound effects were added in post.",
        );
    }

    #[test]
    fn does_not_flag_best_affect() {
        assert_lint_count(
            "Using linear regression to predict and understand what factors best affect house price",
            NounVerbConfusion::default(),
            0,
        );
    }

    #[test]
    fn does_not_flag_sound_affect() {
        assert_lint_count(
            "The goal of this study was to learn what properties of sound affect human focus the most.",
            NounVerbConfusion::default(),
            0,
        );
    }

    #[test]
    fn corrects_sound_affect() {
        assert_suggestion_result(
            "Diesel Generator's animation returns to 'idle' state, but it's sound affect remains in the 'work' state.",
            NounVerbConfusion::default(),
            "Diesel Generator's animation returns to 'idle' state, but it's sound effect remains in the 'work' state.",
        );
    }

    #[test]
    fn does_not_flag_affect_as_verb() {
        assert_lint_count(
            "The change will affect our revenue significantly.",
            NounVerbConfusion::default(),
            0,
        );
    }

    #[test]
    fn does_not_flag_affects_as_verb() {
        assert_lint_count(
            "This policy directly affects remote workers.",
            NounVerbConfusion::default(),
            0,
        );
    }

    #[test]
    fn does_not_flag_correct_effect_noun() {
        assert_lint_count(
            "The placebo effect can be powerful.",
            NounVerbConfusion::default(),
            0,
        );
    }

    #[test]
    fn does_not_flag_sound_effects() {
        assert_lint_count(
            "Sound effects were added in post.",
            NounVerbConfusion::default(),
            0,
        );
    }

    #[test]
    fn issue_1997() {
        assert_no_lints(
            "It depends on which sources it affects, what parameters it uses, etc.",
            NounVerbConfusion::default(),
        );
    }

    #[test]
    fn issue_1996() {
        assert_no_lints(
            "Avoid effects outside of functions.",
            NounVerbConfusion::default(),
        );
    }

    #[test]
    fn issue_2008() {
        assert_no_lints(
            "Changes that only affect static types, without breaking runtime behavior.",
            NounVerbConfusion::default(),
        );
    }

    #[test]
    fn issue_2041() {
        assert_suggestion_result(
            "Let me give you a piece of advise.",
            NounVerbConfusion::default(),
            "Let me give you a piece of advice.",
        );
    }

    #[test]
    fn fix_helps_you_weight() {
        assert_suggestion_result(
            "An iOS app that helps you weight small things on the screen of your iPhone / iPad.",
            NounVerbConfusion::default(),
            "An iOS app that helps you weigh small things on the screen of your iPhone / iPad.",
        );
    }

    #[test]
    fn fix_do_you_weight() {
        assert_suggestion_result(
            "How much do you weight?",
            NounVerbConfusion::default(),
            "How much do you weigh?",
        );
    }

    #[test]
    fn fix_more_than_you_weight() {
        assert_suggestion_result(
            "contributed more than you weight",
            NounVerbConfusion::default(),
            "contributed more than you weigh",
        );
    }
}



================================================
FILE: harper-core/src/linting/noun_verb_confusion/verb_instead_of_noun.rs
================================================
use crate::linting::expr_linter::Chunk;
use crate::{
    Lrc, Token,
    expr::{Expr, SequenceExpr},
    linting::{ExprLinter, Lint, LintKind, Suggestion},
    patterns::{UPOSSet, WordSet},
};
use harper_brill::UPOS;

use super::NOUN_VERB_PAIRS;

pub struct VerbInsteadOfNoun {
    expr: Box<dyn Expr>,
}

impl Default for VerbInsteadOfNoun {
    fn default() -> Self {
        let verbs = Lrc::new(WordSet::new(
            &NOUN_VERB_PAIRS
                .iter()
                .map(|&(_, verb)| verb)
                .collect::<Vec<_>>(),
        ));
        Self {
            expr: Box::new(
                SequenceExpr::default()
                    .then(UPOSSet::new(&[UPOS::ADJ, UPOS::ADP]))
                    .then_whitespace()
                    .then(verbs.clone()),
            ),
        }
    }
}

impl ExprLinter for VerbInsteadOfNoun {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, toks: &[Token], src: &[char]) -> Option<Lint> {
        let adj_tok = &toks.first()?;
        let verb_tok = &toks.last()?;

        let adj_text = adj_tok.span.get_content_string(src);
        let verb_text = verb_tok.span.get_content_string(src);
        let verb_lower = verb_text.to_lowercase();

        if adj_tok.kind.is_auxiliary_verb() || adj_tok.kind.is_upos(UPOS::AUX) {
            return None;
        }

        let noun = NOUN_VERB_PAIRS
            .iter()
            .find(|(_, verb)| *verb == verb_lower)
            .map(|(noun, _)| noun)?;

        // Don't flag "so I better advise you", "you'd better believe this", "you'd best listen to me".
        if adj_text == "better" || adj_text == "best" {
            return None;
        }

        // "Sound" is both adjective and noun. We want to flag the common "sound advise"
        // But not "sound affect", which is just as correct as "sound effect".
        if adj_text == "sound" && verb_text == "affect" {
            return None;
        }

        Some(Lint {
            span: verb_tok.span,
            lint_kind: LintKind::WordChoice,
            suggestions: vec![Suggestion::replace_with_match_case(
                noun.chars().collect(),
                verb_tok.span.get_content(src),
            )],
            message: format!("`{verb_text}` is a verb, the noun should be `{noun}`."),
            priority: 63,
        })
    }

    fn description(&self) -> &'static str {
        "Corrects verbs used instead of nouns when the two are related."
    }
}



================================================
FILE: harper-core/src/linting/noun_verb_confusion/effect_affect/affect_to_effect.rs
================================================
use std::sync::Arc;

use harper_brill::UPOS;

use crate::linting::expr_linter::Chunk;
use crate::{
    CharStringExt, Token, TokenKind,
    expr::{Expr, ExprMap, SequenceExpr},
    linting::{ExprLinter, Lint, LintKind, Suggestion},
    patterns::{ModalVerb, Pattern, UPOSSet},
};

pub(super) struct AffectToEffect {
    expr: Box<dyn Expr>,
    map: Arc<ExprMap<usize>>,
}

impl Default for AffectToEffect {
    fn default() -> Self {
        let mut map = ExprMap::default();

        let adj_then_noun_follow = SequenceExpr::default()
            .then(|tok: &Token, source: &[char]| matches_preceding_context_adj_noun(tok, source))
            .t_ws()
            .then(|tok: &Token, source: &[char]| is_affect_word(tok, source))
            .t_ws()
            .then(UPOSSet::new(&[UPOS::ADJ]))
            .t_ws()
            .then(UPOSSet::new(&[UPOS::NOUN]));

        map.insert(adj_then_noun_follow, 2);

        let word_follow = SequenceExpr::default()
            .then(|tok: &Token, source: &[char]| matches_preceding_context(tok, source))
            .t_ws()
            .then(|tok: &Token, source: &[char]| is_affect_word(tok, source))
            .t_ws()
            .then(UPOSSet::new(&[
                UPOS::PROPN,
                UPOS::INTJ,
                UPOS::ADP,
                UPOS::SCONJ,
            ]));

        map.insert(word_follow, 2);

        let verb_follow = SequenceExpr::default()
            .then(|tok: &Token, source: &[char]| matches_preceding_context_verb_follow(tok, source))
            .t_ws()
            .then(|tok: &Token, source: &[char]| is_affect_word(tok, source))
            .t_ws()
            .then(UPOSSet::new(&[UPOS::AUX, UPOS::VERB]));

        map.insert(verb_follow, 2);

        let punctuation_follow = SequenceExpr::default()
            .then(|tok: &Token, source: &[char]| matches_preceding_context(tok, source))
            .t_ws()
            .then(|tok: &Token, source: &[char]| is_affect_word(tok, source))
            .then_kind_where(|kind| kind.is_punctuation());

        map.insert(punctuation_follow, 2);

        let great_affect = SequenceExpr::default()
            .t_aco("great")
            .t_ws()
            .then(|tok: &Token, source: &[char]| is_affect_word(tok, source));

        map.insert(great_affect, 2);

        let map = Arc::new(map);

        Self {
            expr: Box::new(map.clone()),
            map,
        }
    }
}

impl ExprLinter for AffectToEffect {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], source: &[char]) -> Option<Lint> {
        let offending_index = *self.map.lookup(0, matched_tokens, source)?;
        let target = &matched_tokens[offending_index];

        let preceding = matched_tokens[..offending_index]
            .iter()
            .rfind(|tok| !tok.kind.is_whitespace());

        if preceding.is_some_and(|tok| {
            (tok.kind.is_pronoun() || tok.kind.is_upos(UPOS::PRON))
                && !tok.kind.is_possessive_pronoun()
        }) {
            // Pronouns like "it" or "they" almost always introduce the verb form ("it affects").
            return None;
        }

        let token_text = target.span.get_content_string(source);
        let lower = token_text.to_lowercase();
        let replacement = match lower.as_str() {
            "affect" => "effect",
            "affects" => "effects",
            _ => return None,
        };

        Some(Lint {
            span: target.span,
            lint_kind: LintKind::WordChoice,
            suggestions: vec![Suggestion::replace_with_match_case_str(
                replacement,
                target.span.get_content(source),
            )],
            message: "`affect` is usually a verb; use `effect` here for the result or outcome."
                .into(),
            priority: 63,
        })
    }

    fn description(&self) -> &'static str {
        "Corrects `affect` to `effect` when the context shows the noun meaning `result`."
    }
}

fn is_affect_word(token: &Token, source: &[char]) -> bool {
    const AFFECT: &[char] = &['a', 'f', 'f', 'e', 'c', 't'];
    const AFFECTS: &[char] = &['a', 'f', 'f', 'e', 'c', 't', 's'];

    if !matches!(token.kind, TokenKind::Word(_)) {
        return false;
    }

    let text = token.span.get_content(source);
    text.eq_ignore_ascii_case_chars(AFFECT) || text.eq_ignore_ascii_case_chars(AFFECTS)
}

fn is_take_form(chars: &[char]) -> bool {
    chars.eq_ignore_ascii_case_str("take")
        || chars.eq_ignore_ascii_case_str("takes")
        || chars.eq_ignore_ascii_case_str("taking")
        || chars.eq_ignore_ascii_case_str("took")
        || chars.eq_ignore_ascii_case_str("taken")
}

fn is_modal_like(token: &Token, source: &[char], prev: &[char]) -> bool {
    if ModalVerb::default()
        .matches(std::slice::from_ref(token), source)
        .is_some()
    {
        return true;
    }

    prev.eq_ignore_ascii_case_str("do")
        || prev.eq_ignore_ascii_case_str("does")
        || prev.eq_ignore_ascii_case_str("did")
        || prev.eq_ignore_ascii_case_str("don't")
        || prev.eq_ignore_ascii_case_str("dont")
        || prev.eq_ignore_ascii_case_str("doesn't")
        || prev.eq_ignore_ascii_case_str("doesnt")
        || prev.eq_ignore_ascii_case_str("didn't")
        || prev.eq_ignore_ascii_case_str("didnt")
}

fn matches_preceding_context(token: &Token, source: &[char]) -> bool {
    matches_preceding_context_impl(token, source, true, true)
}

fn matches_preceding_context_adj_noun(token: &Token, source: &[char]) -> bool {
    matches_preceding_context_impl(token, source, false, true)
}

fn matches_preceding_context_verb_follow(token: &Token, source: &[char]) -> bool {
    matches_preceding_context_impl(token, source, true, false)
}

fn matches_preceding_context_impl(
    token: &Token,
    source: &[char],
    allow_noun_like: bool,
    allow_verb_like: bool,
) -> bool {
    if token.kind.is_possessive_nominal() {
        return false;
    }

    if !is_preceding_context(token) {
        return false;
    }

    let content = token.span.get_content(source);
    let is_take_form_word = is_take_form(content);

    if behaves_like_verb(token, source, content) && !is_take_form_word {
        return false;
    }

    if !allow_verb_like && token.kind.is_upos(UPOS::VERB) && !is_take_form_word {
        return false;
    }

    if !allow_noun_like
        && (token.kind.is_noun() || token.kind.is_proper_noun())
        && !is_take_form_word
    {
        return false;
    }

    true
}

fn behaves_like_verb(token: &Token, source: &[char], prev: &[char]) -> bool {
    token.kind.is_upos(UPOS::AUX)
        || token.kind.is_auxiliary_verb()
        || is_modal_like(token, source, prev)
}

fn is_preceding_context(token: &Token) -> bool {
    if token.kind.is_upos(UPOS::ADV) {
        return false;
    }

    matches!(token.kind, TokenKind::Punctuation(_))
        || token.kind.is_preposition()
        || token.kind.is_conjunction()
        || token.kind.is_proper_noun()
        || token.kind.is_verb()
        || token.kind.is_adjective()
        || token.kind.is_determiner()
        || token.kind.is_noun()
}



================================================
FILE: harper-core/src/linting/noun_verb_confusion/effect_affect/effect_to_affect.rs
================================================
use std::sync::Arc;

use harper_brill::UPOS;

use crate::linting::expr_linter::Chunk;
use crate::{
    CharStringExt, Token, TokenKind,
    expr::{Expr, ExprMap, SequenceExpr},
    linting::{ExprLinter, Lint, LintKind, Suggestion},
    patterns::WhitespacePattern,
};

pub(super) struct EffectToAffect {
    expr: Box<dyn Expr>,
    map: Arc<ExprMap<usize>>,
}

impl Default for EffectToAffect {
    fn default() -> Self {
        let mut map = ExprMap::default();

        let context = SequenceExpr::default()
            .then(matches_preceding_context)
            .t_ws()
            .then(|tok: &Token, source: &[char]| is_effect_word(tok, source))
            .t_ws()
            .then(matches_following_context)
            .then_optional(WhitespacePattern)
            .then_optional(matches_optional_following)
            .then_optional(WhitespacePattern);

        map.insert(context, 2);

        let map = Arc::new(map);

        Self {
            expr: Box::new(map.clone()),
            map,
        }
    }
}

impl ExprLinter for EffectToAffect {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], source: &[char]) -> Option<Lint> {
        let offending_idx = *self.map.lookup(0, matched_tokens, source)?;
        let target = &matched_tokens[offending_idx];

        let preceding = matched_tokens[..offending_idx]
            .iter()
            .rfind(|tok| !tok.kind.is_whitespace());

        let mut following = matched_tokens[offending_idx + 1..]
            .iter()
            .filter(|tok| !tok.kind.is_whitespace());

        let first_following = following.next()?;
        let second_following = following.next();

        if let Some(prev) = preceding {
            let lower_prev = prev.span.get_content_string(source).to_lowercase();

            if matches!(
                lower_prev.as_str(),
                "take" | "takes" | "taking" | "took" | "taken"
            ) {
                return None;
            }
        }

        if first_following.kind.is_upos(UPOS::AUX) || first_following.kind.is_linking_verb() {
            return None;
        }

        let first_following_lower = first_following
            .span
            .get_content_string(source)
            .to_lowercase();

        if matches!(
            first_following_lower.as_str(),
            "is" | "are" | "was" | "were" | "be" | "been" | "being"
        ) {
            return None;
        }

        // Avoid "to effect change", which uses the legitimate verb "effect".
        if let Some(prev) = preceding
            && is_token_to(prev, source)
            && is_change_like(first_following, source)
        {
            return None;
        }

        if first_following.kind.is_upos(UPOS::VERB)
            && preceding.is_some_and(|tok| {
                tok.kind.is_upos(UPOS::NOUN)
                    || tok.kind.is_upos(UPOS::DET)
                    || tok.kind.is_upos(UPOS::ADJ)
                    || (tok.kind.is_noun()
                        && !tok.kind.is_upos(UPOS::VERB)
                        && !tok.kind.is_upos(UPOS::AUX))
            })
        {
            return None;
        }

        // Skip when the context already shows a clear noun usage (e.g., "the effect your idea had").
        if let Some(prev) = preceding
            && (prev.kind.is_upos(UPOS::DET) || prev.kind.is_upos(UPOS::ADJ))
        {
            return None;
        }

        // Do not flag when the following noun is clearly the result of "effect" in the idiomatic sense.
        if let Some(next) = second_following
            && next.kind.is_noun()
            && is_change_like(next, source)
        {
            return None;
        }

        let token_text = target.span.get_content_string(source);
        let lower = token_text.to_lowercase();

        if lower.as_str() == "effects" && preceding.is_some_and(|tok| tok.kind.is_upos(UPOS::VERB))
        {
            // Imperative phrases like "Avoid effects" legitimately use the noun.
            return None;
        }

        let replacement = match lower.as_str() {
            "effect" => "affect",
            "effects" => "affects",
            _ => return None,
        };

        Some(Lint {
            span: target.span,
            lint_kind: LintKind::WordChoice,
            suggestions: vec![Suggestion::replace_with_match_case_str(
                replacement,
                target.span.get_content(source),
            )],
            message:
                "Use `affect` for the verb meaning to influence; `effect` usually names the result."
                    .into(),
            priority: 63,
        })
    }

    fn description(&self) -> &'static str {
        "Corrects `effect` to `affect` when the context shows the verb meaning `influence`."
    }
}

fn is_effect_word(token: &Token, source: &[char]) -> bool {
    if !matches!(token.kind, TokenKind::Word(_)) {
        return false;
    }

    const EFFECT: &[char] = &['e', 'f', 'f', 'e', 'c', 't'];
    const EFFECTS: &[char] = &['e', 'f', 'f', 'e', 'c', 't', 's'];

    let text = token.span.get_content(source);
    text.eq_ignore_ascii_case_chars(EFFECT) || text.eq_ignore_ascii_case_chars(EFFECTS)
}

fn is_token_to(token: &Token, source: &[char]) -> bool {
    token
        .span
        .get_content(source)
        .eq_ignore_ascii_case_chars(&['t', 'o'])
}

fn is_change_like(token: &Token, source: &[char]) -> bool {
    if !token.kind.is_word() {
        return false;
    }

    matches!(
        token
            .span
            .get_content_string(source)
            .to_lowercase()
            .as_str(),
        "change" | "changes" | "substitution" | "substitutions"
    )
}

fn matches_preceding_context(token: &Token, _source: &[char]) -> bool {
    tag_matches_any(
        token,
        &[
            UPOS::PART,
            UPOS::NOUN,
            UPOS::PRON,
            UPOS::PROPN,
            UPOS::ADV,
            UPOS::AUX,
            UPOS::VERB,
            UPOS::ADJ,
        ],
    )
}

fn matches_following_context(token: &Token, _source: &[char]) -> bool {
    tag_matches_any(
        token,
        &[
            UPOS::ADV,
            UPOS::AUX,
            UPOS::PRON,
            UPOS::PROPN,
            UPOS::VERB,
            UPOS::NUM,
            UPOS::NOUN,
            UPOS::INTJ,
            UPOS::SCONJ,
            UPOS::DET,
            UPOS::ADJ,
        ],
    )
}

fn matches_optional_following(token: &Token, _source: &[char]) -> bool {
    if token.kind.is_punctuation() {
        return true;
    }

    tag_matches_any(token, &[UPOS::NOUN])
}

fn tag_matches_any(token: &Token, allowed: &[UPOS]) -> bool {
    let Some(word_meta_opt) = token.kind.as_word() else {
        return false;
    };

    match word_meta_opt {
        Some(meta) => meta.pos_tag.is_none_or(|tag| allowed.contains(&tag)),
        None => true,
    }
}



================================================
FILE: harper-core/src/linting/noun_verb_confusion/effect_affect/mod.rs
================================================
mod affect_to_effect;
mod effect_to_affect;

use affect_to_effect::AffectToEffect;
use effect_to_affect::EffectToAffect;

use crate::linting::merge_linters::merge_linters;

merge_linters!(
    EffectAffect =>
        EffectToAffect,
        AffectToEffect
    => "Guides writers toward the right choice between `effect` and `affect`, correcting each term when it shows up in the other one's role."
);



================================================
FILE: harper-core/src/linting/noun_verb_confusion/noun_instead_of_verb/general.rs
================================================
use crate::{
    CharStringExt, Lrc, Token,
    expr::{Expr, FirstMatchOf, LongestMatchOf, SequenceExpr},
    linting::{ExprLinter, Lint, LintKind, Suggestion, expr_linter::Chunk},
    patterns::{ModalVerb, Word, WordSet},
};

use super::super::NOUN_VERB_PAIRS;

/// Pronouns that can come before verbs but not nouns
const PRONOUNS: &[&str] = &["he", "I", "it", "she", "they", "we", "who", "you"];

/// Linter that corrects common noun/verb confusions
pub(super) struct GeneralNounInsteadOfVerb {
    expr: Box<dyn Expr>,
}

impl Default for GeneralNounInsteadOfVerb {
    fn default() -> Self {
        // Adverbs that can come before verbs but not nouns
        // Note: "Sometimes" can come before a noun.
        let adverb_of_frequency = |tok: &Token, src: &[char]| {
            tok.kind.is_frequency_adverb()
                && !tok
                    .span
                    .get_content(src)
                    .eq_ignore_ascii_case_str("sometimes")
        };

        let pre_context = FirstMatchOf::new(vec![
            Box::new(WordSet::new(PRONOUNS)),
            Box::new(ModalVerb::with_common_errors()),
            Box::new(WordSet::new(&["do", "don't", "dont"])),
            Box::new(adverb_of_frequency),
            Box::new(Word::new("to")),
        ]);

        let nouns = Lrc::new(WordSet::new(
            &NOUN_VERB_PAIRS
                .iter()
                .map(|&(noun, _)| noun)
                .collect::<Vec<_>>(),
        ));

        let basic_pattern = Lrc::new(
            SequenceExpr::default()
                .then(pre_context)
                .then_whitespace()
                .then(nouns.clone()),
        );

        let pattern_followed_by_punctuation = SequenceExpr::default()
            .then(basic_pattern.clone())
            .then_punctuation();

        let pattern_followed_by_word = SequenceExpr::default()
            .then(basic_pattern.clone())
            .then_whitespace()
            .then_any_word();

        Self {
            expr: Box::new(LongestMatchOf::new(vec![
                Box::new(pattern_followed_by_punctuation),
                Box::new(pattern_followed_by_word),
                Box::new(basic_pattern),
            ])),
        }
    }
}

impl ExprLinter for GeneralNounInsteadOfVerb {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, toks: &[Token], src: &[char]) -> Option<Lint> {
        let prev_tok = &toks[0];

        // If we have the next word token, try to rule out compound nouns
        if toks.len() > 4 {
            let following_tok = &toks[4];
            if following_tok.kind.is_noun()
                && !following_tok.kind.is_proper_noun()
                && !following_tok.kind.is_preposition()
            {
                // But first rule out marginal "nouns"
                if !following_tok
                    .span
                    .get_content(src)
                    .eq_any_ignore_ascii_case_str(&["it", "me", "on", "that"])
                {
                    return None;
                }
            }

            // If the previous word is "to", use the following word to disambiguate
            if prev_tok
                .span
                .get_content(src)
                .eq_ignore_ascii_case_chars(&['t', 'o'])
                && !following_tok.kind.is_determiner()
            {
                return None;
            }
        }

        // If we don't have the next word token, don't continue if the previous token is "to"
        // since "to" is a preposition and an infinitive marker and there's not enough context to disambiguate.
        if toks.len() <= 4
            && prev_tok
                .span
                .get_content(src)
                .eq_ignore_ascii_case_chars(&['t', 'o'])
        {
            return None;
        }

        let noun_tok = &toks[2];
        let noun_chars = noun_tok.span.get_content(src);
        let noun_text = noun_tok.span.get_content_string(src);
        let noun_lower = noun_text.to_lowercase();

        let verb = NOUN_VERB_PAIRS
            .iter()
            .find(|(noun, _)| *noun == noun_lower)
            .map(|(_, verb)| verb)?;

        Some(Lint {
            span: noun_tok.span,
            lint_kind: LintKind::WordChoice,
            suggestions: vec![Suggestion::replace_with_match_case(
                verb.chars().collect(),
                noun_chars,
            )],
            message: format!("`{noun_text}` is a noun, the verb should be `{verb}`."),
            priority: 63,
        })
    }

    fn description(&self) -> &'static str {
        "Corrects nouns used instead of verbs when the two are related."
    }
}



================================================
FILE: harper-core/src/linting/noun_verb_confusion/noun_instead_of_verb/mod.rs
================================================
mod general;

use super::effect_affect::EffectAffect;
use crate::linting::merge_linters::merge_linters;
use general::GeneralNounInsteadOfVerb;

merge_linters! {
    NounInsteadOfVerb =>
        GeneralNounInsteadOfVerb,
        EffectAffect
    => "Corrects noun/verb confusions such as `advice/advise` and handles the common `effect/affect` mix-up."
}



================================================
FILE: harper-core/src/linting/phrase_set_corrections/mod.rs
================================================
use crate::linting::LintKind;

use super::{LintGroup, MapPhraseSetLinter};

#[cfg(test)]
mod tests;

/// Produce a [`LintGroup`] that looks for errors in sets of common phrases.
pub fn lint_group() -> LintGroup {
    let mut group = LintGroup::default();

    // Each correction pair has a single bad form and a single correct form.
    macro_rules! add_1_to_1_mappings {
        ($group:expr, {
            $($name:expr => ($input_correction_pairs:expr, $message:expr, $description:expr $(, $lint_kind:expr)?)),+ $(,)?
        }) => {
            $(
                $group.add_chunk_expr_linter(
                    $name,
                    Box::new(
                        MapPhraseSetLinter::one_to_one(
                            $input_correction_pairs,
                            $message,
                            $description,
                            None$(.or(Some($lint_kind)))?,
                        ),
                    ),
                );
            )+
        };
    }

    // Each correction pair has multiple bad forms and multiple correct forms.
    macro_rules! add_many_to_many_mappings {
        ($group:expr, {
            $($name:expr => ($input_correction_multi_pairs:expr, $message:expr, $description:expr $(, $lint_kind:expr)?)),+ $(,)?
        }) => {
            $(
                $group.add_chunk_expr_linter(
                    $name,
                    Box::new(
                        MapPhraseSetLinter::many_to_many(
                            $input_correction_multi_pairs,
                            $message,
                            $description,
                            None$(.or(Some($lint_kind)))?,
                        ),
                    ),
                );
            )+
        };
    }

    add_1_to_1_mappings!(group, {
        "Ado" => (
            &[
                ("further adieu", "further ado"),
                ("much adieu", "much ado"),
            ],
            "Don't confuse the French/German `adieu`, meaning `farewell`, with the English `ado`, meaning `fuss`.",
            "Corrects `adieu` to `ado`.",
            LintKind::Eggcorn
        ),
        "ChampAtTheBit" => (
            &[
                ("chomp at the bit", "champ at the bit"),
                ("chomped at the bit", "champed at the bit"),
                ("chomping at the bit", "champing at the bit"),
                ("chomps at the bit", "champs at the bit"),
            ],
            "The correct idiom is `champ at the bit`.",
            "Corrects `chomp at the bit` to the idiom `champ at the bit`, which has an equestrian origin referring to the way an anxious horse grinds its teeth against the metal part of the bridle.",
            LintKind::Eggcorn
        ),
        "ClientOrServerSide" => (
            &[
                ("client's side", "client-side"),
                ("server's side", "server-side"),
            ],
            "`Client-side` and `server-side` do not use an apostrophe.",
            "Corrects extraneous apostrophe in `client's side` and `server's side`.",
            LintKind::Punctuation
        ),
        "ConfirmThat" => (
            &[
                ("conform that", "confirm that"),
                ("conformed that", "confirmed that"),
                ("conforms that", "confirms that"),
                // Note: false positives in this inflection:
                // "is there any example of a case that isn't fully conforming that is supported today?"
                ("conforming that", "confirming that"),
            ],
            "Did you mean `confirm` rather than `conform`?",
            "Corrects `conform` typos to `confirm`.",
            LintKind::Typo
        ),
        "DefiniteArticle" => (
            &[
                ("definitive article", "definite article"),
                ("definitive articles", "definite articles")
            ],
            "The correct term for `the` is `definite article`.",
            "The name of the word `the` is `definite article`.",
            LintKind::Usage
        ),
        "DigestiveTract" => (
            &[
                ("digestive track", "digestive tract"),
                ("digestive tracks", "digestive tracts"),
            ],
            "The correct term is digestive `tract`.",
            "Corrects `digestive track` to `digestive tract`.",
            LintKind::WordChoice
        ),
        "Discuss" => (
            &[
                ("discuss about", "discuss"),
                ("discussed about", "discussed"),
                ("discusses about", "discusses"),
                ("discussing about", "discussing"),
            ],
            "`About` is redundant",
            "Removes unnecessary `about` after `discuss`.",
            // or maybe Redundancy?
            LintKind::Usage
        ),
        "DoesOrDose" => (
            &[
                // Negatives
                ("dose not", "does not"),
                // Pronouns
                ("he dose", "he does"),
                ("it dose", "it does"),
                ("she dose", "she does"),
                ("someone dose", "someone does"),
                // Interrogatives
                ("how dose", "how does"),
                ("when dose", "when does"),
                ("where dose", "where does"),
                ("who dose", "who does"),
                ("why dose", "why does"),
            ],
            "This may be a typo for `does`.",
            "Tries to correct typos of `dose` to `does`.",
            LintKind::Typo
        ),
        "ExpandArgument" => (
            &[
                ("arg", "argument"),
                ("args", "arguments"),
            ],
            "Use `argument` instead of `arg`",
            "Expands the abbreviation `arg` to the full word `argument` for clarity.",
            LintKind::Style
        ),
        "ExpandDependencies" => (
            &[
                ("dep", "dependency"),
                ("deps", "dependencies"),
            ],
            "Use `dependencies` instead of `deps`",
            "Expands the abbreviation `deps` to the full word `dependencies` for clarity.",
            LintKind::Style
        ),
        "ExpandDeref" => (
            &[
                ("deref", "dereference"),
                ("derefs", "dereferences"),
            ],
            "Use `dereference` instead of `deref`",
            "Expands the abbreviation `deref` to the full word `dereference` for clarity.",
            LintKind::Style
        ),
        "ExpandParameter" => (
            &[
                ("param", "parameter"),
                ("params", "parameters"),
            ],
            "Use `parameter` instead of `param`",
            "Expands the abbreviation `param` to the full word `parameter` for clarity.",
            LintKind::Style
        ),
        "ExpandPointer" => (
            &[
                ("ptr", "pointer"),
                ("ptrs", "pointers"),
            ],
            "Use `pointer` instead of `ptr`",
            "Expands the abbreviation `ptr` to the full word `pointer` for clarity.",
            LintKind::Style
        ),
        "ExpandStandardInputAndOutput" => (
            &[
                ("stdin", "standard input"),
                ("stdout", "standard output"),
                ("stderr", "standard error"),
            ],
            "Use `standard input`, `standard output`, and `standard error` instead of `stdin`, `stdout`, and `stderr`",
            "Expands the abbreviations `stdin`, `stdout`, and `stderr` to the full words `standard input`, etc. for clarity.",
            LintKind::Style
        ),
        "ExplanationMark" => (
            &[
                ("explanation mark", "exclamation mark"),
                ("explanation marks", "exclamation marks"),
                ("explanation point", "exclamation point"),
            ],
            "The correct names for the `!` punctuation are `exclamation mark` and `exclamation point`.",
            "Corrects the eggcorn `explanation mark/point` to `exclamation mark/point`.",
            LintKind::Usage
        ),
        "ExtendOrExtent" => (
            &[
                ("a certain extend", "a certain extent"),
                ("to an extend", "to an extent"),
                ("to some extend", "to some extent"),
                ("to the extend that", "to the extent that")
            ],
            "Use `extent` for the noun and `extend` for the verb.",
            "Corrects `extend` to `extent` when the context is a noun.",
            // ConfusedPair??
            LintKind::WordChoice
        ),
        "FoamAtTheMouth" => (
            &[
                ("foam out the mouth", "foam at the mouth"),
                ("foamed out the mouth", "foamed at the mouth"),
                ("foaming out the mouth", "foaming at the mouth"),
                ("foams out the mouth", "foams at the mouth"),
            ],
            "The correct idiom is `foam at the mouth`.",
            "Corrects the idiom `foam out the mouth` to the standard `foam at the mouth`.",
            LintKind::Nonstandard
        ),
        "FootTheBill" => (
            &[
                ("flip the bill", "foot the bill"),
                ("flipped the bill", "footed the bill"),
                ("flipping the bill", "footing the bill"),
                ("flips the bill", "foots the bill"),
            ],
            "The standard expression is `foot the bill`.",
            "Corrects `flip the bill` to `foot the bill`.",
            LintKind::Nonstandard
        ),
        "HavePassed" => (
            &[
                ("had past", "had passed"),
                ("has past", "has passed"),
                ("have past", "have passed"),
                ("having past", "having passed"),
            ],
            "Did you mean the verb `passed`?",
            "Suggests `past` for `passed` in case a verb was intended.",
            // ConfusedPair?
            LintKind::WordChoice
        ),
        "HomeInOn" => (
            &[
                ("hone in on", "home in on"),
                ("honed in on", "homed in on"),
                ("hones in on", "homes in on"),
                ("honing in on", "homing in on"),
            ],
            "Use `home in on` rather than `hone in on`",
            "Corrects `hone in on` to `home in on`.",
            LintKind::Eggcorn
        ),
        "InDetail" => (
            &[
                ("in details", "in detail"),
                ("in more details", "in more detail"),
            ],
            "Use singular `in detail` for referring to a detailed description.",
            "Corrects unidiomatic plural `in details` to `in detail`.",
            LintKind::Usage
        ),
        "InvestIn" => (
            &[
                // Verb
                ("invest into", "invest in"),
                ("invested into", "invested in"),
                ("investing into", "investing in"),
                ("invests into", "invests in"),
                // Noun
                ("investment into", "investment in"),
                // Note "investments into" can be correct in some contexts
            ],
            "Traditionally `invest` uses the preposition `in`.",
            "`Invest` is traditionally followed by 'in,' not `into.`",
            LintKind::Usage
        ),

        // General litotes (double negatives) → direct positive suggestions
        "LitotesDirectPositive" => (
            &[
                ("not uncommon", "common"),
                ("not unusual", "common"),
                ("not insignificant", "significant"),
                ("not unimportant", "important"),
                ("not unlikely", "likely"),
                ("not infrequent", "frequent"),
                ("not inaccurate", "accurate"),
                ("not unclear", "clear"),
                ("not irrelevant", "relevant"),
                ("not unpredictable", "predictable"),
                ("not inadequate", "adequate"),
                ("not unpleasant", "pleasant"),
                ("not unreasonable", "reasonable"),
                ("not impossible", "possible"),
                ("more preferable", "preferable"),
                ("not online", "offline"),
                ("not offline", "online"),
            ],
            "Consider the direct form.",
            "Offers direct-positive alternatives when double negatives might feel heavy.",
            LintKind::Style
        ),

        "MakeDoWith" => (
            &[
                ("make due with", "make do with"),
                ("made due with", "made do with"),
                ("makes due with", "makes do with"),
                ("making due with", "making do with"),
            ],
            "Use `do` instead of `due` when referring to a resource scarcity.",
            "Corrects `make due` to `make do` when followed by `with`."
        ),
        "MakeSense" => (
            &[
                ("make senses", "make sense"),
                ("made senses", "made sense"),
                ("makes senses", "makes sense"),
                ("making senses", "making sense")
            ],
            "Use `sense` instead of `senses`.",
            "Corrects `make senses` to `make sense`.",
            LintKind::Usage
        ),
        "MootPoint" => (
            &[
                ("mute point", "moot point"),
                ("point is mute", "point is moot"),
            ],
            "Use `moot` instead of `mute` when referring to a debatable or irrelevant point.",
            "Corrects `mute` to `moot` in the phrase `moot point`.",
            LintKind::Eggcorn
        ),
        "OperatingSystem" => (
            &[
                ("operative system", "operating system"),
                ("operative systems", "operating systems"),
            ],
            "Did you mean `operating system`?",
            "Ensures `operating system` is used correctly instead of `operative system`.",
            LintKind::Usage
        ),
        "PassersBy" => (
            &[
                ("passerbys", "passersby"),
                ("passer-bys", "passers-by"),
            ],
            "The correct plural is `passersby` or `passers-by`.",
            "Corrects `passerbys` and `passer-bys` to `passersby` or `passers-by`.",
            LintKind::Grammar
        ),
        "Piggyback" => (
            &[
                ("piggy bag", "piggyback"),
                ("piggy bagged", "piggybacked"),
                ("piggy bagging", "piggybacking"),
            ],
            "Did you mean `piggyback`?",
            "Corrects the eggcorn `piggy bag` to `piggyback`, which is the proper term for riding on someone’s back or using an existing system.",
            LintKind::Eggcorn
        ),
        // Redundant degree modifiers on positives (double positives) → base form
        "RedundantSuperlatives" => (
            &[
                ("more optimal", "optimal"),
                ("most optimal", "optimal"),
                ("more ideal", "ideal"),
                ("most ideal", "ideal"),
            ],
            "Avoid redundant degree modifiers; prefer the base adjective.",
            "Simplifies redundant double positives like `most optimal` to the base form.",
            LintKind::Redundancy
        ),
        "ScapeGoat" => (
            &[
                ("an escape goat", "a scapegoat"),
                ("escape goat", "scapegoat"),
                ("escape goats", "scapegoats"),
            ],
            "If you're referring someone is being blamed unfairly, write it as a single word: `scapegoat`.",
            "Corrects `scape goat` to `scapegoat`, which is the proper term for a person blamed for others' failures.",
            LintKind::Eggcorn
        ),
        "WreakHavoc" => (
            &[
                ("wreck havoc", "wreak havoc"),
                ("wrecked havoc", "wreaked havoc"),
                ("wrecking havoc", "wreaking havoc"),
                ("wrecks havoc", "wreaks havoc"),
            ],
            "Did you mean `wreak havoc`?",
            "Corrects the eggcorn `wreck havoc` to `wreak havoc`, which is the proper term for causing chaos or destruction.",
            LintKind::Eggcorn
        )
    });

    add_many_to_many_mappings!(group, {
        "AwaitFor" => (
            &[
                (&["await for"], &["await", "wait for"]),
                (&["awaited for"], &["awaited", "waited for"]),
                (&["awaiting for"], &["awaiting", "waiting for"]),
                (&["awaits for"], &["awaits", "waits for"])
            ],
            "`Await` and `for` are redundant when used together - use one or the other",
            "Suggests using either `await` or `wait for` but not both, as they express the same meaning.",
            LintKind::Redundancy
        ),
        "Copyright" => (
            &[
                (&["copywrite"], &["copyright"]),
                (&["copywrites"], &["copyrights"]),
                (&["copywriting"], &["copyrighting"]),
                (&["copywritten", "copywrited", "copywrote"], &["copyrighted"]),
            ],
            "Did you mean `copyright`? `Copywrite` means to write copy (advertising text), while `copyright` is the legal right to control use of creative works.",
            "Corrects `copywrite` to `copyright`. `Copywrite` refers to writing copy, while `copyright` is the legal right to creative works.",
            LintKind::WordChoice
        ),
        "DoubleEdgedSword" => (
            &[
                (&["double edge sword", "double-edge sword", "double edge-sword", "double-edge-sword",
                   "double edged sword", "double edged-sword", "double-edged-sword"], &["double-edged sword"]),
                (&["double edge swords", "double-edge swords", "double edge-swords", "double-edge-swords",
                   "double edged swords", "double edged-swords", "double-edged-swords"], &["double-edged swords"]),
            ],
            "Did you mean `double-edged sword`?",
            "Corrects variants of `double-edged sword`.",
            LintKind::Spelling
        ),
        "ExpandAlloc" => (
            &[
                (&["alloc"], &["allocate", "allocation"]),
                (&["allocs"], &["allocates", "allocations"]),
            ],
            "Use `allocate` or `allocation` instead of `alloc`",
            "Expands the abbreviation `alloc` to the full word `allocate` or `allocation` for clarity.",
            LintKind::Style
        ),
        "ExpandDecl" => (
            &[
                (&["decl"], &["declaration", "declarator"]),
                (&["decls"], &["declarations", "declarators"])
            ],
            "Use `declaration` or `declarator` instead of `decl`",
            "Expands the abbreviation `decl` to the full word `declaration` or `declarator` for clarity.",
            LintKind::Style
        ),
        "Expat" => (
            &[
                (&["ex-pat", "ex pat"], &["expat"]),
                (&["ex-pats", "ex pats"], &["expats"]),
                (&["ex-pat's", "ex pat's"], &["expat's"]),
            ],
            "The correct spelling is `expat` with no hyphen or space.",
            "Corrects the mistake of writing `expat` as two words.",
            LintKind::Spelling
        ),
        "Expatriate" => (
            &[
                (&["ex-patriot", "expatriot", "ex patriot"], &["expatriate"]),
                (&["ex-patriots", "expatriots", "ex patriots"], &["expatriates"]),
                (&["ex-patriot's", "expatriot's", "ex patriot's"], &["expatriate's"]),
            ],
            "Use the correct term for someone living abroad.",
            "Fixes the misinterpretation of `expatriate`, ensuring the correct term is used for individuals residing abroad.",
            LintKind::Eggcorn
        ),
        "GetRidOf" => (
            &[
                (&["get rid off", "get ride of", "get ride off"], &["get rid of"]),
                (&["gets rid off", "gets ride of", "gets ride off"], &["gets rid of"]),
                (&["getting rid off", "getting ride of", "getting ride off"], &["getting rid of"]),
                (&["got rid off", "got ride of", "got ride off"], &["got rid of"]),
                (&["gotten rid off", "gotten ride of", "gotten ride off"], &["gotten rid of"]),
            ],
            "The idiom is `to get rid of`, not `off` or `ride`.",
            "Corrects common misspellings of the idiom `get rid of`.",
            LintKind::Typo
        ),
        "HolyWar" => (
            &[
                (&["holey war", "holly war"], &["holy war"]),
                (&["holey wars", "holly wars"], &["holy wars"]),
            ],
            "Literally for religious conflicts and metaphorically for tech preference debats, the correct spelling is `holy war`.",
            "Corrects misspellings of `holy war`.",
            LintKind::Malapropism
        ),
        "HowItLooksLike" => (
            &[
                (&["how he looks like"], &["how he looks", "what he looks like"]),
                (&["how it looks like", "how it look like", "how it look's like"], &["how it looks", "what it looks like"]),
                (&["how she looks like"], &["how she looks", "what she looks like"]),
                (&["how they look like", "how they looks like"], &["how they look", "what they look like"]),
            ],
            "Don't use both `how` and `like` together to express similarity.",
            "Corrects `how ... looks like` to `how ... looks` or `what ... looks like`.",
            LintKind::Grammar
        ),
        "MakeItSeem" => (
            &[
                (&["make it seems"], &["make it seem"]),
                (&["made it seems", "made it seemed"], &["made it seem"]),
                (&["makes it seems"], &["makes it seem"]),
                (&["making it seems"], &["making it seem"]),
            ],
            "Don't inflect `seem` in `make it seem`.",
            "Corrects `make it seems` to `make it seem`."
        ),
        "NervousWreck" => (
            &[
                (&["nerve wreck", "nerve-wreck"], &["nervous wreck"]),
                (&["nerve wrecks", "nerve-wrecks"], &["nervous wrecks"]),
            ],
            "Use `nervous wreck` when referring to a person who is extremely anxious or upset. `Nerve wreck` is non-standard but sometimes used for events or situations.",
            "Suggests using `nervous wreck` when referring to a person's emotional state.",
            LintKind::Eggcorn
        ),
        "NotOnly" => (
            &[
                (&["no only are"], &["not only are"]),
                (&["no only is"], &["not only is"]),
                (&["no only was"], &["not only was"]),
                (&["no only were"], &["not only were"]),
            ],
            "Use `not only` instead of `no only` in this expression.",
            "Corrects `no only` to `not only` before forms of `to be`.",
            LintKind::Grammar
        ),
        "RiseTheQuestion" => (
            &[
                (&["rise the question", "arise the question"], &["raise the question"]),
                (&["rises the question", "arises the question"], &["raises the question"]),
                (
                    &[
                        "risen the question", "rose the question", "rised the question",
                        "arisen the question", "arose the question", "arised the question"
                    ],
                    &["raised the question"]
                ),
                (&["rising the question", "arising the question"], &["raising the question"])
            ],
            "Use `raise` instead of `rise` when referring to the act of asking a question.",
            "Corrects `rise the question` to `raise the question`.",
            LintKind::Grammar
        ),
        "ToTooIdioms" => (
            &[
                (&["a bridge to far"], &["a bridge too far"]),
                (&["cake and eat it to"], &["cake and eat it too"]),
                // "a few to many" has many false positives

                (&["go to far"], &["go too far"]),
                (&["goes to far"], &["goes too far"]),
                (&["going to far"], &["going too far"]),
                (&["gone to far"], &["gone too far"]),
                (&["went to far"], &["went too far"]),

                // "in to deep" has many false positives
                (&["life's to short", "lifes to short"], &["life's too short"]),
                (&["life is to short"], &["life is too short"]),

                // "one to many" has many false positives
                (&["put to fine a point"], &["put too fine a point"], ),

                (&["speak to soon"], &["speak too soon"]),
                (&["speaking to soon"], &["speaking too soon"]),
                // "speaks to soon" is very rare
                (&["spoke to soon"], &["spoke too soon"]),
                (&["spoken to soon"], &["spoken too soon"]),

                (&["think to much"], &["think too much"]),
                (&["to big for"], &["too big for"]),
                (&["to big to fail"], &["too big to fail"]),
                (&["to good to be true", "too good too be true"], &["too good to be true"]),
                (&["to much information"], &["too much information"]),
            ],
            "Use `too` rather than `to` in this expression.",
            "Corrects `to` used instead of `too`.",
            LintKind::Grammar
        ),
        "TooTo" => (
            &[
                (&["too big too fail"], &["too big to fail"])
            ],
            "Use `to` rather than `too` in this expression.",
            "Corrects `too` used instead of `to`.",
            LintKind::Grammar
        ),
        "WholeEntire" => (
            &[
                (&["whole entire"], &["whole", "entire"]),
                // Avoid suggestions resulting in "a entire ...."
                (&["a whole entire"], &["a whole", "an entire"]),
            ],
            "Avoid redundancy. Use either `whole` or `entire` for referring to the complete amount or extent.",
            "Corrects the redundancy in `whole entire` to `whole` or `entire`.",
            LintKind::Redundancy
        ),
        "WorseOrWorst" => (
            &[
                // worst -> worse
                (&["a lot worst", "alot worst"], &["a lot worse"]),
                (&["become worst"], &["become worse"]),
                (&["became worst"], &["became worse"]),
                (&["becomes worst"], &["becomes worse"]),
                (&["becoming worst"], &["becoming worse"]),
                (&["far worst"], &["far worse"]),
                (&["get worst"], &["get worse"]),
                (&["gets worst"], &["gets worse"]),
                (&["getting worst"], &["getting worse"]),
                (&["got worst"], &["got worse"]),
                (&["gotten worst"], &["gotten worse"]),
                (&["make it worst"], &["make it worse"]),
                (&["made it worst"], &["made it worse"]),
                (&["makes it worst"], &["makes it worse"]),
                (&["making it worst"], &["making it worse"]),
                (&["make them worst"], &["make them worse"]),
                (&["made them worst"], &["made them worse"]),
                (&["makes them worst"], &["makes them worse"]),
                (&["making them worst"], &["making them worse"]),
                (&["much worst"], &["much worse"]),
                (&["turn for the worst"], &["turn for the worse"]),
                (&["worst and worst", "worse and worst", "worst and worse"], &["worse and worse"]),
                (&["worst than"], &["worse than"]),
                // worse -> worst
                (&["at worse"], &["at worst"]),
                (&["worse case scenario", "worse-case scenario", "worse-case-scenario"], &["worst-case scenario"]),
                (&["worse ever"], &["worst ever"]),
            ],
            "`Worse` is for comparing and `worst` is for the extreme case.",
            "Corrects `worse` and `worst` used in contexts where the other belongs.",
            LintKind::Agreement
        )
    });

    group.set_all_rules_to(Some(true));

    group
}



================================================
FILE: harper-core/src/linting/pronoun_contraction/avoid_contraction.rs
================================================
use crate::expr::{Expr, SequenceExpr};
use crate::{Token, TokenKind};

use super::super::{ExprLinter, Lint, LintKind, Suggestion};
use crate::linting::expr_linter::Chunk;

pub struct AvoidContraction {
    expr: Box<dyn Expr>,
}

impl Default for AvoidContraction {
    fn default() -> Self {
        let pattern = SequenceExpr::aco("you're")
            .then_whitespace()
            .then_kind_is_but_is_not(TokenKind::is_nominal, TokenKind::is_likely_homograph);

        Self {
            expr: Box::new(pattern),
        }
    }
}

impl ExprLinter for AvoidContraction {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], source: &[char]) -> Option<Lint> {
        let word = matched_tokens[0].span.get_content(source);

        Some(Lint {
            span: matched_tokens[0].span,
            lint_kind: LintKind::WordChoice,
            suggestions: vec![Suggestion::replace_with_match_case(
                vec!['y', 'o', 'u', 'r'],
                word,
            )],
            message: "It appears you intended to use the possessive version of this word"
                .to_owned(),
            priority: 63,
        })
    }

    fn description(&self) -> &'static str {
        "This rule looks for situations where a contraction was used where it shouldn't have been."
    }
}



================================================
FILE: harper-core/src/linting/pronoun_contraction/mod.rs
================================================
use super::merge_linters::merge_linters;

mod avoid_contraction;
mod should_contract;

use avoid_contraction::AvoidContraction;
use should_contract::ShouldContract;

merge_linters! {PronounContraction => ShouldContract, AvoidContraction => "Choosing when to contract pronouns is a challenging art. This rule looks for faults." }

#[cfg(test)]
mod tests {
    use super::PronounContraction;
    use crate::linting::tests::{assert_lint_count, assert_suggestion_result};

    #[test]
    fn issue_225() {
        assert_suggestion_result(
            "Your the man",
            PronounContraction::default(),
            "You're the man",
        );
    }

    #[test]
    fn were_team() {
        assert_suggestion_result(
            "Were the best team.",
            PronounContraction::default(),
            "We're the best team.",
        );
    }

    #[test]
    fn issue_139() {
        assert_suggestion_result(
            "it would be great if you're PR was merged into tower-lsp",
            PronounContraction::default(),
            "it would be great if your PR was merged into tower-lsp",
        );
    }

    #[test]
    fn car() {
        assert_suggestion_result(
            "You're car is black.",
            PronounContraction::default(),
            "Your car is black.",
        );
    }

    #[test]
    fn allows_you_are_still() {
        assert_lint_count(
            "In case you're still not convinced.",
            PronounContraction::default(),
            0,
        );
    }

    #[test]
    fn issue_576() {
        assert_lint_count(
            "If you're not happy you try again.",
            PronounContraction::default(),
            0,
        );
        assert_lint_count("No you're not.", PronounContraction::default(), 0);
        assert_lint_count(
            "Even if you're not fluent in arm assembly, you surely noticed this.",
            PronounContraction::default(),
            0,
        );
    }
}



================================================
FILE: harper-core/src/linting/pronoun_contraction/should_contract.rs
================================================
use std::sync::Arc;

use crate::TokenKind;
use crate::expr::AnchorStart;
use crate::expr::Expr;
use crate::expr::OwnedExprExt;
use crate::expr::SequenceExpr;
use crate::{Token, patterns::WordSet};

use crate::Lint;
use crate::linting::expr_linter::Chunk;
use crate::linting::{ExprLinter, LintKind, Suggestion};

/// See also:
/// harper-core/src/linting/compound_nouns/implied_ownership_compound_nouns.rs
/// harper-core/src/linting/lets_confusion/mod.rs
/// harper-core/src/linting/lets_confusion/let_us_redundancy.rs
/// harper-core/src/linting/lets_confusion/no_contraction_with_verb.rs
pub struct ShouldContract {
    expr: Box<dyn Expr>,
}

impl Default for ShouldContract {
    fn default() -> Self {
        let cap = Arc::new(
            SequenceExpr::default()
                .then(WordSet::new(&["your", "were"]))
                .then_whitespace()
                .then_kind_is_but_is_not(
                    TokenKind::is_non_quantifier_determiner,
                    TokenKind::is_pronoun,
                )
                .then_whitespace()
                .then_adjective(),
        );

        let start = SequenceExpr::with(AnchorStart).then(cap.clone());
        let mid = SequenceExpr::default()
            .then_unless(WordSet::new(&["what"]))
            .t_ws()
            .then(cap);

        Self {
            expr: Box::new(start.or(mid)),
        }
    }
}

impl ShouldContract {
    fn mistake_to_correct(mistake: &str) -> Option<Vec<Vec<char>>> {
        let words = match mistake.to_lowercase().as_str() {
            "your" => vec!["you're", "you are"],
            "were" => vec!["we're", "we are"],
            _ => return None,
        }
        .into_iter()
        .map(|v| v.chars().collect())
        .collect();

        Some(words)
    }
}

impl ExprLinter for ShouldContract {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], source: &[char]) -> Option<Lint> {
        // Locate the mistake
        let possible_mistakes = [matched_tokens[0].span, matched_tokens[1].span];

        let mut correct = None;
        let mut span = None;

        for p_mist in possible_mistakes {
            let mistake = p_mist.get_content_string(source);
            let correct_cand = Self::mistake_to_correct(&mistake);
            if correct_cand.is_some() {
                correct = correct_cand;
                span = Some(p_mist);
            }
        }

        let correct = correct?;
        let span = span?;

        Some(Lint {
            span,
            lint_kind: LintKind::WordChoice,
            suggestions: correct
                .into_iter()
                .map(|v| Suggestion::replace_with_match_case(v, span.get_content(source)))
                .collect(),
            message: "Use the contraction or separate the words instead.".to_string(),
            priority: 31,
        })
    }

    fn description(&self) -> &'static str {
        "Neglecting the apostrophe when contracting pronouns with \"are\" (like \"your\" and \"you are\") is a fatal, but extremely common mistake to make."
    }
}

#[cfg(test)]
mod tests {
    use super::ShouldContract;
    use crate::linting::tests::{assert_lint_count, assert_no_lints, assert_suggestion_result};

    #[test]
    fn contracts_your_correctly() {
        assert_suggestion_result(
            "your the best",
            ShouldContract::default(),
            "you're the best",
        );
    }

    #[test]
    fn contracts_were_complex_correctly() {
        assert_suggestion_result(
            "were a good team",
            ShouldContract::default(),
            "we're a good team",
        );
    }

    #[test]
    fn case_insensitive_handling() {
        assert_suggestion_result(
            "Your the best",
            ShouldContract::default(),
            "You're the best",
        );
    }

    #[test]
    fn no_match_without_the() {
        assert_lint_count("your best", ShouldContract::default(), 0);
        assert_lint_count("were best", ShouldContract::default(), 0);
    }

    #[test]
    fn no_match_with_punctuation() {
        assert_lint_count("your, the best", ShouldContract::default(), 0);
    }

    #[test]
    fn allow_norm() {
        assert_lint_count(
            "Let's start this story by going back to the dark ages before internet applications were the norm.",
            ShouldContract::default(),
            0,
        );
    }

    #[test]
    fn allow_issue_1508() {
        assert_no_lints("Were any other toys fun?", ShouldContract::default());
        assert_no_lints("You were his closest friend.", ShouldContract::default());
    }

    #[test]
    fn allows_issue_1673() {
        assert_no_lints("What were the action items?", ShouldContract::default());
    }
}



================================================
FILE: harper-core/src/linting/to_two_too/mod.rs
================================================
mod to_too_adjective_end;
mod to_too_adjective_punct;
mod to_too_adjverb_ed_punct;
mod to_too_adverb;
mod to_too_chunk_start_comma;
mod to_too_degree_words;
mod to_too_eos;
mod to_too_pronoun_end;
mod too_to;

use super::merge_linters::merge_linters;
use super::{ExprLinter, Lint, LintKind, Suggestion};
use to_too_adjective_end::ToTooAdjectiveEnd;
use to_too_adjective_punct::ToTooAdjectivePunct;
use to_too_adjverb_ed_punct::ToTooAdjVerbEdPunct;
use to_too_adverb::ToTooAdverb;
use to_too_chunk_start_comma::ToTooChunkStartComma;
use to_too_degree_words::ToTooDegreeWords;
use to_too_eos::ToTooEos;
use to_too_pronoun_end::ToTooPronounEnd;
use too_to::TooTo;

merge_linters!(
    ToTwoToo =>
        ToTooAdjectiveEnd,
        ToTooAdjectivePunct,
        ToTooAdverb,
        ToTooAdjVerbEdPunct,
        ToTooChunkStartComma,
        ToTooDegreeWords,
        ToTooPronounEnd,
        ToTooEos,
        TooTo
    => "Corrects homophone confusion between `to` and `too`."
);

#[cfg(test)]
mod tests {
    use crate::linting::tests::{assert_lint_count, assert_no_lints, assert_suggestion_result};

    use super::ToTwoToo;

    #[test]
    fn fixes_to_ambitious() {
        assert_suggestion_result(
            "The project scope is to ambitious",
            ToTwoToo::default(),
            "The project scope is too ambitious",
        );
    }

    #[test]
    fn fixes_end_of_sent() {
        assert_suggestion_result(
            "She wants ice cream, to.",
            ToTwoToo::default(),
            "She wants ice cream, too.",
        );
    }

    #[test]
    fn flags_to_hungry() {
        assert_lint_count("I am to hungry.", ToTwoToo::default(), 1);
    }

    #[test]
    fn no_lint_on_proper_too() {
        assert_no_lints("I am too hungry.", ToTwoToo::default());
    }

    #[test]
    fn flags_to_with_irregular_whitespace() {
        assert_lint_count("She was to\t   tired.", ToTwoToo::default(), 1);
        assert_lint_count("He felt it was\nto cold.", ToTwoToo::default(), 1);
    }

    #[test]
    fn flags_to_with_trailing_punct() {
        assert_lint_count("He spoke to loud!", ToTwoToo::default(), 1);
        assert_lint_count("He spoke to loud?", ToTwoToo::default(), 1);
        assert_lint_count("He spoke to loud.", ToTwoToo::default(), 1);
    }

    #[test]
    fn no_lint_to_eat() {
        assert_no_lints(
            "Please remember to eat your vegetables.",
            ToTwoToo::default(),
        );
    }

    #[test]
    fn no_lint_to_nashville_or_you() {
        assert_no_lints("I’m going to Nashville next week.", ToTwoToo::default());
        assert_no_lints("Talk to you later.", ToTwoToo::default());
    }

    #[test]
    fn no_lint_distance_from_center() {
        assert_no_lints("Distance from the center to any face", ToTwoToo::default());
    }

    #[test]
    fn fixes_too_go() {
        assert_suggestion_result(
            "I want too go abroad.",
            ToTwoToo::default(),
            "I want to go abroad.",
        );
    }

    #[test]
    fn fixes_too_him() {
        assert_suggestion_result(
            "Give it too him as a gift",
            ToTwoToo::default(),
            "Give it to him as a gift",
        );
    }

    #[test]
    fn fixes_too_the() {
        assert_suggestion_result(
            "We're going too the conference.",
            ToTwoToo::default(),
            "We're going to the conference.",
        );
    }

    #[test]
    fn fixes_too_a() {
        assert_suggestion_result(
            "We're going too a concert.",
            ToTwoToo::default(),
            "We're going to a concert.",
        );
    }

    #[test]
    fn fixes_to_hard() {
        assert_suggestion_result(
            "It's not to hard, is it?",
            ToTwoToo::default(),
            "It's not too hard, is it?",
        );
    }

    #[test]
    fn no_lint_too_hot() {
        assert_no_lints("The coffee is too hot to drink.", ToTwoToo::default());
    }

    #[test]
    fn no_lint_too_loud() {
        assert_no_lints(
            "The music was too loud, making it hard to hear.",
            ToTwoToo::default(),
        );
    }

    #[test]
    fn no_lint_too_shy() {
        assert_no_lints("He's too shy to speak in public.", ToTwoToo::default());
    }

    #[test]
    fn no_lint_too_sweet() {
        assert_no_lints("The cake is too sweet for my taste.", ToTwoToo::default());
    }

    #[test]
    fn no_lint_too_expensive() {
        assert_no_lints(
            "It's too expensive for me to buy right now.",
            ToTwoToo::default(),
        );
    }

    #[test]
    fn no_lint_too_hard() {
        assert_no_lints(
            "She worked too hard and ended up getting sick.",
            ToTwoToo::default(),
        );
    }

    #[test]
    fn no_lint_too_complicated() {
        assert_no_lints(
            "The instructions were too complicated to understand.",
            ToTwoToo::default(),
        );
    }

    #[test]
    fn no_lint_too_too() {
        assert_no_lints(
            "I like apples, and my brother does too.",
            ToTwoToo::default(),
        );
    }

    #[test]
    fn no_lint_too_too_2() {
        assert_no_lints(
            "She's coming to the party, and he is too.",
            ToTwoToo::default(),
        );
    }

    #[test]
    fn no_lint_too_too_3() {
        assert_no_lints(
            "I want to go to the beach, and you do too?",
            ToTwoToo::default(),
        );
    }

    #[test]
    fn no_lint_too_too_4() {
        assert_no_lints(
            "He's a talented musician, and a great friend too.",
            ToTwoToo::default(),
        );
    }

    #[test]
    fn no_lint_too_too_5() {
        assert_no_lints(
            "The movie was good, and the popcorn was delicious too.",
            ToTwoToo::default(),
        );
    }

    #[test]
    fn no_lint_too_difficult_too_close() {
        assert_no_lints(
            "The problem is too difficult, and the deadline is too close.",
            ToTwoToo::default(),
        );
    }

    #[test]
    fn no_lint_too_good_too_nice() {
        assert_no_lints(
            "He's too good at the game, and he's too nice to win.",
            ToTwoToo::default(),
        );
    }

    #[test]
    fn allow_young_musicians() {
        assert_no_lints(
            "Bringing Hope and Opportunity to Young Musicians",
            ToTwoToo::default(),
        );
    }

    #[test]
    fn allow_semicolon() {
        assert_no_lints("Attendees can look forward to:", ToTwoToo::default());
    }

    #[test]
    fn allow_build_brighter() {
        assert_no_lints(
            "We're empowering them to build brighter futures.",
            ToTwoToo::default(),
        );
    }

    #[test]
    fn allow_delegate() {
        assert_no_lints(
            "I’d like you to consciously delegate one task",
            ToTwoToo::default(),
        );
    }

    #[test]
    fn no_lint_soundscapes() {
        assert_no_lints(
            "Soundscapes are not merely environmental features; they are integral to human identity and cultural expression.",
            ToTwoToo::default(),
        );
    }

    #[test]
    fn no_lint_speed_flexibility() {
        assert_no_lints(
            "Its speed, flexibility, and seamless integration with FZF make it a compelling alternative to traditional fuzzy finding solutions.",
            ToTwoToo::default(),
        );
    }

    #[test]
    fn no_lint_explicitly_cast() {
        assert_no_lints(
            "Attempted to explicitly cast the result back to a string",
            ToTwoToo::default(),
        );
    }

    #[test]
    fn no_lint_buried_under_data() {
        assert_no_lints(
            "They felt buried under the data, unable to proactively address emerging threats.",
            ToTwoToo::default(),
        );
    }

    #[test]
    fn no_lint_familiarize() {
        assert_no_lints(
            "Familiarize yourself with these resources to learn how to effectively utilize the plugin’s features.",
            ToTwoToo::default(),
        );
    }

    #[test]
    fn no_lint_great_deal_of_energy() {
        assert_no_lints(
            "It takes a great deal of energy to consistently operate under that kind of pressure.",
            ToTwoToo::default(),
        );
    }

    #[test]
    fn no_lint_occasionally_troubleshoot() {
        assert_no_lints(
            "Just be prepared to occasionally troubleshoot the debugger itself.",
            ToTwoToo::default(),
        );
    }

    #[test]
    fn ccoveille_suggestion() {
        assert_no_lints("He goes too far with bets.", ToTwoToo::default());
    }

    #[test]
    fn no_lint_auto_detect_debuggers() {
        assert_no_lints(
            "Daprio attempts to auto-detect debugger servers and configurations, which can save significant time, especially for common languages.",
            ToTwoToo::default(),
        );
    }

    #[test]
    fn no_lint_commitment_open_source() {
        assert_no_lints(
            "I believe a commitment to open-source solutions and internal skill development would ultimately yield a more sustainable and ethical approach.",
            ToTwoToo::default(),
        );
    }

    #[test]
    fn no_lint_feeling_confident_dominate() {
        assert_no_lints(
            "I'm feeling confident, and I suspect you all should be too – because I’m about to dominate.",
            ToTwoToo::default(),
        );
    }

    #[test]
    fn no_lint_egyptian_smiling_faces_commentary() {
        assert_no_lints(
            "Today I learned that the ubiquitous, seemingly cheerful faces carved into ancient Egyptian relief sculptures – often referred to as “smiling faces” – weren’t simply a stylistic choice reflecting happiness. Recent scholarship suggests they functioned as a subtle, often satirical, form of social commentary, particularly targeting individuals who were arrogant, boastful, or otherwise deserving of ridicule.",
            ToTwoToo::default(),
        );
    }

    #[test]
    fn no_lint_intended_to_leave_it_to() {
        assert_no_lints(
            "Beatrice never explicitly said who she intended to leave it to.",
            ToTwoToo::default(),
        );
    }

    #[test]
    fn no_lint_time_for_good_girl_to_bed() {
        assert_no_lints("Time for this good girl to go to bed.", ToTwoToo::default());
    }

    #[test]
    fn no_lint_connected_to_many_other_fields() {
        assert_no_lints(
            "The study is connected to many other fields.",
            ToTwoToo::default(),
        );
    }

    #[test]
    fn no_lint_till_she_too_began_dreaming() {
        assert_no_lints(
            "till she too began dreaming after a fashion",
            ToTwoToo::default(),
        );
    }

    #[test]
    fn no_lint_to_quickly_find_a_factory() {
        assert_no_lints(
            "To quickly find a factory, look for a map.",
            ToTwoToo::default(),
        );
    }

    #[test]
    fn no_lint_llm_as_judge_to_automatically_score() {
        assert_no_lints(
            "We used an LLM-as-judge to automatically score agent trajectories.",
            ToTwoToo::default(),
        );
    }

    #[test]
    fn no_lint_all_the_way_to_advanced_usage() {
        assert_no_lints(
            "All the way to advanced usage, like an expert.",
            ToTwoToo::default(),
        );
    }

    #[test]
    fn no_lint_access_to_over_400_integrations() {
        assert_no_lints(
            "You'll have access to over 400 integrations.",
            ToTwoToo::default(),
        );
    }

    #[test]
    fn no_lint_accustomed_to_precision() {
        assert_no_lints("I’m rather accustomed to precision.", ToTwoToo::default());
    }

    #[test]
    fn no_lint_prone_to_melancholy() {
        assert_no_lints("He wasn’t a man prone to melancholy.", ToTwoToo::default());
    }
}



================================================
FILE: harper-core/src/linting/to_two_too/to_too_adjective_end.rs
================================================
use crate::{
    Token, TokenKind,
    char_string::CharStringExt,
    expr::{Expr, SequenceExpr},
    patterns::{SingleTokenPattern, WhitespacePattern, prepositional_preceder},
};

use super::{ExprLinter, Lint, LintKind, Suggestion};
use crate::linting::expr_linter::Chunk;

pub struct ToTooAdjectiveEnd {
    expr: Box<dyn Expr>,
}

impl Default for ToTooAdjectiveEnd {
    fn default() -> Self {
        let expr = SequenceExpr::optional(
            SequenceExpr::default()
                .then_any_word()
                .then(WhitespacePattern),
        )
        .t_aco("to")
        .t_ws()
        .then_kind_is_but_is_not_except(TokenKind::is_adjective, TokenKind::is_verb, &["standard"])
        .then_optional(WhitespacePattern)
        .then_optional(SequenceExpr::default().then_any_word())
        .then_optional(WhitespacePattern)
        .then_optional(SequenceExpr::default().then_punctuation());

        Self {
            expr: Box::new(expr),
        }
    }
}

impl ExprLinter for ToTooAdjectiveEnd {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, tokens: &[Token], source: &[char]) -> Option<Lint> {
        // Find the `to` token
        let to_index = tokens.iter().position(|t| {
            t.span
                .get_content(source)
                .eq_ignore_ascii_case_chars(&['t', 'o'])
        })?;

        // First non-whitespace after `to` should be the adjective
        let mut idx = to_index + 1;
        while idx < tokens.len() && tokens[idx].kind.is_whitespace() {
            idx += 1;
        }
        if idx >= tokens.len() || !tokens[idx].kind.is_adjective() {
            return None;
        }
        let prev_non_ws = tokens[..to_index].iter().rfind(|t| !t.kind.is_whitespace());
        if tokens[idx].kind.is_preposition() {
            return None;
        }

        if let Some(prev_token) = prev_non_ws
            && prepositional_preceder().matches_token(prev_token, source)
        {
            return None;
        }

        // Find the next non-whitespace after the adjective
        let mut j = idx + 1;
        while j < tokens.len() && tokens[j].kind.is_whitespace() {
            j += 1;
        }

        let should_lint = if j >= tokens.len() {
            true
        } else if tokens[j].kind.is_punctuation() {
            let punct: String = tokens[j].span.get_content(source).iter().collect();
            !matches!(
                punct.as_str(),
                "`" | "\"" | "'" | "“" | "”" | "‘" | "’" | "-" | "–" | "—"
            )
        } else {
            false
        };

        if !should_lint {
            return None;
        }

        let to_tok = &tokens[to_index];

        Some(Lint {
            span: to_tok.span,
            lint_kind: LintKind::WordChoice,
            suggestions: vec![Suggestion::replace_with_match_case_str(
                "too",
                to_tok.span.get_content(source),
            )],
            message: "Use `too` here to mean ‘also’ or an excessive degree.".to_string(),
            ..Default::default()
        })
    }

    fn description(&self) -> &str {
        "Detects `to` before an adjective when no word follows (end or punct)."
    }
}



================================================
FILE: harper-core/src/linting/to_two_too/to_too_adjective_punct.rs
================================================
use crate::{
    Token, TokenKind,
    char_string::CharStringExt,
    expr::{Expr, SequenceExpr},
    patterns::{SingleTokenPattern, WhitespacePattern, prepositional_preceder},
};

use super::{ExprLinter, Lint, LintKind, Suggestion};
use crate::linting::expr_linter::Chunk;

pub struct ToTooAdjectivePunct {
    expr: Box<dyn Expr>,
}

impl Default for ToTooAdjectivePunct {
    fn default() -> Self {
        let expr = SequenceExpr::optional(
            SequenceExpr::default()
                .then_any_word()
                .then(WhitespacePattern),
        )
        .t_aco("to")
        .t_ws()
        .then_kind_is_but_is_not_except(TokenKind::is_adjective, TokenKind::is_verb, &["standard"])
        .then_optional(WhitespacePattern)
        .then_sentence_terminator();

        Self {
            expr: Box::new(expr),
        }
    }
}

impl ExprLinter for ToTooAdjectivePunct {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, tokens: &[Token], source: &[char]) -> Option<Lint> {
        let to_index = tokens.iter().position(|t| {
            t.span
                .get_content(source)
                .eq_ignore_ascii_case_chars(&['t', 'o'])
        })?;

        let mut idx = to_index + 1;
        while idx < tokens.len() && tokens[idx].kind.is_whitespace() {
            idx += 1;
        }
        if idx >= tokens.len() {
            return None;
        }
        let adjective = &tokens[idx];
        if !adjective.kind.is_adjective() {
            return None;
        }
        if adjective.kind.is_preposition() {
            return None;
        }

        let prev_non_ws = tokens[..to_index].iter().rfind(|t| !t.kind.is_whitespace());
        if let Some(prev_token) = prev_non_ws
            && prepositional_preceder().matches_token(prev_token, source)
        {
            return None;
        }

        let to_tok = &tokens[to_index];

        Some(Lint {
            span: to_tok.span,
            lint_kind: LintKind::WordChoice,
            suggestions: vec![Suggestion::replace_with_match_case_str(
                "too",
                to_tok.span.get_content(source),
            )],
            message: "Use `too` here to mean ‘also’ or an excessive degree.".to_string(),
            ..Default::default()
        })
    }

    fn description(&self) -> &str {
        "Detects `to` before an adjective when followed by punctuation."
    }
}



================================================
FILE: harper-core/src/linting/to_two_too/to_too_adjverb_ed_punct.rs
================================================
use crate::char_string::CharStringExt;
use crate::{
    Token,
    expr::{Expr, SequenceExpr},
};

use super::{ExprLinter, Lint, LintKind, Suggestion};
use crate::linting::expr_linter::Chunk;

pub struct ToTooAdjVerbEdPunct {
    expr: Box<dyn Expr>,
}

impl Default for ToTooAdjVerbEdPunct {
    fn default() -> Self {
        let expr = SequenceExpr::default()
            .t_aco("to")
            .t_ws()
            .then(|tok: &crate::Token, src: &[char]| {
                tok.kind.is_adjective()
                    && tok.kind.is_verb()
                    && !tok.kind.is_noun()
                    && tok
                        .span
                        .get_content(src)
                        .ends_with_ignore_ascii_case_chars(&['e', 'd'])
            })
            .then_sentence_terminator();

        Self {
            expr: Box::new(expr),
        }
    }
}

impl ExprLinter for ToTooAdjVerbEdPunct {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, tokens: &[Token], source: &[char]) -> Option<Lint> {
        let to_tok = tokens.iter().find(|t| {
            t.span
                .get_content(source)
                .eq_ignore_ascii_case_chars(&['t', 'o'])
        })?;

        Some(Lint {
            span: to_tok.span,
            lint_kind: LintKind::WordChoice,
            suggestions: vec![Suggestion::replace_with_match_case_str(
                "too",
                to_tok.span.get_content(source),
            )],
            message: "Use `too` here to mean ‘also’ or an excessive degree.".to_string(),
            ..Default::default()
        })
    }

    fn description(&self) -> &str {
        "Detects `to` before words that are adj/verb ending with `ed`, followed by punctuation."
    }
}



================================================
FILE: harper-core/src/linting/to_two_too/to_too_adverb.rs
================================================
use crate::patterns::WhitespacePattern;
use crate::{
    Token, TokenKind,
    char_string::CharStringExt,
    expr::{AnchorEnd, Expr, SequenceExpr},
};

use super::{ExprLinter, Lint, LintKind, Suggestion};
use crate::linting::expr_linter::Chunk;

pub struct ToTooAdverb {
    expr: Box<dyn Expr>,
}

impl Default for ToTooAdverb {
    fn default() -> Self {
        let expr = SequenceExpr::default()
            .t_aco("to")
            .t_ws()
            .then_kind_is_but_is_not_except(TokenKind::is_adverb, TokenKind::is_determiner, &["as"])
            .then_optional(WhitespacePattern)
            .then_any_of(vec![
                Box::new(SequenceExpr::default().then_kind_is_but_is_not_except(
                    TokenKind::is_punctuation,
                    |_| false,
                    &["`", "\"", "'", "“", "”", "‘", "’", "-", "–", "—"],
                )),
                Box::new(AnchorEnd),
            ]);

        Self {
            expr: Box::new(expr),
        }
    }
}

impl ExprLinter for ToTooAdverb {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, tokens: &[Token], source: &[char]) -> Option<Lint> {
        let to_tok = tokens.iter().find(|t| {
            t.span
                .get_content(source)
                .eq_ignore_ascii_case_chars(&['t', 'o'])
        })?;

        Some(Lint {
            span: to_tok.span,
            lint_kind: LintKind::WordChoice,
            suggestions: vec![Suggestion::replace_with_match_case_str(
                "too",
                to_tok.span.get_content(source),
            )],
            message: "Use `too` here to mean ‘also’ or an excessive degree.".to_string(),
            ..Default::default()
        })
    }

    fn description(&self) -> &str {
        "Detects `to` before an adverb when it should be `too`."
    }
}



================================================
FILE: harper-core/src/linting/to_two_too/to_too_chunk_start_comma.rs
================================================
use crate::{
    Token,
    char_string::CharStringExt,
    expr::{AnchorStart, Expr, SequenceExpr},
    patterns::WhitespacePattern,
};

use super::{ExprLinter, Lint, LintKind, Suggestion};
use crate::linting::expr_linter::Chunk;

pub struct ToTooChunkStartComma {
    expr: Box<dyn Expr>,
}

impl Default for ToTooChunkStartComma {
    fn default() -> Self {
        let expr = SequenceExpr::default()
            .then(AnchorStart)
            .t_aco("to")
            .then_optional(WhitespacePattern)
            .then_comma();

        Self {
            expr: Box::new(expr),
        }
    }
}

impl ExprLinter for ToTooChunkStartComma {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, tokens: &[Token], source: &[char]) -> Option<Lint> {
        let to_tok = tokens.iter().find(|t| {
            t.span
                .get_content(source)
                .eq_ignore_ascii_case_chars(&['t', 'o'])
        })?;

        Some(Lint {
            span: to_tok.span,
            lint_kind: LintKind::WordChoice,
            suggestions: vec![Suggestion::replace_with_match_case_str(
                "too",
                to_tok.span.get_content(source),
            )],
            message: "Use `too` here to mean ‘also’ or an excessive degree.".to_string(),
            ..Default::default()
        })
    }

    fn description(&self) -> &str {
        "Detects `to` at the start of a clause before a comma."
    }
}



================================================
FILE: harper-core/src/linting/to_two_too/to_too_degree_words.rs
================================================
use crate::{
    Token, TokenKind,
    char_string::CharStringExt,
    expr::{AnchorEnd, Expr, SequenceExpr},
};

use super::{ExprLinter, Lint, LintKind, Suggestion};
use crate::linting::expr_linter::Chunk;

pub struct ToTooDegreeWords {
    expr: Box<dyn Expr>,
}

impl Default for ToTooDegreeWords {
    fn default() -> Self {
        // Only flag `to` before degree words when the phrase ends the clause
        // (punctuation or end). Avoids false positives like "connected to many X".
        let expr = SequenceExpr::default()
            .t_aco("to")
            .t_ws()
            .then_word_set(&["many", "much", "few"])
            .then_any_of(vec![
                Box::new(SequenceExpr::default().then_kind_is_but_is_not_except(
                    TokenKind::is_punctuation,
                    |_| false,
                    &["`", "\"", "'", "“", "”", "‘", "’", "-", "–", "—"],
                )),
                Box::new(AnchorEnd),
            ]);

        Self {
            expr: Box::new(expr),
        }
    }
}

impl ExprLinter for ToTooDegreeWords {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, tokens: &[Token], source: &[char]) -> Option<Lint> {
        let to_tok = tokens.iter().find(|t| {
            t.span
                .get_content(source)
                .eq_ignore_ascii_case_chars(&['t', 'o'])
        })?;

        Some(Lint {
            span: to_tok.span,
            lint_kind: LintKind::WordChoice,
            suggestions: vec![Suggestion::replace_with_match_case_str(
                "too",
                to_tok.span.get_content(source),
            )],
            message: "Use `too` here to mean ‘also’ or an excessive degree.".to_string(),
            ..Default::default()
        })
    }

    fn description(&self) -> &str {
        "Detects `to` used before degree words like `many`, `much`, or `few`."
    }
}



================================================
FILE: harper-core/src/linting/to_two_too/to_too_eos.rs
================================================
use crate::{
    Document,
    expr::{ExprExt, SequenceExpr},
    linting::Linter,
};

use super::{Lint, LintKind, Suggestion};

pub struct ToTooEos {
    expr: SequenceExpr,
}

impl ToTooEos {
    pub fn new() -> Self {
        Self {
            expr: SequenceExpr::default()
                .then_comma()
                .t_ws()
                .t_aco("to")
                .then_sentence_terminator(),
        }
    }
}

impl Default for ToTooEos {
    fn default() -> Self {
        Self::new()
    }
}

impl Linter for ToTooEos {
    fn lint(&mut self, document: &Document) -> Vec<Lint> {
        let matches = self.expr.iter_matches_in_doc(document);

        matches
            .map(|m| {
                let tok = &m.get_content(document.get_tokens())[2];

                Lint {
                    span: tok.span,
                    lint_kind: LintKind::Typo,
                    suggestions: vec![Suggestion::replace_with_match_case_str(
                        "too",
                        tok.span.get_content(document.get_source()),
                    )],
                    message: "Use `too` when expressing similarity.".to_owned(),
                    priority: 63,
                }
            })
            .collect()
    }

    fn description(&self) -> &str {
        "Identifies incorrect usage of the term `to` at the end of a sentence."
    }
}



================================================
FILE: harper-core/src/linting/to_two_too/to_too_pronoun_end.rs
================================================
use crate::{
    Token, TokenKind,
    char_string::CharStringExt,
    expr::{AnchorEnd, AnchorStart, Expr, SequenceExpr},
    patterns::WhitespacePattern,
};

use super::{ExprLinter, Lint, LintKind, Suggestion};
use crate::linting::expr_linter::Chunk;

pub struct ToTooPronounEnd {
    expr: Box<dyn Expr>,
}

impl Default for ToTooPronounEnd {
    fn default() -> Self {
        // Match at clause start or after punctuation to avoid cases like
        // "leave it to." where `it` is an object pronoun.
        let expr = SequenceExpr::default()
            .then_any_of(vec![
                Box::new(SequenceExpr::with(AnchorStart)),
                Box::new(
                    SequenceExpr::default()
                        .then_kind_is_but_is_not_except(
                            TokenKind::is_punctuation,
                            |_| false,
                            &["`", "\"", "'", "“", "”", "‘", "’"],
                        )
                        .then_optional(WhitespacePattern),
                ),
            ])
            .then_pronoun()
            .t_ws()
            .t_aco("to")
            .then_any_of(vec![
                Box::new(SequenceExpr::default().then_kind_is_but_is_not_except(
                    TokenKind::is_punctuation,
                    |_| false,
                    &["`", "\"", "'", "“", "”", "‘", "’"],
                )),
                Box::new(AnchorEnd),
            ]);

        Self {
            expr: Box::new(expr),
        }
    }
}

impl ExprLinter for ToTooPronounEnd {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, tokens: &[Token], source: &[char]) -> Option<Lint> {
        let to_tok = tokens.iter().find(|t| {
            t.span
                .get_content(source)
                .eq_ignore_ascii_case_chars(&['t', 'o'])
        })?;

        Some(Lint {
            span: to_tok.span,
            lint_kind: LintKind::WordChoice,
            suggestions: vec![Suggestion::replace_with_match_case_str(
                "too",
                to_tok.span.get_content(source),
            )],
            message: "Use `too` here to mean ‘also’ or an excessive degree.".to_string(),
            ..Default::default()
        })
    }

    fn description(&self) -> &str {
        "Detects `to` after a pronoun at clause end (e.g., `Me to!`)."
    }
}



================================================
FILE: harper-core/src/linting/to_two_too/too_to.rs
================================================
use harper_brill::UPOS;

use crate::Token;
use crate::expr::Expr;
use crate::expr::SequenceExpr;
use crate::patterns::UPOSSet;

use super::{ExprLinter, Lint, LintKind, Suggestion};
use crate::linting::expr_linter::Chunk;

pub struct TooTo {
    expr: Box<dyn Expr>,
}

impl Default for TooTo {
    fn default() -> Self {
        let expr = SequenceExpr::aco("too").t_ws().then(UPOSSet::new(&[
            UPOS::NOUN,
            UPOS::PRON,
            UPOS::PROPN,
            UPOS::VERB,
            UPOS::DET,
        ]));
        Self {
            expr: Box::new(expr),
        }
    }
}

impl ExprLinter for TooTo {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    fn match_to_lint(&self, matched_tokens: &[Token], source: &[char]) -> Option<Lint> {
        let too_token = &matched_tokens[0];
        let span = too_token.span;
        let text = span.get_content(source);

        if let Some(next_tok) = matched_tokens.get(2)
            && next_tok.kind.is_upos(UPOS::VERB)
            && !next_tok.kind.is_verb_lemma()
        {
            return None;
        }

        Some(Lint {
            span,
            lint_kind: LintKind::Typo,
            suggestions: vec![
                Suggestion::replace_with_match_case("to".chars().collect(), text)
            ],
            message: "Use the infinitive marker `to` here instead of the adverb `too`, which indicates excess degree.".to_string(),
            priority: 31,
        })
    }

    fn description(&self) -> &'static str {
        "Handles the transition from `too` -> `to`."
    }
}



================================================
FILE: harper-core/src/linting/vicious_loop/mod.rs
================================================
use crate::{
    CharStringExt, Lint, Token, TokenStringExt,
    expr::{Expr, OwnedExprExt, SequenceExpr},
    linting::{ExprLinter, LintKind, Suggestion, expr_linter::Chunk},
};

#[derive(PartialEq)]
enum Prefer {
    Circle,
    Cycle,
    DontCare,
}

pub struct ViciousCircle {
    expr: Box<dyn Expr>,
}
pub struct ViciousCycle {
    expr: Box<dyn Expr>,
}
pub struct ViciousCircleOrCycle {
    expr: Box<dyn Expr>,
}

// The Expr must have all three tokens because they should only be flagged when used together.
// But we don't want to flag the legitimate combinations, and which those are depends on the user's preferences.
fn build_expr(flag: Prefer) -> Box<dyn Expr> {
    let seq = SequenceExpr::word_set(&["vicious", "virtuous", "viscous"])
        .t_ws()
        .then_word_set(&["circle", "circles", "cycle", "cycles"]);

    match flag {
        Prefer::Circle => Box::new(
            seq.and_not(
                SequenceExpr::default()
                    .then_word_except(&["viscous"])
                    .t_ws()
                    .then_word_set(&["circle", "circles"]),
            ),
        ),
        Prefer::Cycle => Box::new(
            seq.and_not(
                SequenceExpr::default()
                    .then_word_except(&["viscous"])
                    .t_ws()
                    .then_word_set(&["cycle", "cycles"]),
            ),
        ),
        Prefer::DontCare => {
            Box::new(seq.and_not(SequenceExpr::default().then_word_except(&["viscous"])))
        }
    }
}

fn to_lint(toks: &[Token], src: &[char], pref: Prefer) -> Option<Lint> {
    let tokspan = toks.span()?;
    let (adjtok, nountok) = (toks.first()?, toks.last()?);

    let badadj = adjtok
        .span
        .get_content(src)
        .eq_ignore_ascii_case_chars(&['v', 'i', 's', 'c', 'o', 'u', 's']);

    let badnoun = match pref {
        Prefer::Circle => nountok
            .span
            .get_content(src)
            .starts_with_ignore_ascii_case_str("cycle"),
        Prefer::Cycle => nountok
            .span
            .get_content(src)
            .starts_with_ignore_ascii_case_str("circle"),
        Prefer::DontCare => false,
    };

    let is_plural = matches!(nountok.span.get_content(src).last(), Some('s' | 'S'));

    // The noun doesn't match the user's preferred word.
    if badnoun && !badadj {
        return Some(Lint {
            span: nountok.span,
            lint_kind: LintKind::Usage,
            suggestions: vec![Suggestion::replace_with_match_case_str(
                match (&pref, is_plural) {
                    (Prefer::Circle, false) => "circle",
                    (Prefer::Circle, true) => "circles",
                    (Prefer::Cycle, false) => "cycle",
                    (Prefer::Cycle, true) => "cycles",
                    _ => unreachable!(),
                },
                nountok.span.get_content(src),
            )],
            message: if pref == Prefer::Circle {
                "This idiom originally used `circle`, not `cycle`".to_string()
            } else {
                "Though this idiom originally used `circle`, `cycle` is preferred.".to_string()
            },
            ..Default::default()
        });
    }

    // The noun doesn't match the user's preference *and* the adjective also needs to be corrected from "viscous" to "vicious"
    if badnoun && badadj {
        let nouns = &["circle", "cycle"];
        let i = match pref {
            Prefer::Circle => 0,
            Prefer::Cycle => 1,
            Prefer::DontCare => return None, // Unreachable, but we don't risk crashing the LSP.
        };

        let message = format!(
            "The idiom uses the word `vicious`, not `viscous`, which describes thick liquids. And we prefer `{}` over `{}`.",
            nouns[i],
            nouns[1 - i],
        );

        return Some(Lint {
            span: tokspan,
            lint_kind: LintKind::Usage,
            suggestions: vec![Suggestion::replace_with_match_case_str(
                match (&pref, is_plural) {
                    (Prefer::Circle, false) => "vicious circle",
                    (Prefer::Circle, true) => "vicious circles",
                    (Prefer::Cycle, false) => "vicious cycle",
                    (Prefer::Cycle, true) => "vicious cycles",
                    _ => return None, // Unreachable, but we don't risk crashing the LSP.
                },
                tokspan.get_content(src),
            )],
            message,
            ..Default::default()
        });
    }

    // Nouns are fine, but we need to correct "viscous" to "vicious".
    if badadj {
        return Some(Lint {
            span: adjtok.span,
            lint_kind: LintKind::Usage,
            suggestions: vec![Suggestion::replace_with_match_case_str(
                "vicious",
                adjtok.span.get_content(src),
            )],
            message:
                "The idiom uses the word `vicious`, not `viscous`, which describes thick liquids."
                    .to_string(),
            ..Default::default()
        });
    }

    None
}

macro_rules! impl_expr_linter {
    ($name:ident, $pref:expr, $desc:expr) => {
        impl Default for $name {
            fn default() -> Self {
                Self {
                    expr: build_expr($pref),
                }
            }
        }

        impl ExprLinter for $name {
            type Unit = Chunk;

            fn description(&self) -> &str {
                $desc
            }

            fn match_to_lint(&self, toks: &[Token], src: &[char]) -> Option<Lint> {
                to_lint(toks, src, $pref)
            }

            fn expr(&self) -> &dyn Expr {
                self.expr.as_ref()
            }
        }
    };
}

impl_expr_linter!(
    ViciousCircle,
    Prefer::Circle,
    "Corrects and standardizes common errors and variants of `vicious/virtuous circle`."
);

impl_expr_linter!(
    ViciousCycle,
    Prefer::Cycle,
    "Corrects and standardizes common errors and variants of `vicious/virtuous cycle`."
);

impl_expr_linter!(
    ViciousCircleOrCycle,
    Prefer::DontCare,
    "Corrects common errors in `vicious/virtuous circle/cycle`."
);

#[cfg(test)]
mod tests {
    use super::{ViciousCircle, ViciousCircleOrCycle, ViciousCycle};
    use crate::linting::tests::{
        assert_no_lints, assert_suggestion_result, assert_top3_suggestion_result,
    };

    // Prefer "circle" -  Made up, simple examples

    #[test]
    fn vicious_singular() {
        assert_suggestion_result("vicious cycle", ViciousCircle::default(), "vicious circle");
    }
    #[test]
    fn vicious_plural() {
        assert_suggestion_result(
            "vicious cycles",
            ViciousCircle::default(),
            "vicious circles",
        );
    }
    #[test]
    fn viscous_singular() {
        assert_suggestion_result("viscous cycle", ViciousCircle::default(), "vicious circle");
    }
    #[test]
    fn viscous_plural() {
        assert_suggestion_result(
            "viscous cycles",
            ViciousCircle::default(),
            "vicious circles",
        );
    }

    #[test]
    fn ignore_vicious_singular() {
        assert_no_lints("vicious circle", ViciousCircle::default());
    }
    #[test]
    fn ignore_virtuous_plural() {
        assert_no_lints("virtuous circles", ViciousCircle::default());
    }

    // Prefer "circle" -  Real-world examples

    #[test]
    fn fix_singular_and_plural_nouns() {
        assert_top3_suggestion_result(
            "The file Vicious Cycle Dataset.ods contains 33 vicious cycles from 13 open source systems studied in our paper.",
            ViciousCircle::default(),
            "The file Vicious Circle Dataset.ods contains 33 vicious circles from 13 open source systems studied in our paper.",
        );
    }

    #[test]
    fn fix_virtuous() {
        assert_suggestion_result(
            "FlashInfer-Bench is a benchmark suite and production workflow designed to build a virtuous cycle of self-improving AI systems.",
            ViciousCircle::default(),
            "FlashInfer-Bench is a benchmark suite and production workflow designed to build a virtuous circle of self-improving AI systems.",
        );
    }

    // Prefer "cycle" - Made up, simple examples

    #[test]
    fn fix_singular() {
        assert_suggestion_result("vicious circle", ViciousCycle::default(), "vicious cycle");
    }
    #[test]
    fn fix_plural() {
        assert_suggestion_result(
            "virtuous circles",
            ViciousCycle::default(),
            "virtuous cycles",
        );
    }
    #[test]
    fn fix_viscous_singular() {
        assert_suggestion_result("viscous circle", ViciousCycle::default(), "vicious cycle");
    }
    #[test]
    fn fix_viscous_plural() {
        assert_suggestion_result("viscous circles", ViciousCycle::default(), "vicious cycles");
    }
    #[test]
    fn dont_flag_singular() {
        assert_no_lints("viscious cycle", ViciousCycle::default());
    }
    #[test]
    fn dont_flag_plural() {
        assert_no_lints("virtuous cycles", ViciousCycle::default());
    }

    // Prefer "cycle" -  Real-world examples

    #[test]
    fn fix_its_a_virtuous() {
        assert_suggestion_result(
            "It's a virtuous circle: if it's interesting to do a project, a person spends a lot of time on it",
            ViciousCycle::default(),
            "It's a virtuous cycle: if it's interesting to do a project, a person spends a lot of time on it",
        );
    }

    #[test]
    #[ignore = "Harper currently misinterprets the words around the ellipses as a hostname"]
    fn fix_viscous() {
        assert_suggestion_result(
            "However, adding it to $connectionsToTransact causes the tests to stop running...viscous circle.",
            ViciousCycle::default(),
            "However, adding it to $connectionsToTransact causes the tests to stop running...vicious cycle.",
        );
    }

    // No preference - both "circle" and "cycle" are fine.

    #[test]
    fn dont_flag_either() {
        assert_no_lints(
            "vicious circle, virtuous cycle, vicious cycles, virtuous circles",
            ViciousCircleOrCycle::default(),
        );
    }

    #[test]
    fn fix_both_viscous() {
        assert_suggestion_result(
            "viscous circle, viscous cycles",
            ViciousCircleOrCycle::default(),
            "vicious circle, vicious cycles",
        );
    }

    // No preference - Real-world examples

    #[test]
    fn dont_flag_combo() {
        assert_no_lints(
            "Instead of a vicious cycle, popularity creates a virtuous circle.",
            ViciousCircleOrCycle::default(),
        );
    }

    #[test]
    fn fix_its_a_viscous_cycle() {
        assert_suggestion_result(
            "Its a viscous cycle that started back in 1.13 for a few plugins but is now hurting every single world generation plugin",
            ViciousCircleOrCycle::default(),
            "Its a vicious cycle that started back in 1.13 for a few plugins but is now hurting every single world generation plugin",
        );
    }
}



================================================
FILE: harper-core/src/linting/weir_rules/ACoupleMore.weir
================================================
expr main (a couple of more)

let message "The correct wording is `a couple more`, without the `of`."
let description "Corrects `a couple of more` to `a couple more`."
let kind "Redundancy"
let becomes "a couple more"

test "There are a couple of more rules that could be added, how can I contribute?" "There are a couple more rules that could be added, how can I contribute?"



================================================
FILE: harper-core/src/linting/weir_rules/AdNauseam.weir
================================================
expr main (as nauseam)

let message "This phrase comes from Latin, where `ad` means `to`."
let description "Corrects `as nauseam` to `ad nauseam`."
let kind "Spelling"
let becomes "ad nauseam"

test "As you say, discussed as nauseam, but no nearer a solution." "As you say, discussed ad nauseam, but no nearer a solution."
test "no more autism please, hearing about it as nauseam is starting to make me sick" "no more autism please, hearing about it ad nauseam is starting to make me sick"



================================================
FILE: harper-core/src/linting/weir_rules/AfterAll.weir
================================================
expr main (afterall)

let message "Did you mean `after all`?"
let description "Corrects `afterall` to `after all`."
let kind "BoundaryError"
let becomes "after all"

test "I hope it will pop up afterall but that remains to be seen." "I hope it will pop up after all but that remains to be seen."



================================================
FILE: harper-core/src/linting/weir_rules/AfterAWhile.weir
================================================
expr main (after while)

let message "When describing a timeframe, use `a while`."
let description "Corrects the missing article in `after while`, forming `after a while`."
let kind "Grammar"
let becomes "after a while"

test "bromite Crashes on all sites after while." "bromite Crashes on all sites after a while."



================================================
FILE: harper-core/src/linting/weir_rules/AheadAnd.weir
================================================
expr main (ahead an)

let message "Did you make a typo? Shouldn't it be `and`?"
let description "Corrects `an` to `and` after `ahead`."
let becomes "ahead and"

test "If it's important, go ahead an open an issue." "If it's important, go ahead and open an issue."



================================================
FILE: harper-core/src/linting/weir_rules/AllOfASudden.weir
================================================
expr main [(all of the sudden), (all of sudden), (all the sudden)]

let message "Prefer the standard phrasing `all of a sudden`."
let description "Guides this expression toward the standard `all of a sudden`."
let kind "Nonstandard"
let becomes "all of a sudden"

test "On an app that has been released since December, all of the sudden around February 5th ANRs started going up." "On an app that has been released since December, all of a sudden around February 5th ANRs started going up."
test "It happened all the sudden when the lights went out." "It happened all of a sudden when the lights went out."
test "All the sudden the room fell quiet." "All of a sudden the room fell quiet."
test "The music stopped, all the sudden, during the chorus." "The music stopped, all of a sudden, during the chorus."
test "Did the power cut all the sudden?" "Did the power cut all of a sudden?"
test "He whispered, \"all the sudden we were alone.\"" "He whispered, \"all of a sudden we were alone.\""
test "ALL THE SUDDEN THE ROOM WENT DARK." "ALL OF A SUDDEN THE ROOM WENT DARK."
test "They were laughing all the sudden." "They were laughing all of a sudden."
test "It stormed all of sudden after a warm morning." "It stormed all of a sudden after a warm morning."
allows "Their excitement and suddenness were all the suddenness she remembered."
test "This all the sudden change surprised everyone." "This all of a sudden change surprised everyone."



================================================
FILE: harper-core/src/linting/weir_rules/Alongside.weir
================================================
expr main (along side)

let message "Use the single word `alongside`."
let description "Replaces the spaced form `along side` with `alongside`."
let kind "WordChoice"
let becomes "alongside"

test "They walked along side the river." "They walked alongside the river."
test "Along side the road, we saw a parade." "Alongside the road, we saw a parade."
test "The banner read ALONG SIDE THE TEAM!" "The banner read ALONGSIDE THE TEAM!"
test "The skiff pulled along side." "The skiff pulled alongside."
test "\"We drifted along side,\" she said." "\"We drifted alongside,\" she said."
test "They stood along side, waiting patiently." "They stood alongside, waiting patiently."
test "Cars lined up along side the curb." "Cars lined up alongside the curb."
allows "They walked alongside the river."
allows "They walked along the side of the river."
allows "We camped along the lakeside all weekend."


================================================
FILE: harper-core/src/linting/weir_rules/ALongTime.weir
================================================
expr main (along time)

let message "Use `a long time` for referring to a duration of time."
let description "Corrects `along time` to `a long time`."
let kind "Grammar"
let becomes "a long time"

test "along time" "a long time"
test "Fast refreshing is very slow had to wait along time for it to update." "Fast refreshing is very slow had to wait a long time for it to update."



================================================
FILE: harper-core/src/linting/weir_rules/AlzheimersDisease.weir
================================================
expr main (old-timers' disease)

let message "Use the correct medical term."
let description "Fixes the common misnomer `old-timers' disease`, ensuring the correct medical term `Alzheimer’s disease` is used."
let kind "Eggcorn"
let becomes "Alzheimer’s disease"




================================================
FILE: harper-core/src/linting/weir_rules/AnAnother.weir
================================================
expr main [(an another), (a another)]

let message "Use `another` on its own."
let description "Corrects `an another` and `a another`."
let kind "Redundancy"
let becomes "another"

test "Render shader to use it as texture in an another shader." "Render shader to use it as texture in another shader."
test "Audit login is a another package for laravel framework." "Audit login is another package for laravel framework."



================================================
FILE: harper-core/src/linting/weir_rules/AnotherAn.weir
================================================
expr main (another an)

let message "Use `another` on its own."
let description "Corrects `another an` to `another`."
let kind "Redundancy"
let becomes "another"

test "Yet another an atomic deployment tool." "Yet another atomic deployment tool."



================================================
FILE: harper-core/src/linting/weir_rules/AnotherOnes.weir
================================================
expr main (another ones)

let message "`another` is singular but `ones` is plural. Or maybe you meant the possessive `one's`."
let description "Corrects `another ones`."
let kind "Agreement"
let becomes ["another one", "another one's", "other ones"]

test "Change list params of a resource, another ones change too" "Change list params of a resource, other ones change too"



================================================
FILE: harper-core/src/linting/weir_rules/AnotherThings.weir
================================================
expr main (another things)

let message "`another` is singular but `things` is plural."
let description "Corrects `another things`."
let kind "Agreement"
let becomes ["another thing", "other things"]

test "Another things to fix in the Mask editor" "Other things to fix in the Mask editor"



================================================
FILE: harper-core/src/linting/weir_rules/AOkHyphen.weir
================================================
expr main a [ok, okay]

let message "Use `A-OK` when stating that something is acceptable or ready."
let description "Replaces the loose article-plus-abbreviation pairing with the standard hyphenated form whenever a linking verb describes readiness or approval."
let kind "Style"
let becomes "A-OK"

test "I am a ok with the plan." "I am a-ok with the plan."
test "We are totally a ok team before the launch." "We are totally a-ok team before the launch."
test "The crew was pretty a okay about the repairs." "The crew was pretty a-ok about the repairs."
test "It will be a ok once the update reaches the fleet." "It will be a-ok once the update reaches the fleet."
test "You are very a ok partner for the call." "You are very a-ok partner for the call."
test "This is almost a ok outcome for the holiday." "This is almost a-ok outcome for the holiday."
test "I am just a okay voice on the call." "I am just a-ok voice on the call."
test "We were really a ok group at the summit." "We were really a-ok group at the summit."
test "It is a ok moment to decide." "It is a-ok moment to decide."
test "The product is pretty a ok example of resilience." "The product is pretty a-ok example of resilience."
test "The service was totally a okay signal." "The service was totally a-ok signal."
test "Are you a ok with this change?" "Are you a-ok with this change?"
test "It is A OK to proceed." "It is A-OK to proceed."
test "I was a ok support while the team was busy." "I was a-ok support while the team was busy."
test "You were totally a ok host." "You were totally a-ok host."
test "Being a ok line of communication matters." "Being a-ok line of communication matters."
test "It has been a ok solution in the past." "It has been a-ok solution in the past."

allows "The dashboard shows A-OK feedback."
allows "Our status is OK."
allows "This is a good plan."
allows "AOK signals readiness."


================================================
FILE: harper-core/src/linting/weir_rules/AsFarBackAs.weir
================================================
expr main (as early back as)

let message "Use `as far back as` for referring to a time in the past."
let description "Corrects nonstandard `as early back as` to `as far back as`."
let kind "WordChoice"
let becomes "as far back as"

test "as early back as" "as far back as"
test "skin overrides also supports a wide variety of minecraft versions - as early back as 1.14.4." "skin overrides also supports a wide variety of minecraft versions - as far back as 1.14.4."



================================================
FILE: harper-core/src/linting/weir_rules/AsFollows.weir
================================================
expr main (as follow)

let message "Use `as follows`."
let description "Corrects the phrase `as follow`, which is sometimes produced by overcorrection. While it appeared briefly in 19th-century English, it is now considered archaic; modern standard usage requires `as follows` regardless of number."
let kind "Grammar"
let becomes "as follows"

test "The main points are as follow:" "The main points are as follows:"
test "Please read the steps as follow before you begin." "Please read the steps as follows before you begin."
test "As follow you requested, I have compiled the list." "As follows you requested, I have compiled the list."
test "I write this as follow for future reference." "I write this as follows for future reference."
test "as follow" "as follows"
test "AS FOLLOW" "AS FOLLOWS"
test "The instructions are listed as follow in the appendix." "The instructions are listed as follows in the appendix."
test "We were told as follow the timeline would slip." "We were told as follows the timeline would slip."
test "Is this description as follow the sample?" "Is this description as follows the sample?"
test "You can verify as follow once the build completes." "You can verify as follows once the build completes."

# Ensure unrelated uses of "follow" are not affected
allows "Follow the instructions as written."
allows "We follow-up on these requests weekly."
allows "This is the way to follow as best you can."
allows "As follows the plan will unfold."
allows "I will follow your lead."
allows "The as follows section is helpful."


================================================
FILE: harper-core/src/linting/weir_rules/AsIfThough.weir
================================================
expr main (as if though)

let message "This should be `as if` or `as though`."
let description "Corrects redundant `as if though`."
let kind "Redundancy"
let becomes ["as if", "as though"]

test "It's coming back to you. and looking as if though it's very bright red." "It's coming back to you. and looking as if it's very bright red."
test "it passes right on by it as if though nothing happened." "it passes right on by it as though nothing happened."



================================================
FILE: harper-core/src/linting/weir_rules/AsItHappens.weir
================================================
expr main (as it so happens)

let message "Did you mean `as it happens`?"
let description "Corrects `as it so happens` to `as it happens`."
let kind "Usage"
let becomes "as it happens"

test "As it so happens, we have language currently in review that basically states that a major version break means backwards incompatibility ..." "As it happens, we have language currently in review that basically states that a major version break means backwards incompatibility ..."



================================================
FILE: harper-core/src/linting/weir_rules/AsLongAs.weir
================================================
expr main (aslong as)

let message "`As long` should be written as two words."
let description "Corrects `aslong as` to `as long as`."
let kind "BoundaryError"
let becomes "as long as"

test "server loads up fine but cant log on client side aslong as the plugin is installed" "server loads up fine but cant log on client side as long as the plugin is installed"



================================================
FILE: harper-core/src/linting/weir_rules/AsOfCurrently.weir
================================================
expr main (as of currently)

let message "Standard equivalents are `currently` or `as of now`."
let description "Corrects `as of currently` to `currently` or `as of now`."
let kind "WordChoice"
let becomes ["currently", "as of now"]

test "Note that, as of currently, selecting a method on the list leaves it highlighted as such, until the script is changed." "Note that, currently, selecting a method on the list leaves it highlighted as such, until the script is changed."
test "As of currently, Cervo offers a set of inferers, noise generators (for continuous-action/parametrized policies), and a unified asset format." "As of now, Cervo offers a set of inferers, noise generators (for continuous-action/parametrized policies), and a unified asset format."


================================================
FILE: harper-core/src/linting/weir_rules/AsOfLately.weir
================================================
expr main (as of lately)

let message "Standard equivalents are `lately` or `as of late`."
let description "Corrects `as of lately` to `lately` or `as of late`."
let kind "WordChoice"
let becomes ["lately", "as of late"]

test "I haven't noticed any crashing with AMDGPU as of lately, so this looks to not be an issue anymore." "I haven't noticed any crashing with AMDGPU as of late, so this looks to not be an issue anymore."
test "As of lately, I've been more active on Gitlab." "As of late, I've been more active on Gitlab."



================================================
FILE: harper-core/src/linting/weir_rules/AsOpposedTo.weir
================================================
expr main (as oppose to)

let message "Did you mean `as opposed to`?"
let description "Corrects `as oppose to` to `as opposed to`."
let kind "Usage"
let becomes "as opposed to"

test "Distorted image upon opening the app as oppose to running the app after successful build" "Distorted image upon opening the app as opposed to running the app after successful build"



================================================
FILE: harper-core/src/linting/weir_rules/AtFaceValue.weir
================================================
expr main (on face value)

let message "`at face value is more idiomatic and more common."
let description "Corrects `on face value` to the more usual `at face value`."
let kind "WordChoice"
let becomes "at face value"

test "Obviously what you want is possible and on face value it's a trivial change on our end." "Obviously what you want is possible and at face value it's a trivial change on our end."



================================================
FILE: harper-core/src/linting/weir_rules/AtTheEndOfTheDay.weir
================================================
expr main (in the end of the day)

let message "Did you mean `at the end of the day`?"
let description "Corrects `in the end of the day` to `at the end of the day`."
let kind "WordChoice"
let becomes "at the end of the day"

test "In the end of the day, it's not a big deal." "At the end of the day, it's not a big deal."



================================================
FILE: harper-core/src/linting/weir_rules/AvoidAndAlso.weir
================================================
expr main (and also)

let message "Consider using just `and`."
let description "Reduces redundancy by replacing `and also` with `and`."
let kind "Redundancy"
let becomes "and"




================================================
FILE: harper-core/src/linting/weir_rules/BadRap.weir
================================================
expr main [(bed rap), (bad rep)]

let message "Did you mean `bad rap`?"
let description "Changes `bed rap` to the proper idiom `bad rap`."
let kind "Eggcorn"
let becomes "bad rap"

test "bad rep" "bad rap"



================================================
FILE: harper-core/src/linting/weir_rules/BanTogether.weir
================================================
expr main (ban together)

let message "Did you mean `band together`?"
let description "Detects and corrects the common error of using `ban together` instead of the idiom `band together`, which means to unite or join forces."
let kind "Eggcorn"
let becomes "band together"




================================================
FILE: harper-core/src/linting/weir_rules/BareInMind.weir
================================================
expr main (bare in mind)

let message "Did you mean `bear in mind`?"
let description "Ensures the phrase `bear in mind` is used correctly instead of `bare in mind`."
let kind "Eggcorn"
let becomes "bear in mind"




================================================
FILE: harper-core/src/linting/weir_rules/BatedBreath.weir
================================================
expr main (baited breath)

let message "Did you mean `bated breath`?"
let description "Changes `baited breath` to the correct `bated breath`."
let kind "Eggcorn"
let becomes "bated breath"

test "baited breath" "bated breath"



================================================
FILE: harper-core/src/linting/weir_rules/BeckAndCall.weir
================================================
expr main (back and call)

let message "Did you mean `beck and call`?"
let description "Fixes `back and call` to `beck and call`."
let kind "Eggcorn"
let becomes "beck and call"




================================================
FILE: harper-core/src/linting/weir_rules/BeenThere.weir
================================================
expr main (bee there)

let message "Did you mean `been there`?"
let description "Corrects the misspelling `bee there` to the proper phrase `been there`."
let kind "Typo"
let becomes "been there"




================================================
FILE: harper-core/src/linting/weir_rules/Beforehand.weir
================================================
expr main [(before hand), (before-hand)]

let message "Prefer the single-word adverb `beforehand`."
let description "`Beforehand` functions as a fixed adverb meaning ‘in advance’; writing it as two words or with a hyphen is nonstandard and can jar readers."
let becomes "beforehand"

test "Let me know before hand if you will attend." "Let me know beforehand if you will attend."
test "I prepared the documents before-hand." "I prepared the documents beforehand."
allows "We finished the preparations beforehand."


================================================
FILE: harper-core/src/linting/weir_rules/BesideThePoint.weir
================================================
expr main (besides the point)

let message "Use `beside` in the idiom `beside the point`."
let description "Corrects `besides the point` to `beside the point`."
let kind "Eggcorn"
let becomes "beside the point"

test "we kind of focus on GPUs a lot but uh that's besides the point so uh sometime ago" "we kind of focus on GPUs a lot but uh that's beside the point so uh sometime ago"



================================================
FILE: harper-core/src/linting/weir_rules/BestRegards.weir
================================================
expr main (beat regards)

let message "Use `best regards` to convey sincere well wishes in a closing."
let description "In valedictions, `best` expresses your highest regard—avoid the typo `beat regards`."
let kind "Typo"
let becomes "best regards"




================================================
FILE: harper-core/src/linting/weir_rules/BetterOffWith.weir
================================================
expr main (better of with)

let message "This phrase uses the word `off`."
let description "Corrects `better of with` to `better off with`."
let kind "Typo"
let becomes "better off with"

test "If you're wanting dynamic meta data, your might be better of with getServerSideProps ." "If you're wanting dynamic meta data, your might be better off with getServerSideProps ."


================================================
FILE: harper-core/src/linting/weir_rules/BewareOf.weir
================================================
expr main [(beware with regard to), (beware about), (beware with), (beware regarding), (beware concerning), (beware against), (beware for), (beware in), (beware on), (beware at), (beware among), (beware between)]

let message "Use `beware of` when naming the object you want readers to avoid."
let description "The verb `beware` naturally pairs with `of` before the noun being warned about, so swap other prepositions for clarity."
let kind "Usage"
let becomes "beware of"
let strategy "MatchCase"

test "Beware about scams that arrive by email." "Beware of scams that arrive by email."
test "beware with the loose wires behind the TV." "beware of the loose wires behind the TV."
test "Beware with regard to the rusted railing." "Beware of the rusted railing."
test "Beware regarding the crumbling guardrail." "Beware of the crumbling guardrail."
test "Beware concerning the expired coupon." "Beware of the expired coupon."
test "Beware against mixing cleaning chemicals." "Beware of mixing cleaning chemicals."
test "Beware for the slippery tile near the pool." "Beware of the slippery tile near the pool."
test "Beware in the area where the fog hides the cliffs." "Beware of the area where the fog hides the cliffs."
test "Beware on the step that squeaks." "Beware of the step that squeaks."
test "Beware at that crossing when traffic is heavy." "Beware of that crossing when traffic is heavy."
test "Beware among the wild animals outside the park." "Beware of the wild animals outside the park."
test "Beware between the gaps in the scaffolding." "Beware of the gaps in the scaffolding."
test "BEWARE WITH THE LOUD CRASHING." "BEWARE OF THE LOUD CRASHING."

allows "Beware of the dog that guards the porch."
allows "Beware the gap between the platforms."
allows "Beware every time you go near the cliff."
allows "Some people say beware: the path narrows."
allows "Beware of tall waves on this beach."


================================================
FILE: harper-core/src/linting/weir_rules/BlanketStatement.weir
================================================
expr main (blanketed statement)

let message "Use the more idiomatic phrasing."
let description "Corrects common errors in the phrase `blanket statement`."
let kind "Usage"
let becomes "blanket statement"

test "This seems like a blanketed statement and I have not found any info to back up whether PyJWT is affected." "This seems like a blanket statement and I have not found any info to back up whether PyJWT is affected."



================================================
FILE: harper-core/src/linting/weir_rules/Brutality.weir
================================================
expr main (brutalness)

let message "This word has a more standard, more common synonym."
let description "Suggests the more standard and common synonym `brutality`."
let kind "WordChoice"
let becomes "brutality"

test "the mildness and brutalness of the story rises." "the mildness and brutality of the story rises."



================================================
FILE: harper-core/src/linting/weir_rules/BuiltIn.weir
================================================
expr main [(in built), (in-built), (built in)]

let message "Prefer the hyphenated compound `built-in`."
let description "English convention treats `built-in` as a single, attributive adjective—meaning something integrated from the outset—whereas other forms like `in built` are nonstandard and can feel awkward to readers."
let becomes "built-in"
let kind "Punctuation"




================================================
FILE: harper-core/src/linting/weir_rules/ByAccident.weir
================================================
expr main (on accident)

let message "Did you mean `by accident`?"
let description "Incorrect preposition: `by accident` is the idiomatic expression."
let kind "Usage"
let becomes "by accident"




================================================
FILE: harper-core/src/linting/weir_rules/CanBeSeen.weir
================================================
expr main (can be seem)

let message "Did you mean `can be seen`?"
let description "Corrects `can be seem` to the proper phrase `can be seen`."
let kind "Typo"
let becomes "can be seen"




================================================
FILE: harper-core/src/linting/weir_rules/CaseInPoint.weir
================================================
expr main (case and point)

let message "`Case in point` is the correct form of the phrase."
let description "Corrects `case and point` to `case in point`."
let kind "Malapropism"
let becomes "case in point"

test "They are just not as high of a priority as other tasks that user's are requesting for, a case and point is I have never ran into this issue." "They are just not as high of a priority as other tasks that user's are requesting for, a case in point is I have never ran into this issue."



================================================
FILE: harper-core/src/linting/weir_rules/CaseSensitive.weir
================================================
expr main (case sensitive)

let message "Use the hyphenated form for `case-sensitive`."
let description "Ensures `case-sensitive` is correctly hyphenated."
let kind "Punctuation"
let becomes "case-sensitive"




================================================
FILE: harper-core/src/linting/weir_rules/CondenseAllThe.weir
================================================
expr main (all of the)

let message "Consider simplifying to `all the`."
let description "Suggests removing `of` in `all of the` for a more concise phrase."
let kind "Redundancy"
let becomes "all the"




================================================
FILE: harper-core/src/linting/weir_rules/CoursingThroughVeins.weir
================================================
expr main (cursing through veins)

let message "In this idiom, blood `courses` (flows) through veins, not `curses`."
let description "In English idioms, `to course` means to flow rapidly—so avoid the eggcorn `cursing through veins.`"
let kind "Eggcorn"
let becomes "coursing through veins"

test "cursing through veins" "coursing through veins"
test "It felt like the drugs were cursing through veins." "It felt like the drugs were coursing through veins."
allows "He was cursing through the entire meeting."


================================================
FILE: harper-core/src/linting/weir_rules/Cybersec.weir
================================================
expr main (cybersec)

let message "Use `cybersecurity` instead of `cybersec`."
let description "Expands the informal abbreviation `cybersec` to `cybersecurity`."
let kind "Style"
let becomes "cybersecurity"
let strategy "MatchCase"

test "We hired a cybersec analyst." "We hired a cybersecurity analyst."
test "Cybersec teams are growing." "Cybersecurity teams are growing."
test "CYBERSEC is a priority." "CYBERSECURITY is a priority."
test "Our cybersec program needs funding." "Our cybersecurity program needs funding."
test "They focus on cybersec in healthcare." "They focus on cybersecurity in healthcare."
test "cybersec." "cybersecurity."
test "cybersec," "cybersecurity,"
test "cybersec?" "cybersecurity?"
test "cybersec!" "cybersecurity!"
test "The cybersec training starts Monday." "The cybersecurity training starts Monday."
test "A cybersec role opened today." "A cybersecurity role opened today."
test "We discussed cybersec risks." "We discussed cybersecurity risks."

test "Cybersecurity is important." "Cybersecurity is important."
test "cybersecurity is important." "cybersecurity is important."
test "This is about cyber-sec systems." "This is about cyber-sec systems."
test "We build cybersecops tooling." "We build cybersecops tooling."
test "The cybersecx team is separate." "The cybersecx team is separate."



================================================
FILE: harper-core/src/linting/weir_rules/DampSquib.weir
================================================
expr main (damp squid)

let message "Use the correct phrase for a disappointing outcome."
let description "Corrects the eggcorn `damp squid` to `damp squib`, ensuring the intended meaning of a failed or underwhelming outcome."
let kind "Eggcorn"
let becomes "damp squib"




================================================
FILE: harper-core/src/linting/weir_rules/DayAndAge.weir
================================================
expr main (day in age)

let message "Use `day and age` for referring to the present time."
let description "Corrects the eggcorn `day in age` to `day and age`, which properly means the current era or time period."
let kind "Eggcorn"
let becomes "day and age"




================================================
FILE: harper-core/src/linting/weir_rules/DegreesKelvin.weir
================================================
expr main [(degrees kelvin), (degrees Kelvin), (degree kelvin), (degree Kelvin)]

let message "Use `kelvins` when discussing the unit Kelvin."
let description "Corrects use of `degrees kelvin` to `kelvins`."
let kind "Usage"
let becomes ["kelvins", "kelvin"]

test "degrees kelvin" "kelvins"



================================================
FILE: harper-core/src/linting/weir_rules/DegreesKelvinSymbol.weir
================================================
expr main (°K)

let message "Use just the symbol `K` when discussing the unit Kelvin."
let description "Corrects use of `°K` to `K`."
let kind "Usage"
let becomes "K"

test "°K" "K"



================================================
FILE: harper-core/src/linting/weir_rules/DoIAdjective.weir
================================================
expr main <([(Do I [interested, excited, tired, ready, curious, comfortable, prepared, overwhelmed, confident, available, worried, annoyed, relieved, frustrated, surprised, anxious, calm, satisfied, concerned]), (Do I not [interested, excited, tired, ready, curious, comfortable, prepared, overwhelmed, confident, available, worried, annoyed, relieved, frustrated, surprised, anxious, calm, satisfied, concerned])]), Do>

let message "When describing how you feel, `I` pairs with `am`, not `do`."
let description "Swaps the helping verb `do` for `am` in `Do I <adjective>` questions so they use the correct linking verb."
let kind "Grammar"
let becomes "am"

test "Do I interested in music?" "Am I interested in music?"
test "Do I excited about the launch?" "Am I excited about the launch?"
test "Do I tired after the hike?" "Am I tired after the hike?"
test "Do I ready for the interview?" "Am I ready for the interview?"
test "Do I curious what they decide?" "Am I curious what they decide?"
test "Do I comfortable sharing that detail?" "Am I comfortable sharing that detail?"
test "Do I prepared to join the call?" "Am I prepared to join the call?"
test "Do I overwhelmed by the inbox?" "Am I overwhelmed by the inbox?"
test "Do I confident in that plan?" "Am I confident in that plan?"
test "Do I not interested in attending?" "Am I not interested in attending?"
test "Do I not ready yet?" "Am I not ready yet?"
test "do I concerned about the changes?" "am I concerned about the changes?"

allows "Do I want to help you?"
allows "Do I need to finish this tonight?"
allows "Do I have to explain everything?"
allows "Do I run the tests again?"
allows "Do I look like I'm not listening?"


================================================
FILE: harper-core/src/linting/weir_rules/DoNotWant.weir
================================================
expr main [(don't wan), (do not wan)]

let message "Use the full verb `want` after negation: `don't want` or `do not want.`"
let description "In English, negation still requires the complete verb form (`want`), so avoid truncating it to `wan.`"
let kind "Typo"
let becomes ["don't want", "do not want"]

test "I don't wan to pay for this." "I don't want to pay for this."
test "Don't Wan that option." "Don't Want that option."
allows "I don't want to leave."


================================================
FILE: harper-core/src/linting/weir_rules/DontCan.weir
================================================
expr main (don't can)

let message "The grammatically correct form is `can't` or `cannot`."
let description "Corrects `don't can` to `can't` or `cannot`."
let kind "Grammar"
let becomes ["can't", "cannot"]

test "And currently uh I'm looking at it when I don't can see it like you know where it is, right?" "And currently uh I'm looking at it when I can't see it like you know where it is, right?"



================================================
FILE: harper-core/src/linting/weir_rules/DoToDueTo.weir
================================================
expr main <([(![PRON, INTJ, PART, ADV, CCONJ, SCONJ, ADP, DET] do to [ADJ, NOUN, VERB, PROPN] NOUN), (![PRON, INTJ, PART, ADV, CCONJ, SCONJ, ADP, DET] do to DET * NOUN), (![PRON, INTJ, PART, ADV, CCONJ, SCONJ, ADP, DET] ADV do to [ADJ, NOUN, VERB, PROPN] NOUN), (![PRON, INTJ, PART, ADV, CCONJ, SCONJ, ADP, DET] ADV do to DET * NOUN)]), (do to)>

let message "Did you mean `due to`?"
let description "Corrects the typo `do to` when it is intended to mean `due to` in causal phrases."
let kind "Usage"
let becomes "due to"

test "Many restaurants will close do to the corona restrictions." "Many restaurants will close due to the corona restrictions."
test "The event was canceled do to bad weather." "The event was canceled due to bad weather."
test "Production stopped do to a supply shortage." "Production stopped due to a supply shortage."
test "Flights were delayed do to heavy fog." "Flights were delayed due to heavy fog."
test "The server rebooted do to power issues." "The server rebooted due to power issues."
test "They left early do to a family emergency." "They left early due to a family emergency."
test "The cancelation happened do to unexpected maintenance." "The cancelation happened due to unexpected maintenance."
test "Our plan changed do to the new policy." "Our plan changed due to the new policy."
test "The app crashed do to memory leaks." "The app crashed due to memory leaks."
test "Tickets sold quickly do to a viral post." "Tickets sold quickly due to a viral post."
test "It failed do to data loss." "It failed due to data loss."

allows "What did you do to the file?"
allows "Please do to the file what you did to the other one."
allows "Don't do to others what you wouldn't want done to you."
allows "We need to do to this spreadsheet what we did last week."
allows "She asked what the update would do to her settings."


================================================
FILE: harper-core/src/linting/weir_rules/DoubleNegative.weir
================================================
expr main <([(didn't), (did not), (did n't)] [need, have, want, make, take, get] no), no>

let message "With `didn't/did not`, using `no` creates a double negative; replace `no` with `any` to keep a single negation."
let description "Replaces the determiner `no` with `any` when it follows the auxiliary `didn't/did not` plus a main verb (e.g., have, need, want, make, take, get) so the clause contains only one negation."
let kind "Grammar"
let becomes "any"

test "I didn't have no idea what to say." "I didn't have any idea what to say."
test "She didn't want no trouble last night." "She didn't want any trouble last night."
test "He did not make no progress this week." "He did not make any progress this week."
test "We didn't take no for an answer." "We didn't take any for an answer."
test "They didn't get no signal from the device." "They didn't get any signal from the device."
test "You didn't need no permission to do that." "You didn't need any permission to do that."
test "I didn't have no choice after the meeting." "I didn't have any choice after the meeting."
test "I didn't want no part of it." "I didn't want any part of it."
test "The driver didn't take no excuses." "The driver didn't take any excuses."
test "I didn't have no time for that." "I didn't have any time for that."
test "I DIDN'T HAVE NO IDEA WHEN THIS WOULD END." "I DIDN'T HAVE ANY IDEA WHEN THIS WOULD END."
test "She did not make no progress yet." "She did not make any progress yet."

# Should not change when there's no double negative `no`
allows "I didn't have any idea what to do."
allows "I didn't say no to the invitation."
allows "She doesn't have any idea why the alarm rang."
allows "I did not see any sign of trouble."
allows "No friends came over."


================================================
FILE: harper-core/src/linting/weir_rules/EachAndEveryOne.weir
================================================
expr main (each and everyone)

let message "Use `each and every one` for referring to a group of people or things."
let description "Corrects `each and everyone` to `each and every one`."
let kind "BoundaryError"
let becomes "each and every one"

test "each and everyone" "each and every one"
test "I have modified each and everyone of them to keep only the best of the best!" "I have modified each and every one of them to keep only the best of the best!"



================================================
FILE: harper-core/src/linting/weir_rules/EggYolk.weir
================================================
expr main (egg yoke)

let message "Use `egg yolk` when you mean the yellow portion of an egg."
let description "Corrects the eggcorn `egg yoke`, replacing it with the standard culinary term `egg yolk`."
let kind "Eggcorn"
let becomes "egg yolk"

test "She whisked the egg yoke briskly." "She whisked the egg yolk briskly."
test "Egg yoke is rich in nutrients." "Egg yolk is rich in nutrients."
test "Add the EGG YOKE to the batter." "Add the EGG YOLK to the batter."
test "Separate the egg yoke, then fold it in." "Separate the egg yolk, then fold it in."
test "The runny egg yoke spilled over the toast." "The runny egg yolk spilled over the toast."
test "Blend the cream with each egg yoke before baking." "Blend the cream with each egg yolk before baking."
allows "The custard calls for one egg yolk."
allows "Reserve the egg yolks for later."
allows "The artisan carved a wooden yoke for the oxen."
allows "Crack the eggs so no yoke spills."


================================================
FILE: harper-core/src/linting/weir_rules/EludedTo.weir
================================================
expr main (eluded to)

let message "Did you mean `alluded to`?"
let description "Corrects `eluded to` to `alluded to` in contexts referring to indirect references."
let kind "Malapropism"
let becomes "alluded to"




================================================
FILE: harper-core/src/linting/weir_rules/EnMasse.weir
================================================
expr main [(on mass), (on masse), (in mass)]

let message "Did you mean `en masse`?"
let description "Detects variants like `on mass` or `in mass` and suggests `en masse`."
let kind "Eggcorn"
let becomes "en masse"

test "in mass" "en masse"



================================================
FILE: harper-core/src/linting/weir_rules/EnRoute.weir
================================================
expr main [(on route to), (in route to), (on-route to), (in-route to)]

let message "Did you mean `en route`?"
let description "Detects variants like `on route` or `in route` and suggests `en route`."
let kind "Eggcorn"
let becomes ["en route to", "en-route to"]

test "on route to" "en route to"
test "in route to" "en route to"
test "vehicles may already be on route to one end of a Shipment" "vehicles may already be en route to one end of a Shipment"
test "TF-South is in route to conduct SSE on the strike." "TF-South is en route to conduct SSE on the strike."
test "I ultimately just want a slight preference for matches that are on-route to correct cases like the above." "I ultimately just want a slight preference for matches that are en-route to correct cases like the above."



================================================
FILE: harper-core/src/linting/weir_rules/EverPresent.weir
================================================
expr main (ever present)

let message "Hyphenate `ever-present` when it functions as a compound adjective."
let description "Corrects the missing hyphen in `ever present` to the compound adjective `ever-present`."
let kind "Punctuation"
let becomes "ever-present"

test "ever present" "ever-present"
test "Distrust was an ever present tension in the negotiations." "Distrust was an ever-present tension in the negotiations."



================================================
FILE: harper-core/src/linting/weir_rules/EverSince.weir
================================================
expr main (every since)

let message "Did you mean `ever since`?"
let description "Corrects `every since` to `ever since`."
let kind "Typo"
let becomes "ever since"

test "einstein been real quiet every since this dropped" "einstein been real quiet ever since this dropped"



================================================
FILE: harper-core/src/linting/weir_rules/EveryOnceAndAgain.weir
================================================
expr main (every once and again)

let message "For things that happen only occasionaly use `every once in a while. For things that persistently happen use `once again`."
let description "Corrects `every once and again` to `every once in a while` or `once again`."
let kind "Usage"
let becomes ["every once in a while", "once again"]

test "Ys have been replaced with Ps, happens randomly every once and again with different letters" "Ys have been replaced with Ps, happens randomly every once in a while with different letters"



================================================
FILE: harper-core/src/linting/weir_rules/EveryTime.weir
================================================
expr main (everytime)

let message "`Everytime` as a single word is proscribed. Use `every time` instead."
let description "Corrects `everytime` to `every time`."
let kind "Usage"
let becomes "every time"

test "Init tool everytime a file in a directory is modified" "Init tool every time a file in a directory is modified"



================================================
FILE: harper-core/src/linting/weir_rules/Excellent.weir
================================================
expr main (very good)

let message "Vocabulary enhancement: use `excellent` instead of `very good`"
let description "Provides a stronger word choice by replacing `very good` with `excellent` for clarity and emphasis."
let kind "Enhancement"
let becomes "excellent"

test "Her results were very good this semester." "Her results were excellent this semester."
allows "The performance was excellent, drawing praise from all critics."
allows "He radiated a sense of very goodness in his charitable acts."
test "She generally gave herself very good advice" "She generally gave herself excellent advice"



================================================
FILE: harper-core/src/linting/weir_rules/ExpandBecause.weir
================================================
expr main (cuz)

let message "Use `because` instead of informal `cuz`"
let description "Expands the informal abbreviation `cuz` to the full word `because` for formality."
let kind "Style"
let becomes "because"

test "Stick around cuz I got a surprise for you at the end." "Stick around because I got a surprise for you at the end."



================================================
FILE: harper-core/src/linting/weir_rules/ExpandForward.weir
================================================
expr main (fwd)

let message "Use `forward` instead of `fwd`"
let description "Expands the abbreviation `fwd` to the full word `forward` for clarity."
let kind "Style"
let becomes "forward"

test "Now I look fwd to the interior, the color, etc." "Now I look forward to the interior, the color, etc."



================================================
FILE: harper-core/src/linting/weir_rules/ExpandMinimum.weir
================================================
expr main (min)

let message "Use `minimum` instead of `min`"
let description "Expands the abbreviation `min` to the full word `minimum` for clarity."
let kind "Style"
let becomes "minimum"




================================================
FILE: harper-core/src/linting/weir_rules/ExpandPrevious.weir
================================================
expr main (prev)

let message "Use `previous` instead of `prev`"
let description "Expands the abbreviation `prev` to the full word `previous` for clarity."
let kind "Style"
let becomes "previous"

test "Just change :after by :before in the code above. Otherwise, you'll see the default prev/next images + the font awesome chevrons.Read" "Just change :after by :before in the code above. Otherwise, you'll see the default previous/next images + the font awesome chevrons.Read"


================================================
FILE: harper-core/src/linting/weir_rules/ExpandWith.weir
================================================
expr main (w/)

let message "Use `with` instead of `w/`"
let description "Expands the abbreviation `w/` to the full word `with` for clarity."
let kind "Style"
let becomes "with"




================================================
FILE: harper-core/src/linting/weir_rules/ExpandWithout.weir
================================================
expr main (w/o)

let message "Use `without` instead of `w/o`"
let description "Expands the abbreviation `w/o` to the full word `without` for clarity."
let kind "Style"
let becomes "without"

test "She lacks w/o experience." "She lacks without experience."
test "He has w/o skills w/o knowledge." "He has without skills without knowledge."
test "The report includes w/o details." "The report includes without details."
allows "She works with out effort."
test "She’s w/o a plan." "She’s without a plan."



================================================
FILE: harper-core/src/linting/weir_rules/FaceFirst.weir
================================================
expr main (face first into)

let message "Should this be `face-first`?"
let description "Ensures `face first` is correctly hyphenated as `face-first` when used before `into`."
let kind "Punctuation"
let becomes "face-first into"




================================================
FILE: harper-core/src/linting/weir_rules/FairBit.weir
================================================
expr main (fare bit)

let message "A `decent amount` is a `fair bit`. `Fare` is the price of a ticket."
let description "Corrects malapropisms of `a fair bit`."
let kind "Eggcorn"
let becomes "fair bit"

test "I've read through a fare bit of the ecosystem framework, but I am not clear on what is modified..." "I've read through a fair bit of the ecosystem framework, but I am not clear on what is modified..."



================================================
FILE: harper-core/src/linting/weir_rules/FarAndFewBetween.weir
================================================
expr main (far and few between)

let message "The correct idiom is `few and far between`?"
let description "Corrects `far and few between` to the standard idiom `few and far between`."
let kind "Eggcorn"
let becomes "few and far between"

test "Their neighbors were far and few between, which only made it even more unlikely that surveillance footage recovered from their properties could help." "Their neighbors were few and far between, which only made it even more unlikely that surveillance footage recovered from their properties could help."



================================================
FILE: harper-core/src/linting/weir_rules/FastPaste.weir
================================================
expr main [(fast paste), (fast-paste)]

let message "Did you mean `fast-paced`?"
let description "Detects incorrect usage of `fast paste` or `fast-paste` and suggests `fast-paced` as the correct phrase."
let kind "Eggcorn"
let becomes "fast-paced"




================================================
FILE: harper-core/src/linting/weir_rules/FatalOutcome.weir
================================================
expr main (fatal outcome)

let message "Consider using `death` for clarity."
let description "Replaces `fatal outcome` with the more direct term `death` for conciseness."
let kind "Style"
let becomes "death"




================================================
FILE: harper-core/src/linting/weir_rules/FetalPosition.weir
================================================
expr main (the feeble position)

let message "Use the correct term for a curled-up posture."
let description "Ensures the correct use of `fetal position`, avoiding confusion with `feeble position`, which is not a standard phrase."
let kind "Malapropism"
let becomes "the fetal position"




================================================
FILE: harper-core/src/linting/weir_rules/ForALongTime.weir
================================================
expr main (for along time)

let message "Use the standard phrase `for a long time` to indicate an extended duration."
let description "Eliminates the incorrect merging in `for along time`."
let kind "Grammar"
let becomes "for a long time"

test "I was stuck there for along time." "I was stuck there for a long time."



================================================
FILE: harper-core/src/linting/weir_rules/ForAWhile.weir
================================================
expr main (for while)

let message "When describing a timeframe, use `a while`."
let description "Corrects the missing article in `for while`, forming `for a while`."
let kind "Typo"
let becomes "for a while"

test "Build flutter releases in github actions for production only android for while." "Build flutter releases in github actions for production only android for a while."



================================================
FILE: harper-core/src/linting/weir_rules/FreeRein.weir
================================================
expr main (free reign)

let message "Use the correct phrase for unrestricted control."
let description "Ensures the correct use of `free rein`, avoiding confusion with `free reign`, which incorrectly suggests authority rather than freedom of action."
let kind "Eggcorn"
let becomes "free rein"




================================================
FILE: harper-core/src/linting/weir_rules/Freezing.weir
================================================
expr main [(very cold), (really cold), (extremely cold)]

let message "A more vivid adjective would better capture extreme cold."
let description "Encourages vivid writing by suggesting `freezing` instead of weaker expressions like `very cold.`"
let kind "Enhancement"
let becomes "freezing"




================================================
FILE: harper-core/src/linting/weir_rules/FromTheGetGo.weir
================================================
expr main (from the get go)

let message "Use the hyphenated form: `from the get-go`."
let description "Ensures `from the get-go` is correctly hyphenated, preserving the idiom’s meaning of ‘from the very beginning’."
let kind "Punctuation"
let becomes "from the get-go"




================================================
FILE: harper-core/src/linting/weir_rules/GildedAge.weir
================================================
expr main (guilded age)

let message "The period of economic prosperity is called the `Gilded Age`."
let description "If referring to the period of economic prosperity, the correct term is `Gilded Age`."
let kind "Eggcorn"
let becomes "Gilded Age"
let strategy "Exact"

test "It is especially a reflection of the socio-economic patterns in the Guilded Age." "It is especially a reflection of the socio-economic patterns in the Gilded Age."
test "It is especially a reflection of the socio-economic patterns in the guilded age." "It is especially a reflection of the socio-economic patterns in the Gilded Age."



================================================
FILE: harper-core/src/linting/weir_rules/GoingTo.weir
================================================
expr main (gong to)

let message "Did you mean `going to`?"
let description "Corrects `gong to` to the intended phrase `going to`."
let kind "Typo"
let becomes "going to"




================================================
FILE: harper-core/src/linting/weir_rules/GuineaBissau.weir
================================================
expr main (Guinea Bissau)

let message "The official spelling is hyphenated."
let description "Checks for the correct official name of the African country."
let kind "Punctuation"
let becomes "Guinea-Bissau"

test "Guinea Bissau" "Guinea-Bissau"



================================================
FILE: harper-core/src/linting/weir_rules/HadOf.weir
================================================
expr main (had of)

let message "Did you mean `had have` or `had've`?"
let description "Flags the unnecessary use of `of` after `had` and suggests the correct forms."
let kind "Grammar"
let becomes ["had have", "had've"]




================================================
FILE: harper-core/src/linting/weir_rules/HalfAnHour.weir
================================================
expr main (half an our)

let message "Remember the silent 'h' when writing `hour`: `half an hour`."
let description "Fixes the eggcorn `half an our` to the accepted `half an hour`."
let kind "Typo"
let becomes "half an hour"

test "It took half an our to get there." "It took half an hour to get there."



================================================
FILE: harper-core/src/linting/weir_rules/Haphazard.weir
================================================
expr main [(half hazard), (half-hazard), (halfhazard)]

let message "Use `haphazard` for randomness or lack of organization."
let description "Corrects the eggcorn `half hazard` to `haphazard`, which properly means lacking organization or being random."
let kind "Eggcorn"
let becomes "haphazard"




================================================
FILE: harper-core/src/linting/weir_rules/HeartToHeard.weir
================================================
expr main <([([have, has, had] [I, you, he, she, it, we, they] [heart, herd] [of, about, from, in, on, for, to, with]), ([have, has, had] [I, you, he, she, it, we, they] ADV [heart, herd] [of, about, from, in, on, for, to, with]), ([have, has, had] n't [I, you, he, she, it, we, they] [heart, herd] [of, about, from, in, on, for, to, with]), ([have, has, had] n't [I, you, he, she, it, we, they] ADV [heart, herd] [of, about, from, in, on, for, to, with]), ([have, has, had] DET NOUN ADV [heart, herd] [of, about, from, in, on, for, to, with]), ([have, has, had] n't DET NOUN ADV [heart, herd] [of, about, from, in, on, for, to, with]), ([haven't, hasn't, hadn't] [I, you, he, she, it, we, they] [heart, herd] [of, about, from, in, on, for, to, with]), ([haven't, hasn't, hadn't] [I, you, he, she, it, we, they] ADV [heart, herd] [of, about, from, in, on, for, to, with]), ([haven't, hasn't, hadn't] DET NOUN ADV [heart, herd] [of, about, from, in, on, for, to, with])]), [heart, herd]>

let message "Did you mean the verb `heard` (= past tense of `hear`)?"
let description "Corrects `heart` or `herd` to `heard` in common `have ... heard of/about` questions."
let kind "Usage"
let becomes "heard"

test "Have you heart of this band?" "Have you heard of this band?"
test "Have you herd of this band?" "Have you heard of this band?"
test "Have you ever heart of this band?" "Have you ever heard of this band?"
test "Have you ever herd of this band?" "Have you ever heard of this band?"
test "Has she heart of the update?" "Has she heard of the update?"
test "Has she ever heart of the update?" "Has she ever heard of the update?"
test "Had they heart of the plan?" "Had they heard of the plan?"
test "Have the police ever heart of this?" "Have the police ever heard of this?"
test "Have the staff ever herd of the policy?" "Have the staff ever heard of the policy?"
test "Haven't you heart of that movie?" "Haven't you heard of that movie?"
test "Haven't you ever herd of that movie?" "Haven't you ever heard of that movie?"
allows "Have you heard of this band?"
allows "Have the police heard of this?"
allows "Have the heart of this story been told?"
allows "I have a herd of cattle."
allows "I have heart of the matter already."


================================================
FILE: harper-core/src/linting/weir_rules/HeDos.weir
================================================
expr main <([(he dos), (he ADV dos), (she dos), (she ADV dos), (it dos), (it ADV dos)]), dos>

let message "Did you mean `does`?"
let description "Corrects the misspelling `dos` after `he`, `she`, or `it`."
let kind "Typo"
let becomes "does"

test "He dos not want to go." "He does not want to go."
test "She dos it." "She does it."
test "It dos work." "It does work."
test "he dos not like it." "he does not like it."
test "HE DOS IT." "HE DOES IT."
test "He just dos it." "He just does it."
test "She never dos that." "She never does that."
test "It really dos." "It really does."
test "He dos." "He does."
test "She dos, then she stops." "She does, then she stops."
allows "I dos it."
allows "They dos it."
allows "Dos is Spanish for two."
allows "He does it."
allows "He doso it."


================================================
FILE: harper-core/src/linting/weir_rules/HowMach.weir
================================================
expr main <(how [mach, match] !PUNCT), [mach, match]>

let message "Use `how much` when you're asking about quantity, not the brand name or verb."
let description "Swaps `how mach` or `how match` with the correct quantifier `how much`."
let kind "Typo"
let becomes "much"

test "Do you know how mach it weighs?" "Do you know how much it weighs?"
test "Tell me how match sugar you want." "Tell me how much sugar you want."
test "How mach are we supposed to study?" "How much are we supposed to study?"
test "How match time have we spent already?" "How much time have we spent already?"
test "He wondered how mach courage it takes." "He wondered how much courage it takes."
test "She asked how match water to add." "She asked how much water to add."
test "Ask how mach light you need." "Ask how much light you need."
test "How mach did you train for this race?" "How much did you train for this race?"
test "How match of those settings are legal?" "How much of those settings are legal?"
test "HOW MACH DO YOU WANT IT?" "HOW MUCH DO YOU WANT IT?"
allows "Now that we know how match() works, let's refactor."
allows "How Match.com Got Women to Sign Up for Online Dating."
allows "The engine develops 131.7kN and the speed of the aircraft is Mach 2."
allows "Tell me how much time you need."
allows "I can't decide how much of this to keep."


================================================
FILE: harper-core/src/linting/weir_rules/HumanBeings.weir
================================================
expr main [(human's beings), (humans beings)]

let message "Use `human beings` to refer to people collectively."
let description "Eliminates the incorrect possessive/plural usage like `human's beings` or `humans beings`."
let kind "Grammar"
let becomes "human beings"

test "All humans beings deserve empathy." "All human beings deserve empathy."
test "We should respect a human's beings fundamental rights." "We should respect a human beings fundamental rights."



================================================
FILE: harper-core/src/linting/weir_rules/HumanLife.weir
================================================
expr main (human live)

let message "Did you mean `human life`?"
let description "Changes `human live` to `human life`."
let kind "Typo"
let becomes "human life"




================================================
FILE: harper-core/src/linting/weir_rules/HungerPang.weir
================================================
expr main (hunger pain)

let message "Did you mean `hunger pang`?"
let description "Corrects `hunger pain` to `hunger pang`."
let kind "Eggcorn"
let becomes "hunger pang"

test "hunger pain" "hunger pang"



================================================
FILE: harper-core/src/linting/weir_rules/IAm.weir
================================================
expr main (I a m)

let message "Did you mean `I am`?"
let description "Fixes the incorrect spacing in `I a m` to properly form `I am`."
let kind "Typo"
let becomes "I am"




================================================
FILE: harper-core/src/linting/weir_rules/IDo.weir
================================================
expr main (I does)

let message "`I` pairs with the bare verb `do`; the –s inflection `does` is reserved for third-person singular subjects."
let description "Corrects `I does` to `I do`."
let kind "Agreement"
let becomes "I do"

test "I does enjoy writing Rust." "I do enjoy writing Rust."



================================================
FILE: harper-core/src/linting/weir_rules/InAnyWay.weir
================================================
expr main (in anyway)

let message "Use `in any way` for emphasizing a point."
let description "Corrects ungrammatical `in anyway` to `in any way`."
let kind "BoundaryError"
let becomes "in any way"

test "in anyway" "in any way"
test "The names should not affect your application in anyway and you can override extension names." "The names should not affect your application in any way and you can override extension names."



================================================
FILE: harper-core/src/linting/weir_rules/InAWhile.weir
================================================
expr main (in while)

let message "When describing a timeframe, use `a while`."
let description "Corrects the missing article in `in while`, forming `in a while`."
let kind "Grammar"
let becomes "in a while"

test "We’ll talk again in while." "We’ll talk again in a while."



================================================
FILE: harper-core/src/linting/weir_rules/Initiatively.weir
================================================
expr main initiatively

let message "Did you mean `proactive` (taking initiative, acting in advance) or `initially` (at first, in the beginning)?"
let description "Corrects nonstandard `initiatively`."
let kind "Nonstandard"
let becomes ["proactively", "initially"]

test "I have initiatively signed up for the course." "I have proactively signed up for the course."



================================================
FILE: harper-core/src/linting/weir_rules/InLieuOf.weir
================================================
expr main (in lue of)

let message "Did you mean `in lieu of`?"
let description "Corrects the misspelling `in lue of` to `in lieu of`."
let kind "Spelling"
let becomes "in lieu of"

test "Controller Emulation in lue of Direct Controller binding" "Controller Emulation in lieu of Direct Controller binding"



================================================
FILE: harper-core/src/linting/weir_rules/InNeedOf.weir
================================================
expr main (in need for)

let message "Use `in need of` for when something is required or necessary."
let description "Corrects `in need for` to `in need of`."
let kind "Usage"
let becomes "in need of"

test "In need for a native control for map symbols (map legend) #5203." "In need of a native control for map symbols (map legend) #5203."



================================================
FILE: harper-core/src/linting/weir_rules/InOfItself.weir
================================================
expr main (in of itself)

let message "Use `in itself` (more common) or `in and of itself` (more formal) to mean 'intrinsically'."
let description "Corrects nonstandard `in of itself` to standard `in itself` or `in and of itself`."
let kind "Usage"
let becomes ["in itself", "in and of itself"]

test "in of itself" "in and of itself"
test "This is not entirely unexpected in of itself, as Git and GitHub Desktop both generally prove fairly bad at delineating context intelligently..." "This is not entirely unexpected in and of itself, as Git and GitHub Desktop both generally prove fairly bad at delineating context intelligently..."



================================================
FILE: harper-core/src/linting/weir_rules/InOneFellSwoop.weir
================================================
expr main (in one foul swoop)

let message "Use the correct phrase for something happening suddenly."
let description "Corrects `in one foul swoop` to `in one fell swoop`, preserving the phrase’s original meaning of sudden and complete action."
let kind "Eggcorn"
let becomes "in one fell swoop"




================================================
FILE: harper-core/src/linting/weir_rules/Insensitive.weir
================================================
expr main (unsensitive)

let message "This word has a more standard, more common synonym."
let description "Suggests the more standard and common synonym `insensitive`."
let kind "WordChoice"
let becomes "insensitive"

test "We want to potentially make an unsensitive header" "We want to potentially make an insensitive header"



================================================
FILE: harper-core/src/linting/weir_rules/InsteadOf.weir
================================================
expr main (in stead of)

let message "Use the modern single word `instead of` to indicate a replacement."
let description "Corrects the archaic or mistaken separation `in stead of` to `instead of` in everyday usage."
let kind "BoundaryError"
let becomes "instead of"

test "He used water in stead of soda." "He used water instead of soda."
allows "He used water instead of soda."


================================================
FILE: harper-core/src/linting/weir_rules/Insurmountable.weir
================================================
expr main (unsurmountable)

let message "This word has a more standard, more common synonym."
let description "Suggests the more standard and common synonym `insurmountable`."
let kind "WordChoice"
let becomes "insurmountable"

test "That being said, if you find upgrading to newer versions to be unsurmountable, please open an issue." "That being said, if you find upgrading to newer versions to be insurmountable, please open an issue."



================================================
FILE: harper-core/src/linting/weir_rules/Intact.weir
================================================
expr main (in tact)

let message "Use `intact` to mean undamaged or whole."
let description "Prevents the erroneous spacing in `in tact`; `intact` is the single correct word."
let kind "BoundaryError"
let becomes "intact"

test "The code remains in tact after the merge." "The code remains intact after the merge."
allows "The data set remains intact."


================================================
FILE: harper-core/src/linting/weir_rules/InThe.weir
================================================
expr main (int he)

let message "Did you mean `in the`?"
let description "Detects and corrects a spacing error where `in the` is mistakenly written as `int he`. Proper spacing is essential for readability and grammatical correctness in common phrases."
let kind "Typo"
let becomes "in the"




================================================
FILE: harper-core/src/linting/weir_rules/IsKnownFor.weir
================================================
expr main (is know for)

let message "Did you mean `is known for`?"
let description "Typo: `known` is the correct past participle."
let kind "Typo"
let becomes "is known for"




================================================
FILE: harper-core/src/linting/weir_rules/ItCan.weir
================================================
expr main (It cam)

let message "Did you mean `It can`?"
let description "Corrects the misspelling `It cam` to the proper phrase `It can`."
let kind "Typo"
let becomes "It can"




================================================
FILE: harper-core/src/linting/weir_rules/IveGotTo.weir
================================================
expr main (I've go to)

let message "Use `I've got to` for necessity or obligation."
let description "Corrects the slip `I've go to` to the idiomatic `I've got to`."
let kind "Typo"
let becomes "I've got to"

test "I've go to finish this before Monday." "I've got to finish this before Monday."



================================================
FILE: harper-core/src/linting/weir_rules/JawDropping.weir
================================================
expr main (jar-dropping)

let message "Use the correct phrase for something astonishing."
let description "Corrects `jar-dropping` to `jaw-dropping`, ensuring the intended meaning of something that causes amazement."
let kind "Eggcorn"
let becomes "jaw-dropping"




================================================
FILE: harper-core/src/linting/weir_rules/JustDeserts.weir
================================================
expr main (just desserts)

let message "Use the correct phrase for receiving what one deserves."
let description "Ensures `just deserts` is used correctly, preserving its meaning of receiving an appropriate outcome for one's actions."
let kind "Spelling"
let becomes "just deserts"




================================================
FILE: harper-core/src/linting/weir_rules/KindOf.weir
================================================
expr main (kinda of)

let message "`Kinda` already means `kind of`, so `kinda of` is redundant."
let description "Corrects `kinda of` to `kind of`."
let kind "Redundancy"
let becomes ["kind of", "kinda"]

test "Some kinda of Sync issue only with 0.79.1" "Some kind of Sync issue only with 0.79.1"



================================================
FILE: harper-core/src/linting/weir_rules/KindRegards.weir
================================================
expr main (kid regards)

let message "Did you mean `kind regards`?"
let description "Changes `kid regards` to `kind regards`."
let kind "Typo"
let becomes "kind regards"




================================================
FILE: harper-core/src/linting/weir_rules/LastButNotLeast.weir
================================================
expr main [(last but not the least), (last, but not the least), (last but, not least), (last but not last)]

let message "Use the more idiomatic phrasing."
let description "Corrects common errors in the phrase `last but not least`."
let kind "Usage"
let becomes "last but not least"

test "Last but not the least, with VS2013 you can use Web Essentials 2013" "Last but not least, with VS2013 you can use Web Essentials 2013"
test "Last but not last, I'd like to thank my parents." "Last but not least, I'd like to thank my parents."



================================================
FILE: harper-core/src/linting/weir_rules/LastDitch.weir
================================================
expr main [(last ditch), (last ditched), (last-ditched)]

let message "In this idiom, `ditch` is a noun and a hyphen is needed."
let description "Corrects wrong variations of the idiomatic adjective `last-ditch`."
let kind "Usage"
let becomes "last-ditch"

test "I was actually just trying that as a last ditched attempt to get it working, previously those ..." "I was actually just trying that as a last-ditch attempt to get it working, previously those ..."
test "There are unique use cases and is meant to be a last ditch option." "There are unique use cases and is meant to be a last-ditch option."



================================================
FILE: harper-core/src/linting/weir_rules/LastNight.weir
================================================
expr main (yesterday night)

let message "The idiomatic phrase is `last night`."
let description "Flags `yesterday night` and suggests the standard phrasing `last night`."
let kind "WordChoice"
let becomes "last night"

test "I was there yesterday night." "I was there last night."
test "Yesterday night was fun." "Last night was fun."
test "Yesterday night, we watched a movie." "Last night, we watched a movie."
test "They left yesterday night after the show." "They left last night after the show."
allows "I remember last night clearly."


================================================
FILE: harper-core/src/linting/weir_rules/LaughOfAt.weir
================================================
expr main <([laugh, laughs, laughed, laughing] of [PRON, PROPN]), of>

let message "Use `laugh at ...` instead of `laugh of ...` when pointing at someone."
let description "Warns when `laugh` takes `of` before a person or pronoun and nudges writers toward the conventional `at`."
let kind "Usage"
let becomes "at"

test "I laugh of him." "I laugh at him."
test "She laughs of her teacher." "She laughs at her teacher."
test "They laughed of us in the hallway." "They laughed at us in the hallway."
test "He's laughing of them already." "He's laughing at them already."
test "We laugh of you whenever you wear that hat." "We laugh at you whenever you wear that hat."
test "Laugh of John while he waits." "Laugh at John while he waits."
test "Don't laugh of your teammate again." "Don't laugh at your teammate again."
test "The crowd laughs of Mary when she trips." "The crowd laughs at Mary when she trips."
test "I was laughing of Alex when the joke landed." "I was laughing at Alex when the joke landed."
test "They laugh of me even when I'm serious." "They laugh at me even when I'm serious."
allows "The laugh of the audience shook the rafters."
allows "That's the laugh of the most relentless critic."
allows "The laugh of the baby warmed everyone."
allows "We had a laugh of relief when it ended."
allows "A laugh of astonishment escaped him."
allows "Her laugh of disbelief made us pause."
allows "The laugh of a friend sounded distant."
allows "I savor the laugh of children playing outside."


================================================
FILE: harper-core/src/linting/weir_rules/LeaveToFor.weir
================================================
expr main <([leave, leaves, left, leaving] to [PROPN] [next, tomorrow, soon]), to>

let message "Use `for` when pointing a departure toward a place."
let description "When describing travel plans that include a destination and a time frame, prefer `leave for a destination` instead of `leave to a destination`."
let kind "Usage"
let becomes "for"
let strategy "MatchCase"

test "They are leaving to England soon." "They are leaving for England soon."
test "We leave to Japan tomorrow morning." "We leave for Japan tomorrow morning."
test "He leaves to Canada next week." "He leaves for Canada next week."
test "We're leaving to Morocco next fall." "We're leaving for Morocco next fall."
test "They're leaving to France tomorrow." "They're leaving for France tomorrow."
test "My team leaves to London soon for the conference." "My team leaves for London soon for the conference."
test "We are leaving to Brazil soon." "We are leaving for Brazil soon."
test "I leave to Spain next Monday." "I leave for Spain next Monday."
test "He left to Italy soon after the ceremony." "He left for Italy soon after the ceremony."
test "The crew is leaving to Paris soon." "The crew is leaving for Paris soon."
allows "I leave it to you."
allows "Leave it to me, and I'll handle it."
allows "We are leaving to the west soon."
allows "We left to surprise them."
allows "They leave to inform the board tomorrow."


================================================
FILE: harper-core/src/linting/weir_rules/LetAlone.weir
================================================
expr main (let along)

let message "Did you mean `let alone`?"
let description "Changes `let along` to `let alone`."
let kind "Typo"
let becomes "let alone"

test "let along" "let alone"



================================================
FILE: harper-core/src/linting/weir_rules/LikeAsIf.weir
================================================
expr main (like as if)

let message "Avoid redundancy. Use either `like` or `as if`."
let description "Corrects redundant `like as if` to `like` or `as if`."
let becomes ["like", "as if"]

test "And looks like as if linux-personality hasn't got any changes for 8 years." "And looks as if linux-personality hasn't got any changes for 8 years."
test "She looks like as if she’s tired." "She looks as if she’s tired."
test "He seems like as if he’s happy." "He seems as if he’s happy."
test "It feels like as if it’s a dream." "It feels as if it’s a dream."
allows "She acts like a hero."
test "She seems like as if she’s in love." "She seems as if she’s in love."



================================================
FILE: harper-core/src/linting/weir_rules/LikeThePlague.weir
================================================
expr main (like a plague)

let message "`Things are avoided `like the plague` not `like a plague`."
let description "Corrects `like a plague` to `like the plague`."
let kind "Usage"
let becomes "like the plague"

test "Below is the worst example of them all (avoid such coding like a plague):" "Below is the worst example of them all (avoid such coding like the plague):"



================================================
FILE: harper-core/src/linting/weir_rules/LinesOfCode.weir
================================================
expr main [(line of codes), (lines of codes)]

let message "The correct plural is `lines of code`."
let description "Corrects pluralizing the wrong noun in `lines of code`."
let kind "Usage"
let becomes "lines of code"

test "These are line of codes we should refactor." "These are lines of code we should refactor."
test "We removed several lines of codes yesterday." "We removed several lines of code yesterday."



================================================
FILE: harper-core/src/linting/weir_rules/LooksLikes.weir
================================================
expr main <([looks, looked, looking] likes), likes>

let message "Drop the extra `s` in `likes` when it immediately follows a form of `look`."
let description "This rule turns `looks likes`, `looked likes`, and `looking likes` into the idiomatic `look ... like`."
let kind "Typo"
let becomes "like"

test "It looks likes the same story." "It looks like the same story."
test "The memoir looked likes a diary." "The memoir looked like a diary."
test "The detective is looking likes the culprit." "The detective is looking like the culprit."
test "She looks likes, honestly, a champion." "She looks like, honestly, a champion."
test "LOOKS LIKES a bad omen." "LOOKS LIKE a bad omen."
test "It looked LIKES a mirage." "It looked LIKE a mirage."
test "He is looking LIKES his brother." "He is looking LIKE his brother."
test "Looks likes both people are arriving." "Looks like both people are arriving."
test "She looked likes, well there it is." "She looked like, well there it is."
test "Those who are looking likes a miracle never arrive." "Those who are looking like a miracle never arrive."
test "Looks  likes the worst scenario." "Looks  like the worst scenario."

allows "Looks like the winner."
allows "He likes to code every day."
allows "She looked like a star."
allows "I was looking carefully."
allows "I like how it looks."
allows "Like how he likes the team."


================================================
FILE: harper-core/src/linting/weir_rules/LowHangingFruit.weir
================================================
expr main [(low[-, ( )]hanging fruits), (low hanging fruit)]

let message "The standard form is `low-hanging fruit` with a hyphen and singular form."
let description "Corrects nonstandard variants of `low-hanging fruit`."
let kind "Usage"
let becomes "low-hanging fruit"

test "If you add me as a collaborator i can start merging some of the low hanging fruit." "If you add me as a collaborator i can start merging some of the low-hanging fruit."
test "Field guide to gather low-hanging fruits." "Field guide to gather low-hanging fruit."
test "Will search for low hanging fruits and useful information for escalation on a compromised workstation." "Will search for low-hanging fruit and useful information for escalation on a compromised workstation."



================================================
FILE: harper-core/src/linting/weir_rules/ManagerialReins.weir
================================================
expr main (managerial reigns)

let message "Swap in `reins` when talking about control of a team or project."
let description "Corrects the eggcorn `managerial reigns` to the idiomatic `managerial reins`."
let kind "Eggcorn"
let becomes "managerial reins"

test "She grabbed the managerial reigns during the crisis." "She grabbed the managerial reins during the crisis."
test "Managerial reigns are never easy to hand over." "Managerial reins are never easy to hand over."
test "The managerial reigns belong to Carla now." "The managerial reins belong to Carla now."
test "By winter, he held the managerial reigns, and morale improved." "By winter, he held the managerial reins, and morale improved."
test "Who will hold the managerial reigns after April?" "Who will hold the managerial reins after April?"
test "\"managerial reigns\" showed up in the draft notes." "\"managerial reins\" showed up in the draft notes."
allows "He kept the managerial reins despite the reshuffle."
allows "Legends of ancient reigns filled the museum."
test "They debated who should manage the managerial reigns for the quarter." "They debated who should manage the managerial reins for the quarter."
test "Their memo shouted MANAGERIAL REIGNS." "Their memo shouted MANAGERIAL REINS."



================================================
FILE: harper-core/src/linting/weir_rules/mod.rs
================================================
use super::LintGroup;
use crate::weir::WeirLinter;

macro_rules! generate_boilerplate {
    ([$($name:ident),+ $(,)?]) => {
        pub fn lint_group() -> LintGroup {
            let mut group = LintGroup::default();

                {
                    $(
                        group.add_chunk_expr_linter(stringify!($name), WeirLinter::new(include_str!(concat!(env!("WEIR_RULE_DIR"), "/", stringify!($name), ".weir"))).unwrap());
                    )+
                }

            group.set_all_rules_to(Some(true));

            group
        }

        #[cfg(test)]
        mod tests {
            use paste::paste;
            use crate::weir::tests::assert_passes_all;
            use crate::weir::WeirLinter;

            $(
                paste! {
                    #[test]
                    fn [<run_tests_for_ $name:snake>](){
                        let mut linter = WeirLinter::new(include_str!(concat!(env!("WEIR_RULE_DIR"), "/", stringify!($name), ".weir"))).unwrap();
                        assert_passes_all(&mut linter);
                    }
                }
            )+
        }
    };
}

include!(env!("WEIR_RULE_LIST"));



================================================
FILE: harper-core/src/linting/weir_rules/Monumentous.weir
================================================
expr main (monumentous)

let message "Retain `monumentous` for jocular effect. Otherwise `momentous` indicates great signifcance while `monumental` indicates imposing size."
let description "Advises using `momentous` or `monumental` instead of `monumentous` for serious usage."
let kind "Nonstandard"
let becomes ["momentous", "monumental"]

test "monumentous" "momentous"
test "I think that would be a monumentous step in the right direction, and would DEFINATLY turn heads in not just the music industry, but every ..." "I think that would be a momentous step in the right direction, and would DEFINATLY turn heads in not just the music industry, but every ..."



================================================
FILE: harper-core/src/linting/weir_rules/MyHouse.weir
================================================
expr main (mu house)

let message "Did you mean `my house`?"
let description "Fixes the typo `mu house` to `my house`."
let kind "Typo"
let becomes "my house"




================================================
FILE: harper-core/src/linting/weir_rules/NeedHelp.weir
================================================
expr main (ned help)

let message "Did you mean `need help`?"
let description "Changes `ned help` to the correct `need help`."
let kind "Typo"
let becomes "need help"




================================================
FILE: harper-core/src/linting/weir_rules/NerveRacking.weir
================================================
expr main [(nerve racking), (nerve wracking), (nerve wrecking), (nerve-wracking), (nerve-wrecking)]

let message "Use `nerve-racking` for something that causes anxiety or tension."
let description "Corrects common misspellings and missing hyphen in `nerve-racking`."
let kind "Eggcorn"
let becomes "nerve-racking"

test "We've gone through several major changes / upgrades to atlantis, and it's always a little bit nerve-wracking because if we mess something up we ..." "We've gone through several major changes / upgrades to atlantis, and it's always a little bit nerve-racking because if we mess something up we ..."
test "The issue happens to me on a daily basis, and it is nerve-wrecking because I become unsure if I have actually saved the diagram, but every time ..." "The issue happens to me on a daily basis, and it is nerve-racking because I become unsure if I have actually saved the diagram, but every time ..."
test "Very nerve wracking landing in an unfamiliar mountainous airport in dead of night with no radar to show surrounding terrain." "Very nerve-racking landing in an unfamiliar mountainous airport in dead of night with no radar to show surrounding terrain."
test "I appreciate any kind of help since this is kind of nerve wrecking." "I appreciate any kind of help since this is kind of nerve-racking."
test "It's nerve racking to think about it because I have code inside the callback that resolves the member and somehow I feel like it's so .." "It's nerve-racking to think about it because I have code inside the callback that resolves the member and somehow I feel like it's so .."



================================================
FILE: harper-core/src/linting/weir_rules/NotIn.weir
================================================
expr main (no in)

let message "Use `not in` for correct grammar."
let description "Replaces `no in` with `not in`."
let kind "Typo"
let becomes "not in"




================================================
FILE: harper-core/src/linting/weir_rules/NotTo.weir
================================================
expr main (no to)

let message "Did you mean `not to`?"
let description "Corrects `no to` to `not to`, ensuring proper negation."
let kind "Typo"
let becomes "not to"




================================================
FILE: harper-core/src/linting/weir_rules/OfCourse.weir
================================================
expr main [(off course), (o course), (ofcourse)]

let message "Did you mean `of course`?"
let description "Detects the common mistake `off course` and suggests the correct form `of course`."
let kind "Eggcorn"
let becomes "of course"

test "Yes, off course we should do that." "Yes, of course we should do that."
test "Yes, o course we should do that." "Yes, of course we should do that."
test "Ofcourse, I like other languages.. uzulla has 183 repositories available." "Of course, I like other languages.. uzulla has 183 repositories available."



================================================
FILE: harper-core/src/linting/weir_rules/OffTheCuff.weir
================================================
expr main (off the cuff)

let message "Use the hyphenated form for `off-the-cuff`."
let description "Ensures `off-the-cuff` is correctly hyphenated."
let kind "Punctuation"
let becomes "off-the-cuff"




================================================
FILE: harper-core/src/linting/weir_rules/OldWivesTale.weir
================================================
expr main (old wise tale)

let message "Use the correct phrase for a superstition or myth."
let description "Corrects `old wise tale` to `old wives' tale`, preserving the phrase’s meaning as an unfounded traditional belief."
let kind "Eggcorn"
let becomes "old wives' tale"




================================================
FILE: harper-core/src/linting/weir_rules/OnceInAWhile.weir
================================================
expr main [(once a while), (once and a while)]

let message "The correct idiom is `once in a while`."
let description "Corrects two common malapropisms of `once in a while`."
let kind "Usage"
let becomes "once in a while"

test "For me it is a SMB mount I have on the client device that I sync only once a while for a backup into the cloud." "For me it is a SMB mount I have on the client device that I sync only once in a while for a backup into the cloud."
test "Every once and a while all the links on my page seem to stop working." "Every once in a while all the links on my page seem to stop working."



================================================
FILE: harper-core/src/linting/weir_rules/OnSecondThought.weir
================================================
expr main <([on, my] second though), (second though)>

let message "Idiomatic expression: use `on second thought` instead of `on second though`"
let description "Replaces the nonstandard `on second though` with the common idiom `on second thought` to indicate reconsideration."
let kind "Typo"
let becomes "second thought"

test "I was going to buy it, but on second though, maybe I'll wait." "I was going to buy it, but on second thought, maybe I'll wait."
allows "She considered driving home, but on second thought, she decided to walk."
test "My second though is that I'd prefer something else entirely." "My second thought is that I'd prefer something else entirely."



================================================
FILE: harper-core/src/linting/weir_rules/OnTheSpurOfTheMoment.weir
================================================
expr main [(on the spurt of the moment), (at the spur of the moment), (in the spur of the moment), (in the spurt of the moment)]

let message "Use the correct phrase for acting spontaneously."
let description "Ensures the correct use of `on the spur of the moment`, avoiding nonstandard variations."
let kind "Eggcorn"
let becomes "on the spur of the moment"

test "Quite often in the spurt of the moment, someone will say something which they think is witty." "Quite often on the spur of the moment, someone will say something which they think is witty."
test "but at the spur of the moment, I'd say that ansible-lint should work exactly like ansible" "but on the spur of the moment, I'd say that ansible-lint should work exactly like ansible"
test "an assortment of things I started yesterday in the spur of the moment" "an assortment of things I started yesterday on the spur of the moment"



================================================
FILE: harper-core/src/linting/weir_rules/OnTopOf.weir
================================================
expr main (ontop of)

let message "Did you mean `on top of`?"
let description "Corrects `ontop of` to `on top of`."
let kind "BoundaryError"
let becomes "on top of"

test "Initcpio hooks for overlayfs ontop of root." "Initcpio hooks for overlayfs on top of root."



================================================
FILE: harper-core/src/linting/weir_rules/PartsOfSpeech.weir
================================================
expr main [(part of speeches), (parts of speeches)]

let message "The correct plural is `parts of speech`."
let description "Corrects pluralizing the wrong noun in `part of speech`."
let kind "Grammar"
let becomes "parts of speech"

test "Learning the part of speeches is important." "Learning the parts of speech is important."
test "We studied parts of speeches yesterday." "We studied parts of speech yesterday."



================================================
FILE: harper-core/src/linting/weir_rules/PasswordProtectedHyphen.weir
================================================
expr main <(password protected [(area), (areas), (document), (documents), (doc), (docs), (spreadsheet), (spreadsheets), (archive), (archives), (zip), (zips), (pdf), (pdfs), (folder), (folders), (system), (systems), (page), (pages), (website), (websites), (site), (sites), (file), (files), (account), (accounts), (drive), (drives), (stick), (sticks), (usb), (usbs), (excel), (apps), (app), (cd), (cds), (dropbox), (dropboxes), (email), (emails), (gallery), (galleries), (iphone), (iphones)]), (password protected)>

let message "Hyphenate `password-protected` when the phrase modifies a following resource."
let description "Keeps the compound adjective together before nouns like folders, files, or web pages so the dependency between them is clear."
let kind "Style"
let becomes "password-protected"

test "A password protected area restricts access." "A password-protected area restricts access."
test "We store logs in a password protected folder." "We store logs in a password-protected folder."
test "Please send the password protected document tomorrow." "Please send the password-protected document tomorrow."
test "The password protected spreadsheet contains numbers." "The password-protected spreadsheet contains numbers."
test "They locked the password protected archive." "They locked the password-protected archive."
test "Bring the password protected pdf to the meeting." "Bring the password-protected pdf to the meeting."
test "That password protected page requires a login." "That password-protected page requires a login."
test "This password protected website is for beta users." "This password-protected website is for beta users."
test "Our password protected file sits on the drive." "Our password-protected file sits on the drive."
test "The password protected account holds secrets." "The password-protected account holds secrets."
test "Their password protected app went live." "Their password-protected app went live."
test "We updated the password protected system this morning." "We updated the password-protected system this morning."
test "These password protected folders double as backups." "These password-protected folders double as backups."
test "Password protected emails pile up." "Password-protected emails pile up."
test "The password protected gallery remains hidden." "The password-protected gallery remains hidden."
test "A password protected iphone case is ready." "A password-protected iphone case is ready."
test "A password protected drive keeps everything safe." "A password-protected drive keeps everything safe."
allows "The area is password protected."
allows "She mentioned password protected with no follow-up."
allows "The password protected from clause does not match."


================================================
FILE: harper-core/src/linting/weir_rules/PeaceOfMind.weir
================================================
expr main (piece of mind)

let message "The phrase is `peace of mind`, meaning `calm`. A `piece` is a `part` of something."
let description "Corrects `piece of mind` to `peace of mind`."
let kind "Eggcorn"
let becomes "peace of mind"

test "A Discord bot that gives you piece of mind knowing you are free from obnoxious intrusions in a Discord Voice Channel" "A Discord bot that gives you peace of mind knowing you are free from obnoxious intrusions in a Discord Voice Channel"



================================================
FILE: harper-core/src/linting/weir_rules/PedalToTheMetal.weir
================================================
expr main pedal to the medal

let message "Use the idiom `pedal to the metal`."
let description "Corrects the eggcorn `pedal to the medal` to the standard idiom `pedal to the metal`, meaning to accelerate at full speed."
let kind "Typo"
let becomes "pedal to the metal"

test "pedal to the medal" "pedal to the metal"
test "Pedal to the medal when you see the green flag." "Pedal to the metal when you see the green flag."
test "The coach shouted pedal to the medal before the jump." "The coach shouted pedal to the metal before the jump."
test "We pedal to the medal whenever the lights go yellow." "We pedal to the metal whenever the lights go yellow."
test "Pedal to the medal is how you fly out of the gate." "Pedal to the metal is how you fly out of the gate."
test "He loves to say pedal to the medal while revving engines." "He loves to say pedal to the metal while revving engines."
test "Pedal to the medal in these conditions and the tyres scream." "Pedal to the metal in these conditions and the tyres scream."
test "Pedal to the medal, please, once we cross the start line." "Pedal to the metal, please, once we cross the start line."
test "Keep saying pedal to the medal until the rival hears it." "Keep saying pedal to the metal until the rival hears it."
test "PEDAL TO THE MEDAL seems to be the rally cry." "PEDAL TO THE METAL seems to be the rally cry."

allows "Pedal to the metal is the correct idiom."
allows "She earned a medal for her performance."
allows "The medal ceremony happened before the race."
allows "Pedal to the mettle, not the medal, outlines courage."
allows "The medal in our archive dates to 1895."
allows "They pedaled to the medal."


================================================
FILE: harper-core/src/linting/weir_rules/PerSe.weir
================================================
expr main [(per say), (per-se), (per-say)]

let message "The correct spelling is `per se` (with no hyphen)"
let description "Corrects common misspellings of `per se`."
let kind "Spelling"
let becomes "per se"

test "It's not a problem per-se, but it would make the desktop more consistent when using QT and KDE apps." "It's not a problem per se, but it would make the desktop more consistent when using QT and KDE apps."
test "Hi all - not really an issue per say, but more of a request for some suggestions and guidance." "Hi all - not really an issue per se, but more of a request for some suggestions and guidance."
test "Whilst I don't think this is wrong per-say, I'm not confident it is necessary." "Whilst I don't think this is wrong per se, I'm not confident it is necessary."



================================================
FILE: harper-core/src/linting/weir_rules/PointsOfView.weir
================================================
expr main (point of views)

let message "The correct plural is `points of view`."
let description "Corrects pluralizing the wrong noun in `point of view`."
let kind "Grammar"
let becomes "points of view"

test "This will produce a huge amount of raw data, representing the region in multiple point of views." "This will produce a huge amount of raw data, representing the region in multiple points of view."



================================================
FILE: harper-core/src/linting/weir_rules/PortAuPrince.weir
================================================
expr main (Port au Prince)

let message "The official spelling is hyphenated."
let description "Checks for the correct official name of the capital of Haiti."
let kind "Punctuation"
let becomes "Port-au-Prince"




================================================
FILE: harper-core/src/linting/weir_rules/PortoNovo.weir
================================================
expr main (Porto Novo)

let message "The official spelling is hyphenated."
let description "Checks for the correct official name of the capital of Benin."
let kind "Punctuation"
let becomes "Porto-Novo"




================================================
FILE: harper-core/src/linting/weir_rules/PrayingMantis.weir
================================================
expr main (preying mantis)

let message "Use the insect's correct name."
let description "Corrects `preying mantis` to `praying mantis`, ensuring accurate reference to the insect’s characteristic pose."
let kind "Eggcorn"
let becomes "praying mantis"




================================================
FILE: harper-core/src/linting/weir_rules/QuiteMany.weir
================================================
expr main (quite many)

let message "Use `quite a few` instead of `quite many`."
let description "Corrects `quite many` to `quite a few`, which is the more natural and idiomatic phrase in standard English. `Quite many` is considered nonstandard usage."
let kind "Nonstandard"
let becomes "quite a few"

test "To me it seems it might be caused by a2aaa55 which contains quite many build-related changes." "To me it seems it might be caused by a2aaa55 which contains quite a few build-related changes."



================================================
FILE: harper-core/src/linting/weir_rules/RainbowColoredHyphen.weir
================================================
expr main <(([rainbow, cream] [colored, coloured]) NOUN), ( )>

let message "Keep these compound color modifiers hyphenated before their nouns."
let description "When rainbow-colored or cream-colored describe a noun, replace the space between the color words with a hyphen to keep the modifier cohesive."
let kind "Style"
let becomes "-"

test "The rainbow colored leaves shimmered in the morning light." "The rainbow-colored leaves shimmered in the morning light."
test "A cream colored sofa anchored the living room." "A cream-colored sofa anchored the living room."
test "Bright rainbow colored banners lined the promenade." "Bright rainbow-colored banners lined the promenade."
test "Bring the cream colored napkins to the table." "Bring the cream-colored napkins to the table."
test "RAINBOW COLORED FLAGS fluttered over the pier." "RAINBOW-COLORED FLAGS fluttered over the pier."
test "Our designer introduced cream coloured sneakers for fall." "Our designer introduced cream-coloured sneakers for fall."
test "These rainbow colored posters mark the festival days." "These rainbow-colored posters mark the festival days."
test "Cream coloured curtains softened the gallery lights." "Cream-coloured curtains softened the gallery lights."
test "The designer chose rainbow colored tiles for the backsplash." "The designer chose rainbow-colored tiles for the backsplash."
test "Our lineup now shows cream colored lipsticks and rainbow colored gloss." "Our lineup now shows cream-colored lipsticks and rainbow-colored gloss."

allows "The rainbow colored the sky with a soft gradient."
allows "She rainbow colored every triangle on the quilt."
allows "The artist cream colored the mural in minutes."
allows "The leaves were rainbow colored after the festival lights."
allows "Cream colored the vase intentionally for the commission."


================================================
FILE: harper-core/src/linting/weir_rules/RallyToReally.weir
================================================
expr main <([(am rally PROG), (am not rally PROG), (am PRON rally PROG), (am PRON not rally PROG), (is rally PROG), (is not rally PROG), (is PRON rally PROG), (is PRON not rally PROG), (isn't rally PROG), (isn't PRON rally PROG), (are rally PROG), (are not rally PROG), (are PRON rally PROG), (are PRON not rally PROG), (aren't rally PROG), (aren't PRON rally PROG), (was rally PROG), (was not rally PROG), (was PRON rally PROG), (was PRON not rally PROG), (wasn't rally PROG), (wasn't PRON rally PROG), (were rally PROG), (were not rally PROG), (were PRON rally PROG), (were PRON not rally PROG), (weren't rally PROG), (weren't PRON rally PROG), (be rally PROG), (be not rally PROG), (be PRON rally PROG), (be PRON not rally PROG), (being rally PROG), (being not rally PROG), (been rally PROG), (been not rally PROG), (ain't rally PROG), (ain't PRON rally PROG)]), (rally)>

let message "Replace `rally` with `really` whenever a form of `be` introduces a progressive verb."
let description "Catches the typo where `rally` sneaks into `be + ...ing` constructions, including common contractions."
let kind "Typo"
let becomes "really"
let strategy "MatchCase"

test "It is rally going to happen." "It is really going to happen."
test "We are rally getting closer to shipping." "We are really getting closer to shipping."
test "I am rally trying to finish this before midnight." "I am really trying to finish this before midnight."
test "She is not rally learning the concept." "She is not really learning the concept."
test "It isn't rally raining anymore." "It isn't really raining anymore."
test "They were rally practicing their lines." "They were really practicing their lines."
test "It was not rally raining on our drive." "It was not really raining on our drive."
test "He had been rally preparing to leave." "He had been really preparing to leave."
test "Ain't rally happening yet?" "Ain't really happening yet?"
test "Weren't we rally celebrating that plan?" "Weren't we really celebrating that plan?"
allows "Be rally precise when you describe the steps."
test "He was RALLY going to go all night." "He was REALLY going to go all night."

allows "The rally celebrating our victory lasted forever."
allows "I really appreciate your effort."
allows "Rally fans gathered outside the stadium."
allows "We had a rally before the game."
allows "The news rallied the team but left them motivated."
allows "We were ready to rally around the idea."


================================================
FILE: harper-core/src/linting/weir_rules/RapidFire.weir
================================================
expr main (rapid fire)

let message "It is more idiomatic to hypenate `rapid-fire`."
let description "Checks to ensure writers hyphenate `rapid-fire`."
let kind "Punctuation"
let becomes "rapid-fire"




================================================
FILE: harper-core/src/linting/weir_rules/RealTrouper.weir
================================================
expr main (real trooper)

let message "Use the correct phrase for someone who perseveres."
let description "Ensures the correct use of `real trouper`, distinguishing it from `trooper`, which refers to a soldier or police officer."
let kind "Eggcorn"
let becomes "real trouper"




================================================
FILE: harper-core/src/linting/weir_rules/RedundantIIRC.weir
================================================
expr main [(if IIRC), (IIRC correctly)]

let message "`IIRC` already means 'if I recall correctly', so adding 'if' or 'correctly' is redundant."
let description "Flags redundant use of 'if' or 'correctly' with `IIRC`, since `IIRC` already stands for 'if I recall correctly'."
let kind "Redundancy"
let becomes "IIRC"
let strategy "Exact"

test "This is due to the fact that if IIRC up to 2 processes mpirun will bind to core and then it will be socket." "This is due to the fact that IIRC up to 2 processes mpirun will bind to core and then it will be socket."
test "if iirc getting it to work with the SQLite storage engine was turning into a whole project and we decided to punt it" "IIRC getting it to work with the SQLite storage engine was turning into a whole project and we decided to punt it"
test "IIRC correctly, someone on the Home Assistant forums went as far as discovering that RS-485 was being used." "IIRC, someone on the Home Assistant forums went as far as discovering that RS-485 was being used."



================================================
FILE: harper-core/src/linting/weir_rules/RedundantPretty.weir
================================================
expr main (pretty decent)

let message "Avoid redundancy."
let description "`Pretty` is redundant when modifying `decent`. Use `decent` alone."
let kind "Style"
let becomes "decent"

test "The movie was pretty decent." "The movie was decent."
test "It is pretty decent work." "It is decent work."
test "She did a pretty decent job." "She did a decent job."
test "That sounds pretty decent to me." "That sounds decent to me."
test "We had a pretty decent time." "We had a decent time."

test "The movie was Pretty Decent." "The movie was Decent."
test "The movie was PRETTY DECENT." "The movie was DECENT."

allows "The movie was pretty good."
allows "The movie was decent."
allows "It was quite decent."
allows "Pretty much anything works."


================================================
FILE: harper-core/src/linting/weir_rules/RedundantThat.weir
================================================
expr main (that that)

let message "Consider whether the second `that` adds meaning in this context."
let description "There is rarely a situation where `that that` cannot be condensed into a single token."
let kind "Repetition"
let becomes "that"

test "I know that that answer is correct" "I know that answer is correct"



================================================
FILE: harper-core/src/linting/weir_rules/RifeWith.weir
================================================
expr main (ripe with)

let message "Use the correct phrase for something abundant."
let description "Corrects `ripe with` to `rife with`, preserving the phrase’s meaning of being filled with something, often undesirable."
let kind "Eggcorn"
let becomes "rife with"




================================================
FILE: harper-core/src/linting/weir_rules/RoadMap.weir
================================================
expr main (roadmap)

let message "Did you mean `road map`?"
let description "Detects when `roadmap` is used instead of `road map`, prompting the correct spacing."
let kind "WordChoice"
let becomes "road map"




================================================
FILE: harper-core/src/linting/weir_rules/RulesOfThumb.weir
================================================
expr main [(rule of thumbs), (rule-of-thumbs)]

let message "The correct plural is `rules of thumb`."
let description "Corrects pluralizing the wrong noun in `rule of thumb`."
let kind "Grammar"
let becomes "rules of thumb"

test "Thanks. 0.2 is just from my rule of thumbs." "Thanks. 0.2 is just from my rules of thumb."
test "Add rule-of-thumbs for basic metrics, like \"Spill more than 1GB is a red flag\"." "Add rules of thumb for basic metrics, like \"Spill more than 1GB is a red flag\"."



================================================
FILE: harper-core/src/linting/weir_rules/SameAs.weir
================================================
expr main (same then)

let message "Did you mean `same as`?"
let description "Corrects the incorrect phrase `same then` to the standard `same as`."
let kind "Grammar"
let becomes "same as"




================================================
FILE: harper-core/src/linting/weir_rules/ScantilyClad.weir
================================================
expr main (scandally clad)

let message "Use the correct phrase for minimal attire."
let description "Fixes `scandally clad` to `scantily clad`, ensuring clarity in describing minimal attire."
let kind "Eggcorn"
let becomes "scantily clad"




================================================
FILE: harper-core/src/linting/weir_rules/SendAnEmailTo.weir
================================================
expr main (send an email to)

let message "Use the shorter verb form."
let description "Replaces the verbose phrase `send an email to` with the concise verb `email`."
let kind "Style"
let becomes "email"
let strategy "Exact"

test "Please send an email to John." "Please email John."
test "I will send an email to the team later." "I will email the team later."
test "SEND AN EMAIL TO support." "email support."
test "Send An Email To HR." "email HR."
test "Can you send an email to her?" "Can you email her?"
test "They decided to send an email to all users." "They decided to email all users."
test "Send an email to John, please." "email John, please."
test "Before noon, send an email to marketing." "Before noon, email marketing."
allows "Please write an email to John."
allows "She sent a message to John."


================================================
FILE: harper-core/src/linting/weir_rules/SimpleGrammatical.weir
================================================
expr main (simply grammatical)

let message "Use `simple grammatical` for correct adjective usage."
let description "Corrects `simply grammatical` to `simple grammatical` for proper adjective usage."
let kind "Usage"
let becomes "simple grammatical"




================================================
FILE: harper-core/src/linting/weir_rules/SneakingSuspicion.weir
================================================
expr main (sneaky suspicion)

let message "Did you mean `sneaking suspicion`?"
let description "Changes `sneaky suspicion` to `sneaking suspicion`."
let kind "Eggcorn"
let becomes "sneaking suspicion"

test "sneaky suspicion" "sneaking suspicion"



================================================
FILE: harper-core/src/linting/weir_rules/SomebodyElses.weir
================================================
expr main [(somebody's else), (somebody's else's)]

let message "This should be `somebody else's`?"
let description "Corrects `somebody else's` when the `'s` is in the wrong place."
let kind "Grammar"
let becomes "somebody else's"

test "I really like your component and change to somebody's else would be really bad for now." "I really like your component and change to somebody else's would be really bad for now."
test "Nice to know it's somebody's else's problem for a change." "Nice to know it's somebody else's problem for a change."



================================================
FILE: harper-core/src/linting/weir_rules/SomeOfThe.weir
================================================
expr main (some the)

let message "Add `of` to form the partitive phrase: `some of the`."
let description "Quantity words such as `some` normally take `of` before a definite article. Including `of` signals that you mean a subset of a larger set, preventing a momentary stumble in comprehension."
let kind "Typo"
let becomes "some of the"

test "Some the trees are too thick to climb." "Some of the trees are too thick to climb."
test "You have misplaced some the config files." "You have misplaced some of the config files."



================================================
FILE: harper-core/src/linting/weir_rules/SoonerOrLater.weir
================================================
expr main (sooner than later)

let message "Did you mean `sooner rather than later` or `sooner or later`?"
let description "Fixes the improper phrase `sooner than later` by suggesting standard alternatives."
let kind "Usage"
let becomes ["sooner rather than later", "sooner or later"]




================================================
FILE: harper-core/src/linting/weir_rules/SpecialAttention.weir
================================================
expr main (spacial attention)

let message "Did you mean `special attention`?"
let description "Changes `spacial attention` to `special attention`."
let kind "Typo"
let becomes "special attention"

test "spacial attention" "special attention"



================================================
FILE: harper-core/src/linting/weir_rules/Starving.weir
================================================
expr main [(very hungry), (really hungry), (extremely hungry)]

let message "A more vivid adjective would better convey intense hunger."
let description "Encourages vivid writing by suggesting `starving` instead of weaker expressions like `very hungry.`"
let kind "Enhancement"
let becomes "starving"




================================================
FILE: harper-core/src/linting/weir_rules/StateOfTheArt.weir
================================================
expr main (state of art)

let message "Did you mean `state of the art`?"
let description "Detects incorrect usage of `state of art` and suggests `state of the art` as the correct phrase."
let kind "Usage"
let becomes "state of the art"




================================================
FILE: harper-core/src/linting/weir_rules/StatuteOfLimitations.weir
================================================
expr main (statue of limitations)

let message "A `statue` is a sculpture; in legal terms, the correct word is `statute`."
let description "Corrects `statue of limitations` to `statute of limitations`."
let kind "Eggcorn"
let becomes "statute of limitations"

test "Shouldn't there be a grandfathered-in or statue of limitations for posts before the original punishment?" "Shouldn't there be a grandfathered-in or statute of limitations for posts before the original punishment?"



================================================
FILE: harper-core/src/linting/weir_rules/SufficeItToSay.weir
================================================
expr main (suffice to say)

let message "`Suffice it to say` is the more standard and more common variant."
let description "Corrects `suffice to say` to `suffice it to say`."
let kind "Usage"
let becomes "suffice it to say"

test "I don't fully grok the bug, but suffice to say it is not an RCD issue." "I don't fully grok the bug, but suffice it to say it is not an RCD issue."



================================================
FILE: harper-core/src/linting/weir_rules/SupposedTo.weir
================================================
expr main (suppose to)

let message "Did you mean `supposed to`?"
let description "Fixes `suppose to` to the correct `supposed to`."
let kind "Usage"
let becomes "supposed to"

test "suppose to" "supposed to"



================================================
FILE: harper-core/src/linting/weir_rules/TakeItPersonally.weir
================================================
expr main (take it personal)

let message "The more standard, less colloquial form is `take it personally`."
let description "Corrects `take it personal` to `take it personally`."
let kind "Usage"
let becomes "take it personally"

test "This is not personal, do not take it personal, we also think Thingsboard is a extraordinary tool (we are using in several scenarios in fact)" "This is not personal, do not take it personally, we also think Thingsboard is a extraordinary tool (we are using in several scenarios in fact)"



================================================
FILE: harper-core/src/linting/weir_rules/ThanksALot.weir
================================================
expr main (thanks lot)

let message "The indefinite article `a` is required in `thanks a lot`."
let description "Corrects the missing article in `thanks lot`, forming `thanks a lot`."
let kind "Grammar"
let becomes "thanks a lot"

test "thanks lot" "thanks a lot"
allows "thanks a lot"


================================================
FILE: harper-core/src/linting/weir_rules/ThatChallenged.weir
================================================
expr main (the challenged)

let message "Use `that challenged` for correct relative clause."
let description "Corrects `the challenged` to `that challenged` for proper relative clause usage."
let becomes "that challenged"




================================================
FILE: harper-core/src/linting/weir_rules/ThatThis.weir
================================================
expr main (the this)

let message "Did you mean `that this`?"
let description "Fixes `the this` to the correct phrase `that this`."
let kind "Typo"
let becomes "that this"




================================================
FILE: harper-core/src/linting/weir_rules/The.weir
================================================
expr main [(teh), (te)]

let message "Did you mean the definite article?"
let description "Fixes especially common misspellings of the word `the`"
let kind "Typo"
let becomes "the"

test "I adore teh light of the moon." "I adore the light of the moon."



================================================
FILE: harper-core/src/linting/weir_rules/TheAnother.weir
================================================
expr main (the another)

let message "Use `the other` or `another`, not both."
let description "Corrects `the another`."
let kind "Grammar"
let becomes ["the other", "another"]

test "Another possible cause is simply that the application does not have file creation permissions on the another machine." "Another possible cause is simply that the application does not have file creation permissions on the other machine."



================================================
FILE: harper-core/src/linting/weir_rules/TheirToThere.weir
================================================
expr main [<(their [is, are, was, were, isn't, aren't, wasn't, weren't, (will be), (can be), (could be), (should be), (would be), (may be), (might be), (must be), (has been), (have been)]), their>, <(their [on, after, beside, in, by, until, again, to, and, right]), their>, <(their,), their>, their's]

let message "Did you mean `there`?"
let description "Corrects `their` when the intended meaning is `there`."
let kind "Grammar"
let becomes ["there", "there's", "there's"]

test "Their is a problem with the build." "There is a problem with the build."
test "Their are several options to consider." "There are several options to consider."
test "Their was a delay in the rollout." "There was a delay in the rollout."
test "Their were no updates last week." "There were no updates last week."
test "Their isn't any time left." "There isn't any time left."
test "Their aren't enough chairs." "There aren't enough chairs."
test "Their wasn't a clear answer." "There wasn't a clear answer."
test "Their weren't any tickets left." "There weren't any tickets left."
test "Their will be more questions." "There will be more questions."
test "Their can be a conflict of interest." "There can be a conflict of interest."
test "Their could be a better approach." "There could be a better approach."
test "Their should be a warning." "There should be a warning."
test "Their would be a delay if we waited." "There would be a delay if we waited."
test "Their may be changes later." "There may be changes later."
test "Their might be issues later." "There might be issues later."
test "Their must be a simpler way." "There must be a simpler way."
test "Their has been a change in scope." "There has been a change in scope."
test "Their have been delays all week." "There have been delays all week."

allows "Their car is in the driveway."
allows "We used their tools for the repair."
allows "Their team was excited."
allows "I appreciate their help."
allows "Their willpower is strong."
test "Their is a cat sleeping on the radiator." "There is a cat sleeping on the radiator."
test "I left the keys their on the counter." "I left the keys there on the counter."
test "Their are three clean mugs in the cupboard." "There are three clean mugs in the cupboard."
test "We should meet their after work, near the fountain." "We should meet there after work, near the fountain."
test "Their was a strange echo in the stairwell." "There was a strange echo in the stairwell."
test "Put the blue folder their, beside the printer." "Put the blue folder there, beside the printer."
test "Their will be a storm tonight, so bring the plants in." "There will be a storm tonight, so bring the plants in."
test "I've never been their, but I've read about it." "I've never been there, but I've read about it."
test "Their isn't enough coffee for everyone." "There isn't enough coffee for everyone."
test "She paused their, mid-sentence, as if listening." "She paused there, mid-sentence, as if listening."
test "Their were fingerprints on the glass." "There were fingerprints on the glass."
test "We can stop their and refuel before the mountains." "We can stop there and refuel before the mountains."
test "Their's a tiny crack in the screen." "There's a tiny crack in the screen."
test "I saw him standing their, perfectly still." "I saw him standing there, perfectly still."
test "Their are more questions than answers." "There are more questions than answers."
test "Leave the umbrella their by the door." "Leave the umbrella there by the door."
test "Their must be a simpler explanation." "There must be a simpler explanation."
test "I wish I could go their again in summer." "I wish I could go there again in summer."
test "Their is no shortcut through this part of the forest." "There is no shortcut through this part of the forest."
test "He moved the chair their to catch the sunlight." "He moved the chair there to catch the sunlight."
test "Their were candles on every windowsill." "There were candles on every windowsill."
test "You can park their, but only after 6 p.m." "You can park there, but only after 6 p.m."
test "Their's a note taped under the table." "There's a note taped under the table."
test "She felt safer their, among familiar faces." "She felt safer there, among familiar faces."
test "Their were no footprints their in the fresh snow." "There were no footprints there in the fresh snow."
test "I'll wait their until you arrive." "I'll wait there until you arrive."
test "Their is a quiet confidence in her voice." "There is a quiet confidence in her voice."
test "The answer is right their in the first paragraph." "The answer is right there in the first paragraph."
test "Their are deadlines, and then their are consequences." "There are deadlines, and then there are consequences."
test "I can't believe you're still standing their, smiling." "I can't believe you're still standing there, smiling."



================================================
FILE: harper-core/src/linting/weir_rules/TheirToTheyre.weir
================================================
expr main [<(their [AUX, (supposed to), (allowed to), (invited to), (going to), (trying to), (coming over), (leaving in), (moving to), (planning a), (waiting for), (answering any), (wondering where), (running behind), (far too), even, (already here), (in the), (on the), (at the), (a lot), an, two, offline, (ADV [PROG, AUX]), (ADV VERB), (PART [PROG, VERB, ADJ, AUX]), (ready to), the]), their>]

let message "Did you mean `they're`?"
let description "Corrects `their` when the intended meaning is `they're`."
let kind "Grammar"
let becomes ["they're", "they're "]

test "Their going to be late." "They're going to be late."
test "I think their already here." "I think they're already here."
test "Their not sure what to do next." "They're not sure what to do next."
test "Their coming over after work." "They're coming over after work."
test "Tell them their invited to the meeting." "Tell them they're invited to the meeting."
test "Their trying to fix the bug right now." "They're trying to fix the bug right now."
test "Their going to love this movie." "They're going to love this movie."
test "Their the fastest team in the league." "They're the fastest team in the league."
test "Their supposed to call you back today." "They're supposed to call you back today."
test "Their leaving in five minutes." "They're leaving in five minutes."
test "I heard their moving to Denver." "I heard they're moving to Denver."
test "Their just kidding--don't worry." "They're just kidding--don't worry."
test "Their going to email the final draft tonight." "They're going to email the final draft tonight."
test "Their not available until Tuesday." "They're not available until Tuesday."
test "Their planning a surprise party." "They're planning a surprise party."
test "Looks like their running behind schedule." "Looks like they're running behind schedule."
test "Their the ones who approved it." "They're the ones who approved it."
test "Their going to miss the train." "They're going to miss the train."
test "Their still waiting for the test results." "They're still waiting for the test results."
test "Their not allowed to park here." "They're not allowed to park here."
test "Their going to change the policy." "They're going to change the policy."
test "Their ready to start whenever you are." "They're ready to start whenever you are."
test "Their not answering any messages." "They're not answering any messages."
test "Their going to be a problem if we don't hurry." "They're going to be a problem if we don't hurry."
test "Their probably wondering where we went." "They're probably wondering where we went."

allows "Their backpacks were stacked neatly by the door."
allows "I admired their patience during the long, glitchy delay."
allows "Their dog sprinted across the yard like a furry comet."
allows "The committee revised their proposal after the budget changed."
allows "Their laughter drifted down the hallway, bright and unguarded."
allows "We borrowed their ladder to reach the stubborn light fixture."
allows "Their apartment smells like coffee, citrus, and old paperbacks."
allows "The kids lost their mittens somewhere between the car and the rink."
allows "Their answer was careful, precise, and unexpectedly kind."
allows "The artists framed their sketches before the gallery opened."
allows "Their server crashed, but their backup plan worked flawlessly."
allows "I couldn't ignore their evidence; it was meticulously documented."
allows "Their garden is a riot of basil, tomatoes, and bee traffic."
allows "The hikers checked their maps twice before leaving the trailhead."
allows "Their team celebrated quietly--relieved more than triumphant."
allows "Users should be able to visualize their connected notes as a knowledge graph, allowing them to explore relationships and identify patterns."
allows "The frustration was palpable; the team felt they were fighting a constant uphill battle against their own data infrastructure."
allows "Historians and sociologists have long examined how societies construct and maintain narratives about their past."
allows "Traditional maps, often produced by the colonizers, replaced native nomenclature with European equivalents, effectively severing a vital link between people and their ancestral lands."
allows "She believes I should prioritize their needs above my own."
allows "Each player places their pawn on GRI Headquarters (designated space on the board)."
allows "This fragmented view hindered their ability to make timely adjustments, ultimately impacting their return on investment."
allows "My shift was nearing its end, and I was conducting my final rounds, ensuring each patient was comfortable and their needs were met."
allows "Upon opening the application, users see a prioritized list of information cards related to their most recently accessed projects or tasks in connected applications."
allows "For instance, a musician who has lost their hearing might collaborate with a visual artist to create a series of abstract paintings that attempt to translate the emotional impact of music into a visual form."
allows "Their relatively low density facilitates handling and transportation."
allows "The growing interest in mycelium-based construction materials stems from their potential to offer a sustainable alternative to conventional building materials."
allows "Similarly, the individual experiencing sensory loss must actively reconstruct their understanding of the world, mapping the contours of their new, altered reality."
test "Their far too warm for that." "They're far too warm for that."
test "Their far too cold for that." "They're far too cold for that."
test "Their even, just as I said!" "They're even, just as I said!"

test "Their in the kitchen already." "They're in the kitchen already."
test "Their on the way to the airport." "They're on the way to the airport."
test "Their at the wrong address." "They're at the wrong address."

test "Their a lot of people waiting outside." "They're a lot of people waiting outside."
test "Their an example of how not to do it." "They're an example of how not to do it."
test "Their two options left." "They're two options left."

test "Their to blame for the mistake." "They're to blame for the mistake."
test "Their to meet us after work." "They're to meet us after work."

test "Their offline right now, try again later." "They're offline right now, try again later."



================================================
FILE: harper-core/src/linting/weir_rules/ThereToTheir.weir
================================================
expr main [<(there [NOUN, (NOUN NOUN), mittens, sketches, past, needs, pawn, ability, return]), there>, <(there connected notes), there>, <(there own data infrastructure), there>, <(there ancestral lands), there>, <(there relatively low density), there>, <(there potential to), there>, <(there backup plan), there>, <(there most recently accessed projects), there>, <(there new), there>]

let message "Did you mean `their`?"
let description "Corrects `there` when the intended meaning is `their`."
let kind "Grammar"
let becomes "their"

test "There backpacks were stacked neatly by the door." "Their backpacks were stacked neatly by the door."
test "I admired there patience during the long, glitchy delay." "I admired their patience during the long, glitchy delay."
test "There dog sprinted across the yard like a furry comet." "Their dog sprinted across the yard like a furry comet."
test "The committee revised there proposal after the budget changed." "The committee revised their proposal after the budget changed."
test "There laughter drifted down the hallway, bright and unguarded." "Their laughter drifted down the hallway, bright and unguarded."
test "We borrowed there ladder to reach the stubborn light fixture." "We borrowed their ladder to reach the stubborn light fixture."
test "There apartment smells like coffee, citrus, and old paperbacks." "Their apartment smells like coffee, citrus, and old paperbacks."
test "The kids lost there mittens somewhere between the car and the rink." "The kids lost their mittens somewhere between the car and the rink."
test "There answer was careful, precise, and unexpectedly kind." "Their answer was careful, precise, and unexpectedly kind."
test "The artists framed there sketches before the gallery opened." "The artists framed their sketches before the gallery opened."
test "There server crashed, but there backup plan worked flawlessly." "Their server crashed, but their backup plan worked flawlessly."
test "I couldn't ignore there evidence; it was meticulously documented." "I couldn't ignore their evidence; it was meticulously documented."
test "There garden is a riot of basil, tomatoes, and bee traffic." "Their garden is a riot of basil, tomatoes, and bee traffic."
test "The hikers checked there maps twice before leaving the trailhead." "The hikers checked their maps twice before leaving the trailhead."
test "There team celebrated quietly--relieved more than triumphant." "Their team celebrated quietly--relieved more than triumphant."
test "Users should be able to visualize there connected notes as a knowledge graph, allowing them to explore relationships and identify patterns." "Users should be able to visualize their connected notes as a knowledge graph, allowing them to explore relationships and identify patterns."
test "The frustration was palpable; the team felt they were fighting a constant uphill battle against there own data infrastructure." "The frustration was palpable; the team felt they were fighting a constant uphill battle against their own data infrastructure."
test "Historians and sociologists have long examined how societies construct and maintain narratives about there past." "Historians and sociologists have long examined how societies construct and maintain narratives about their past."
test "Traditional maps, often produced by the colonizers, replaced native nomenclature with European equivalents, effectively severing a vital link between people and there ancestral lands." "Traditional maps, often produced by the colonizers, replaced native nomenclature with European equivalents, effectively severing a vital link between people and their ancestral lands."
test "She believes I should prioritize there needs above my own." "She believes I should prioritize their needs above my own."
test "Each player places there pawn on GRI Headquarters (designated space on the board)." "Each player places their pawn on GRI Headquarters (designated space on the board)."
test "This fragmented view hindered there ability to make timely adjustments, ultimately impacting there return on investment." "This fragmented view hindered their ability to make timely adjustments, ultimately impacting their return on investment."
test "My shift was nearing its end, and I was conducting my final rounds, ensuring each patient was comfortable and there needs were met." "My shift was nearing its end, and I was conducting my final rounds, ensuring each patient was comfortable and their needs were met."
test "Upon opening the application, users see a prioritized list of information cards related to there most recently accessed projects or tasks in connected applications." "Upon opening the application, users see a prioritized list of information cards related to their most recently accessed projects or tasks in connected applications."
test "For instance, a musician who has lost there hearing might collaborate with a visual artist to create a series of abstract paintings that attempt to translate the emotional impact of music into a visual form." "For instance, a musician who has lost their hearing might collaborate with a visual artist to create a series of abstract paintings that attempt to translate the emotional impact of music into a visual form."
test "There relatively low density facilitates handling and transportation." "Their relatively low density facilitates handling and transportation."
test "The growing interest in mycelium-based construction materials stems from there potential to offer a sustainable alternative to conventional building materials." "The growing interest in mycelium-based construction materials stems from their potential to offer a sustainable alternative to conventional building materials."
test "Similarly, the individual experiencing sensory loss must actively reconstruct there understanding of the world, mapping the contours of there new, altered reality." "Similarly, the individual experiencing sensory loss must actively reconstruct their understanding of the world, mapping the contours of their new, altered reality."

allows "There are several options to consider."
allows "I left the keys there on the counter."
allows "We should meet there after work, near the fountain."
allows "There will be more questions."
allows "There isn't any time left."
allows "There's a note taped under the table."
allows "I saw him standing there, perfectly still."
allows "Leave the umbrella there by the door."
allows "The answer is right there in the first paragraph."
allows "Are there known issues between these specific versions of Elementor and ACF that I’m unaware of?"
allows "There are lots of different phases."
allows "Yet, there are pockets of silence, moments where the urban soundscape recedes."
allows "While there are areas for improvement, the plugin is already a valuable tool for developers who want a modern and efficient debugging experience."


================================================
FILE: harper-core/src/linting/weir_rules/TheyreToTheir.weir
================================================
expr main [<(they're [NOUN, (NOUN NOUN), (ADJ NOUN), (ADV ADJ NOUN), (VERB NOUN), (ADV VERB NOUN), (ADV ADV VERB NOUN), (ADJ PUNCT ADJ NOUN), (mittens), (sketches), (past), (needs), (pawn), (ability), (return), (potential to), (understanding), (new)]), they're>]

let message "Did you mean `their`?"
let description "Corrects `they're` when the intended meaning is `their`."
let kind "Grammar"
let becomes "their"

allows "They're going to be late."
allows "I think they're already here."
allows "They're not sure what to do next."
allows "They're coming over after work."
allows "Tell them they're invited to the meeting."
allows "They're trying to fix the bug right now."
allows "They're going to love this movie."
allows "They're the fastest team in the league."
allows "They're supposed to call you back today."
allows "They're leaving in five minutes."
allows "I heard they're moving to Denver."
allows "They're just kidding--don't worry."
allows "They're going to email the final draft tonight."
allows "They're not available until Tuesday."
allows "They're planning a surprise party."
allows "Looks like they're running behind schedule."
allows "They're the ones who approved it."
allows "They're going to miss the train."
allows "They're still waiting for the test results."
allows "They're not allowed to park here."
allows "They're going to change the policy."
allows "They're ready to start whenever you are."
allows "They're not answering any messages."
allows "They're going to be a problem if we don't hurry."
allows "They're probably wondering where we went."
test "They're backpacks were stacked neatly by the door." "Their backpacks were stacked neatly by the door."
test "I admired they're patience during the long, glitchy delay." "I admired their patience during the long, glitchy delay."
test "They're dog sprinted across the yard like a furry comet." "Their dog sprinted across the yard like a furry comet."
test "The committee revised they're proposal after the budget changed." "The committee revised their proposal after the budget changed."
test "They're laughter drifted down the hallway, bright and unguarded." "Their laughter drifted down the hallway, bright and unguarded."
test "We borrowed they're ladder to reach the stubborn light fixture." "We borrowed their ladder to reach the stubborn light fixture."
test "They're apartment smells like coffee, citrus, and old paperbacks." "Their apartment smells like coffee, citrus, and old paperbacks."
test "The kids lost they're mittens somewhere between the car and the rink." "The kids lost their mittens somewhere between the car and the rink."
test "They're answer was careful, precise, and unexpectedly kind." "Their answer was careful, precise, and unexpectedly kind."
test "The artists framed they're sketches before the gallery opened." "The artists framed their sketches before the gallery opened."
test "They're server crashed, but they're backup plan worked flawlessly." "Their server crashed, but their backup plan worked flawlessly."
test "I couldn't ignore they're evidence; it was meticulously documented." "I couldn't ignore their evidence; it was meticulously documented."
test "They're garden is a riot of basil, tomatoes, and bee traffic." "Their garden is a riot of basil, tomatoes, and bee traffic."
test "The hikers checked they're maps twice before leaving the trailhead." "The hikers checked their maps twice before leaving the trailhead."
test "They're team celebrated quietly--relieved more than triumphant." "Their team celebrated quietly--relieved more than triumphant."
test "Users should be able to visualize they're connected notes as a knowledge graph, allowing them to explore relationships and identify patterns." "Users should be able to visualize their connected notes as a knowledge graph, allowing them to explore relationships and identify patterns."
test "The frustration was palpable; the team felt they were fighting a constant uphill battle against they're own data infrastructure." "The frustration was palpable; the team felt they were fighting a constant uphill battle against their own data infrastructure."
test "Historians and sociologists have long examined how societies construct and maintain narratives about they're past." "Historians and sociologists have long examined how societies construct and maintain narratives about their past."
test "Traditional maps, often produced by the colonizers, replaced native nomenclature with European equivalents, effectively severing a vital link between people and they're ancestral lands." "Traditional maps, often produced by the colonizers, replaced native nomenclature with European equivalents, effectively severing a vital link between people and their ancestral lands."
test "She believes I should prioritize they're needs above my own." "She believes I should prioritize their needs above my own."
test "Each player places they're pawn on GRI Headquarters (designated space on the board)." "Each player places their pawn on GRI Headquarters (designated space on the board)."
test "This fragmented view hindered they're ability to make timely adjustments, ultimately impacting they're return on investment." "This fragmented view hindered their ability to make timely adjustments, ultimately impacting their return on investment."
test "My shift was nearing its end, and I was conducting my final rounds, ensuring each patient was comfortable and they're needs were met." "My shift was nearing its end, and I was conducting my final rounds, ensuring each patient was comfortable and their needs were met."
test "Upon opening the application, users see a prioritized list of information cards related to they're most recently accessed projects or tasks in connected applications." "Upon opening the application, users see a prioritized list of information cards related to their most recently accessed projects or tasks in connected applications."
test "For instance, a musician who has lost they're hearing might collaborate with a visual artist to create a series of abstract paintings that attempt to translate the emotional impact of music into a visual form." "For instance, a musician who has lost their hearing might collaborate with a visual artist to create a series of abstract paintings that attempt to translate the emotional impact of music into a visual form."
test "They're relatively low density facilitates handling and transportation." "Their relatively low density facilitates handling and transportation."
test "The growing interest in mycelium-based construction materials stems from they're potential to offer a sustainable alternative to conventional building materials." "The growing interest in mycelium-based construction materials stems from their potential to offer a sustainable alternative to conventional building materials."
test "Similarly, the individual experiencing sensory loss must actively reconstruct they're understanding of the world, mapping the contours of they're new, altered reality." "Similarly, the individual experiencing sensory loss must actively reconstruct their understanding of the world, mapping the contours of their new, altered reality."



================================================
FILE: harper-core/src/linting/weir_rules/ThoughtProcess.weir
================================================
expr main (though process)

let message "Did you mean `thought process`?"
let description "Changes `though process` to `thought process`."
let kind "Typo"
let becomes "thought process"




================================================
FILE: harper-core/src/linting/weir_rules/TickingTimeClock.weir
================================================
expr main (ticking time clock)

let message "Use `ticking time bomb` for disastrous consequences, otherwise avoid redundancy with just `ticking clock`."
let description "Corrects `ticking time clock` to `ticking time bomb` for idiomatic urgency or `ticking clock` otherwise."
let kind "Usage"
let becomes ["ticking time bomb", "ticking clock"]

test "One element that can help up the stakes (and tension!) is a \“ticking time clock.\”" "One element that can help up the stakes (and tension!) is a \“ticking time bomb.\”"
test "The opportunity itself has a ticking time clock as all great opportunities do." "The opportunity itself has a ticking clock as all great opportunities do."



================================================
FILE: harper-core/src/linting/weir_rules/ToDoHyphen.weir
================================================
expr main (todo)

let message "Hyphenate `to-do`."
let description "Ensures `to-do` is correctly hyphenated."
let becomes "to-do"




================================================
FILE: harper-core/src/linting/weir_rules/ToGreatLengths.weir
================================================
expr main [(through great lengths), (to a great length)]

let message "The idiom is to go `to great lengths`."
let description "Corrects `through great lengths` to `to great lengths`."
let becomes "to great lengths"

test "Bloomberg's sponsored paid for content goes through great lengths to market Nvidia's products and in particular its AI products that we've frequently criticized." "Bloomberg's sponsored paid for content goes to great lengths to market Nvidia's products and in particular its AI products that we've frequently criticized."
test "While ratatui-image goes to a great length to detect a rendered image's pixel size in terms of \"character cells that will be covered\", via font pixel size detection, ultimately it's up to the terminal emulator to decide what exactly a pixel is." "While ratatui-image goes to great lengths to detect a rendered image's pixel size in terms of \"character cells that will be covered\", via font pixel size detection, ultimately it's up to the terminal emulator to decide what exactly a pixel is."



================================================
FILE: harper-core/src/linting/weir_rules/ToLoseTooLoose.weir
================================================
expr main [(to loose), (too lose)]

let message "For `not to win`, use `to lose`. For `not tight enough`, use `too loose`."
let description "Corrects mixing up `to` with `too` and `lose` with `loose`."
let kind "Spelling"
let becomes ["to lose", "too loose"]

test "Bits and pieces of legacy code that are lying around on my system and that it would be a pity to loose" "Bits and pieces of legacy code that are lying around on my system and that it would be a pity to lose"
test "infinite recursion caused by transforms that have their preconditions too lose and/or conflict with each other" "infinite recursion caused by transforms that have their preconditions too loose and/or conflict with each other"


================================================
FILE: harper-core/src/linting/weir_rules/TongueInCheek.weir
================================================
expr main (tongue and cheek)

let message "Use `tongue in cheek` for the idiom."
let description "Corrects the idiom when `and` replaces the needed preposition."
let kind "WordChoice"
let becomes "tongue in cheek"

test "The remark was entirely tongue and cheek." "The remark was entirely tongue in cheek."
test "It was a tongue and cheek response." "It was a tongue in cheek response."
test "He delivered it tongue and cheek, expecting a laugh." "He delivered it tongue in cheek, expecting a laugh."
test "\"tongue and cheek\" jokes are tough to read." "\"tongue in cheek\" jokes are tough to read."
test "Their tone was TONGUE AND CHEEK all night." "Their tone was TONGUE IN CHEEK all night."
test "Tongue and cheek banter kept the meeting light." "Tongue in cheek banter kept the meeting light."
test "Her note (totally tongue and cheek) made us smile." "Her note (totally tongue in cheek) made us smile."
test "Was that tongue and cheek or sincere?" "Was that tongue in cheek or sincere?"
allows "Their comments were deliberately tongue in cheek."
allows "That was a tongue-in-cheek reply."


================================================
FILE: harper-core/src/linting/weir_rules/ToTheMannerBorn.weir
================================================
expr main (to the manor born)

let message "Use the correct phrase for being naturally suited to something."
let description "Corrects `to the manor born` to `to the manner born`, ensuring the intended meaning of being naturally suited to a way of life."
let kind "Eggcorn"
let becomes "to the manner born"




================================================
FILE: harper-core/src/linting/weir_rules/Towards.weir
================================================
expr main (to towards)

let message "Use `towards` without the preceding `to`."
let description "Removes redundant `to` before `towards`."
let kind "Redundancy"
let becomes "towards"




================================================
FILE: harper-core/src/linting/weir_rules/ToWorryAbout.weir
================================================
expr main (to worried about)

let message "Did you mean the progressive form?"
let description "Fixes incorrect use of `to worried about`."
let becomes ["to worry about", "too worried about"]

test "I don't want you to worried about it." "I don't want you to worry about it."
test "I don't want you to worried about it." "I don't want you too worried about it."



================================================
FILE: harper-core/src/linting/weir_rules/TrialAndError.weir
================================================
expr main (trail and error)

let message "You misspelled `trial`."
let description "Corrects `trail` to `trial` in `trial and error`."
let kind "Typo"
let becomes "trial and error"

test "It was produced through trail and error." "It was produced through trial and error."



================================================
FILE: harper-core/src/linting/weir_rules/TrueToWord.weir
================================================
expr main <(true to [my, your, his, her, its, our, their, one's] words), words>

let message "Replace the plural `words` with the idiomatic singular form when someone stays true to a promise."
let description "Normalizes phrasing around `true to <possessive>` so it follows the conventional `true to one's word`."
let kind "Style"
let becomes "word"

test "She was true to her words." "She was true to her word."
test "He stays TRUE to his words daily." "He stays TRUE to his word daily."
test "We're true to our words even when it's hard." "We're true to our word even when it's hard."
test "You're true to your words, no matter what." "You're true to your word, no matter what."
test "I try to be true to my words." "I try to be true to my word."
test "They remain true to their words after the announcement." "They remain true to their word after the announcement."
test "True to one's words, the promise held." "True to one's word, the promise held."
test "True to its words, the contract stands." "True to its word, the contract stands."
test "He has been true to her words through thick and thin." "He has been true to her word through thick and thin."
test "They were true to THEIR words, so the customers celebrated." "They were true to THEIR word, so the customers celebrated."
test "One stays true to one's words while keeping a diary." "One stays true to one's word while keeping a diary."
test "I'm true to my words." "I'm true to my word."
test "True to your words, you resumed the pledge." "True to your word, you resumed the pledge."

allows "She was true to her word."
allows "They were true to the words they heard in class."
allows "Being true to your word is the goal."
allows "The article praised her true words."
allows "Our team is true to the word we said earlier."


================================================
FILE: harper-core/src/linting/weir_rules/TurnItOff.weir
================================================
expr main [(turn it of), (turn i of)]

let message "Did you mean `turn it off`?"
let description "Fixes the mistake in the phrase `turn it off`."
let kind "Typo"
let becomes "turn it off"

test "Turn it of" "Turn it off"
test "Turn i of" "Turn it off"
allows "turn it off"
allows "Turn it off"
allows "run by one"


================================================
FILE: harper-core/src/linting/weir_rules/Unless.weir
================================================
expr main (unless if)

let message "`Unless if` is not idiomatic English. `Unless`, `except if`, and `except when` express a condition that is true in all cases except one."
let description "Corrects `unless if`."
let kind "Usage"
let becomes ["unless", "except if", "except when"]

test "Simplex does not interpret the following invite link as an invite link unless if it has https:// in front of it." "Simplex does not interpret the following invite link as an invite link unless it has https:// in front of it."



================================================
FILE: harper-core/src/linting/weir_rules/VeryLess.weir
================================================
expr main (very less)

let message "English doesn't use `very` with `less`."
let description "Corrects `very less`."
let kind "Grammar"
let becomes ["much less", "far less", "a lot less"]

test "here is a simple way to do it with very less coding ... ;)" "here is a simple way to do it with much less coding ... ;)"
test "algorithm for processing large datasets with very less pre-configuration" "algorithm for processing large datasets with far less pre-configuration"
test "Also the gpu memory usage is very less." "Also the gpu memory usage is a lot less."



================================================
FILE: harper-core/src/linting/weir_rules/WantBe.weir
================================================
expr main (want be)

let message "Did you mean `won't be` or `want to be`?"
let description "Detects incorrect usage of `want be` and suggests `won't be` or `want to be` based on context."
let becomes ["won't be", "want to be"]




================================================
FILE: harper-core/src/linting/weir_rules/WaveFunction.weir
================================================
expr main (wavefunction)

let message "Did you mean `wave function`?"
let description "Identifies the mistake of merging `wave` and `function` into one word. In quantum mechanics, a `wave function` (written as two words) describes the mathematical function that represents the quantum state of a particle or system. Correct usage is crucial for clear and accurate scientific communication."
let kind "WordChoice"
let becomes "wave function"




================================================
FILE: harper-core/src/linting/weir_rules/WellBeing.weir
================================================
expr main (wellbeing)

let message "Use the hyphenated form for `well-being`."
let description "Ensures `well-being` is correctly hyphenated."
let kind "Punctuation"
let becomes "well-being"




================================================
FILE: harper-core/src/linting/weir_rules/WellKept.weir
================================================
expr main [(highly-kept), (highly kept)]

let message "`Highly-kept` is not standard. To describe secrets, `well-kept` is the most used phrase."
let description "Flags `highly-kept` and recommends `well-kept` as an alternative."
let kind "Usage"
let becomes "well-kept"

test "I assure you that frequency/angle dependence is a highly kept secret." "I assure you that frequency/angle dependence is a well-kept secret."
test "Well, Kushina's giving birth was already a highly-kept secret so it makes sense to operate with only the completely necessary personnel." "Well, Kushina's giving birth was already a well-kept secret so it makes sense to operate with only the completely necessary personnel."



================================================
FILE: harper-core/src/linting/weir_rules/WhetYourAppetite.weir
================================================
expr main (wet your appetite)

let message "Use the correct phrase for stimulating desire."
let description "Ensures `whet your appetite` is used correctly, distinguishing it from the incorrect `wet` variation."
let kind "Eggcorn"
let becomes "whet your appetite"




================================================
FILE: harper-core/src/linting/weir_rules/WillContain.weir
================================================
expr main (will contains)

let message "Did you mean `will contain`?"
let description "Incorrect verb form: `will` should be followed by the base form `contain`."
let kind "Agreement"
let becomes "will contain"




================================================
FILE: harper-core/src/linting/weir_rules/WithoutOut.weir
================================================
expr main without out

let message "Drop the duplicated `out` when it follows `without`."
let description "When writers accidentally type `without out`, Harper can collapse the two words back into the single preposition."
let kind "Typo"
let becomes "without"
let strategy "MatchCase"

test "Without out a doubt, the team delivered." "Without a doubt, the team delivered."
test "She ran without out hesitation this morning." "She ran without hesitation this morning."
test "Without out fail, the backup completed." "Without fail, the backup completed."
test "We proceed without out complaint from clients." "We proceed without complaint from clients."
test "Without out this addition, the plan collapses." "Without this addition, the plan collapses."
test "Without out any warning, the lights went out." "Without any warning, the lights went out."
test "Without OUT, the process would stop." "Without, the process would stop."
test "WITHOUT OUT luck, the players backed down." "WITHOUT luck, the players backed down."
test "without out all hope, we succeeded." "without all hope, we succeeded."
test "Last week we moved without out delay." "Last week we moved without delay."
allows "Without outstanding debts we can pivot."
allows "There is a without output fallback."
allows "The absence of outbuildings was puzzling."
allows "Without doubt, the plan succeeded."
allows "Mind the output to ensure correctness."


================================================
FILE: harper-core/src/linting/weir_rules/WorstCaseScenario.weir
================================================
expr main [(worst case scenario), (worst-case-scenario)]

let message "Hyphenate `worst-case`."
let description "Corrects `worst-case scenario` when the hyphen is missing or `worse` is used instead of `worst`."
let kind "Punctuation"
let becomes "worst-case scenario"

test "The worst case scenario can be calculated without looking at streams of data." "The worst-case scenario can be calculated without looking at streams of data."
test "CAPD worst-case-scenario cloud simulator for naughty clouds." "CAPD worst-case scenario cloud simulator for naughty clouds."
allows "Those are now on hold for month."


================================================
FILE: harper-core/src/linting/weir_rules/WroughtIron.weir
================================================
expr main [(rod iron), (rot iron), (rod-iron), (rot-iron)]

let message "Prefer the standard term `wrought iron`."
let description "`Wrought iron` is low-carbon, malleable iron used for decorative work; variants like `rod iron` or `rot iron` are phonetic misspellings that may confuse readers."
let kind "Eggcorn"
let becomes "wrought iron"

test "The gate was crafted from rod iron." "The gate was crafted from wrought iron."
test "The artisan works in rot iron." "The artisan works in wrought iron."
allows "She specialized in wrought iron artwork."


================================================
FILE: harper-core/src/linting/weir_rules/YeaToYeah.weir
================================================
expr main (yea)

let message "If you mean the informal word for `yes` and not the biblical or legalistic `yea`, the standard spelling is `yeah`."
let description "Corrects `yea` to `yeah`."
let kind "Spelling"
let becomes "yeah"

test "The very core basics are essentially the same because yea - it's just a web browser." "The very core basics are essentially the same because yeah - it's just a web browser."


================================================
FILE: harper-core/src/linting/weir_rules/YehToYeah.weir
================================================
expr main (yeh)

let message "If you mean the informal word for `yes`, the standard spelling is `yeah`."
let description "Corrects `yeh` to `yeah`."
let kind "Spelling"
let becomes "yeah"

test "But yeh, it seems I'm the only one that feels that way" "But yeah, it seems I'm the only one that feels that way"


================================================
FILE: harper-core/src/mask/mod.rs
================================================
use itertools::Itertools;

use crate::Span;

/// A Masker is a tool that can be composed to eliminate chunks of text from
/// being parsed. They can be composed to do things like isolate comments from a
/// programming language or disable linting for languages that have been
/// determined to not be English.
///
/// This is primarily used by [`crate::parsers::Mask`] to create parsers for
/// things like comments of programming languages.
pub trait Masker: Send + Sync {
    fn create_mask(&self, source: &[char]) -> Mask;
}

/// Identifies portions of a [`char`] sequence that should __not__ be ignored by
/// Harper.
pub struct Mask {
    // Right now, there aren't any use-cases where we can't treat this as a stack.
    //
    // Assumed that no elements overlap and exist in sorted order.
    pub(self) allowed: Vec<Span<char>>,
}

impl FromIterator<Span<char>> for Mask {
    fn from_iter<T: IntoIterator<Item = Span<char>>>(iter: T) -> Self {
        let allowed = iter
            .into_iter()
            .sorted_by_key(|span| span.start)
            .collect_vec();
        assert!(
            allowed.is_sorted_by(|a, b| a.end <= b.start),
            "Masker elements cannot overlap and must be sorted!"
        );

        Self { allowed }
    }
}

impl Mask {
    /// Create a new Mask for a given piece of text, marking all text as
    /// disallowed.
    pub fn new_blank() -> Self {
        Self {
            allowed: Vec::new(),
        }
    }

    pub fn iter_allowed<'a>(
        &'a self,
        source: &'a [char],
    ) -> impl Iterator<Item = (Span<char>, &'a [char])> {
        self.allowed.iter().map(|s| (*s, s.get_content(source)))
    }

    /// Mark a span of the text as allowed.
    pub fn push_allowed(&mut self, allowed: Span<char>) {
        if let Some(last) = self.allowed.last_mut() {
            assert!(
                allowed.start >= last.end,
                "Masker elements cannot overlap and must be sorted!"
            );

            if allowed.start == last.end {
                last.end = allowed.end;
                return;
            }
        }

        self.allowed.push(allowed)
    }

    /// Merge chunks that are only separated by whitespace.
    pub fn merge_whitespace_sep(&mut self, source: &[char]) {
        let mut after = Vec::with_capacity(self.allowed.len());

        let mut iter = 0..self.allowed.len();

        while let Some(i) = iter.next() {
            let a = self.allowed[i];

            if let Some(b) = self.allowed.get(i + 1) {
                let sep = Span::new(a.end, b.start);
                let sep_content = sep.get_content(source);

                if sep_content.iter().all(|c| c.is_whitespace() || *c == '\n') {
                    iter.next();
                    after.push(Span::new(a.start, b.end));
                    continue;
                }
            }

            after.push(a);
        }

        if self.allowed.len() != after.len() {
            self.allowed = after;
            self.merge_whitespace_sep(source);
        } else {
            self.allowed = after;
        }
    }
}

#[cfg(test)]
mod tests {
    use crate::{Mask, Span};

    #[test]
    fn bumps_existing() {
        let mut mask = Mask::new_blank();

        mask.push_allowed(Span::new_with_len(0, 1));
        mask.push_allowed(Span::new_with_len(1, 2));

        assert_eq!(mask.allowed.len(), 1)
    }

    #[test]
    fn merges_whitespace_sep() {
        let source: Vec<_> = "word word\nword".chars().collect();

        let mut mask = Mask::new_blank();
        mask.push_allowed(Span::new_with_len(0, 4));
        mask.push_allowed(Span::new_with_len(5, 4));
        mask.push_allowed(Span::new_with_len(10, 4));

        assert_eq!(mask.allowed.len(), 3);

        mask.merge_whitespace_sep(&source);

        assert_eq!(mask.allowed.len(), 1);
    }
}



================================================
FILE: harper-core/src/parsers/collapse_identifiers.rs
================================================
use std::collections::VecDeque;
use std::sync::Arc;

use itertools::Itertools;

use super::Parser;
use crate::expr::{ExprExt, SequenceExpr};
use crate::spell::Dictionary;
use crate::{Lrc, Span, Token, TokenKind, VecExt};

/// A parser that wraps any other parser to collapse token strings that match
/// the pattern `word_word` or `word-word`.
pub struct CollapseIdentifiers {
    inner: Box<dyn Parser>,
    dict: Arc<dyn Dictionary>,
}

impl CollapseIdentifiers {
    pub fn new(inner: Box<dyn Parser>, dict: Box<Arc<dyn Dictionary>>) -> Self {
        Self {
            inner,
            dict: *dict.clone(),
        }
    }
}

thread_local! {
    static WORD_OR_NUMBER: Lrc<SequenceExpr> = Lrc::new(SequenceExpr::default()
                .then_any_word()
                .then_one_or_more(SequenceExpr::default()
        .then_case_separator()
        .then_any_word()));
}

impl Parser for CollapseIdentifiers {
    fn parse(&self, source: &[char]) -> Vec<Token> {
        let mut tokens = self.inner.parse(source);

        let mut to_remove = VecDeque::default();

        for tok_span in WORD_OR_NUMBER
            .with(|v| v.clone())
            .iter_matches(&tokens, source)
            .collect::<Vec<_>>()
        {
            let start_tok = &tokens[tok_span.start];
            let end_tok = &tokens[tok_span.end - 1];
            let char_span = Span::new(start_tok.span.start, end_tok.span.end);

            if self.dict.contains_word(char_span.get_content(source)) {
                tokens[tok_span.start] = Token::new(char_span, TokenKind::blank_word());
                to_remove.extend(tok_span.start + 1..tok_span.end);
            }
        }

        tokens.remove_indices(to_remove.into_iter().sorted().unique().collect());

        tokens
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::spell::{FstDictionary, MergedDictionary, MutableDictionary};
    use crate::{
        DictWordMetadata,
        parsers::{PlainEnglish, StrParser},
    };

    #[test]
    fn matches_kebab() {
        let source: Vec<_> = "kebab-case".chars().collect();

        assert_eq!(
            WORD_OR_NUMBER
                .with(|v| v.clone())
                .iter_matches(&PlainEnglish.parse(&source), &source)
                .count(),
            1
        );
    }

    #[test]
    fn no_collapse() {
        let dict = FstDictionary::curated();
        let source = "This is a test.";

        let tokens =
            CollapseIdentifiers::new(Box::new(PlainEnglish), Box::new(dict)).parse_str(source);
        assert_eq!(tokens.len(), 8);
    }

    #[test]
    fn one_collapse() {
        let source = "This is a separated_identifier, wow!";
        let curated_dictionary = FstDictionary::curated();

        let tokens =
            CollapseIdentifiers::new(Box::new(PlainEnglish), Box::new(curated_dictionary.clone()))
                .parse_str(source);
        assert_eq!(tokens.len(), 13);

        let mut dict = MutableDictionary::new();
        dict.append_word_str("separated_identifier", DictWordMetadata::default());

        let mut merged_dict = MergedDictionary::new();
        merged_dict.add_dictionary(curated_dictionary);
        merged_dict.add_dictionary(Arc::new(dict));

        let tokens =
            CollapseIdentifiers::new(Box::new(PlainEnglish), Box::new(Arc::new(merged_dict)))
                .parse_str(source);
        assert_eq!(tokens.len(), 11);
    }

    #[test]
    fn kebab_collapse() {
        let source = "This is a separated-identifier, wow!";
        let curated_dictionary = FstDictionary::curated();

        let tokens =
            CollapseIdentifiers::new(Box::new(PlainEnglish), Box::new(curated_dictionary.clone()))
                .parse_str(source);

        assert_eq!(tokens.len(), 13);

        let mut dict = MutableDictionary::new();
        dict.append_word_str("separated-identifier", DictWordMetadata::default());

        let mut merged_dict = MergedDictionary::new();
        merged_dict.add_dictionary(curated_dictionary);
        merged_dict.add_dictionary(Arc::new(dict));

        let tokens =
            CollapseIdentifiers::new(Box::new(PlainEnglish), Box::new(Arc::new(merged_dict)))
                .parse_str(source);

        assert_eq!(tokens.len(), 11);
    }

    #[test]
    fn double_collapse() {
        let source = "This is a separated_identifier_token, wow!";
        let curated_dictionary = FstDictionary::curated();

        let tokens =
            CollapseIdentifiers::new(Box::new(PlainEnglish), Box::new(curated_dictionary.clone()))
                .parse_str(source);
        assert_eq!(tokens.len(), 15);

        let mut dict = MutableDictionary::new();
        dict.append_word_str("separated_identifier_token", DictWordMetadata::default());

        let mut merged_dict = MergedDictionary::new();
        merged_dict.add_dictionary(curated_dictionary);
        merged_dict.add_dictionary(Arc::new(dict));

        let tokens =
            CollapseIdentifiers::new(Box::new(PlainEnglish), Box::new(Arc::new(merged_dict)))
                .parse_str(source);
        assert_eq!(tokens.len(), 11);
    }

    #[test]
    fn two_collapses() {
        let source = "This is a separated_identifier, wow! separated_identifier";
        let curated_dictionary = FstDictionary::curated();

        let tokens =
            CollapseIdentifiers::new(Box::new(PlainEnglish), Box::new(curated_dictionary.clone()))
                .parse_str(source);
        assert_eq!(tokens.len(), 17);

        let mut dict = MutableDictionary::new();
        dict.append_word_str("separated_identifier", DictWordMetadata::default());

        let mut merged_dict = MergedDictionary::new();
        merged_dict.add_dictionary(curated_dictionary);
        merged_dict.add_dictionary(Arc::new(dict));

        let tokens =
            CollapseIdentifiers::new(Box::new(PlainEnglish), Box::new(Arc::new(merged_dict)))
                .parse_str(source);
        assert_eq!(tokens.len(), 13);
    }

    #[test]
    fn overlapping_identifiers() {
        let source = "This is a separated_identifier_token, wow!";
        let curated_dictionary = FstDictionary::curated();

        let tokens =
            CollapseIdentifiers::new(Box::new(PlainEnglish), Box::new(curated_dictionary.clone()))
                .parse_str(source);
        assert_eq!(tokens.len(), 15);

        let mut dict = MutableDictionary::new();
        dict.append_word_str("separated_identifier", DictWordMetadata::default());
        dict.append_word_str("identifier_token", DictWordMetadata::default());

        let mut merged_dict = MergedDictionary::new();
        merged_dict.add_dictionary(curated_dictionary);
        merged_dict.add_dictionary(Arc::new(dict));

        let tokens =
            CollapseIdentifiers::new(Box::new(PlainEnglish), Box::new(Arc::new(merged_dict)))
                .parse_str(source);
        assert_eq!(tokens.len(), 15);
    }

    #[test]
    fn nested_identifiers() {
        let source = "This is a separated_identifier_token, wow!";
        let curated_dictionary = FstDictionary::curated();

        let tokens =
            CollapseIdentifiers::new(Box::new(PlainEnglish), Box::new(curated_dictionary.clone()))
                .parse_str(source);
        assert_eq!(tokens.len(), 15);

        let mut dict = MutableDictionary::new();
        dict.append_word_str("separated_identifier_token", DictWordMetadata::default());
        dict.append_word_str("separated_identifier", DictWordMetadata::default());

        let mut merged_dict = MergedDictionary::new();
        merged_dict.add_dictionary(curated_dictionary);
        merged_dict.add_dictionary(Arc::new(dict));

        let tokens =
            CollapseIdentifiers::new(Box::new(PlainEnglish), Box::new(Arc::new(merged_dict)))
                .parse_str(source);
        assert_eq!(tokens.len(), 11);
    }
}



================================================
FILE: harper-core/src/parsers/isolate_english.rs
================================================
use super::{Parser, Token, TokenStringExt};
use crate::language_detection::is_likely_english;
use crate::spell::Dictionary;

/// A parser that wraps another, using heuristics to quickly redact paragraphs of a document that aren't
/// intended to be English text.
pub struct IsolateEnglish<D: Dictionary> {
    inner: Box<dyn Parser>,
    dict: D,
}

impl<D: Dictionary> IsolateEnglish<D> {
    pub fn new(inner: Box<dyn Parser>, dictionary: D) -> Self {
        Self {
            inner,
            dict: dictionary,
        }
    }
}

impl<D: Dictionary> Parser for IsolateEnglish<D> {
    fn parse(&self, source: &[char]) -> Vec<Token> {
        let tokens = self.inner.parse(source);

        let mut english_tokens: Vec<Token> = Vec::with_capacity(tokens.len());

        for chunk in tokens.iter_chunks() {
            if chunk.len() < 4 || is_likely_english(chunk, source, &self.dict) {
                english_tokens.extend_from_slice(chunk);
            }
        }

        english_tokens
    }
}

#[cfg(test)]
mod tests {
    use super::IsolateEnglish;
    use crate::spell::FstDictionary;
    use crate::{Document, TokenStringExt, parsers::PlainEnglish};

    /// Assert that the provided text contains _no_ chunks of valid English
    fn assert_no_english(text: &str) {
        let dict = FstDictionary::curated();

        let document = Document::new(
            text,
            &IsolateEnglish::new(Box::new(PlainEnglish), dict.clone()),
            &dict,
        );

        assert_eq!(document.iter_words().count(), 0);
        assert_eq!(document.iter_punctuations().count(), 0);
    }

    /// Assert that, once stripped of non-English chunks, the resulting document looks like another
    /// piece of text.
    fn assert_stripped_english(source: &str, target: &str) {
        let dict = FstDictionary::curated();

        let document = Document::new(
            source,
            &IsolateEnglish::new(Box::new(PlainEnglish), dict.clone()),
            &dict,
        );

        assert_eq!(document.to_string(), target);
    }

    #[test]
    fn mixed_spanish_english_breakfast() {
        assert_no_english(
            "En la mañana, como a dish de los huevos, un poquito of tocino, y a lot of leche.",
        );
    }

    #[test]
    fn mixed_spanish_english_politics() {
        assert_no_english(
            "No estoy of acuerdo con the politics de Los estados unidos ahora; pienso que we need mas diversidad in el gobierno.",
        );
    }

    #[test]
    fn english_no_edit_motto() {
        assert_stripped_english(
            "I have a simple motto in life: ",
            "I have a simple motto in life: ",
        );
    }

    #[test]
    fn chunked_trad_chinese_english() {
        assert_stripped_english(
            "I have a simple motto in life: 如果你渴了，就喝水。",
            "I have a simple motto in life:",
        );
    }

    #[test]
    fn chunked_trad_polish_english() {
        assert_stripped_english(
            "I have a simple motto in life: jeśli jesteś spragniony, napij się wody.",
            "I have a simple motto in life:",
        );
    }
}



================================================
FILE: harper-core/src/parsers/markdown.rs
================================================
use std::collections::VecDeque;

use serde::{Deserialize, Serialize};

use super::{Parser, PlainEnglish};
use crate::{Span, Token, TokenKind, TokenStringExt, VecExt};

/// A parser that wraps the [`PlainEnglish`] parser that allows one to parse
/// CommonMark files.
///
/// Will ignore code blocks and tables.
#[derive(Default, Clone, Debug, Copy)]
pub struct Markdown {
    options: MarkdownOptions,
}

#[derive(Copy, Clone, Debug, Serialize, Deserialize)]
#[non_exhaustive]
pub struct MarkdownOptions {
    pub ignore_link_title: bool,
}

// Clippy rule excepted because this can easily be expanded later
#[allow(clippy::derivable_impls)]
impl Default for MarkdownOptions {
    fn default() -> Self {
        Self {
            ignore_link_title: false,
        }
    }
}

impl Markdown {
    pub fn new(options: MarkdownOptions) -> Self {
        Self { options }
    }

    /// Remove hidden Wikilink target text.
    ///
    /// As in the stuff to the left of the pipe operator:
    ///
    /// ```markdown
    /// [[Target text|Display Text]]
    /// ```
    fn remove_hidden_wikilink_tokens(tokens: &mut Vec<Token>) {
        let mut to_remove = VecDeque::new();

        for pipe_idx in tokens.iter_pipe_indices() {
            if pipe_idx < 2 {
                continue;
            }

            // Locate preceding `[[`
            let mut cursor = pipe_idx - 2;
            let mut open_bracket = None;

            loop {
                let Some((a, b)) = tokens.get(cursor).zip(tokens.get(cursor + 1)) else {
                    break;
                };

                if a.kind.is_newline() {
                    break;
                }

                if a.kind.is_open_square() && b.kind.is_open_square() {
                    open_bracket = Some(cursor);
                    break;
                } else if cursor == 0 {
                    break;
                } else {
                    cursor -= 1;
                }
            }

            // Locate succeeding `[[`
            cursor = pipe_idx + 1;
            let mut close_bracket = None;

            loop {
                let Some((a, b)) = tokens.get(cursor).zip(tokens.get(cursor + 1)) else {
                    break;
                };

                if a.kind.is_newline() {
                    break;
                }

                if a.kind.is_close_square() && b.kind.is_close_square() {
                    close_bracket = Some(cursor);
                    break;
                } else {
                    cursor += 1;
                }
            }

            if let Some(open_bracket_idx) = open_bracket
                && let Some(close_bracket_idx) = close_bracket
            {
                to_remove.extend(open_bracket_idx..=pipe_idx);
                to_remove.push_back(close_bracket_idx);
                to_remove.push_back(close_bracket_idx + 1);
            }
        }

        tokens.remove_indices(to_remove);
    }

    /// Remove the brackets from Wikilinks without pipe operators.
    /// For __those__ Wikilinks, see [`Self::remove_hidden_wikilink_tokens`]
    fn remove_wikilink_brackets(tokens: &mut Vec<Token>) {
        let mut to_remove = VecDeque::new();
        let mut open_brackets = None;

        let mut cursor = 0;

        loop {
            let Some((a, b)) = tokens.get(cursor).zip(tokens.get(cursor + 1)) else {
                break;
            };

            if let Some(open_brackets_idx) = open_brackets {
                if a.kind.is_newline() {
                    open_brackets = None;
                    cursor += 1;
                    continue;
                }

                if a.kind.is_close_square() && b.kind.is_close_square() {
                    to_remove.push_back(open_brackets_idx);
                    to_remove.push_back(open_brackets_idx + 1);

                    to_remove.push_back(cursor);
                    to_remove.push_back(cursor + 1);

                    open_brackets = None;
                }
            } else if a.kind.is_open_square() && b.kind.is_open_square() {
                open_brackets = Some(cursor);
            }

            cursor += 1;
        }

        tokens.remove_indices(to_remove);
    }
}

impl Parser for Markdown {
    /// This implementation is quite gross to look at, but it works.
    /// If any issues arise, it would likely help to refactor this out first.
    fn parse(&self, source: &[char]) -> Vec<Token> {
        let english_parser = PlainEnglish;

        let source_str: String = source.iter().collect();
        let md_parser = pulldown_cmark::Parser::new_ext(
            &source_str,
            pulldown_cmark::Options::all()
                .difference(pulldown_cmark::Options::ENABLE_SMART_PUNCTUATION),
        );

        let mut tokens = Vec::new();

        // Build a mapping from the inner parser's byte-based indexing to Harper's char-based
        // indexing
        let mut byte_to_char = vec![0; source_str.len() + 1];
        let mut char_index = 0;
        let mut byte_idx = 0;
        for ch in source_str.chars() {
            let char_len = ch.len_utf8();
            for _ in 0..char_len {
                byte_to_char[byte_idx] = char_index;
                byte_idx += 1;
            }
            char_index += 1;
        }
        byte_to_char[source_str.len()] = char_index;

        let mut stack = Vec::new();

        // NOTE: the range spits out __byte__ indices, not char indices.
        // This is why we keep track above.
        for (event, range) in md_parser.into_offset_iter() {
            let span_start = byte_to_char[range.start];
            let span_end = byte_to_char[range.end];

            match event {
                pulldown_cmark::Event::SoftBreak => {
                    tokens.push(Token {
                        span: Span::new_with_len(span_start, 1),
                        kind: TokenKind::Newline(1),
                    });
                }
                pulldown_cmark::Event::HardBreak => {
                    tokens.push(Token {
                        span: Span::new_with_len(span_start, 1),
                        kind: TokenKind::Newline(2),
                    });
                }
                pulldown_cmark::Event::Start(pulldown_cmark::Tag::List(v)) => {
                    tokens.push(Token {
                        span: Span::new_with_len(span_start, 0),
                        kind: TokenKind::Newline(2),
                    });
                    stack.push(pulldown_cmark::Tag::List(v));
                }
                pulldown_cmark::Event::Start(tag) => {
                    if matches!(tag, pulldown_cmark::Tag::Heading { .. }) {
                        tokens.push(Token {
                            span: Span::new_with_len(span_start, 0),
                            kind: TokenKind::HeadingStart,
                        });
                    }

                    stack.push(tag)
                }
                pulldown_cmark::Event::End(pulldown_cmark::TagEnd::Paragraph)
                | pulldown_cmark::Event::End(pulldown_cmark::TagEnd::Item)
                | pulldown_cmark::Event::End(pulldown_cmark::TagEnd::Heading(_))
                | pulldown_cmark::Event::End(pulldown_cmark::TagEnd::CodeBlock)
                | pulldown_cmark::Event::End(pulldown_cmark::TagEnd::TableCell) => {
                    tokens.push(Token {
                        // We cannot use `span_start` here, as it will still point to the
                        // first character of the `Event` at this point. Instead, we use the
                        // position of the previous token's last character. This ensures the
                        // paragraph break is placed at the end of the content, not its beginning.
                        // For more info, see: https://github.com/Automattic/harper/pull/1239.
                        span: Span::new_with_len(tokens.last().map_or(0, |last| last.span.end), 0),
                        kind: TokenKind::ParagraphBreak,
                    });
                    stack.pop();
                }
                pulldown_cmark::Event::End(_) => {
                    stack.pop();
                }
                pulldown_cmark::Event::InlineMath(_)
                | pulldown_cmark::Event::DisplayMath(_)
                | pulldown_cmark::Event::Code(_) => {
                    let chunk_len = span_end - span_start;

                    tokens.push(Token {
                        span: Span::new_with_len(span_start, chunk_len),
                        kind: TokenKind::Unlintable,
                    });
                }
                pulldown_cmark::Event::Text(_text) => {
                    let chunk_len = span_end - span_start;

                    if let Some(tag) = stack.last() {
                        use pulldown_cmark::Tag;

                        if matches!(tag, Tag::CodeBlock(..)) {
                            tokens.push(Token {
                                span: Span::new_with_len(span_start, chunk_len),

                                kind: TokenKind::Unlintable,
                            });
                            continue;
                        }
                        if matches!(tag, Tag::Link { .. }) && self.options.ignore_link_title {
                            tokens.push(Token {
                                span: Span::new_with_len(span_start, chunk_len),
                                kind: TokenKind::Unlintable,
                            });
                            continue;
                        }
                        if !(matches!(tag, Tag::Paragraph)
                            || (matches!(tag, Tag::Link { .. }) && !self.options.ignore_link_title)
                            || matches!(tag, Tag::Heading { .. })
                            || matches!(tag, Tag::Item)
                            || matches!(tag, Tag::TableCell)
                            || matches!(tag, Tag::Emphasis)
                            || matches!(tag, Tag::Strong)
                            || matches!(tag, Tag::Strikethrough))
                        {
                            continue;
                        }
                    }

                    let mut new_tokens = english_parser.parse(&source[span_start..span_end]);

                    new_tokens
                        .iter_mut()
                        .for_each(|token| token.span.push_by(span_start));

                    tokens.append(&mut new_tokens);
                }
                // TODO: Support via `harper-html`
                pulldown_cmark::Event::Html(_) | pulldown_cmark::Event::InlineHtml(_) => {
                    let size = span_end - span_start;
                    tokens.push(Token {
                        span: Span::new_with_len(span_start, size),
                        kind: TokenKind::Unlintable,
                    });
                }
                _ => (),
            }
        }

        if matches!(
            tokens.last(),
            Some(Token {
                kind: TokenKind::Newline(_) | TokenKind::ParagraphBreak,
                ..
            })
        ) && source.last() != Some(&'\n')
        {
            tokens.pop();
        }

        Self::remove_hidden_wikilink_tokens(&mut tokens);
        Self::remove_wikilink_brackets(&mut tokens);

        tokens
    }
}

#[cfg(test)]
mod tests {
    use super::super::StrParser;
    use super::Markdown;
    use crate::{Punctuation, TokenKind, TokenStringExt, parsers::markdown::MarkdownOptions};

    #[test]
    fn survives_emojis() {
        let source = r"🤷.";

        Markdown::default().parse_str(source);
    }

    /// Check whether the Markdown parser will emit a breaking newline
    /// at the end of each input.
    ///
    /// It should _not_ do this.
    #[test]
    fn ends_with_newline() {
        let source = "This is a test.";

        let tokens = Markdown::default().parse_str(source);
        assert_ne!(tokens.len(), 0);
        assert!(!tokens.last().unwrap().kind.is_newline());
    }

    #[test]
    fn math_becomes_unlintable() {
        let source = r"$\Katex$ $\text{is}$ $\text{great}$.";

        let tokens = Markdown::default().parse_str(source);
        assert_eq!(
            tokens.iter().map(|t| t.kind.clone()).collect::<Vec<_>>(),
            vec![
                TokenKind::Unlintable,
                TokenKind::Space(1),
                TokenKind::Unlintable,
                TokenKind::Space(1),
                TokenKind::Unlintable,
                TokenKind::Punctuation(Punctuation::Period)
            ]
        )
    }

    #[test]
    fn hidden_wikilink_text() {
        let source = r"[[this is hidden|this is not]]";

        let tokens = Markdown::default().parse_str(source);

        let token_kinds = tokens.iter().map(|t| t.kind.clone()).collect::<Vec<_>>();

        assert!(matches!(
            token_kinds.as_slice(),
            &[
                TokenKind::Word(_),
                TokenKind::Space(1),
                TokenKind::Word(_),
                TokenKind::Space(1),
                TokenKind::Word(_),
            ]
        ))
    }

    #[test]
    fn just_pipe() {
        let source = r"|";

        let tokens = Markdown::default().parse_str(source);

        let token_kinds = tokens.iter().map(|t| t.kind.clone()).collect::<Vec<_>>();

        dbg!(&token_kinds);

        assert!(matches!(
            token_kinds.as_slice(),
            &[TokenKind::Punctuation(Punctuation::Pipe)]
        ))
    }

    #[test]
    fn empty_wikilink_text() {
        let source = r"[[|]]";

        let tokens = Markdown::default().parse_str(source);

        let token_kinds = tokens.iter().map(|t| t.kind.clone()).collect::<Vec<_>>();

        dbg!(&token_kinds);

        assert!(matches!(token_kinds.as_slice(), &[]))
    }

    #[test]
    fn improper_wikilink_text() {
        let source = r"this is shown|this is also shown]]";

        let tokens = Markdown::default().parse_str(source);

        let token_kinds = tokens.iter().map(|t| t.kind.clone()).collect::<Vec<_>>();

        dbg!(&token_kinds);

        assert!(matches!(
            token_kinds.as_slice(),
            &[
                TokenKind::Word(_),
                TokenKind::Space(1),
                TokenKind::Word(_),
                TokenKind::Space(1),
                TokenKind::Word(_),
                TokenKind::Punctuation(Punctuation::Pipe),
                TokenKind::Word(_),
                TokenKind::Space(1),
                TokenKind::Word(_),
                TokenKind::Space(1),
                TokenKind::Word(_),
                TokenKind::Space(1),
                TokenKind::Word(_),
                TokenKind::Punctuation(Punctuation::CloseSquare),
                TokenKind::Punctuation(Punctuation::CloseSquare),
            ]
        ))
    }

    #[test]
    fn normal_wikilink() {
        let source = r"[[Wikilink]]";
        let tokens = Markdown::default().parse_str(source);
        let token_kinds = tokens.iter().map(|t| t.kind.clone()).collect::<Vec<_>>();

        dbg!(&token_kinds);

        assert!(matches!(token_kinds.as_slice(), &[TokenKind::Word(_)]))
    }

    #[test]
    fn html_is_unlintable() {
        let source = r"The range of inputs from <ctrl-g> to ctrl-z";
        let tokens = Markdown::default().parse_str(source);
        assert_eq!(tokens.iter_unlintables().count(), 1);
    }

    #[test]
    fn link_title_unlintable() {
        let parser = Markdown::new(MarkdownOptions {
            ignore_link_title: true,
            ..MarkdownOptions::default()
        });
        let source = r"[elijah-potter/harper](https://github.com/elijah-potter/harper)";
        let tokens = parser.parse_str(source);
        let token_kinds = tokens.iter().map(|t| t.kind.clone()).collect::<Vec<_>>();

        dbg!(&token_kinds);

        assert!(matches!(token_kinds.as_slice(), &[TokenKind::Unlintable]))
    }

    #[test]
    fn issue_194() {
        let source = r"<http://localhost:9093>";
        let parser = Markdown::new(MarkdownOptions {
            ignore_link_title: true,
            ..MarkdownOptions::default()
        });
        let token_kinds = parser
            .parse_str(source)
            .iter()
            .map(|t| t.kind.clone())
            .collect::<Vec<_>>();

        assert!(matches!(token_kinds.as_slice(), &[TokenKind::Unlintable]));
    }

    #[test]
    fn respects_link_title_config() {
        let source = r"[elijah-potter/harper](https://github.com/elijah-potter/harper)";
        let parser = Markdown::new(MarkdownOptions {
            ignore_link_title: true,
            ..MarkdownOptions::default()
        });
        let token_kinds = parser
            .parse_str(source)
            .iter()
            .map(|t| t.kind.clone())
            .collect::<Vec<_>>();

        assert!(matches!(token_kinds.as_slice(), &[TokenKind::Unlintable]));

        let parser = Markdown::new(MarkdownOptions {
            ignore_link_title: false,
            ..MarkdownOptions::default()
        });
        let token_kinds = parser
            .parse_str(source)
            .iter()
            .map(|t| t.kind.clone())
            .collect::<Vec<_>>();

        dbg!(&token_kinds);

        assert!(matches!(
            token_kinds.as_slice(),
            &[
                TokenKind::Word(_),
                TokenKind::Punctuation(Punctuation::Hyphen),
                TokenKind::Word(_),
                TokenKind::Punctuation(Punctuation::ForwardSlash),
                TokenKind::Word(_)
            ]
        ));
    }

    /// Test that code blocks are immediately followed by a paragraph break.
    #[test]
    fn issue_880() {
        let source = r#"
Paragraph.

```
Code block
```
Paragraph.
        "#;
        let parser = Markdown::new(MarkdownOptions::default());
        let tokens = parser.parse_str(source);
        let token_kinds = tokens.iter().map(|t| t.kind.clone()).collect::<Vec<_>>();

        dbg!(&token_kinds);

        assert!(matches!(
            token_kinds.as_slice(),
            &[
                TokenKind::Word(_),
                TokenKind::Punctuation(_),
                TokenKind::ParagraphBreak,
                TokenKind::Unlintable,
                TokenKind::ParagraphBreak,
                TokenKind::Word(_),
                TokenKind::Punctuation(_),
            ]
        ))
    }

    /// Helps ensure that ending tokens (like `ParagraphBreak`) don't get erroneously placed at
    /// the beginning of a sentence. This kind of behavior can cause crashes, as seen in
    /// [#1181](https://github.com/Automattic/harper/issues/1181).
    #[test]
    fn no_end_token_incorrectly_ending_at_zero() {
        let source = "Something\n";
        let parser = Markdown::new(MarkdownOptions::default());
        let tokens = parser.parse_str(source);
        assert_ne!(tokens.last().unwrap().span.end, 0);
    }

    #[test]
    fn hang() {
        let opts = MarkdownOptions::default();
        let parser = Markdown::new(opts);
        let _res = parser.parse_str("[[#|]]:A]");
    }

    #[test]
    fn hang2() {
        // This seems to only be a java specific problem...
        let opts = MarkdownOptions::default();
        let parser = Markdown::new(opts);
        let _res = parser.parse_str("//{@j");
    }

    #[test]
    fn simple_headings_are_marked() {
        let opts = MarkdownOptions::default();
        let parser = Markdown::new(opts);
        let tokens = parser.parse_str("# This is a simple heading");

        assert_eq!(tokens.iter_heading_starts().count(), 1);
        assert_eq!(tokens.iter_headings().count(), 1);
    }

    #[test]
    fn multiple_headings_are_marked() {
        let opts = MarkdownOptions::default();
        let parser = Markdown::new(opts);
        let tokens = parser.parse_str(
            r#"# This is a simple heading

## This is a second simple heading"#,
        );

        assert_eq!(tokens.iter_heading_starts().count(), 2);
        assert_eq!(tokens.iter_headings().count(), 2);
    }
}



================================================
FILE: harper-core/src/parsers/mask.rs
================================================
use super::Parser;
use crate::mask::Masker;
use crate::{Span, Token, TokenKind};

/// Composes a Masker and a Parser to parse only masked chunks of text.
pub struct Mask<M, P>
where
    M: Masker,
    P: Parser,
{
    pub masker: M,
    pub parser: P,
}

impl<M, P> Mask<M, P>
where
    M: Masker,
    P: Parser,
{
    pub fn new(masker: M, parser: P) -> Self {
        Self { masker, parser }
    }
}

impl<M, P> Parser for Mask<M, P>
where
    M: Masker,
    P: Parser,
{
    fn parse(&self, source: &[char]) -> Vec<Token> {
        let mask = self.masker.create_mask(source);

        let mut tokens: Vec<Token> = Vec::new();

        let mut last_allowed: Option<Span<char>> = None;

        for (span, content) in mask.iter_allowed(source) {
            // Check for a line break separating the current chunk from the preceding one.
            if let Some(last_allowed) = last_allowed {
                let intervening = Span::new(last_allowed.end, span.start);

                if intervening.get_content(source).contains(&'\n') {
                    tokens.push(Token::new(intervening, TokenKind::ParagraphBreak))
                }
            }

            let new_tokens = &mut self.parser.parse(content);

            for token in new_tokens.iter_mut() {
                token.span.push_by(span.start);
            }

            tokens.append(new_tokens);
            last_allowed = Some(span);
        }

        tokens
    }
}



================================================
FILE: harper-core/src/parsers/mod.rs
================================================
//! Adds support for parsing various programming and markup languages through a unified trait: [`Parser`].

mod collapse_identifiers;
mod isolate_english;
mod markdown;
mod mask;
mod oops_all_headings;
mod org_mode;
mod plain_english;

use blanket::blanket;
pub use collapse_identifiers::CollapseIdentifiers;
pub use isolate_english::IsolateEnglish;
pub use markdown::{Markdown, MarkdownOptions};
pub use mask::Mask;
pub use oops_all_headings::OopsAllHeadings;
pub use org_mode::OrgMode;
pub use plain_english::PlainEnglish;

use crate::{LSend, Token, TokenStringExt};

#[cfg_attr(feature = "concurrent", blanket(derive(Ref, Box, Arc)))]
#[cfg_attr(not(feature = "concurrent"), blanket(derive(Ref, Box, Rc)))]
pub trait Parser: LSend {
    fn parse(&self, source: &[char]) -> Vec<Token>;
}

pub trait StrParser {
    fn parse_str(&self, source: impl AsRef<str>) -> Vec<Token>;
}

impl<T> StrParser for T
where
    T: Parser,
{
    fn parse_str(&self, source: impl AsRef<str>) -> Vec<Token> {
        let source: Vec<_> = source.as_ref().chars().collect();
        self.parse(&source)
    }
}

#[cfg(test)]
mod tests {
    use super::{Markdown, OrgMode, Parser, PlainEnglish};
    use crate::Punctuation;
    use crate::TokenKind::{self, *};

    fn assert_tokens_eq(test_str: impl AsRef<str>, expected: &[TokenKind], parser: &impl Parser) {
        let chars: Vec<_> = test_str.as_ref().chars().collect();
        let tokens = parser.parse(&chars);
        let kinds: Vec<_> = tokens.into_iter().map(|v| v.kind).collect();

        assert_eq!(&kinds, expected)
    }

    fn assert_tokens_eq_plain(test_str: impl AsRef<str>, expected: &[TokenKind]) {
        assert_tokens_eq(test_str, expected, &PlainEnglish);
    }

    fn assert_tokens_eq_md(test_str: impl AsRef<str>, expected: &[TokenKind]) {
        assert_tokens_eq(test_str, expected, &Markdown::default())
    }

    fn assert_tokens_eq_org(test_str: impl AsRef<str>, expected: &[TokenKind]) {
        assert_tokens_eq(test_str, expected, &OrgMode)
    }

    #[test]
    fn single_letter() {
        assert_tokens_eq_plain("a", &[TokenKind::blank_word()])
    }

    #[test]
    fn sentence() {
        assert_tokens_eq_plain(
            "hello world, my friend",
            &[
                TokenKind::blank_word(),
                Space(1),
                TokenKind::blank_word(),
                Punctuation(Punctuation::Comma),
                Space(1),
                TokenKind::blank_word(),
                Space(1),
                TokenKind::blank_word(),
            ],
        )
    }

    #[test]
    fn sentence_md() {
        assert_tokens_eq_md(
            "__hello__ world, [my]() friend",
            &[
                TokenKind::blank_word(),
                Space(1),
                TokenKind::blank_word(),
                Punctuation(Punctuation::Comma),
                Space(1),
                TokenKind::blank_word(),
                Space(1),
                TokenKind::blank_word(),
            ],
        );
    }

    #[test]
    fn inserts_newlines() {
        assert_tokens_eq_md(
            "__hello__ world,\n\n[my]() friend",
            &[
                TokenKind::blank_word(),
                Space(1),
                TokenKind::blank_word(),
                Punctuation(Punctuation::Comma),
                ParagraphBreak,
                TokenKind::blank_word(),
                Space(1),
                TokenKind::blank_word(),
            ],
        );
    }

    /// Make sure that the English parser correctly identifies non-English
    /// characters as part of the same word.
    #[test]
    fn parses_non_english() {
        assert_tokens_eq_plain("Løvetann", &[TokenKind::blank_word()]);
        assert_tokens_eq_plain("Naïve", &[TokenKind::blank_word()]);
    }

    #[test]
    fn org_mode_basic() {
        assert_tokens_eq_org(
            "hello world",
            &[TokenKind::blank_word(), Space(1), TokenKind::blank_word()],
        );
    }
}



================================================
FILE: harper-core/src/parsers/oops_all_headings.rs
================================================
use crate::{Span, Token, TokenKind};

use super::Parser;

/// A parser that wraps another, forcing the entirety of the document to be composed of headings.
pub struct OopsAllHeadings<P: Parser + 'static> {
    inner: P,
}

impl<P: Parser + 'static> OopsAllHeadings<P> {
    pub fn new(inner: P) -> Self {
        Self { inner }
    }
}

impl<P: Parser + 'static> Parser for OopsAllHeadings<P> {
    fn parse(&self, source: &[char]) -> Vec<Token> {
        let inner = self.inner.parse(source);
        let mut output = Vec::with_capacity(inner.capacity());

        output.push(Token {
            span: Span::default(),
            kind: TokenKind::HeadingStart,
        });

        let mut iter = inner.into_iter().peekable();

        while let Some(tok) = iter.next() {
            let heading_start = if tok.kind.is_paragraph_break()
                && iter.peek().is_some_and(|t| !t.kind.is_heading_start())
            {
                Some(Token {
                    span: Span::new_with_len(tok.span.end, 0),
                    kind: TokenKind::HeadingStart,
                })
            } else {
                None
            };

            output.push(tok);

            if let Some(extra) = heading_start {
                output.push(extra);
            }
        }

        output
    }
}



================================================
FILE: harper-core/src/parsers/org_mode.rs
================================================
use super::{Parser, PlainEnglish};
use crate::{Span, Token, TokenKind};

#[derive(Debug, PartialEq, Copy, Clone)]
enum SourceBlockMarker {
    Begin,
    End,
}

// Check if a line starts with a header (starts with one or more '*')
fn is_header_line(chars: &[char], start: usize) -> bool {
    chars.get(start).is_some_and(|c| *c == '*')
}

// Check if a line starts with a source block begin/end
fn is_source_block_marker(chars: &[char], start: usize) -> Option<SourceBlockMarker> {
    let line = get_line_from_start(chars, start);
    let line_str: String = line.iter().collect();
    let line_str = line_str.trim();

    if line_str.starts_with("#+BEGIN_SRC") || line_str.starts_with("#+begin_src") {
        Some(SourceBlockMarker::Begin)
    } else if line_str.starts_with("#+END_SRC") || line_str.starts_with("#+end_src") {
        Some(SourceBlockMarker::End)
    } else {
        None
    }
}

// Check if a line is a directive (starts with #+)
fn is_directive(chars: &[char], start: usize) -> bool {
    if start + 1 >= chars.len() {
        return false;
    }
    chars[start] == '#' && chars[start + 1] == '+'
}

// Check if a line is a list item (starts with -, +, or number)
fn is_list_item(chars: &[char], start: usize) -> bool {
    let mut pos = start;

    // initial whitespaces or tabs
    while pos < chars.len() && (chars[pos] == ' ' || chars[pos] == '\t') {
        pos += 1;
    }

    if pos >= chars.len() {
        return false;
    }

    // Check for - or + followed by space
    if (chars[pos] == '-' || chars[pos] == '+') && pos + 1 < chars.len() && chars[pos + 1] == ' ' {
        return true;
    }

    // Check for numbered list
    if chars[pos].is_ascii_digit() {
        let mut num_pos = pos;
        while num_pos < chars.len() && chars[num_pos].is_ascii_digit() {
            num_pos += 1;
        }

        if num_pos < chars.len()
            && (chars[num_pos] == '.' || chars[num_pos] == ')')
            && num_pos + 1 < chars.len()
            && chars[num_pos + 1] == ' '
        {
            return true;
        }
    }

    false
}

// Convert tabs to spaces in list items to avoid French spaces error
fn normalize_list_item_whitespace(chars: &[char]) -> Vec<char> {
    let mut result = Vec::new();
    let mut init_list = false;
    for &ch in chars {
        if !init_list && ch == '\t' {
            result.push(' ');
            init_list = true;
        } else {
            result.push(ch);
        }
    }
    result
}

// Get the rest of the line from a starting position
fn get_line_from_start(chars: &[char], start: usize) -> &[char] {
    let mut end = start;
    while end < chars.len() && chars[end] != '\n' {
        end += 1;
    }
    &chars[start..end]
}

// Find the end of the current line starting from position
fn find_line_end(chars: &[char], start: usize) -> usize {
    let mut pos = start;
    while pos < chars.len() && chars[pos] != '\n' {
        pos += 1;
    }
    if pos < chars.len() && chars[pos] == '\n' {
        pos + 1 // Include the newline
    } else {
        pos
    }
}

// Find the start of the line containing the given position
fn find_line_start(chars: &[char], pos: usize) -> usize {
    let mut start = pos;
    while start > 0 && chars[start - 1] != '\n' {
        start -= 1;
    }
    start
}

/// A parser that wraps the [`PlainEnglish`] parser that allows one to parse
/// Org-mode files.
///
/// Will ignore code blocks, source blocks, and other org-mode specific elements
/// that should not be linted for prose.
#[derive(Default, Clone, Debug, Copy)]
pub struct OrgMode;

impl OrgMode {}

impl Parser for OrgMode {
    fn parse(&self, source: &[char]) -> Vec<Token> {
        let english_parser = PlainEnglish;
        let mut tokens = Vec::new();
        let mut cursor = 0;
        let mut in_source_block = false;

        while cursor < source.len() {
            let line_start = find_line_start(source, cursor);

            // Check for source block markers
            let source_marker = is_source_block_marker(source, line_start);
            if let Some(marker) = source_marker {
                in_source_block = marker == SourceBlockMarker::Begin;
            }

            // If we're in a source block or found a source block marker, make the line unlintable
            if in_source_block || source_marker.is_some() {
                let line_end = find_line_end(source, line_start);
                tokens.push(Token {
                    span: Span::new(line_start, line_end),
                    kind: TokenKind::Unlintable,
                });
                cursor = line_end;
                continue;
            }

            // Check for headers
            if is_header_line(source, line_start) {
                let line_end = find_line_end(source, line_start);

                // Find where the header text starts (after the stars and spaces)
                let mut header_text_start = line_start;
                while header_text_start < line_end
                    && (source[header_text_start] == '*' || source[header_text_start] == ' ')
                {
                    header_text_start += 1;
                }

                // If there's actual text after the stars, parse it
                if header_text_start < line_end {
                    let mut header_tokens =
                        english_parser.parse(&source[header_text_start..line_end]);
                    header_tokens
                        .iter_mut()
                        .for_each(|token| token.span.push_by(header_text_start));
                    tokens.append(&mut header_tokens);
                }

                // Add paragraph break after header
                tokens.push(Token {
                    span: Span::new_with_len(line_end.saturating_sub(1), 0),
                    kind: TokenKind::ParagraphBreak,
                });

                cursor = line_end;
                continue;
            }

            // Check for directives (#+SOMETHING)
            if is_directive(source, line_start) {
                let line_end = find_line_end(source, line_start);
                tokens.push(Token {
                    span: Span::new(line_start, line_end),
                    kind: TokenKind::Unlintable,
                });
                cursor = line_end;
                continue;
            }

            // Check for list items and normalize tabs to avoid French spaces
            if is_list_item(source, line_start) {
                let line_end = find_line_end(source, line_start);
                let line_chars = &source[line_start..line_end];
                let normalized_chars = normalize_list_item_whitespace(line_chars);

                let mut line_tokens = english_parser.parse(&normalized_chars);
                line_tokens
                    .iter_mut()
                    .for_each(|token| token.span.push_by(line_start));
                tokens.append(&mut line_tokens);

                cursor = line_end;
                continue;
            }

            // For normal text, parse with the English parser
            let line_end = find_line_end(source, cursor);
            if cursor < line_end {
                let mut line_tokens = english_parser.parse(&source[cursor..line_end]);
                line_tokens
                    .iter_mut()
                    .for_each(|token| token.span.push_by(cursor));
                tokens.append(&mut line_tokens);
            }

            cursor = line_end;
        }

        // Remove trailing newline/paragraph break tokens if the source doesn't actually end with a newline.
        if matches!(
            tokens.last(),
            Some(Token {
                kind: TokenKind::Newline(_) | TokenKind::ParagraphBreak,
                ..
            })
        ) && source.last() != Some(&'\n')
        {
            tokens.pop();
        }

        tokens
    }
}

#[cfg(test)]
mod tests {
    use super::super::StrParser;
    use super::OrgMode;
    use crate::TokenKind;

    #[test]
    fn simple_text() {
        let source = "This is simple text.";
        let tokens = OrgMode.parse_str(source);
        assert!(!tokens.is_empty());
        assert!(tokens.iter().any(|t| matches!(t.kind, TokenKind::Word(_))));
    }

    #[test]
    fn header_parsing() {
        let source = "* This is a header\nThis is regular text.";
        let tokens = OrgMode.parse_str(source);
        let token_kinds: Vec<_> = tokens.iter().map(|t| &t.kind).collect();

        // Should have words from header and paragraph break
        assert!(token_kinds.iter().any(|k| matches!(k, TokenKind::Word(_))));
        assert!(
            token_kinds
                .iter()
                .any(|k| matches!(k, TokenKind::ParagraphBreak))
        );
    }

    #[test]
    fn multiple_level_headers() {
        let source = "** Second level header\n*** Third level header";
        let tokens = OrgMode.parse_str(source);
        let token_kinds: Vec<_> = tokens.iter().map(|t| &t.kind).collect();

        // Should parse text from both headers
        let word_count = token_kinds
            .iter()
            .filter(|k| matches!(k, TokenKind::Word(_)))
            .count();
        assert!(word_count >= 4); // "Second", "level", "Third", "header"
    }

    #[test]
    fn source_block_unlintable() {
        let source = r#"Regular text.
#+BEGIN_SRC rust
fn main() {
    println!("Hello, world!");
}
#+END_SRC
More regular text."#;

        let tokens = OrgMode.parse_str(source);
        let unlintable_count = tokens
            .iter()
            .filter(|t| matches!(t.kind, TokenKind::Unlintable))
            .count();

        // Should have unlintable tokens for the source block lines
        assert!(unlintable_count > 0);

        // Should still have regular words from the non-source-block text
        assert!(tokens.iter().any(|t| matches!(t.kind, TokenKind::Word(_))));
    }

    #[test]
    fn directive_unlintable() {
        let source = r#"#+TITLE: My Document
#+AUTHOR: Test Author
This is regular text."#;

        let tokens = OrgMode.parse_str(source);
        let unlintable_count = tokens
            .iter()
            .filter(|t| matches!(t.kind, TokenKind::Unlintable))
            .count();

        // Should have unlintable tokens for directives
        assert_eq!(unlintable_count, 2);

        // Should still have regular words
        assert!(tokens.iter().any(|t| matches!(t.kind, TokenKind::Word(_))));
    }

    #[test]
    fn case_insensitive_source_blocks() {
        let source = r#"#+begin_src python
print("hello")
#+end_src"#;

        let tokens = OrgMode.parse_str(source);
        let unlintable_count = tokens
            .iter()
            .filter(|t| matches!(t.kind, TokenKind::Unlintable))
            .count();

        // All lines should be unlintable
        assert_eq!(unlintable_count, 3);
    }

    #[test]
    fn empty_header() {
        let source = "*\nRegular text.";
        let tokens = OrgMode.parse_str(source);

        // Should handle empty headers gracefully
        assert!(tokens.iter().any(|t| matches!(t.kind, TokenKind::Word(_))));
    }

    #[test]
    fn no_trailing_newline() {
        let source = "Simple text without newline";
        let tokens = OrgMode.parse_str(source);

        // Should not end with newline token if source doesn't
        assert!(!tokens.last().unwrap().kind.is_newline());
    }

    #[test]
    fn list_items_with_tabs() {
        let source = "- First item\n\t- Indented with tab\n+ Second item\n1. Numbered item";
        let tokens = OrgMode.parse_str(source);

        assert!(tokens.iter().any(|t| matches!(t.kind, TokenKind::Word(_))));

        let unlintable_count = tokens
            .iter()
            .filter(|t| matches!(t.kind, TokenKind::Unlintable))
            .count();
        assert_eq!(unlintable_count, 0);
    }

    #[test]
    fn mixed_list_formats() {
        let source = r#"- Bullet item
1. Numbered item
+ Plus item
2) Parenthesis numbered"#;

        let tokens = OrgMode.parse_str(source);

        // Should recognize all list formats
        let word_count = tokens
            .iter()
            .filter(|t| matches!(t.kind, TokenKind::Word(_)))
            .count();

        assert!(word_count == 8, "{:?}", tokens); // "Bullet", "item", "Numbered", "item", "Plus", "item", "Parenthesis", "numbered"
    }
}



================================================
FILE: harper-core/src/parsers/plain_english.rs
================================================
use super::Parser;
use crate::lexing::{FoundToken, lex_english_token};
use crate::{Span, Token};

/// A parser that will attempt to lex as many tokens as possible,
/// without discrimination and until the end of input.
#[derive(Clone, Copy)]
pub struct PlainEnglish;

impl Parser for PlainEnglish {
    fn parse(&self, source: &[char]) -> Vec<Token> {
        let mut cursor = 0;

        // Lex tokens
        let mut tokens = Vec::new();

        loop {
            if cursor >= source.len() {
                return tokens;
            }

            if let Some(FoundToken { token, next_index }) = lex_english_token(&source[cursor..]) {
                tokens.push(Token {
                    span: Span::new(cursor, cursor + next_index),
                    kind: token,
                });
                cursor += next_index;
            } else {
                panic!()
            }
        }
    }
}



================================================
FILE: harper-core/src/patterns/any_pattern.rs
================================================
use crate::Token;

use super::SingleTokenPattern;

/// Matches any single token.
pub struct AnyPattern;

impl SingleTokenPattern for AnyPattern {
    fn matches_token(&self, _token: &Token, _source: &[char]) -> bool {
        true
    }
}



================================================
FILE: harper-core/src/patterns/derived_from.rs
================================================
use crate::spell::WordId;

use super::Pattern;

/// A [Pattern] that looks for Word tokens that are either derived from a given word, or the word
/// itself.
///
/// For example, this will match "call" as well as "recall", "calling", etc.
pub struct DerivedFrom {
    word_id: WordId,
}

impl DerivedFrom {
    pub fn new_from_str(word: &str) -> DerivedFrom {
        Self::new(WordId::from_word_str(word))
    }

    pub fn new_from_chars(word: &[char]) -> DerivedFrom {
        Self::new(WordId::from_word_chars(word))
    }

    pub fn new(word_id: WordId) -> Self {
        Self { word_id }
    }
}

impl Pattern for DerivedFrom {
    fn matches(&self, tokens: &[crate::Token], source: &[char]) -> Option<usize> {
        let tok = tokens.first()?;
        let metadata = tok.kind.as_word()?.as_ref()?;

        if metadata.derived_from == Some(self.word_id) {
            return Some(1);
        }

        let chars = tok.span.get_content(source);
        let word_id = WordId::from_word_chars(chars);

        if word_id == self.word_id {
            return Some(1);
        }

        None
    }
}



================================================
FILE: harper-core/src/patterns/implies_quantity.rs
================================================
use crate::{Token, TokenKind};

use super::SingleTokenPattern;

/// This struct does two things.
///
/// First, it acts as a pattern that looks for phrases that describe a quantity of a noun
/// that may or may not succeed it.
///
/// Second, it determines the implied plurality of that quantity.implies
pub struct ImpliesQuantity;

impl ImpliesQuantity {
    pub fn implies_plurality(token: &Token, source: &[char]) -> Option<bool> {
        match &token.kind {
            TokenKind::Word(Some(lexeme_metadata)) => {
                if lexeme_metadata.is_determiner() {
                    return Some(false);
                }

                let source = token.span.get_content(source);

                match source {
                    ['a'] => Some(false),
                    ['a', 'n'] => Some(false),
                    ['m', 'a', 'n', 'y'] => Some(true),
                    _ => None,
                }
            }
            TokenKind::Number(number) => Some((number.value.abs() - 1.).abs() > f64::EPSILON),
            _ => None,
        }
    }
}

impl SingleTokenPattern for ImpliesQuantity {
    fn matches_token(&self, token: &Token, source: &[char]) -> bool {
        Self::implies_plurality(token, source).is_some()
    }
}

#[cfg(test)]
mod tests {
    use crate::{
        Document, Span,
        patterns::{DocPattern, ImpliesQuantity},
    };

    #[test]
    fn number_implies() {
        let doc = Document::new_plain_english_curated("There are 60 minutes in an hour.");

        assert_eq!(
            ImpliesQuantity.find_all_matches_in_doc(&doc),
            vec![Span::new(4, 5), Span::new(10, 11)]
        )
    }
}



================================================
FILE: harper-core/src/patterns/indefinite_article.rs
================================================
use crate::Token;

use super::{SingleTokenPattern, WordSet};

pub struct IndefiniteArticle {
    inner: WordSet,
}

impl Default for IndefiniteArticle {
    fn default() -> Self {
        Self {
            inner: WordSet::new(&["a", "an"]),
        }
    }
}

impl SingleTokenPattern for IndefiniteArticle {
    fn matches_token(&self, token: &Token, source: &[char]) -> bool {
        self.inner.matches_token(token, source)
    }
}



================================================
FILE: harper-core/src/patterns/inflection_of_be.rs
================================================
use super::SingleTokenPattern;
use crate::Token;
use crate::patterns::WordSet;

/// Matches any inflection of the verb “be”:
/// `am`, `is`, `are`, `was`, `were`, `be`, `been`, `being`.
pub struct InflectionOfBe {
    /// If using a `WordSet` proves expensive, we'll switch to something else.
    inner: WordSet,
}

impl Default for InflectionOfBe {
    fn default() -> Self {
        Self::new()
    }
}

impl InflectionOfBe {
    pub fn new() -> Self {
        Self {
            inner: WordSet::new(&["be", "am", "is", "are", "was", "were", "been", "being"]),
        }
    }
}

impl SingleTokenPattern for InflectionOfBe {
    fn matches_token(&self, token: &Token, source: &[char]) -> bool {
        self.inner.matches_token(token, source)
    }
}



================================================
FILE: harper-core/src/patterns/invert.rs
================================================
use crate::Token;

use super::Pattern;

/// A struct that matches any pattern __except__ the one provided.
pub struct Invert {
    inner: Box<dyn Pattern>,
}

impl Invert {
    pub fn new(inner: impl Pattern + 'static) -> Self {
        Self {
            inner: Box::new(inner),
        }
    }
}

impl Pattern for Invert {
    fn matches(&self, tokens: &[Token], source: &[char]) -> Option<usize> {
        if self.inner.matches(tokens, source).is_some() {
            None
        } else {
            Some(1)
        }
    }
}



================================================
FILE: harper-core/src/patterns/mod.rs
================================================
//! [`Pattern`]s are one of the more powerful ways to query text inside Harper, especially for beginners. They are a simplified abstraction over [`Expr`](crate::expr::Expr).
//!
//! Through the [`ExprLinter`](crate::linting::ExprLinter) trait, they make it much easier to
//! build Harper [rules](crate::linting::Linter).
//!
//! See the page about [`SequenceExpr`](crate::expr::SequenceExpr) for a concrete example of their use.

use crate::{Document, LSend, Span, Token};

mod any_pattern;
mod derived_from;
mod implies_quantity;
mod indefinite_article;
mod inflection_of_be;
mod invert;
mod modal_verb;
mod nominal_phrase;
mod prepositional_preceder;
mod upos_set;
mod whitespace_pattern;
mod within_edit_distance;
mod word;
mod word_set;

pub use any_pattern::AnyPattern;
pub use derived_from::DerivedFrom;
pub use implies_quantity::ImpliesQuantity;
pub use indefinite_article::IndefiniteArticle;
pub use inflection_of_be::InflectionOfBe;
pub use invert::Invert;
pub use modal_verb::ModalVerb;
pub use nominal_phrase::NominalPhrase;
pub use prepositional_preceder::{PrepositionalPrecederPattern, prepositional_preceder};
pub use upos_set::UPOSSet;
pub use whitespace_pattern::WhitespacePattern;
pub use within_edit_distance::WithinEditDistance;
pub use word::Word;
pub use word_set::WordSet;

pub trait Pattern: LSend {
    /// Check if the pattern matches at the start of the given token slice.
    ///
    /// Returns the length of the match if successful, or `None` if not.
    fn matches(&self, tokens: &[Token], source: &[char]) -> Option<usize>;
}

pub trait PatternExt {
    fn iter_matches(&self, tokens: &[Token], source: &[char]) -> impl Iterator<Item = Span<Token>>;

    /// Search through all tokens to locate all non-overlapping pattern matches.
    fn find_all_matches(&self, tokens: &[Token], source: &[char]) -> Vec<Span<Token>> {
        self.iter_matches(tokens, source).collect()
    }
}

impl<P> PatternExt for P
where
    P: Pattern + ?Sized,
{
    fn iter_matches(&self, tokens: &[Token], source: &[char]) -> impl Iterator<Item = Span<Token>> {
        MatchIter::new(self, tokens, source)
    }
}

struct MatchIter<'a, 'b, 'c, P: ?Sized> {
    pattern: &'a P,
    tokens: &'b [Token],
    source: &'c [char],
    index: usize,
}
impl<'a, 'b, 'c, P> MatchIter<'a, 'b, 'c, P>
where
    P: Pattern + ?Sized,
{
    fn new(pattern: &'a P, tokens: &'b [Token], source: &'c [char]) -> Self {
        Self {
            pattern,
            tokens,
            source,
            index: 0,
        }
    }
}
impl<P> Iterator for MatchIter<'_, '_, '_, P>
where
    P: Pattern + ?Sized,
{
    type Item = Span<Token>;

    fn next(&mut self) -> Option<Self::Item> {
        while self.index < self.tokens.len() {
            if let Some(len) = self
                .pattern
                .matches(&self.tokens[self.index..], self.source)
            {
                let span = Span::new_with_len(self.index, len);
                self.index += len.max(1);
                return Some(span);
            } else {
                self.index += 1;
            }
        }

        None
    }
}

/// A simpler version of the [`Pattern`] trait that only matches a single
/// token.
pub trait SingleTokenPattern: LSend {
    fn matches_token(&self, token: &Token, source: &[char]) -> bool;
}

impl<S: SingleTokenPattern> Pattern for S {
    fn matches(&self, tokens: &[Token], source: &[char]) -> Option<usize> {
        if self.matches_token(tokens.first()?, source) {
            Some(1)
        } else {
            None
        }
    }
}

impl<F: LSend + Fn(&Token, &[char]) -> bool> SingleTokenPattern for F {
    fn matches_token(&self, token: &Token, source: &[char]) -> bool {
        self(token, source)
    }
}

pub trait DocPattern {
    fn find_all_matches_in_doc(&self, document: &Document) -> Vec<Span<Token>>;
}

impl<P: PatternExt> DocPattern for P {
    fn find_all_matches_in_doc(&self, document: &Document) -> Vec<Span<Token>> {
        self.find_all_matches(document.get_tokens(), document.get_source())
    }
}



================================================
FILE: harper-core/src/patterns/modal_verb.rs
================================================
use super::{Pattern, WordSet};

pub struct ModalVerb {
    inner: WordSet,
    include_common_errors: bool,
}

impl Default for ModalVerb {
    fn default() -> Self {
        let (words, include_common_errors) = Self::init(false);
        Self {
            inner: words,
            include_common_errors,
        }
    }
}

impl ModalVerb {
    fn init(include_common_errors: bool) -> (WordSet, bool) {
        let modals = [
            "can", "can't", "could", "may", "might", "must", "shall", "shan't", "should", "will",
            "won't", "would", "ought", "dare",
        ];

        let mut words = WordSet::new(&modals);
        modals.iter().for_each(|word| {
            words.add(&format!("{word}n't"));
            if include_common_errors {
                words.add(&format!("{word}nt"));
            }
        });
        words.add("cannot");
        (words, include_common_errors)
    }

    pub fn with_common_errors() -> Self {
        let (words, _) = Self::init(true);
        Self {
            inner: words,
            include_common_errors: true,
        }
    }
}

impl Pattern for ModalVerb {
    fn matches(&self, tokens: &[crate::Token], source: &[char]) -> Option<usize> {
        self.inner.matches(tokens, source)
    }
}



================================================
FILE: harper-core/src/patterns/nominal_phrase.rs
================================================
use crate::Token;

use super::Pattern;

/// A pattern that uses primitive syntax-tree heuristics to locate nominal phrases.
/// Given that it does not take context into account, it is not recommended for new code.
/// Please prefer [`DictWordMetadata::np_member`](crate::DictWordMetadata::np_member).
#[derive(Default)]
pub struct NominalPhrase;

impl Pattern for NominalPhrase {
    fn matches(&self, tokens: &[Token], _source: &[char]) -> Option<usize> {
        let mut cursor = 0;

        loop {
            let tok = tokens.get(cursor)?;

            if (tok.kind.is_adjective()
                || tok.kind.is_determiner()
                || tok.kind.is_verb_progressive_form())
                && let Some(next) = tokens.get(cursor + 1)
                && next.kind.is_whitespace()
            {
                cursor += 2;
                continue;
            }

            if tok.kind.is_nominal() {
                return Some(cursor + 1);
            }

            return None;
        }
    }
}

#[cfg(test)]
mod tests {
    use super::super::DocPattern;
    use super::NominalPhrase;
    use crate::{Document, Span, Token, patterns::Pattern};

    trait SpanVecExt {
        fn to_strings(&self, doc: &Document) -> Vec<String>;
    }

    impl SpanVecExt for Vec<Span<Token>> {
        fn to_strings(&self, doc: &Document) -> Vec<String> {
            self.iter()
                .map(|sp| {
                    doc.get_tokens()[sp.start..sp.end]
                        .iter()
                        .map(|tok| doc.get_span_content_str(&tok.span))
                        .collect::<String>()
                })
                .collect()
        }
    }

    #[test]
    fn simple_apple() {
        let doc = Document::new_markdown_default_curated("A red apple");
        let matches = NominalPhrase.find_all_matches_in_doc(&doc);

        assert_eq!(matches.to_strings(&doc), vec!["A red apple"])
    }

    #[test]
    fn complex_apple() {
        let doc = Document::new_markdown_default_curated("A red apple with a long stem");
        let matches = NominalPhrase.find_all_matches_in_doc(&doc);

        assert_eq!(matches.to_strings(&doc), vec!["A red apple", "a long stem"])
    }

    #[test]
    fn list_fruit() {
        let doc = Document::new_markdown_default_curated("An apple, a banana and a pear");
        let matches = NominalPhrase.find_all_matches_in_doc(&doc);

        assert_eq!(
            matches.to_strings(&doc),
            vec!["An apple", "a banana", "a pear"]
        )
    }

    #[test]
    fn simplest_banana() {
        let doc = Document::new_markdown_default_curated("a banana");
        assert!(
            NominalPhrase
                .matches(doc.get_tokens(), doc.get_source())
                .is_some()
        );
    }

    #[test]
    fn food() {
        let doc = Document::new_markdown_default_curated(
            "My favorite foods are pizza, sushi, tacos and burgers.",
        );
        let matches = NominalPhrase.find_all_matches_in_doc(&doc);

        dbg!(&matches);
        dbg!(matches.to_strings(&doc));

        for span in &matches {
            let gc = span
                .to_char_span(doc.get_tokens())
                .get_content(doc.get_source());
            dbg!(gc);
        }

        assert_eq!(
            matches.to_strings(&doc),
            vec!["My favorite foods", "pizza", "sushi", "tacos", "burgers"]
        )
    }

    #[test]
    fn simplest_way() {
        let doc = Document::new_markdown_default_curated("a way");
        assert!(
            NominalPhrase
                .matches(doc.get_tokens(), doc.get_source())
                .is_some()
        );
    }

    #[test]
    fn present_participle_way() {
        let doc = Document::new_markdown_default_curated("a winning way");
        assert!(
            NominalPhrase
                .matches(doc.get_tokens(), doc.get_source())
                .is_some()
        );
    }

    #[test]
    fn perfect_participle_way() {
        let doc = Document::new_markdown_default_curated("a failed way");
        assert!(
            NominalPhrase
                .matches(doc.get_tokens(), doc.get_source())
                .is_some()
        );
    }
}



================================================
FILE: harper-core/src/patterns/prepositional_preceder.rs
================================================
use std::sync::LazyLock;

use super::{SingleTokenPattern, WordSet};
use crate::Token;

/// Matches adjectives that routinely introduce a `… to …` prepositional phrase, such as
/// `accustomed`, `prone`, or `used`.
///
/// Several `ToTwoToo` branches need this guard so they only flag cases where `to` is meant as
/// `too`, not when it participates in idioms like `accustomed to precision`.
#[derive(Debug, Clone)]
pub struct PrepositionalPrecederPattern {
    word_set: WordSet,
}

impl Default for PrepositionalPrecederPattern {
    fn default() -> Self {
        Self {
            word_set: WordSet::new(&[
                "accustomed",
                "addicted",
                "adjacent",
                "allergic",
                "attached",
                "attuned",
                "committed",
                "connected",
                "dedicated",
                "devoted",
                "immune",
                "oblivious",
                "opposed",
                "partial",
                "prone",
                "receptive",
                "related",
                "resistant",
                "sensitive",
                "subject",
                "susceptible",
                "used",
            ]),
        }
    }
}

impl SingleTokenPattern for PrepositionalPrecederPattern {
    fn matches_token(&self, token: &Token, source: &[char]) -> bool {
        self.word_set.matches_token(token, source)
    }
}

static PREPOSITIONAL_PRECEDER_PATTERN: LazyLock<PrepositionalPrecederPattern> =
    LazyLock::new(PrepositionalPrecederPattern::default);

/// Shared accessor for the lazily-initialized [`PrepositionalPrecederPattern`].
pub fn prepositional_preceder() -> &'static PrepositionalPrecederPattern {
    &PREPOSITIONAL_PRECEDER_PATTERN
}



================================================
FILE: harper-core/src/patterns/upos_set.rs
================================================
use harper_brill::UPOS;
use serde::{Deserialize, Serialize};
use smallvec::{SmallVec, ToSmallVec};

use crate::Token;

use super::Pattern;

#[derive(Debug, Serialize, Deserialize, Clone)]
pub struct UPOSSet {
    allowed_tags: SmallVec<[UPOS; 10]>,
}

impl UPOSSet {
    pub fn new(allowed: &[UPOS]) -> Self {
        Self {
            allowed_tags: allowed.to_smallvec(),
        }
    }
}

impl Pattern for UPOSSet {
    fn matches(&self, tokens: &[Token], _source: &[char]) -> Option<usize> {
        tokens.first()?.kind.as_word()?.as_ref().and_then(|w| {
            if self.allowed_tags.contains(&(w.pos_tag?)) {
                Some(1)
            } else {
                None
            }
        })
    }
}



================================================
FILE: harper-core/src/patterns/whitespace_pattern.rs
================================================
use super::Pattern;

pub struct WhitespacePattern;

impl Pattern for WhitespacePattern {
    fn matches(&self, tokens: &[crate::Token], _source: &[char]) -> Option<usize> {
        let count = tokens
            .iter()
            .position(|t| !t.kind.is_whitespace())
            .unwrap_or(tokens.len());

        if count == 0 { None } else { Some(count) }
    }
}



================================================
FILE: harper-core/src/patterns/within_edit_distance.rs
================================================
use std::cell::RefCell;

use super::SingleTokenPattern;
use crate::{CharString, CharStringExt, Token};

use crate::edit_distance::edit_distance_min_alloc;

/// Matches single words within a certain edit distance of a given word.
pub struct WithinEditDistance {
    word: CharString,
    max_edit_dist: u8,
}

impl WithinEditDistance {
    pub fn new(word: CharString, max_edit_dist: u8) -> Self {
        Self {
            word,
            max_edit_dist,
        }
    }

    pub fn from_str(word: &str, edit_dist: u8) -> Self {
        let chars = word.chars().collect();

        Self::new(chars, edit_dist)
    }
}

thread_local! {
    // To avoid allocating each call to `matches`.
    static BUFFERS: RefCell<(Vec<u8>, Vec<u8>)> = const { RefCell::new((Vec::new(), Vec::new())) };
}

impl SingleTokenPattern for WithinEditDistance {
    fn matches_token(&self, token: &Token, source: &[char]) -> bool {
        if !token.kind.is_word() {
            return false;
        }

        let content = token.span.get_content(source);

        BUFFERS.with_borrow_mut(|(buffer_a, buffer_b)| {
            let distance = edit_distance_min_alloc(
                &content.to_lower(),
                &self.word.to_lower(),
                buffer_a,
                buffer_b,
            );
            distance <= self.max_edit_dist
        })
    }
}



================================================
FILE: harper-core/src/patterns/word.rs
================================================
use super::SingleTokenPattern;

use crate::{CharString, Token};

/// Matches a predefined word.
#[derive(Clone)]
pub struct Word {
    /// The word to match.
    word: CharString,
    /// Determines whether the match is case-sensitive.
    case_sensitive: bool,
}

impl Word {
    /// Matches the provided word, ignoring case.
    pub fn new(word: &'static str) -> Self {
        Self {
            word: word.chars().collect(),
            case_sensitive: false,
        }
    }

    /// Matches the provided word, ignoring case.
    pub fn from_chars(word: &[char]) -> Self {
        Self {
            word: word.iter().copied().collect(),
            case_sensitive: false,
        }
    }

    /// Matches the provided word, ignoring case.
    pub fn from_char_string(word: CharString) -> Self {
        Self {
            word,
            case_sensitive: false,
        }
    }

    /// Matches the provided word, case-sensitive.
    pub fn new_exact(word: &'static str) -> Self {
        Self {
            word: word.chars().collect(),
            case_sensitive: true,
        }
    }
}

impl SingleTokenPattern for Word {
    fn matches_token(&self, token: &Token, source: &[char]) -> bool {
        if !token.kind.is_word() {
            return false;
        }
        if token.span.len() != self.word.len() {
            return false;
        }

        let chars = token.span.get_content(source);
        if self.case_sensitive {
            chars == self.word.as_slice()
        } else {
            chars
                .iter()
                .zip(&self.word)
                .all(|(a, b)| a.eq_ignore_ascii_case(b))
        }
    }
}

#[cfg(test)]
mod tests {
    use crate::{Document, Span, patterns::DocPattern};

    use super::Word;

    #[test]
    fn fruit() {
        let doc = Document::new_markdown_default_curated("I ate a banana and an apple today.");

        assert_eq!(
            Word::new("banana").find_all_matches_in_doc(&doc),
            vec![Span::new(6, 7)]
        );
        assert_eq!(
            Word::new_exact("banana").find_all_matches_in_doc(&doc),
            vec![Span::new(6, 7)]
        );
    }

    #[test]
    fn fruit_whack_capitalization() {
        let doc = Document::new_markdown_default_curated("I Ate A bAnaNa And aN apPlE today.");

        assert_eq!(
            Word::new("banana").find_all_matches_in_doc(&doc),
            vec![Span::new(6, 7)]
        );
        assert_eq!(
            Word::new_exact("banana").find_all_matches_in_doc(&doc),
            vec![]
        );
    }
}



================================================
FILE: harper-core/src/patterns/word_set.rs
================================================
use super::SingleTokenPattern;
use smallvec::SmallVec;

use crate::{CharString, Token, char_ext::CharExt};

/// A [`super::Pattern`] that matches against any of a set of provided words.
/// For small sets of short words, it doesn't allocate.
///
/// Note that any capitalization of the contained words will result in a match.
#[derive(Debug, Default, Clone)]
pub struct WordSet {
    words: SmallVec<[CharString; 4]>,
}

impl WordSet {
    pub fn add(&mut self, word: &str) {
        let chars = word.chars().collect();

        if !self.words.contains(&chars) {
            self.words.push(chars);
        }
    }

    pub fn add_chars(&mut self, chars: &[char]) {
        if !self.words.iter().any(|i| i.as_ref() == chars) {
            self.words.push(chars.into());
        }
    }

    pub fn contains(&self, word: &str) -> bool {
        self.words.contains(&word.chars().collect())
    }

    /// Create a new word set that matches against any word in the provided list.
    pub fn new(words: &[&'static str]) -> Self {
        let mut set = Self::default();

        for str in words {
            set.add(str);
        }

        set
    }
}

impl SingleTokenPattern for WordSet {
    fn matches_token(&self, token: &Token, source: &[char]) -> bool {
        if !token.kind.is_word() {
            return false;
        }

        let tok_chars = token.span.get_content(source);

        for word in &self.words {
            if tok_chars.len() != word.len() {
                continue;
            }

            let partial_match = tok_chars
                .iter()
                .map(CharExt::normalized)
                .zip(word.iter().map(CharExt::normalized))
                .all(|(a, b)| a.eq_ignore_ascii_case(&b));

            if partial_match {
                return true;
            }
        }

        false
    }
}

#[cfg(test)]
mod tests {
    use crate::{Document, Span, patterns::DocPattern};

    use super::WordSet;

    #[test]
    fn fruit() {
        let set = WordSet::new(&["banana", "apple", "orange"]);

        let doc = Document::new_markdown_default_curated("I ate a banana and an apple today.");

        let matches = set.find_all_matches_in_doc(&doc);

        assert_eq!(matches, vec![Span::new(6, 7), Span::new(12, 13)]);
    }

    #[test]
    fn fruit_whack_capitalization() {
        let set = WordSet::new(&["banana", "apple", "orange"]);

        let doc = Document::new_markdown_default_curated("I Ate A bAnaNa And aN apPlE today.");

        let matches = set.find_all_matches_in_doc(&doc);

        assert_eq!(matches, vec![Span::new(6, 7), Span::new(12, 13)]);
    }

    #[test]
    fn supports_typographic_apostrophes() {
        let set = WordSet::new(&["They're"]);

        let doc = Document::new_markdown_default_curated("They’re");

        let matches = set.find_all_matches_in_doc(&doc);

        assert_eq!(matches, vec![Span::new(0, 1)]);
    }
}



================================================
FILE: harper-core/src/spell/dictionary.rs
================================================
use blanket::blanket;
use std::borrow::Cow;

use super::FuzzyMatchResult;
use super::WordId;
use crate::DictWordMetadata;

/// An in-memory database that contains everything necessary to parse and analyze English text.
///
/// See also: [`super::FstDictionary`] and [`super::MutableDictionary`].
#[blanket(derive(Arc, Ref))]
pub trait Dictionary: Send + Sync {
    /// Check if the dictionary contains any capitalization of a given word.
    fn contains_word(&self, word: &[char]) -> bool;
    /// Check if the dictionary contains any capitalization of a given word.
    fn contains_word_str(&self, word: &str) -> bool;
    /// Check if the dictionary contains the exact capitalization of a given word.
    fn contains_exact_word(&self, word: &[char]) -> bool;
    /// Check if the dictionary contains the exact capitalization of a given word.
    fn contains_exact_word_str(&self, word: &str) -> bool;
    /// Gets best fuzzy match from dictionary
    fn fuzzy_match(
        &'_ self,
        word: &[char],
        max_distance: u8,
        max_results: usize,
    ) -> Vec<FuzzyMatchResult<'_>>;
    /// Gets best fuzzy match from dictionary
    fn fuzzy_match_str(
        &'_ self,
        word: &str,
        max_distance: u8,
        max_results: usize,
    ) -> Vec<FuzzyMatchResult<'_>>;
    fn get_correct_capitalization_of(&self, word: &[char]) -> Option<&'_ [char]>;
    /// Get the associated [`DictWordMetadata`] for any capitalization of a given word.
    fn get_word_metadata(&self, word: &[char]) -> Option<Cow<'_, DictWordMetadata>>;
    /// Get the associated [`DictWordMetadata`] for any capitalization of a given word.
    /// If the word isn't in the dictionary, the resulting metadata will be
    /// empty.
    fn get_word_metadata_str(&self, word: &str) -> Option<Cow<'_, DictWordMetadata>>;

    /// Iterate over the words in the dictionary.
    fn words_iter(&self) -> Box<dyn Iterator<Item = &'_ [char]> + Send + '_>;

    /// The number of words in the dictionary.
    fn word_count(&self) -> usize;

    /// Returns the correct capitalization of the word with the given ID.
    fn get_word_from_id(&self, id: &WordId) -> Option<&[char]>;

    /// Look for words with a specific prefix
    fn find_words_with_prefix(&self, prefix: &[char]) -> Vec<Cow<'_, [char]>>;

    /// Look for words that share a prefix with the provided word
    fn find_words_with_common_prefix(&self, word: &[char]) -> Vec<Cow<'_, [char]>>;
}



================================================
FILE: harper-core/src/spell/fst_dictionary.rs
================================================
use super::{MutableDictionary, WordId};
use fst::{IntoStreamer, Map as FstMap, Streamer, map::StreamWithState};
use hashbrown::HashMap;
use levenshtein_automata::{DFA, LevenshteinAutomatonBuilder};
use std::borrow::Cow;
use std::sync::LazyLock;
use std::{cell::RefCell, sync::Arc};

use crate::{CharString, CharStringExt, DictWordMetadata};

use super::Dictionary;
use super::FuzzyMatchResult;

/// An immutable dictionary allowing for very fast spellchecking.
///
/// For dictionaries with changing contents, such as user and file dictionaries, prefer
/// [`MutableDictionary`].
pub struct FstDictionary {
    /// Underlying [`super::MutableDictionary`] used for everything except fuzzy finding
    mutable_dict: Arc<MutableDictionary>,
    /// Used for fuzzy-finding the index of words or metadata
    word_map: FstMap<Vec<u8>>,
    /// Used for fuzzy-finding the index of words or metadata
    words: Vec<(CharString, DictWordMetadata)>,
}

const EXPECTED_DISTANCE: u8 = 3;
const TRANSPOSITION_COST_ONE: bool = true;

static DICT: LazyLock<Arc<FstDictionary>> =
    LazyLock::new(|| Arc::new((*MutableDictionary::curated()).clone().into()));

thread_local! {
    // Builders are computationally expensive and do not depend on the word, so we store a
    // collection of builders and the associated edit distance here.
    // Currently, the edit distance we use is three, but a value that does not exist in this
    // collection will create a new builder of that distance and push it to the collection.
    static AUTOMATON_BUILDERS: RefCell<Vec<(u8, LevenshteinAutomatonBuilder)>> = RefCell::new(vec![(
        EXPECTED_DISTANCE,
        LevenshteinAutomatonBuilder::new(EXPECTED_DISTANCE, TRANSPOSITION_COST_ONE),
    )]);
}

impl PartialEq for FstDictionary {
    fn eq(&self, other: &Self) -> bool {
        self.mutable_dict == other.mutable_dict
    }
}

impl FstDictionary {
    /// Create a dictionary from the curated dictionary included
    /// in the Harper binary.
    pub fn curated() -> Arc<Self> {
        (*DICT).clone()
    }

    /// Construct a new [`FstDictionary`] using a wordlist as a source.
    /// This can be expensive, so only use this if fast fuzzy searches are worth it.
    pub fn new(mut words: Vec<(CharString, DictWordMetadata)>) -> Self {
        words.sort_unstable_by(|(a, _), (b, _)| a.cmp(b));
        words.dedup_by(|(a, _), (b, _)| a == b);

        let mut builder = fst::MapBuilder::memory();
        for (index, (word, _)) in words.iter().enumerate() {
            let word = word.iter().collect::<String>();
            builder
                .insert(word, index as u64)
                .expect("Insertion not in lexicographical order!");
        }

        let mut mutable_dict = MutableDictionary::new();
        mutable_dict.extend_words(words.iter().cloned());

        let fst_bytes = builder.into_inner().unwrap();
        let word_map = FstMap::new(fst_bytes).expect("Unable to build FST map.");

        FstDictionary {
            mutable_dict: Arc::new(mutable_dict),
            word_map,
            words,
        }
    }
}

fn build_dfa(max_distance: u8, query: &str) -> DFA {
    // Insert if it does not exist
    AUTOMATON_BUILDERS.with_borrow_mut(|v| {
        if !v.iter().any(|t| t.0 == max_distance) {
            v.push((
                max_distance,
                LevenshteinAutomatonBuilder::new(max_distance, TRANSPOSITION_COST_ONE),
            ));
        }
    });

    AUTOMATON_BUILDERS.with_borrow(|v| {
        v.iter()
            .find(|a| a.0 == max_distance)
            .unwrap()
            .1
            .build_dfa(query)
    })
}

/// Consumes a DFA stream and emits the index-edit distance pairs it produces.
fn stream_distances_vec(stream: &mut StreamWithState<&DFA>, dfa: &DFA) -> Vec<(u64, u8)> {
    let mut word_index_pairs = Vec::new();
    while let Some((_, v, s)) = stream.next() {
        word_index_pairs.push((v, dfa.distance(s).to_u8()));
    }

    word_index_pairs
}

impl Dictionary for FstDictionary {
    fn contains_word(&self, word: &[char]) -> bool {
        self.mutable_dict.contains_word(word)
    }

    fn contains_word_str(&self, word: &str) -> bool {
        self.mutable_dict.contains_word_str(word)
    }

    fn get_word_metadata(&self, word: &[char]) -> Option<Cow<'_, DictWordMetadata>> {
        self.mutable_dict.get_word_metadata(word)
    }

    fn get_word_metadata_str(&self, word: &str) -> Option<Cow<'_, DictWordMetadata>> {
        self.mutable_dict.get_word_metadata_str(word)
    }

    fn fuzzy_match(
        &'_ self,
        word: &[char],
        max_distance: u8,
        max_results: usize,
    ) -> Vec<FuzzyMatchResult<'_>> {
        let misspelled_word_charslice = word.normalized();
        let misspelled_word_string = misspelled_word_charslice.to_string();

        // Actual FST search
        let dfa = build_dfa(max_distance, &misspelled_word_string);
        let dfa_lowercase = build_dfa(max_distance, &misspelled_word_string.to_lowercase());
        let mut word_indexes_stream = self.word_map.search_with_state(&dfa).into_stream();
        let mut word_indexes_lowercase_stream = self
            .word_map
            .search_with_state(&dfa_lowercase)
            .into_stream();

        let upper_dists = stream_distances_vec(&mut word_indexes_stream, &dfa);
        let lower_dists = stream_distances_vec(&mut word_indexes_lowercase_stream, &dfa_lowercase);

        // Merge the two results, keeping the smallest distance when both DFAs match.
        // The uppercase and lowercase searches can return different result counts, so
        // we can't simply zip the vectors without losing matches.
        let mut merged = Vec::with_capacity(upper_dists.len().max(lower_dists.len()));
        let mut best_distances = HashMap::<u64, u8>::new();

        for (idx, dist) in upper_dists.into_iter().chain(lower_dists.into_iter()) {
            best_distances
                .entry(idx)
                .and_modify(|existing| *existing = (*existing).min(dist))
                .or_insert(dist);
        }

        for (index, edit_distance) in best_distances {
            let (word, metadata) = &self.words[index as usize];
            merged.push(FuzzyMatchResult {
                word,
                edit_distance,
                metadata: Cow::Borrowed(metadata),
            });
        }

        // Ignore exact matches
        merged.retain(|v| v.edit_distance > 0);
        merged.sort_unstable_by(|a, b| {
            a.edit_distance
                .cmp(&b.edit_distance)
                .then_with(|| a.word.cmp(b.word))
        });
        merged.truncate(max_results);

        merged
    }

    fn fuzzy_match_str(
        &'_ self,
        word: &str,
        max_distance: u8,
        max_results: usize,
    ) -> Vec<FuzzyMatchResult<'_>> {
        self.fuzzy_match(
            word.chars().collect::<Vec<_>>().as_slice(),
            max_distance,
            max_results,
        )
    }

    fn words_iter(&self) -> Box<dyn Iterator<Item = &'_ [char]> + Send + '_> {
        self.mutable_dict.words_iter()
    }

    fn word_count(&self) -> usize {
        self.mutable_dict.word_count()
    }

    fn contains_exact_word(&self, word: &[char]) -> bool {
        self.mutable_dict.contains_exact_word(word)
    }

    fn contains_exact_word_str(&self, word: &str) -> bool {
        self.mutable_dict.contains_exact_word_str(word)
    }

    fn get_correct_capitalization_of(&self, word: &[char]) -> Option<&'_ [char]> {
        self.mutable_dict.get_correct_capitalization_of(word)
    }

    fn get_word_from_id(&self, id: &WordId) -> Option<&[char]> {
        self.mutable_dict.get_word_from_id(id)
    }

    fn find_words_with_prefix(&self, prefix: &[char]) -> Vec<Cow<'_, [char]>> {
        self.mutable_dict.find_words_with_prefix(prefix)
    }

    fn find_words_with_common_prefix(&self, word: &[char]) -> Vec<Cow<'_, [char]>> {
        self.mutable_dict.find_words_with_common_prefix(word)
    }
}

#[cfg(test)]
mod tests {
    use itertools::Itertools;

    use crate::CharStringExt;
    use crate::spell::{Dictionary, WordId};

    use super::FstDictionary;

    #[test]
    fn damerau_transposition_costs_one() {
        let lev_automata =
            levenshtein_automata::LevenshteinAutomatonBuilder::new(1, true).build_dfa("woof");
        assert_eq!(
            lev_automata.eval("wofo"),
            levenshtein_automata::Distance::Exact(1)
        );
    }

    #[test]
    fn damerau_transposition_costs_two() {
        let lev_automata =
            levenshtein_automata::LevenshteinAutomatonBuilder::new(1, false).build_dfa("woof");
        assert_eq!(
            lev_automata.eval("wofo"),
            levenshtein_automata::Distance::AtLeast(2)
        );
    }

    #[test]
    fn fst_map_contains_all_in_mutable_dict() {
        let dict = FstDictionary::curated();

        for word in dict.words_iter() {
            let misspelled_normalized = word.normalized();
            let misspelled_word = misspelled_normalized.to_string();
            let misspelled_lower = misspelled_normalized.to_lower().to_string();

            dbg!(&misspelled_lower);

            assert!(!misspelled_word.is_empty());
            assert!(dict.word_map.contains_key(misspelled_word));
        }
    }

    #[test]
    fn fst_contains_hello() {
        let dict = FstDictionary::curated();

        let word: Vec<_> = "hello".chars().collect();
        let misspelled_normalized = word.normalized();
        let misspelled_word = misspelled_normalized.to_string();
        let misspelled_lower = misspelled_normalized.to_lower().to_string();

        assert!(dict.contains_word(&misspelled_normalized));
        assert!(
            dict.word_map.contains_key(misspelled_lower)
                || dict.word_map.contains_key(misspelled_word)
        );
    }

    #[test]
    fn on_is_not_nominal() {
        let dict = FstDictionary::curated();

        assert!(!dict.get_word_metadata_str("on").unwrap().is_nominal());
    }

    #[test]
    fn fuzzy_result_sorted_by_edit_distance() {
        let dict = FstDictionary::curated();

        let results = dict.fuzzy_match_str("hello", 3, 100);
        let is_sorted_by_dist = results
            .iter()
            .map(|fm| fm.edit_distance)
            .tuple_windows()
            .all(|(a, b)| a <= b);

        assert!(is_sorted_by_dist)
    }

    #[test]
    fn curated_contains_no_duplicates() {
        let dict = FstDictionary::curated();

        assert!(dict.words.iter().map(|(word, _)| word).all_unique());
    }

    #[test]
    fn contractions_not_derived() {
        let dict = FstDictionary::curated();

        let contractions = ["there's", "we're", "here's"];

        for contraction in contractions {
            dbg!(contraction);
            assert!(
                dict.get_word_metadata_str(contraction)
                    .unwrap()
                    .derived_from
                    .is_none()
            )
        }
    }

    #[test]
    fn plural_llamas_derived_from_llama() {
        let dict = FstDictionary::curated();

        assert_eq!(
            dict.get_word_metadata_str("llamas")
                .unwrap()
                .derived_from
                .unwrap(),
            WordId::from_word_str("llama")
        )
    }

    #[test]
    fn plural_cats_derived_from_cat() {
        let dict = FstDictionary::curated();

        assert_eq!(
            dict.get_word_metadata_str("cats")
                .unwrap()
                .derived_from
                .unwrap(),
            WordId::from_word_str("cat")
        );
    }

    #[test]
    fn unhappy_derived_from_happy() {
        let dict = FstDictionary::curated();

        assert_eq!(
            dict.get_word_metadata_str("unhappy")
                .unwrap()
                .derived_from
                .unwrap(),
            WordId::from_word_str("happy")
        );
    }

    #[test]
    fn quickly_derived_from_quick() {
        let dict = FstDictionary::curated();

        assert_eq!(
            dict.get_word_metadata_str("quickly")
                .unwrap()
                .derived_from
                .unwrap(),
            WordId::from_word_str("quick")
        );
    }
}



================================================
FILE: harper-core/src/spell/merged_dictionary.rs
================================================
use std::borrow::Cow;
use std::hash::{BuildHasher, Hasher};
use std::sync::Arc;

use foldhash::quality::FixedState;
use itertools::Itertools;

use super::{FstDictionary, WordId};
use super::{FuzzyMatchResult, dictionary::Dictionary};
use crate::{CharString, DictWordMetadata};

/// A simple wrapper over [`Dictionary`] that allows
/// one to merge multiple dictionaries without copying.
///
/// In cases where more than one dictionary contains a word, data in the first
/// dictionary inserted will be returned.
#[derive(Clone)]
pub struct MergedDictionary {
    children: Vec<Arc<dyn Dictionary>>,
    hasher_builder: FixedState,
    child_hashes: Vec<u64>,
}

impl MergedDictionary {
    pub fn new() -> Self {
        Self {
            children: Vec::new(),
            hasher_builder: FixedState::default(),
            child_hashes: Vec::new(),
        }
    }

    pub fn add_dictionary(&mut self, dictionary: Arc<dyn Dictionary>) {
        self.child_hashes.push(self.hash_dictionary(&dictionary));
        self.children.push(dictionary);
    }

    fn hash_dictionary(&self, dictionary: &Arc<dyn Dictionary>) -> u64 {
        // Hashing the curated dictionary isn't super helpful and takes a long time.
        if Arc::ptr_eq(
            dictionary,
            &(FstDictionary::curated() as Arc<dyn Dictionary>),
        ) {
            return 1;
        }

        let mut hasher = self.hasher_builder.build_hasher();

        dictionary
            .words_iter()
            .for_each(|w| w.iter().for_each(|c| hasher.write_u32(*c as u32)));

        hasher.finish()
    }
}

impl PartialEq for MergedDictionary {
    fn eq(&self, other: &Self) -> bool {
        self.child_hashes == other.child_hashes
    }
}

impl Default for MergedDictionary {
    fn default() -> Self {
        Self::new()
    }
}

impl Dictionary for MergedDictionary {
    fn get_correct_capitalization_of(&self, word: &[char]) -> Option<&'_ [char]> {
        for child in &self.children {
            if let Some(word) = child.get_correct_capitalization_of(word) {
                return Some(word);
            }
        }
        None
    }

    fn contains_word(&self, word: &[char]) -> bool {
        for child in &self.children {
            if child.contains_word(word) {
                return true;
            }
        }
        false
    }

    fn contains_exact_word(&self, word: &[char]) -> bool {
        for child in &self.children {
            if child.contains_exact_word(word) {
                return true;
            }
        }
        false
    }

    fn get_word_metadata(&self, word: &[char]) -> Option<Cow<'_, DictWordMetadata>> {
        self.children
            .iter()
            .filter_map(|d| d.get_word_metadata(word))
            .reduce(|acc, md| Cow::Owned(acc.or(&md)))
    }

    fn words_iter(&self) -> Box<dyn Iterator<Item = &'_ [char]> + Send + '_> {
        Box::new(self.children.iter().flat_map(|c| c.words_iter()))
    }

    fn contains_word_str(&self, word: &str) -> bool {
        let chars: CharString = word.chars().collect();
        self.contains_word(&chars)
    }

    fn contains_exact_word_str(&self, word: &str) -> bool {
        let chars: CharString = word.chars().collect();
        self.contains_word(&chars)
    }

    fn get_word_metadata_str(&self, word: &str) -> Option<Cow<'_, DictWordMetadata>> {
        let chars: CharString = word.chars().collect();
        self.get_word_metadata(&chars)
    }

    fn fuzzy_match(
        &'_ self,
        word: &[char],
        max_distance: u8,
        max_results: usize,
    ) -> Vec<FuzzyMatchResult<'_>> {
        self.children
            .iter()
            .flat_map(|d| d.fuzzy_match(word, max_distance, max_results))
            .sorted_by_key(|r| r.word)
            .dedup_by(|a, b| a.word == b.word)
            .sorted_by_key(|r| r.edit_distance)
            .take(max_results)
            .collect()
    }

    fn fuzzy_match_str(
        &'_ self,
        word: &str,
        max_distance: u8,
        max_results: usize,
    ) -> Vec<FuzzyMatchResult<'_>> {
        self.children
            .iter()
            .flat_map(|d| d.fuzzy_match_str(word, max_distance, max_results))
            .sorted_by_key(|r| r.word)
            .dedup_by(|a, b| a.word == b.word)
            .sorted_by_key(|r| r.edit_distance)
            .take(max_results)
            .collect()
    }

    fn word_count(&self) -> usize {
        self.children.iter().map(|d| d.word_count()).sum()
    }

    fn get_word_from_id(&self, id: &WordId) -> Option<&[char]> {
        self.children
            .iter()
            .find_map(|dict| dict.get_word_from_id(id))
    }

    fn find_words_with_prefix(&self, prefix: &[char]) -> Vec<Cow<'_, [char]>> {
        self.children
            .iter()
            .flat_map(|dict| dict.find_words_with_prefix(prefix))
            .sorted()
            .dedup()
            .collect()
    }

    fn find_words_with_common_prefix(&self, word: &[char]) -> Vec<Cow<'_, [char]>> {
        self.children
            .iter()
            .flat_map(|dict| dict.find_words_with_common_prefix(word))
            .sorted()
            .dedup()
            .collect()
    }
}



================================================
FILE: harper-core/src/spell/mod.rs
================================================
//! Contains the relevant code for performing dictionary lookups and spellchecking (i.e. fuzzy
//! dictionary lookups).

use itertools::Itertools;

use crate::{CharString, CharStringExt, DictWordMetadata};

pub use self::dictionary::Dictionary;
pub use self::fst_dictionary::FstDictionary;
pub use self::merged_dictionary::MergedDictionary;
pub use self::mutable_dictionary::MutableDictionary;
pub use self::trie_dictionary::TrieDictionary;
pub use self::word_id::WordId;

mod dictionary;
mod fst_dictionary;
mod merged_dictionary;
mod mutable_dictionary;
mod rune;
mod trie_dictionary;
mod word_id;
mod word_map;

#[derive(PartialEq, Debug, Hash, Eq)]
pub struct FuzzyMatchResult<'a> {
    pub word: &'a [char],
    pub edit_distance: u8,
    pub metadata: std::borrow::Cow<'a, DictWordMetadata>,
}

impl PartialOrd for FuzzyMatchResult<'_> {
    fn partial_cmp(&self, other: &Self) -> Option<std::cmp::Ordering> {
        self.edit_distance.partial_cmp(&other.edit_distance)
    }
}

/// Returns whether the two words are the same, expect that one is written
/// with 'ou' and the other with 'o'.
///
/// E.g. "color" and "colour"
pub(crate) fn is_ou_misspelling(a: &[char], b: &[char]) -> bool {
    if a.len().abs_diff(b.len()) != 1 {
        return false;
    }

    let mut a_iter = a.iter();
    let mut b_iter = b.iter();

    loop {
        match (
            a_iter.next().map(char::to_ascii_lowercase),
            b_iter.next().map(char::to_ascii_lowercase),
        ) {
            (Some('o'), Some('o')) => {
                let mut a_next = a_iter.next().map(char::to_ascii_lowercase);
                let mut b_next = b_iter.next().map(char::to_ascii_lowercase);
                if a_next != b_next {
                    if a_next == Some('u') {
                        a_next = a_iter.next().map(char::to_ascii_lowercase);
                    } else if b_next == Some('u') {
                        b_next = b_iter.next().map(char::to_ascii_lowercase);
                    }

                    if a_next != b_next {
                        return false;
                    }
                }
            }
            (Some(a_char), Some(b_char)) => {
                if !a_char.eq_ignore_ascii_case(&b_char) {
                    return false;
                }
            }
            (None, None) => return true,
            _ => return false,
        }
    }
}

/// Returns whether the two words are the same, expect for a single confusion of:
///
/// - `s` and `z`. E.g."realize" and "realise"
/// - `s` and `c`. E.g. "defense" and "defence"
/// - `k` and `c`. E.g. "skepticism" and "scepticism"
pub(crate) fn is_cksz_misspelling(a: &[char], b: &[char]) -> bool {
    if a.len() != b.len() {
        return false;
    }
    if a.is_empty() {
        return true;
    }

    // the first character must be the same
    if !a[0].eq_ignore_ascii_case(&b[0]) {
        return false;
    }

    let mut found = false;
    for (a_char, b_char) in a.iter().copied().zip(b.iter().copied()) {
        let a_char = a_char.to_ascii_lowercase();
        let b_char = b_char.to_ascii_lowercase();

        if a_char != b_char {
            if (a_char == 's' && b_char == 'z')
                || (a_char == 'z' && b_char == 's')
                || (a_char == 's' && b_char == 'c')
                || (a_char == 'c' && b_char == 's')
                || (a_char == 'k' && b_char == 'c')
                || (a_char == 'c' && b_char == 'k')
            {
                if found {
                    return false;
                }
                found = true;
            } else {
                return false;
            }
        }
    }

    found
}

/// Returns whether the two words are the same, expect that one is written
/// with '-er' and the other with '-re'.
///
/// E.g. "meter" and "metre"
pub(crate) fn is_er_misspelling(a: &[char], b: &[char]) -> bool {
    if a.len() != b.len() || a.len() <= 4 {
        return false;
    }

    let len = a.len();
    let a_suffix = [&a[len - 2], &a[len - 1]].map(char::to_ascii_lowercase);
    let b_suffix = [&b[len - 2], &b[len - 1]].map(char::to_ascii_lowercase);

    if a_suffix == ['r', 'e'] && b_suffix == ['e', 'r']
        || a_suffix == ['e', 'r'] && b_suffix == ['r', 'e']
    {
        return a[0..len - 2]
            .iter()
            .copied()
            .zip(b[0..len - 2].iter().copied())
            .all(|(a_char, b_char)| a_char.eq_ignore_ascii_case(&b_char));
    }

    false
}

/// Returns whether the two words are the same, expect that one is written
/// with 'll' and the other with 'l'.
///
/// E.g. "traveller" and "traveler"
pub(crate) fn is_ll_misspelling(a: &[char], b: &[char]) -> bool {
    if a.len().abs_diff(b.len()) != 1 {
        return false;
    }

    let mut a_iter = a.iter();
    let mut b_iter = b.iter();

    loop {
        match (
            a_iter.next().map(char::to_ascii_lowercase),
            b_iter.next().map(char::to_ascii_lowercase),
        ) {
            (Some('l'), Some('l')) => {
                let mut a_next = a_iter.next().map(char::to_ascii_lowercase);
                let mut b_next = b_iter.next().map(char::to_ascii_lowercase);
                if a_next != b_next {
                    if a_next == Some('l') {
                        a_next = a_iter.next().map(char::to_ascii_lowercase);
                    } else if b_next == Some('l') {
                        b_next = b_iter.next().map(char::to_ascii_lowercase);
                    }

                    if a_next != b_next {
                        return false;
                    }
                }
            }
            (Some(a_char), Some(b_char)) => {
                if !a_char.eq_ignore_ascii_case(&b_char) {
                    return false;
                }
            }
            (None, None) => return true,
            _ => return false,
        }
    }
}

pub fn is_th_h_missing(a: &[char], b: &[char]) -> bool {
    a.iter().any(|c| c.eq_ignore_ascii_case(&'t'))
        && b.iter()
            .tuple_windows()
            .any(|(a, b)| a.eq_ignore_ascii_case(&'t') && b.eq_ignore_ascii_case(&'h'))
}

/// Returns whether the two words are the same, except that one is written
/// with 'ay' and the other with 'ey'.
///
/// E.g. "gray" and "grey"
pub(crate) fn is_ay_ey_misspelling(a: &[char], b: &[char]) -> bool {
    if a.len() != b.len() {
        return false;
    }

    let mut found_ay_ey = false;
    let mut a_iter = a.iter();
    let mut b_iter = b.iter();

    while let (Some(&a_char), Some(&b_char)) = (a_iter.next(), b_iter.next()) {
        if a_char.eq_ignore_ascii_case(&b_char) {
            continue;
        }

        // Check for 'a'/'e' difference
        if (a_char.eq_ignore_ascii_case(&'a') && b_char.eq_ignore_ascii_case(&'e'))
            || (a_char.eq_ignore_ascii_case(&'e') && b_char.eq_ignore_ascii_case(&'a'))
        {
            // Check if next character is 'y' for both
            if let (Some(&a_next), Some(&b_next)) = (a_iter.next(), b_iter.next())
                && a_next.eq_ignore_ascii_case(&'y')
                && b_next.eq_ignore_ascii_case(&'y')
            {
                if found_ay_ey {
                    return false; // More than one ay/ey difference
                }
                found_ay_ey = true;
                continue;
            }
        }
        return false; // Non-ay/ey difference found
    }

    if !found_ay_ey {
        return false;
    }
    found_ay_ey
}

/// Returns whether the two words are the same, except that one is written
/// with 'ei' and the other with 'ie'.
///
/// E.g. "recieved" instead of "received", "cheif" instead of "chief"
pub(crate) fn is_ei_ie_misspelling(a: &[char], b: &[char]) -> bool {
    if a.len() != b.len() {
        return false;
    }
    let mut found_ei_ie = false;
    let mut a_iter = a.iter();
    let mut b_iter = b.iter();

    while let (Some(&a_char), Some(&b_char)) = (a_iter.next(), b_iter.next()) {
        if a_char.eq_ignore_ascii_case(&b_char) {
            continue;
        }

        // Check for 'e' vs 'i' in first position
        if a_char.eq_ignore_ascii_case(&'e') && b_char.eq_ignore_ascii_case(&'i') {
            if let (Some(&a_next), Some(&b_next)) = (a_iter.next(), b_iter.next()) {
                // Next chars must be 'i' and 'e' respectively
                if a_next.eq_ignore_ascii_case(&'i') && b_next.eq_ignore_ascii_case(&'e') {
                    if found_ei_ie {
                        return false; // More than one ei/ie difference
                    }
                    found_ei_ie = true;
                    continue;
                }
            }
        }
        // Check for 'i' vs 'e' in first position
        else if a_char.eq_ignore_ascii_case(&'i')
            && b_char.eq_ignore_ascii_case(&'e')
            && let (Some(&a_next), Some(&b_next)) = (a_iter.next(), b_iter.next())
        {
            // Next chars must be 'e' and 'i' respectively
            if a_next.eq_ignore_ascii_case(&'e') && b_next.eq_ignore_ascii_case(&'i') {
                if found_ei_ie {
                    return false; // More than one ei/ie difference
                }
                found_ei_ie = true;
                continue;
            }
        }
        return false;
    }
    found_ei_ie
}

/// Scores a possible spelling suggestion based on possible relevance to the user.
///
/// Lower = better.
fn score_suggestion(misspelled_word: &[char], sug: &FuzzyMatchResult) -> i32 {
    if misspelled_word.is_empty() || sug.word.is_empty() {
        return i32::MAX;
    }

    let mut score = sug.edit_distance as i32 * 10;

    // People are much less likely to mistype the first letter.
    if misspelled_word
        .first()
        .unwrap()
        .eq_ignore_ascii_case(sug.word.first().unwrap())
    {
        score -= 10;
    }

    // If the original word is plural, the correct one probably is too.
    if *misspelled_word.last().unwrap() == 's' && *sug.word.last().unwrap() == 's' {
        score -= 5;
    }

    // Boost common words.
    if sug.metadata.common {
        score -= 5;
    }

    // For turning words into contractions.
    if sug.word.iter().filter(|c| **c == '\'').count() == 1 {
        score -= 5;
    }

    if is_th_h_missing(misspelled_word, sug.word) {
        score -= 6;
    }

    if !misspelled_word.contains_vowel() && !sug.word.contains_vowel() {
        score += 10;
    }

    // Detect dialect-specific variations
    if sug.edit_distance == 1
        && (is_cksz_misspelling(misspelled_word, sug.word)
            || is_ou_misspelling(misspelled_word, sug.word)
            || is_ll_misspelling(misspelled_word, sug.word)
            || is_ay_ey_misspelling(misspelled_word, sug.word)
            || is_th_h_missing(misspelled_word, sug.word))
    {
        score -= 6;
    }

    if sug.edit_distance <= 2 {
        if is_ei_ie_misspelling(misspelled_word, sug.word) {
            score -= 11;
        }
        if is_er_misspelling(misspelled_word, sug.word) {
            score -= 15;
        }
    }

    score
}

/// Order the suggestions to be shown to the user.
fn order_suggestions<'b>(
    misspelled_word: &[char],
    mut matches: Vec<FuzzyMatchResult<'b>>,
) -> Vec<&'b [char]> {
    matches.sort_by_cached_key(|v| score_suggestion(misspelled_word, v));

    matches.into_iter().map(|v| v.word).collect()
}

/// Get the closest matches in the provided [`Dictionary`] and rank them
/// Implementation is left up to the underlying dictionary.
pub fn suggest_correct_spelling<'a>(
    misspelled_word: &[char],
    result_limit: usize,
    max_edit_dist: u8,
    dictionary: &'a impl Dictionary,
) -> Vec<&'a [char]> {
    let matches: Vec<FuzzyMatchResult> = dictionary
        .fuzzy_match(misspelled_word, max_edit_dist, result_limit)
        .into_iter()
        .collect();

    order_suggestions(misspelled_word, matches)
}

/// Convenience function over [`suggest_correct_spelling`] that does conversions
/// for you.
pub fn suggest_correct_spelling_str(
    misspelled_word: impl Into<String>,
    result_limit: usize,
    max_edit_dist: u8,
    dictionary: &impl Dictionary,
) -> Vec<String> {
    let chars: CharString = misspelled_word.into().chars().collect();
    suggest_correct_spelling(&chars, result_limit, max_edit_dist, dictionary)
        .into_iter()
        .map(|a| a.to_string())
        .collect()
}

#[cfg(test)]
mod tests {
    use itertools::Itertools;

    use crate::{
        CharStringExt, Dialect,
        linting::{
            SpellCheck,
            tests::{assert_suggestion_result, assert_top3_suggestion_result},
        },
    };

    use super::{FstDictionary, suggest_correct_spelling_str};

    const RESULT_LIMIT: usize = 200;
    const MAX_EDIT_DIST: u8 = 2;

    #[test]
    fn normalizes_weve() {
        let word = ['w', 'e', '’', 'v', 'e'];
        let norm = word.normalized();

        assert_eq!(norm.clone(), vec!['w', 'e', '\'', 'v', 'e'])
    }

    #[test]
    fn punctation_no_duplicates() {
        let results = suggest_correct_spelling_str(
            "punctation",
            RESULT_LIMIT,
            MAX_EDIT_DIST,
            &FstDictionary::curated(),
        );

        assert!(results.iter().all_unique())
    }

    #[test]
    fn youre_contraction() {
        assert_suggests_correction("youre", "you're");
    }

    #[test]
    fn thats_contraction() {
        assert_suggests_correction("thats", "that's");
    }

    #[test]
    fn weve_contraction() {
        assert_suggests_correction("weve", "we've");
    }

    #[test]
    fn this_correction() {
        assert_suggests_correction("ths", "this");
    }

    #[test]
    fn issue_624_no_duplicates() {
        let results = suggest_correct_spelling_str(
            "Semantical",
            RESULT_LIMIT,
            MAX_EDIT_DIST,
            &FstDictionary::curated(),
        );

        assert!(results.iter().all_unique())
    }

    #[test]
    fn issue_182() {
        assert_suggests_correction("Im", "I'm");
    }

    #[test]
    fn fst_spellcheck_hvllo() {
        let results = suggest_correct_spelling_str(
            "hvllo",
            RESULT_LIMIT,
            MAX_EDIT_DIST,
            &FstDictionary::curated(),
        );

        assert!(results.iter().take(3).contains(&"hello".to_string()));
    }

    /// Assert that the default suggestion settings result in a specific word
    /// being in the top three results for a given misspelling.
    #[track_caller]
    fn assert_suggests_correction(misspelled_word: &str, correct: &str) {
        let results = suggest_correct_spelling_str(
            misspelled_word,
            RESULT_LIMIT,
            MAX_EDIT_DIST,
            &FstDictionary::curated(),
        );

        dbg!(&results);

        assert!(results.iter().take(3).contains(&correct.to_string()));
    }

    #[test]
    fn spellcheck_hvllo() {
        assert_suggests_correction("hvllo", "hello");
    }

    #[test]
    fn spellcheck_aout() {
        assert_suggests_correction("aout", "about");
    }

    #[test]
    fn spellchecking_is_deterministic() {
        let results1 = suggest_correct_spelling_str(
            "hello",
            RESULT_LIMIT,
            MAX_EDIT_DIST,
            &FstDictionary::curated(),
        );
        let results2 = suggest_correct_spelling_str(
            "hello",
            RESULT_LIMIT,
            MAX_EDIT_DIST,
            &FstDictionary::curated(),
        );
        let results3 = suggest_correct_spelling_str(
            "hello",
            RESULT_LIMIT,
            MAX_EDIT_DIST,
            &FstDictionary::curated(),
        );

        assert_eq!(results1, results2);
        assert_eq!(results1, results3);
    }

    #[test]
    fn adviced_correction() {
        assert_suggests_correction("adviced", "advised");
    }

    #[test]
    fn aknowledged_correction() {
        assert_suggests_correction("aknowledged", "acknowledged");
    }

    #[test]
    fn alcaholic_correction() {
        assert_suggests_correction("alcaholic", "alcoholic");
    }

    #[test]
    fn slaves_correction() {
        assert_suggests_correction("Slaves", "Slavs");
    }

    #[test]
    fn conciousness_correction() {
        assert_suggests_correction("conciousness", "consciousness");
    }

    // Tests for dialect-specific misspelling patterns

    // is_ou_misspelling
    #[test]
    fn suggest_color_for_colour_lowercase() {
        assert_suggestion_result(
            "colour",
            SpellCheck::new(FstDictionary::curated(), Dialect::American),
            "color",
        );
    }

    #[test]
    fn suggest_colour_for_color_lowercase() {
        assert_suggestion_result(
            "color",
            SpellCheck::new(FstDictionary::curated(), Dialect::British),
            "colour",
        );
    }

    // titlecase
    #[test]
    fn suggest_color_for_colour_titlecase() {
        assert_suggestion_result(
            "Colour",
            SpellCheck::new(FstDictionary::curated(), Dialect::American),
            "Color",
        );
    }

    #[test]
    #[ignore = "known failure due to bug"]
    fn suggest_colour_for_color_titlecase() {
        assert_suggestion_result(
            "Color",
            SpellCheck::new(FstDictionary::curated(), Dialect::British),
            "Colour",
        );
    }

    // all-caps
    #[test]
    #[ignore = "known failure due to bug"]
    fn suggest_color_for_colour_all_caps() {
        assert_suggestion_result(
            "COLOUR",
            SpellCheck::new(FstDictionary::curated(), Dialect::American),
            "COLOR",
        );
    }

    #[test]
    #[ignore = "known failure due to bug"]
    fn suggest_colour_for_color_all_caps() {
        assert_suggestion_result(
            "COLOR",
            SpellCheck::new(FstDictionary::curated(), Dialect::British),
            "COLOUR",
        );
    }

    // is_cksz_misspelling

    // s/z as in realise/realize
    #[test]
    #[ignore = "both spellings are acceptable in UK, AU, and IN despite popular opinion"]
    fn suggest_realise_for_realize() {
        assert_suggestion_result(
            "realize",
            SpellCheck::new(FstDictionary::curated(), Dialect::British),
            "realise",
        );
    }

    #[test]
    fn suggest_realize_for_realise() {
        assert_suggestion_result(
            "realise",
            SpellCheck::new(FstDictionary::curated(), Dialect::American),
            "realize",
        );
    }

    #[test]
    #[ignore = "both spellings are acceptable in UK, AU, and IN despite popular opinion"]
    fn suggest_realise_for_realize_titlecase() {
        assert_suggestion_result(
            "Realize",
            SpellCheck::new(FstDictionary::curated(), Dialect::British),
            "Realise",
        );
    }

    #[test]
    #[ignore = "known failure due to bug"]
    fn suggest_realize_for_realise_titlecase() {
        assert_suggestion_result(
            "Realise",
            SpellCheck::new(FstDictionary::curated(), Dialect::American),
            "Realize",
        );
    }

    #[test]
    #[ignore = "known failure due to bug"]
    fn suggest_realise_for_realize_all_caps() {
        assert_suggestion_result(
            "REALIZE",
            SpellCheck::new(FstDictionary::curated(), Dialect::British),
            "REALISE",
        );
    }

    #[test]
    #[ignore = "known failure due to bug"]
    fn suggest_realize_for_realise_all_caps() {
        assert_suggestion_result(
            "REALISE",
            SpellCheck::new(FstDictionary::curated(), Dialect::American),
            "REALIZE",
        );
    }

    // s/c as in defense/defence
    #[test]
    fn suggest_defence_for_defense() {
        assert_suggestion_result(
            "defense",
            SpellCheck::new(FstDictionary::curated(), Dialect::British),
            "defence",
        );
    }

    #[test]
    fn suggest_defense_for_defence() {
        assert_suggestion_result(
            "defence",
            SpellCheck::new(FstDictionary::curated(), Dialect::American),
            "defense",
        );
    }

    #[test]
    fn suggest_defense_for_defence_titlecase() {
        assert_suggestion_result(
            "Defense",
            SpellCheck::new(FstDictionary::curated(), Dialect::British),
            "Defence",
        );
    }

    #[test]
    fn suggest_defence_for_defense_titlecase() {
        assert_suggestion_result(
            "Defence",
            SpellCheck::new(FstDictionary::curated(), Dialect::American),
            "Defense",
        );
    }

    #[test]
    #[ignore = "known failure due to bug"]
    fn suggest_defense_for_defence_all_caps() {
        assert_suggestion_result(
            "DEFENSE",
            SpellCheck::new(FstDictionary::curated(), Dialect::British),
            "DEFENCE",
        );
    }

    #[test]
    #[ignore = "known failure due to bug"]
    fn suggest_defence_for_defense_all_caps() {
        assert_suggestion_result(
            "DEFENCE",
            SpellCheck::new(FstDictionary::curated(), Dialect::American),
            "DEFENSE",
        );
    }

    // k/c as in skeptic/sceptic
    #[test]
    fn suggest_sceptic_for_skeptic() {
        assert_suggestion_result(
            "skeptic",
            SpellCheck::new(FstDictionary::curated(), Dialect::British),
            "sceptic",
        );
    }

    #[test]
    fn suggest_skeptic_for_sceptic() {
        assert_suggestion_result(
            "sceptic",
            SpellCheck::new(FstDictionary::curated(), Dialect::American),
            "skeptic",
        );
    }

    #[test]
    fn suggest_sceptic_for_skeptic_titlecase() {
        assert_suggestion_result(
            "Skeptic",
            SpellCheck::new(FstDictionary::curated(), Dialect::British),
            "Sceptic",
        );
    }

    #[test]
    #[ignore = "known failure due to bug"]
    fn suggest_skeptic_for_sceptic_titlecase() {
        assert_suggestion_result(
            "Sceptic",
            SpellCheck::new(FstDictionary::curated(), Dialect::American),
            "Skeptic",
        );
    }

    #[test]
    #[ignore = "known failure due to bug"]
    fn suggest_skeptic_for_sceptic_all_caps() {
        assert_suggestion_result(
            "SKEPTIC",
            SpellCheck::new(FstDictionary::curated(), Dialect::British),
            "SCEPTIC",
        );
    }

    #[test]
    #[ignore = "known failure due to bug"]
    fn suggest_sceptic_for_skeptic_all_caps() {
        assert_suggestion_result(
            "SCEPTIC",
            SpellCheck::new(FstDictionary::curated(), Dialect::American),
            "SKEPTIC",
        );
    }

    // is_er_misspelling
    // as in meter/metre
    #[test]
    fn suggest_centimeter_for_centimetre() {
        assert_suggestion_result(
            "centimetre",
            SpellCheck::new(FstDictionary::curated(), Dialect::American),
            "centimeter",
        );
    }

    #[test]
    fn suggest_centimetre_for_centimeter() {
        assert_suggestion_result(
            "centimeter",
            SpellCheck::new(FstDictionary::curated(), Dialect::British),
            "centimetre",
        );
    }

    #[test]
    fn suggest_centimeter_for_centimetre_titlecase() {
        assert_suggestion_result(
            "Centimetre",
            SpellCheck::new(FstDictionary::curated(), Dialect::American),
            "Centimeter",
        );
    }

    #[test]
    #[ignore = "known failure due to bug"]
    fn suggest_centimetre_for_centimeter_titlecase() {
        assert_suggestion_result(
            "Centimeter",
            SpellCheck::new(FstDictionary::curated(), Dialect::British),
            "Centimetre",
        );
    }

    #[test]
    #[ignore = "known failure due to bug"]
    fn suggest_centimeter_for_centimetre_all_caps() {
        assert_suggestion_result(
            "CENTIMETRE",
            SpellCheck::new(FstDictionary::curated(), Dialect::American),
            "CENTIMETER",
        );
    }

    #[test]
    #[ignore = "known failure due to bug"]
    fn suggest_centimetre_for_centimeter_all_caps() {
        assert_suggestion_result(
            "CENTIMETER",
            SpellCheck::new(FstDictionary::curated(), Dialect::British),
            "CENTIMETRE",
        );
    }

    // is_ll_misspelling
    // as in traveller/traveler
    #[test]
    fn suggest_traveler_for_traveller() {
        assert_suggestion_result(
            "traveller",
            SpellCheck::new(FstDictionary::curated(), Dialect::American),
            "traveler",
        );
    }

    #[test]
    fn suggest_traveller_for_traveler() {
        assert_suggestion_result(
            "traveler",
            SpellCheck::new(FstDictionary::curated(), Dialect::British),
            "traveller",
        );
    }

    #[test]
    fn suggest_traveler_for_traveller_titlecase() {
        assert_suggestion_result(
            "Traveller",
            SpellCheck::new(FstDictionary::curated(), Dialect::American),
            "Traveler",
        );
    }

    #[test]
    #[ignore = "known failure due to bug"]
    fn suggest_traveller_for_traveler_titlecase() {
        assert_suggestion_result(
            "Traveler",
            SpellCheck::new(FstDictionary::curated(), Dialect::British),
            "Traveller",
        );
    }

    #[test]
    #[ignore = "known failure due to bug"]
    fn suggest_traveler_for_traveller_all_caps() {
        assert_suggestion_result(
            "TRAVELLER",
            SpellCheck::new(FstDictionary::curated(), Dialect::American),
            "TRAVELER",
        );
    }

    #[test]
    #[ignore = "known failure due to bug"]
    fn suggest_traveller_for_traveler_all_caps() {
        assert_suggestion_result(
            "TRAVELER",
            SpellCheck::new(FstDictionary::curated(), Dialect::British),
            "TRAVELLER",
        );
    }

    // is_ay_ey_misspelling
    // as in gray/grey

    #[test]
    fn suggest_grey_for_gray_in_non_american() {
        assert_suggestion_result(
            "I've got a gray cat.",
            SpellCheck::new(FstDictionary::curated(), Dialect::British),
            "I've got a grey cat.",
        );
    }

    #[test]
    fn suggest_gray_for_grey_in_american() {
        assert_suggestion_result(
            "It's a greyscale photo.",
            SpellCheck::new(FstDictionary::curated(), Dialect::American),
            "It's a grayscale photo.",
        );
    }

    #[test]
    #[ignore = "known failure due to bug"]
    fn suggest_grey_for_gray_in_non_american_titlecase() {
        assert_suggestion_result(
            "I've Got a Gray Cat.",
            SpellCheck::new(FstDictionary::curated(), Dialect::British),
            "I've Got a Grey Cat.",
        );
    }

    #[test]
    fn suggest_gray_for_grey_in_american_titlecase() {
        assert_suggestion_result(
            "It's a Greyscale Photo.",
            SpellCheck::new(FstDictionary::curated(), Dialect::American),
            "It's a Grayscale Photo.",
        );
    }

    #[test]
    #[ignore = "known failure due to bug"]
    fn suggest_grey_for_gray_in_non_american_all_caps() {
        assert_suggestion_result(
            "GRAY",
            SpellCheck::new(FstDictionary::curated(), Dialect::British),
            "GREY",
        );
    }

    #[test]
    #[ignore = "known failure due to bug"]
    fn suggest_gray_for_grey_in_american_all_caps() {
        assert_suggestion_result(
            "GREY",
            SpellCheck::new(FstDictionary::curated(), Dialect::American),
            "GRAY",
        );
    }

    // Tests for non-dialectal misspelling patterns

    // is_ei_ie_misspelling
    #[test]
    fn fix_cheif_and_recieved() {
        assert_top3_suggestion_result(
            "The cheif recieved a letter.",
            SpellCheck::new(FstDictionary::curated(), Dialect::British),
            "The chief received a letter.",
        );
    }

    #[test]
    #[ignore = "known failure due to bug"]
    fn fix_cheif_and_recieved_titlecase() {
        assert_top3_suggestion_result(
            "The Cheif Recieved a Letter.",
            SpellCheck::new(FstDictionary::curated(), Dialect::British),
            "The Chief Received a Letter.",
        );
    }

    #[test]
    #[ignore = "known failure due to bug"]
    fn fix_cheif_and_recieved_all_caps() {
        assert_top3_suggestion_result(
            "THE CHEIF RECIEVED A LETTER.",
            SpellCheck::new(FstDictionary::curated(), Dialect::British),
            "THE CHEIF RECEIVED A LETTER.",
        );
    }
}



================================================
FILE: harper-core/src/spell/mutable_dictionary.rs
================================================
use super::{
    FstDictionary, WordId,
    rune::{self, AttributeList, parse_word_list},
    word_map::{WordMap, WordMapEntry},
};
use crate::edit_distance::edit_distance_min_alloc;
use itertools::Itertools;
use std::sync::Arc;
use std::{borrow::Cow, sync::LazyLock};

use crate::{CharString, CharStringExt, DictWordMetadata};

use super::FuzzyMatchResult;
use super::dictionary::Dictionary;

/// A basic dictionary that allows words to be added after instantiating.
/// This is useful for user and file dictionaries that may change at runtime.
///
/// For immutable use-cases that require fuzzy lookups, such as the curated dictionary, prefer [`super::FstDictionary`],
/// as it is much faster.
///
/// To combine the contents of multiple dictionaries, regardless of type, use
/// [`super::MergedDictionary`].
#[derive(Debug, Clone, Eq, PartialEq)]
pub struct MutableDictionary {
    /// All English words
    word_map: WordMap,
}

/// The uncached function that is used to produce the original copy of the
/// curated dictionary.
fn uncached_inner_new() -> Arc<MutableDictionary> {
    MutableDictionary::from_rune_files(
        include_str!("../../dictionary.dict"),
        include_str!("../../annotations.json"),
    )
    .map(Arc::new)
    .unwrap_or_else(|e| panic!("Failed to load curated dictionary: {}", e))
}

static DICT: LazyLock<Arc<MutableDictionary>> = LazyLock::new(uncached_inner_new);

impl MutableDictionary {
    pub fn new() -> Self {
        Self {
            word_map: WordMap::default(),
        }
    }

    pub fn from_rune_files(word_list: &str, attr_list: &str) -> Result<Self, rune::Error> {
        let word_list = parse_word_list(word_list)?;
        let attr_list = AttributeList::parse(attr_list)?;

        // There will be at _least_ this number of words
        let mut word_map = WordMap::default();

        attr_list.expand_annotated_words(word_list, &mut word_map);

        Ok(Self { word_map })
    }

    /// Create a dictionary from the curated dictionary included
    /// in the Harper binary.
    /// Consider using [`super::FstDictionary::curated()`] instead, as it is more performant for spellchecking.
    pub fn curated() -> Arc<Self> {
        (*DICT).clone()
    }

    /// Appends words to the dictionary.
    /// It is significantly faster to append many words with one call than many
    /// distinct calls to this function.
    pub fn extend_words(
        &mut self,
        words: impl IntoIterator<Item = (impl AsRef<[char]>, DictWordMetadata)>,
    ) {
        for (chars, metadata) in words.into_iter() {
            self.word_map.insert(WordMapEntry {
                metadata,
                canonical_spelling: chars.as_ref().into(),
            })
        }
    }

    /// Append a single word to the dictionary.
    ///
    /// If you are appending many words, consider using [`Self::extend_words`]
    /// instead.
    pub fn append_word(&mut self, word: impl AsRef<[char]>, metadata: DictWordMetadata) {
        self.extend_words(std::iter::once((word.as_ref(), metadata)))
    }

    /// Append a single string to the dictionary.
    ///
    /// If you are appending many words, consider using [`Self::extend_words`]
    /// instead.
    pub fn append_word_str(&mut self, word: &str, metadata: DictWordMetadata) {
        self.append_word(word.chars().collect::<Vec<_>>(), metadata)
    }
}

impl Default for MutableDictionary {
    fn default() -> Self {
        Self::new()
    }
}

impl Dictionary for MutableDictionary {
    fn get_word_metadata(&self, word: &[char]) -> Option<Cow<'_, DictWordMetadata>> {
        self.word_map
            .get_with_chars(word)
            .map(|v| Cow::Borrowed(&v.metadata))
    }

    fn contains_word(&self, word: &[char]) -> bool {
        self.word_map.contains_chars(word)
    }

    fn contains_word_str(&self, word: &str) -> bool {
        let chars: CharString = word.chars().collect();
        self.contains_word(&chars)
    }

    fn get_word_metadata_str(&self, word: &str) -> Option<Cow<'_, DictWordMetadata>> {
        let chars: CharString = word.chars().collect();
        self.get_word_metadata(&chars)
    }

    fn get_correct_capitalization_of(&self, word: &[char]) -> Option<&'_ [char]> {
        self.word_map
            .get_with_chars(word)
            .map(|v| v.canonical_spelling.as_slice())
    }

    /// Suggest a correct spelling for a given misspelled word.
    /// `Self::word` is assumed to be quite small (n < 100).
    /// `max_distance` relates to an optimization that allows the search
    /// algorithm to prune large portions of the search.
    fn fuzzy_match(
        &'_ self,
        word: &[char],
        max_distance: u8,
        max_results: usize,
    ) -> Vec<FuzzyMatchResult<'_>> {
        let misspelled_charslice = word.normalized();
        let misspelled_charslice_lower = misspelled_charslice.to_lower();

        let shortest_word_len = if misspelled_charslice.len() <= max_distance as usize {
            1
        } else {
            misspelled_charslice.len() - max_distance as usize
        };
        let longest_word_len = misspelled_charslice.len() + max_distance as usize;

        // Get candidate words
        let words_to_search = self
            .words_iter()
            .filter(|word| (shortest_word_len..=longest_word_len).contains(&word.len()));

        // Pre-allocated vectors for the edit-distance calculation
        // 53 is the length of the longest word.
        let mut buf_a = Vec::with_capacity(53);
        let mut buf_b = Vec::with_capacity(53);

        // Sort by edit-distance
        words_to_search
            .filter_map(|word| {
                let dist =
                    edit_distance_min_alloc(&misspelled_charslice, word, &mut buf_a, &mut buf_b);
                let lowercase_dist = edit_distance_min_alloc(
                    &misspelled_charslice_lower,
                    word,
                    &mut buf_a,
                    &mut buf_b,
                );

                let smaller_dist = dist.min(lowercase_dist);
                if smaller_dist <= max_distance {
                    Some((word, smaller_dist))
                } else {
                    None
                }
            })
            .sorted_unstable_by_key(|a| a.1)
            .take(max_results)
            .map(|(word, edit_distance)| FuzzyMatchResult {
                word,
                edit_distance,
                metadata: self.get_word_metadata(word).unwrap(),
            })
            .collect()
    }

    fn fuzzy_match_str(
        &'_ self,
        word: &str,
        max_distance: u8,
        max_results: usize,
    ) -> Vec<FuzzyMatchResult<'_>> {
        let word: Vec<_> = word.chars().collect();
        self.fuzzy_match(&word, max_distance, max_results)
    }

    fn words_iter(&self) -> Box<dyn Iterator<Item = &'_ [char]> + Send + '_> {
        Box::new(
            self.word_map
                .iter()
                .map(|v| v.canonical_spelling.as_slice()),
        )
    }

    fn word_count(&self) -> usize {
        self.word_map.len()
    }

    fn contains_exact_word(&self, word: &[char]) -> bool {
        let normalized = word.normalized();

        if let Some(found) = self.word_map.get_with_chars(normalized.as_ref())
            && found.canonical_spelling.as_ref() == normalized.as_ref()
        {
            return true;
        }

        false
    }

    fn contains_exact_word_str(&self, word: &str) -> bool {
        let word: CharString = word.chars().collect();
        self.contains_exact_word(word.as_ref())
    }

    fn get_word_from_id(&self, id: &WordId) -> Option<&[char]> {
        self.word_map.get(id).map(|w| w.canonical_spelling.as_ref())
    }

    fn find_words_with_prefix(&self, prefix: &[char]) -> Vec<Cow<'_, [char]>> {
        let mut found = Vec::new();

        for word in self.words_iter() {
            if let Some(item_prefix) = word.get(0..prefix.len())
                && item_prefix == prefix
            {
                found.push(Cow::Borrowed(word));
            }
        }

        found
    }

    fn find_words_with_common_prefix(&self, word: &[char]) -> Vec<Cow<'_, [char]>> {
        let mut found = Vec::new();

        for item in self.words_iter() {
            if let Some(item_prefix) = word.get(0..item.len())
                && item_prefix == item
            {
                found.push(Cow::Borrowed(item));
            }
        }

        found
    }
}

impl From<MutableDictionary> for FstDictionary {
    fn from(dict: MutableDictionary) -> Self {
        let words = dict
            .word_map
            .into_iter()
            .map(|entry| (entry.canonical_spelling, entry.metadata))
            .collect();

        FstDictionary::new(words)
    }
}

#[cfg(test)]
mod tests {
    use std::borrow::Cow;

    use hashbrown::HashSet;
    use itertools::Itertools;

    use crate::spell::{Dictionary, MutableDictionary};
    use crate::{DictWordMetadata, char_string::char_string};

    #[test]
    fn curated_contains_no_duplicates() {
        let dict = MutableDictionary::curated();
        assert!(dict.words_iter().all_unique());
    }

    #[test]
    fn curated_matches_capitalized() {
        let dict = MutableDictionary::curated();
        assert!(dict.contains_word_str("this"));
        assert!(dict.contains_word_str("This"));
    }

    // "This" is a determiner when used similarly to "the"
    // but when used alone it's a "demonstrative pronoun".
    // Harper previously wrongly classified it as a noun.
    #[test]
    fn this_is_determiner() {
        let dict = MutableDictionary::curated();
        assert!(dict.get_word_metadata_str("this").unwrap().is_determiner());
        assert!(dict.get_word_metadata_str("This").unwrap().is_determiner());
    }

    #[test]
    fn several_is_quantifier() {
        let dict = MutableDictionary::curated();
        assert!(
            dict.get_word_metadata_str("several")
                .unwrap()
                .is_quantifier()
        );
    }

    #[test]
    fn few_is_quantifier() {
        let dict = MutableDictionary::curated();
        assert!(dict.get_word_metadata_str("few").unwrap().is_quantifier());
    }

    #[test]
    fn fewer_is_quantifier() {
        let dict = MutableDictionary::curated();
        assert!(dict.get_word_metadata_str("fewer").unwrap().is_quantifier());
    }

    #[test]
    fn than_is_conjunction() {
        let dict = MutableDictionary::curated();
        assert!(dict.get_word_metadata_str("than").unwrap().is_conjunction());
        assert!(dict.get_word_metadata_str("Than").unwrap().is_conjunction());
    }

    #[test]
    fn herself_is_pronoun() {
        let dict = MutableDictionary::curated();
        assert!(dict.get_word_metadata_str("herself").unwrap().is_pronoun());
        assert!(dict.get_word_metadata_str("Herself").unwrap().is_pronoun());
    }

    #[test]
    fn discussion_171() {
        let dict = MutableDictionary::curated();
        assert!(dict.contains_word_str("natively"));
    }

    #[test]
    fn im_is_common() {
        let dict = MutableDictionary::curated();
        assert!(dict.get_word_metadata_str("I'm").unwrap().common);
    }

    #[test]
    fn fuzzy_result_sorted_by_edit_distance() {
        let dict = MutableDictionary::curated();

        let results = dict.fuzzy_match_str("hello", 3, 100);
        let is_sorted_by_dist = results
            .iter()
            .map(|fm| fm.edit_distance)
            .tuple_windows()
            .all(|(a, b)| a <= b);

        assert!(is_sorted_by_dist)
    }

    #[test]
    fn there_is_not_a_pronoun() {
        let dict = MutableDictionary::curated();

        assert!(!dict.get_word_metadata_str("there").unwrap().is_nominal());
        assert!(!dict.get_word_metadata_str("there").unwrap().is_pronoun());
    }

    #[test]
    fn expanded_contains_giants() {
        assert!(MutableDictionary::curated().contains_word_str("giants"));
    }

    #[test]
    fn expanded_contains_deallocate() {
        assert!(MutableDictionary::curated().contains_word_str("deallocate"));
    }

    #[test]
    fn curated_contains_repo() {
        let dict = MutableDictionary::curated();

        assert!(dict.contains_word_str("repo"));
        assert!(dict.contains_word_str("repos"));
        assert!(dict.contains_word_str("repo's"));
    }

    #[test]
    fn curated_contains_possessive_abandonment() {
        assert!(
            MutableDictionary::curated()
                .get_word_metadata_str("abandonment's")
                .unwrap()
                .is_possessive_noun()
        )
    }

    #[test]
    fn has_is_not_a_nominal() {
        let dict = MutableDictionary::curated();

        let has = dict.get_word_metadata_str("has");
        assert!(has.is_some());

        assert!(!has.unwrap().is_nominal())
    }

    #[test]
    fn is_is_linking_verb() {
        let dict = MutableDictionary::curated();

        let is = dict.get_word_metadata_str("is");

        assert!(is.is_some());
        assert!(is.unwrap().is_linking_verb());
    }

    #[test]
    fn are_merged_attrs_same_as_spread_attrs() {
        let curated_attr_list = include_str!("../../annotations.json");

        let merged = MutableDictionary::from_rune_files("1\nblork/DGS", curated_attr_list).unwrap();
        let spread =
            MutableDictionary::from_rune_files("2\nblork/DG\nblork/S", curated_attr_list).unwrap();

        assert_eq!(
            merged.word_map.into_iter().collect::<HashSet<_>>(),
            spread.word_map.into_iter().collect::<HashSet<_>>()
        );
    }

    #[test]
    fn apart_is_not_noun() {
        let dict = MutableDictionary::curated();

        assert!(!dict.get_word_metadata_str("apart").unwrap().is_noun());
    }

    #[test]
    fn be_is_verb_lemma() {
        let dict = MutableDictionary::curated();

        let is = dict.get_word_metadata_str("be");

        assert!(is.is_some());
        assert!(is.unwrap().is_verb_lemma());
    }

    #[test]
    fn gets_prefixes_as_expected() {
        let mut dict = MutableDictionary::new();
        dict.append_word_str("predict", DictWordMetadata::default());
        dict.append_word_str("prelude", DictWordMetadata::default());
        dict.append_word_str("preview", DictWordMetadata::default());
        dict.append_word_str("dwight", DictWordMetadata::default());

        let with_prefix = dict.find_words_with_prefix(char_string!("pre").as_slice());

        assert_eq!(with_prefix.len(), 3);
        assert!(with_prefix.contains(&Cow::Owned(char_string!("predict").into_vec())));
        assert!(with_prefix.contains(&Cow::Owned(char_string!("prelude").into_vec())));
        assert!(with_prefix.contains(&Cow::Owned(char_string!("preview").into_vec())));
    }

    #[test]
    fn gets_common_prefixes_as_expected() {
        let mut dict = MutableDictionary::new();
        dict.append_word_str("pre", DictWordMetadata::default());
        dict.append_word_str("prep", DictWordMetadata::default());
        dict.append_word_str("dwight", DictWordMetadata::default());

        let with_prefix =
            dict.find_words_with_common_prefix(char_string!("preposition").as_slice());

        assert_eq!(with_prefix.len(), 2);
        assert!(with_prefix.contains(&Cow::Owned(char_string!("pre").into_vec())));
        assert!(with_prefix.contains(&Cow::Owned(char_string!("prep").into_vec())));
    }
}



================================================
FILE: harper-core/src/spell/trie_dictionary.rs
================================================
use std::borrow::Cow;
use std::sync::{Arc, LazyLock};

use trie_rs::Trie;
use trie_rs::iter::{Keys, PrefixIter, SearchIter};

use crate::DictWordMetadata;

use super::{Dictionary, FstDictionary, FuzzyMatchResult, WordId};

/// A [`Dictionary`] optimized for pre- and postfix search.
/// Wraps another dictionary to implement other operations.
pub struct TrieDictionary<D: Dictionary> {
    trie: Trie<char>,
    inner: D,
}

pub static DICT: LazyLock<Arc<TrieDictionary<Arc<FstDictionary>>>> =
    LazyLock::new(|| Arc::new(TrieDictionary::new(FstDictionary::curated())));

impl TrieDictionary<Arc<FstDictionary>> {
    /// Create a dictionary from the curated dictionary included
    /// in the Harper binary.
    pub fn curated() -> Arc<Self> {
        (*DICT).clone()
    }
}

impl<D: Dictionary> TrieDictionary<D> {
    pub fn new(inner: D) -> Self {
        let trie = Trie::from_iter(inner.words_iter());

        Self { inner, trie }
    }
}

impl<D: Dictionary> Dictionary for TrieDictionary<D> {
    fn contains_word(&self, word: &[char]) -> bool {
        self.inner.contains_word(word)
    }

    fn contains_word_str(&self, word: &str) -> bool {
        self.inner.contains_word_str(word)
    }

    fn contains_exact_word(&self, word: &[char]) -> bool {
        self.inner.contains_exact_word(word)
    }

    fn contains_exact_word_str(&self, word: &str) -> bool {
        self.inner.contains_exact_word_str(word)
    }

    fn fuzzy_match(
        &'_ self,
        word: &[char],
        max_distance: u8,
        max_results: usize,
    ) -> Vec<FuzzyMatchResult<'_>> {
        self.inner.fuzzy_match(word, max_distance, max_results)
    }

    fn fuzzy_match_str(
        &'_ self,
        word: &str,
        max_distance: u8,
        max_results: usize,
    ) -> Vec<FuzzyMatchResult<'_>> {
        self.inner.fuzzy_match_str(word, max_distance, max_results)
    }

    fn get_correct_capitalization_of(&self, word: &[char]) -> Option<&'_ [char]> {
        self.inner.get_correct_capitalization_of(word)
    }

    fn get_word_metadata(&self, word: &[char]) -> Option<Cow<'_, DictWordMetadata>> {
        self.inner.get_word_metadata(word)
    }

    fn get_word_metadata_str(&self, word: &str) -> Option<Cow<'_, DictWordMetadata>> {
        self.inner.get_word_metadata_str(word)
    }

    fn words_iter(&self) -> Box<dyn Iterator<Item = &'_ [char]> + Send + '_> {
        self.inner.words_iter()
    }

    fn word_count(&self) -> usize {
        self.inner.word_count()
    }

    fn get_word_from_id(&self, id: &WordId) -> Option<&[char]> {
        self.inner.get_word_from_id(id)
    }

    fn find_words_with_prefix(&self, prefix: &[char]) -> Vec<Cow<'_, [char]>> {
        let results: Keys<SearchIter<'_, char, (), Vec<char>, _>> =
            self.trie.predictive_search(prefix);
        results.map(Cow::Owned).collect()
    }

    fn find_words_with_common_prefix(&self, word: &[char]) -> Vec<Cow<'_, [char]>> {
        let results: Keys<PrefixIter<'_, char, (), Vec<char>, _>> =
            self.trie.common_prefix_search(word);
        results.map(Cow::Owned).collect()
    }
}

#[cfg(test)]
mod tests {
    use std::borrow::Cow;

    use crate::DictWordMetadata;
    use crate::char_string::char_string;
    use crate::spell::MutableDictionary;
    use crate::spell::dictionary::Dictionary;
    use crate::spell::trie_dictionary::TrieDictionary;

    #[test]
    fn gets_prefixes_as_expected() {
        let mut inner = MutableDictionary::new();
        inner.append_word_str("predict", DictWordMetadata::default());
        inner.append_word_str("prelude", DictWordMetadata::default());
        inner.append_word_str("preview", DictWordMetadata::default());
        inner.append_word_str("dwight", DictWordMetadata::default());

        let dict = TrieDictionary::new(inner);

        let with_prefix = dict.find_words_with_prefix(char_string!("pre").as_slice());

        assert_eq!(with_prefix.len(), 3);
        assert!(with_prefix.contains(&Cow::Owned(char_string!("predict").into_vec())));
        assert!(with_prefix.contains(&Cow::Owned(char_string!("prelude").into_vec())));
        assert!(with_prefix.contains(&Cow::Owned(char_string!("preview").into_vec())));
    }

    #[test]
    fn gets_common_prefixes_as_expected() {
        let mut inner = MutableDictionary::new();
        inner.append_word_str("pre", DictWordMetadata::default());
        inner.append_word_str("prep", DictWordMetadata::default());
        inner.append_word_str("dwight", DictWordMetadata::default());

        let dict = TrieDictionary::new(inner);

        let with_prefix =
            dict.find_words_with_common_prefix(char_string!("preposition").as_slice());

        assert_eq!(with_prefix.len(), 2);
        assert!(with_prefix.contains(&Cow::Owned(char_string!("pre").into_vec())));
        assert!(with_prefix.contains(&Cow::Owned(char_string!("prep").into_vec())));
    }
}



================================================
FILE: harper-core/src/spell/word_id.rs
================================================
use std::hash::BuildHasher;

use foldhash::fast::FixedState;
use serde::{Deserialize, Serialize};

use crate::{CharString, CharStringExt};

/// An identifier for a particular word.
///
/// It works by hashing the word it represents, normalized to lowercase.
/// It is meant for situations where you need to refer to a word (or a collection of words),
/// without storing all of accompanying data (like spelling or metadata).
#[derive(Hash, Copy, Clone, PartialEq, Eq, PartialOrd, Debug, Serialize, Deserialize)]
pub struct WordId {
    hash: u64,
}

impl WordId {
    /// Create a Word ID from a character slice.
    pub fn from_word_chars(chars: impl AsRef<[char]>) -> Self {
        let normalized = chars.as_ref().normalized();
        let lower = normalized.to_lower();
        let hash = FixedState::default().hash_one(lower);

        Self { hash }
    }

    /// Create a word ID from a string.
    /// Requires allocation, so use sparingly.
    pub fn from_word_str(text: impl AsRef<str>) -> Self {
        let chars: CharString = text.as_ref().chars().collect();
        Self::from_word_chars(chars)
    }
}



================================================
FILE: harper-core/src/spell/word_map.rs
================================================
use hashbrown::{HashMap, hash_map::IntoValues};

use crate::{CharString, DictWordMetadata};

use super::WordId;

/// The underlying data structure for the `MutableDictionary`.
#[derive(Debug, Clone, Eq, PartialEq, Default)]
pub struct WordMap {
    inner: HashMap<WordId, WordMapEntry>,
}

#[derive(Debug, Clone, Eq, PartialEq, Hash)]
pub struct WordMapEntry {
    pub metadata: DictWordMetadata,
    pub canonical_spelling: CharString,
}

impl WordMap {
    /// Get an entry from the word map using raw chars.
    pub fn get_with_str(&self, string: &str) -> Option<&WordMapEntry> {
        let chars: CharString = string.chars().collect();
        let id = WordId::from_word_chars(chars);

        self.get(&id)
    }

    pub fn contains_str(&self, string: &str) -> bool {
        self.get_with_str(string).is_some()
    }

    pub fn contains_chars(&self, chars: impl AsRef<[char]>) -> bool {
        self.get_with_chars(chars).is_some()
    }

    pub fn contains(&self, id: &WordId) -> bool {
        self.get(id).is_some()
    }

    /// Get an entry from the word map using raw chars.
    pub fn get_with_chars(&self, chars: impl AsRef<[char]>) -> Option<&WordMapEntry> {
        let id = WordId::from_word_chars(chars);

        self.get(&id)
    }

    /// Get an entry from the word map using a word identifier.
    pub fn get(&self, id: &WordId) -> Option<&WordMapEntry> {
        self.inner.get(id)
    }

    /// Borrow a word's metadata mutably
    pub fn get_metadata_mut_chars(
        &mut self,
        chars: impl AsRef<[char]>,
    ) -> Option<&mut DictWordMetadata> {
        let id = WordId::from_word_chars(chars);

        self.get_metadata_mut(&id)
    }

    /// Borrow a word's metadata mutably
    pub fn get_metadata_mut(&mut self, id: &WordId) -> Option<&mut DictWordMetadata> {
        self.inner.get_mut(id).map(|v| &mut v.metadata)
    }

    pub fn insert(&mut self, entry: WordMapEntry) {
        let id = WordId::from_word_chars(&entry.canonical_spelling);

        self.inner.insert(id, entry);
    }

    /// Reserves capacity for at least `additional` more elements to be inserted
    /// in the `WordMap`. The collection may reserve more space to avoid
    /// frequent reallocations.
    pub fn reserve(&mut self, additional: usize) {
        self.inner.reserve(additional);
    }

    /// Iterate through the canonical spellings of the words in the map.
    pub fn iter(&self) -> impl Iterator<Item = &WordMapEntry> {
        self.inner.values()
    }

    pub fn len(&self) -> usize {
        self.inner.len()
    }

    pub fn with_capacity(capacity: usize) -> Self {
        Self {
            inner: HashMap::with_capacity(capacity),
        }
    }
}

impl IntoIterator for WordMap {
    type Item = WordMapEntry;

    fn into_iter(self) -> Self::IntoIter {
        self.inner.into_values()
    }

    type IntoIter = IntoValues<WordId, WordMapEntry>;
}



================================================
FILE: harper-core/src/spell/rune/affix_replacement.rs
================================================
use serde::{Deserialize, Serialize};

use super::Error;
use super::matcher::Matcher;

#[derive(Debug, Clone)]
pub struct AffixReplacement {
    pub remove: Vec<char>,
    pub add: Vec<char>,
    pub condition: Matcher,
}

impl AffixReplacement {
    pub fn to_human_readable(&self) -> HumanReadableAffixReplacement {
        HumanReadableAffixReplacement {
            remove: self.remove.iter().collect(),
            add: self.add.iter().collect(),
            condition: self.condition.to_string(),
        }
    }
}

/// A version of [`AffixReplacement`] that can be serialized to JSON (or
/// whatever) and maintain the nice Regex syntax of the inner [`Matcher`].
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct HumanReadableAffixReplacement {
    pub remove: String,
    pub add: String,
    pub condition: String,
}

impl HumanReadableAffixReplacement {
    pub fn to_normal(&self) -> Result<AffixReplacement, Error> {
        Ok(AffixReplacement {
            remove: self.remove.chars().collect(),
            add: self.add.chars().collect(),
            condition: Matcher::parse(&self.condition)?,
        })
    }
}



================================================
FILE: harper-core/src/spell/rune/attribute_list.rs
================================================
use hashbrown::HashMap;
use serde::{Deserialize, Serialize};
use smallvec::ToSmallVec;

use super::super::word_map::{WordMap, WordMapEntry};
use super::Error;
use super::affix_replacement::AffixReplacement;
use super::expansion::Property;
use super::expansion::{
    AffixEntryKind,
    AffixEntryKind::{Prefix, Suffix},
    Expansion, HumanReadableExpansion,
};
use super::word_list::AnnotatedWord;
use crate::dict_word_metadata_orthography::OrthFlags;
use crate::spell::WordId;
use crate::{CharString, DictWordMetadata, Span};

#[derive(Debug, Clone)]
pub struct AttributeList {
    /// Key = Affix Flag
    affixes: HashMap<char, Expansion>,
    properties: HashMap<char, Property>,
}

impl AttributeList {
    fn into_human_readable(self) -> HumanReadableAttributeList {
        HumanReadableAttributeList {
            affixes: self
                .affixes
                .into_iter()
                .map(|(affix, exp)| (affix, exp.into_human_readable()))
                .collect(),
            properties: self.properties,
        }
    }

    pub fn parse(source: &str) -> Result<Self, Error> {
        let human_readable: Result<HumanReadableAttributeList, _> = serde_json::from_str(source);
        human_readable
            .map_err(Error::from)
            .and_then(|parsed| parsed.into_normal())
    }

    /// Expand an [`AnnotatedWord`] into a list of full words, including itself.
    ///
    /// This function processes a word and its attributes to:
    /// 1. Apply properties to the base word
    /// 2. Generate derived words using affix rules
    /// 3. Handle conditional expansions
    /// 4. Manage cross-product expansions
    ///
    /// # Arguments
    /// * `word` - The word to expand, along with its attributes
    /// * `dest` - The WordMap to store the expanded words and their metadata
    pub fn expand_annotated_word(&self, annotated_word: AnnotatedWord, word_map: &mut WordMap) {
        // Pre-allocate space in the destination map for better performance
        word_map.reserve(annotated_word.annotations.len() + 1);

        // Initialize base metadata that will be applied to all derived forms
        let mut base_metadata = DictWordMetadata::default();

        // Store metadata that should only be applied if certain conditions are met
        let orth_flags = OrthFlags::from_letters(&annotated_word.letters);
        base_metadata.orth_info = orth_flags;

        let mut conditional_expansion_metadata = Vec::new();

        // First pass: Process all properties to build the base metadata
        // Properties directly modify the word's metadata (e.g., part of speech, usage)
        for attr in &annotated_word.annotations {
            let Some(property) = self.properties.get(attr) else {
                continue;
            };
            base_metadata.append(&property.metadata);
        }

        // Second pass: Process all affix rules to generate derived forms
        for attr in &annotated_word.annotations {
            // Skip if this attribute isn't an affix rule
            let Some(expansion) = self.affixes.get(attr) else {
                continue;
            };

            // Add any base metadata from this affix rule
            base_metadata.append(&expansion.base_metadata);

            // Track new words generated by this affix rule
            let mut new_words: HashMap<CharString, DictWordMetadata> = HashMap::new();

            // Apply each replacement rule in this affix
            for replacement in &expansion.replacements {
                if let Some(replaced) =
                    Self::apply_replacement(replacement, &annotated_word.letters, expansion.kind)
                {
                    // Get or create metadata for this new word form
                    let metadata = new_words.entry(replaced.clone()).or_default();

                    // Process each target for this replacement
                    for target in &expansion.target {
                        if let Some(condition) = &target.if_base {
                            // Store conditional metadata to be applied later
                            conditional_expansion_metadata.push((
                                replaced.clone(),
                                target.metadata.clone(),
                                condition.clone(),
                            ));
                        } else {
                            // Apply target metadata immediately
                            metadata.append(&target.metadata);
                        }
                    }
                }
            }

            // Handle cross-product expansions (e.g., both prefix and suffix)
            if expansion.cross_product {
                // Collect attributes that should be applied to the opposite affix type
                let mut opposite_attributes = Vec::new();

                // Add properties that should propagate to derived forms
                for attr in &annotated_word.annotations {
                    let Some(property) = self.properties.get(attr) else {
                        continue;
                    };
                    if expansion.kind == Prefix || property.propagate {
                        opposite_attributes.push(*attr);
                    }
                }

                // Add affix attributes of the opposite type
                for attr in &annotated_word.annotations {
                    let Some(attr_def) = self.affixes.get(attr) else {
                        continue;
                    };
                    // This checks if the current affix is of the opposite type
                    if (attr_def.kind != Prefix) != (expansion.kind != Prefix) {
                        opposite_attributes.push(*attr);
                    }
                }

                // Recursively process each new word form
                for (new_word, metadata) in new_words {
                    self.expand_annotated_word(
                        AnnotatedWord {
                            letters: new_word.clone(),
                            annotations: opposite_attributes.clone(),
                        },
                        word_map,
                    );
                    // Update the metadata of the expanded word
                    let target_metadata = word_map.get_metadata_mut_chars(&new_word).unwrap();
                    target_metadata.append(&metadata);
                    target_metadata.derived_from =
                        Some(WordId::from_word_chars(&annotated_word.letters));
                }
            } else {
                // Simple case: no cross-product expansion needed
                for (key, mut value) in new_words.into_iter() {
                    value.derived_from = Some(WordId::from_word_chars(&annotated_word.letters));

                    if let Some(existing_metadata) = word_map.get_metadata_mut_chars(&key) {
                        // Merge with existing metadata
                        existing_metadata.append(&value);
                    } else {
                        // Add new entry
                        word_map.insert(WordMapEntry {
                            canonical_spelling: key,
                            metadata: value,
                        });
                    }
                }
            }
        }

        // Finalize the metadata for the base word
        let mut full_metadata = base_metadata;

        // Merge with any existing metadata for this word
        if let Some(existing_metadata) = word_map.get_with_chars(&annotated_word.letters) {
            full_metadata.append(&existing_metadata.metadata);
        }

        // Store the final metadata for the base word
        word_map.insert(WordMapEntry {
            metadata: full_metadata.clone(),
            canonical_spelling: annotated_word.letters,
        });

        // Process any conditional expansions
        for (letters, metadata, condition) in conditional_expansion_metadata {
            // Check if the condition is satisfied by the base word's metadata
            let condition_satisfied = full_metadata.or(&condition) == full_metadata;
            if !condition_satisfied {
                continue;
            }

            // Apply the conditional metadata
            word_map
                .get_metadata_mut_chars(&letters)
                .unwrap()
                .append(&metadata);
        }
    }

    /// Expand an iterator of annotated words into strings.
    /// Note that this does __not__ guarantee that produced words will be
    /// unique.
    pub fn expand_annotated_words(
        &self,
        words: impl IntoIterator<Item = AnnotatedWord>,
        dest: &mut WordMap,
    ) {
        for word in words {
            self.expand_annotated_word(word, dest);
        }
    }

    fn apply_replacement(
        replacement: &AffixReplacement,
        letters: &[char],
        kind: AffixEntryKind,
    ) -> Option<CharString> {
        if replacement.condition.len() > letters.len() {
            return None;
        }

        let target_span = if kind == Suffix {
            Span::new(letters.len() - replacement.condition.len(), letters.len())
        } else {
            Span::new(0, replacement.condition.len())
        };

        let target_segment = target_span.get_content(letters);

        if replacement.condition.matches(target_segment) {
            let mut replaced_segment = letters.to_smallvec();
            let mut remove: CharString = replacement.remove.to_smallvec();

            if kind != Suffix {
                replaced_segment.reverse();
            } else {
                remove.reverse();
            }

            for c in &remove {
                let last = replaced_segment.last()?;

                if last == c {
                    replaced_segment.pop();
                } else {
                    return None;
                }
            }

            let mut to_add = replacement.add.to_vec();

            if kind != Suffix {
                to_add.reverse()
            }

            replaced_segment.extend(to_add);

            if kind != Suffix {
                replaced_segment.reverse();
            }

            return Some(replaced_segment);
        }

        None
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct HumanReadableAttributeList {
    affixes: HashMap<char, HumanReadableExpansion>,
    properties: HashMap<char, Property>,
}

impl HumanReadableAttributeList {
    pub fn into_normal(self) -> Result<AttributeList, Error> {
        let mut affixes = HashMap::with_capacity(self.affixes.len());

        for (affix, expansion) in self.affixes.into_iter() {
            affixes.insert(affix, expansion.into_normal()?);
        }

        Ok(AttributeList {
            affixes,
            properties: self.properties,
        })
    }
}

#[cfg(test)]
mod tests {
    use crate::spell::{Dictionary, FstDictionary};

    #[test]
    fn proper_noun_property_propagates_to_plurals() {
        let fst_dict = FstDictionary::curated();
        if let Some(vw_plural) = fst_dict.get_word_metadata_str("Volkswagens") {
            assert!(vw_plural.is_proper_noun());
        }
    }

    #[test]
    fn proper_noun_propagates_to_possessives_2327() {
        if let Some(vw_possessive) = FstDictionary::curated().get_word_metadata_str("Volkswagen's")
        {
            assert!(vw_possessive.is_possessive_noun());
        }
    }
}



================================================
FILE: harper-core/src/spell/rune/error.rs
================================================
use super::matcher;

use serde_json::Error as SerdeJsonError;

#[derive(Debug, Clone, thiserror::Error)]
pub enum Error {
    #[error("The provided file's item count was malformed.")]
    MalformedItemCount,
    #[error("Expected affix flag to be exactly one character.")]
    MultiCharacterFlag,
    #[error("Expected affix option to be a boolean.")]
    ExpectedBoolean,
    #[error("Expected affix option to be an unsigned integer.")]
    ExpectedUnsignedInteger,
    #[error("Could not parse because we encountered the end of the line.")]
    UnexpectedEndOfLine,
    #[error("Received malformed JSON at line {line}, column {column}: {message}")]
    MalformedJSON {
        message: String,
        line: usize,
        column: usize,
    },
    #[error("An error occurred with a condition: {0}")]
    Matcher(#[from] matcher::Error),
}

impl From<SerdeJsonError> for Error {
    fn from(e: SerdeJsonError) -> Self {
        Error::MalformedJSON {
            message: e.to_string(),
            line: e.line(),
            column: e.column(),
        }
    }
}



================================================
FILE: harper-core/src/spell/rune/expansion.rs
================================================
use serde::{Deserialize, Serialize};

use super::Error;
use super::affix_replacement::{AffixReplacement, HumanReadableAffixReplacement};
use crate::DictWordMetadata;

#[derive(Debug, Clone, Copy, Serialize, Deserialize, PartialEq)]
#[serde(rename_all = "snake_case")]
pub enum AffixEntryKind {
    Suffix,
    Prefix,
}

/// Defines how a word can be transformed and what metadata to apply
#[derive(Debug, Clone)]
pub struct Expansion {
    /// Whether this is a prefix or suffix expansion
    pub kind: AffixEntryKind,
    /// If true, allows this expansion to be combined with others (e.g., both prefix and suffix)
    pub cross_product: bool,
    /// The replacement rules that define how to modify the word
    pub replacements: Vec<AffixReplacement>,
    /// Metadata to apply to the transformed word
    pub target: Vec<MetadataExpansion>,
    /// Metadata to apply to the base word when this expansion is applied
    pub base_metadata: DictWordMetadata,
}

impl Expansion {
    pub fn into_human_readable(self) -> HumanReadableExpansion {
        HumanReadableExpansion {
            kind: self.kind,
            cross_product: self.cross_product,
            replacements: self
                .replacements
                .iter()
                .map(AffixReplacement::to_human_readable)
                .collect(),
            target: self.target,
            base_metadata: self.base_metadata,
        }
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct MetadataExpansion {
    pub metadata: DictWordMetadata,
    pub if_base: Option<DictWordMetadata>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct HumanReadableExpansion {
    pub kind: AffixEntryKind,
    pub cross_product: bool,
    pub replacements: Vec<HumanReadableAffixReplacement>,
    pub target: Vec<MetadataExpansion>,
    pub base_metadata: DictWordMetadata,
}

impl HumanReadableExpansion {
    pub fn into_normal(self) -> Result<Expansion, Error> {
        let mut replacements = Vec::with_capacity(self.replacements.len());

        for replacement in &self.replacements {
            replacements.push(replacement.to_normal()?);
        }

        Ok(Expansion {
            kind: self.kind,
            cross_product: self.cross_product,
            replacements,
            target: self.target,
            base_metadata: self.base_metadata,
        })
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Property {
    /// Whether the metadata will propagate to all derived words.
    #[serde(default)]
    pub propagate: bool,
    /// The metadata applied to the word.
    pub metadata: DictWordMetadata,
}



================================================
FILE: harper-core/src/spell/rune/matcher.rs
================================================
use std::fmt::{Display, Formatter};

use serde::{Deserialize, Serialize};

/// A simplified, Regex-like matcher.
///
/// See the Hunspell documentation on affixes for more information.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Matcher {
    /// Position-based operators.
    operators: Vec<Operator>,
}

impl Matcher {
    pub fn parse(source: &str) -> Result<Self, Error> {
        let mut operators = Vec::new();

        let char_indices: Vec<_> = source.char_indices().collect();
        let mut char_idx = 0;

        while char_idx < char_indices.len() {
            let (idx, c) = char_indices[char_idx];

            match c {
                '[' => {
                    let close_idx = source[idx..]
                        .find(']')
                        .ok_or(Error::UnmatchedBracket { index: idx })?;

                    let bracket_contents = &source[idx + 1..close_idx];

                    let invert = matches!(bracket_contents.chars().next(), Some('^'));

                    if invert {
                        let chars: Vec<char> = bracket_contents.chars().skip(1).collect();
                        char_idx += chars.len() + 2;
                        operators.push(Operator::MatchNone(chars));
                    } else {
                        let chars: Vec<char> = bracket_contents.chars().collect();
                        char_idx += chars.len() + 1;
                        operators.push(Operator::MatchOne(chars));
                    }
                }
                '.' => operators.push(Operator::Any),
                _ => operators.push(Operator::Literal(c)),
            }

            char_idx += 1;
        }

        Ok(Self { operators })
    }

    pub fn len(&self) -> usize {
        self.operators.len()
    }

    pub fn matches(&self, chars: &[char]) -> bool {
        if chars.len() != self.len() {
            return false;
        }

        for (c, op) in chars.iter().zip(self.operators.iter()) {
            if !op.matches(*c) {
                return false;
            }
        }

        true
    }
}

impl Display for Matcher {
    fn fmt(&self, f: &mut Formatter<'_>) -> std::fmt::Result {
        for op in &self.operators {
            match op {
                Operator::Literal(c) => write!(f, "{c}")?,
                Operator::MatchOne(cs) => {
                    write!(f, "[")?;

                    for c in cs {
                        write!(f, "{c}")?;
                    }

                    write!(f, "]")?;
                }
                Operator::MatchNone(cs) => {
                    write!(f, "[^")?;

                    for c in cs {
                        write!(f, "{c}")?;
                    }

                    write!(f, "]")?;
                }
                Operator::Any => write!(f, ".")?,
            }
        }

        Ok(())
    }
}

#[derive(Debug, Clone, PartialEq, Eq, Serialize, Deserialize)]
enum Operator {
    Literal(char),
    MatchOne(Vec<char>),
    MatchNone(Vec<char>),
    Any,
}

impl Operator {
    fn matches(&self, a: char) -> bool {
        match self {
            Operator::Literal(b) => a == *b,
            Operator::MatchOne(b) => b.contains(&a),
            Operator::MatchNone(b) => !b.contains(&a),
            Operator::Any => true,
        }
    }
}

#[derive(Debug, Clone, Copy, thiserror::Error)]
pub enum Error {
    #[error("Unmatched bracket at index: {index}")]
    UnmatchedBracket { index: usize },
}

#[cfg(test)]
mod tests {
    use super::{Matcher, Operator};

    #[test]
    fn parses_simple() {
        let matcher = Matcher::parse("[^aeiou]a.s").unwrap();
        assert_eq!(
            matcher.operators,
            vec![
                Operator::MatchNone(vec!['a', 'e', 'i', 'o', 'u']),
                Operator::Literal('a'),
                Operator::Any,
                Operator::Literal('s')
            ]
        )
    }

    #[test]
    fn matches_vowels() {
        let matcher = Matcher::parse("[aeiou]").unwrap();

        assert!(matcher.matches(&['a']));
        assert!(matcher.matches(&['e']));
        assert!(matcher.matches(&['i']));
        assert!(matcher.matches(&['o']));
        assert!(matcher.matches(&['u']));
    }

    #[test]
    fn round_trip() {
        let source = "[^aeiou]a.s";
        let matcher = Matcher::parse(source).unwrap();

        assert_eq!(matcher.to_string(), source);
    }
}



================================================
FILE: harper-core/src/spell/rune/mod.rs
================================================
mod affix_replacement;
mod attribute_list;
mod error;
mod expansion;
mod matcher;
pub mod word_list;

pub use attribute_list::AttributeList;
pub use error::Error;

pub use self::word_list::parse_word_list;

#[cfg(test)]
mod tests {
    use hashbrown::HashSet;
    use once_cell::sync::Lazy;
    use serde_json::json;

    use super::super::word_map::WordMap;
    use super::word_list::parse_word_list;
    use crate::CharStringExt;
    use crate::spell::rune::AttributeList;

    pub const TEST_WORD_LIST: &str = "4\nhello\ntry/B\nwork/AB\nblank/";

    pub const TEST_WORD_LIST_WITH_BLANK_LINES: &str = "4\n\nhello\n\ntry/B\nwork/AB\n\n\nblank/";

    pub const TEST_WORD_LIST_WITH_FULL_LINE_COMMENTS: &str =
        "4\n#\nhello\n#with\ntry/B\nwork/AB\n# some\n# comments aded\nblank/";

    pub const TEST_WORD_LIST_WITH_COMMENTS: &str = "4\nhello       # a word without attributes\ntry/B   \t  # a word with empty attributes\nwork/AB\t   #a word with one attribute\nblank/      #a word with two attributes";

    pub static TEST_AFFIX_JSON: Lazy<serde_json::Value> = Lazy::new(|| {
        json!({
            "affixes": {
                "A": {
                    "kind": "prefix",
                    "cross_product": true,
                    "replacements": [
                      {
                        "remove": "",
                        "add": "re",
                        "condition": "."
                      }
                    ],
                    "target": [],
                    "base_metadata": {}
                },
                "B": {
                    "kind": "suffix",
                    "cross_product": true,
                    "replacements": [
                      {
                        "remove": "",
                        "add": "ed",
                        "condition": "[^y]"
                      },
                      {
                        "remove": "y",
                        "add": "ied",
                        "condition": "y"
                      }
                    ],
                    "target": [
                        {
                            "metadata": {
                                "noun": {}
                            }
                        }
                    ],
                    "base_metadata": {}
                }
            },
            "properties": {}
        })
    });

    fn assert_expansion_results(test_word_list: &str, expected: Vec<&str>) {
        let words = parse_word_list(test_word_list).unwrap();
        let attributes = AttributeList::parse(&TEST_AFFIX_JSON.to_string()).unwrap();

        let mut expanded = WordMap::default();

        attributes.expand_annotated_words(words, &mut expanded);

        let expanded: HashSet<String> = expanded
            .into_iter()
            .map(|v| v.canonical_spelling.into_iter().collect())
            .collect();

        assert_eq!(expanded, expected.into_iter().map(|v| v.into()).collect());
    }

    #[test]
    fn correctly_expands_test_files() {
        assert_expansion_results(
            TEST_WORD_LIST,
            vec![
                "reworked", "rework", "tried", "try", "hello", "worked", "work", "blank",
            ],
        );
    }

    #[test]
    fn correctly_expands_test_files_with_blank_lines() {
        assert_expansion_results(
            TEST_WORD_LIST_WITH_BLANK_LINES,
            vec![
                "reworked", "rework", "tried", "try", "hello", "worked", "work", "blank",
            ],
        );
    }

    fn correctly_expands_test_files_with_full_line_comments() {
        assert_expansion_results(
            TEST_WORD_LIST_WITH_FULL_LINE_COMMENTS,
            vec![
                "reworked", "rework", "tried", "try", "hello", "worked", "work", "blank",
            ],
        );
    }

    #[test]
    fn correctly_expands_test_files_with_comments() {
        let words = parse_word_list(TEST_WORD_LIST_WITH_COMMENTS).unwrap();
        let attributes = AttributeList::parse(&TEST_AFFIX_JSON.to_string()).unwrap();

        let mut expanded = WordMap::default();

        attributes.expand_annotated_words(words, &mut expanded);
        let expanded: HashSet<String> = expanded
            .into_iter()
            .map(|v| v.canonical_spelling.to_string())
            .collect();

        assert_eq!(
            expanded,
            vec![
                "reworked", "rework", "tried", "try", "hello", "worked", "work", "blank"
            ]
            .into_iter()
            .map(|v| v.into())
            .collect()
        )
    }

    #[test]
    fn plural_giants() {
        let words = parse_word_list("1\ngiant/SM").unwrap();

        let attributes = AttributeList::parse(
            &json!({
                "affixes": {
                    "S": {
                        "kind": "suffix",
                        "cross_product": true,
                        "replacements": [
                          {
                            "remove": "y",
                            "add": "ies",
                            "condition": "[^aeiou]"
                          },
                          {
                            "remove": "",
                            "add": "s",
                            "condition": "[aeiou]y"
                          },
                          {
                            "remove": "",
                            "add": "s",
                            "condition": "[^sxzhy]"
                          }
                        ],
                        "target": [
                            {
                                "metadata": {
                                    "noun": {
                                        "is_plural": true
                                    }
                                }
                            }
                        ],
                        "base_metadata": {
                            "noun": {}
                        }
                    },
                    "M": {
                        "kind": "suffix",
                        "cross_product": true,
                        "replacements": [
                          {
                            "remove": "",
                            "add": "'s",
                            "condition": "."
                          }
                        ],
                        "target": [],
                        "base_metadata": {}
                    }
                },
                "properties": {}
            })
            .to_string(),
        )
        .unwrap();

        let mut expanded = WordMap::default();

        attributes.expand_annotated_words(words, &mut expanded);

        let giant_data = expanded.get_with_str("giant").unwrap();
        assert!(giant_data.metadata.is_noun());

        let giants_data = expanded.get_with_str("giants").unwrap();
        assert!(giants_data.metadata.is_plural_noun());
    }
}



================================================
FILE: harper-core/src/spell/rune/word_list.rs
================================================
use super::Error;
use crate::CharString;

#[derive(Debug, Clone)]
pub struct AnnotatedWord {
    pub letters: CharString,
    pub annotations: Vec<char>,
}

/// Parse a Rune word list
///
/// Returns [`None`] if the given string is invalid.
pub fn parse_word_list(source: &str) -> Result<Vec<AnnotatedWord>, Error> {
    let mut lines = source.lines();

    let approx_item_count = lines
        .next()
        .ok_or(Error::MalformedItemCount)?
        .parse()
        .map_err(|_| Error::MalformedItemCount)?;

    let mut words = Vec::with_capacity(approx_item_count);

    for line in lines {
        // Ignore blank lines and full line comments.
        if line.is_empty() || line.starts_with('#') {
            continue;
        }

        let entry: &str;
        if let Some((entry_part, _comment_part)) = line.split_once('#') {
            entry = entry_part.trim_end();
        } else {
            entry = line.trim_end();
        }

        let word: &str;
        let attr: Option<&str>;
        if let Some((word_part, attr_part)) = entry.split_once('/') {
            word = word_part;
            attr = Some(attr_part);
        } else {
            word = entry;
            attr = None;
        }

        words.push(AnnotatedWord {
            letters: word.chars().collect(),
            annotations: attr.unwrap_or_default().chars().collect(),
        })
    }

    Ok(words)
}

#[cfg(test)]
mod tests {
    use super::super::tests::TEST_WORD_LIST;
    use super::parse_word_list;

    #[test]
    fn can_parse_test_file() {
        let list = parse_word_list(TEST_WORD_LIST).unwrap();

        assert_eq!(list.last().unwrap().annotations.len(), 0);
        assert_eq!(list.len(), 4);
    }
}



================================================
FILE: harper-core/src/weir/ast.rs
================================================
use harper_brill::UPOS;
use is_macro::Is;
use itertools::Itertools;

use crate::expr::{Expr, Filter, FirstMatchOf, SequenceExpr, UnlessStep};
use crate::patterns::{AnyPattern, DerivedFrom, UPOSSet, WhitespacePattern, Word};
use crate::{CharString, Punctuation, Token};

#[derive(Debug, Clone, Eq, PartialEq)]
pub struct Ast {
    pub stmts: Vec<AstStmtNode>,
}

impl Ast {
    /// Construct a new abstract syntax tree from individual statements.
    pub fn new(stmts: Vec<AstStmtNode>) -> Self {
        Self { stmts }
    }

    /// Get the value of a variable from the last time it was set.
    pub fn get_variable_value(&self, var_name: &str) -> Option<&'_ AstVariable> {
        for stmt in self.stmts.iter().rev() {
            if let AstStmtNode::DeclareVariable { name, value } = stmt
                && name == var_name
            {
                return Some(value);
            }
        }
        None
    }

    /// Get the value of an expression from the last time it was set.
    pub fn get_expr(&self, expr_name: &str) -> Option<&'_ AstExprNode> {
        for stmt in self.stmts.iter().rev() {
            if let AstStmtNode::SetExpr { name, value } = stmt
                && name == expr_name
            {
                return Some(value);
            }
        }
        None
    }

    /// Iterate through all unique variable values, from the last time they were set.
    pub fn iter_variable_values(&self) -> impl Iterator<Item = (&str, &AstVariable)> {
        self.stmts
            .iter()
            .rev()
            .filter_map(|n| match n {
                AstStmtNode::DeclareVariable { name, value } => Some((name.as_str(), value)),
                _ => None,
            })
            .unique_by(|(n, _)| *n)
    }

    /// Iterate through all the tests in the tree, starting with the one first declared in the
    /// tree.
    pub fn iter_tests(&self) -> impl Iterator<Item = (&str, &str)> {
        self.stmts.iter().filter_map(|stmt| match stmt {
            AstStmtNode::Test { expect, to_be } => Some((expect.as_str(), to_be.as_str())),
            AstStmtNode::Allows { value } => Some((value.as_str(), value.as_str())),
            _ => None,
        })
    }
}

/// A node that represents an expression that can be used to search through natural language.
#[derive(Debug, Clone, Is, Eq, PartialEq)]
pub enum AstExprNode {
    Whitespace,
    /// A progressive verb.
    Progressive,
    UPOSSet(Vec<UPOS>),
    Word(CharString),
    DerivativeOf(CharString),
    Punctuation(Punctuation),
    Not(Box<AstExprNode>),
    Seq(Vec<AstExprNode>),
    Arr(Vec<AstExprNode>),
    Filter(Vec<AstExprNode>),
    Anything,
}

impl AstExprNode {
    /// Create an actual expression that fulfills the pattern matching contract defined by this tree.
    pub fn to_expr(&self) -> Box<dyn Expr> {
        match self {
            AstExprNode::Anything => Box::new(AnyPattern),
            AstExprNode::Progressive => {
                Box::new(|tok: &Token, _: &[char]| tok.kind.is_verb_progressive_form())
            }
            AstExprNode::UPOSSet(upos) => Box::new(UPOSSet::new(upos)),
            AstExprNode::Whitespace => Box::new(WhitespacePattern),
            AstExprNode::Word(word) => Box::new(Word::from_chars(word)),
            AstExprNode::DerivativeOf(word) => Box::new(DerivedFrom::new_from_chars(word)),
            AstExprNode::Not(ast_node) => Box::new(UnlessStep::new(
                ast_node.to_expr(),
                |_tok: &Token, _: &[char]| true,
            )),
            AstExprNode::Seq(children) => {
                let mut expr = SequenceExpr::default();

                for node in children {
                    expr = expr.then_boxed(node.to_expr());
                }

                Box::new(expr)
            }
            AstExprNode::Arr(children) => {
                let mut expr = FirstMatchOf::default();

                for node in children {
                    expr.add_boxed(node.to_expr());
                }

                Box::new(expr)
            }
            AstExprNode::Filter(children) => {
                Box::new(Filter::new(children.iter().map(|n| n.to_expr()).collect()))
            }
            AstExprNode::Punctuation(punct) => {
                let punct = *punct;

                Box::new(move |tok: &Token, _: &[char]| {
                    tok.kind.as_punctuation().is_some_and(|p| *p == punct)
                })
            }
        }
    }
}

/// A variable defined by the `let` keyword.
#[derive(Debug, Clone, Is, Eq, PartialEq)]
pub enum AstVariable {
    String(String),
    Array(Vec<AstVariable>),
}

impl AstVariable {
    pub fn create_string(val: impl ToString) -> Self {
        Self::String(val.to_string())
    }
}

/// An AST node that represents a top-level statement.
#[derive(Debug, Clone, Is, Eq, PartialEq)]
pub enum AstStmtNode {
    DeclareVariable { name: String, value: AstVariable },
    SetExpr { name: String, value: AstExprNode },
    Comment(String),
    Test { expect: String, to_be: String },
    Allows { value: String },
}

impl AstStmtNode {
    pub fn create_declare_variable(name: impl ToString, value: AstVariable) -> Self {
        Self::DeclareVariable {
            name: name.to_string(),
            value,
        }
    }

    pub fn create_set_expr(name: impl ToString, value: AstExprNode) -> Self {
        Self::SetExpr {
            name: name.to_string(),
            value,
        }
    }

    pub fn create_test(expect: impl ToString, to_be: impl ToString) -> Self {
        Self::Test {
            expect: expect.to_string(),
            to_be: to_be.to_string(),
        }
    }

    pub fn create_allow_test(value: impl ToString) -> Self {
        Self::Allows {
            value: value.to_string(),
        }
    }
}



================================================
FILE: harper-core/src/weir/error.rs
================================================
use thiserror::Error;

#[derive(Debug, Error, Eq, PartialEq)]
pub enum Error {
    #[error("Encountered a token that is unsupported by the parser.")]
    UnsupportedToken(String),
    #[error("Reached the end of the input token stream prematurely.")]
    EndOfInput,
    #[error("Unmatched brace")]
    UnmatchedBrace,
    #[error("Expected a comma here.")]
    ExpectedComma,
    #[error("Expected a valid keyword.")]
    UnexpectedToken(String),
    #[error("Expected a value to be defined.")]
    ExpectedVariableUndefined,
    #[error("Invalid LintKind")]
    InvalidLintKind,
    #[error("Invalid Replacement Strategy")]
    InvalidReplacementStrategy,
    #[error("Expected a variable type other than the one provided.")]
    ExpectedDifferentVariableType,
}



================================================
FILE: harper-core/src/weir/mod.rs
================================================
//! Weir is a programming language for finding errors in natural language.
//! See our [main documentation](https://writewithharper.com/docs/weir) for more details.

mod ast;
mod error;
mod optimize;
mod parsing;

use std::str::FromStr;
use std::sync::Arc;

pub use error::Error;
use is_macro::Is;
use parsing::{parse_expr_str, parse_str};
use strum_macros::{AsRefStr, EnumString};

use crate::expr::Expr;
use crate::linting::{Chunk, ExprLinter, Lint, LintKind, Linter, Suggestion};
use crate::parsers::Markdown;
use crate::spell::FstDictionary;
use crate::{Document, Token, TokenStringExt};

use self::ast::{Ast, AstVariable};

pub(crate) fn weir_expr_to_expr(weir_code: &str) -> Result<Box<dyn Expr>, Error> {
    let ast = parse_expr_str(weir_code, true)?;
    Ok(ast.to_expr())
}

#[derive(Debug, Is, EnumString, AsRefStr)]
enum ReplacementStrategy {
    MatchCase,
    Exact,
}

#[derive(Debug, Clone, PartialEq, Eq)]
pub struct TestResult {
    expected: String,
    got: String,
}

pub struct WeirLinter {
    expr: Box<dyn Expr>,
    description: String,
    message: String,
    strategy: ReplacementStrategy,
    replacements: Vec<String>,
    lint_kind: LintKind,
    ast: Arc<Ast>,
}

impl WeirLinter {
    pub fn new(weir_code: &str) -> Result<WeirLinter, Error> {
        let ast = parse_str(weir_code, true)?;

        let main_expr_name = "main";
        let description_name = "description";
        let message_name = "message";
        let lint_kind_name = "kind";
        let replacement_name = "becomes";
        let replacement_strat_name = "strategy";

        let expr = ast
            .get_expr(main_expr_name)
            .ok_or(Error::ExpectedVariableUndefined)?
            .to_expr();

        let description = ast
            .get_variable_value(description_name)
            .ok_or(Error::ExpectedVariableUndefined)?
            .as_string()
            .ok_or(Error::ExpectedDifferentVariableType)?
            .to_owned();

        let message = ast
            .get_variable_value(message_name)
            .ok_or(Error::ExpectedVariableUndefined)?
            .as_string()
            .ok_or(Error::ExpectedDifferentVariableType)?
            .to_owned();

        let replacement_val = ast
            .get_variable_value(replacement_name)
            .ok_or(Error::ExpectedVariableUndefined)?;

        let replacements = match replacement_val {
            AstVariable::String(s) => vec![s.to_owned()],
            AstVariable::Array(arr) => {
                let mut out = Vec::with_capacity(arr.len());
                for item in arr.iter().map(|v| {
                    v.as_string()
                        .cloned()
                        .ok_or(Error::ExpectedDifferentVariableType)
                }) {
                    let item = item?;
                    out.push(item);
                }
                out
            }
        };

        let replacement_strat_var = ast.get_variable_value(replacement_strat_name);
        let replacement_strat = if let Some(replacement_strat) = replacement_strat_var {
            let str = replacement_strat
                .as_string()
                .ok_or(Error::ExpectedDifferentVariableType)?;
            ReplacementStrategy::from_str(str)
                .ok()
                .ok_or(Error::InvalidReplacementStrategy)?
        } else {
            ReplacementStrategy::MatchCase
        };

        let lint_kind_var = ast.get_variable_value(lint_kind_name);
        let lint_kind = if let Some(lint_kind) = lint_kind_var {
            let str = lint_kind
                .as_string()
                .ok_or(Error::ExpectedDifferentVariableType)?;
            LintKind::from_string_key(str).ok_or(Error::InvalidLintKind)?
        } else {
            LintKind::Miscellaneous
        };

        let linter = WeirLinter {
            strategy: replacement_strat,
            ast,
            expr,
            lint_kind,
            description,
            message,
            replacements,
        };

        Ok(linter)
    }

    /// Counts the total number of tests defined.
    pub fn count_tests(&self) -> usize {
        self.ast.iter_tests().count()
    }

    /// Runs the tests defined in the source code, returning any failing results.
    pub fn run_tests(&mut self) -> Vec<TestResult> {
        fn transform_nth_str(text: &str, linter: &mut impl Linter, n: usize) -> String {
            let mut text_chars: Vec<char> = text.chars().collect();
            let mut iter_count = 0;

            loop {
                let test = Document::new_from_vec(
                    text_chars.clone().into(),
                    &Markdown::default(),
                    &FstDictionary::curated(),
                );
                let lints = linter.lint(&test);

                if let Some(lint) = lints.first() {
                    if let Some(suggestion) = lint.suggestions.get(n) {
                        suggestion.apply(lint.span, &mut text_chars);
                    } else {
                        break;
                    }
                } else {
                    break;
                }

                iter_count += 1;
                if iter_count == 100 {
                    break;
                }
            }

            text_chars.iter().collect()
        }

        fn lint_count(text: &str, linter: &mut impl Linter) -> usize {
            let document = Document::new_from_vec(
                text.chars().collect::<Vec<_>>().into(),
                &Markdown::default(),
                &FstDictionary::curated(),
            );

            linter.lint(&document).len()
        }

        let mut results = Vec::new();
        let tests: Vec<(String, String)> = self
            .ast
            .iter_tests()
            .map(|(text, expected)| (text.to_string(), expected.to_string()))
            .collect();

        for (text, expected) in tests {
            if text == expected && lint_count(&text, self) != 0 {
                results.push(TestResult {
                    expected: text.to_string(),
                    got: text.to_string(),
                });
                continue;
            }

            let zeroth = transform_nth_str(&text, self, 0);
            let first = transform_nth_str(&text, self, 1);
            let second = transform_nth_str(&text, self, 2);

            let matched = if zeroth == expected {
                Some(zeroth.clone())
            } else if first == expected {
                Some(first.clone())
            } else if second == expected {
                Some(second.clone())
            } else {
                None
            };

            match matched {
                Some(result) => {
                    let remaining_lints = lint_count(&result, self);

                    if remaining_lints != 0 {
                        results.push(TestResult {
                            expected: expected.to_string(),
                            got: result,
                        });
                    }
                }
                None => results.push(TestResult {
                    expected: expected.to_string(),
                    got: zeroth,
                }),
            }
        }

        results
    }
}

impl ExprLinter for WeirLinter {
    type Unit = Chunk;

    fn expr(&self) -> &dyn Expr {
        &self.expr
    }

    fn match_to_lint(&self, matched_tokens: &[Token], source: &[char]) -> Option<Lint> {
        let span = matched_tokens.span()?;
        let orig = span.get_content(source);

        let suggestions = match self.strategy {
            ReplacementStrategy::MatchCase => self
                .replacements
                .iter()
                .map(|s| Suggestion::replace_with_match_case(s.chars().collect(), orig))
                .collect(),
            ReplacementStrategy::Exact => self
                .replacements
                .iter()
                .map(|r| Suggestion::ReplaceWith(r.chars().collect()))
                .collect(),
        };

        Some(Lint {
            span,
            lint_kind: self.lint_kind,
            suggestions,
            message: self.message.to_owned(),
            priority: 31,
        })
    }

    fn description(&self) -> &str {
        &self.description
    }
}

#[cfg(test)]
pub mod tests {
    use quickcheck_macros::quickcheck;

    use crate::weir::Error;

    use super::{TestResult, WeirLinter};

    #[track_caller]
    pub fn assert_passes_all(linter: &mut WeirLinter) {
        assert_eq!(Vec::<TestResult>::new(), linter.run_tests());
    }

    #[test]
    fn simple_right_click_linter() {
        let source = r#"
            expr main <([right, middle, left] $click), ( )>
            let message "Hyphenate this mouse command"
            let description "Hyphenates right-click style mouse commands."
            let kind "Punctuation"
            let becomes "-"

            test "Right click the icon." "Right-click the icon."
            test "Please right click on the link." "Please right-click on the link."
            test "They right clicked the submit button." "They right-clicked the submit button."
            test "Right clicking the item highlights it." "Right-clicking the item highlights it."
            test "Right clicks are tracked in the log." "Right-clicks are tracked in the log."
            test "He RIGHT CLICKED the file." "He RIGHT-CLICKED the file."
            test "Left click the checkbox." "Left-click the checkbox."
            test "Middle click to open in a new tab." "Middle-click to open in a new tab."

            allows "This test contains the correct version of right-click and therefore shouldn't error."
            "#;

        let mut linter = WeirLinter::new(source).unwrap();
        assert_passes_all(&mut linter);
        assert_eq!(9, linter.count_tests());
    }

    #[test]
    fn g_suite() {
        let source = r#"
            expr main [(G [Suite, Suit]), (Google Apps for Work)]
            let message "Use the updated brand."
            let description "`G Suite` or `Google Apps for Work` is now called `Google Workspace`"
            let kind "Miscellaneous"
            let becomes "Google Workspace"
            let strategy "Exact"

            test "We migrated from G Suite last year." "We migrated from Google Workspace last year."
            test "This account is still labeled as Google Apps for Work." "This account is still labeled as Google Workspace."
            test "The pricing page mentions G Suit for legacy plans." "The pricing page mentions Google Workspace for legacy plans."
            test "New customers sign up for Google Workspace." "New customers sign up for Google Workspace."

            allows "This test contains the correct version of Google Workspace and therefore shouldn't error."
            "#;

        let mut linter = WeirLinter::new(source).unwrap();

        assert_passes_all(&mut linter);
        assert_eq!(5, linter.count_tests());
    }

    #[test]
    fn wildcard() {
        let source = r#"
            expr main <(NOUN * NOUN), (* NOUN), *>
            let message ""
            let description ""
            let kind "Miscellaneous"
            let becomes ""
            let strategy "Exact"

            test "I like trees and plants of all kinds" "I like trees  plants of all kinds"
            test "homework tempts teachers" "homework  teachers"
            "#;

        let mut linter = WeirLinter::new(source).unwrap();

        assert_passes_all(&mut linter);
        assert_eq!(2, linter.count_tests());
    }

    #[test]
    fn dashes() {
        let source = r#"
            expr main --
            let message ""
            let description ""
            let kind "Miscellaneous"
            let becomes "-"
            let strategy "Exact"

            test "This--and--that" "This-and-that"

            allows "this-and-that"
            "#;

        let mut linter = WeirLinter::new(source).unwrap();

        assert_passes_all(&mut linter);
        assert_eq!(2, linter.count_tests());
    }

    #[test]
    fn fails_on_ignore_test() {
        let source = r#"
            expr main test
            let message ""
            let description ""
            let kind "Miscellaneous"
            let becomes "-"
            let strategy "Exact"

            allows "test"
            "#;

        let mut linter = WeirLinter::new(source).unwrap();

        assert_eq!(linter.run_tests().len(), 1)
    }

    #[test]
    fn errors_properly_with_missing_expr() {
        let source = "expr main";
        let res = WeirLinter::new(source);
        assert_eq!(res.err(), Some(Error::ExpectedVariableUndefined))
    }

    #[quickcheck]
    fn does_not_panic(s: String) {
        let _ = WeirLinter::new(s.as_str());
    }
}



================================================
FILE: harper-core/src/weir/optimize.rs
================================================
use super::ast::{AstExprNode, AstStmtNode};

/// Optimizes the AST to use fewer nodes.
/// Returns whether an edit was made.
pub fn optimize(stmts: &mut Vec<AstStmtNode>) -> bool {
    let mut edit = false;

    for stmt in stmts {
        if let AstStmtNode::SetExpr { value, .. } = stmt
            && optimize_expr(value)
        {
            edit = true;
        }
    }

    edit
}

/// Optimizes the AST of the expression to use fewer nodes.
/// Returns whether an edit was made.
pub fn optimize_expr(ast: &mut AstExprNode) -> bool {
    let mut edit = false;
    match ast {
        AstExprNode::Not(child) => return optimize_expr(child),
        AstExprNode::Seq(children) => {
            if children.len() == 1 {
                *ast = children.pop().unwrap();
                edit = true;
            } else {
                children.iter_mut().for_each(|child| {
                    if optimize_expr(child) {
                        edit = true;
                    }
                });
            }
        }
        AstExprNode::Arr(children) => {
            if children.len() == 1 {
                *ast = children.pop().unwrap();
                edit = true;
            } else if !children.is_empty() && children.iter().all(|n| n.is_upos_set()) {
                *ast = AstExprNode::UPOSSet(
                    children
                        .iter_mut()
                        .flat_map(|n| n.as_upos_set().unwrap())
                        .copied()
                        .collect(),
                )
            } else {
                children.iter_mut().for_each(|child| {
                    if optimize_expr(child) {
                        edit = true;
                    }
                });
            }
        }
        _ => (),
    }

    edit
}



================================================
FILE: harper-core/src/weir/parsing/expr.rs
================================================
use std::str::FromStr;

use harper_brill::UPOS;

use crate::{CharString, Currency, Punctuation, Token, TokenKind};

use super::{
    AstExprNode, Error, FoundNode, lex, locate_matching_brace, optimize_expr, parse_collection,
};

/// Parse a raw expression string.
pub fn parse_expr_str(weir_code: &str, use_optimizer: bool) -> Result<AstExprNode, Error> {
    let chars: CharString = weir_code.chars().collect();
    let tokens = lex(&chars);

    let seq = parse_seq(&tokens, &chars)?;
    let mut root = AstExprNode::Seq(seq);

    if use_optimizer {
        while optimize_expr(&mut root) {}
    }

    Ok(root)
}

/// Parse a sequence of expressions, one after the other.
pub fn parse_seq(tokens: &[Token], source: &[char]) -> Result<Vec<AstExprNode>, Error> {
    let mut seq = Vec::new();

    let mut cursor = 0;
    while let Some(remainder) = tokens.get(cursor..)
        && !remainder.is_empty()
    {
        let res = parse_single_expr(remainder, source)?;
        seq.push(res.node);
        cursor += res.next_idx;
    }

    Ok(seq)
}

/// Parse an individual expression.
fn parse_single_expr(tokens: &[Token], source: &[char]) -> Result<FoundNode<AstExprNode>, Error> {
    let cursor = 0;

    let tok = tokens.get(cursor).ok_or(Error::EndOfInput)?;

    match tok.kind {
        TokenKind::Space(_) => Ok(FoundNode::new(AstExprNode::Whitespace, 1)),
        // The derivation notation.
        TokenKind::Punctuation(Punctuation::Currency(Currency::Dollar)) => {
            let word_tok = tokens.get(1).ok_or(Error::EndOfInput)?;

            let word = word_tok.span.get_content(source);
            Ok(FoundNode::new(AstExprNode::DerivativeOf(word.into()), 2))
        }
        TokenKind::Punctuation(Punctuation::Star) => {
            Ok(FoundNode::new(AstExprNode::Anything, 1))
        }
        TokenKind::Word(_) => {
            let text = tok.span.get_content_string(source);

            if let Ok(upos) = UPOS::from_str(&text){
                Ok(FoundNode::new(
                    AstExprNode::UPOSSet(vec![upos]),
                1,
                ))
            }else{
                let node = match text.as_str() {
                    "PROG" => AstExprNode::Progressive,
                    _ => AstExprNode::Word(text.chars().collect()),
                };

                Ok(FoundNode::new(
                        node,
                1,
                ))
            }
        }
        ,
        // The sequence notation. Useful for representing strings.
        TokenKind::Punctuation(Punctuation::OpenRound) => {
            let close_idx =
                locate_matching_brace(tokens, TokenKind::is_open_round, TokenKind::is_close_round)
                    .ok_or(Error::UnmatchedBrace)?;
            let child = parse_seq(&tokens[1..close_idx], source)?;
            Ok(FoundNode::new(AstExprNode::Seq(child), close_idx + 1))
        }
        // The _not_ or _unless_ notation
        TokenKind::Punctuation(Punctuation::Bang) => {
            let res = parse_single_expr(&tokens[1..], source)?;

            Ok(FoundNode::new(
                AstExprNode::Not(Box::new(res.node)),
                res.next_idx + 1,
            ))
        }
        // The array notation
        TokenKind::Punctuation(Punctuation::OpenSquare) => {
            let close_idx = locate_matching_brace(
                tokens,
                TokenKind::is_open_square,
                TokenKind::is_close_square,
            )
            .ok_or(Error::UnmatchedBrace)?;

            let children = parse_collection(&tokens[1..close_idx], source, parse_single_expr)?;

            Ok(FoundNode::new(AstExprNode::Arr(children), close_idx + 1))
        }
        // The filter notation
        TokenKind::Punctuation(Punctuation::LessThan) => {
            let close_idx =
                locate_matching_brace(tokens, TokenKind::is_less_than, TokenKind::is_greater_than)
                    .ok_or(Error::UnmatchedBrace)?;

            let children = parse_collection(&tokens[1..close_idx], source, parse_single_expr)?;

            Ok(FoundNode::new(AstExprNode::Filter(children), close_idx + 1))
        }

        TokenKind::Punctuation(p) => Ok(FoundNode::new(AstExprNode::Punctuation(p), 1)),
        _ => Err(Error::UnsupportedToken(tok.span.get_content_string(source))),
    }
}

#[cfg(test)]
mod tests {
    use harper_brill::UPOS;

    use crate::Punctuation;
    use crate::char_string::char_string;

    use super::{AstExprNode, parse_expr_str};

    #[test]
    fn parses_whitespace() {
        assert_eq!(parse_expr_str(" ", true).unwrap(), AstExprNode::Whitespace)
    }

    #[test]
    fn parses_word() {
        assert_eq!(
            parse_expr_str("word", true).unwrap(),
            AstExprNode::Word(char_string!("word"))
        )
    }

    #[test]
    fn parses_word_space() {
        assert_eq!(
            parse_expr_str("word ", true).unwrap(),
            AstExprNode::Seq(vec![
                AstExprNode::Word(char_string!("word")),
                AstExprNode::Whitespace
            ])
        )
    }

    #[test]
    fn parses_word_space_word() {
        assert_eq!(
            parse_expr_str("word word", true).unwrap(),
            AstExprNode::Seq(vec![
                AstExprNode::Word(char_string!("word")),
                AstExprNode::Whitespace,
                AstExprNode::Word(char_string!("word")),
            ])
        )
    }

    #[test]
    fn parses_simple_seq() {
        assert_eq!(
            parse_expr_str("a (b c) d", false).unwrap(),
            AstExprNode::Seq(vec![
                AstExprNode::Word(char_string!("a")),
                AstExprNode::Whitespace,
                AstExprNode::Seq(vec![
                    AstExprNode::Word(char_string!("b")),
                    AstExprNode::Whitespace,
                    AstExprNode::Word(char_string!("c")),
                ]),
                AstExprNode::Whitespace,
                AstExprNode::Word(char_string!("d")),
            ])
        )
    }

    #[test]
    fn parses_nested_seqs() {
        assert_eq!(
            parse_expr_str("a (b (c)) d", false).unwrap(),
            AstExprNode::Seq(vec![
                AstExprNode::Word(char_string!("a")),
                AstExprNode::Whitespace,
                AstExprNode::Seq(vec![
                    AstExprNode::Word(char_string!("b")),
                    AstExprNode::Whitespace,
                    AstExprNode::Seq(vec![AstExprNode::Word(char_string!("c")),]),
                ]),
                AstExprNode::Whitespace,
                AstExprNode::Word(char_string!("d")),
            ])
        )
    }

    #[test]
    fn parses_paired_seqs() {
        assert_eq!(
            parse_expr_str("a (b) (c) d", false).unwrap(),
            AstExprNode::Seq(vec![
                AstExprNode::Word(char_string!("a")),
                AstExprNode::Whitespace,
                AstExprNode::Seq(vec![AstExprNode::Word(char_string!("b")),]),
                AstExprNode::Whitespace,
                AstExprNode::Seq(vec![AstExprNode::Word(char_string!("c")),]),
                AstExprNode::Whitespace,
                AstExprNode::Word(char_string!("d")),
            ])
        )
    }

    #[test]
    fn parses_not() {
        assert_eq!(
            parse_expr_str("a !b c", false).unwrap(),
            AstExprNode::Seq(vec![
                AstExprNode::Word(char_string!("a")),
                AstExprNode::Whitespace,
                AstExprNode::Not(Box::new(AstExprNode::Word(char_string!("b")))),
                AstExprNode::Whitespace,
                AstExprNode::Word(char_string!("c")),
            ])
        )
    }

    #[test]
    fn parses_not_seq() {
        assert_eq!(
            parse_expr_str("a !(b c) d", false).unwrap(),
            AstExprNode::Seq(vec![
                AstExprNode::Word(char_string!("a")),
                AstExprNode::Whitespace,
                AstExprNode::Not(Box::new(AstExprNode::Seq(vec![
                    AstExprNode::Word(char_string!("b")),
                    AstExprNode::Whitespace,
                    AstExprNode::Word(char_string!("c")),
                ]),)),
                AstExprNode::Whitespace,
                AstExprNode::Word(char_string!("d")),
            ])
        )
    }

    #[test]
    fn parses_empty_array() {
        assert_eq!(
            parse_expr_str("[]", true).unwrap(),
            AstExprNode::Arr(vec![])
        )
    }

    #[test]
    fn parses_single_element_array() {
        assert_eq!(
            parse_expr_str("[a]", false).unwrap(),
            AstExprNode::Seq(vec![AstExprNode::Arr(vec![AstExprNode::Word(
                char_string!("a")
            )])])
        )
    }

    #[test]
    fn optimizer_deconstructs_single_element_array() {
        assert_eq!(
            parse_expr_str("[a]", true).unwrap(),
            AstExprNode::Word(char_string!("a"))
        )
    }

    #[test]
    fn optimizer_deconstructs_single_element_seq() {
        assert_eq!(
            parse_expr_str("(a)", true).unwrap(),
            AstExprNode::Word(char_string!("a"))
        )
    }

    #[test]
    fn parses_double_element_array() {
        assert_eq!(
            parse_expr_str("[a, b]", true).unwrap(),
            AstExprNode::Arr(vec![
                AstExprNode::Word(char_string!("a")),
                AstExprNode::Word(char_string!("b"))
            ])
        )
    }

    #[test]
    fn parses_triple_element_array() {
        assert_eq!(
            parse_expr_str("[a, b, c]", true).unwrap(),
            AstExprNode::Arr(vec![
                AstExprNode::Word(char_string!("a")),
                AstExprNode::Word(char_string!("b")),
                AstExprNode::Word(char_string!("c"))
            ])
        )
    }

    #[test]
    fn parses_not_triple_element_array() {
        assert_eq!(
            parse_expr_str("![a, b, c]", true).unwrap(),
            AstExprNode::Not(Box::new(AstExprNode::Arr(vec![
                AstExprNode::Word(char_string!("a")),
                AstExprNode::Word(char_string!("b")),
                AstExprNode::Word(char_string!("c"))
            ])))
        )
    }

    #[test]
    fn parses_triple_dot() {
        assert_eq!(
            parse_expr_str("...", false).unwrap(),
            AstExprNode::Seq(vec![
                AstExprNode::Punctuation(Punctuation::Period),
                AstExprNode::Punctuation(Punctuation::Period),
                AstExprNode::Punctuation(Punctuation::Period),
            ])
        )
    }

    #[test]
    fn parses_space_comma() {
        assert_eq!(
            parse_expr_str("[( ), (,)]", true).unwrap(),
            AstExprNode::Arr(vec![
                AstExprNode::Whitespace,
                AstExprNode::Punctuation(Punctuation::Comma),
            ])
        )
    }

    #[test]
    fn parses_space_dash() {
        assert_eq!(
            parse_expr_str("[( ), (-)]", true).unwrap(),
            AstExprNode::Arr(vec![
                AstExprNode::Whitespace,
                AstExprNode::Punctuation(Punctuation::Hyphen),
            ])
        )
    }

    #[test]
    fn parses_filter() {
        assert_eq!(
            parse_expr_str("<a, b, c>", true).unwrap(),
            AstExprNode::Filter(vec![
                AstExprNode::Word(char_string!("a")),
                AstExprNode::Word(char_string!("b")),
                AstExprNode::Word(char_string!("c")),
            ])
        )
    }

    #[test]
    fn parses_filter_with_space_prefixing_element() {
        assert_eq!(
            parse_expr_str("< a, b, c>", true).unwrap(),
            AstExprNode::Filter(vec![
                AstExprNode::Word(char_string!("a")),
                AstExprNode::Word(char_string!("b")),
                AstExprNode::Word(char_string!("c")),
            ])
        )
    }

    #[test]
    fn parses_filter_with_space_postfixing_element() {
        assert_eq!(
            parse_expr_str("<a, b, c >", true).unwrap(),
            AstExprNode::Filter(vec![
                AstExprNode::Word(char_string!("a")),
                AstExprNode::Word(char_string!("b")),
                AstExprNode::Word(char_string!("c")),
            ])
        )
    }

    #[test]
    fn parses_derivative() {
        assert_eq!(
            parse_expr_str("$word", true).unwrap(),
            AstExprNode::DerivativeOf(char_string!("word"))
        )
    }

    #[test]
    fn parses_derivative_seq() {
        assert_eq!(
            parse_expr_str("$a $b $c", true).unwrap(),
            AstExprNode::Seq(vec![
                AstExprNode::DerivativeOf(char_string!("a")),
                AstExprNode::Whitespace,
                AstExprNode::DerivativeOf(char_string!("b")),
                AstExprNode::Whitespace,
                AstExprNode::DerivativeOf(char_string!("c")),
            ])
        )
    }

    #[test]
    fn parses_contraction() {
        assert_eq!(
            parse_expr_str("don't do this", true).unwrap(),
            AstExprNode::Seq(vec![
                AstExprNode::Word(char_string!("don't")),
                AstExprNode::Whitespace,
                AstExprNode::Word(char_string!("do")),
                AstExprNode::Whitespace,
                AstExprNode::Word(char_string!("this")),
            ])
        )
    }

    #[test]
    fn parses_upos() {
        assert_eq!(
            parse_expr_str("PROPN NOUN VERB", false).unwrap(),
            AstExprNode::Seq(vec![
                AstExprNode::UPOSSet(vec![UPOS::PROPN]),
                AstExprNode::Whitespace,
                AstExprNode::UPOSSet(vec![UPOS::NOUN]),
                AstExprNode::Whitespace,
                AstExprNode::UPOSSet(vec![UPOS::VERB]),
            ])
        )
    }

    #[test]
    fn optimizes_upos_set() {
        assert_eq!(
            parse_expr_str("[PROPN, NOUN, VERB]", true).unwrap(),
            AstExprNode::UPOSSet(vec![UPOS::PROPN, UPOS::NOUN, UPOS::VERB]),
        )
    }

    #[test]
    fn parses_prog() {
        assert_eq!(
            parse_expr_str("PROG", true).unwrap(),
            AstExprNode::Progressive
        )
    }

    #[test]
    fn parses_anything() {
        assert_eq!(parse_expr_str("*", true).unwrap(), AstExprNode::Anything)
    }

    #[test]
    fn parses_anything_seq() {
        assert_eq!(
            parse_expr_str("* * *", true).unwrap(),
            AstExprNode::Seq(vec![
                AstExprNode::Anything,
                AstExprNode::Whitespace,
                AstExprNode::Anything,
                AstExprNode::Whitespace,
                AstExprNode::Anything,
            ])
        )
    }
}



================================================
FILE: harper-core/src/weir/parsing/mod.rs
================================================
mod expr;
mod stmt;

use super::Error;
use ast::{Ast, AstExprNode, AstStmtNode};

pub use expr::parse_expr_str;
pub use stmt::parse_str;

use crate::lexing::{FoundToken, lex_weir_token};
use crate::{Span, Token, TokenKind};

use super::{
    ast,
    optimize::{optimize, optimize_expr},
};

/// Lex the entirety of a Weir document.
fn lex(source: &[char]) -> Vec<Token> {
    let mut cursor = 0;

    let mut tokens = Vec::new();

    loop {
        if cursor >= source.len() {
            return tokens;
        }

        if let Some(FoundToken { token, next_index }) = lex_weir_token(&source[cursor..]) {
            tokens.push(Token {
                span: Span::new(cursor, cursor + next_index),
                kind: token,
            });
            cursor += next_index;
        } else {
            panic!()
        }
    }
}

#[derive(Debug)]
struct FoundNode<T> {
    /// The parsed node found.
    node: T,
    /// The next token to be read.
    next_idx: usize,
}

impl<T> FoundNode<T> {
    pub fn new(node: T, next_idx: usize) -> Self {
        Self { node, next_idx }
    }
}

/// A utility for parsing a collection of items, separated by commas.
/// Requires a parser used for parsing individual elements.
fn parse_collection<T>(
    tokens: &[Token],
    source: &[char],
    el_parser: impl Fn(&[Token], &[char]) -> Result<FoundNode<T>, Error>,
) -> Result<Vec<T>, Error> {
    let mut children = Vec::new();

    let mut cursor = 0;

    while cursor < tokens.len() {
        while tokens[cursor].kind.is_space() {
            cursor += 1;
        }

        let new_child = el_parser(&tokens[cursor..], source)?;
        children.push(new_child.node);

        cursor += new_child.next_idx;

        while cursor != tokens.len() && tokens[cursor].kind.is_space() {
            cursor += 1;
        }

        if cursor != tokens.len() && !tokens[cursor].kind.is_comma() {
            return Err(Error::ExpectedComma);
        }

        cursor += 1;

        if cursor < tokens.len() && tokens[cursor].kind.is_space() {
            cursor += 1;
        }
    }

    Ok(children)
}

/// Locates the closing brace for the token at index zero.
fn locate_matching_brace(
    tokens: &[Token],
    is_open: impl Fn(&TokenKind) -> bool,
    is_close: impl Fn(&TokenKind) -> bool,
) -> Option<usize> {
    // Locate closing brace
    let mut visited_opens = 0;
    let mut cursor = 1;

    inc_by_spaces(&mut cursor, tokens);

    loop {
        let cur = tokens.get(cursor)?;

        if is_open(&cur.kind) {
            visited_opens += 1;
        } else if is_close(&cur.kind) {
            if visited_opens == 0 {
                return Some(cursor);
            } else {
                visited_opens -= 1;
            }
        }

        cursor += 1;
    }
}

/// Increments the cursor until it is no longer over a space.
fn inc_by_spaces(cursor: &mut usize, tokens: &[Token]) {
    // Skip whitespace at the beginning.
    while matches!(
        tokens.get(*cursor).map(|t| &t.kind),
        Some(&TokenKind::Space(..))
    ) {
        *cursor += 1;
    }
}

/// Increments the cursor until it is no longer over whitespace.
fn inc_by_whitespace(cursor: &mut usize, tokens: &[Token]) {
    // Skip whitespace at the beginning.
    while tokens
        .get(*cursor)
        .map(|t| &t.kind)
        .is_some_and(|t| t.is_whitespace())
    {
        *cursor += 1;
    }
}

/// Asserts that a space is expected in the location of the cursor.
/// Returns the proper arrow type that can be handled with the `?` syntax.
fn expected_space(cursor: usize, tokens: &[Token], source: &[char]) -> Result<(), Error> {
    let expected_space = &tokens[cursor];

    if !expected_space.kind.is_space() {
        return Err(Error::UnexpectedToken(
            expected_space.span.get_content_string(source),
        ));
    }

    Ok(())
}



================================================
FILE: harper-core/src/weir/parsing/stmt.rs
================================================
use std::num::NonZeroUsize;
use std::sync::{Arc, LazyLock, RwLock};

use lru::LruCache;

use super::ast::AstVariable;
use super::inc_by_spaces;
use crate::{CharStringExt, Punctuation, Token, TokenKind, TokenStringExt};

use super::expr::parse_seq;
use super::{
    Ast, AstExprNode, AstStmtNode, Error, FoundNode, expected_space, inc_by_whitespace, lex,
    locate_matching_brace, optimize, parse_collection,
};

/// Parse the provided string using caching to speed up repeated requests.
///
/// Will return the cached AST if the provided code has previously been cached. Otherwise, it will
/// parse the code and cache the resulting AST.
pub fn parse_str(weir_code: &str, use_optimizer: bool) -> Result<Arc<Ast>, Error> {
    // The parameters that might influence the generated AST.
    // This is used as the key for the cache hashmap.
    type ParseStrParams = (Arc<String>, bool);

    static PARSE_CACHE: LazyLock<
        RwLock<LruCache<ParseStrParams, Arc<Ast>, hashbrown::DefaultHashBuilder>>,
    > = LazyLock::new(|| RwLock::new(LruCache::new(NonZeroUsize::new(10000).unwrap())));

    let weir_code = Arc::new(weir_code.to_owned());

    Ok(
        if let Some(cached) = PARSE_CACHE
            .read()
            .unwrap()
            .peek(&(weir_code.clone(), use_optimizer))
        {
            cached.clone()
        } else {
            let chars: Vec<char> = weir_code.chars().collect();
            let tokens = lex(&chars);

            let mut stmts = parse_stmt_list(&tokens, &chars)?;

            if use_optimizer {
                while optimize(&mut stmts) {}
            }

            let ast = Arc::new(Ast { stmts });

            PARSE_CACHE
                .write()
                .unwrap()
                .put((weir_code, use_optimizer), ast.clone());

            ast
        },
    )
}

fn parse_stmt_list(tokens: &[Token], source: &[char]) -> Result<Vec<AstStmtNode>, Error> {
    let mut list = Vec::new();

    let mut cursor = 0;
    while let Some(remainder) = tokens.get(cursor..)
        && !remainder.is_empty()
    {
        let res = parse_stmt(remainder, source)?;
        if let Some(node) = res.node {
            list.push(node);
        }
        cursor += res.next_idx;
    }
    Ok(list)
}

fn parse_stmt(tokens: &[Token], source: &[char]) -> Result<FoundNode<Option<AstStmtNode>>, Error> {
    let mut cursor = 0;
    inc_by_whitespace(&mut cursor, tokens);

    let end = tokens
        .iter()
        .enumerate()
        .skip(cursor)
        .find_map(|(i, t)| t.kind.is_newline().then_some(i))
        .unwrap_or(tokens.len());

    let Some(key_token) = tokens.get(cursor) else {
        return Ok(FoundNode {
            node: None,
            next_idx: cursor + 1,
        });
    };

    match key_token.kind {
        TokenKind::Punctuation(Punctuation::Hash) => {
            let comment = tokens[cursor..end]
                .span()
                .unwrap()
                .get_content_string(source);
            Ok(FoundNode::new(Some(AstStmtNode::Comment(comment)), end + 1))
        }
        TokenKind::Word(_) => {
            let word_literal = key_token.span.get_content(source);

            match word_literal {
                ['l', 'e', 't'] => {
                    expected_space(cursor + 1, tokens, source)?;
                    let name = tokens[cursor + 2].span.get_content_string(source);
                    expected_space(cursor + 3, tokens, source)?;

                    let str_res = parse_quoted_string(&tokens[cursor + 4..end], source);

                    if let Ok(str_contents) = str_res {
                        if tokens[str_contents.next_idx + cursor + 4..end]
                            .iter()
                            .any(|t| !t.kind.is_space())
                        {
                            return Err(Error::UnexpectedToken(
                                tokens[str_contents.next_idx + cursor + 4]
                                    .span
                                    .get_content_string(source),
                            ));
                        }

                        Ok(FoundNode::new(
                            Some(AstStmtNode::create_declare_variable(
                                name,
                                AstVariable::String(str_contents.node),
                            )),
                            end + 1,
                        ))
                    } else {
                        let open_brac_tok = &tokens[cursor + 4];
                        if !open_brac_tok.kind.is_open_square() {
                            return Err(Error::UnexpectedToken(
                                open_brac_tok.span.get_content_string(source),
                            ));
                        }

                        let matching = locate_matching_brace(
                            &tokens[cursor + 4..end],
                            TokenKind::is_open_square,
                            TokenKind::is_close_square,
                        )
                        .ok_or(Error::UnmatchedBrace)?
                            + cursor
                            + 4;

                        let elements = parse_collection(
                            &tokens[cursor + 5..matching],
                            source,
                            parse_quoted_string,
                        )?;

                        Ok(FoundNode::new(
                            Some(AstStmtNode::create_declare_variable(
                                name,
                                AstVariable::Array(
                                    elements.into_iter().map(AstVariable::String).collect(),
                                ),
                            )),
                            end + 1,
                        ))
                    }
                }
                ['e', 'x', 'p', 'r'] => {
                    expected_space(cursor + 1, tokens, source)?;

                    Ok(FoundNode::new(
                        Some(AstStmtNode::create_set_expr(
                            tokens[cursor + 2].span.get_content_string(source),
                            AstExprNode::Seq(parse_seq(
                                &tokens[(cursor + 4).min(end)..end],
                                source,
                            )?),
                        )),
                        end + 1,
                    ))
                }
                ['a', 'l', 'l', 'o', 'w', 's'] => {
                    let case = parse_quoted_string(&tokens[cursor + 1..], source)?;
                    cursor += 1 + case.next_idx;

                    if cursor != end {
                        return Err(Error::UnexpectedToken(
                            tokens[cursor].span.get_content_string(source),
                        ));
                    }

                    Ok(FoundNode::new(
                        Some(AstStmtNode::create_allow_test(case.node)),
                        end + 1,
                    ))
                }
                ['t', 'e', 's', 't'] => {
                    let case = parse_quoted_string(&tokens[cursor + 1..], source)?;
                    cursor += 1 + case.next_idx;

                    expected_space(cursor, tokens, source)?;

                    let sol = parse_quoted_string(&tokens[cursor + 1..], source)?;
                    cursor += 1 + sol.next_idx;

                    if cursor != end {
                        return Err(Error::UnexpectedToken(
                            tokens[cursor].span.get_content_string(source),
                        ));
                    }

                    Ok(FoundNode::new(
                        Some(AstStmtNode::create_test(case.node, sol.node)),
                        end + 1,
                    ))
                }
                _ => Err(Error::UnexpectedToken(word_literal.to_string())),
            }
        }
        _ => Err(Error::UnsupportedToken(
            key_token.span.get_content_string(source),
        )),
    }
}

fn parse_quoted_string(tokens: &[Token], source: &[char]) -> Result<FoundNode<String>, Error> {
    fn is_escaped(pos: usize, source: &[char]) -> bool {
        if pos == 0 {
            return false;
        }
        let mut i = pos;
        let mut n = 0;
        while i > 0 && source[i - 1] == '\\' {
            n += 1;
            i -= 1;
        }
        n % 2 == 1
    }

    let mut cursor = 0;

    inc_by_spaces(&mut cursor, tokens);

    let quote_tok = tokens.get(cursor).ok_or(Error::EndOfInput)?;
    if !quote_tok.kind.is_quote() {
        return Err(Error::UnexpectedToken(
            quote_tok.span.get_content_string(source),
        ));
    }

    let mut end = None;
    for (i, tok) in tokens.iter().enumerate().skip(cursor + 1) {
        if tok.kind.is_quote() {
            let qpos = tok.span.start;
            if !is_escaped(qpos, source) {
                end = Some(i);
                break;
            }
        }
    }

    let end = end.ok_or(Error::EndOfInput)?;

    Ok(FoundNode {
        node: tokens[cursor + 1..end]
            .span()
            .unwrap_or_default()
            .get_content_string(source),
        next_idx: end + 1,
    })
}

#[cfg(test)]
mod tests {
    use quickcheck_macros::quickcheck;

    use crate::char_string::char_string;

    use super::{AstExprNode, AstStmtNode, AstVariable, parse_str};

    #[test]
    fn parses_single_var_stmt() {
        let ast = parse_str("let test \"to be this\"", true).unwrap();

        assert_eq!(
            ast.stmts,
            vec![AstStmtNode::create_declare_variable(
                "test",
                AstVariable::create_string("to be this")
            ),]
        );
        assert_eq!(
            ast.get_variable_value("test"),
            Some(&AstVariable::create_string("to be this"))
        );
    }

    #[test]
    fn parses_single_var_stmt_with_lots_of_space() {
        let ast = parse_str("let            test \"to be this\"", true).unwrap();

        assert_eq!(
            ast.stmts,
            vec![AstStmtNode::create_declare_variable(
                "test",
                AstVariable::create_string("to be this")
            ),]
        );
        assert_eq!(
            ast.get_variable_value("test"),
            Some(&AstVariable::create_string("to be this"))
        );
    }

    #[test]
    fn parses_single_var_stmt_array() {
        let ast = parse_str("let test [\"to be this\", \"and this\"]", true).unwrap();

        let correct_var_val = AstVariable::Array(vec![
            AstVariable::create_string("to be this"),
            AstVariable::create_string("and this"),
        ]);

        assert_eq!(ast.get_variable_value("test"), Some(&correct_var_val));
        assert_eq!(
            ast.stmts,
            vec![AstStmtNode::create_declare_variable(
                "test",
                correct_var_val
            ),]
        );
    }

    #[test]
    fn parses_single_expr_stmt() {
        assert_eq!(
            parse_str("expr main word", true).unwrap().stmts,
            vec![AstStmtNode::create_set_expr(
                "main",
                AstExprNode::Word(char_string!("word"))
            )]
        )
    }

    #[test]
    fn parses_single_comment_stmt() {
        assert_eq!(
            parse_str("# this is a comment", true).unwrap().stmts,
            vec![AstStmtNode::Comment("# this is a comment".to_string())]
        )
    }

    #[test]
    fn parses_single_comment_stmt_with_space_prefix() {
        assert_eq!(
            parse_str("    # this is a comment", true).unwrap().stmts,
            vec![AstStmtNode::Comment("# this is a comment".to_string())]
        )
    }

    #[test]
    fn parses_tests() {
        assert_eq!(
            parse_str("test \"this is the case\" \"this is the solution\"", true)
                .unwrap()
                .stmts,
            vec![AstStmtNode::create_test(
                "this is the case",
                "this is the solution"
            )]
        )
    }

    #[test]
    fn parses_multiple_spaces_in_tests() {
        assert_eq!(
            parse_str(
                "test \"this is the case\"           \"this is the solution\"",
                true
            )
            .unwrap()
            .stmts,
            vec![AstStmtNode::create_test(
                "this is the case",
                "this is the solution"
            )]
        )
    }

    #[test]
    fn parses_allows() {
        assert_eq!(
            parse_str("allows \"this is the case\"", true)
                .unwrap()
                .stmts,
            vec![AstStmtNode::create_allow_test("this is the case",)]
        )
    }

    #[test]
    fn parses_comment_expr_var_together() {
        let ast = parse_str(
            "let test \"to be this\"\nexpr main word\n# this is a comment",
            true,
        )
        .unwrap();

        assert_eq!(
            ast.stmts,
            vec![
                AstStmtNode::create_declare_variable(
                    "test",
                    AstVariable::create_string("to be this")
                ),
                AstStmtNode::create_set_expr("main", AstExprNode::Word(char_string!("word"))),
                AstStmtNode::Comment("# this is a comment".to_string())
            ]
        );

        assert_eq!(
            ast.get_variable_value("test"),
            Some(&AstVariable::create_string("to be this"))
        );
        assert_eq!(
            ast.get_expr("main"),
            Some(&AstExprNode::Word(char_string!("word")))
        );
    }

    #[test]
    fn parses_comment_in_middle() {
        let ast = parse_str(
            "let test \"to be this\"\n# this is a comment\nexpr main word",
            true,
        )
        .unwrap();

        assert_eq!(
            ast.stmts,
            vec![
                AstStmtNode::create_declare_variable(
                    "test",
                    AstVariable::create_string("to be this")
                ),
                AstStmtNode::Comment("# this is a comment".to_string()),
                AstStmtNode::create_set_expr("main", AstExprNode::Word(char_string!("word")))
            ]
        );

        assert_eq!(
            ast.get_variable_value("test"),
            Some(&AstVariable::create_string("to be this"))
        );
        assert_eq!(
            ast.get_expr("main"),
            Some(&AstExprNode::Word(char_string!("word")))
        );
    }

    #[test]
    #[should_panic]
    fn catches_non_whitespace_after_expr() {
        parse_str("expr+this is a test", false).unwrap();
    }

    #[test]
    #[should_panic]
    fn catches_non_whitespace_after_test() {
        parse_str("test+\"\" \"\"", false).unwrap();
    }

    #[test]
    #[should_panic]
    fn catches_non_whitespace_between_test() {
        parse_str("test \"\"+\"\"", false).unwrap();
    }

    #[test]
    #[should_panic]
    fn catches_non_whitespace_after_let() {
        parse_str("let+var \"\"", false).unwrap();
    }

    #[test]
    #[should_panic]
    fn catches_non_whitespace_after_let_var() {
        parse_str("let var+\"\"", false).unwrap();
    }

    #[test]
    #[should_panic]
    fn catches_non_whitespace_after_allows() {
        parse_str("allows+\"\"", false).unwrap();
    }

    #[quickcheck]
    fn catches_anything_after_test(a: String) {
        if !a.is_empty() && !a.starts_with('\n') {
            let code = format!("test \"\" \"\"{a}");
            assert!(parse_str(code.as_str(), false).is_err())
        }
    }

    #[quickcheck]
    fn catches_anything_after_allows(a: String) {
        if !a.is_empty() && !a.starts_with('\n') {
            let code = format!("allows \"\" {a}");
            assert!(parse_str(code.as_str(), false).is_err())
        }
    }
}



================================================
FILE: harper-core/tests/linters.rs
================================================
//! This test creates snapshots of the reports of all linters.
//!
//! # Usage
//!
//! To add a new snapshot, simply add the document to `tests/text` and run this
//! test. It will automatically create a new snapshot in `tests/text/linters`.
//! To update an existing snapshot, also just run this test.
//!
//! Note: This test will fail if the snapshot files are not up to date. This
//! ensures that CI will fail if linters change their behavior.

use harper_core::spell::FstDictionary;
use harper_core::{
    Dialect, Document,
    linting::{LintGroup, Linter},
};

mod snapshot;

struct LinePos {
    /// 0-based index of the line
    pub line: usize,
    /// 0-based index of the column
    pub col: usize,
}

struct Lines<'a> {
    lines: Vec<&'a str>,
    offsets: Vec<usize>,
}
impl Lines<'_> {
    fn new(source: &'_ str) -> Lines<'_> {
        let lines: Vec<&str> = source.split('\n').collect();
        let offsets: Vec<usize> = lines
            .iter()
            .scan(0, |offset, line| {
                let old_offset = *offset;
                *offset += line.chars().count() + 1;
                Some(old_offset)
            })
            .collect();

        Lines { lines, offsets }
    }

    fn len(&self) -> usize {
        self.lines.len()
    }

    fn get_pos(&self, offset: usize) -> LinePos {
        let line_index = self
            .offsets
            .binary_search(&offset)
            .unwrap_or_else(|x| x - 1);

        LinePos {
            line: line_index,
            col: offset - self.offsets[line_index],
        }
    }
}
impl<'a> std::ops::Index<usize> for Lines<'a> {
    type Output = &'a str;

    fn index(&self, index: usize) -> &Self::Output {
        &self.lines[index]
    }
}

fn print_error(lines: &Lines, start: usize, end: usize, message: &str) -> String {
    let mut out = String::new();

    fn print_line(out: &mut String, line: &str, number: usize) {
        out.push_str(&format!("{number:>6} | {line}\n"));
    }

    fn is_sentence_boundary(c: char) -> bool {
        matches!(c, '.' | '?' | '!' | ':' | ';')
    }
    fn print_pre_line_context(
        out: &mut String,
        context_line: &str,
        number: usize,
        line: &str,
        start_col: usize,
    ) {
        if context_line.is_empty() {
            return;
        }
        if start_col > 40 {
            // that's enough context
            return;
        }

        let last_char = context_line.chars().last().unwrap();
        let mut chars_before = line.chars().take(start_col);
        if !is_sentence_boundary(last_char) && !chars_before.any(is_sentence_boundary) {
            print_line(out, context_line, number);
        }
    }
    fn print_post_line_context(
        out: &mut String,
        context_line: &str,
        number: usize,
        line: &str,
        end_col: usize,
    ) {
        if context_line.is_empty() {
            return;
        }
        if end_col < 40 {
            // that's enough context
            return;
        }

        let mut chars_after = line.chars().skip(end_col);
        if !chars_after.any(is_sentence_boundary) {
            print_line(out, context_line, number);
        }
    }

    fn print_underline(
        out: &mut String,
        start_col: usize,
        end_col: usize,
        continuation: bool,
        message: &str,
    ) {
        out.push_str("       | ");
        for _ in 0..start_col {
            out.push(' ');
        }
        out.push(if continuation { '~' } else { '^' });
        for _ in 0..end_col.saturating_sub(start_col) {
            out.push('~');
        }

        if !message.is_empty() {
            out.push(' ');
            out.push_str(message);
        }
        out.push('\n');
    }

    let start = lines.get_pos(start);
    let end = lines.get_pos(end - 1);

    if start.line > 0 {
        print_pre_line_context(
            &mut out,
            lines[start.line - 1],
            start.line,
            lines[start.line],
            start.col,
        );
    }

    if start.line == end.line {
        print_line(&mut out, lines[start.line], start.line + 1);
        print_underline(&mut out, start.col, end.col, false, message);
    } else {
        for i in start.line..end.line {
            let line = lines[i];
            print_line(&mut out, line, i + 1);
            print_underline(
                &mut out,
                if i == start.line { start.col } else { 0 },
                line.chars().count(),
                i != start.line,
                "",
            );
        }

        print_line(&mut out, lines[end.line], end.line + 1);
        print_underline(&mut out, 0, end.col, true, message);
    }

    if end.line + 1 < lines.len() {
        print_post_line_context(
            &mut out,
            lines[end.line + 1],
            end.line + 2,
            lines[end.line],
            end.col,
        );
    }

    out
}

#[test]
fn test_most_lints() {
    snapshot::snapshot_all_text_files("linters", ".snap.yml", |source, dialect_override| {
        let dict = FstDictionary::curated();
        let document = Document::new_markdown_default(source, &dict);

        let mut linter = LintGroup::new_curated(
            dict,
            dialect_override.unwrap_or_else(|| {
                Dialect::try_guess_from_document(&document).unwrap_or(Dialect::American)
            }),
        );

        let mut lints = linter.lint(&document);
        lints.sort_by(|a, b| {
            a.span
                .start
                .cmp(&b.span.start)
                .then(a.span.end.cmp(&b.span.end))
        });

        // split the input document into lines
        let lines = Lines::new(source);

        let mut out = String::new();

        for lint in lints {
            out.push_str(&format!(
                "Lint:    {:?} ({} priority)\n",
                lint.lint_kind, lint.priority
            ));

            let message = print_error(&lines, lint.span.start, lint.span.end, &lint.message);
            out.push_str("Message: |\n");
            for l in message.lines() {
                out.push_str("  ");
                out.push_str(l);
                out.push('\n');
            }

            if !lint.suggestions.is_empty() {
                out.push_str("Suggest:\n");
                for suggestion in &lint.suggestions {
                    out.push_str(&format!("  - {suggestion}\n"));
                }
            }

            out.push_str("\n\n\n");
        }

        out
    });
}



================================================
FILE: harper-core/tests/pos_tags.rs
================================================
//! This test creates snapshots of the part-of-speech (POS) tags assigned by the
//! [`Document`] struct to the text files in the `tests/text` directory.
//!
//! # Usage
//!
//! To add a new snapshot, simply add the document to `tests/text` and run this
//! test. It will automatically create a new snapshot in `tests/text/tagged`.
//! To update an existing snapshot, also just run this test.
//!
//! Note: This test will fail if the snapshot files are not up to date. This
//! ensures that CI will fail if the POS tagger changes its behavior.
//!
//! # Snapshot format
//!
//! The snapshot files contain 2 lines for every line in the original text. The
//! first line contains the original text, and the second line contains the POS
//! tags. The text and tags are aligned so that the tags are directly below the
//! corresponding words in the text. Example:
//!
//! ```md
//! > I   told her   how   I   had stopped off       in          Chicago for a   day   on  my way East    .
//! # ISg V    I/J/D NSg/C ISg V   V/J     NSg/V/J/P NPrSg/V/J/P NPr     C/P D/P NPrSg J/P D  J   NPrSg/J .
//! ```
//!
//! ## Tags
//!
//! Tags are assigned based on the [`TokenKind`] and [`DictWordMetadata`] of a
//! token.
//!
//! - The tag of [`TokenKind::Word`] variants depends on their
//!   [`DictWordMetadata`]. If they don't have any metadata, they are denoted by `?`.
//!   Otherwise, the tag is constructed as follows:
//!
//!   - Nouns are denoted by `N`.
//!     - The `Pl` suffix means plural, and `Sg` means singular.
//!     - The `Pr` suffix means proper noun.
//!     - The `$` suffix means possessive.
//!     - Superscript `ᴹ` means mass (uncountable) noun.
//!     - Superscript `🅪` means mass + countable noun.
//!   - Pronouns are denoted by `I`.
//!     - The `Pl` suffix means plural, and `Sg` means singular.
//!     - The `$` suffix means possessive.
//!   - Verbs are denoted by `V`.
//!     - The `L` suffix means linking verb.
//!     - The `X` suffix means auxiliary verb.
//!     - The `B` suffix means base (lemma) form.
//!     - The `P` suffix means simple past tense & past participle.
//!     - The `Pr` suffix means progressive form.
//!     - The `Pt` suffix means simple past tense.
//!     - The `Pp` suffix means past participle.
//!     - The `3` suffix means third person singular present form.
//!   - Adjectives are denoted by `J`.
//!     - The `C` suffix means comparative.
//!     - The `S` suffix means superlative.
//!   - Adverbs are denoted by `R`.
//!   - Conjunctions are denoted by `C`.
//!   - Determiners are denoted by `D`.
//!     - The `dem` suffix means demonstrative.
//!     - The `q` suffix means quantifier.
//!   - Prepositions are denoted by `P`.
//!   - Dialects are denoted by `Am`, `Br`, `Ca`, or `Au` for individual
//!     dialects, or `NoAm` for North America (US and Canada)
//!     or `Comm` for Commonwealth (UK, Australia, and Canada).
//!   - Swear words are denoted by `B` (for bad).
//!   - Noun phrase membership is denoted by `+`
//!   - For words not in the dictionary or without annotations,
//!     they are denoted by `K` for "contraction" if they contain an apostrophe,
//!     or `W?` otherwise.
//!
//!   The tagger supports uncertainty, so a single word can be e.g. both a
//!   noun and a verb. This is denoted by a `/` between the tags.
//!   For example, `N/V/J` means the word is a noun, verb, and/or adjective.
//!
//! - [`TokenKind::Punctuation`] are denoted by `.`.
//! - [`TokenKind::Number`] are denoted by `#`.
//! - [`TokenKind::Decade`] are denoted by `#d`.
//! - Roman numerals are denoted by `#r`.
//! - [`TokenKind::Space`], [`TokenKind::Newline`], and
//!   [`TokenKind::ParagraphBreak`] are ignored.
//! - All other token kinds are denoted by their variant name.
use std::borrow::Cow;

use harper_core::spell::FstDictionary;
use harper_core::{
    Degree, Dialect, DictWordMetadata, Document, OrthFlags, TokenKind, VerbFormFlags,
};

mod snapshot;

fn format_word_tag(word: &DictWordMetadata) -> String {
    // These tags are inspired by the Penn Treebank POS tagset
    let mut tags = String::new();
    fn add(t: &str, tags: &mut String) {
        if !tags.is_empty() {
            tags.push('/');
        }
        tags.push_str(t);
    }

    fn add_bool(tag: &mut String, name: &str, value: Option<bool>) {
        if let Some(value) = value {
            if !value {
                tag.push('!');
            }
            tag.push_str(name);
        }
    }
    fn add_switch(tag: &mut String, value: Option<bool>, yes: &str, no: &str) {
        if let Some(value) = value {
            if value {
                tag.push_str(yes);
            } else {
                tag.push_str(no);
            }
        }
    }

    if let Some(noun) = word.noun {
        let mut tag = String::from("N");
        add_bool(&mut tag, "Pr", noun.is_proper);
        if word.is_mass_noun() {
            add_switch(&mut tag, Some(word.is_countable_noun()), "🅪", "ᴹ");
        }
        if word.is_countable_noun() {
            // Countable nouns are optionally marked in the dictionary. Countable is default if neither it nor mass is marked.
            // Common nouns are not marked in the dictionary, but being a mass noun implies being a common noun.
            // We don't want to clutter the output with `Sg` for mass nouns unless they are also countable.
            // We don't want to clutter the output with `Sg` for proper nouns unless they are also common.
            // "wood"/"Wood" is a countable and mass common noun and also a proper noun.
            if word.is_singular_noun() && (!word.is_proper_noun() || word.is_mass_noun()) {
                tag.push_str("Sg");
            }
            if word.is_plural_noun() {
                tag.push_str("Pl");
            }
        }
        add_bool(&mut tag, "$", noun.is_possessive);
        add(&tag, &mut tags);
    }
    if let Some(pronoun) = word.pronoun {
        let mut tag = String::from("I");
        add_bool(
            &mut tag,
            "Sg",
            pronoun.is_singular.and_then(|sg| sg.then_some(true)),
        );
        add_bool(
            &mut tag,
            "Pl",
            pronoun.is_plural.and_then(|pl| pl.then_some(true)),
        );
        add_bool(&mut tag, "$", pronoun.is_possessive);
        add(&tag, &mut tags);
    }
    if let Some(verb) = word.verb {
        let mut tag = String::from("V");
        add_bool(&mut tag, "L", verb.is_linking);
        add_bool(&mut tag, "X", verb.is_auxiliary);
        if let Some(forms) = verb.verb_forms {
            // If Lemma flag is explicitly set; or if no verb forms are set Lemma is the default.
            match (
                forms.contains(VerbFormFlags::LEMMA),
                forms.contains(VerbFormFlags::PAST),
                forms.contains(VerbFormFlags::PAST_PARTICIPLE),
                forms.contains(VerbFormFlags::PRETERITE),
                forms.contains(VerbFormFlags::PROGRESSIVE),
                forms.contains(VerbFormFlags::THIRD_PERSON_SINGULAR),
            ) {
                (true, _, _, _, _, _) | (false, false, false, false, false, false) => {
                    tag.push_str("B")
                }
                _ => {}
            }
            // Regular verbs set both together; Irregular verbs can set them separately.
            match (
                forms.contains(VerbFormFlags::PAST),
                forms.contains(VerbFormFlags::PRETERITE),
                forms.contains(VerbFormFlags::PAST_PARTICIPLE),
            ) {
                (true, _, _) | (_, true, true) => tag.push_str("P"),
                (false, true, false) => tag.push_str("Pt"),
                (false, false, true) => tag.push_str("Pp"),
                _ => {}
            }
            if forms.contains(VerbFormFlags::PROGRESSIVE) {
                tag.push_str("g");
            }
            if forms.contains(VerbFormFlags::THIRD_PERSON_SINGULAR) {
                tag.push_str("3");
            }
        } else {
            tag.push_str("B");
        }
        add(&tag, &mut tags);
    }
    if let Some(adjective) = word.adjective {
        let mut tag = String::from("J");
        if let Some(degree) = adjective.degree {
            tag.push_str(match degree {
                Degree::Comparative => "C",
                Degree::Superlative => "S",
                _ => "",
            });
        }
        add(&tag, &mut tags);
    }
    if let Some(_adverb) = word.adverb {
        add("R", &mut tags);
    }
    if let Some(_conj) = word.conjunction {
        add("C", &mut tags);
    }
    if let Some(determiner) = word.determiner {
        let mut tag = String::from("D");
        add_bool(&mut tag, "$", determiner.is_possessive);
        add_bool(&mut tag, "dem", determiner.is_demonstrative);
        add_bool(&mut tag, "q", determiner.is_quantifier);
        add(&tag, &mut tags);
    }
    if word.preposition {
        add("P", &mut tags);
    }
    if word.is_roman_numerals() {
        add("#r", &mut tags);
    }

    get_dialect_annotations(word).into_iter().for_each(|tag| {
        add(tag, &mut tags);
    });

    add_switch(&mut tags, word.np_member, "+", "");

    if word.swear == Some(true) {
        add("B", &mut tags);
    }

    match tags.is_empty() {
        true if word.orth_info.contains(OrthFlags::APOSTROPHE) => String::from("K"),
        true => String::from("W?"),
        false => tags,
    }
}

/// Returns a vector of dialect annotation strings for the given word.
/// Handles both individual dialects and special groupings (NoAm, Comm).
fn get_dialect_annotations(word: &DictWordMetadata) -> Vec<&'static str> {
    let mut annotations = Vec::new();
    let mut north_america = false;
    let mut commonwealth = false;

    let en_au = word.dialects.is_dialect_enabled_strict(Dialect::Australian);
    let en_ca = word.dialects.is_dialect_enabled_strict(Dialect::Canadian);
    let en_gb = word.dialects.is_dialect_enabled_strict(Dialect::British);
    let en_us = word.dialects.is_dialect_enabled_strict(Dialect::American);

    // Dialect groups in alphabetical order
    if en_gb && en_au && en_ca {
        annotations.push("Comm");
        commonwealth = true;
    }
    if en_us && en_ca {
        annotations.push("NoAm");
        north_america = true;
    }
    // Individual dialects in alphabetical order
    if en_us && !north_america {
        annotations.push("Am");
    }
    if en_au && !commonwealth {
        annotations.push("Au");
    }
    if en_gb && !commonwealth {
        annotations.push("Br");
    }
    if en_ca && !north_america && !commonwealth {
        annotations.push("Ca");
    }

    annotations
}

fn format_tag(kind: &TokenKind) -> Cow<'static, str> {
    match kind {
        TokenKind::Word(word) => {
            // These tags are inspired by the Penn Treebank POS tagset
            if let Some(word) = word {
                Cow::Owned(format_word_tag(word))
            } else {
                Cow::Borrowed("?")
            }
        }
        TokenKind::Punctuation(_) => Cow::Borrowed("."),
        TokenKind::Number(_) => Cow::Borrowed("#"),
        TokenKind::Decade => Cow::Borrowed("#d"),

        // The following variants just print their variant name
        TokenKind::Space(_) => Cow::Borrowed("Space"),
        TokenKind::Newline(_) => Cow::Borrowed("Newline"),
        TokenKind::EmailAddress => Cow::Borrowed("Email"),
        TokenKind::Url => Cow::Borrowed("Url"),
        TokenKind::Hostname => Cow::Borrowed("Hostname"),
        TokenKind::Unlintable => Cow::Borrowed("Unlintable"),
        TokenKind::Regexish => Cow::Borrowed("Regexish"),
        TokenKind::ParagraphBreak => Cow::Borrowed("ParagraphBreak"),
        TokenKind::HeadingStart => Cow::Borrowed("HeadingStart"),
    }
}

struct Formatter {
    out: String,
    line1: String,
    line2: String,
}
impl Formatter {
    const LINE1_PREFIX: &'static str = "> ";
    const LINE2_PREFIX: &'static str = "# ";
    fn new() -> Self {
        Self {
            out: String::new(),
            line1: String::from(Self::LINE1_PREFIX),
            line2: String::from(Self::LINE2_PREFIX),
        }
    }

    fn add(&mut self, token: &str, tag: &str) {
        for (line_number, token_line) in token.split('\n').enumerate() {
            if line_number > 0 {
                self.new_line();
            }

            self.line1.push_str(token_line);
            self.line1.push(' ');
            self.line2.push_str(tag);
            self.line2.push(' ');
            let token_chars = token_line.chars().count();
            let tag_chars = tag.chars().count();
            for _ in token_chars..tag_chars {
                self.line1.push(' ');
            }
            for _ in tag_chars..token_chars {
                self.line2.push(' ');
            }
        }
    }

    fn new_line(&mut self) {
        self.out.push_str(self.line1.trim_end());
        self.out.push('\n');
        self.out.push_str(self.line2.trim_end());
        self.out.push('\n');

        self.line1.clear();
        self.line2.clear();

        self.line1.push_str(Self::LINE1_PREFIX);
        self.line2.push_str(Self::LINE2_PREFIX);
    }

    fn finish(mut self) -> String {
        self.new_line();
        self.out
    }
}

#[test]
fn test_pos_tagger() {
    snapshot::snapshot_all_text_files("tagged", ".md", |source, _| {
        let dict = FstDictionary::curated();
        let document = Document::new_markdown_default(source, &dict);

        let mut formatter = Formatter::new();
        for token in document.fat_string_tokens() {
            match token.kind {
                TokenKind::Space(_) => { /* ignore */ }
                TokenKind::ParagraphBreak => {
                    formatter.new_line();
                    formatter.new_line();
                }
                TokenKind::Newline(_) => {
                    formatter.new_line();
                }
                kind => {
                    let text = &token.content;
                    let tag = format_tag(&kind);
                    formatter.add(text, &tag);
                }
            }
        }

        formatter.finish()
    });
}



================================================
FILE: harper-core/tests/run_tests.rs
================================================
use harper_core::linting::{LintGroup, Linter};
use harper_core::parsers::OrgMode;
use harper_core::spell::FstDictionary;
use harper_core::{Dialect, Document};

/// Creates a unit test checking that the linting of a Markdown document (in
/// `tests_sources`) produces the expected number of lints.
macro_rules! create_test {
    ($filename:ident.md, $correct_expected:expr, $dialect:expr) => {
        paste::paste! {
            #[test]
            fn [<lints_ $filename _correctly>](){
                let source = include_str!(
                    concat!(
                        "./test_sources/",
                        concat!(stringify!($filename), ".md")
                    )
                );

                let dict = FstDictionary::curated();
                let document = Document::new_markdown_default(&source, &dict);

                let mut linter = LintGroup::new_curated(dict, $dialect);
                let lints = linter.lint(&document);

                dbg!(&lints);
                assert_eq!(lints.len(), $correct_expected);

                // Make sure that all generated tokens span real characters
                for token in document.tokens(){
                     assert!(token.span.try_get_content(document.get_source()).is_some());
                }
            }
        }
    };
}

/// Creates a unit test checking that the linting of an Org mode document (in
/// `tests_sources`) produces the expected number of lints.
macro_rules! create_org_test {
    ($filename:ident.org, $correct_expected:expr, $dialect:expr) => {
        paste::paste! {
            #[test]
            fn [<lints_ $filename _correctly>](){
                let source = include_str!(
                    concat!(
                        "./test_sources/",
                        concat!(stringify!($filename), ".org")
                    )
                );

                let dict = FstDictionary::curated();
                let document = Document::new(&source, &OrgMode, &dict);

                let mut linter = LintGroup::new_curated(dict, $dialect);
                let lints = linter.lint(&document);

                dbg!(&lints);
                assert_eq!(lints.len(), $correct_expected);

                // Make sure that all generated tokens span real characters
                for token in document.tokens(){
                     assert!(token.span.try_get_content(document.get_source()).is_some());
                }
            }
        }
    };
}

create_test!(whack_bullets.md, 1, Dialect::American);
create_test!(issue_109.md, 0, Dialect::American);
create_test!(issue_109_ext.md, 0, Dialect::American);
create_test!(chinese_lorem_ipsum.md, 2, Dialect::American);
create_test!(obsidian_links.md, 3, Dialect::American);
create_test!(issue_267.md, 0, Dialect::American);
create_test!(proper_noun_capitalization.md, 3, Dialect::American);
create_test!(amazon_hostname.md, 0, Dialect::American);
create_test!(issue_159.md, 1, Dialect::American);
create_test!(issue_358.md, 0, Dialect::American);
create_test!(issue_195.md, 0, Dialect::American);
create_test!(issue_118.md, 0, Dialect::American);
create_test!(lots_of_latin.md, 1, Dialect::American);
create_test!(pr_504.md, 1, Dialect::American);
create_test!(pr_452.md, 2, Dialect::American);
create_test!(hex_basic_clean.md, 0, Dialect::American);
create_test!(hex_basic_dirty.md, 1, Dialect::American);
create_test!(misc_closed_compound_clean.md, 0, Dialect::American);
create_test!(statist_localist.md, 0, Dialect::American);
create_test!(yogurt_british_clean.md, 0, Dialect::British);
create_test!(issue_1581.md, 0, Dialect::British);
create_test!(issue_2054.md, 6, Dialect::British);
create_test!(issue_1988.md, 0, Dialect::American);
create_test!(issue_2054_clean.md, 0, Dialect::British);
create_test!(issue_1873.md, 0, Dialect::British);
create_test!(issue_2246.md, 0, Dialect::American);
create_test!(title_case_errors.md, 2, Dialect::American);
create_test!(title_case_clean.md, 0, Dialect::American);
create_test!(issue_2233.md, 0, Dialect::American);
create_test!(issue_2240.md, 0, Dialect::American);
// It just matters that it is > 1
create_test!(issue_2151.md, 4, Dialect::British);

// Make sure it doesn't panic
create_test!(lukas_homework.md, 4, Dialect::American);

// Org mode tests
create_org_test!(index.org, 49, Dialect::American);



================================================
FILE: harper-core/tests/snapshot.rs
================================================
use std::{
    marker::Sync,
    path::{Path, PathBuf},
};

use harper_core::Dialect;
use itertools::Itertools;
use rayon::iter::{IntoParallelRefIterator, ParallelIterator};

fn get_tests_dir() -> PathBuf {
    PathBuf::from(env!("CARGO_MANIFEST_DIR")).join("tests")
}
fn get_text_dir() -> PathBuf {
    get_tests_dir().join("text")
}

/// Tries to find a dialect override from a given file path. Returns `None` if the number of
/// dialect overrides found is not 1.
#[must_use]
fn try_get_dialect_override(path: &Path) -> Option<Dialect> {
    path.file_stem()?
        .to_string_lossy()
        .split('.')
        .filter_map(Dialect::try_from_abbr)
        .exactly_one() // If we find multiple overrides, it's unlikely that a dialect override is intended.
        .ok()
}

pub fn get_text_files() -> Vec<PathBuf> {
    let mut files = vec![];
    for entry in std::fs::read_dir(get_text_dir())
        .unwrap()
        .filter_map(|f| f.ok())
        .filter(|f| f.metadata().unwrap().is_file())
    {
        let path = entry.path();
        let ext = path
            .extension()
            .map(|e| e.to_string_lossy().to_string())
            .unwrap_or_default();
        if matches!(ext.as_str(), "txt" | "md") {
            files.push(entry.path());
        }
    }
    files
}

fn tag_file(
    text_file: &Path,
    snapshot_file: &Path,
    create_snapshot: impl Fn(&str, Option<Dialect>) -> String,
) -> Result<(), Box<dyn std::error::Error>> {
    let source = std::fs::read_to_string(text_file)?.replace("\r\n", "\n");
    let dialect_override = try_get_dialect_override(text_file);
    let tagged = create_snapshot(source.trim_end(), dialect_override);

    // compare with snapshot
    let has_snapshot = snapshot_file.exists();
    if has_snapshot {
        let snapshot = std::fs::read_to_string(snapshot_file)?;
        if tagged == snapshot {
            return Ok(());
        }
    }

    // write snapshot
    std::fs::write(snapshot_file, tagged)?;

    Err(if has_snapshot {
        "Snapshot mismatches!".into()
    } else {
        "No snapshot!".into()
    })
}
fn get_snapshot_file(text_file: &Path, snapshot_dir: &Path, ext: &str) -> PathBuf {
    let snapshot_name = text_file.file_stem().unwrap().to_string_lossy().to_string() + ext;
    snapshot_dir.join(snapshot_name)
}
#[allow(dead_code)]
pub fn snapshot_all_text_files(
    out_dir: &str,
    snapshot_ext: &str,
    create_snapshot: impl Copy + Fn(&str, Option<Dialect>) -> String + 'static + Sync,
) {
    let snapshot_dir = get_text_dir().join(out_dir);
    std::fs::create_dir_all(&snapshot_dir).expect("Failed to create snapshot directory");

    let errors: u64 = get_text_files()
        .par_iter()
        .map(|text_file| {
            println!("Processing {}", text_file.display());
            let snapshot_file = get_snapshot_file(text_file, &snapshot_dir, snapshot_ext);
            if let Err(e) = tag_file(text_file, &snapshot_file, create_snapshot) {
                eprintln!("Error processing {}: {}", text_file.display(), e);
                1
            } else {
                0
            }
        })
        .sum();

    if errors > 0 {
        panic!("{errors} errors occurred while processing files");
    }
}



================================================
FILE: harper-core/tests/test_sources/amazon_hostname.md
================================================
This is a test of whether Amazon.com is considered a URI.



================================================
FILE: harper-core/tests/test_sources/chinese_lorem_ipsum.md
================================================
[Binary file]


================================================
FILE: harper-core/tests/test_sources/hex_basic_clean.md
================================================
If p is an `int*`, and `p = 0x1000`, what is the value of `p+3`?

_0x100C_




================================================
FILE: harper-core/tests/test_sources/hex_basic_dirty.md
================================================
If p is an `int*`, and `p = 0x1000`, what is the value of `p+3`?

_0x100C_

asdkjd



================================================
FILE: harper-core/tests/test_sources/index.org
================================================
#+OPTIONS: H:9 ^:nil
* Nvim Orgmode

Nvim orgmode is a clone of Emacs Orgmode for Neovim 0.10.3+.
It aims to be a feature-complete implementation of Orgmode features in Neovim.

Online version of this documentation is available at [[https://nvim-orgmode.github.io]].

To view this documentation offline in Neovim, run =:Org help=. More info in [[#globals-and-commands][Globals and commands]] section.

** Quick start
:PROPERTIES:
:CUSTOM_ID: quick-start
:END:
- Install with [[https://github.com/folke/lazy.nvim][lazy.nvim]]:
  #+begin_src lua
  {
    'nvim-orgmode/orgmode',
    event = 'VeryLazy',
    config = function()
      -- Setup orgmode
      require('orgmode').setup({
        org_agenda_files = '~/orgfiles/**/*',
        org_default_notes_file = '~/orgfiles/refile.org',
      })
    end,
  }
  #+end_src
- Capture your first note with =<leader>oc=
- Open up the prompt for agenda with =<leader>oa=

For more details about the installation and usage, check [[./installation.org][Installation page]].

To see all configuration options, check [[file:./configuration.org][Configuration page]].

** Getting started with orgmode
:PROPERTIES:
:CUSTOM_ID: getting-started
:END:
To get a basic idea how Orgmode works, check our hands-on [[file:./tutorial.org][tutorial]].

You can also check this screencast from [[https://github.com/dhruvasagar][@dhruvasagar]]
that demonstrates how the similar Orgmode clone [[https://github.com/dhruvasagar/vim-dotoo][vim-dotoo]] works.

[[https://www.youtube.com/watch?v=nsv33iOnH34]]

** API docs
:PROPERTIES:
:CUSTOM_ID: api-docs
:END:
Nvim-orgmode exposes a Lua API that can be used to interact with the orgmode. To view it, check [[file:../doc/orgmode_api.txt][orgmode_api.txt]]
or do =:h OrgApi= in Neovim.

** Globals and commands
:PROPERTIES:
:CUSTOM_ID: globals-and-commands
:END:
There are 2 additional ways to interact with Orgmode:
1. Through the =:Org= command
2. Through =Org= Lua global variable

List of available actions:
- =:Org help= - Open this documentation in new tab, set working directory to the doc's folder for the tab to allow browsing
- =:Org helpgrep= - Open search agenda view that allows searching through the documentation
- =:Org agenda {type?}= - Open agenda view by the shortcut, for example =:Org agenda M= will open =tags_todo= view. When =type= is omitted, it opens up Agenda view.
- =:Org capture {type?}= - Open capture template by the shortcut, for example =:Org capture t=. When =type= is omitted, it opens up Capture prompt.
- =:Org install_treesitter_grammar= - Install the treesitter grammar for Orgmode. If installed, prompt to reinstall. Grammar is installed automatically
  on first run, but this is useful in case when there are issues with the grammar.
- =:Org store_link= - [[file:./configuration.org::#org_store_link][Store link]] to the headline under cursor. Works in both agenda and org files.
- =:Org indent_mode= - Toggle virtual indent mode in the current buffer. See [[file:./configuration.org::#org_startup_indented][osg_startup_indented]] for additional info.

All of the commands above can be executed through the global Lua =Org= variable. Examples:
- =Org.help()=
- =Org.helpgrep()=
- =Org.install_treesitter_grammar()=
- =Org.store_link()=
- =Org.indent_mode()=
- =Org.agenda()= - Opens =agenda= prompt
- =Org.agenda.m()= - Opens =tags= view
- =Org.capture()= - Opens capture prompt
- =Org.capture.t()= - Opens capture template for =t= shortcut



================================================
FILE: harper-core/tests/test_sources/issue_109.md
================================================
本文档是使用 Microsoft Translate 翻译的。哈珀根本不应该抱怨。



================================================
FILE: harper-core/tests/test_sources/issue_109_ext.md
================================================
[Binary file]


================================================
FILE: harper-core/tests/test_sources/issue_118.md
================================================
This is another sentence that says item 1, item 2, etc. in the middle of the sentence.



================================================
FILE: harper-core/tests/test_sources/issue_1581.md
================================================
Simple walkthroughs with...

The above phrase supposedly threw an error in an older version of Harper.



================================================
FILE: harper-core/tests/test_sources/issue_159.md
================================================
The file in question was myfile.txt, and it was glorious.
It was referenced by https://pax.grsecurity.net/docs/pageexec.old.txt.

this is another test for the sentence capitalization.



================================================
FILE: harper-core/tests/test_sources/issue_1873.md
================================================
TeX is a typesetting system.




================================================
FILE: harper-core/tests/test_sources/issue_195.md
================================================
If we have words with numbers in them, like IPv4, they should get marked as just that: words.



================================================
FILE: harper-core/tests/test_sources/issue_1988.md
================================================
When this test is run, it returns a result.



================================================
FILE: harper-core/tests/test_sources/issue_2054.md
================================================
I really enjoy a good ui or gui.
When developer put time and effort into a good ux, I feel so much more productive.



================================================
FILE: harper-core/tests/test_sources/issue_2054_clean.md
================================================
I really enjoy a good UI or GUI.
When developer put time and effort into a good UX, I feel so much more productive.



================================================
FILE: harper-core/tests/test_sources/issue_2151.md
================================================
Are cloudflare and CloudFlare incorrect?



================================================
FILE: harper-core/tests/test_sources/issue_2233.md
================================================
In foobar, apple is a fruit, and "beer" is not a fruit.



================================================
FILE: harper-core/tests/test_sources/issue_2240.md
================================================
There is no more need to run `git`.



================================================
FILE: harper-core/tests/test_sources/issue_2246.md
================================================
But current implementations will likely be bypassable. 



================================================
FILE: harper-core/tests/test_sources/issue_267.md
================================================
<p id="question">What did you learn from the assignment? Were there any special insights you had? What did you find that you already knew?</p>



================================================
FILE: harper-core/tests/test_sources/issue_358.md
================================================
The total number of pixels in the image pertains to a one channel image.



================================================
FILE: harper-core/tests/test_sources/lots_of_latin.md
================================================
We had some issues with correctly parsing certain Latin terms.

It caused issues with phrases like, "it was Mike Tyson vs. Weird Al!" and "Mike Tyson et al. wrote this paper," etc., especially for scientific papers.



================================================
FILE: harper-core/tests/test_sources/lukas_homework.md
================================================
# Native American Assimilation and Activism Week Two Reflection

> This is the first in a bi-weekly series that I will be publishing for my Native
American Assimilation and Activism class. Every two weeks we make posts
sharing what we learned in the class. Unfortunately, due to weather in England I
was unable to make it back to the United States in time for the first lecture.

One of the key discussions in Monday's lecture/discussion was since time
immemorial and teaching around that. Time Immemorium is a period before
human memory, and involved other human species, travel stories, and creation
stories. Some of the key lessons I learned from that class were:

* Humans branched from some common ancestor that had multiple other human species branch off
    * We are not evolved from chimps but also have a shared ancestor
* Many genetic evolutional specializations have to do with environmental adaptation
    * Some of these adaptations were shared when isolated groups had visitors (Weaving rivers theory)
    * Also related: Intergenerational Trauma

Oregon and Washington have been leading the country when it comes to
integrating Native Americans into their school curriculum. This includes
adding Since Time Immemorium curriculum. These advances have the
possibility to significantly improve the awareness and appreciation of Native
American Peoples who have and still live in these lands.



================================================
FILE: harper-core/tests/test_sources/misc_closed_compound_clean.md
================================================
It's hidden right here under the carpet.

I got there after him. 

Go back there after dinner and finish it.

We've gotta go down right here.

I hereby state that I got here by way of the "issues" link.

It's over there in that box.

I'll still be here after work.

I'll meet you here after work.



================================================
FILE: harper-core/tests/test_sources/obsidian_links.md
================================================
# Example Obsidian Links

Below, you will find a number of example links that Obsidian is able to process.

These should be treated as normal Markdown links.
The things inside the square brackets are visible and should be checked by Harper.

[[Three lws of motion]]
[Three las of motion](Three%20laws%20of%20motion.md)


Wikilinks allow you to replace the visible text with a pipe (|) operator.
The text to the left of the operator should be ignored.

[[lnk tget|Link Text]]



================================================
FILE: harper-core/tests/test_sources/pr_452.md
================================================
Lets go and check if this lint let's us catch this class of errors.



================================================
FILE: harper-core/tests/test_sources/pr_504.md
================================================
These say "This is in Greek/Georgian/Thai" in those languages:

Αυτό είναι στα ελληνικά.
ეს ქართულად.
นี่มันภาษาไทย

This is English with misstakes.



================================================
FILE: harper-core/tests/test_sources/proper_noun_capitalization.md
================================================
Apple watch should have been capitalized here.

Similarly, amazon web seRVices should have been capitalized differently here.



================================================
FILE: harper-core/tests/test_sources/statist_localist.md
================================================
These villages run the gamut from statist too localist.

Their pedigree can be traced back to Plato, the father of statism.

But the localism of France at the time should not be underestimated.



================================================
FILE: harper-core/tests/test_sources/title_case_clean.md
================================================
# Here, We Try to Test Our Title-Casing Feature

It should only pay attention to headings.

## Maybe It Works?

There will be a similar file with the corrected headings.



================================================
FILE: harper-core/tests/test_sources/title_case_errors.md
================================================
# Here, we try to test our title-casing feature

It should only pay attention to headings.

## Maybe it works?

There will be a similar file with the corrected headings.



================================================
FILE: harper-core/tests/test_sources/whack_bullets.md
================================================
# This Is a Big Heading, with a Lot of Words

- New here's a list, this part doesn't have as many words
    - But this part does, it has so many words, more words than you could ever dream of
      Just look at all those words
        - So does this part, I might be overwhelmed with all these words
            - This is an test to make sure it isn't crashing



================================================
FILE: harper-core/tests/test_sources/yogurt_british_clean.md
================================================
The following essay should produce no errors when Harper is set to British English.

Yoghurt, a simple yet remarkably versatile food, has a rich history that stretches back thousands of years. Originating from the ancient civilizations of the Middle East and Central Asia, yoghurt has transcended geographical boundaries, becoming a staple in diets around the globe.

Historically, yoghurt was discovered by chance, likely from milk stored in warm climates naturally turning into a cultured product. This process, involving beneficial bacteria, not only preserves milk but also enhances its nutritional value, digestibility, and flavour. Over centuries, yoghurt evolved from a basic dietary component into a diverse food enjoyed in numerous culinary traditions.

The versatility of yoghurt is evident in its varied uses across different cuisines. In Mediterranean and Middle Eastern dishes, yoghurt often accompanies savoury meals, acting as a refreshing complement to spicy flavours. Tzatziki, a blend of yoghurt, cucumber, garlic, and mint, exemplifies this culinary tradition. Similarly, Indian cuisine features yoghurt prominently, using it as the base for marinades.

Yoghurt is not just a savoury food; it is equally embraced in sweet dishes. Its creamy texture and tangy taste make it ideal for desserts, smoothies, and breakfast dishes. In European countries, yoghurt mixed with fresh fruit, granola, and honey is a popular breakfast or snack option, providing a nutritious and delicious start to the day.

Nutritionally, yoghurt is celebrated for its health benefits. It is rich in protein, calcium, vitamins, and probiotics—live bacteria that support digestive health and immune function. These beneficial bacteria contribute to maintaining a balanced gut microbiome, essential for overall wellness. The popularity of yoghurt has further increased with rising consumer awareness about gut health and nutrition, fuelling innovations in dairy and plant-based yoghurt alternatives.

The production methods of yoghurt have evolved significantly over time, from traditional artisanal practices to advanced industrial techniques. Modern yoghurt manufacturing employs precise control of temperature, bacterial cultures, and incubation processes to ensure consistent quality, taste, and nutritional content. Additionally, innovations in packaging and preservation have expanded yoghurt's accessibility and convenience, making it an ubiquitous presence in supermarkets worldwide.

However, yoghurt production and consumption also present certain challenges. Concerns around sustainability, environmental impact, and ethical dairy farming practices have encouraged a shift toward organic and plant-based alternatives. This has spurred market growth for nondairy yoghurts made from ingredients such as coconut, almond, oat, and soy, reflecting evolving consumer preferences and dietary needs.

In conclusion, yoghurt is much more than a simple dairy product—it is a cultural and nutritional cornerstone that continues to adapt and thrive across global culinary traditions. Its enduring popularity is a testament to its delicious versatility, health benefits, and adaptability to changing dietary trends, ensuring yoghurt's continued prominence in diets around the world.




================================================
FILE: harper-core/tests/text/Computer science.md
================================================
<!--
source: https://en.wikipedia.org/w/index.php?title=Computer_science&oldid=1286173304
license: CC BY-SA 4.0
-->

# Computer science

Computer science is the study of computation, information, and automation.
Computer science spans theoretical disciplines (such as algorithms, theory of
computation, and information theory) to applied disciplines (including the
design and implementation of hardware and software).

Algorithms and data structures are central to computer science. The theory of
computation concerns abstract models of computation and general classes of
problems that can be solved using them. The fields of cryptography and computer
security involve studying the means for secure communication and preventing
security vulnerabilities. Computer graphics and computational geometry address
the generation of images. Programming language theory considers different ways
to describe computational processes, and database theory concerns the management
of repositories of data. Human–computer interaction investigates the interfaces
through which humans and computers interact, and software engineering focuses on
the design and principles behind developing software. Areas such as operating
systems, networks and embedded systems investigate the principles and design
behind complex systems. Computer architecture describes the construction of
computer components and computer-operated equipment. Artificial intelligence and
machine learning aim to synthesize goal-orientated processes such as
problem-solving, decision-making, environmental adaptation, planning and
learning found in humans and animals. Within artificial intelligence, computer
vision aims to understand and process image and video data, while natural
language processing aims to understand and process textual and linguistic data.

The fundamental concern of computer science is determining what can and cannot
be automated. The Turing Award is generally recognized as the highest
distinction in computer science.

## History

The earliest foundations of what would become computer science predate the
invention of the modern digital computer. Machines for calculating fixed
numerical tasks such as the abacus have existed since antiquity, aiding in
computations such as multiplication and division. Algorithms for performing
computations have existed since antiquity, even before the development of
sophisticated computing equipment.

Wilhelm Schickard designed and constructed the first working mechanical
calculator in 1623. In 1673, Gottfried Leibniz demonstrated a digital mechanical
calculator, called the Stepped Reckoner. Leibniz may be considered the first
computer scientist and information theorist, because of various reasons,
including the fact that he documented the binary number system. In 1820, Thomas
de Colmar launched the mechanical calculator industry[note 1] when he invented
his simplified arithmometer, the first calculating machine strong enough and
reliable enough to be used daily in an office environment. Charles Babbage
started the design of the first automatic mechanical calculator, his Difference
Engine, in 1822, which eventually gave him the idea of the first programmable
mechanical calculator, his Analytical Engine. He started developing this machine
in 1834, and "in less than two years, he had sketched out many of the salient
features of the modern computer". "A crucial step was the adoption of a punched
card system derived from the Jacquard loom" making it infinitely
programmable.[note 2] In 1843, during the translation of a French article on the
Analytical Engine, Ada Lovelace wrote, in one of the many notes she included, an
algorithm to compute the Bernoulli numbers, which is considered to be the first
published algorithm ever specifically tailored for implementation on a computer.
Around 1885, Herman Hollerith invented the tabulator, which used punched cards
to process statistical information; eventually his company became part of IBM.
Following Babbage, although unaware of his earlier work, Percy Ludgate in 1909
published the 2nd of the only two designs for mechanical analytical engines in
history. In 1914, the Spanish engineer Leonardo Torres Quevedo published his
Essays on Automatics, and designed, inspired by Babbage, a theoretical
electromechanical calculating machine which was to be controlled by a read-only
program. The paper also introduced the idea of floating-point arithmetic. In
1920, to celebrate the 100th anniversary of the invention of the arithmometer,
Torres presented in Paris the Electromechanical Arithmometer, a prototype that
demonstrated the feasibility of an electromechanical analytical engine, on which
commands could be typed and the results printed automatically. In 1937, one
hundred years after Babbage's impossible dream, Howard Aiken convinced IBM,
which was making all kinds of punched card equipment and was also in the
calculator business to develop his giant programmable calculator, the
ASCC/Harvard Mark I, based on Babbage's Analytical Engine, which itself used
cards and a central computing unit. When the machine was finished, some hailed
it as "Babbage's dream come true".

During the 1940s, with the development of new and more powerful computing
machines such as the Atanasoff–Berry computer and ENIAC, the term computer came
to refer to the machines rather than their human predecessors. As it became
clear that computers could be used for more than just mathematical calculations,
the field of computer science broadened to study computation in general. In
1945, IBM founded the Watson Scientific Computing Laboratory at Columbia
University in New York City. The renovated fraternity house on Manhattan's West
Side was IBM's first laboratory devoted to pure science. The lab is the
forerunner of IBM's Research Division, which today operates research facilities
around the world. Ultimately, the close relationship between IBM and Columbia
University was instrumental in the emergence of a new scientific discipline,
with Columbia offering one of the first academic-credit courses in computer
science in 1946. Computer science began to be established as a distinct academic
discipline in the 1950s and early 1960s. The world's first computer science
degree program, the Cambridge Diploma in Computer Science, began at the
University of Cambridge Computer Laboratory in 1953. The first computer science
department in the United States was formed at Purdue University in 1962. Since
practical computers became available, many applications of computing have become
distinct areas of study in their own rights.

## Etymology and scope

Although first proposed in 1956, the term "computer science" appears in a 1959
article in Communications of the ACM, in which Louis Fein argues for the
creation of a Graduate School in Computer Sciences analogous to the creation of
Harvard Business School in 1921. Louis justifies the name by arguing that, like
management science, the subject is applied and interdisciplinary in nature,
while having the characteristics typical of an academic discipline. His efforts,
and those of others such as numerical analyst George Forsythe, were rewarded:
universities went on to create such departments, starting with Purdue in 1962.
Despite its name, a significant amount of computer science does not involve the
study of computers themselves. Because of this, several alternative names have
been proposed. Certain departments of major universities prefer the term
computing science, to emphasize precisely that difference. Danish scientist
Peter Naur suggested the term datalogy, to reflect the fact that the scientific
discipline revolves around data and data treatment, while not necessarily
involving computers. The first scientific institution to use the term was the
Department of Datalogy at the University of Copenhagen, founded in 1969, with
Peter Naur being the first professor in datalogy. The term is used mainly in the
Scandinavian countries. An alternative term, also proposed by Naur, is data
science; this is now used for a multi-disciplinary field of data analysis,
including statistics and databases.

In the early days of computing, a number of terms for the practitioners of the
field of computing were suggested (albeit facetiously) in the Communications of
the ACM—turingineer, turologist, flow-charts-man, applied meta-mathematician,
and applied epistemologist. Three months later in the same journal, comptologist
was suggested, followed next year by hypologist. The term computics has also
been suggested. In Europe, terms derived from contracted translations of the
expression "automatic information" (e.g. "informazione automatica" in Italian)
or "information and mathematics" are often used, e.g. informatique (French),
Informatik (German), informatica (Italian, Dutch), informática (Spanish,
Portuguese), informatika (Slavic languages and Hungarian) or pliroforiki
(πληροφορική, which means informatics) in Greek. Similar words have also been
adopted in the UK (as in the School of Informatics, University of Edinburgh).
"In the U.S., however, informatics is linked with applied computing, or
computing in the context of another domain."

A folkloric quotation, often attributed to—but almost certainly not first
formulated by—Edsger Dijkstra, states that "computer science is no more about
computers than astronomy is about telescopes."[note 3] The design and deployment
of computers and computer systems is generally considered the province of
disciplines other than computer science. For example, the study of computer
hardware is usually considered part of computer engineering, while the study of
commercial computer systems and their deployment is often called information
technology or information systems. However, there has been exchange of ideas
between the various computer-related disciplines. Computer science research also
often intersects other disciplines, such as cognitive science, linguistics,
mathematics, physics, biology, Earth science, statistics, philosophy, and logic.

Computer science is considered by some to have a much closer relationship with
mathematics than many scientific disciplines, with some observers saying that
computing is a mathematical science. Early computer science was strongly
influenced by the work of mathematicians such as Kurt Gödel, Alan Turing, John
von Neumann, Rózsa Péter and Alonzo Church and there continues to be a useful
interchange of ideas between the two fields in areas such as mathematical logic,
category theory, domain theory, and algebra.

The relationship between computer science and software engineering is a
contentious issue, which is further muddied by disputes over what the term
"software engineering" means, and how computer science is defined. David Parnas,
taking a cue from the relationship between other engineering and science
disciplines, has claimed that the principal focus of computer science is
studying the properties of computation in general, while the principal focus of
software engineering is the design of specific computations to achieve practical
goals, making the two separate but complementary disciplines.

The academic, political, and funding aspects of computer science tend to depend
on whether a department is formed with a mathematical emphasis or with an
engineering emphasis. Computer science departments with a mathematics emphasis
and with a numerical orientation consider alignment with computational science.
Both types of departments tend to make efforts to bridge the field educationally
if not across all research.

## Philosophy

### Epistemology of computer science

Despite the word science in its name, there is debate over whether or not
computer science is a discipline of science, mathematics, or engineering. Allen
Newell and Herbert A. Simon argued in 1975,

> Computer science is an empirical discipline. We would have called it an
> experimental science, but like astronomy, economics, and geology, some of its
> unique forms of observation and experience do not fit a narrow stereotype of
> the experimental method. Nonetheless, they are experiments. Each new machine
> that is built is an experiment. Actually constructing the machine poses a
> question to nature; and we listen for the answer by observing the machine in
> operation and analyzing it by all analytical and measurement means available.

It has since been argued that computer science can be classified as an empirical
science since it makes use of empirical testing to evaluate the correctness of
programs, but a problem remains in defining the laws and theorems of computer
science (if any exist) and defining the nature of experiments in computer
science. Proponents of classifying computer science as an engineering discipline
argue that the reliability of computational systems is investigated in the same
way as bridges in civil engineering and airplanes in aerospace engineering. They
also argue that while empirical sciences observe what presently exists, computer
science observes what is possible to exist and while scientists discover laws
from observation, no proper laws have been found in computer science and it is
instead concerned with creating phenomena.

Proponents of classifying computer science as a mathematical discipline argue
that computer programs are physical realizations of mathematical entities and
programs that can be deductively reasoned through mathematical formal methods.
Computer scientists Edsger W. Dijkstra and Tony Hoare regard instructions for
computer programs as mathematical sentences and interpret formal semantics for
programming languages as mathematical axiomatic systems.

### Paradigms of computer science

A number of computer scientists have argued for the distinction of three
separate paradigms in computer science. Peter Wegner argued that those paradigms
are science, technology, and mathematics. Peter Denning's working group argued
that they are theory, abstraction (modeling), and design. Amnon H. Eden
described them as the "rationalist paradigm" (which treats computer science as a
branch of mathematics, which is prevalent in theoretical computer science, and
mainly employs deductive reasoning), the "technocratic paradigm" (which might be
found in engineering approaches, most prominently in software engineering), and
the "scientific paradigm" (which approaches computer-related artifacts from the
empirical perspective of natural sciences, identifiable in some branches of
artificial intelligence). Computer science focuses on methods involved in
design, specification, programming, verification, implementation and testing of
human-made computing systems.

## Fields

As a discipline, computer science spans a range of topics from theoretical
studies of algorithms and the limits of computation to the practical issues of
implementing computing systems in hardware and software. CSAB, formerly called
Computing Sciences Accreditation Board—which is made up of representatives of
the Association for Computing Machinery (ACM), and the IEEE Computer Society
(IEEE CS)—identifies four areas that it considers crucial to the discipline of
computer science: theory of computation, algorithms and data structures,
programming methodology and languages, and computer elements and architecture.
In addition to these four areas, CSAB also identifies fields such as software
engineering, artificial intelligence, computer networking and communication,
database systems, parallel computation, distributed computation, human–computer
interaction, computer graphics, operating systems, and numerical and symbolic
computation as being important areas of computer science.

### Theoretical computer science

Theoretical computer science is mathematical and abstract in spirit, but it
derives its motivation from practical and everyday computation. It aims to
understand the nature of computation and, as a consequence of this
understanding, provide more efficient methodologies.

#### Theory of computation

According to Peter Denning, the fundamental question underlying computer science
is, "What can be automated?" Theory of computation is focused on answering
fundamental questions about what can be computed and what amount of resources
are required to perform those computations. In an effort to answer the first
question, computability theory examines which computational problems are
solvable on various theoretical models of computation. The second question is
addressed by computational complexity theory, which studies the time and space
costs associated with different approaches to solving a multitude of
computational problems.

The famous P = NP? problem, one of the Millennium Prize Problems, is an open
problem in the theory of computation.

#### Information and coding theory

Information theory, closely related to probability and statistics, is related to
the quantification of information. This was developed by Claude Shannon to find
fundamental limits on signal processing operations such as compressing data and
on reliably storing and communicating data. Coding theory is the study of the
properties of codes (systems for converting information from one form to
another) and their fitness for a specific application. Codes are used for data
compression, cryptography, error detection and correction, and more recently
also for network coding. Codes are studied for the purpose of designing
efficient and reliable data transmission methods.

#### Data structures and algorithms

Data structures and algorithms are the studies of commonly used computational
methods and their computational efficiency.

#### Programming language theory and formal methods

Programming language theory is a branch of computer science that deals with the
design, implementation, analysis, characterization, and classification of
programming languages and their individual features. It falls within the
discipline of computer science, both depending on and affecting mathematics,
software engineering, and linguistics. It is an active research area, with
numerous dedicated academic journals.

Formal methods are a particular kind of mathematically based technique for the
specification, development and verification of software and hardware systems.
The use of formal methods for software and hardware design is motivated by the
expectation that, as in other engineering disciplines, performing appropriate
mathematical analysis can contribute to the reliability and robustness of a
design. They form an important theoretical underpinning for software
engineering, especially where safety or security is involved. Formal methods are
a useful adjunct to software testing since they help avoid errors and can also
give a framework for testing. For industrial use, tool support is required.
However, the high cost of using formal methods means that they are usually only
used in the development of high-integrity and life-critical systems, where
safety or security is of utmost importance. Formal methods are best described as
the application of a fairly broad variety of theoretical computer science
fundamentals, in particular logic calculi, formal languages, automata theory,
and program semantics, but also type systems and algebraic data types to
problems in software and hardware specification and verification.

### Applied computer science

#### Computer graphics and visualization

Computer graphics is the study of digital visual contents and involves the
synthesis and manipulation of image data. The study is connected to many other
fields in computer science, including computer vision, image processing, and
computational geometry, and is heavily applied in the fields of special effects
and video games.

#### Image and sound processing

Information can take the form of images, sound, video or other multimedia. Bits
of information can be streamed via signals. Its processing is the central notion
of informatics, the European view on computing, which studies information
processing algorithms independently of the type of information carrier – whether
it is electrical, mechanical or biological. This field plays important role in
information theory, telecommunications, information engineering and has
applications in medical image computing and speech synthesis, among others. What
is the lower bound on the complexity of fast Fourier transform algorithms? is
one of the unsolved problems in theoretical computer science.

#### Computational science, finance and engineering

Scientific computing (or computational science) is the field of study concerned
with constructing mathematical models and quantitative analysis techniques and
using computers to analyze and solve scientific problems. A major usage of
scientific computing is simulation of various processes, including computational
fluid dynamics, physical, electrical, and electronic systems and circuits, as
well as societies and social situations (notably war games) along with their
habitats, among many others. Modern computers enable optimization of such
designs as complete aircraft. Notable in electrical and electronic circuit
design are SPICE, as well as software for physical realization of new (or
modified) designs. The latter includes essential design software for integrated
circuits.

#### Human–computer interaction

Human–computer interaction (HCI) is the field of study and research concerned
with the design and use of computer systems, mainly based on the analysis of the
interaction between humans and computer interfaces. HCI has several subfields
that focus on the relationship between emotions, social behavior and brain
activity with computers.

#### Software engineering

Software engineering is the study of designing, implementing, and modifying the
software in order to ensure it is of high quality, affordable, maintainable, and
fast to build. It is a systematic approach to software design, involving the
application of engineering practices to software. Software engineering deals
with the organizing and analyzing of software—it does not just deal with the
creation or manufacture of new software, but its internal arrangement and
maintenance. For example software testing, systems engineering, technical debt
and software development processes.

#### Artificial intelligence

Artificial intelligence (AI) aims to or is required to synthesize
goal-orientated processes such as problem-solving, decision-making,
environmental adaptation, learning, and communication found in humans and
animals. From its origins in cybernetics and in the Dartmouth Conference (1956),
artificial intelligence research has been necessarily cross-disciplinary,
drawing on areas of expertise such as applied mathematics, symbolic logic,
semiotics, electrical engineering, philosophy of mind, neurophysiology, and
social intelligence. AI is associated in the popular mind with robotic
development, but the main field of practical application has been as an embedded
component in areas of software development, which require computational
understanding. The starting point in the late 1940s was Alan Turing's question
"Can computers think?", and the question remains effectively unanswered,
although the Turing test is still used to assess computer output on the scale of
human intelligence. But the automation of evaluative and predictive tasks has
been increasingly successful as a substitute for human monitoring and
intervention in domains of computer application involving complex real-world
data.

### Computer systems

#### Computer architecture and microarchitecture

Computer architecture, or digital computer organization, is the conceptual
design and fundamental operational structure of a computer system. It focuses
largely on the way by which the central processing unit performs internally and
accesses addresses in memory. Computer engineers study computational logic and
design of computer hardware, from individual processor components,
microcontrollers, personal computers to supercomputers and embedded systems. The
term "architecture" in computer literature can be traced to the work of Lyle R.
Johnson and Frederick P. Brooks Jr., members of the Machine Organization
department in IBM's main research center in 1959.

#### Concurrent, parallel and distributed computing

Concurrency is a property of systems in which several computations are executing
simultaneously, and potentially interacting with each other. A number of
mathematical models have been developed for general concurrent computation
including Petri nets, process calculi and the parallel random access machine
model. When multiple computers are connected in a network while using
concurrency, this is known as a distributed system. Computers within that
distributed system have their own private memory, and information can be
exchanged to achieve common goals.

#### Computer networks

This branch of computer science aims to manage networks between computers
worldwide.

#### Computer security and cryptography

Computer security is a branch of computer technology with the objective of
protecting information from unauthorized access, disruption, or modification
while maintaining the accessibility and usability of the system for its intended
users.

Historical cryptography is the art of writing and deciphering secret messages.
Modern cryptography is the scientific study of problems relating to distributed
computations that can be attacked. Technologies studied in modern cryptography
include symmetric and asymmetric encryption, digital signatures, cryptographic
hash functions, key-agreement protocols, blockchain, zero-knowledge proofs, and
garbled circuits.

#### Databases and data mining

A database is intended to organize, store, and retrieve large amounts of data
easily. Digital databases are managed using database management systems to
store, create, maintain, and search data, through database models and query
languages. Data mining is a process of discovering patterns in large data sets.

## Discoveries

The philosopher of computing Bill Rapaport noted three Great Insights of
Computer Science:

- Gottfried Wilhelm Leibniz's, George Boole's, Alan Turing's, Claude Shannon's,
  and Samuel Morse's insight: there are only two objects that a computer has to
  deal with in order to represent "anything".[note 4]
  > All the information about any computable problem can be represented using
  > only 0 and 1 (or any other bistable pair that can flip-flop between two
  > easily distinguishable states, such as "on/off", "magnetized/de-magnetized",
  > "high-voltage/low-voltage", etc.).
- Alan Turing's insight: there are only five actions that a computer has to
  perform in order to do "anything".

  Every algorithm can be expressed in a language for a computer consisting of
  only five basic instructions:

  - move left one location;
  - move right one location;
  - read symbol at current location;
  - print 0 at current location;
  - print 1 at current location.

- Corrado Böhm and Giuseppe Jacopini's insight: there are only three ways of
  combining these actions (into more complex ones) that are needed in order for
  a computer to do "anything".

  Only three rules are needed to combine any set of basic instructions into more
  complex ones:

  - sequence: first do this, then do that;
  - selection: IF such-and-such is the case, THEN do this, ELSE do that;
  - repetition: WHILE such-and-such is the case, DO this. The three rules of
    Boehm's and Jacopini's insight can be further simplified with the use of
    goto (which means it is more elementary than structured programming).

## Programming paradigms

Programming languages can be used to accomplish different tasks in different
ways. Common programming paradigms include:

- Functional programming, a style of building the structure and elements of
  computer programs that treats computation as the evaluation of mathematical
  functions and avoids state and mutable data. It is a declarative programming
  paradigm, which means programming is done with expressions or declarations
  instead of statements.
- Imperative programming, a programming paradigm that uses statements that
  change a program's state. In much the same way that the imperative mood in
  natural languages expresses commands, an imperative program consists of
  commands for the computer to perform. Imperative programming focuses on
  describing how a program operates.
- Object-oriented programming, a programming paradigm based on the concept of
  "objects", which may contain data, in the form of fields, often known as
  attributes; and code, in the form of procedures, often known as methods. A
  feature of objects is that an object's procedures can access and often modify
  the data fields of the object with which they are associated. Thus
  object-oriented computer programs are made out of objects that interact with
  one another.
- Service-oriented programming, a programming paradigm that uses "services" as
  the unit of computer work, to design and implement integrated business
  applications and mission critical software programs.

Many languages offer support for multiple paradigms, making the distinction more
a matter of style than of technical capabilities.

## Research

Conferences are important events for computer science research. During these
conferences, researchers from the public and private sectors present their
recent work and meet. Unlike in most other academic fields, in computer science,
the prestige of conference papers is greater than that of journal publications.
One proposed explanation for this is the quick development of this relatively
new field requires rapid review and distribution of results, a task better
handled by conferences than by journals.



================================================
FILE: harper-core/tests/text/Difficult sentences.md
================================================
# Difficult sentences

A collection of difficult sentences to test Harper's ability to correctly tag unusual/uncommon but correct sentences.

Note that some word may **not** be tagged correctly right now.

Most example sentences are taken from https://en.wiktionary.org/. License: CC BY-SA 4.0.

# A

With one attack, he was torn a pieces.
I brush my teeth twice a day.

## At

### Preposition

Caesar was at Rome; a climate treaty was signed at Kyoto in 1997.
I was at Jim’s house at the corner of Fourth Street and Vine.
at the bottom of the page; sitting at the table; at church; at sea
Target at five miles. Prepare torpedoes!
Look out! UFO at two o'clock!
Don't pick at your food!
My cat keeps scratching at the furniture.
I was working at the problem all day.
He shouted at her.
She pointed at the curious animal.
At my request, they agreed to move us to another hotel.
He jumped at the sudden noise.
We laughed at the joke.
She was mad at their comments.
men at work; children at play
The two countries are at war.
She is at sixes and sevens with him.

### Noun

The at sign.

### Verb

(In online chats:) Don't @ me! Don't at me!

## By

### Preposition

The mailbox is by the bus stop.
The stream runs by our back door.
He ran straight by me.
Be back by ten o'clock!.
We'll find someone by the end of March.
We will send it by the first week of July.
The matter was decided by the chairman.
The boat was swamped by the water.
He was protected by his body armour.
There was a call by the unions for a 30% pay rise.
I was aghast by what I saw.
There are many well-known plays by William Shakespeare.
I avoided the guards by moving only when they weren't looking.
By Pythagoras' theorem, we can calculate the length of the hypotenuse.
We went by bus.
I discovered it by chance.
By 'maybe' she means 'no'.
The electricity was cut off, so we had to read by candlelight.
By the power vested in me, I now pronounce you man and wife.
By Jove! I think she's got it!
By all that is holy, I'll put an end to this.
I sorted the items by category.
Table 1 shows details of our employees broken down by sex and age.
Our stock is up by ten percent.
We won by six goals to three.
His date of birth was wrong by ten years.
We went through the book page by page.
We crawled forward by inches.
sold by the yard; cheaper if bought by the gross
While sitting listening to the radio by the hour, she can drink brandy by the bucketful!
He sits listening to the radio by the hour.
His health was deteriorating by the day.
The pickers are paid by the bushel.
He cheated by his own admission.
By my reckoning, we should be nearly there.
It is easy to invert a 2-by-2 matrix.
The room was about 4 foot by 6 foot.
The bricks used to build the wall measured 10 by 20 by 30 cm.
She's a lovely little filly, by Big Lad, out of Damsel in Distress.
Are you eating by Rabbi Fischer? (at the house of)
By Chabad, it's different. (with, among)

### Adverb

I watched the parade as it passed by.
There was a shepherd close by.
I'll stop by on my way home from work.
We're right near the lifeguard station. Come by before you leave.
The women spent much time after harvest putting jams by for winter and spring.

### Adjective

a by path; a by room (Out of the way, off to one side.)
by catch; a by issue (Subsidiary, incidental.)

## For

### Conjunction

I had to stay with my wicked stepmother, for I had nowhere else to go.

### Preposition

The astronauts headed for the moon.
Run for the hills!
He was headed for the door when he remembered.
I have something for you.
Everything I do, I do for you.
We're having a birthday party for Janet.
The mayor gave a speech for the charity gala.
If having to bag the groceries correctly is more than you can handle, then this isn't the job for you.
This is a new bell for my bicycle.
The cake is for Tom and Helen's anniversary.
This medicine is for your cough.
He wouldn't apologize; and just for that, she refused to help him.
He looks better for having lost weight. (UK usage)
She was the worse for drink.
All those for the motion, raise your hands.
Who's for ice-cream?
I'm for going by train
Ten voted for, and three against. (with implied object)
Make way for the president!
Clear the shelves for our new Christmas stock!
Stand by for your cue.
Prepare for battle.
They swept the area for enemy operatives.
Police combed his flat for clues.
I've lived here for three years.
They fought for days over a silly pencil.
The store is closed for the day.
I can see for miles.
I will stand in for him.
I speak for the Prime Minister.
It is unreasonable for our boss to withhold our wages.
I don't think it's a good idea for you and me to meet ever again.
I am aiming for completion by the end of business Thursday.
He's going for his doctorate.
Do you want to go for coffee?
I'm saving up for a car.
Don't wait for an answer.
Fair for its day.
She's spry for an old lady.
Don't take me for a fool.
For all his expensive education, he didn't seem very bright.
And now for a slap-up meal!
Go scuba diving? For one thing, I can't even swim.
For another, we don't have any equipment.
He is named for his grandfather.
He totally screwed up that project. Now he's surely for the sack.
In term of base hits, Jones was three for four on the day
At close of play, England were 305 for 3.
He took the swing shift for he could get more overtime.
to account for one's whereabouts.

## From

Paul is from New Zealand.
I got a letter from my brother.
You can't get all your news from the Internet.
He had books piled from floor to ceiling.
He departed yesterday from Chicago.
This figure has been changed from a one to a seven.
Face away from the wall!
The working day runs from 9 am to 5 pm.
Tickets are available from 17th July.
Rate your pain from 1 to 10.
Start counting from 1.
You can study anything from math to literature.
It's hard to tell from here.
Try to see it from his point of view.
The bomb went off just 100 yards from where they were standing.
From the top of the lighthouse you can just see the mainland.
I’ve been doing this from pickney.
Your opinions differ from mine.
He knows right from wrong.

## In

### Preposition

Who lives in a pineapple under the sea?
The dog is in the kennel.
There were three pickles in a jar.
I like living in the city.
There are lots of trees in the park.
We are in the enemy camp.
Her plane is in the air.
I glanced over at the pretty girl in the red dress.
There wasn't much of interest in her speech.
He hasn't got an original idea in him.
You are one in a million.
She's in an orchestra.
My birthday is in the first week of December.
Easter falls in the fourth lunar month.
Will you be able to finish this in a week?
They said they would call us in a week.
Less water gets in your boots this way.
She stood there looking in the window longingly.
In replacing the faucet washers, he felt he was making his contribution to the environment.
In trying to make amends, she actually made matters worse.
My aim in travelling there was to find my missing friend.
My fat rolls around in folds.
The planes flew over in waves.
Arrange the chairs in a circle.
He stalked away in anger.
John is in a coma.
My fruit trees are in bud.
The company is in profit.
You've got a friend in me.
He's met his match in her.
There has been no change in his condition.
What grade did he get in English?
Please pay me in cash — preferably in tens and twenties.
The deposit can be in any legal tender, even in gold.
Beethoven's "Symphony No. 5" in C minor is among his most popular.
His speech was in French, but was simultaneously translated into eight languages.
When you write in cursive, it's illegible.
Military letters should be formal in tone, but not stilted.

### Verb

He that ears my land spares my team and gives me leave to in the crop.

### Adverb

Suddenly a strange man walked in.
Would you like that to take away or eat in?
He ran to the edge of the swimming pool and dived in.
They flew in from London last night.
For six hours the tide flows in, then for another six hours it flows out.
Bring the water to the boil and drop the vegetables in.
The show still didn't become interesting 20 minutes in.

### Noun

His parents got him an in with the company.

### Adjective

Is Mr. Smith in?
Little by little I pushed the snake into the basket, until finally all of it was in.
The bullet is about five centimetres in.
If the tennis ball bounces on the line then it's in.
I've discovered why the TV wasn't working – the plug wasn't in!
The replies to the questionnaires are now all in.
Skirts are in this year.
the in train (incoming train)
You can't get round the headland when the tide's in.
in by descent; in by purchase; in of the seisin of her husband
He is very in with the Joneses.
I need to keep in with the neighbours in case I ever need a favour from them.
I think that bird fancies you. You're in there, mate!
I'm three drinks in right now.
I was 500 dollars in when the stock crashed.

### Unit

The glass is 8 inches.
The glass is 8in.

## Of

Take the chicken out of the freezer.
He hasn't been well of late.
Finally she was relieved of the burden of caring for her sick husband.
He seemed devoid of human feelings.
The word is believed to be of Japanese origin.
Jesus of Nazareth
The invention was born of necessity.
It is said that she died of a broken heart.
What a lot of nonsense!
I'll have a dozen of those apples, please.
Welcome to the historic town of Harwich.
I'm not driving this wreck of a car.
I'm always thinking of you.
He told us the story of his journey to India.
This behaviour is typical of teenagers.
He is a friend of mine.
We want a larger slice of the cake.
The owner of the nightclub was arrested.
My companion seemed affable and easy of manner.
It's not that big of a deal.
I’ve not taken her out of a goodly long while.
After a delay of three hours, the plane finally took off.

## On

### Adjective

All the lights are on, so they must be home.
We had to ration our food because there was a war on.
Some of the cast went down with flu, but the show's still on.
That TV programme that you wanted to watch is on now.
This is her last song. You're on next!
Are we still on for tonight?
Mike just threw coffee onto Paul's lap. It's on now.
England need a hundred runs, with twenty-five overs remaining. Game on!
Your feet will soon warm up once your socks are on.
I was trying to drink out of the bottle while the top was still on!
Climbing up that steep ridge isn't on. We'll have to find another route.
He'd like to play the red next to the black spot, but that shot isn't on.
The captain moved two fielders to the on side.
Ponsonby-Smythe hit a thumping on drive.
If the player fails to hit the ball on, it's a foul.
He always has to be on, it's so exhausting.

### Adverb

turn the television on
The lid wasn't screwed on properly.
Put on your hat and gloves.
The policeman moved the tramp on.
Drive on past the railway station.
From now on things are going to be different.
and so on.
He rambled on and on.
Ten years on, nothing had changed in the village.

### Preposition

A vase of flowers stood on the table.
Please lie down on the couch.
The parrot was sitting on Jim's shoulder.
He had a scar on the side of his face.
There is a dirty smudge on this window.
The painting hangs on the wall.
The fruit ripened on the trees.
Should there be an accent on the "e"?
He wore old shoes on his feet.
The lighthouse that you can see is on the mainland.
The suspect is thought to still be on the campus.
We live on the edge of the city.
on the left, on the right, on the side, on the bottom.
The fleet is on the American coast.
on a bus, on a train, on a plane, on a ferry, on a yacht.
All of the responsibility is on him.
I put a bet on the winning horse.
tug on the rope; push hard on the door.
I stubbed my toe on an old tree stump.
I caught my fingernail on the door handle.
The rope snagged on a branch.
to play on a violin or piano.
A table can't stand on two legs.
After resting on his elbows, he stood on his toes, then walked on his heels.
The Tories are on twenty-five percent in this constituency.
The blue team are on six points and the red team on five.
I'm on question four.
Born on the 4th of July.
On Sunday I'm busy. I'll see you on Monday.
Can I see you on a different day?
Smith scored again on twelve minutes, doubling Mudchester Rovers' lead.
I was reading a book on history.
The city hosted the World Summit on the Information Society
I have no opinion on this subject.
I saw it on television.
Can't you see I'm on the phone?
My favorite shows are on BBC America.
I'll pay on card.
He travelled on false documents.
They planned an attack on London.
The soldiers mutinied and turned their guns on their officers.
Her words made a lasting impression on my mind.
What will be the effect on morale?
I haven't got any money on me.
On Jack's entry, William got up to leave.
On the addition of ammonia, a chemical reaction begins.
The drinks are on me tonight, boys.
The meal is on the house.
I had a terrible thirst on me.
Have pity or compassion on him.
He's on his lunch break.
I'm on nights all this week.
You've been on these antidepressants far too long.
I depended on them for assistance.
He will promise on certain conditions.
A curse on him!
Please don't tell on her and get her in trouble.

### Verb

Can you on the light? (switch on)

## To

### Particle

I want to leave.
He asked me what to do.
I have places to go and people to see.
To err is human.
Who am I to criticise? I've done worse things myself.
Precisely to get away from you was why I did what I did.
I need some more books to read and friends to go partying with.
If he hasn't read it yet, he ought to.
I went to the shops to buy some bread.

### Preposition

She looked to the heavens.
We are walking to the shop.
The water came right to the top of this wall.
The coconut fell to the ground.
I gave the book to him.
His face was beaten to a pulp.
I sang my baby to sleep.
Whisk the mixture to a smooth consistency.
He made several bad-taste jokes to groans from the audience.
I tried complaining, but it was to no effect.
It was to a large extent true.
We manufacture these parts to a very high tolerance.
This gauge is accurate to a second.
There's a lot of sense to what he says.
The name has a nice ring to it.
There are 100 pence to the pound.
It takes 2 to 4 weeks to process typical applications.
Three to the power of two is nine.
Three to the second is nine.
Three squared or three to the second power is nine.
What's the time? – It's quarter to four in the afternoon (or 3:45 pm).

### Adverb

Please push the door to. (close)

## With

### Preposition

He picked a fight with the class bully.
He went with his friends.
She owns a motorcycle with a sidecar.
Jim was listening to Bach with his eyes closed.
The match result was 10-5, with John scoring three goals.
With a heavy sigh, she looked around the empty room.
Four people were injured, with one of them in critical condition.
With their reputation on the line, they decided to fire their PR team.
We are with you all the way.
There are a number of problems with your plan.
What on Earth is wrong with my keyboard?
He was pleased with the outcome.
I’m upset with my father.
slain with robbers.
cut with a knife
I water my plants with this watering can. This is the watering can I water my plants with.
Find what you want instantly with our search engine.
They dismissed the meeting with a wave of their hand.
Speak with a confident voice.
With what/whose money? I have nothing left to buy groceries (with).
It was small and bumpy, with a tinge of orange.
There are lots of people with no homes after the wildfire.
Speak with confidence.
He spoke with sadness in his voice.
The sailors were infected with malaria.
overcome with happiness
green with envy; flushed with success
She was with Acme for twenty years before retiring last fall.
With your kind of body size, you shouldn’t be eating pizza at all.
That was a lot to explain; are you still with me?

### Adverb

Do you want to come with?



================================================
FILE: harper-core/tests/text/Part-of-speech tagging.md
================================================
<!--
source: https://en.wikipedia.org/w/index.php?title=Part-of-speech_tagging&oldid=1275774341
license: CC BY-SA 4.0
-->

# Part-of-speech tagging

In corpus linguistics, part-of-speech tagging (POS tagging or PoS tagging or
POST), also called grammatical tagging is the process of marking up a word in a
text (corpus) as corresponding to a particular part of speech, based on both its
definition and its context. A simplified form of this is commonly taught to
school-age children, in the identification of words as nouns, verbs, adjectives,
adverbs, etc.

Once performed by hand, POS tagging is now done in the context of computational
linguistics, using algorithms which associate discrete terms, as well as hidden
parts of speech, by a set of descriptive tags. POS-tagging algorithms fall into
two distinctive groups: rule-based and stochastic. E. Brill's tagger, one of the
first and most widely used English POS-taggers, employs rule-based algorithms.

## Principle

Part-of-speech tagging is harder than just having a list of words and their
parts of speech, because some words can represent more than one part of speech
at different times, and because some parts of speech are complex. This is not
rare—in natural languages (as opposed to many artificial languages), a large
percentage of word-forms are ambiguous. For example, even "dogs", which is
usually thought of as just a plural noun, can also be a verb:

> The sailor dogs the hatch.

Correct grammatical tagging will reflect that "dogs" is here used as a verb, not
as the more common plural noun. Grammatical context is one way to determine
this; semantic analysis can also be used to infer that "sailor" and "hatch"
implicate "dogs" as 1) in the nautical context and 2) an action applied to the
object "hatch" (in this context, "dogs" is a nautical term meaning "fastens (a
watertight door) securely").

### Tag sets

Schools commonly teach that there are 9 parts of speech in English: noun, verb,
article, adjective, preposition, pronoun, adverb, conjunction, and interjection.
However, there are clearly many more categories and sub-categories. For nouns,
the plural, possessive, and singular forms can be distinguished. In many
languages words are also marked for their "case" (role as subject, object,
etc.), grammatical gender, and so on; while verbs are marked for tense, aspect,
and other things. In some tagging systems, different inflections of the same
root word will get different parts of speech, resulting in a large number of
tags. For example, NN for singular common nouns, NNS for plural common nouns, NP
for singular proper nouns (see the POS tags used in the Brown Corpus). Other
tagging systems use a smaller number of tags and ignore fine differences or
model them as features somewhat independent from part-of-speech.

In part-of-speech tagging by computer, it is typical to distinguish from 50 to
150 separate parts of speech for English. Work on stochastic methods for tagging
Koine Greek (DeRose 1990) has used over 1,000 parts of speech and found that
about as many words were ambiguous in that language as in English. A
morphosyntactic descriptor in the case of morphologically rich languages is
commonly expressed using very short mnemonics, such as Ncmsan for Category=Noun,
Type = common, Gender = masculine, Number = singular, Case = accusative, Animate
= no.

The most popular "tag set" for POS tagging for American English is probably the
Penn tag set, developed in the Penn Treebank project. It is largely similar to
the earlier Brown Corpus and LOB Corpus tag sets, though much smaller. In
Europe, tag sets from the Eagles Guidelines see wide use and include versions
for multiple languages.

POS tagging work has been done in a variety of languages, and the set of POS
tags used varies greatly with language. Tags usually are designed to include
overt morphological distinctions, although this leads to inconsistencies such as
case-marking for pronouns but not nouns in English, and much larger
cross-language differences. The tag sets for heavily inflected languages such as
Greek and Latin can be very large; tagging words in agglutinative languages such
as Inuit languages may be virtually impossible. At the other extreme, Petrov et
al. have proposed a "universal" tag set, with 12 categories (for example, no
subtypes of nouns, verbs, punctuation, and so on). Whether a very small set of
very broad tags or a much larger set of more precise ones is preferable, depends
on the purpose at hand. Automatic tagging is easier on smaller tag-sets.

## History

### The Brown Corpus

Research on part-of-speech tagging has been closely tied to corpus linguistics.
The first major corpus of English for computer analysis was the Brown Corpus
developed at Brown University by Henry Kučera and W. Nelson Francis, in the
mid-1960s. It consists of about 1,000,000 words of running English prose text,
made up of 500 samples from randomly chosen publications. Each sample is 2,000
or more words (ending at the first sentence-end after 2,000 words, so that the
corpus contains only complete sentences).

The Brown Corpus was painstakingly "tagged" with part-of-speech markers over
many years. A first approximation was done with a program by Greene and Rubin,
which consisted of a huge handmade list of what categories could co-occur at
all. For example, article then noun can occur, but article then verb (arguably)
cannot. The program got about 70% correct. Its results were repeatedly reviewed
and corrected by hand, and later users sent in errata so that by the late 70s
the tagging was nearly perfect (allowing for some cases on which even human
speakers might not agree).

This corpus has been used for innumerable studies of word-frequency and of
part-of-speech and inspired the development of similar "tagged" corpora in many
other languages. Statistics derived by analyzing it formed the basis for most
later part-of-speech tagging systems, such as CLAWS and VOLSUNGA. However, by
this time (2005) it has been superseded by larger corpora such as the 100
million word British National Corpus, even though larger corpora are rarely so
thoroughly curated.

For some time, part-of-speech tagging was considered an inseparable part of
natural language processing, because there are certain cases where the correct
part of speech cannot be decided without understanding the semantics or even the
pragmatics of the context. This is extremely expensive, especially because
analyzing the higher levels is much harder when multiple part-of-speech
possibilities must be considered for each word.

### Use of hidden Markov models

In the mid-1980s, researchers in Europe began to use hidden Markov models (HMMs)
to disambiguate parts of speech, when working to tag the Lancaster-Oslo-Bergen
Corpus of British English. HMMs involve counting cases (such as from the Brown
Corpus) and making a table of the probabilities of certain sequences. For
example, once you've seen an article such as 'the', perhaps the next word is a
noun 40% of the time, an adjective 40%, and a number 20%. Knowing this, a
program can decide that "can" in "the can" is far more likely to be a noun than
a verb or a modal. The same method can, of course, be used to benefit from
knowledge about the following words.

More advanced ("higher-order") HMMs learn the probabilities not only of pairs
but triples or even larger sequences. So, for example, if you've just seen a
noun followed by a verb, the next item may be very likely a preposition,
article, or noun, but much less likely another verb.

When several ambiguous words occur together, the possibilities multiply.
However, it is easy to enumerate every combination and to assign a relative
probability to each one, by multiplying together the probabilities of each
choice in turn. The combination with the highest probability is then chosen. The
European group developed CLAWS, a tagging program that did exactly this and
achieved accuracy in the 93–95% range.

Eugene Charniak points out in Statistical techniques for natural language
parsing (1997) that merely assigning the most common tag to each known word and
the tag "proper noun" to all unknowns will approach 90% accuracy because many
words are unambiguous, and many others only rarely represent their less-common
parts of speech.

CLAWS pioneered the field of HMM-based part of speech tagging but was quite
expensive since it enumerated all possibilities. It sometimes had to resort to
backup methods when there were simply too many options (the Brown Corpus
contains a case with 17 ambiguous words in a row, and there are words such as
"still" that can represent as many as 7 distinct parts of speech.

HMMs underlie the functioning of stochastic taggers and are used in various
algorithms one of the most widely used being the bi-directional inference
algorithm.

### Dynamic programming methods

In 1987, Steven DeRose and Kenneth W. Church independently developed dynamic
programming algorithms to solve the same problem in vastly less time. Their
methods were similar to the Viterbi algorithm known for some time in other
fields. DeRose used a table of pairs, while Church used a table of triples and a
method of estimating the values for triples that were rare or nonexistent in the
Brown Corpus (an actual measurement of triple probabilities would require a much
larger corpus). Both methods achieved an accuracy of over 95%. DeRose's 1990
dissertation at Brown University included analyses of the specific error types,
probabilities, and other related data, and replicated his work for Greek, where
it proved similarly effective.

These findings were surprisingly disruptive to the field of natural language
processing. The accuracy reported was higher than the typical accuracy of very
sophisticated algorithms that integrated part of speech choice with many higher
levels of linguistic analysis: syntax, morphology, semantics, and so on. CLAWS,
DeRose's and Church's methods did fail for some of the known cases where
semantics is required, but those proved negligibly rare. This convinced many in
the field that part-of-speech tagging could usefully be separated from the other
levels of processing; this, in turn, simplified the theory and practice of
computerized language analysis and encouraged researchers to find ways to
separate other pieces as well. Markov Models became the standard method for the
part-of-speech assignment.

#### Unsupervised taggers

The methods already discussed involve working from a pre-existing corpus to
learn tag probabilities. It is, however, also possible to bootstrap using
"unsupervised" tagging. Unsupervised tagging techniques use an untagged corpus
for their training data and produce the tagset by induction. That is, they
observe patterns in word use, and derive part-of-speech categories themselves.
For example, statistics readily reveal that "the", "a", and "an" occur in
similar contexts, while "eat" occurs in very different ones. With sufficient
iteration, similarity classes of words emerge that are remarkably similar to
those human linguists would expect; and the differences themselves sometimes
suggest valuable new insights.

These two categories can be further subdivided into rule-based, stochastic, and
neural approaches.

#### Other taggers and methods

Some current major algorithms for part-of-speech tagging include the Viterbi
algorithm, Brill tagger, Constraint Grammar, and the Baum-Welch algorithm (also
known as the forward-backward algorithm). Hidden Markov model and visible Markov
model taggers can both be implemented using the Viterbi algorithm. The
rule-based Brill tagger is unusual in that it learns a set of rule patterns, and
then applies those patterns rather than optimizing a statistical quantity.

Many machine learning methods have also been applied to the problem of POS
tagging. Methods such as SVM, maximum entropy classifier, perceptron, and
nearest-neighbor have all been tried, and most can achieve accuracy above
95%.[citation needed]

A direct comparison of several methods is reported (with references) at the ACL
Wiki. This comparison uses the Penn tag set on some of the Penn Treebank data,
so the results are directly comparable. However, many significant taggers are
not included (perhaps because of the labor involved in reconfiguring them for
this particular dataset). Thus, it should not be assumed that the results
reported here are the best that can be achieved with a given approach; nor even
the best that have been achieved with a given approach.

In 2014, a paper reporting using the structure regularization method for
part-of-speech tagging, achieving 97.36% on a standard benchmark dataset.



================================================
FILE: harper-core/tests/text/Spell.md
================================================
# Spell

This document contains example sentences with misspelled words that we want to test the spell checker on.

## Example Sentences

My favourite color is blu.
I must defend my honour!
I recognize that you recognise me.
I analyze how you infantilize me.
I analyse how you infantilise me.
Careful, traveller!
At the centre of the theatre I dropped a litre of coke.



================================================
FILE: harper-core/tests/text/Spell.US.md
================================================
# Spell

This document contains a list of words spelled correctly in some dialects of English, but not American English. This is designed to test the spelling suggestions we give for such mistakes.

To achieve this, the filename of this file contains `.US.`, which will tell the snapshot generator to use the American dialect, rather than trying to use an automatically detected dialect.

## Words

- Afterwards.
- Centre.
- Labelled.
- Flavour.
- Favoured.
- Honour.
- Grey.
- Quarrelled.
- Quarrelling.
- Recognised.
- Neighbour.
- Neighbouring.
- Clamour.
- Theatre.
- Analyse.



================================================
FILE: harper-core/tests/text/Swear.md
================================================
# Swears

This documents tests that different forms/variations of swears are tagged as such.

## Examples

One turd, two turds.

I fart, you're farting, he farts, she farted.



================================================
FILE: harper-core/tests/text/The Constitution of the United States.md
================================================
<!-- source: https://github.com/JesseKPhillips/USA-Constitution/blob/4cfdd130709fa7e8db998383b6917ba33b402ec6/Constitution.md -->

# The Constitution Of The United States Of America

**We the People** of the United States, in Order to form a more perfect Union,
establish Justice, insure domestic Tranquility, provide for the common defence,
promote the general Welfare, and secure the Blessings of Liberty to ourselves
and our Posterity, do ordain and establish this Constitution for the United
States of America.

## Article. I.

### Section. 1.

All legislative Powers herein granted shall be vested in a
Congress of the United States, which shall consist of a Senate and House of
Representatives. Congress shall make no law respecting an establishment of
religion, or prohibiting the free exercise thereof; or abridging the freedom of
speech, or of the press; or the right of the people peaceably to assemble, and
to petition the government for a redress of grievances.

No person shall be a Senator or Representative in Congress, or elector of
President and Vice President, or hold any office, civil or military, under the
United States, or under any State, who, having previously taken an oath, as a
member of Congress, or as an officer of the United States, or as a member of
any State legislature, or as an executive or judicial officer of any State, to
support the Constitution of the United States, shall have engaged in
insurrection or rebellion against the same, or given aid or comfort to the
enemies thereof. But Congress may, by a vote of two-thirds of each House,
remove such disability.

The terms of Senators and Representatives shall end at noon on the 3d day of
January, of the years in which such terms end; and the terms of their
successors shall then begin.

### Section. 2.

The House of Representatives shall be composed of Members
chosen every second Year by the People of the several States, and the Electors
in each State shall have the Qualifications requisite for Electors of the most
numerous Branch of the State Legislature.

No Person shall be a Representative who shall not have attained to the Age of
twenty five Years, and been seven Years a Citizen of the United States, and who
shall not, when elected, be an Inhabitant of that State in which he shall be
chosen.

Representatives shall be apportioned among the several States according to
their respective numbers, counting the whole number of persons in each State,
excluding Indians not taxed. But when the right to vote at any election for the
choice of electors for President and Vice President of the United States,
Representatives in Congress, the Executive and Judicial officers of a State, or
the members of the Legislature thereof, is denied to any of the male
inhabitants of such State, being twenty-one years of age, and citizens of the
United States, or in any way abridged, except for participation in rebellion,
or other crime, the basis of representation therein shall be reduced in the
proportion which the number of such male citizens shall bear to the whole
number of male citizens twenty-one years of age in such State. The actual
Enumeration shall be made within three Years after the first Meeting of the
Congress of the United States, and within every subsequent Term of ten Years,
in such Manner as they shall by Law direct. The Number of Representatives shall
not exceed one for every thirty Thousand, but each State shall have at Least
one Representative; and until such enumeration shall be made, the State of New
Hampshire shall be entitled to chuse three, Massachusetts eight, Rhode-Island
and Providence Plantations one, Connecticut five, New-York six, New Jersey
four, Pennsylvania eight, Delaware one, Maryland six, Virginia ten, North
Carolina five, South Carolina five, and Georgia three.

When vacancies happen in the Representation from any State, the Executive
Authority thereof shall issue Writs of Election to fill such Vacancies.

The House of Representatives shall chuse their Speaker and other Officers; and
shall have the sole Power of Impeachment.



### Section. 3.

The Senate of the United States shall be composed of two
Senators from each State, elected by the people thereof, for six years; and
each Senator shall have one vote. The electors in each State shall have the
qualifications requisite for electors of the most numerous branch of the State
legislatures.

Immediately after they shall be assembled in Consequence of the first Election,
they shall be divided as equally as may be into three Classes. The Seats of the
Senators of the first Class shall be vacated at the Expiration of the second
Year, of the second Class at the Expiration of the fourth Year, and of the
third Class at the Expiration of the sixth Year, so that one third may be
chosen every second Year; and when vacancies happen in the representation of
any State in the Senate, the executive authority of such State shall issue
writs of election to fill such vacancies: Provided, That the legislature of any
State may empower the executive thereof to make temporary appointments until
the people fill the vacancies by election as the legislature may direct.

No Person shall be a Senator who shall not have attained to the Age of thirty
Years, and been nine Years a Citizen of the United States, and who shall not,
when elected, be an Inhabitant of that State for which he shall be chosen.

The Vice President of the United States shall be President of the Senate, but
shall have no Vote, unless they be equally divided.

The Senate shall chuse their other Officers, and also a President pro tempore,
in the Absence of the Vice President, or when he shall exercise the Office of
President of the United States.

The Senate shall have the sole Power to try all Impeachments. When sitting for
that Purpose, they shall be on Oath or Affirmation. When the President of the
United States is tried, the Chief Justice shall preside: And no Person shall be
convicted without the Concurrence of two thirds of the Members present.

Judgment in Cases of impeachment shall not extend further than to removal from
Office, and disqualification to hold and enjoy any Office of honor, Trust or
Profit under the United States: but the Party convicted shall nevertheless be
liable and subject to Indictment, Trial, Judgment and Punishment, according to
Law.



### Section. 4.

The Times, Places and Manner of holding Elections for Senators
and Representatives, shall be prescribed in each State by the Legislature
thereof; but the Congress may at any time by Law make or alter such
Regulations, except as to the Places of chusing Senators.

The Congress shall assemble at least once in every year, and such meeting shall
begin at noon on the 3d day of January, unless they shall by law appoint a
different day.

### Section. 5.

Each House shall be the Judge of the Elections, Returns and
Qualifications of its own Members, and a Majority of each shall constitute a
Quorum to do Business; but a smaller Number may adjourn from day to day, and
may be authorized to compel the Attendance of absent Members, in such Manner,
and under such Penalties as each House may provide.

Each House may determine the Rules of its Proceedings, punish its Members for
disorderly Behaviour, and, with the Concurrence of two thirds, expel a Member.

Each House shall keep a Journal of its Proceedings, and from time to time
publish the same, excepting such Parts as may in their Judgment require
Secrecy; and the Yeas and Nays of the Members of either House on any question
shall, at the Desire of one fifth of those Present, be entered on the Journal.

Neither House, during the Session of Congress, shall, without the Consent of
the other, adjourn for more than three days, nor to any other Place than that
in which the two Houses shall be sitting.

### Section. 6.

The Senators and Representatives shall receive a Compensation
for their Services, to be ascertained by Law, and paid out of the Treasury of
the United States. They shall in all Cases, except Treason, Felony and Breach
of the Peace, be privileged from Arrest during their Attendance at the Session
of their respective Houses, and in going to and returning from the same; and
for any Speech or Debate in either House, they shall not be questioned in any
other Place.

No Senator or Representative shall, during the Time for which he was elected,
be appointed to any civil Office under the Authority of the United States,
which shall have been created, or the Emoluments whereof shall have been
encreased during such time; and no Person holding any Office under the United
States, shall be a Member of either House during his Continuance in Office. No
law, varying the compensation for the services of the Senators and
Representatives, shall take effect, until an election of Representatives shall
have intervened.


### Section. 7.

All Bills for raising Revenue shall originate in the House of
Representatives; but the Senate may propose or concur with Amendments as on
other Bills.

Every Bill which shall have passed the House of Representatives and the Senate,
shall, before it become a Law, be presented to the President of the United
States; If he approve he shall sign it, but if not he shall return it, with his
Objections to that House in which it shall have originated, who shall enter the
Objections at large on their Journal, and proceed to reconsider it. If after
such Reconsideration two thirds of that House shall agree to pass the Bill, it
shall be sent, together with the Objections, to the other House, by which it
shall likewise be reconsidered, and if approved by two thirds of that House, it
shall become a Law. But in all such Cases the Votes of both Houses shall be
determined by yeas and Nays, and the Names of the Persons voting for and
against the Bill shall be entered on the Journal of each House respectively. If
any Bill shall not be returned by the President within ten Days (Sundays
excepted) after it shall have been presented to him, the Same shall be a Law,
in like Manner as if he had signed it, unless the Congress by their Adjournment
prevent its Return, in which Case it shall not be a Law.

Every Order, Resolution, or Vote to which the Concurrence of the Senate and
House of Representatives may be necessary (except on a question of Adjournment)
shall be presented to the President of the United States; and before the Same
shall take Effect, shall be approved by him, or being disapproved by him, shall
be repassed by two thirds of the Senate and House of Representatives, according
to the Rules and Limitations prescribed in the Case of a Bill.

### Section. 8.

The Congress shall have Power To lay and collect Taxes, Duties,
Imposts and Excises, to pay the Debts and provide for the common Defence and
general Welfare of the United States; but all Duties, Imposts and Excises shall
be uniform throughout the United States;

1. To borrow Money on the credit of the United States;

2. To regulate Commerce with foreign Nations, and among the several States, and
with the Indian Tribes;

3. To establish an uniform Rule of Naturalization, and uniform Laws on the subject
of Bankruptcies throughout the United States;

4. To coin Money, regulate the Value thereof, and of foreign Coin, and fix the
Standard of Weights and Measures;

5. To provide for the Punishment of counterfeiting the Securities and current Coin
of the United States;

6. To establish Post Offices and post Roads;

7. To promote the Progress of Science and useful Arts, by securing for limited
Times to Authors and Inventors the exclusive Right to their respective Writings
and Discoveries;

8. To constitute Tribunals inferior to the supreme Court;

9. To define and punish Piracies and Felonies committed on the high Seas, and
Offences against the Law of Nations;

10. To declare War, grant Letters of Marque and Reprisal, and make Rules concerning
Captures on Land and Water;

11. To raise and support Armies, but no Appropriation of Money to that Use shall be
for a longer Term than two Years;

12. To provide and maintain a Navy;

13. To make Rules for the Government and Regulation of the land and naval Forces;

14. To provide for calling forth the Militia to execute the Laws of the Union,
suppress Insurrections and repel Invasions;

15. To provide for organizing, arming, and disciplining, the Militia, and for
governing such Part of them as may be employed in the Service of the United
States, reserving to the States respectively, the Appointment of the Officers,
and the Authority of training the Militia according to the discipline
prescribed by Congress;

16. To exercise exclusive Legislation in all Cases whatsoever, over such District
(not exceeding ten Miles square) as may, by Cession of particular States, and
the Acceptance of Congress, become the Seat of the Government of the United
States, and to exercise like Authority over all Places purchased by the Consent
of the Legislature of the State in which the Same shall be, for the Erection of
Forts, Magazines, Arsenals, dock-Yards, and other needful Buildings;—And

17. To make all Laws which shall be necessary and proper for carrying into
Execution the foregoing Powers, and all other Powers vested by this
Constitution in the Government of the United States, or in any Department or
Officer thereof.

### Section. 9.

The Migration or Importation of such Persons as any of the
States now existing shall think proper to admit, shall not be prohibited by the
Congress prior to the Year one thousand eight hundred and eight, but a Tax or
duty may be imposed on such Importation, not exceeding ten dollars for each
Person.

The Privilege of the Writ of Habeas Corpus shall not be suspended, unless when
in Cases of Rebellion or Invasion the public Safety may require it.

No Bill of Attainder or ex post facto Law shall be passed.

No Capitation, or other direct, Tax shall be laid, unless in Proportion to the
Census or Enumeration herein before directed to be taken. Congress shall have
power to lay and collect taxes on incomes, from whatever source derived,
without apportionment among the several States, and without regard to any
census or enumeration.

No Tax or Duty shall be laid on Articles exported from any State.

No Preference shall be given by any Regulation of Commerce or Revenue to the
Ports of one State over those of another: nor shall Vessels bound to, or from,
one State, be obliged to enter, clear, or pay Duties in another.

No Money shall be drawn from the Treasury, but in Consequence of Appropriations
made by Law; and a regular Statement and Account of the Receipts and
Expenditures of all public Money shall be published from time to time.

No Title of Nobility shall be granted by the United States: And no Person
holding any Office of Profit or Trust under them, shall, without the Consent of
the Congress, accept of any present, Emolument, Office, or Title, of any kind
whatever, from any King, Prince, or foreign State.

The right of citizens of the United States to vote in any primary or other
election for President or Vice President, for electors for President or Vice
President, or for Senator or Representative in Congress, shall not be denied or
abridged by the United States or any State by reason of failure to pay any poll
tax or other tax.

### Section. 10.

No State shall enter into any Treaty, Alliance, or
Confederation; grant Letters of Marque and Reprisal; coin Money; emit Bills of
Credit; make any Thing but gold and silver Coin a Tender in Payment of Debts;
pass any Bill of Attainder, ex post facto Law, or Law impairing the Obligation
of Contracts, or grant any Title of Nobility.

No State shall, without the Consent of the Congress, lay any Imposts or Duties
on Imports or Exports, except what may be absolutely necessary for executing
it's inspection Laws: and the net Produce of all Duties and Imposts, laid by
any State on Imports or Exports, shall be for the Use of the Treasury of the
United States; and all such Laws shall be subject to the Revision and Controul
of the Congress.

No State shall, without the Consent of Congress, lay any Duty of Tonnage, keep
Troops, or Ships of War in time of Peace, enter into any Agreement or Compact
with another State, or with a foreign Power, or engage in War, unless actually
invaded, or in such imminent Danger as will not admit of delay.

## Article. II.

### Section. 1.

The executive Power shall be vested in a President of the
United States of America. He shall hold his Office during the Term of four
Years ending at noon on the 20th day of January, and, together with the Vice
President, chosen for the same Term, be elected, as follows

Each State shall appoint, in such Manner as the Legislature thereof may direct,
a Number of Electors, equal to the whole Number of Senators and Representatives
to which the State may be entitled in the Congress: but no Senator or
Representative, or Person holding an Office of Trust or Profit under the United
States, shall be appointed an Elector.

#### SubSection. 1.

The Electors shall meet in their respective states, and vote
by ballot for President and Vice-President, one of whom, at least, shall not be
an inhabitant of the same state with themselves; they shall name in their
ballots the person voted for as President, and in distinct ballots the person
voted for as Vice-President, and they shall make distinct lists of all persons
voted for as President, and all persons voted for as Vice-President and of the
number of votes for each, which lists they shall sign and certify, and transmit
sealed to the seat of the government of the United States, directed to the
President of the Senate;—The President of the Senate shall, in the presence of
the Senate and House of Representatives, open all the certificates and the
votes shall then be counted;—The person having the greatest Number of votes for
President, shall be the President, if such number be a majority of the whole
number of Electors appointed; and if no person have such majority, then from
the persons having the highest numbers not exceeding three on the list of those
voted for as President, the House of Representatives shall choose immediately,
by ballot, the President. But in choosing the President, the votes shall be
taken by states, the representation from each state having one vote; a quorum
for this purpose shall consist of a member or members from two-thirds of the
states, and a majority of all the states shall be necessary to a choice. [If,
at the time fixed for the beginning of the term of the President, the President
elect shall have died, the Vice President elect shall become President. If a
President shall not have been chosen before the time fixed for the beginning of
his term, or if the President elect shall have failed to qualify, then the Vice
President elect shall act as President until a President shall have qualified;
and the Congress may by law provide for the case wherein neither a President
elect nor a Vice President elect shall have qualified, declaring who shall then
act as President, or the manner in which one who is to act shall be selected,
and such person shall act accordingly until a President or Vice President shall
have qualified.The Congress may by law provide for the case of the death of any
of the persons from whom the House of Representatives may choose a President
whenever the right of choice shall have devolved upon them, and for the case of
the death of any of the persons from whom the Senate may choose a Vice
President whenever the right of choice shall have devolved upon them.]The
person having the greatest number of votes as Vice-President, shall be the
Vice-President, if such number be a majority of the whole number of Electors
appointed, and if no person have a majority, then from the two highest numbers
on the list, the Senate shall choose the Vice-President; a quorum for the
purpose shall consist of two-thirds of the whole number of Senators, and a
majority of the whole number shall be necessary to a choice. But no person
constitutionally ineligible to the office of President shall be eligible to
that of Vice-President of the United States.


The Congress may determine the Time of chusing the Electors, and the Day on
which they shall give their Votes; which Day shall be the same throughout the
United States.


#### SubSection. 2

No Person except a natural born Citizen, or a Citizen of the
United States, at the time of the Adoption of this Constitution, shall be
eligible to the Office of President; neither shall any Person be eligible to
that Office who shall not have attained to the Age of thirty five Years, and
been fourteen Years a Resident within the United States.

No person shall be elected to the office of the President more than twice, and
no person who has held the office of President, or acted as President, for more
than two years of a term to which some other person was elected President shall
be elected to the office of the President more than once. But this article
shall not apply to any person holding the office of President when this article
was proposed by the Congress, and shall not prevent any person who may be
holding the office of President, or acting as President, during the term within
which this article becomes operative from holding the office of President or
acting as President during the remainder of such term.

#### SubSection 3.

In case of the removal of the President from office or of his
death or resignation, the Vice President shall become President.

Whenever there is a vacancy in the office of the Vice President, the President
shall nominate a Vice President who shall take office upon confirmation by a
majority vote of both Houses of Congress.

Whenever the President transmits to the President pro tempore of the Senate and
the Speaker of the House of Representatives his written declaration that he is
unable to discharge the powers and duties of his office, and until he transmits
to them a written declaration to the contrary, such powers and duties shall be
discharged by the Vice President as Acting President.

Whenever the Vice President and a majority of either the principal officers of
the executive departments or of such other body as Congress may by law provide,
transmit to the President pro tempore of the Senate and the Speaker of the
House of Representatives their written declaration that the President is unable
to discharge the powers and duties of his office, the Vice President shall
immediately assume the powers and duties of the office as Acting President.

Thereafter, when the President transmits to the President pro tempore of the
Senate and the Speaker of the House of Representatives his written declaration
that no inability exists, he shall resume the powers and duties of his office
unless the Vice President and a majority of either the principal officers of
the executive department or of such other body as Congress may by law provide,
transmit within four days to the President pro tempore of the Senate and the
Speaker of the House of Representatives their written declaration that the
President is unable to discharge the powers and duties of his office. Thereupon
Congress shall decide the issue, assembling within forty-eight hours for that
purpose if not in session. If the Congress, within twenty-one days after
receipt of the latter written declaration, or, if Congress is not in session,
within twenty-one days after Congress is required to assemble, determines by
two-thirds vote of both Houses that the President is unable to discharge the
powers and duties of his office, the Vice President shall continue to discharge
the same as Acting President; otherwise, the President shall resume the powers
and duties of his office.


#### SubSection 4.

The President shall, at stated Times, receive for his
Services, a Compensation, which shall neither be encreased nor diminished
during the Period for which he shall have been elected, and he shall not
receive within that Period any other Emolument from the United States, or any
of them.

Before he enter on the Execution of his Office, he shall take the following
Oath or Affirmation:-- "I do solemnly swear (or affirm) that I will faithfully
execute the Office of President of the United States, and will to the best of
my Ability, preserve, protect and defend the Constitution of the United
States."

#### SubSection 5.

The District constituting the seat of Government of the
United States shall appoint in such manner as the Congress may direct:

A number of electors of President and Vice President equal to the whole number
of Senators and Representatives in Congress to which the District would be
entitled if it were a State, but in no event more than the least populous
State; they shall be in addition to those appointed by the States, but they
shall be considered, for the purposes of the election of President and Vice
President, to be electors appointed by a State; and they shall meet in the
District and perform such duties as provided by this article of the
Constitution.

### Section. 2.

The President shall be Commander in Chief of the Army and Navy
of the United States, and of the Militia of the several States, when called
into the actual Service of the United States; he may require the Opinion, in
writing, of the principal Officer in each of the executive Departments, upon
any Subject relating to the Duties of their respective Offices, and he shall
have Power to grant Reprieves and Pardons for Offences against the United
States, except in Cases of Impeachment.

He shall have Power, by and with the Advice and Consent of the Senate, to make
Treaties, provided two thirds of the Senators present concur; and he shall
nominate, and by and with the Advice and Consent of the Senate, shall appoint
Ambassadors, other public Ministers and Consuls, Judges of the supreme Court,
and all other Officers of the United States, whose Appointments are not herein
otherwise provided for, and which shall be established by Law: but the Congress
may by Law vest the Appointment of such inferior Officers, as they think
proper, in the President alone, in the Courts of Law, or in the Heads of
Departments.

The President shall have Power to fill up all Vacancies that may happen during
the Recess of the Senate, by granting Commissions which shall expire at the End
of their next Session.

No soldier shall, in time of peace be quartered in any house, without the
consent of the owner, nor in time of war, but in a manner to be prescribed by
law.

### Section. 3.

He shall from time to time give to the Congress Information of
the State of the Union, and recommend to their Consideration such Measures as
he shall judge necessary and expedient; he may, on extraordinary Occasions,
convene both Houses, or either of them, and in Case of Disagreement between
them, with Respect to the Time of Adjournment, he may adjourn them to such Time
as he shall think proper; he shall receive Ambassadors and other public
Ministers; he shall take Care that the Laws be faithfully executed, and shall
Commission all the Officers of the United States.

### Section. 4.

The President, Vice President and all civil Officers of the
United States, shall be removed from Office on Impeachment for, and Conviction
of, Treason, Bribery, or other high Crimes and Misdemeanors.

## Article. III.

### Section. 1.

The judicial Power of the United States, shall be vested in
one supreme Court, and in such inferior Courts as the Congress may from time to
time ordain and establish. The Judges, both of the supreme and inferior Courts,
shall hold their Offices during good Behaviour, and shall, at stated Times,
receive for their Services, a Compensation, which shall not be diminished
during their Continuance in Office.

### Section. 2.

The judicial Power shall extend to all Cases, in Law and
Equity, arising under this Constitution, the Laws of the United States, and
Treaties made, or which shall be made, under their Authority;—to all Cases
affecting Ambassadors, other public Ministers and Consuls;—to all Cases of
admiralty and maritime Jurisdiction;—to Controversies to which the United
States shall be a Party;—to Controversies between two or more States;—between
Citizens of different States, —between Citizens of the same State claiming
Lands under Grants of different States.


In all Cases affecting Ambassadors, other public Ministers and Consuls, and
those in which a State shall be Party, the supreme Court shall have original
Jurisdiction. In all the other Cases before mentioned, the supreme Court shall
have appellate Jurisdiction, both as to Law and Fact, with such Exceptions, and
under such Regulations as the Congress shall make.

The Trial of all Crimes, except in Cases of Impeachment, shall be by Jury; and
such Trial shall be held in the State where the said Crimes shall have been
committed; but when not committed within any State, the Trial shall be at such
Place or Places as the Congress may by Law have directed.

### Section. 3.

Treason against the United States, shall consist only in
levying War against them, or in adhering to their Enemies, giving them Aid and
Comfort. No Person shall be convicted of Treason unless on the Testimony of two
Witnesses to the same overt Act, or on Confession in open Court.

The Congress shall have Power to declare the Punishment of Treason, but no
Attainder of Treason shall work Corruption of Blood, or Forfeiture except
during the Life of the Person attainted.

### Section. 4.

The right of the people to be secure in their persons, houses,
papers, and effects, against unreasonable searches and seizures, shall not be
violated, and no warrants shall issue, but upon probable cause, supported by
oath or affirmation, and particularly describing the place to be searched, and
the persons or things to be seized.

No person shall be held to answer for a capital, or otherwise infamous crime,
unless on a presentment or indictment of a grand jury, except in cases arising
in the land or naval forces, or in the militia, when in actual service in time
of war or public danger; nor shall any person be subject for the same offense
to be twice put in jeopardy of life or limb; nor shall be compelled in any
criminal case to be a witness against himself, nor be deprived of life,
liberty, or property, without due process of law; nor shall private property be
taken for public use, without just compensation.

In all criminal prosecutions, the accused shall enjoy the right to a speedy and
public trial, by an impartial jury of the state and district wherein the crime
shall have been committed, which district shall have been previously
ascertained by law, and to be informed of the nature and cause of the
accusation; to be confronted with the witnesses against him; to have compulsory
process for obtaining witnesses in his favor, and to have the assistance of
counsel for his defense.

In suits at common law, where the value in controversy shall exceed twenty
dollars, the right of trial by jury shall be preserved, and no fact tried by a
jury, shall be otherwise reexamined in any court of the United States, than
according to the rules of the common law.

Excessive bail shall not be required, nor excessive fines imposed, nor cruel
and unusual punishments inflicted.

## Article. IV.

### Section. 1.

Full Faith and Credit shall be given in each State to the
public Acts, Records, and judicial Proceedings of every other State. And the
Congress may by general Laws prescribe the Manner in which such Acts, Records
and Proceedings shall be proved, and the Effect thereof.

### Section. 2.

All persons born or naturalized in the United States, and
subject to the jurisdiction thereof, are citizens of the United States and of
the State wherein they reside. No State shall make or enforce any law which
shall abridge the privileges or immunities of citizens of the United States;
nor shall any State deprive any person of life, liberty, or property, without
due process of law; nor deny to any person within its jurisdiction the equal
protection of the laws.

The right of citizens of the United States, who are eighteen years of age or
older, to vote shall not be denied or abridged by the United States or by any
State on account of age, sex, race, color, or previous condition of servitude.

A Person charged in any State with Treason, Felony, or other Crime, who shall
flee from Justice, and be found in another State, shall on Demand of the
executive Authority of the State from which he fled, be delivered up, to be
removed to the State having Jurisdiction of the Crime.

Neither slavery nor involuntary servitude, except as a punishment for crime
whereof the party shall have been duly convicted, shall exist within the United
States, or any place subject to their jurisdiction. No Person held to Service
or Labour in one State, under the Laws thereof, escaping into another, shall,
in Consequence of any Law or Regulation therein, be discharged from such
Service or Labour, but shall be delivered up on Claim of the Party to whom such
Service or Labour may be due.

### Section. 3.

New States may be admitted by the Congress into this Union; but
no new State shall be formed or erected within the Jurisdiction of any other
State; nor any State be formed by the Junction of two or more States, or Parts
of States, without the Consent of the Legislatures of the States concerned as
well as of the Congress.

The Congress shall have Power to dispose of and make all needful Rules and
Regulations respecting the Territory or other Property belonging to the United
States; and nothing in this Constitution shall be so construed as to Prejudice
any Claims of the United States, or of any particular State.

### Section. 4.

The United States shall guarantee to every State in this Union
a Republican Form of Government, and shall protect each of them against
Invasion; and on Application of the Legislature, or of the Executive (when the
Legislature cannot be convened) against domestic Violence.

### Section. 5.

The validity of the public debt of the United States,
authorized by law, including debts incurred for payment of pensions and
bounties for services in suppressing insurrection or rebellion, shall not be
questioned. But neither the United States nor any State shall assume or pay any
debt or obligation incurred in aid of insurrection or rebellion against the
United States, or any claim for the loss or emancipation of any slave; but all
such debts, obligations and claims shall be held illegal and void.

## Article. V.

The Congress, whenever two thirds of both Houses shall deem it necessary, shall
propose Amendments to this Constitution, or, on the Application of the
Legislatures of two thirds of the several States, shall call a Convention for
proposing Amendments, which, in either Case, shall be valid to all Intents and
Purposes, as Part of this Constitution, when ratified by the Legislatures of
three fourths of the several States, or by Conventions in three fourths
thereof, as the one or the other Mode of Ratification may be proposed by the
Congress; Provided that no Amendment which may be made prior to the Year One
thousand eight hundred and eight shall in any Manner affect the first and
fourth Clauses in the Ninth Section of the first Article; and that no State,
without its Consent, shall be deprived of its equal Suffrage in the Senate.

## Article. VI.

All Debts contracted and Engagements entered into, before the Adoption of this
Constitution, shall be as valid against the United States under this
Constitution, as under the Confederation.

This Constitution, and the Laws of the United States which shall be made in
Pursuance thereof; and all Treaties made, or which shall be made, under the
Authority of the United States, shall be the supreme Law of the Land; and the
Judges in every State shall be bound thereby, any Thing in the Constitution or
Laws of any State to the Contrary notwithstanding.

The Senators and Representatives before mentioned, and the Members of the
several State Legislatures, and all executive and judicial Officers, both of
the United States and of the several States, shall be bound by Oath or
Affirmation, to support this Constitution; but no religious Test shall ever be
required as a Qualification to any Office or public Trust under the United
States.

A well regulated militia, being necessary to the security of a free state, the
right of the people to keep and bear arms, shall not be infringed.

### Section. 1.

The enumeration in the Constitution, of certain rights, shall
not be construed to deny or disparage others retained by the people.

The powers not delegated to the United States by the Constitution, nor
prohibited by it to the states, are reserved to the states respectively, or to
the people.

## Article. VII.

The Ratification of the Conventions of nine States, shall be sufficient for the
Establishment of this Constitution between the States so ratifying the Same.

The Word "the", being interlined between the seventh and eight Lines of the
first Page, The Word "Thirty" being partly written on an Erazure in the
fifteenth Line of the first Page. The Words "is tried" being interlined between
the thirty second and thirty third Lines of the first Page and the Word "the"
being interlined between the forty third and forty fourth Lines of the second
Page.


done in Convention by the Unanimous Consent of the States present the
Seventeenth Day of September in the Year of our Lord one thousand seven hundred
and Eighty seven and of the Independence of the United States of America the
Twelfth In witness whereof We have hereunto subscribed our Names,

## Article. VIII.

### Section 1.

The transportation or importation into any State, Territory, or
possession of the United States for delivery or use therein of intoxicating
liquors, in violation of the laws thereof, is hereby prohibited.



================================================
FILE: harper-core/tests/text/this and that.md
================================================
"This" and "that" are common and fulfill multiple purposes in everyday English.
As such, disambiguating them is necessary.

This document contains various sentences that use "this", "that", "these", and
"those" in different contexts with a lot of edge cases.

## Examples

This triangle is nice.
This is nice.
That triangle is nice.
That is nice.
These triangles are nice.
These are nice.
Those triangles are nice.
Those are nice.

This massage is nice.
That massage is nice.
These massages are nice.
Those massages are nice.
This massages well.
That massages well.
These massage well.
Those massage well.

That could be a solution.
Find all candidates that could be a solution.

This is all that I have.
This is all that solutions can do.
That solution can do.

We can do this!
I can do this and that.

We unite to stand united in unity.



================================================
FILE: harper-core/tests/text/linters/Computer science.snap.yml
================================================
Lint:    Capitalization (127 priority)
Message: |
       6 | # Computer science
         | ^~~~~~~~~~~~~~~~~~ Try to use title case in headings.
Suggest:
  - Replace with: “# Computer Science”



Lint:    Style (31 priority)
Message: |
      27 | problem-solving, decision-making, environmental adaptation, planning and
         |                                                             ^~~~~~~~ An Oxford comma is necessary here.
      28 | learning found in humans and animals. Within artificial intelligence, computer
Suggest:
  - Insert “,”



Lint:    Spelling (63 priority)
Message: |
      45 | Wilhelm Schickard designed and constructed the first working mechanical
         |         ^~~~~~~~~ Did you mean to spell `Schickard` this way?
Suggest:
  - Replace with: “Schick's”
  - Replace with: “Shipyard”
  - Replace with: “Schick”



Lint:    Spelling (63 priority)
Message: |
      46 | calculator in 1623. In 1673, Gottfried Leibniz demonstrated a digital mechanical
         |                              ^~~~~~~~~ Did you mean to spell `Gottfried` this way?
Suggest:
  - Replace with: “Guttered”
  - Replace with: “Lotteries”
  - Replace with: “Notified”



Lint:    Spelling (63 priority)
Message: |
      46 | calculator in 1623. In 1673, Gottfried Leibniz demonstrated a digital mechanical
      47 | calculator, called the Stepped Reckoner. Leibniz may be considered the first
         |                                ^~~~~~~~ Did you mean to spell `Reckoner` this way?
Suggest:
  - Replace with: “Reckoned”
  - Replace with: “Recover”
  - Replace with: “Rickover”



Lint:    Spelling (63 priority)
Message: |
      49 | including the fact that he documented the binary number system. In 1820, Thomas
      50 | de Colmar launched the mechanical calculator industry[note 1] when he invented
         |    ^~~~~~ Did you mean to spell `Colmar` this way?
Suggest:
  - Replace with: “Collar”
  - Replace with: “Cellar”
  - Replace with: “Clear”



Lint:    Spelling (63 priority)
Message: |
      50 | de Colmar launched the mechanical calculator industry[note 1] when he invented
      51 | his simplified arithmometer, the first calculating machine strong enough and
         |                ^~~~~~~~~~~~ Did you mean to spell `arithmometer` this way?
Suggest:
  - Replace with: “arithmetic”
  - Replace with: “anemometer”



Lint:    Readability (127 priority)
Message: |
      59 | programmable.[note 2] In 1843, during the translation of a French article on the
         |               ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
      60 | Analytical Engine, Ada Lovelace wrote, in one of the many notes she included, an
         | ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
      61 | algorithm to compute the Bernoulli numbers, which is considered to be the first
         | ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
      62 | published algorithm ever specifically tailored for implementation on a computer.
         | ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ This sentence is 48 words long.



Lint:    Spelling (63 priority)
Message: |
      65 | Following Babbage, although unaware of his earlier work, Percy Ludgate in 1909
         |                                                                ^~~~~~~ Did you mean to spell `Ludgate` this way?
      66 | published the 2nd of the only two designs for mechanical analytical engines in
Suggest:
  - Replace with: “Legate”
  - Replace with: “Luggage”
  - Replace with: “Luddite”



Lint:    Spelling (63 priority)
Message: |
      67 | history. In 1914, the Spanish engineer Leonardo Torres Quevedo published his
         |                                                        ^~~~~~~ Did you mean to spell `Quevedo` this way?
      68 | Essays on Automatics, and designed, inspired by Babbage, a theoretical
Suggest:
  - Replace with: “Queued”
  - Replace with: “Acevedo”



Lint:    Spelling (63 priority)
Message: |
      71 | 1920, to celebrate the 100th anniversary of the invention of the arithmometer,
         |                                                                  ^~~~~~~~~~~~ Did you mean to spell `arithmometer` this way?
      72 | Torres presented in Paris the Electromechanical Arithmometer, a prototype that
Suggest:
  - Replace with: “arithmetic”
  - Replace with: “anemometer”



Lint:    Spelling (63 priority)
Message: |
      72 | Torres presented in Paris the Electromechanical Arithmometer, a prototype that
         |                                                 ^~~~~~~~~~~~ Did you mean to spell `Arithmometer` this way?
      73 | demonstrated the feasibility of an electromechanical analytical engine, on which
Suggest:
  - Replace with: “Arithmetic”
  - Replace with: “Anemometer”



Lint:    Readability (127 priority)
Message: |
      74 | commands could be typed and the results printed automatically. In 1937, one
         |                                                                ^~~~~~~~~~~~~
      75 | hundred years after Babbage's impossible dream, Howard Aiken convinced IBM,
         | ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
      76 | which was making all kinds of punched card equipment and was also in the
         | ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
      77 | calculator business to develop his giant programmable calculator, the
         | ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
      78 | ASCC/Harvard Mark I, based on Babbage's Analytical Engine, which itself used
         | ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
      79 | cards and a central computing unit. When the machine was finished, some hailed
         | ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ This sentence is 53 words long.



Lint:    Spelling (63 priority)
Message: |
      77 | calculator business to develop his giant programmable calculator, the
      78 | ASCC/Harvard Mark I, based on Babbage's Analytical Engine, which itself used
         | ^~~~ Did you mean to spell `ASCC` this way?
Suggest:
  - Replace with: “Ac”
  - Replace with: “Ace”
  - Replace with: “Act”



Lint:    Spelling (63 priority)
Message: |
      82 | During the 1940s, with the development of new and more powerful computing
      83 | machines such as the Atanasoff–Berry computer and ENIAC, the term computer came
         |                      ^~~~~~~~~ Did you mean to spell `Atanasoff` this way?
Suggest:
  - Replace with: “Standoff”
  - Replace with: “Stand off”



Lint:    Spelling (63 priority)
Message: |
      83 | machines such as the Atanasoff–Berry computer and ENIAC, the term computer came
         |                                                   ^~~~~ Did you mean to spell `ENIAC` this way?
      84 | to refer to the machines rather than their human predecessors. As it became
Suggest:
  - Replace with: “Enact”
  - Replace with: “Epic”
  - Replace with: “Enc”



Lint:    Capitalization (31 priority)
Message: |
      87 | 1945, IBM founded the Watson Scientific Computing Laboratory at Columbia
         |                                                                 ^~~~~~~~~
      88 | University in New York City. The renovated fraternity house on Manhattan's West
         | ~~~~~~~~~~ Ensure proper capitalization of major universities in the United States.
Suggest:
  - Replace with: “Columbia University”



Lint:    Capitalization (31 priority)
Message: |
      91 | around the world. Ultimately, the close relationship between IBM and Columbia
         |                                                                      ^~~~~~~~~
      92 | University was instrumental in the emergence of a new scientific discipline,
         | ~~~~~~~~~~ Ensure proper capitalization of major universities in the United States.
Suggest:
  - Replace with: “Columbia University”



Lint:    Capitalization (127 priority)
Message: |
     102 | ## Etymology and scope
         | ^~~~~~~~~~~~~~~~~~~~~~ Try to use title case in headings.
Suggest:
  - Replace with: “## Etymology and Scope”



Lint:    Readability (127 priority)
Message: |
     104 | Although first proposed in 1956, the term "computer science" appears in a 1959
         | ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
     105 | article in Communications of the ACM, in which Louis Fein argues for the
         | ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
     106 | creation of a Graduate School in Computer Sciences analogous to the creation of
         | ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
     107 | Harvard Business School in 1921. Louis justifies the name by arguing that, like
         | ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ This sentence is 41 words long.



Lint:    Spelling (63 priority)
Message: |
     105 | article in Communications of the ACM, in which Louis Fein argues for the
         |                                                      ^~~~ Did you mean to spell `Fein` this way?
     106 | creation of a Graduate School in Computer Sciences analogous to the creation of
Suggest:
  - Replace with: “Fen”
  - Replace with: “Fern”
  - Replace with: “Fin”



Lint:    Spelling (63 priority)
Message: |
     110 | and those of others such as numerical analyst George Forsythe, were rewarded:
         |                                                      ^~~~~~~~ Did you mean `Forsythia`?
Suggest:
  - Replace with: “Forsythia”



Lint:    Spelling (63 priority)
Message: |
     115 | computing science, to emphasize precisely that difference. Danish scientist
     116 | Peter Naur suggested the term datalogy, to reflect the fact that the scientific
         |       ^~~~ Did you mean to spell `Naur` this way?
Suggest:
  - Replace with: “Nair”
  - Replace with: “Nauru”
  - Replace with: “Nag”



Lint:    Spelling (63 priority)
Message: |
     115 | computing science, to emphasize precisely that difference. Danish scientist
     116 | Peter Naur suggested the term datalogy, to reflect the fact that the scientific
         |                               ^~~~~~~~ Did you mean to spell `datalogy` this way?
Suggest:
  - Replace with: “analogy”
  - Replace with: “catalog”
  - Replace with: “catalogs”



Lint:    Spelling (63 priority)
Message: |
     118 | involving computers. The first scientific institution to use the term was the
     119 | Department of Datalogy at the University of Copenhagen, founded in 1969, with
         |               ^~~~~~~~ Did you mean to spell `Datalogy` this way?
Suggest:
  - Replace with: “DataDog”
  - Replace with: “Analogy”
  - Replace with: “Catalog”



Lint:    Spelling (63 priority)
Message: |
     119 | Department of Datalogy at the University of Copenhagen, founded in 1969, with
     120 | Peter Naur being the first professor in datalogy. The term is used mainly in the
         |       ^~~~ Did you mean to spell `Naur` this way?
Suggest:
  - Replace with: “Nair”
  - Replace with: “Nauru”
  - Replace with: “Nag”



Lint:    Spelling (63 priority)
Message: |
     119 | Department of Datalogy at the University of Copenhagen, founded in 1969, with
     120 | Peter Naur being the first professor in datalogy. The term is used mainly in the
         |                                         ^~~~~~~~ Did you mean to spell `datalogy` this way?
Suggest:
  - Replace with: “analogy”
  - Replace with: “catalog”
  - Replace with: “catalogs”



Lint:    Spelling (63 priority)
Message: |
     121 | Scandinavian countries. An alternative term, also proposed by Naur, is data
         |                                                               ^~~~ Did you mean to spell `Naur` this way?
     122 | science; this is now used for a multi-disciplinary field of data analysis,
Suggest:
  - Replace with: “Nair”
  - Replace with: “Nauru”
  - Replace with: “Nag”



Lint:    Spelling (127 priority)
Message: |
     122 | science; this is now used for a multi-disciplinary field of data analysis,
         |                                 ^~~~~~~~~~~~~~~~~~ This looks like a prefix that can be joined with the rest of the word.
     123 | including statistics and databases.
Suggest:
  - Replace with: “multidisciplinary”



Lint:    Spelling (63 priority)
Message: |
     126 | field of computing were suggested (albeit facetiously) in the Communications of
     127 | the ACM—turingineer, turologist, flow-charts-man, applied meta-mathematician,
         |         ^~~~~~~~~~~ Did you mean to spell `turingineer` this way?
Suggest:
  - Replace with: “engineer”
  - Replace with: “springier”
  - Replace with: “springiness”



Lint:    Spelling (63 priority)
Message: |
     126 | field of computing were suggested (albeit facetiously) in the Communications of
     127 | the ACM—turingineer, turologist, flow-charts-man, applied meta-mathematician,
         |                      ^~~~~~~~~~ Did you mean to spell `turologist` this way?
Suggest:
  - Replace with: “theologist”
  - Replace with: “urologist”
  - Replace with: “neurologist”



Lint:    Spelling (63 priority)
Message: |
     128 | and applied epistemologist. Three months later in the same journal, comptologist
         |                                                                     ^~~~~~~~~~~~ Did you mean `cosmetologist`?
     129 | was suggested, followed next year by hypologist. The term computics has also
Suggest:
  - Replace with: “cosmetologist”



Lint:    Spelling (63 priority)
Message: |
     128 | and applied epistemologist. Three months later in the same journal, comptologist
     129 | was suggested, followed next year by hypologist. The term computics has also
         |                                      ^~~~~~~~~~ Did you mean to spell `hypologist` this way?
Suggest:
  - Replace with: “horologist”
  - Replace with: “hydrologist”
  - Replace with: “apologist”



Lint:    Spelling (63 priority)
Message: |
     129 | was suggested, followed next year by hypologist. The term computics has also
         |                                                           ^~~~~~~~~ Did you mean to spell `computics` this way?
     130 | been suggested. In Europe, terms derived from contracted translations of the
Suggest:
  - Replace with: “computers”
  - Replace with: “computes”
  - Replace with: “computing”



Lint:    Readability (127 priority)
Message: |
     130 | been suggested. In Europe, terms derived from contracted translations of the
         |                 ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
     131 | expression "automatic information" (e.g. "informazione automatica" in Italian)
         | ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
     132 | or "information and mathematics" are often used, e.g. informatique (French),
         | ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
     133 | Informatik (German), informatica (Italian, Dutch), informática (Spanish,
         | ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
     134 | Portuguese), informatika (Slavic languages and Hungarian) or pliroforiki
         | ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
     135 | (πληροφορική, which means informatics) in Greek. Similar words have also been
         | ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ This sentence is 47 words long.



Lint:    Spelling (63 priority)
Message: |
     131 | expression "automatic information" (e.g. "informazione automatica" in Italian)
         |                                           ^~~~~~~~~~~~ Did you mean `information`?
     132 | or "information and mathematics" are often used, e.g. informatique (French),
Suggest:
  - Replace with: “information”



Lint:    Spelling (63 priority)
Message: |
     131 | expression "automatic information" (e.g. "informazione automatica" in Italian)
         |                                                        ^~~~~~~~~~ Did you mean to spell `automatica` this way?
     132 | or "information and mathematics" are often used, e.g. informatique (French),
Suggest:
  - Replace with: “automatic”
  - Replace with: “automatics”
  - Replace with: “automata”



Lint:    Typo (31 priority)
Message: |
     131 | expression "automatic information" (e.g. "informazione automatica" in Italian)
         |                                                        ^~~~~~~~~~ `automatica` should probably be written as `automatic a`.
     132 | or "information and mathematics" are often used, e.g. informatique (French),
Suggest:
  - Replace with: “automatic a”



Lint:    Spelling (63 priority)
Message: |
     132 | or "information and mathematics" are often used, e.g. informatique (French),
         |                                                       ^~~~~~~~~~~~ Did you mean `informative`?
     133 | Informatik (German), informatica (Italian, Dutch), informática (Spanish,
Suggest:
  - Replace with: “informative”



Lint:    Spelling (63 priority)
Message: |
     132 | or "information and mathematics" are often used, e.g. informatique (French),
     133 | Informatik (German), informatica (Italian, Dutch), informática (Spanish,
         | ^~~~~~~~~~ Did you mean to spell `Informatik` this way?
Suggest:
  - Replace with: “Informatics”
  - Replace with: “Information”
  - Replace with: “Informative”



Lint:    Spelling (63 priority)
Message: |
     132 | or "information and mathematics" are often used, e.g. informatique (French),
     133 | Informatik (German), informatica (Italian, Dutch), informática (Spanish,
         |                      ^~~~~~~~~~~ Did you mean to spell `informatica` this way?
Suggest:
  - Replace with: “informatics”
  - Replace with: “information”
  - Replace with: “informative”



Lint:    Spelling (63 priority)
Message: |
     133 | Informatik (German), informatica (Italian, Dutch), informática (Spanish,
         |                                                    ^~~~~~~~~~~ Did you mean `informatics`?
     134 | Portuguese), informatika (Slavic languages and Hungarian) or pliroforiki
Suggest:
  - Replace with: “informatics”



Lint:    Spelling (63 priority)
Message: |
     133 | Informatik (German), informatica (Italian, Dutch), informática (Spanish,
     134 | Portuguese), informatika (Slavic languages and Hungarian) or pliroforiki
         |              ^~~~~~~~~~~ Did you mean to spell `informatika` this way?
Suggest:
  - Replace with: “informatics”
  - Replace with: “information”
  - Replace with: “informative”



Lint:    Spelling (63 priority)
Message: |
     134 | Portuguese), informatika (Slavic languages and Hungarian) or pliroforiki
         |                                                              ^~~~~~~~~~~ Did you mean to spell `pliroforiki` this way?
     135 | (πληροφορική, which means informatics) in Greek. Similar words have also been



Lint:    Spelling (63 priority)
Message: |
     140 | A folkloric quotation, often attributed to—but almost certainly not first
     141 | formulated by—Edsger Dijkstra, states that "computer science is no more about
         |               ^~~~~~ Did you mean to spell `Edsger` this way?
Suggest:
  - Replace with: “Edger”
  - Replace with: “Eager”
  - Replace with: “Edge”



Lint:    Readability (127 priority)
Message: |
     154 | computing is a mathematical science. Early computer science was strongly
         |                                      ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
     155 | influenced by the work of mathematicians such as Kurt Gödel, Alan Turing, John
         | ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
     156 | von Neumann, Rózsa Péter and Alonzo Church and there continues to be a useful
         | ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
     157 | interchange of ideas between the two fields in areas such as mathematical logic,
         | ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
     158 | category theory, domain theory, and algebra.
         | ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ This sentence is 51 words long.



Lint:    Spelling (63 priority)
Message: |
     155 | influenced by the work of mathematicians such as Kurt Gödel, Alan Turing, John
     156 | von Neumann, Rózsa Péter and Alonzo Church and there continues to be a useful
         | ^~~ Did you mean to spell `von` this way?
Suggest:
  - Replace with: “van”
  - Replace with: “vol”
  - Replace with: “vow”



Lint:    Spelling (63 priority)
Message: |
     155 | influenced by the work of mathematicians such as Kurt Gödel, Alan Turing, John
     156 | von Neumann, Rózsa Péter and Alonzo Church and there continues to be a useful
         |     ^~~~~~~ Did you mean `Newman`?
Suggest:
  - Replace with: “Newman”



Lint:    Spelling (63 priority)
Message: |
     155 | influenced by the work of mathematicians such as Kurt Gödel, Alan Turing, John
     156 | von Neumann, Rózsa Péter and Alonzo Church and there continues to be a useful
         |              ^~~~~ Did you mean `Rosa`?
Suggest:
  - Replace with: “Rosa”



Lint:    Spelling (63 priority)
Message: |
     155 | influenced by the work of mathematicians such as Kurt Gödel, Alan Turing, John
     156 | von Neumann, Rózsa Péter and Alonzo Church and there continues to be a useful
         |                    ^~~~~ Did you mean to spell `Péter` this way?
Suggest:
  - Replace with: “Peter”
  - Replace with: “Pother”
  - Replace with: “Paper”



Lint:    WordChoice (63 priority)
Message: |
     161 | contentious issue, which is further muddied by disputes over what the term
     162 | "software engineering" means, and how computer science is defined. David Parnas,
         |                                   ^~~~ Insert `to` after `how` (e.g., `how to clone`).
Suggest:
  - Insert “to ”



Lint:    Readability (127 priority)
Message: |
     162 | "software engineering" means, and how computer science is defined. David Parnas,
         |                                                                    ^~~~~~~~~~~~~~
     163 | taking a cue from the relationship between other engineering and science
         | ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
     164 | disciplines, has claimed that the principal focus of computer science is
         | ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
     165 | studying the properties of computation in general, while the principal focus of
         | ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
     166 | software engineering is the design of specific computations to achieve practical
         | ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
     167 | goals, making the two separate but complementary disciplines.
         | ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ This sentence is 55 words long.



Lint:    Spelling (63 priority)
Message: |
     162 | "software engineering" means, and how computer science is defined. David Parnas,
         |                                                                          ^~~~~~ Did you mean to spell `Parnas` this way?
     163 | taking a cue from the relationship between other engineering and science
Suggest:
  - Replace with: “Paras”
  - Replace with: “Parkas”
  - Replace with: “Parana's”



Lint:    Capitalization (127 priority)
Message: |
     178 | ### Epistemology of computer science
         | ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Try to use title case in headings.
Suggest:
  - Replace with: “### Epistemology of Computer Science”



Lint:    Spelling (63 priority)
Message: |
     181 | computer science is a discipline of science, mathematics, or engineering. Allen
     182 | Newell and Herbert A. Simon argued in 1975,
         | ^~~~~~ Did you mean to spell `Newell` this way?
Suggest:
  - Replace with: “Newel”
  - Replace with: “Newels”
  - Replace with: “Newel's”



Lint:    Spelling (63 priority)
Message: |
     181 | computer science is a discipline of science, mathematics, or engineering. Allen
     182 | Newell and Herbert A. Simon argued in 1975,
         |                    ^~ Did you mean to spell `A.` this way?
Suggest:
  - Replace with: “A”
  - Replace with: “Ab”
  - Replace with: “Ac”



Lint:    Readability (127 priority)
Message: |
     192 | It has since been argued that computer science can be classified as an empirical
         | ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
     193 | science since it makes use of empirical testing to evaluate the correctness of
         | ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
     194 | programs, but a problem remains in defining the laws and theorems of computer
         | ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
     195 | science (if any exist) and defining the nature of experiments in computer
         | ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
     196 | science. Proponents of classifying computer science as an engineering discipline
         | ~~~~~~~~ This sentence is 53 words long.



Lint:    Readability (127 priority)
Message: |
     198 | way as bridges in civil engineering and airplanes in aerospace engineering. They
         |                                                                             ^~~~~
     199 | also argue that while empirical sciences observe what presently exists, computer
         | ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
     200 | science observes what is possible to exist and while scientists discover laws
         | ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
     201 | from observation, no proper laws have been found in computer science and it is
         | ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
     202 | instead concerned with creating phenomena.
         | ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ This sentence is 43 words long.



Lint:    Spelling (63 priority)
Message: |
     207 | Computer scientists Edsger W. Dijkstra and Tony Hoare regard instructions for
         |                     ^~~~~~ Did you mean to spell `Edsger` this way?
Suggest:
  - Replace with: “Edger”
  - Replace with: “Eager”
  - Replace with: “Edge”



Lint:    Spelling (63 priority)
Message: |
     207 | Computer scientists Edsger W. Dijkstra and Tony Hoare regard instructions for
         |                            ^~ Did you mean to spell `W.` this way?
Suggest:
  - Replace with: “We”
  - Replace with: “WA”
  - Replace with: “WI”



Lint:    Spelling (63 priority)
Message: |
     207 | Computer scientists Edsger W. Dijkstra and Tony Hoare regard instructions for
         |                                                 ^~~~~ Did you mean to spell `Hoare` this way?
     208 | computer programs as mathematical sentences and interpret formal semantics for
Suggest:
  - Replace with: “Hare”
  - Replace with: “Hoard”
  - Replace with: “Hoary”



Lint:    Capitalization (127 priority)
Message: |
     211 | ### Paradigms of computer science
         | ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Try to use title case in headings.
Suggest:
  - Replace with: “### Paradigms of Computer Science”



Lint:    Spelling (63 priority)
Message: |
     214 | separate paradigms in computer science. Peter Wegner argued that those paradigms
         |                                               ^~~~~~ Did you mean to spell `Wegner` this way?
     215 | are science, technology, and mathematics. Peter Denning's working group argued
Suggest:
  - Replace with: “Wagner”
  - Replace with: “Wigner”
  - Replace with: “Wager”



Lint:    Spelling (63 priority)
Message: |
     215 | are science, technology, and mathematics. Peter Denning's working group argued
         |                                                 ^~~~~~~~~ Did you mean to spell `Denning's` this way?
     216 | that they are theory, abstraction (modeling), and design. Amnon H. Eden
Suggest:
  - Replace with: “Deming's”
  - Replace with: “Dennis's”
  - Replace with: “Dancing's”



Lint:    Spelling (63 priority)
Message: |
     216 | that they are theory, abstraction (modeling), and design. Amnon H. Eden
         |                                                           ^~~~~ Did you mean to spell `Amnon` this way?
Suggest:
  - Replace with: “Anon”
  - Replace with: “Amnion”
  - Replace with: “Amazon”



Lint:    Readability (127 priority)
Message: |
     216 | that they are theory, abstraction (modeling), and design. Amnon H. Eden
         |                                                           ^~~~~~~~~~~~~~
     217 | described them as the "rationalist paradigm" (which treats computer science as a
         | ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
     218 | branch of mathematics, which is prevalent in theoretical computer science, and
         | ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
     219 | mainly employs deductive reasoning), the "technocratic paradigm" (which might be
         | ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
     220 | found in engineering approaches, most prominently in software engineering), and
         | ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
     221 | the "scientific paradigm" (which approaches computer-related artifacts from the
         | ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
     222 | empirical perspective of natural sciences, identifiable in some branches of
         | ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
     223 | artificial intelligence). Computer science focuses on methods involved in
         | ~~~~~~~~~~~~~~~~~~~~~~~~~ This sentence is 68 words long.



Lint:    Spelling (63 priority)
Message: |
     216 | that they are theory, abstraction (modeling), and design. Amnon H. Eden
         |                                                                 ^~ Did you mean to spell `H.` this way?
Suggest:
  - Replace with: “Ha”
  - Replace with: “He”
  - Replace with: “Hi”



Lint:    Style (31 priority)
Message: |
     224 | design, specification, programming, verification, implementation and testing of
         |                                                   ^~~~~~~~~~~~~~ An Oxford comma is necessary here.
     225 | human-made computing systems.
Suggest:
  - Insert “,”



Lint:    Spelling (63 priority)
Message: |
     231 | implementing computing systems in hardware and software. CSAB, formerly called
         |                                                          ^~~~ Did you mean to spell `CSAB` this way?
     232 | Computing Sciences Accreditation Board—which is made up of representatives of
Suggest:
  - Replace with: “Cab”
  - Replace with: “Crab”
  - Replace with: “Cad”



Lint:    Readability (127 priority)
Message: |
     231 | implementing computing systems in hardware and software. CSAB, formerly called
         |                                                          ^~~~~~~~~~~~~~~~~~~~~~
     232 | Computing Sciences Accreditation Board—which is made up of representatives of
         | ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
     233 | the Association for Computing Machinery (ACM), and the IEEE Computer Society
         | ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
     234 | (IEEE CS)—identifies four areas that it considers crucial to the discipline of
         | ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
     235 | computer science: theory of computation, algorithms and data structures,
         | ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
     236 | programming methodology and languages, and computer elements and architecture.
         | ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ This sentence is 56 words long.



Lint:    Style (31 priority)
Message: |
     235 | computer science: theory of computation, algorithms and data structures,
         |                                          ^~~~~~~~~~ An Oxford comma is necessary here.
     236 | programming methodology and languages, and computer elements and architecture.
Suggest:
  - Insert “,”



Lint:    Readability (127 priority)
Message: |
     237 | In addition to these four areas, CSAB also identifies fields such as software
         | ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
     238 | engineering, artificial intelligence, computer networking and communication,
         | ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
     239 | database systems, parallel computation, distributed computation, human–computer
         | ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
     240 | interaction, computer graphics, operating systems, and numerical and symbolic
         | ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
     241 | computation as being important areas of computer science.
         | ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ This sentence is 45 words long.



Lint:    Spelling (63 priority)
Message: |
     237 | In addition to these four areas, CSAB also identifies fields such as software
         |                                  ^~~~ Did you mean to spell `CSAB` this way?
Suggest:
  - Replace with: “Cab”
  - Replace with: “Crab”
  - Replace with: “Cad”



Lint:    Capitalization (127 priority)
Message: |
     243 | ### Theoretical computer science
         | ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Try to use title case in headings.
Suggest:
  - Replace with: “### Theoretical Computer Science”



Lint:    Capitalization (127 priority)
Message: |
     250 | #### Theory of computation
         | ^~~~~~~~~~~~~~~~~~~~~~~~~~ Try to use title case in headings.
Suggest:
  - Replace with: “#### Theory of Computation”



Lint:    Spelling (63 priority)
Message: |
     252 | According to Peter Denning, the fundamental question underlying computer science
         |                    ^~~~~~~ Did you mean to spell `Denning` this way?
Suggest:
  - Replace with: “Dunning”
  - Replace with: “Denting”
  - Replace with: “Denying”



Lint:    Spelling (63 priority)
Message: |
     262 | The famous P = NP? problem, one of the Millennium Prize Problems, is an open
         |                ^~ Did you mean to spell `NP` this way?
Suggest:
  - Replace with: “Nap”
  - Replace with: “Nip”
  - Replace with: “No”



Lint:    Capitalization (31 priority)
Message: |
     262 | The famous P = NP? problem, one of the Millennium Prize Problems, is an open
         |                    ^~~~~~~ This sentence does not start with a capital letter
Suggest:
  - Replace with: “Problem”



Lint:    Capitalization (127 priority)
Message: |
     265 | #### Information and coding theory
         | ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Try to use title case in headings.
Suggest:
  - Replace with: “#### Information and Coding Theory”



Lint:    Capitalization (127 priority)
Message: |
     277 | #### Data structures and algorithms
         | ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Try to use title case in headings.
Suggest:
  - Replace with: “#### Data Structures and Algorithms”



Lint:    Capitalization (127 priority)
Message: |
     282 | #### Programming language theory and formal methods
         | ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Try to use title case in headings.
Suggest:
  - Replace with: “#### Programming Language Theory and Formal Methods”



Lint:    Agreement (31 priority)
Message: |
     286 | programming languages and their individual features. It falls within the
     287 | discipline of computer science, both depending on and affecting mathematics,
         |                                 ^~~~~~~~~~~~~~ `depending` is a mass noun.
     288 | software engineering, and linguistics. It is an active research area, with
Suggest:
  - Replace with: “both pieces of depending”



Lint:    Style (31 priority)
Message: |
     291 | Formal methods are a particular kind of mathematically based technique for the
     292 | specification, development and verification of software and hardware systems.
         |                ^~~~~~~~~~~ An Oxford comma is necessary here.
Suggest:
  - Insert “,”



Lint:    Readability (127 priority)
Message: |
     302 | safety or security is of utmost importance. Formal methods are best described as
         |                                             ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
     303 | the application of a fairly broad variety of theoretical computer science
         | ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
     304 | fundamentals, in particular logic calculi, formal languages, automata theory,
         | ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
     305 | and program semantics, but also type systems and algebraic data types to
         | ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
     306 | problems in software and hardware specification and verification.
         | ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ This sentence is 46 words long.



Lint:    Capitalization (127 priority)
Message: |
     308 | ### Applied computer science
         | ^~~~~~~~~~~~~~~~~~~~~~~~~~~~ Try to use title case in headings.
Suggest:
  - Replace with: “### Applied Computer Science”



Lint:    Capitalization (127 priority)
Message: |
     310 | #### Computer graphics and visualization
         | ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Try to use title case in headings.
Suggest:
  - Replace with: “#### Computer Graphics and Visualization”



Lint:    Capitalization (127 priority)
Message: |
     318 | #### Image and sound processing
         | ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Try to use title case in headings.
Suggest:
  - Replace with: “#### Image and Sound Processing”



Lint:    Style (31 priority)
Message: |
     320 | Information can take the form of images, sound, video or other multimedia. Bits
         |                                                 ^~~~~ An Oxford comma is necessary here.
Suggest:
  - Insert “,”



Lint:    Style (31 priority)
Message: |
     323 | processing algorithms independently of the type of information carrier – whether
     324 | it is electrical, mechanical or biological. This field plays important role in
         |                   ^~~~~~~~~~ An Oxford comma is necessary here.
Suggest:
  - Insert “,”



Lint:    Capitalization (31 priority)
Message: |
     327 | is the lower bound on the complexity of fast Fourier transform algorithms? is
         |                                                                            ^~ This sentence does not start with a capital letter
     328 | one of the unsolved problems in theoretical computer science.
Suggest:
  - Replace with: “Is”



Lint:    Capitalization (127 priority)
Message: |
     330 | #### Computational science, finance and engineering
         | ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Try to use title case in headings.
Suggest:
  - Replace with: “#### Computational Science, Finance and Engineering”



Lint:    Style (31 priority)
Message: |
     330 | #### Computational science, finance and engineering
         |                             ^~~~~~~ An Oxford comma is necessary here.
Suggest:
  - Insert “,”



Lint:    Capitalization (127 priority)
Message: |
     344 | #### Human–computer interaction
         | ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Try to use title case in headings.
Suggest:
  - Replace with: “#### Human–Computer Interaction”



Lint:    Spelling (63 priority)
Message: |
     346 | Human–computer interaction (HCI) is the field of study and research concerned
         |                             ^~~ Did you mean to spell `HCI` this way?
Suggest:
  - Replace with: “Hi”
  - Replace with: “Chi”
  - Replace with: “Sci”



Lint:    Spelling (63 priority)
Message: |
     348 | interaction between humans and computer interfaces. HCI has several subfields
         |                                                     ^~~ Did you mean to spell `HCI` this way?
     349 | that focus on the relationship between emotions, social behavior and brain
Suggest:
  - Replace with: “Hi”
  - Replace with: “Chi”
  - Replace with: “Sci”



Lint:    Capitalization (127 priority)
Message: |
     352 | #### Software engineering
         | ^~~~~~~~~~~~~~~~~~~~~~~~~ Try to use title case in headings.
Suggest:
  - Replace with: “#### Software Engineering”



Lint:    Punctuation (31 priority)
Message: |
     360 | maintenance. For example software testing, systems engineering, technical debt
         |              ^~~~~~~~~~~ Discourse markers at the beginning of a sentence should be followed by a comma.
Suggest:
  - Insert “,”



Lint:    Capitalization (127 priority)
Message: |
     363 | #### Artificial intelligence
         | ^~~~~~~~~~~~~~~~~~~~~~~~~~~~ Try to use title case in headings.
Suggest:
  - Replace with: “#### Artificial Intelligence”



Lint:    Capitalization (127 priority)
Message: |
     383 | ### Computer systems
         | ^~~~~~~~~~~~~~~~~~~~ Try to use title case in headings.
Suggest:
  - Replace with: “### Computer Systems”



Lint:    Capitalization (127 priority)
Message: |
     385 | #### Computer architecture and microarchitecture
         | ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Try to use title case in headings.
Suggest:
  - Replace with: “#### Computer Architecture and Microarchitecture”



Lint:    Spelling (63 priority)
Message: |
     393 | term "architecture" in computer literature can be traced to the work of Lyle R.
         |                                                                              ^~ Did you mean to spell `R.` this way?
Suggest:
  - Replace with: “RI”
  - Replace with: “Ra”
  - Replace with: “Ru”



Lint:    Spelling (63 priority)
Message: |
     394 | Johnson and Frederick P. Brooks Jr., members of the Machine Organization
         |                       ^~ Did you mean to spell `P.` this way?
Suggest:
  - Replace with: “Pa”
  - Replace with: “Pi”
  - Replace with: “PE”



Lint:    Capitalization (127 priority)
Message: |
     397 | #### Concurrent, parallel and distributed computing
         | ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Try to use title case in headings.
Suggest:
  - Replace with: “#### Concurrent, Parallel and Distributed Computing”



Lint:    Spelling (63 priority)
Message: |
     401 | mathematical models have been developed for general concurrent computation
     402 | including Petri nets, process calculi and the parallel random access machine
         |           ^~~~~ Did you mean to spell `Petri` this way?
Suggest:
  - Replace with: “Petra”
  - Replace with: “Perth”
  - Replace with: “Pear”



Lint:    Capitalization (127 priority)
Message: |
     408 | #### Computer networks
         | ^~~~~~~~~~~~~~~~~~~~~~ Try to use title case in headings.
Suggest:
  - Replace with: “#### Computer Networks”



Lint:    Capitalization (127 priority)
Message: |
     413 | #### Computer security and cryptography
         | ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Try to use title case in headings.
Suggest:
  - Replace with: “#### Computer Security and Cryptography”



Lint:    WordChoice (127 priority)
Message: |
     421 | Modern cryptography is the scientific study of problems relating to distributed
         |                                                                  ^~~~~~~~~~~~~~ The base form of the verb is needed here.
     422 | computations that can be attacked. Technologies studied in modern cryptography
Suggest:
  - Replace with: “to distribute”



Lint:    Capitalization (127 priority)
Message: |
     427 | #### Databases and data mining
         | ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Try to use title case in headings.
Suggest:
  - Replace with: “#### Databases and Data Mining”



Lint:    WordChoice (63 priority)
Message: |
     432 | languages. Data mining is a process of discovering patterns in large data sets.
         |                                                                      ^~~~~~~~~ Did you mean the closed compound noun “datasets”?
Suggest:
  - Replace with: “datasets”



Lint:    Spelling (63 priority)
Message: |
     436 | The philosopher of computing Bill Rapaport noted three Great Insights of
         |                                   ^~~~~~~~ Did you mean to spell `Rapaport` this way?
     437 | Computer Science:
Suggest:
  - Replace with: “Rapport”
  - Replace with: “Rappaport”
  - Replace with: “Rapports”



Lint:    Spelling (63 priority)
Message: |
     439 | - Gottfried Wilhelm Leibniz's, George Boole's, Alan Turing's, Claude Shannon's,
         |   ^~~~~~~~~ Did you mean to spell `Gottfried` this way?
Suggest:
  - Replace with: “Guttered”
  - Replace with: “Lotteries”
  - Replace with: “Notified”



Lint:    Spelling (127 priority)
Message: |
     444 |   > easily distinguishable states, such as "on/off", "magnetized/de-magnetized",
         |                                                                  ^~~~~~~~~~~~~ This looks like a prefix that can be joined with the rest of the word.
     445 |   > "high-voltage/low-voltage", etc.).
Suggest:
  - Replace with: “demagnetized”



Lint:    Capitalization (31 priority)
Message: |
     456 |   - print 1 at current location.
         |     ^~~~~ This sentence does not start with a capital letter
Suggest:
  - Replace with: “Print”



Lint:    Spelling (63 priority)
Message: |
     458 | - Corrado Böhm and Giuseppe Jacopini's insight: there are only three ways of
         |   ^~~~~~~ Did you mean to spell `Corrado` this way?
Suggest:
  - Replace with: “Comrade”
  - Replace with: “Corral”
  - Replace with: “Corridor”



Lint:    Spelling (63 priority)
Message: |
     458 | - Corrado Böhm and Giuseppe Jacopini's insight: there are only three ways of
         |           ^~~~ Did you mean to spell `Böhm` this way?
Suggest:
  - Replace with: “Bah”
  - Replace with: “Baht”
  - Replace with: “Beam”



Lint:    Spelling (63 priority)
Message: |
     458 | - Corrado Böhm and Giuseppe Jacopini's insight: there are only three ways of
         |                             ^~~~~~~~~~ Did you mean `Jacobin's`?
Suggest:
  - Replace with: “Jacobin's”



Lint:    Capitalization (31 priority)
Message: |
     466 |   - selection: IF such-and-such is the case, THEN do this, ELSE do that;
         |     ^~~~~~~~~ This sentence does not start with a capital letter
Suggest:
  - Replace with: “Selection”



Lint:    Capitalization (31 priority)
Message: |
     467 |   - repetition: WHILE such-and-such is the case, DO this. The three rules of
         |     ^~~~~~~~~~ This sentence does not start with a capital letter
Suggest:
  - Replace with: “Repetition”



Lint:    Spelling (63 priority)
Message: |
     467 |   - repetition: WHILE such-and-such is the case, DO this. The three rules of
     468 |     Boehm's and Jacopini's insight can be further simplified with the use of
         |     ^~~~~~~ Did you mean to spell `Boehm's` this way?
Suggest:
  - Replace with: “Boer's”
  - Replace with: “Bohr's”
  - Replace with: “Beam's”



Lint:    Spelling (63 priority)
Message: |
     467 |   - repetition: WHILE such-and-such is the case, DO this. The three rules of
     468 |     Boehm's and Jacopini's insight can be further simplified with the use of
         |                 ^~~~~~~~~~ Did you mean `Jacobin's`?
Suggest:
  - Replace with: “Jacobin's”



Lint:    Spelling (63 priority)
Message: |
     468 |     Boehm's and Jacopini's insight can be further simplified with the use of
     469 |     goto (which means it is more elementary than structured programming).
         |     ^~~~ Did you mean to spell `goto` this way?
Suggest:
  - Replace with: “goo”
  - Replace with: “got”
  - Replace with: “goths”



Lint:    Typo (31 priority)
Message: |
     468 |     Boehm's and Jacopini's insight can be further simplified with the use of
     469 |     goto (which means it is more elementary than structured programming).
         |     ^~~~ `goto` should probably be written as `go to`.
Suggest:
  - Replace with: “go to”



Lint:    Capitalization (127 priority)
Message: |
     471 | ## Programming paradigms
         | ^~~~~~~~~~~~~~~~~~~~~~~~ Try to use title case in headings.
Suggest:
  - Replace with: “## Programming Paradigms”



Lint:    Punctuation (31 priority)
Message: |
     490 |   the data fields of the object with which they are associated. Thus
         |                                                                 ^~~~ Discourse markers at the beginning of a sentence should be followed by a comma.
     491 |   object-oriented computer programs are made out of objects that interact with
Suggest:
  - Insert “,”






================================================
FILE: harper-core/tests/text/linters/Difficult sentences.snap.yml
================================================
Lint:    Capitalization (127 priority)
Message: |
       1 | # Difficult sentences
         | ^~~~~~~~~~~~~~~~~~~~~ Try to use title case in headings.
Suggest:
  - Replace with: “# Difficult Sentences”



Lint:    Capitalization (31 priority)
Message: |
      20 | at the bottom of the page; sitting at the table; at church; at sea
         | ^~ This sentence does not start with a capital letter
Suggest:
  - Replace with: “At”



Lint:    Capitalization (31 priority)
Message: |
      32 | men at work; children at play
         | ^~~ This sentence does not start with a capital letter
Suggest:
  - Replace with: “Men”



Lint:    Spelling (63 priority)
Message: |
      56 | He was protected by his body armour.
         |                              ^~~~~~ Did you mean to spell `armour` this way?
Suggest:
  - Replace with: “armor”
  - Replace with: “amour”
  - Replace with: “arbor”



Lint:    Capitalization (31 priority)
Message: |
      76 | sold by the yard; cheaper if bought by the gross
         | ^~~~ This sentence does not start with a capital letter
Suggest:
  - Replace with: “Sold”



Lint:    Spelling (63 priority)
Message: |
      87 | Are you eating by Rabbi Fischer? (at the house of)
      88 | By Chabad, it's different. (with, among)
         |    ^~~~~~ Did you mean to spell `Chabad` this way?
Suggest:
  - Replace with: “Cabal”
  - Replace with: “Chad”
  - Replace with: “Charade”



Lint:    Capitalization (31 priority)
Message: |
     100 | a by path; a by room (Out of the way, off to one side.)
         | ^ This sentence does not start with a capital letter
Suggest:
  - Replace with: “A”



Lint:    Capitalization (31 priority)
Message: |
     126 | Who's for ice-cream?
         | ^~~~~ The canonical dictionary spelling is `who's`.
Suggest:
  - Replace with: “who's”



Lint:    Capitalization (31 priority)
Message: |
     160 | to account for one's whereabouts.
         | ^~ This sentence does not start with a capital letter
Suggest:
  - Replace with: “To”



Lint:    Spelling (63 priority)
Message: |
     180 | I’ve been doing this from pickney.
         |                           ^~~~~~~ Did you mean to spell `pickney` this way?
Suggest:
  - Replace with: “picket”
  - Replace with: “pickle”
  - Replace with: “piney”



Lint:    Spelling (63 priority)
Message: |
     208 | My aim in travelling there was to find my missing friend.
         |           ^~~~~~~~~~ Did you mean to spell `travelling` this way?
Suggest:
  - Replace with: “traveling”
  - Replace with: “travailing”
  - Replace with: “travelings”



Lint:    Typo (127 priority)
Message: |
     243 | His parents got him an in with the company.
         |                     ^~ Did you mean `and in`?
Suggest:
  - Replace with: “and”



Lint:    Spelling (63 priority)
Message: |
     249 | The bullet is about five centimetres in.
         |                          ^~~~~~~~~~~ Did you mean to spell `centimetres` this way?
Suggest:
  - Replace with: “centimeters”
  - Replace with: “centimeter's”
  - Replace with: “centimeter”



Lint:    Capitalization (31 priority)
Message: |
     254 | the in train (incoming train)
         | ^~~ This sentence does not start with a capital letter
Suggest:
  - Replace with: “The”



Lint:    Spelling (63 priority)
Message: |
     256 | in by descent; in by purchase; in of the seisin of her husband
         |                                          ^~~~~~ Did you mean to spell `seisin` this way?
     257 | He is very in with the Joneses.
Suggest:
  - Replace with: “season”
  - Replace with: “seismic”
  - Replace with: “sepsis”



Lint:    Spelling (63 priority)
Message: |
     258 | I need to keep in with the neighbours in case I ever need a favour from them.
         |                            ^~~~~~~~~~ Did you mean to spell `neighbours` this way?
Suggest:
  - Replace with: “neighbors”
  - Replace with: “neighbor's”
  - Replace with: “neighbor”



Lint:    Spelling (63 priority)
Message: |
     258 | I need to keep in with the neighbours in case I ever need a favour from them.
         |                                                             ^~~~~~ Did you mean to spell `favour` this way?
Suggest:
  - Replace with: “favor”
  - Replace with: “famous”
  - Replace with: “flavor”



Lint:    Spelling (63 priority)
Message: |
     280 | Welcome to the historic town of Harwich.
         |                                 ^~~~~~~ Did you mean to spell `Harwich` this way?
Suggest:
  - Replace with: “Norwich”
  - Replace with: “Warwick”



Lint:    Spelling (63 priority)
Message: |
     284 | This behaviour is typical of teenagers.
         |      ^~~~~~~~~ Did you mean to spell `behaviour` this way?
Suggest:
  - Replace with: “behavior”
  - Replace with: “behaviors”



Lint:    Style (63 priority)
Message: |
     289 | It's not that big of a deal.
         |               ^~~~~~~~ The word `of` is not needed here.
Suggest:
  - Replace with: “big a”



Lint:    Spelling (63 priority)
Message: |
     300 | That TV programme that you wanted to watch is on now.
         |         ^~~~~~~~~ Did you mean to spell `programme` this way?
Suggest:
  - Replace with: “programmed”
  - Replace with: “programmer”
  - Replace with: “programmes”



Lint:    Spelling (63 priority)
Message: |
     310 | Ponsonby-Smythe hit a thumping on drive.
         | ^~~~~~~~ Did you mean to spell `Ponsonby` this way?
Suggest:
  - Replace with: “Poison”
  - Replace with: “Poison's”
  - Replace with: “Poisoned”



Lint:    Spelling (63 priority)
Message: |
     310 | Ponsonby-Smythe hit a thumping on drive.
         |          ^~~~~~ Did you mean to spell `Smythe` this way?
Suggest:
  - Replace with: “Scythe”
  - Replace with: “Smith”
  - Replace with: “Smiths”



Lint:    Agreement (31 priority)
Message: |
     310 | Ponsonby-Smythe hit a thumping on drive.
         |                     ^~~~~~~~~~ `thumping` is a mass noun.
Suggest:
  - Replace with: “thumping”
  - Replace with: “some thumping”
  - Replace with: “a piece of thumping”



Lint:    Capitalization (31 priority)
Message: |
     316 | turn the television on
         | ^~~~ This sentence does not start with a capital letter
Suggest:
  - Replace with: “Turn”



Lint:    Capitalization (31 priority)
Message: |
     322 | and so on.
         | ^~~ This sentence does not start with a capital letter
Suggest:
  - Replace with: “And”



Lint:    Capitalization (31 priority)
Message: |
     340 | on the left, on the right, on the side, on the bottom.
         | ^~ This sentence does not start with a capital letter
Suggest:
  - Replace with: “On”



Lint:    Capitalization (31 priority)
Message: |
     342 | on a bus, on a train, on a plane, on a ferry, on a yacht.
         | ^~ This sentence does not start with a capital letter
Suggest:
  - Replace with: “On”



Lint:    Redundancy (31 priority)
Message: |
     343 | All of the responsibility is on him.
         | ^~~~~~~~~~ Consider simplifying to `all the`.
Suggest:
  - Replace with: “All the”



Lint:    Capitalization (31 priority)
Message: |
     345 | tug on the rope; push hard on the door.
         | ^~~ This sentence does not start with a capital letter
Suggest:
  - Replace with: “Tug”



Lint:    Capitalization (31 priority)
Message: |
     349 | to play on a violin or piano.
         | ^~ This sentence does not start with a capital letter
Suggest:
  - Replace with: “To”



Lint:    Spelling (63 priority)
Message: |
     358 | Smith scored again on twelve minutes, doubling Mudchester Rovers' lead.
         |                                                ^~~~~~~~~~ Did you mean `Manchester`?
Suggest:
  - Replace with: “Manchester”



Lint:    Spelling (63 priority)
Message: |
     366 | He travelled on false documents.
         |    ^~~~~~~~~ Did you mean to spell `travelled` this way?
Suggest:
  - Replace with: “traveled”
  - Replace with: “traveler”
  - Replace with: “travailed”



Lint:    Spelling (63 priority)
Message: |
     398 | Who am I to criticise? I've done worse things myself.
         |             ^~~~~~~~~ Did you mean to spell `criticise` this way?
Suggest:
  - Replace with: “criticize”
  - Replace with: “criticism”
  - Replace with: “critic's”



Lint:    Capitalization (31 priority)
Message: |
     449 | slain with robbers.
         | ^~~~~ This sentence does not start with a capital letter
Suggest:
  - Replace with: “Slain”



Lint:    Capitalization (31 priority)
Message: |
     450 | cut with a knife
         | ^~~ This sentence does not start with a capital letter
Suggest:
  - Replace with: “Cut”



Lint:    Capitalization (31 priority)
Message: |
     461 | overcome with happiness
         | ^~~~~~~~ This sentence does not start with a capital letter
Suggest:
  - Replace with: “Overcome”






================================================
FILE: harper-core/tests/text/linters/Part-of-speech tagging.snap.yml
================================================
Lint:    Capitalization (127 priority)
Message: |
       6 | # Part-of-speech tagging
         | ^~~~~~~~~~~~~~~~~~~~~~~~ Try to use title case in headings.
Suggest:
  - Replace with: “# Part-of-Speech Tagging”



Lint:    Readability (127 priority)
Message: |
       8 | In corpus linguistics, part-of-speech tagging (POS tagging or PoS tagging or
         | ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
       9 | POST), also called grammatical tagging is the process of marking up a word in a
         | ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
      10 | text (corpus) as corresponding to a particular part of speech, based on both its
         | ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
      11 | definition and its context. A simplified form of this is commonly taught to
         | ~~~~~~~~~~~~~~~~~~~~~~~~~~~ This sentence is 46 words long.



Lint:    Capitalization (127 priority)
Message: |
       8 | In corpus linguistics, part-of-speech tagging (POS tagging or PoS tagging or
         |                                                               ^~~ This word's canonical spelling is all-caps.
       9 | POST), also called grammatical tagging is the process of marking up a word in a
Suggest:
  - Replace with: “POS”



Lint:    Spelling (63 priority)
Message: |
       8 | In corpus linguistics, part-of-speech tagging (POS tagging or PoS tagging or
         |                                                               ^~~ Did you mean to spell `PoS` this way?
       9 | POST), also called grammatical tagging is the process of marking up a word in a
Suggest:
  - Replace with: “Pod”
  - Replace with: “Poi”
  - Replace with: “Pol”



Lint:    Spelling (63 priority)
Message: |
      18 | two distinctive groups: rule-based and stochastic. E. Brill's tagger, one of the
         |                                                    ^~ Did you mean to spell `E.` this way?
Suggest:
  - Replace with: “E”
  - Replace with: “Ea”
  - Replace with: “Ed”



Lint:    Spelling (63 priority)
Message: |
      18 | two distinctive groups: rule-based and stochastic. E. Brill's tagger, one of the
         |                                                       ^~~~~~~ Did you mean to spell `Brill's` this way?
      19 | first and most widely used English POS-taggers, employs rule-based algorithms.
Suggest:
  - Replace with: “Brillo's”
  - Replace with: “Bill's”
  - Replace with: “Drill's”



Lint:    Style (127 priority)
Message: |
      32 | Correct grammatical tagging will reflect that "dogs" is here used as a verb, not
      33 | as the more common plural noun. Grammatical context is one way to determine
         |        ^~~~~~~~~~~ This is not an error, but an inflected form of this adjective also exists
Suggest:
  - Replace with: “commoner”



Lint:    Readability (127 priority)
Message: |
      33 | as the more common plural noun. Grammatical context is one way to determine
         |                                 ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
      34 | this; semantic analysis can also be used to infer that "sailor" and "hatch"
         | ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
      35 | implicate "dogs" as 1) in the nautical context and 2) an action applied to the
         | ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
      36 | object "hatch" (in this context, "dogs" is a nautical term meaning "fastens (a
         | ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
      37 | watertight door) securely").
         | ~~~~~~~~~~~~~~~~~~~~~~~~~~~~ This sentence is 49 words long.



Lint:    Capitalization (127 priority)
Message: |
      39 | ### Tag sets
         | ^~~~~~~~~~~~ Try to use title case in headings.
Suggest:
  - Replace with: “### Tag Sets”



Lint:    Spelling (127 priority)
Message: |
      43 | However, there are clearly many more categories and sub-categories. For nouns,
         |                                                     ^~~~~~~~~~~~~~ This looks like a prefix that can be joined with the rest of the word.
Suggest:
  - Replace with: “subcategories”



Lint:    Spelling (63 priority)
Message: |
      49 | tags. For example, NN for singular common nouns, NNS for plural common nouns, NP
         |                    ^~ Did you mean to spell `NN` this way?
Suggest:
  - Replace with: “No”
  - Replace with: “Non”
  - Replace with: “Nu”



Lint:    Spelling (63 priority)
Message: |
      49 | tags. For example, NN for singular common nouns, NNS for plural common nouns, NP
         |                                                  ^~~ Did you mean to spell `NNS` this way?
      50 | for singular proper nouns (see the POS tags used in the Brown Corpus). Other
Suggest:
  - Replace with: “NES”
  - Replace with: “Nos”
  - Replace with: “Nuns”



Lint:    Spelling (63 priority)
Message: |
      49 | tags. For example, NN for singular common nouns, NNS for plural common nouns, NP
         |                                                                               ^~ Did you mean to spell `NP` this way?
      50 | for singular proper nouns (see the POS tags used in the Brown Corpus). Other
Suggest:
  - Replace with: “Nap”
  - Replace with: “Nip”
  - Replace with: “No”



Lint:    Spelling (63 priority)
Message: |
      55 | 150 separate parts of speech for English. Work on stochastic methods for tagging
      56 | Koine Greek (DeRose 1990) has used over 1,000 parts of speech and found that
         | ^~~~~ Did you mean to spell `Koine` this way?
Suggest:
  - Replace with: “Kline”
  - Replace with: “Kine”
  - Replace with: “Kin”



Lint:    Spelling (63 priority)
Message: |
      55 | 150 separate parts of speech for English. Work on stochastic methods for tagging
      56 | Koine Greek (DeRose 1990) has used over 1,000 parts of speech and found that
         |              ^~~~~~ Did you mean to spell `DeRose` this way?
Suggest:
  - Replace with: “Depose”
  - Replace with: “Debase”
  - Replace with: “Decode”



Lint:    Spelling (63 priority)
Message: |
      57 | about as many words were ambiguous in that language as in English. A
      58 | morphosyntactic descriptor in the case of morphologically rich languages is
         | ^~~~~~~~~~~~~~~ Did you mean to spell `morphosyntactic` this way?
Suggest:
  - Replace with: “morphosyntax's”
  - Replace with: “morphosyntax”



Lint:    Spelling (63 priority)
Message: |
      58 | morphosyntactic descriptor in the case of morphologically rich languages is
         |                                           ^~~~~~~~~~~~~~~ Did you mean `morphological`?
      59 | commonly expressed using very short mnemonics, such as Ncmsan for Category=Noun,
Suggest:
  - Replace with: “morphological”



Lint:    Spelling (63 priority)
Message: |
      59 | commonly expressed using very short mnemonics, such as Ncmsan for Category=Noun,
         |                                                        ^~~~~~ Did you mean to spell `Ncmsan` this way?
      60 | Type = common, Gender = masculine, Number = singular, Case = accusative, Animate
Suggest:
  - Replace with: “Nisan”
  - Replace with: “Nissan”



Lint:    Spelling (63 priority)
Message: |
      63 | The most popular "tag set" for POS tagging for American English is probably the
      64 | Penn tag set, developed in the Penn Treebank project. It is largely similar to
         |                                     ^~~~~~~~ Did you mean to spell `Treebank` this way?
Suggest:
  - Replace with: “Tie back”
  - Replace with: “Tieback”
  - Replace with: “Traceback”



Lint:    WordChoice (63 priority)
Message: |
      73 | cross-language differences. The tag sets for heavily inflected languages such as
         |                                 ^~~~~~~~ Did you mean the closed compound noun “tagsets”?
Suggest:
  - Replace with: “tagsets”



Lint:    Spelling (63 priority)
Message: |
      75 | as Inuit languages may be virtually impossible. At the other extreme, Petrov et
         |                                                                       ^~~~~~ Did you mean to spell `Petrov` this way?
      76 | al. have proposed a "universal" tag set, with 12 categories (for example, no
Suggest:
  - Replace with: “Petrol”
  - Replace with: “Patrol”
  - Replace with: “Patron”



Lint:    Spelling (63 priority)
Message: |
      75 | as Inuit languages may be virtually impossible. At the other extreme, Petrov et
         |                                                                              ^~~
      76 | al. have proposed a "universal" tag set, with 12 categories (for example, no
         | ~~~ Did you mean `et al.`?
Suggest:
  - Replace with: “et al.”



Lint:    Spelling (63 priority)
Message: |
      86 | The first major corpus of English for computer analysis was the Brown Corpus
      87 | developed at Brown University by Henry Kučera and W. Nelson Francis, in the
         |                                        ^~~~~~ Did you mean to spell `Kučera` this way?
Suggest:
  - Replace with: “Kara”
  - Replace with: “Kendra”
  - Replace with: “Keri”



Lint:    Spelling (63 priority)
Message: |
      87 | developed at Brown University by Henry Kučera and W. Nelson Francis, in the
         |                                                   ^~ Did you mean to spell `W.` this way?
Suggest:
  - Replace with: “We”
  - Replace with: “WA”
  - Replace with: “WI”



Lint:    Spelling (63 priority)
Message: |
      98 | and corrected by hand, and later users sent in errata so that by the late 70s
         |                                                                             ^ Did you mean to spell `s` this way?
      99 | the tagging was nearly perfect (allowing for some cases on which even human
Suggest:
  - Replace with: “so”
  - Replace with: “as”
  - Replace with: “is”



Lint:    WordChoice (126 priority)
Message: |
     104 | other languages. Statistics derived by analyzing it formed the basis for most
         |                                                                          ^~~~~
     105 | later part-of-speech tagging systems, such as CLAWS and VOLSUNGA. However, by
         | ~~~~~ The degree of the adverb conflicts with the degree of the adjective.
Suggest:
  - Replace with: “later”
  - Replace with: “latest”



Lint:    Spelling (63 priority)
Message: |
     105 | later part-of-speech tagging systems, such as CLAWS and VOLSUNGA. However, by
         |                                                         ^~~~~~~~ Did you mean to spell `VOLSUNGA` this way?
Suggest:
  - Replace with: “Volcanic”
  - Replace with: “Volcano”
  - Replace with: “Voltage”



Lint:    Readability (127 priority)
Message: |
     110 | For some time, part-of-speech tagging was considered an inseparable part of
         | ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
     111 | natural language processing, because there are certain cases where the correct
         | ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
     112 | part of speech cannot be decided without understanding the semantics or even the
         | ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
     113 | pragmatics of the context. This is extremely expensive, especially because
         | ~~~~~~~~~~~~~~~~~~~~~~~~~~ This sentence is 41 words long.



Lint:    Capitalization (127 priority)
Message: |
     117 | ### Use of hidden Markov models
         | ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Try to use title case in headings.
Suggest:
  - Replace with: “### Use of Hidden Markov Models”



Lint:    Spelling (63 priority)
Message: |
     119 | In the mid-1980s, researchers in Europe began to use hidden Markov models (HMMs)
         |                                                                            ^~~~ Did you mean to spell `HMMs` this way?
     120 | to disambiguate parts of speech, when working to tag the Lancaster-Oslo-Bergen
Suggest:
  - Replace with: “Hams”
  - Replace with: “Hems”
  - Replace with: “Hums”



Lint:    Spelling (63 priority)
Message: |
     121 | Corpus of British English. HMMs involve counting cases (such as from the Brown
         |                            ^~~~ Did you mean to spell `HMMs` this way?
Suggest:
  - Replace with: “Hams”
  - Replace with: “Hems”
  - Replace with: “Hums”



Lint:    Style (127 priority)
Message: |
     125 | program can decide that "can" in "the can" is far more likely to be a noun than
         |                                                   ^~~~~~~~~~~ This is not an error, but an inflected form of this adjective also exists
     126 | a verb or a modal. The same method can, of course, be used to benefit from
Suggest:
  - Replace with: “likelier”



Lint:    Spelling (63 priority)
Message: |
     129 | More advanced ("higher-order") HMMs learn the probabilities not only of pairs
         |                                ^~~~ Did you mean to spell `HMMs` this way?
Suggest:
  - Replace with: “Hams”
  - Replace with: “Hems”
  - Replace with: “Hums”



Lint:    Readability (127 priority)
Message: |
     141 | Eugene Charniak points out in Statistical techniques for natural language
         | ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
     142 | parsing (1997) that merely assigning the most common tag to each known word and
         | ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
     143 | the tag "proper noun" to all unknowns will approach 90% accuracy because many
         | ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
     144 | words are unambiguous, and many others only rarely represent their less-common
         | ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
     145 | parts of speech.
         | ~~~~~~~~~~~~~~~~ This sentence is 50 words long.



Lint:    Spelling (63 priority)
Message: |
     141 | Eugene Charniak points out in Statistical techniques for natural language
         |        ^~~~~~~~ Did you mean to spell `Charniak` this way?
Suggest:
  - Replace with: “Cardiac”
  - Replace with: “Carnal”
  - Replace with: “Carnival”



Lint:    Style (127 priority)
Message: |
     142 | parsing (1997) that merely assigning the most common tag to each known word and
         |                                          ^~~~~~~~~~~ This is not an error, but an inflected form of this adjective also exists
     143 | the tag "proper noun" to all unknowns will approach 90% accuracy because many
Suggest:
  - Replace with: “commonest”



Lint:    Readability (127 priority)
Message: |
     148 | expensive since it enumerated all possibilities. It sometimes had to resort to
         |                                                  ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
     149 | backup methods when there were simply too many options (the Brown Corpus
         | ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
     150 | contains a case with 17 ambiguous words in a row, and there are words such as
         | ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
     151 | "still" that can represent as many as 7 distinct parts of speech.
         | ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ This sentence is 44 words long.



Lint:    WordChoice (63 priority)
Message: |
     148 | expensive since it enumerated all possibilities. It sometimes had to resort to
     149 | backup methods when there were simply too many options (the Brown Corpus
         | ^~~~~~ This word should be a phrasal verb, not a compound noun.
Suggest:
  - Replace with: “back up”



Lint:    Spelling (63 priority)
Message: |
     153 | HMMs underlie the functioning of stochastic taggers and are used in various
         | ^~~~ Did you mean to spell `HMMs` this way?
Suggest:
  - Replace with: “Hams”
  - Replace with: “Hems”
  - Replace with: “Hums”



Lint:    Spelling (127 priority)
Message: |
     154 | algorithms one of the most widely used being the bi-directional inference
         |                                                  ^~~~~~~~~~~~~~ This looks like a prefix that can be joined with the rest of the word.
     155 | algorithm.
Suggest:
  - Replace with: “bidirectional”



Lint:    Capitalization (127 priority)
Message: |
     157 | ### Dynamic programming methods
         | ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Try to use title case in headings.
Suggest:
  - Replace with: “### Dynamic Programming Methods”



Lint:    Spelling (63 priority)
Message: |
     159 | In 1987, Steven DeRose and Kenneth W. Church independently developed dynamic
         |                 ^~~~~~ Did you mean to spell `DeRose` this way?
Suggest:
  - Replace with: “Depose”
  - Replace with: “Debase”
  - Replace with: “Decode”



Lint:    Spelling (63 priority)
Message: |
     159 | In 1987, Steven DeRose and Kenneth W. Church independently developed dynamic
         |                                    ^~ Did you mean to spell `W.` this way?
Suggest:
  - Replace with: “We”
  - Replace with: “WA”
  - Replace with: “WI”



Lint:    Spelling (63 priority)
Message: |
     160 | programming algorithms to solve the same problem in vastly less time. Their
     161 | methods were similar to the Viterbi algorithm known for some time in other
         |                             ^~~~~~~ Did you mean to spell `Viterbi` this way?
Suggest:
  - Replace with: “Vite's”
  - Replace with: “Verb”
  - Replace with: “Veteran”



Lint:    Spelling (63 priority)
Message: |
     162 | fields. DeRose used a table of pairs, while Church used a table of triples and a
         |         ^~~~~~ Did you mean to spell `DeRose` this way?
Suggest:
  - Replace with: “Depose”
  - Replace with: “Debase”
  - Replace with: “Decode”



Lint:    Readability (127 priority)
Message: |
     162 | fields. DeRose used a table of pairs, while Church used a table of triples and a
         |         ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
     163 | method of estimating the values for triples that were rare or nonexistent in the
         | ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
     164 | Brown Corpus (an actual measurement of triple probabilities would require a much
         | ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
     165 | larger corpus). Both methods achieved an accuracy of over 95%. DeRose's 1990
         | ~~~~~~~~~~~~~~~ This sentence is 43 words long.



Lint:    Spelling (63 priority)
Message: |
     165 | larger corpus). Both methods achieved an accuracy of over 95%. DeRose's 1990
         |                                                                ^~~~~~~~ Did you mean to spell `DeRose's` this way?
     166 | dissertation at Brown University included analyses of the specific error types,
Suggest:
  - Replace with: “Defoe's”
  - Replace with: “Denise's”
  - Replace with: “Demise's”



Lint:    Spelling (63 priority)
Message: |
     166 | dissertation at Brown University included analyses of the specific error types,
         |                                           ^~~~~~~~ Did you mean to spell `analyses` this way?
     167 | probabilities, and other related data, and replicated his work for Greek, where
Suggest:
  - Replace with: “analyzes”
  - Replace with: “analysis”
  - Replace with: “analysts”



Lint:    Spelling (63 priority)
Message: |
     173 | levels of linguistic analysis: syntax, morphology, semantics, and so on. CLAWS,
     174 | DeRose's and Church's methods did fail for some of the known cases where
         | ^~~~~~~~ Did you mean to spell `DeRose's` this way?
Suggest:
  - Replace with: “Defoe's”
  - Replace with: “Denise's”
  - Replace with: “Demise's”



Lint:    Readability (127 priority)
Message: |
     175 | semantics is required, but those proved negligibly rare. This convinced many in
         |                                                          ^~~~~~~~~~~~~~~~~~~~~~~
     176 | the field that part-of-speech tagging could usefully be separated from the other
         | ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
     177 | levels of processing; this, in turn, simplified the theory and practice of
         | ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
     178 | computerized language analysis and encouraged researchers to find ways to
         | ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
     179 | separate other pieces as well. Markov Models became the standard method for the
         | ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ This sentence is 45 words long.



Lint:    Capitalization (127 priority)
Message: |
     182 | #### Unsupervised taggers
         | ^~~~~~~~~~~~~~~~~~~~~~~~~ Try to use title case in headings.
Suggest:
  - Replace with: “#### Unsupervised Taggers”



Lint:    Spelling (127 priority)
Message: |
     184 | The methods already discussed involve working from a pre-existing corpus to
         |                                                      ^~~~~~~~~~~~ This looks like a prefix that can be joined with the rest of the word.
     185 | learn tag probabilities. It is, however, also possible to bootstrap using
Suggest:
  - Replace with: “preexisting”



Lint:    Capitalization (127 priority)
Message: |
     198 | #### Other taggers and methods
         | ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Try to use title case in headings.
Suggest:
  - Replace with: “#### Other Taggers and Methods”



Lint:    Spelling (63 priority)
Message: |
     200 | Some current major algorithms for part-of-speech tagging include the Viterbi
         |                                                                      ^~~~~~~ Did you mean to spell `Viterbi` this way?
     201 | algorithm, Brill tagger, Constraint Grammar, and the Baum-Welch algorithm (also
Suggest:
  - Replace with: “Vite's”
  - Replace with: “Verb”
  - Replace with: “Veteran”



Lint:    Spelling (63 priority)
Message: |
     201 | algorithm, Brill tagger, Constraint Grammar, and the Baum-Welch algorithm (also
         |                                                           ^~~~~ Did you mean to spell `Welch` this way?
     202 | known as the forward-backward algorithm). Hidden Markov model and visible Markov
Suggest:
  - Replace with: “Welsh”
  - Replace with: “Wench”
  - Replace with: “Watch”



Lint:    Spelling (63 priority)
Message: |
     203 | model taggers can both be implemented using the Viterbi algorithm. The
         |                                                 ^~~~~~~ Did you mean to spell `Viterbi` this way?
Suggest:
  - Replace with: “Vite's”
  - Replace with: “Verb”
  - Replace with: “Veteran”



Lint:    Spelling (63 priority)
Message: |
     208 | tagging. Methods such as SVM, maximum entropy classifier, perceptron, and
         |                          ^~~ Did you mean to spell `SVM` this way?
Suggest:
  - Replace with: “Sim”
  - Replace with: “Sum”
  - Replace with: “SCM”



Lint:    Spelling (63 priority)
Message: |
     213 | Wiki. This comparison uses the Penn tag set on some of the Penn Treebank data,
         |                                                                 ^~~~~~~~ Did you mean to spell `Treebank` this way?
     214 | so the results are directly comparable. However, many significant taggers are
Suggest:
  - Replace with: “Tie back”
  - Replace with: “Tieback”
  - Replace with: “Traceback”






================================================
FILE: harper-core/tests/text/linters/Spell.snap.yml
================================================
Lint:    Spelling (63 priority)
Message: |
       7 | My favourite color is blu.
         |    ^~~~~~~~~ Did you mean to spell `favourite` this way?
Suggest:
  - Replace with: “favorite”
  - Replace with: “favorites”



Lint:    Capitalization (127 priority)
Message: |
       7 | My favourite color is blu.
         |                       ^~~ The canonical dictionary spelling is title case: `Blu`.
Suggest:
  - Replace with: “Blu”



Lint:    Spelling (63 priority)
Message: |
       7 | My favourite color is blu.
         |                       ^~~ Did you mean to spell `blu` this way?
Suggest:
  - Replace with: “bl”
  - Replace with: “blue”
  - Replace with: “blur”



Lint:    Spelling (63 priority)
Message: |
       8 | I must defend my honour!
         |                  ^~~~~~ Did you mean to spell `honour` this way?
Suggest:
  - Replace with: “honor”
  - Replace with: “hour”
  - Replace with: “honer”



Lint:    Spelling (63 priority)
Message: |
       9 | I recognize that you recognise me.
         |                      ^~~~~~~~~ Did you mean to spell `recognise` this way?
Suggest:
  - Replace with: “recognize”
  - Replace with: “recognized”
  - Replace with: “recognizer”



Lint:    Spelling (63 priority)
Message: |
      11 | I analyse how you infantilise me.
         |   ^~~~~~~ Did you mean to spell `analyse` this way?
Suggest:
  - Replace with: “analyze”
  - Replace with: “analyst”
  - Replace with: “analysis”



Lint:    Spelling (63 priority)
Message: |
      11 | I analyse how you infantilise me.
         |                   ^~~~~~~~~~~ Did you mean to spell `infantilise` this way?
Suggest:
  - Replace with: “infantilize”
  - Replace with: “infantile”
  - Replace with: “infanticide”



Lint:    Spelling (63 priority)
Message: |
      12 | Careful, traveller!
         |          ^~~~~~~~~ Did you mean to spell `traveller` this way?
Suggest:
  - Replace with: “traveler”
  - Replace with: “traveled”
  - Replace with: “travelers”



Lint:    Spelling (63 priority)
Message: |
      13 | At the centre of the theatre I dropped a litre of coke.
         |        ^~~~~~ Did you mean to spell `centre` this way?
Suggest:
  - Replace with: “center”
  - Replace with: “censure”
  - Replace with: “cent”



Lint:    Spelling (63 priority)
Message: |
      13 | At the centre of the theatre I dropped a litre of coke.
         |                      ^~~~~~~ Did you mean to spell `theatre` this way?
Suggest:
  - Replace with: “theater”
  - Replace with: “there”
  - Replace with: “they're”



Lint:    Spelling (63 priority)
Message: |
      13 | At the centre of the theatre I dropped a litre of coke.
         |                                          ^~~~~ Did you mean to spell `litre` this way?
Suggest:
  - Replace with: “liter”
  - Replace with: “lithe”
  - Replace with: “lire”






================================================
FILE: harper-core/tests/text/linters/Spell.US.snap.yml
================================================
Lint:    Spelling (63 priority)
Message: |
       9 | - Afterwards.
         |   ^~~~~~~~~~ Did you mean to spell `Afterwards` this way?
Suggest:
  - Replace with: “Afterward”
  - Replace with: “Afterwords”
  - Replace with: “Afterword's”



Lint:    Spelling (63 priority)
Message: |
      10 | - Centre.
         |   ^~~~~~ Did you mean to spell `Centre` this way?
Suggest:
  - Replace with: “Center”
  - Replace with: “Censure”
  - Replace with: “Cent”



Lint:    Spelling (63 priority)
Message: |
      11 | - Labelled.
         |   ^~~~~~~~ Did you mean to spell `Labelled` this way?
Suggest:
  - Replace with: “Labeled”
  - Replace with: “Labeler”
  - Replace with: “Labelless”



Lint:    Spelling (63 priority)
Message: |
      12 | - Flavour.
         |   ^~~~~~~ Did you mean to spell `Flavour` this way?
Suggest:
  - Replace with: “Flavor”
  - Replace with: “Favor”
  - Replace with: “Flour”



Lint:    Spelling (63 priority)
Message: |
      13 | - Favoured.
         |   ^~~~~~~~ Did you mean to spell `Favoured` this way?
Suggest:
  - Replace with: “Favored”
  - Replace with: “Flavored”
  - Replace with: “Floured”



Lint:    Spelling (63 priority)
Message: |
      14 | - Honour.
         |   ^~~~~~ Did you mean to spell `Honour` this way?
Suggest:
  - Replace with: “Honor”
  - Replace with: “Hour”
  - Replace with: “Honer”



Lint:    Spelling (63 priority)
Message: |
      15 | - Grey.
         |   ^~~~ Did you mean to spell `Grey` this way?
Suggest:
  - Replace with: “Gray”
  - Replace with: “Grew”
  - Replace with: “Gorey”



Lint:    Spelling (63 priority)
Message: |
      16 | - Quarrelled.
         |   ^~~~~~~~~~ Did you mean to spell `Quarrelled` this way?
Suggest:
  - Replace with: “Quarreled”
  - Replace with: “Quarreler”



Lint:    Spelling (63 priority)
Message: |
      17 | - Quarrelling.
         |   ^~~~~~~~~~~ Did you mean `Quarreling`?
Suggest:
  - Replace with: “Quarreling”



Lint:    Spelling (63 priority)
Message: |
      18 | - Recognised.
         |   ^~~~~~~~~~ Did you mean to spell `Recognised` this way?
Suggest:
  - Replace with: “Recognized”
  - Replace with: “Recognize”
  - Replace with: “Recognizer”



Lint:    Spelling (63 priority)
Message: |
      19 | - Neighbour.
         |   ^~~~~~~~~ Did you mean to spell `Neighbour` this way?
Suggest:
  - Replace with: “Neighbor”
  - Replace with: “Neighbors”



Lint:    Spelling (63 priority)
Message: |
      20 | - Neighbouring.
         |   ^~~~~~~~~~~~ Did you mean `Neighboring`?
Suggest:
  - Replace with: “Neighboring”



Lint:    Spelling (63 priority)
Message: |
      21 | - Clamour.
         |   ^~~~~~~ Did you mean to spell `Clamour` this way?
Suggest:
  - Replace with: “Clamor”
  - Replace with: “Glamour”
  - Replace with: “Cavour”



Lint:    Spelling (63 priority)
Message: |
      22 | - Theatre.
         |   ^~~~~~~ Did you mean to spell `Theatre` this way?
Suggest:
  - Replace with: “Theater”
  - Replace with: “There”
  - Replace with: “They're”



Lint:    Spelling (63 priority)
Message: |
      23 | - Analyse.
         |   ^~~~~~~ Did you mean to spell `Analyse` this way?
Suggest:
  - Replace with: “Analyze”
  - Replace with: “Analyst”
  - Replace with: “Analysis”






================================================
FILE: harper-core/tests/text/linters/Swear.snap.yml
================================================
Lint:    WordChoice (127 priority)
Message: |
       7 | One turd, two turds.
         |     ^~~~ Try to avoid offensive language.
Suggest:
  - Replace with: “poo”
  - Replace with: “poop”
  - Replace with: “feces”
  - Replace with: “dung”



Lint:    WordChoice (127 priority)
Message: |
       7 | One turd, two turds.
         |               ^~~~~ Try to avoid offensive language.
Suggest:
  - Replace with: “poos”
  - Replace with: “poops”
  - Replace with: “feces”
  - Replace with: “dung”



Lint:    WordChoice (127 priority)
Message: |
       9 | I fart, you're farting, he farts, she farted.
         |   ^~~~ Try to avoid offensive language.
Suggest:
  - Replace with: “gas”
  - Replace with: “wind”
  - Replace with: “break wind”



Lint:    WordChoice (127 priority)
Message: |
       9 | I fart, you're farting, he farts, she farted.
         |                ^~~~~~~ Try to avoid offensive language.
Suggest:
  - Replace with: “breaking wind”



Lint:    WordChoice (127 priority)
Message: |
       9 | I fart, you're farting, he farts, she farted.
         |                            ^~~~~ Try to avoid offensive language.
Suggest:
  - Replace with: “gas”
  - Replace with: “wind”
  - Replace with: “breaks wind”



Lint:    WordChoice (127 priority)
Message: |
       9 | I fart, you're farting, he farts, she farted.
         |                                       ^~~~~~ Try to avoid offensive language.
Suggest:
  - Replace with: “broke wind”
  - Replace with: “broken wind”






================================================
FILE: harper-core/tests/text/linters/this and that.snap.yml
================================================
[Empty file]


================================================
FILE: harper-core/tests/text/tagged/Difficult sentences.md
================================================
>              Difficult sentences
# HeadingStart VB/J+     NPl/V3+
>
#
> A   collection of difficult sentences to test   Harper's ability to correctly tag     unusual / uncommon but     correct  sentences .
# D/P N🅪Sg       P  VB/J      NPl/V3+   P  NSg/VB NPr$     N🅪Sg+   P  R         NSg/VB+ NSg/J   . NSg/VB/J NSg/C/P NSg/VB/J NPl/V3+   .
>
#
> Note    that         some      word    may     not     be      tagged correctly right    now       .
# NSg/VB+ NSg/I/C/Ddem I/J/R/Dq+ NSg/VB+ NPr/VXB NSg/R/C NSg/VXB VP/J   R         NPr/VB/J NSg/J/R/C .
>
#
> Most         example sentences are taken from https://en.wiktionary.org/. License : CC         BY    - SA        4.0 .
# NSg/I/J/R/Dq NSg/VB+ NPl/V3+   VB  VPp/J P    Url                         NSg/VB+ . NSg/VB/#r+ NSg/P . NPr/VB/J+ #   .
>
#
>              A
# HeadingStart D/P
>
#
> With one      attack    , he       was torn a   pieces .
# P    NSg/I/J+ NSg/VB/J+ . NPr/ISg+ VPt VB/J D/P NPl/V3 .
> I       brush  my  teeth twice a    day     .
# ISg/#r+ NSg/VB D$+ NPl+  R     D/P+ NPr🅪Sg+ .
>
#
>              At
# HeadingStart NSg/P
>
#
>              Preposition
# HeadingStart NSg/VB
>
#
> Caesar was at    Rome ; a   climate  treaty  was signed at    Kyoto in        1997 .
# NPr    VPt NSg/P NPr+ . D/P N🅪Sg/VB+ NSg/VB+ VPt VP/J   NSg/P NPr+  NPr/J/R/P #    .
> I       was at    Jim’s house   at    the corner of Fourth   Street   and  Vine .
# ISg/#r+ VPt NSg/P NPr$  NPr/VB+ NSg/P D   NSg/VB P  NPr/VB/J NSg/VB/J VB/C NSg+ .
> at    the bottom   of the page    ; sitting  at    the table   ; at    church     ; at    sea
# NSg/P D   NSg/VB/J P  D+  NPr/VB+ . NSg/Vg/J NSg/P D+  NSg/VB+ . NSg/P NPr🅪Sg/VB+ . NSg/P NSg+
> Target  at    five miles  . Prepare torpedoes !
# NSg/VB+ NSg/P NSg+ NPrPl+ . VB      NPl/VB    .
> Look   out          ! UFO at    two o'clock !
# NSg/VB NSg/VB/J/R/P . NSg NSg/P NSg R       .
> Don't pick   at    your food !
# VXB   NSg/VB NSg/P D$+  NSg+ .
> My  cat       keeps  scratching at    the furniture .
# D$+ NSg/VB/J+ NPl/V3 Nᴹ/Vg/J    NSg/P D+  Nᴹ+       .
> I       was working at    the problem all           day     .
# ISg/#r+ VPt Nᴹ/Vg/J NSg/P D+  NSg/J+  NSg/I/J/C/Dq+ NPr🅪Sg+ .
> He       shouted at    her     .
# NPr/ISg+ VP/J    NSg/P ISg/D$+ .
> She  pointed at    the curious animal .
# ISg+ VP/J    NSg/P D+  J+      NSg/J+ .
> At    my  request , they agreed to move   us       to another hotel .
# NSg/P D$+ NSg/VB+ . IPl+ VP/J   P  NSg/VB NPr/IPl+ P  I/D+    NSg+  .
> He       jumped at    the sudden noise    .
# NPr/ISg+ VP/J   NSg/P D+  NSg/J+ N🅪Sg/VB+ .
> We   laughed at    the joke    .
# IPl+ VP/J    NSg/P D+  NSg/VB+ .
> She  was mad      at    their comments .
# ISg+ VPt NSg/VB/J NSg/P D$+   NPl/V3+  .
> men at    work     ; children at    play
# NPl NSg/P N🅪Sg/VB+ . NPl+     NSg/P N🅪Sg/VB
> The two  countries are at    war      .
# D+  NSg+ NPl+      VB  NSg/P N🅪Sg/VB+ .
> She  is  at    sixes and  sevens with him  .
# ISg+ VL3 NSg/P NPl   VB/C NPl    P    ISg+ .
>
#
>              Noun
# HeadingStart NSg/VB+
>
#
> The at    sign    .
# D   NSg/P NSg/VB+ .
>
#
>              Verb
# HeadingStart NSg/VB+
>
#
> ( In        online chats   : ) Don't @ me       ! Don't at    me       !
# . NPr/J/R/P VB/J+  NPl/V3+ . . VXB   . NPr/ISg+ . VXB   NSg/P NPr/ISg+ .
>
#
>              By
# HeadingStart NSg/P
>
#
>              Preposition
# HeadingStart NSg/VB
>
#
> The mailbox is  by    the bus     stop   .
# D   NSg     VL3 NSg/P D   NSg/VB+ NSg/VB .
> The stream  runs   by    our back     door    .
# D+  NSg/VB+ NPl/V3 NSg/P D$+ NSg/VB/J NSg/VB+ .
> He       ran     straight   by    me       .
# NPr/ISg+ NSg/VPt NSg/VB/J/R NSg/P NPr/ISg+ .
> Be      back     by    ten o'clock ! .
# NSg/VXB NSg/VB/J NSg/P NSg R       . .
> We'll find   someone by    the end    of March   .
# K     NSg/VB NSg/I+  NSg/P D   NSg/VB P  NPr/VB+ .
> We   will    send   it       by    the first week  of July .
# IPl+ NPr/VXB NSg/VB NPr/ISg+ NSg/P D   NSg/J NSg/J P  NPr+ .
> The matter   was decided  by    the chairman .
# D+  N🅪Sg/VB+ VPt NSg/VP/J NSg/P D+  NSg/VB+  .
> The boat    was swamped by    the water    .
# D+  NSg/VB+ VPt VP/J    NSg/P D+  N🅪Sg/VB+ .
> He       was protected by    his     body    armour       .
# NPr/ISg+ VPt VP/J      NSg/P ISg/D$+ NSg/VB+ NPr/VB/Comm+ .
> There was a    call    by    the unions   for   a   30 % pay      rise    .
# R+    VPt D/P+ NSg/VB+ NSg/P D   NPrPl/V3 R/C/P D/P #  . NSg/VB/J NSg/VB+ .
> I       was aghast by    what   I       saw     .
# ISg/#r+ VPt J      NSg/P NSg/I+ ISg/#r+ NSg/VPt .
> There are many       well       - known plays  by    William Shakespeare .
# R+    VB  NSg/I/J/Dq NSg/VB/J/R . VPp/J NPl/V3 NSg/P NPr+    NPr/VB+     .
> I       avoided the guards  by    moving  only  when    they weren't looking .
# ISg/#r+ VP/J    D+  NPl/V3+ NSg/P Nᴹ/Vg/J J/R/C NSg/I/C IPl+ VPt     Nᴹ/Vg/J .
> By    Pythagoras ' theorem , we   can     calculate the length  of the hypotenuse .
# NSg/P NPr        . NSg/VB  . IPl+ NPr/VXB VB        D   N🅪Sg/VB P  D   NSg        .
> We   went    by    bus     .
# IPl+ NSg/VPt NSg/P NSg/VB+ .
> I       discovered it       by    chance    .
# ISg/#r+ VP/J       NPr/ISg+ NSg/P NPr/VB/J+ .
> By    ' maybe   ' she  means  ' no       ' .
# NSg/P . NSg/J/R . ISg+ NPl/V3 . NSg/Dq/P . .
> The electricity was cut       off        , so          we   had to read    by    candlelight .
# D+  Nᴹ+         VPt NSg/VBP/J NSg/VB/J/P . NSg/I/J/R/C IPl+ VP  P  NSg/VBP NSg/P Nᴹ          .
> By    the power      vested in        me       , I       now       pronounce you    man      and  wife      .
# NSg/P D+  N🅪Sg/VB/J+ VP/J   NPr/J/R/P NPr/ISg+ . ISg/#r+ NSg/J/R/C NSg/VB    ISgPl+ NPr/VB/J VB/C NSg/VB/J+ .
> By    Jove ! I       think  she's got it       !
# NSg/P NPr+ . ISg/#r+ NSg/VB K     VP  NPr/ISg+ .
> By    all           that          is  holy    , I'll put     an  end     to this    .
# NSg/P NSg/I/J/C/Dq+ NSg/I/C/Ddem+ VL3 NSg/J/R . K    NSg/VBP D/P NSg/VB+ P  I/Ddem+ .
> I       sorted the items   by    category .
# ISg/#r+ VP/J   D   NPl/V3+ NSg/P NSg+     .
> Table   1 shows  details of our employees broken down        by    sex    and  age      .
# NSg/VB+ # NPl/V3 NPl/V3  P  D$+ NPl+      VPp/J  N🅪Sg/VB/J/P NSg/P NSg/VB VB/C N🅪Sg/VB+ .
> Our stock      is  up         by    ten  percent .
# D$+ N🅪Sg/VB/J+ VL3 NSg/VB/J/P NSg/P NSg+ NSg+    .
> We   won      by    six  goals   to three .
# IPl+ NSgPl/VP NSg/P NSg+ NPl/V3+ P  NSg   .
> His     date    of birth     was wrong      by    ten  years .
# ISg/D$+ N🅪Sg/VB P  NSg/VB/J+ VPt NSg/VB/J/R NSg/P NSg+ NPl+  .
> We   went    through the book    page    by    page    .
# IPl+ NSg/VPt NSg/J/P D+  NSg/VB+ NPr/VB+ NSg/P NPr/VB+ .
> We   crawled forward  by    inches  .
# IPl+ VP/J    NSg/VB/J NSg/P NPl/V3+ .
> sold   by    the yard    ; cheaper if    bought by    the gross
# NSg/VP NSg/P D+  NSg/VB+ . NSg/JC  NSg/C NSg/VP NSg/P D   NPr/VB/J
> While      sitting  listening to the radio    by    the hour , she  can     drink   brandy  by    the bucketful !
# NSg/VB/C/P NSg/Vg/J Nᴹ/Vg/J   P  D+  N🅪Sg/VB+ NSg/P D+  NSg+ . ISg+ NPr/VXB NSg/VB+ NPr/VB+ NSg/P D   NSg       .
> He       sits   listening to the radio    by    the hour .
# NPr/ISg+ NPl/V3 Nᴹ/Vg/J   P  D+  N🅪Sg/VB+ NSg/P D+  NSg+ .
> His     health was deteriorating by    the day     .
# ISg/D$+ Nᴹ+    VPt Nᴹ/Vg/J       NSg/P D+  NPr🅪Sg+ .
> The pickers are paid by    the bushel .
# D   W?      VB  VP/J NSg/P D   NSg/VB .
> He       cheated by    his     own       admission .
# NPr/ISg+ VP/J    NSg/P ISg/D$+ NSg/VB/J+ NSg+      .
> By    my  reckoning , we   should be      nearly there .
# NSg/P D$+ Nᴹ/Vg/J+  . IPl+ VXB    NSg/VXB R      R     .
> It       is  easy     to invert   a   2 - by    - 2 matrix .
# NPr/ISg+ VL3 NSg/VB/J P  NSg/VB/J D/P # . NSg/P . # NSg+   .
> The room       was about 4 foot   by    6 foot    .
# D+  N🅪Sg/VB/J+ VPt J/P   # NSg/VB NSg/P # NSg/VB+ .
> The bricks  used to build  the wall    measured 10 by    20 by    30 cm  .
# D+  NPl/V3+ VP/J P  NSg/VB D+  NPr/VB+ VP/J     #  NSg/P #  NSg/P #  #r+ .
> She's a   lovely little     filly , by    Big   Lad , out          of Damsel in        Distress .
# K     D/P NSg/J  NPr/I/J/Dq NSg   . NSg/P NSg/J NSg . NSg/VB/J/R/P P  NSg    NPr/J/R/P Nᴹ/VB+   .
> Are you    eating  by    Rabbi Fischer ? ( at    the house  of )
# VB  ISgPl+ Nᴹ/Vg/J NSg/P NSg+  NPr+    . . NSg/P D   NPr/VB P  .
> By    Chabad , it's different . ( with , among )
# NSg/P ?      . +    NSg/J     . . P    . P     .
>
#
>              Adverb
# HeadingStart NSg/VB+
>
#
> I       watched the parade  as    it       passed by    .
# ISg/#r+ VP/J    D+  NSg/VB+ R/C/P NPr/ISg+ VP/J   NSg/P .
> There was a    shepherd close    by    .
# R+    VPt D/P+ NPr/VB+  NSg/VB/J NSg/P .
> I'll stop   by    on  my  way    home     from work     .
# K    NSg/VB NSg/P J/P D$+ NSg/J+ NSg/VB/J P    N🅪Sg/VB+ .
> We're right    near       the lifeguard station . Come       by    before you    leave  .
# K     NPr/VB/J NSg/VB/J/P D   NSg+      NSg/VB+ . NSg/VBPp/P NSg/P C/P    ISgPl+ NSg/VB .
> The women spent much         time       after harvest putting jams    by    for   winter  and  spring   .
# D+  NPl+  VP/J  NSg/I/J/R/Dq N🅪Sg/VB/J+ P     NSg/VB+ Nᴹ/Vg/J NPl/V3+ NSg/P R/C/P N🅪Sg/VB VB/C N🅪Sg/VB+ .
>
#
>              Adjective
# HeadingStart NSg/VB/J+
>
#
> a   by    path    ; a   by    room       ( Out          of the way    , off        to one      side      . )
# D/P NSg/P NSg/VB+ . D/P NSg/P N🅪Sg/VB/J+ . NSg/VB/J/R/P P  D+  NSg/J+ . NSg/VB/J/P P  NSg/I/J+ NSg/VB/J+ . .
> by    catch  ; a   by    issue  ( Subsidiary , incidental . )
# NSg/P NSg/VB . D/P NSg/P NSg/VB . NSg/J+     . NSg/J      . .
>
#
>              For
# HeadingStart R/C/P
>
#
>              Conjunction
# HeadingStart NSg/VB+
>
#
> I       had to stay     with my  wicked stepmother , for   I       had nowhere else    to go       .
# ISg/#r+ VP  P  NSg/VB/J P    D$+ VP/J   NSg        . R/C/P ISg/#r+ VP  NSg/J   NSg/J/C P  NSg/VB/J .
>
#
>              Preposition
# HeadingStart NSg/VB
>
#
> The astronauts headed for   the moon    .
# D+  NPl+       VP/J   R/C/P D+  NPr/VB+ .
> Run      for   the hills   !
# NSg/VBPp R/C/P D+  NPl/V3+ .
> He       was headed for   the door    when    he       remembered .
# NPr/ISg+ VPt VP/J   R/C/P D+  NSg/VB+ NSg/I/C NPr/ISg+ VP/J       .
> I       have    something for   you    .
# ISg/#r+ NSg/VXB NSg/I/J+  R/C/P ISgPl+ .
> Everything I       do  , I       do  for   you    .
# NSg/I/VB+  ISg/#r+ VXB . ISg/#r+ VXB R/C/P ISgPl+ .
> We're having  a   birthday party    for   Janet .
# K     Nᴹ/Vg/J D/P NSg/VB+  NSg/VB/J R/C/P NPr+  .
> The mayor gave a   speech  for   the charity gala   .
# D+  NSg+  VPt  D/P N🅪Sg/VB R/C/P D+  NPr+    NSg/J+ .
> If    having  to bag    the groceries correctly is  more         than you    can     handle , then      this   isn't   the job     for   you    .
# NSg/C Nᴹ/Vg/J P  NSg/VB D+  NPl/V3+   R         VL3 NPr/I/J/R/Dq C/P  ISgPl+ NPr/VXB NSg/VB . NSg/J/R/C I/Ddem NSg/VX3 D   NPr/VB+ R/C/P ISgPl+ .
> This    is  a   new   bell   for   my  bicycle .
# I/Ddem+ VL3 D/P NSg/J NPr/VB R/C/P D$+ NSg/VB+ .
> The cake     is  for   Tom    and  Helen's anniversary .
# D+  N🅪Sg/VB+ VL3 R/C/P NPr/VB VB/C NPr$    NSg+        .
> This    medicine is  for   your cough   .
# I/Ddem+ N🅪Sg/VB+ VL3 R/C/P D$+  NSg/VB+ .
> He       wouldn't apologize ; and  just for   that          , she  refused to help   him  .
# NPr/ISg+ VXB      VB        . VB/C J/R  R/C/P NSg/I/C/Ddem+ . ISg+ VP/J    P  NSg/VB ISg+ .
> He       looks  better     for   having  lost weight   . ( UK   usage )
# NPr/ISg+ NPl/V3 NSg/VXB/JC R/C/P Nᴹ/Vg/J VP/J N🅪Sg/VB+ . . NPr+ N🅪Sg+ .
> She  was the worse     for   drink   .
# ISg+ VPt D   NSg/VB/JC R/C/P NSg/VB+ .
> All          those  for   the motion   , raise  your hands   .
# NSg/I/J/C/Dq I/Ddem R/C/P D+  N🅪Sg/VB+ . NSg/VB D$+  NPl/V3+ .
> Who's for   ice        - cream      ?
# NPr$+ R/C/P NPr🅪Sg/VB+ . N🅪Sg/VB/J+ .
> I'm for   going   by    train
# K   R/C/P Nᴹ/Vg/J NSg/P NSg/VB+
> Ten voted for   , and  three against . ( with implied object  )
# NSg VP/J  R/C/P . VB/C NSg   C/P     . . P    VP/J    NSg/VB+ .
> Make   way   for   the president !
# NSg/VB NSg/J R/C/P D+  NSg/VB+   .
> Clear    the shelves for   our new    Christmas stock      !
# NSg/VB/J D   NPl/V3  R/C/P D$+ NSg/J+ NPr/VB/J+ N🅪Sg/VB/J+ .
> Stand  by    for   your cue     .
# NSg/VB NSg/P R/C/P D$+  NSg/VB+ .
> Prepare for   battle    .
# VB      R/C/P NPr/VB/J+ .
> They swept the area for   enemy   operatives .
# IPl+ VP/J  D   N🅪Sg R/C/P NSg/VB+ NPl+       .
> Police combed his     flat     for   clues   .
# Nᴹ/VB+ VP/J   ISg/D$+ NSg/VB/J R/C/P NPl/V3+ .
> I've lived here for   three years .
# K    VP/J  J/R  R/C/P NSg   NPl+  .
> They fought for   days over    a    silly  pencil  .
# IPl+ VB     R/C/P NPl+ NSg/J/P D/P+ NSg/J+ NSg/VB+ .
> The store   is  closed for   the day     .
# D+  NSg/VB+ VL3 VP/J   R/C/P D+  NPr🅪Sg+ .
> I       can     see    for   miles  .
# ISg/#r+ NPr/VXB NSg/VB R/C/P NPrPl+ .
> I       will    stand  in        for   him  .
# ISg/#r+ NPr/VXB NSg/VB NPr/J/R/P R/C/P ISg+ .
> I       speak  for   the Prime     Minister .
# ISg/#r+ NSg/VB R/C/P D+  NSg/VB/J+ NSg/VB+  .
> It       is  unreasonable for   our boss      to withhold our wages   .
# NPr/ISg+ VL3 J            R/C/P D$+ NSg/VB/J+ P  NSg/VB   D$+ NPl/V3+ .
> I       don't think  it's a   good     idea for   you    and  me       to meet     ever again .
# ISg/#r+ VXB   NSg/VB +    D/P NPr/VB/J NSg+ R/C/P ISgPl+ VB/C NPr/ISg+ P  NSg/VB/J J/R  P     .
> I       am       aiming  for   completion by    the end    of business Thursday .
# ISg/#r+ NPr/VB/J Nᴹ/Vg/J R/C/P NSg+       NSg/P D   NSg/VB P  N🅪Sg/J+  NSg+     .
> He's going   for   his     doctorate .
# NPr$ Nᴹ/Vg/J R/C/P ISg/D$+ NSg/VB+   .
> Do  you    want   to go       for   coffee     ?
# VXB ISgPl+ NSg/VB P  NSg/VB/J R/C/P N🅪Sg/VB/J+ .
> I'm saving      up         for   a   car  .
# K   N🅪Sg/Vg/J/P NSg/VB/J/P R/C/P D/P NSg+ .
> Don't wait   for   an  answer  .
# VXB   NSg/VB R/C/P D/P NSg/VB+ .
> Fair     for   its     day     .
# NSg/VB/J R/C/P ISg/D$+ NPr🅪Sg+ .
> She's spry for   an  old   lady    .
# K     J    R/C/P D/P NSg/J NPr/VB+ .
> Don't take   me       for   a   fool      .
# VXB   NSg/VB NPr/ISg+ R/C/P D/P NSg/VB/J+ .
> For   all           his     expensive education , he       didn't seem very bright   .
# R/C/P NSg/I/J/C/Dq+ ISg/D$+ J+        NSg+      . NPr/ISg+ VXPt   VB   J/R  NPr/VB/J .
> And  now       for   a    slap      - up         meal    !
# VB/C NSg/J/R/C R/C/P D/P+ NSg/VB/J+ . NSg/VB/J/P NSg/VB+ .
> Go       scuba   diving   ? For   one      thing , I       can't even       swim   .
# NSg/VB/J N🅪Sg/VB Nᴹ/Vg/J+ . R/C/P NSg/I/J+ NSg+  . ISg/#r+ VXB   NSg/VB/J/R NSg/VB .
> For   another , we   don't have    any    equipment .
# R/C/P I/D     . IPl+ VXB   NSg/VXB I/R/Dq Nᴹ+       .
> He       is  named for   his     grandfather .
# NPr/ISg+ VL3 VP/J  R/C/P ISg/D$+ NSg/VB/J+   .
> He       totally screwed up         that          project . Now       he's surely for   the sack   .
# NPr/ISg+ R       VP/J    NSg/VB/J/P NSg/I/C/Ddem+ NSg/VB+ . NSg/J/R/C NPr$ R      R/C/P D   NSg/VB .
> In        term     of base      hits   , Jones   was three for   four on  the day
# NPr/J/R/P NSg/VB/J P  NSg/VB/J+ NPl/V3 . NPr/VB+ VPt NSg   R/C/P NSg  J/P D+  NPr🅪Sg+
> At    close    of play    , England were    305 for   3 .
# NSg/P NSg/VB/J P  N🅪Sg/VB . NPr+    NSg/VPt #   R/C/P # .
> He       took the swing   shift   for   he       could   get    more         overtime .
# NPr/ISg+ VPt  D+  NSg/VB+ NSg/VB+ R/C/P NPr/ISg+ NSg/VXB NSg/VB NPr/I/J/R/Dq NSg/VB   .
> to account for   one's whereabouts .
# P  NSg/VB  R/C/P NSg$+ NSg+        .
>
#
>              From
# HeadingStart P
>
#
> Paul is  from New    Zealand .
# NPr+ VL3 P    NSg/J+ NPr+    .
> I       got a   letter  from my  brother   .
# ISg/#r+ VP  D/P NSg/VB+ P    D$+ NSg/VB/J+ .
> You    can't get    all          your news   from the Internet .
# ISgPl+ VXB   NSg/VB NSg/I/J/C/Dq D$+  Nᴹ/VB+ P    D   NPrᴹ/VB+ .
> He       had books   piled from floor   to ceiling .
# NPr/ISg+ VP  NPl/V3+ VP/J  P    NSg/VB+ P  NSg/VB  .
> He       departed yesterday from Chicago .
# NPr/ISg+ NSg/VP/J NSg       P    NPr+    .
> This    figure  has been    changed from a    one      to a   seven .
# I/Ddem+ NSg/VB+ V3  NSg/VPp VP/J    P    D/P+ NSg/I/J+ P  D/P NSg   .
> Face    away from the wall    !
# NSg/VB+ VB/J P    D+  NPr/VB+ .
> The working day     runs   from 9 am        to 5 pm      .
# D   Nᴹ/Vg/J NPr🅪Sg+ NPl/V3 P    # NPr/VB/J+ P  # NSg/VB+ .
> Tickets are available from 17th July .
# NPl/V3+ VB  J         P    #    NPr+ .
> Rate    your pain     from 1 to 10 .
# NSg/VB+ D$+  N🅪Sg/VB+ P    # P  #  .
> Start  counting from 1 .
# NSg/VB Nᴹ/Vg/J  P    # .
> You    can     study  anything  from math to literature .
# ISgPl+ NPr/VXB NSg/VB NSg/I/VB+ P    +    P  Nᴹ         .
> It's hard     to tell   from here .
# +    N🅪Sg/J/R P  NPr/VB P    J/R  .
> Try      to see    it       from his     point  of view    .
# NSg/VB/J P  NSg/VB NPr/ISg+ P    ISg/D$+ NSg/VB P  NSg/VB+ .
> The bomb      went     off        just 100 yards   from where   they were    standing .
# D+  NSg/VB/J+ NSg/VPt+ NSg/VB/J/P J/R  #   NPl/V3+ P    NSg/R/C IPl+ NSg/VPt Nᴹ/Vg/J  .
> From the top      of the lighthouse you    can     just see    the mainland .
# P    D   NSg/VB/J P  D+  NSg+       ISgPl+ NPr/VXB J/R  NSg/VB D+  NSg+     .
> I’ve been    doing   this    from pickney .
# K    NSg/VPp Nᴹ/Vg/J I/Ddem+ P    ?       .
> Your opinions differ    from mine      .
# D$+  NPl+     NPr/VB/JC P    NSg/I/VB+ .
> He       knows right    from wrong      .
# NPr/ISg+ V3    NPr/VB/J P    NSg/VB/J/R .
>
#
>              In
# HeadingStart NPr/J/R/P
>
#
>              Preposition
# HeadingStart NSg/VB
>
#
> Who    lives in        a   pineapple under   the sea  ?
# NPr/I+ V3+   NPr/J/R/P D/P NSg       NSg/J/P D   NSg+ .
> The dog       is  in        the kennel .
# D+  NSg/VB/J+ VL3 NPr/J/R/P D   NSg/VB .
> There were    three pickles in        a    jar     .
# R+    NSg/VPt NSg   NPl/V3  NPr/J/R/P D/P+ NSg/VB+ .
> I       like         living  in        the city .
# ISg/#r+ NSg/VB/J/C/P Nᴹ/Vg/J NPr/J/R/P D+  NSg+ .
> There are lots   of trees   in        the park    .
# R+    VB  NPl/V3 P  NPl/V3+ NPr/J/R/P D+  NPr/VB+ .
> We   are in        the enemy   camp      .
# IPl+ VB  NPr/J/R/P D+  NSg/VB+ NSg/VB/J+ .
> Her     plane     is  in        the air      .
# ISg/D$+ NSg/VB/J+ VL3 NPr/J/R/P D+  N🅪Sg/VB+ .
> I       glanced over    at    the pretty     girl    in        the red     dress   .
# ISg/#r+ VP/J    NSg/J/P NSg/P D+  NSg/VB/J/R NSg/VB+ NPr/J/R/P D+  N🅪Sg/J+ NSg/VB+ .
> There wasn't much         of interest in        her     speech   .
# R+    VPt    NSg/I/J/R/Dq P  N🅪Sg/VB+ NPr/J/R/P ISg/D$+ N🅪Sg/VB+ .
> He       hasn't got an  original idea in        him  .
# NPr/ISg+ V3     VP  D/P NSg/J    NSg+ NPr/J/R/P ISg+ .
> You    are one     in        a   million .
# ISgPl+ VB  NSg/I/J NPr/J/R/P D/P NSg     .
> She's in        an  orchestra .
# K     NPr/J/R/P D/P NSg+      .
> My  birthday is  in        the first week  of December .
# D$+ NSg/VB+  VL3 NPr/J/R/P D   NSg/J NSg/J P  NPr+     .
> Easter  falls   in        the fourth    lunar  month  .
# NPr/VB+ NPl/V3+ NPr/J/R/P D+  NPr/VB/J+ NSg/J+ NSg/J+ .
> Will    you    be      able     to finish this    in        a    week   ?
# NPr/VXB ISgPl+ NSg/VXB NSg/VB/J P  NSg/VB I/Ddem+ NPr/J/R/P D/P+ NSg/J+ .
> They said they would call   us       in        a    week   .
# IPl+ VP/J IPl+ VXB   NSg/VB NPr/IPl+ NPr/J/R/P D/P+ NSg/J+ .
> Less       water    gets   in        your boots  this    way    .
# VB/J/R/C/P N🅪Sg/VB+ NPl/V3 NPr/J/R/P D$+  NPl/V3 I/Ddem+ NSg/J+ .
> She  stood there looking in        the window  longingly .
# ISg+ VP    R     Nᴹ/Vg/J NPr/J/R/P D+  NSg/VB+ R         .
> In        replacing the faucet washers , he       felt      he       was making  his     contribution to the environment .
# NPr/J/R/P Nᴹ/Vg/J   D   NSg    NPl/V3  . NPr/ISg+ N🅪Sg/VP/J NPr/ISg+ VPt Nᴹ/Vg/J ISg/D$+ NSg+         P  D   N🅪Sg+       .
> In        trying  to make   amends , she  actually made matters worse     .
# NPr/J/R/P Nᴹ/Vg/J P  NSg/VB NPl/V3 . ISg+ R        VP   NPl/V3+ NSg/VB/JC .
> My  aim     in        travelling    there was to find   my  missing friend    .
# D$+ NSg/VB+ NPr/J/R/P NSg/Vg/J/Comm R+    VPt P  NSg/VB D$+ Nᴹ/Vg/J NPr/VB/J+ .
> My  fat       rolls   around in        folds   .
# D$+ N🅪Sg/VB/J NPl/V3+ J/P    NPr/J/R/P NPl/V3+ .
> The planes  flew      over    in        waves   .
# D+  NPl/V3+ NSg/VPt/J NSg/J/P NPr/J/R/P NPl/V3+ .
> Arrange the chairs  in        a    circle  .
# NSg/VB  D   NPl/V3+ NPr/J/R/P D/P+ NSg/VB+ .
> He       stalked away in        anger  .
# NPr/ISg+ VP/J    VB/J NPr/J/R/P Nᴹ/VB+ .
> John is  in        a   coma .
# NPr+ VL3 NPr/J/R/P D/P NSg  .
> My  fruit    trees   are in        bud        .
# D$+ N🅪Sg/VB+ NPl/V3+ VB  NPr/J/R/P NPr🅪Sg/VB+ .
> The company  is  in        profit      .
# D+  N🅪Sg/VB+ VL3 NPr/J/R/P N🅪Sg/VBP/J+ .
> You've got a   friend    in        me       .
# K      VP  D/P NPr/VB/J+ NPr/J/R/P NPr/ISg+ .
> He's met his     match   in        her     .
# NPr$ VP  ISg/D$+ NSg/VB+ NPr/J/R/P ISg/D$+ .
> There has been    no       change  in        his     condition .
# R+    V3  NSg/VPp NSg/Dq/P N🅪Sg/VB NPr/J/R/P ISg/D$+ N🅪Sg/VB+  .
> What   grade   did  he       get    in        English      ?
# NSg/I+ NSg/VB+ VXPt NPr/ISg+ NSg/VB NPr/J/R/P NPr🅪Sg/VB/J+ .
> Please pay      me       in        cash       — preferably in        tens and  twenties .
# VB     NSg/VB/J NPr/ISg+ NPr/J/R/P NPrᴹ/VB/J+ . R          NPr/J/R/P W?   VB/C NPl+     .
> The deposit can     be      in        any    legal tender   , even       in        gold     .
# D+  NSg/VB+ NPr/VXB NSg/VXB NPr/J/R/P I/R/Dq NSg/J NSg/VB/J . NSg/VB/J/R NPr/J/R/P Nᴹ/VB/J+ .
> Beethoven's " Symphony No       . 5 " in        C          minor    is  among his     most         popular .
# NPr$        . NSg+     NSg/Dq/P . # . NPr/J/R/P NPr/VB/#r+ NSg/VB/J VL3 P     ISg/D$+ NSg/I/J/R/Dq NSg/J   .
> His     speech   was in        French      , but     was simultaneously translated into eight  languages .
# ISg/D$+ N🅪Sg/VB+ VPt NPr/J/R/P NPr🅪Sg/VB/J . NSg/C/P VPt R              VP/J       P    NSg/J+ NPl/V3+   .
> When    you    write  in        cursive , it's illegible .
# NSg/I/C ISgPl+ NSg/VB NPr/J/R/P NSg/J   . +    J         .
> Military letters should be      formal in        tone       , but     not     stilted .
# NSg/J+   NPl/V3+ VXB    NSg/VXB NSg/J  NPr/J/R/P N🅪Sg/I/VB+ . NSg/C/P NSg/R/C VP/J    .
>
#
>              Verb
# HeadingStart NSg/VB+
>
#
> He       that          ears    my  land       spares my  team    and  gives  me       leave  to in        the crop    .
# NPr/ISg+ NSg/I/C/Ddem+ NPl/V3+ D$+ NPr🅪Sg/VB+ NPl/V3 D$+ NSg/VB+ VB/C NPl/V3 NPr/ISg+ NSg/VB P  NPr/J/R/P D   NSg/VB+ .
>
#
>              Adverb
# HeadingStart NSg/VB+
>
#
> Suddenly a    strange   man       walked in        .
# R        D/P+ NSg/VB/J+ NPr/VB/J+ VP/J   NPr/J/R/P .
> Would you    like         that          to take   away or    eat in        ?
# VXB   ISgPl+ NSg/VB/J/C/P NSg/I/C/Ddem+ P  NSg/VB VB/J NPr/C VB  NPr/J/R/P .
> He       ran     to the edge   of the swimming pool    and  dived in        .
# NPr/ISg+ NSg/VPt P  D   NSg/VB P  D+  NSg/VB   NSg/VB+ VB/C VP/J  NPr/J/R/P .
> They flew      in        from London last      night    .
# IPl+ NSg/VPt/J NPr/J/R/P P    NPr+   NSg/VB/J+ N🅪Sg/VB+ .
> For   six  hours the tide    flows  in        , then      for   another six  hours it       flows  out          .
# R/C/P NSg+ NPl+  D+  NSg/VB+ NPl/V3 NPr/J/R/P . NSg/J/R/C R/C/P I/D+    NSg+ NPl+  NPr/ISg+ NPl/V3 NSg/VB/J/R/P .
> Bring the water    to the boil    and  drop   the vegetables in        .
# VB    D+  N🅪Sg/VB+ P  D+  NSg/VB+ VB/C NSg/VB D+  NPl+       NPr/J/R/P .
> The show   still      didn't become interesting 20 minutes in        .
# D   NSg/VB NSg/VB/J/R VXPt   VBPp   Vg/J        #  NPl/V3+ NPr/J/R/P .
>
#
>              Noun
# HeadingStart NSg/VB+
>
#
> His     parents got him  an  in        with the company  .
# ISg/D$+ NPl/V3+ VP  ISg+ D/P NPr/J/R/P P    D+  N🅪Sg/VB+ .
>
#
>              Adjective
# HeadingStart NSg/VB/J+
>
#
> Is  Mr   . Smith   in        ?
# VL3 NSg+ . NPr/VB+ NPr/J/R/P .
> Little     by    little     I       pushed the snake   into the basket  , until finally all          of it       was in        .
# NPr/I/J/Dq NSg/P NPr/I/J/Dq ISg/#r+ VP/J   D+  NPr/VB+ P    D+  NSg/VB+ . C/P   R       NSg/I/J/C/Dq P  NPr/ISg+ VPt NPr/J/R/P .
> The bullet  is  about five centimetres in        .
# D+  NSg/VB+ VL3 J/P   NSg  NPl/Comm    NPr/J/R/P .
> If    the tennis  ball    bounces on  the line    then      it's in        .
# NSg/C D+  NSg/VB+ NPr/VB+ NPl/V3  J/P D+  NSg/VB+ NSg/J/R/C +    NPr/J/R/P .
> I've discovered why    the TV   wasn't working – the plug    wasn't in        !
# K    VP/J       NSg/VB D   NSg+ VPt    Nᴹ/Vg/J . D   NSg/VB+ VPt    NPr/J/R/P .
> The replies to the questionnaires are now       all          in        .
# D   NPl/V3+ P  D+  NPl/V3+        VB  NSg/J/R/C NSg/I/J/C/Dq NPr/J/R/P .
> Skirts  are in        this    year .
# NPl/V3+ VB  NPr/J/R/P I/Ddem+ NSg+ .
> the in        train   ( incoming train   )
# D   NPr/J/R/P NSg/VB+ . Nᴹ/Vg/J  NSg/VB+ .
> You    can't get    round      the headland when    the tide's in        .
# ISgPl+ VXB   NSg/VB NSg/VB/J/P D   NSg      NSg/I/C D   NSg$   NPr/J/R/P .
> in        by    descent  ;            in        by    purchase ;            in        of the seisin of her     husband
# NPr/J/R/P NSg/P N🅪Sg/VB+ . Unlintable NPr/J/R/P NSg/P NSg/VB+  . Unlintable NPr/J/R/P P  D   ?      P  ISg/D$+ NSg/VB+
> He       is  very in        with the Joneses .
# NPr/ISg+ VL3 J/R  NPr/J/R/P P    D   NPl/V3  .
> I       need     to keep   in        with the neighbours   in        case       I       ever need     a    favour        from them     .
# ISg/#r+ N🅪Sg/VXB P  NSg/VB NPr/J/R/P P    D   NPl/V3/Comm+ NPr/J/R/P NPr🅪Sg/VB+ ISg/#r+ J/R  N🅪Sg/VXB D/P+ N🅪Sg/VB/Comm+ P    NSg/IPl+ .
> I       think  that          bird      fancies you    . You're in        there , mate   !
# ISg/#r+ NSg/VB NSg/I/C/Ddem+ NPr/VB/J+ NPl/V3  ISgPl+ . +      NPr/J/R/P R     . NSg/VB .
> I'm three drinks  in        right    now       .
# K   NSg+  NPl/V3+ NPr/J/R/P NPr/VB/J NSg/J/R/C .
> I       was 500 dollars in        when    the stock      crashed .
# ISg/#r+ VPt #   NPl     NPr/J/R/P NSg/I/C D+  N🅪Sg/VB/J+ VP/J    .
>
#
>              Unit
# HeadingStart NSg+
>
#
> The glass      is  8 inches  .
# D+  NPr🅪Sg/VB+ VL3 # NPl/V3+ .
> The glass      is  8 in        .
# D+  NPr🅪Sg/VB+ VL3 # NPr/J/R/P .
>
#
>              Of
# HeadingStart P
>
#
> Take   the chicken    out          of the freezer .
# NSg/VB D+  N🅪Sg/VB/J+ NSg/VB/J/R/P P  D+  NSg+    .
> He       hasn't been    well       of late  .
# NPr/ISg+ V3     NSg/VPp NSg/VB/J/R P  NSg/J .
> Finally she  was relieved of the burden of caring  for   her     sick      husband .
# R       ISg+ VPt VP/J     P  D   NSg/VB P  Nᴹ/Vg/J R/C/P ISg/D$+ NSg/VB/J+ NSg/VB+ .
> He       seemed devoid of human     feelings .
# NPr/ISg+ VP/J   VB/J   P  NSg/VB/J+ NPl/V3+  .
> The word    is  believed to be      of Japanese  origin .
# D+  NSg/VB+ VL3 VP/J     P  NSg/VXB P  NPr🅪Sg/J+ NSg+   .
> Jesus  of Nazareth
# NPr/VB P  NPr+
> The invention was born     of necessity .
# D+  N🅪Sg+     VPt NPr/VB/J P  NSg+      .
> It       is  said that         she  died of a    broken heart    .
# NPr/ISg+ VL3 VP/J NSg/I/C/Ddem ISg+ VP/J P  D/P+ VPp/J  N🅪Sg/VB+ .
> What   a   lot    of nonsense !
# NSg/I+ D/P NPr/VB P  Nᴹ/VB/J+ .
> I'll have    a   dozen of those  apples , please .
# K    NSg/VXB D/P NSg   P  I/Ddem NPl    . VB     .
> Welcome  to the historic town of Harwich .
# NSg/VB/J P  D   NSg/J    NSg  P  ?       .
> I'm not     driving this   wreck  of a   car  .
# K   NSg/R/C Nᴹ/Vg/J I/Ddem NSg/VB P  D/P NSg+ .
> I'm always thinking of you    .
# K   R      Nᴹ/Vg/J  P  ISgPl+ .
> He       told us       the story  of his     journey to India .
# NPr/ISg+ VP   NPr/IPl+ D   NSg/VB P  ISg/D$+ NSg/VB+ P  NPr+  .
> This    behaviour  is  typical of teenagers .
# I/Ddem+ N🅪Sg/Comm+ VL3 NSg/J   P  +         .
> He       is  a   friend   of mine      .
# NPr/ISg+ VL3 D/P NPr/VB/J P  NSg/I/VB+ .
> We   want   a   larger slice    of the cake     .
# IPl+ NSg/VB D/P JC     NSg/VB/J P  D+  N🅪Sg/VB+ .
> The owner of the nightclub was arrested .
# D   NSg   P  D+  NSg/VB+   VPt VP/J     .
> My  companion seemed affable and  easy     of manner .
# D$+ NSg/VB+   VP/J   J       VB/C NSg/VB/J P  NSg+   .
> It's not     that         big   of a    deal      .
# +    NSg/R/C NSg/I/C/Ddem NSg/J P  D/P+ NSg/VB/J+ .
> I’ve not     taken her     out          of a   goodly long     while      .
# K    NSg/R/C VPp/J ISg/D$+ NSg/VB/J/R/P P  D/P J/R    NPr/VB/J NSg/VB/C/P .
> After a   delay     of three hours , the plane     finally took off        .
# P     D/P NSg/VPt/J P  NSg+  NPl+  . D+  NSg/VB/J+ R       VPt  NSg/VB/J/P .
>
#
>              On
# HeadingStart J/P
>
#
>              Adjective
# HeadingStart NSg/VB/J+
>
#
> All           the lights  are on  , so          they must    be      home      .
# NSg/I/J/C/Dq+ D+  NPl/V3+ VB  J/P . NSg/I/J/R/C IPl+ NSg/VXB NSg/VXB NSg/VB/J+ .
> We   had to ration our food because there was a    war      on  .
# IPl+ VP  P  NSg/VB D$+ NSg+ C/P     R+    VPt D/P+ N🅪Sg/VB+ J/P .
> Some     of the cast     went    down        with flu  , but     the show's still      on  .
# I/J/R/Dq P  D   NSg/VB/J NSg/VPt N🅪Sg/VB/J/P P    NSg+ . NSg/C/P D   NSg$   NSg/VB/J/R J/P .
> That          TV   programme     that          you    wanted to watch  is  on  now       .
# NSg/I/C/Ddem+ NSg+ NSg/VB/Au/Br+ NSg/I/C/Ddem+ ISgPl+ VP/J   P  NSg/VB VL3 J/P NSg/J/R/C .
> This    is  her     last      song  . You're on  next    !
# I/Ddem+ VL3 ISg/D$+ NSg/VB/J+ N🅪Sg+ . +      J/P NSg/J/P .
> Are we   still      on  for   tonight ?
# VB  IPl+ NSg/VB/J/R J/P R/C/P NSg+    .
> Mike    just threw coffee     onto Paul's lap       . It's on  now       .
# NPr/VB+ J/R  VPt   N🅪Sg/VB/J+ J/P  NPr$   NSg/VB/J+ . +    J/P NSg/J/R/C .
> England need     a   hundred runs   , with twenty - five overs remaining . Game      on  !
# NPr+    N🅪Sg/VXB D/P NSg     NPl/V3 . P    NSg    . NSg  NPl   Nᴹ/Vg/J   . NSg/VB/J+ J/P .
> Your feet will    soon warm     up         once  your socks   are on  .
# D$+  NPl+ NPr/VXB J/R  NSg/VB/J NSg/VB/J/P NSg/C D$+  NPl/V3+ VB  J/P .
> I       was trying  to drink  out          of the bottle  while      the top       was still      on  !
# ISg/#r+ VPt Nᴹ/Vg/J P  NSg/VB NSg/VB/J/R/P P  D+  NSg/VB+ NSg/VB/C/P D+  NSg/VB/J+ VPt NSg/VB/J/R J/P .
> Climbing up         that          steep     ridge   isn't   on  . We'll have    to find   another route   .
# Nᴹ/Vg/J  NSg/VB/J/P NSg/I/C/Ddem+ NSg/VB/J+ NSg/VB+ NSg/VX3 J/P . K     NSg/VXB P  NSg/VB I/D     NSg/VB+ .
> He'd like         to play    the red    next    to the black     spot      , but     that         shot      isn't   on  .
# K    NSg/VB/J/C/P P  N🅪Sg/VB D   N🅪Sg/J NSg/J/P P  D   N🅪Sg/VB/J NSg/VB/J+ . NSg/C/P NSg/I/C/Ddem NSg/VP/J+ NSg/VX3 J/P .
> The captain moved two fielders to the on  side      .
# D+  NSg/VB+ VP/J  NSg W?       P  D   J/P NSg/VB/J+ .
> Ponsonby - Smythe hit       a   thumping on  drive   .
# ?        . ?      NSg/VBP/J D/P Nᴹ/Vg/J  J/P N🅪Sg/VB .
> If    the player fails  to hit       the ball    on  , it's a   foul     .
# NSg/C D+  NSg+   NPl/V3 P  NSg/VBP/J D+  NPr/VB+ J/P . +    D/P NSg/VB/J .
> He       always has to be      on  , it's so          exhausting .
# NPr/ISg+ R      V3  P  NSg/VXB J/P . +    NSg/I/J/R/C Nᴹ/Vg/J    .
>
#
>              Adverb
# HeadingStart NSg/VB+
>
#
> turn   the television on
# NSg/VB D+  N🅪Sg/VB+   J/P
> The lid     wasn't screwed on  properly .
# D+  NSg/VB+ VPt    VP/J    J/P R        .
> Put     on  your hat    and  gloves  .
# NSg/VBP J/P D$+  NSg/VB VB/C NPl/V3+ .
> The policeman moved the tramp  on  .
# D+  NSg+      VP/J  D   NSg/VB J/P .
> Drive   on  past        the railway station .
# N🅪Sg/VB J/P NSg/VB/J/P+ D+  NSg+    NSg/VB+ .
> From now       on  things are going   to be      different .
# P    NSg/J/R/C J/P NPl+   VB  Nᴹ/Vg/J P  NSg/VXB NSg/J     .
> and  so          on  .
# VB/C NSg/I/J/R/C J/P .
> He       rambled on  and  on  .
# NPr/ISg+ VP/J    J/P VB/C J/P .
> Ten  years on  , nothing  had changed in        the village .
# NSg+ NPl+  J/P . NSg/I/J+ VP  VP/J    NPr/J/R/P D+  NSg+    .
>
#
>              Preposition
# HeadingStart NSg/VB
>
#
> A   vase   of flowers   stood on  the table   .
# D/P NSg/VB P  NPrPl/V3+ VP    J/P D   NSg/VB+ .
> Please lie    down        on  the couch   .
# VB     NPr/VB N🅪Sg/VB/J/P J/P D+  NSg/VB+ .
> The parrot  was sitting  on  Jim's shoulder .
# D+  NSg/VB+ VPt NSg/Vg/J J/P NPr$  NSg/VB+  .
> He       had a   scar    on  the side     of his     face    .
# NPr/ISg+ VP  D/P NSg/VB+ J/P D   NSg/VB/J P  ISg/D$+ NSg/VB+ .
> There is  a   dirty smudge on  this    window  .
# R+    VL3 D/P VB/J  NSg/VB J/P I/Ddem+ NSg/VB+ .
> The painting   hangs  on  the wall    .
# D+  N🅪Sg/Vg/J+ NPl/V3 J/P D+  NPr/VB+ .
> The fruit    ripened on  the trees   .
# D+  N🅪Sg/VB+ VP/J    J/P D   NPl/V3+ .
> Should there be      an  accent  on  the " e      " ?
# VXB    R+    NSg/VXB D/P NSg/VB+ J/P D   . NPr/I+ . .
> He       wore old   shoes   on  his     feet .
# NPr/ISg+ VPt  NSg/J NPl/V3+ J/P ISg/D$+ NPl+ .
> The lighthouse that          you    can     see    is  on  the mainland .
# D+  NSg+       NSg/I/C/Ddem+ ISgPl+ NPr/VXB NSg/VB VL3 J/P D+  NSg+     .
> The suspect   is  thought to still      be      on  the campus  .
# D+  NSg/VB/J+ VL3 N🅪Sg/VP P  NSg/VB/J/R NSg/VXB J/P D+  NSg/VB+ .
> We   live on  the edge   of the city .
# IPl+ VB/J J/P D   NSg/VB P  D+  NSg+ .
> on  the left      , on  the right    , on  the side      , on  the bottom    .
# J/P D+  NPr/VP/J+ . J/P D   NPr/VB/J . J/P D+  NSg/VB/J+ . J/P D+  NSg/VB/J+ .
> The fleet     is  on  the American coast   .
# D+  NSg/VB/J+ VL3 J/P D+  NPr/J+   NSg/VB+ .
> on  a    bus     , on  a    train   , on  a    plane     , on  a    ferry   , on  a    yacht   .
# J/P D/P+ NSg/VB+ . J/P D/P+ NSg/VB+ . J/P D/P+ NSg/VB/J+ . J/P D/P+ NSg/VB+ . J/P D/P+ NSg/VB+ .
> All          of the responsibility is  on  him  .
# NSg/I/J/C/Dq P  D+  N🅪Sg+          VL3 J/P ISg+ .
> I       put     a    bet       on  the winning  horse   .
# ISg/#r+ NSg/VBP D/P+ NSg/VB/P+ J/P D+  NSg/VB/J NSg/VB+ .
> tug     on  the rope    ; push   hard     on  the door    .
# NSg/VB+ J/P D+  NSg/VB+ . NSg/VB N🅪Sg/J/R J/P D+  NSg/VB+ .
> I       stubbed my  toe     on  an  old   tree    stump  .
# ISg/#r+ VB/J    D$+ NSg/VB+ J/P D/P NSg/J NSg/VB+ NSg/VB .
> I       caught my  fingernail on  the door    handle .
# ISg/#r+ VP/J   D$+ NSg+       J/P D+  NSg/VB+ NSg/VB .
> The rope    snagged on  a   branch  .
# D+  NSg/VB+ VP/J    J/P D/P NPr/VB+ .
> to play    on  a   violin or    piano     .
# P  N🅪Sg/VB J/P D/P NSg/VB NPr/C NSg/VB/J+ .
> A    table   can't stand  on  two legs    .
# D/P+ NSg/VB+ VXB   NSg/VB J/P NSg NPl/V3+ .
> After resting  on  his     elbows  , he       stood on  his     toes    , then      walked on  his     heels   .
# P     Nᴹ/Vg/J+ J/P ISg/D$+ NPl/V3+ . NPr/ISg+ VP    J/P ISg/D$+ NPl/V3+ . NSg/J/R/C VP/J   J/P ISg/D$+ NPl/V3+ .
> The Tories are on  twenty - five percent in        this   constituency .
# D   NPrPl  VB  J/P NSg    . NSg  NSg     NPr/J/R/P I/Ddem NSg+         .
> The blue       team    are on  six points and  the red     team    on  five .
# D+  N🅪Sg/VB/J+ NSg/VB+ VB  J/P NSg NPl/V3 VB/C D+  N🅪Sg/J+ NSg/VB+ J/P NSg  .
> I'm on  question four .
# K   J/P NSg/VB+  NSg  .
> Born     on  the 4th of July .
# NPr/VB/J J/P D   #   P  NPr+ .
> On  Sunday  I'm busy     . I'll see    you    on  Monday .
# J/P NSg/VB+ K   NSg/VB/J . K    NSg/VB ISgPl+ J/P NSg+   .
> Can     I       see    you    on  a    different day     ?
# NPr/VXB ISg/#r+ NSg/VB ISgPl+ J/P D/P+ NSg/J+    NPr🅪Sg+ .
> Smith   scored again on  twelve minutes , doubling Mudchester Rovers ' lead      .
# NPr/VB+ VP/J   P     J/P NSg+   NPl/V3+ . Nᴹ/Vg/J  ?          W?     . N🅪Sg/VB/J .
> I       was reading   a   book   on  history .
# ISg/#r+ VPt NPrᴹ/Vg/J D/P NSg/VB J/P N🅪Sg+   .
> The city hosted the World   Summit  on  the Information Society
# D+  NSg+ VP/J   D+  NSg/VB+ NSg/VB+ J/P D+  Nᴹ+         N🅪Sg+
> I       have    no       opinion on  this    subject   .
# ISg/#r+ NSg/VXB NSg/Dq/P N🅪Sg+   J/P I/Ddem+ NSg/VB/J+ .
> I       saw     it       on  television .
# ISg/#r+ NSg/VPt NPr/ISg+ J/P N🅪Sg/VB+   .
> Can't you    see    I'm on  the phone   ?
# VXB   ISgPl+ NSg/VB K   J/P D   NSg/VB+ .
> My  favorite     shows   are on  BBC  America .
# D$+ NSg/VB/J/Am+ NPl/V3+ VB  J/P NPr+ NPr+    .
> I'll pay      on  card     .
# K    NSg/VB/J J/P N🅪Sg/VB+ .
> He       travelled on  false     documents .
# NPr/ISg+ VP/J/Comm J/P NSg/VB/J+ NPl/V3+   .
> They planned an  attack   on  London .
# IPl+ VB/J    D/P NSg/VB/J J/P NPr+   .
> The soldiers mutinied and  turned their guns    on  their officers .
# D+  NPl/V3+  VP/J     VB/C VP/J   D$+   NPl/V3+ J/P D$+   NPl/V3+  .
> Her     words   made a    lasting  impression on  my  mind    .
# ISg/D$+ NPl/V3+ VP   D/P+ Nᴹ/Vg/J+ NSg/VB+    J/P D$+ NSg/VB+ .
> What   will    be      the effect on  morale ?
# NSg/I+ NPr/VXB NSg/VXB D   NSg/VB J/P Nᴹ+    .
> I       haven't got any    money   on  me       .
# ISg/#r+ VXB     VP  I/R/Dq N🅪Sg/J+ J/P NPr/ISg+ .
> On  Jack's entry , William got up         to leave  .
# J/P NPr$   NSg+  . NPr+    VP  NSg/VB/J/P P  NSg/VB .
> On  the addition of ammonia , a    chemical reaction   begins .
# J/P D   NSg      P  Nᴹ+     . D/P+ NSg/J+   N🅪Sg/VB/J+ NPl/V3 .
> The drinks  are on  me       tonight , boys    .
# D+  NPl/V3+ VB  J/P NPr/ISg+ NSg+    . NPl/V3+ .
> The meal    is  on  the house   .
# D+  NSg/VB+ VL3 J/P D+  NPr/VB+ .
> I       had a    terrible thirst on  me       .
# ISg/#r+ VP  D/P+ J+       Nᴹ/VB+ J/P NPr/ISg+ .
> Have    pity    or    compassion on  him  .
# NSg/VXB N🅪Sg/VB NPr/C Nᴹ/VB+     J/P ISg+ .
> He's on  his     lunch    break   .
# NPr$ J/P ISg/D$+ N🅪Sg/VB+ NSg/VB+ .
> I'm on  nights  all          this   week   .
# K   J/P NPl/V3+ NSg/I/J/C/Dq I/Ddem NSg/J+ .
> You've been    on  these  antidepressants far      too long     .
# K      NSg/VPp J/P I/Ddem NPl             NSg/VB/J R   NPr/VB/J .
> I       depended on  them     for   assistance .
# ISg/#r+ VP/J     J/P NSg/IPl+ R/C/P Nᴹ+        .
> He       will    promise on  certain conditions .
# NPr/ISg+ NPr/VXB NSg/VB  J/P I/J+    NPl/V3+    .
> A    curse   on  him  !
# D/P+ NSg/VB+ J/P ISg+ .
> Please don't tell   on  her     and  get    her     in        trouble  .
# VB     VXB   NPr/VB J/P ISg/D$+ VB/C NSg/VB ISg/D$+ NPr/J/R/P N🅪Sg/VB+ .
>
#
>              Verb
# HeadingStart NSg/VB+
>
#
> Can     you    on  the light      ? ( switch    on  )
# NPr/VXB ISgPl+ J/P D+  N🅪Sg/VB/J+ . . NSg/VB/J+ J/P .
>
#
>              To
# HeadingStart P
>
#
>              Particle
# HeadingStart NSg+
>
#
> I       want   to leave  .
# ISg/#r+ NSg/VB P  NSg/VB .
> He       asked me       what   to do  .
# NPr/ISg+ VP/J  NPr/ISg+ NSg/I+ P  VXB .
> I       have    places  to go       and  people  to see    .
# ISg/#r+ NSg/VXB NPl/V3+ P  NSg/VB/J VB/C NPl/VB+ P  NSg/VB .
> To err is  human    .
# P  VB  VL3 NSg/VB/J .
> Who    am       I       to criticise ? I've done      worse      things myself .
# NPr/I+ NPr/VB/J ISg/#r+ P  VB/Au/Br  . K    NSg/VPp/J NSg/VB/JC+ NPl+   ISg+   .
> Precisely to get    away from you    was why    I       did  what   I       did  .
# R         P  NSg/VB VB/J P    ISgPl+ VPt NSg/VB ISg/#r+ VXPt NSg/I+ ISg/#r+ VXPt .
> I       need     some     more         books   to read    and  friends   to go       partying with .
# ISg/#r+ N🅪Sg/VXB I/J/R/Dq NPr/I/J/R/Dq NPl/V3+ P  NSg/VBP VB/C NPrPl/V3+ P  NSg/VB/J Nᴹ/Vg/J  P    .
> If    he       hasn't read    it       yet      , he       ought     to .
# NSg/C NPr/ISg+ V3     NSg/VBP NPr/ISg+ NSg/VB/C . NPr/ISg+ NSg/I/VXB P  .
> I       went    to the shops   to buy    some      bread    .
# ISg/#r+ NSg/VPt P  D+  NPl/V3+ P  NSg/VB I/J/R/Dq+ N🅪Sg/VB+ .
>
#
>              Preposition
# HeadingStart NSg/VB
>
#
> She  looked to the heavens .
# ISg+ VP/J   P  D+  NPl/V3+ .
> We   are walking to the shop    .
# IPl+ VB  Nᴹ/Vg/J P  D+  NSg/VB+ .
> The water    came      right    to the top      of this    wall    .
# D+  N🅪Sg/VB+ NSg/VPt/P NPr/VB/J P  D   NSg/VB/J P  I/Ddem+ NPr/VB+ .
> The coconut fell      to the ground     .
# D+  N🅪Sg+   NSg/VPt/J P  D+  N🅪Sg/VB/J+ .
> I       gave the book    to him  .
# ISg/#r+ VPt  D+  NSg/VB+ P  ISg+ .
> His     face    was beaten to a   pulp      .
# ISg/D$+ NSg/VB+ VPt VB/J   P  D/P N🅪Sg/VB/J .
> I       sang    my  baby      to sleep   .
# ISg/#r+ NPr/VPt D$+ NSg/VB/J+ P  N🅪Sg/VB .
> Whisk  the mixture to a    smooth    consistency .
# NSg/VB D+  N🅪Sg+   P  D/P+ NSg/VB/J+ NSg+        .
> He       made several bad      - taste    jokes  to groans from the audience .
# NPr/ISg+ VP   J/Dq    NSg/VB/J . NSg/VB/J NPl/V3 P  NPl/V3 P    D+  NSg+     .
> I       tried complaining , but     it       was to no        effect  .
# ISg/#r+ VP/J  Nᴹ/Vg/J     . NSg/C/P NPr/ISg+ VPt P  NSg/Dq/P+ NSg/VB+ .
> It       was to a   large extent true     .
# NPr/ISg+ VPt P  D/P NSg/J NSg/J+ NSg/VB/J .
> We   manufacture these   parts   to a   very high        tolerance .
# IPl+ NSg/VB      I/Ddem+ NPl/V3+ P  D/P J/R  NSg/VB/J/R+ N🅪Sg/VB+  .
> This    gauge   is  accurate to a   second   .
# I/Ddem+ NSg/VB+ VL3 J        P  D/P NSg/VB/J .
> There's a   lot    of sense    to what   he       says   .
# K       D/P NPr/VB P  N🅪Sg/VB+ P  NSg/I+ NPr/ISg+ NPl/V3 .
> The name    has a    nice   ring    to it       .
# D+  NSg/VB+ V3  D/P+ NPr/J+ NSg/VB+ P  NPr/ISg+ .
> There are 100 pence to the pound   .
# R+    VB  #   NPl   P  D+  NPr/VB+ .
> It       takes  2 to 4 weeks  to process typical applications .
# NPr/ISg+ NPl/V3 # P  # NPrPl+ P  NSg/VB  NSg/J+  NPl+         .
> Three to the power     of two  is   nine .
# NSg   P  D   N🅪Sg/VB/J P  NSg+ VL3+ NSg  .
> Three to the second   is  nine .
# NSg   P  D   NSg/VB/J VL3 NSg  .
> Three squared or    three to the second    power      is  nine .
# NSg   VP/J    NPr/C NSg   P  D+  NSg/VB/J+ N🅪Sg/VB/J+ VL3 NSg  .
> What's the time       ? – It's quarter   to four in        the afternoon ( or    3 : 45 pm      ) .
# K      D+  N🅪Sg/VB/J+ . . +    NSg/VB/J+ P  NSg  NPr/J/R/P D+  N🅪Sg+     . NPr/C # . #  NSg/VB+ . .
>
#
>              Adverb
# HeadingStart NSg/VB+
>
#
> Please push   the door    to . ( close    )
# VB     NSg/VB D+  NSg/VB+ P  . . NSg/VB/J .
>
#
>              With
# HeadingStart P
>
#
>              Preposition
# HeadingStart NSg/VB
>
#
> He       picked a   fight  with the class      bully     .
# NPr/ISg+ VP/J   D/P NSg/VB P    D+  N🅪Sg/VB/J+ NSg/VB/J+ .
> He       went    with his     friends   .
# NPr/ISg+ NSg/VPt P    ISg/D$+ NPrPl/V3+ .
> She  owns   a    motorcycle with a   sidecar .
# ISg+ NPl/V3 D/P+ NSg/VB+    P    D/P NSg     .
> Jim  was listening to Bach with his     eyes    closed .
# NPr+ VPt Nᴹ/Vg/J   P  NPr  P    ISg/D$+ NPl/V3+ VP/J   .
> The match   result  was 10 - 5 , with John scoring  three goals   .
# D+  NSg/VB+ NSg/VB+ VPt #  . # . P    NPr+ Nᴹ/Vg/J+ NSg+  NPl/V3+ .
> With a   heavy    sigh   , she  looked around the empty     room       .
# P    D/P NSg/VB/J NSg/VB . ISg+ VP/J   J/P    D+  NSg/VB/J+ N🅪Sg/VB/J+ .
> Four people  were    injured , with one     of them     in        critical condition .
# NSg+ NPl/VB+ NSg/VPt VP/J    . P    NSg/I/J P  NSg/IPl+ NPr/J/R/P NSg/J+   N🅪Sg/VB+  .
> With their reputation on  the line    , they decided  to fire      their PR   team    .
# P    D$+   NSg+       J/P D+  NSg/VB+ . IPl+ NSg/VP/J P  N🅪Sg/VB/J D$+   NSg+ NSg/VB+ .
> We   are with you    all          the way    .
# IPl+ VB  P    ISgPl+ NSg/I/J/C/Dq D+  NSg/J+ .
> There are a   number     of problems with your plan   .
# R+    VB  D/P N🅪Sg/VB/JC P  NPl+     P    D$+  NSg/VB .
> What   on  Earth    is  wrong      with my  keyboard ?
# NSg/I+ J/P NPrᴹ/VB+ VL3 NSg/VB/J/R P    D$+ NSg/VB+  .
> He       was pleased with the outcome .
# NPr/ISg+ VPt VP/J    P    D+  NSg+    .
> I’m upset    with my  father  .
# K   NSg/VB/J P    D$+ NPr/VB+ .
> slain   with robbers .
# NSg/VPp P    NPl     .
> cut       with a    knife
# NSg/VBP/J P    D/P+ NSg/VB+
> I       water   my  plants  with this    watering can     . This    is  the watering can     I       water   my  plants  with .
# ISg/#r+ N🅪Sg/VB D$+ NPl/V3+ P    I/Ddem+ Nᴹ/Vg/J+ NPr/VXB . I/Ddem+ VL3 D   Nᴹ/Vg/J  NPr/VXB ISg/#r+ N🅪Sg/VB D$+ NPl/V3+ P    .
> Find   what   you    want   instantly with our search   engine  .
# NSg/VB NSg/I+ ISgPl+ NSg/VB R         P    D$+ N🅪Sg/VB+ NSg/VB+ .
> They dismissed the meeting    with a   wave   of their hand    .
# IPl+ VP/J      D+  N🅪Sg/Vg/J+ P    D/P NSg/VB P  D$+   NSg/VB+ .
> Speak  with a    confident voice   .
# NSg/VB P    D/P+ NSg/J+    NSg/VB+ .
> With what   / whose money   ? I       have    nothing  left     to buy    groceries ( with ) .
# P    NSg/I+ . I+    N🅪Sg/J+ . ISg/#r+ NSg/VXB NSg/I/J+ NPr/VP/J P  NSg/VB NPl/V3+   . P    . .
> It       was small    and  bumpy , with a   tinge  of orange      .
# NPr/ISg+ VPt NPr/VB/J VB/C J     . P    D/P NSg/VB P  NPr🅪Sg/VB/J .
> There are lots   of people  with no        homes   after the wildfire .
# R+    VB  NPl/V3 P  NPl/VB+ P    NSg/Dq/P+ NPl/V3+ P     D   NSg      .
> Speak  with confidence .
# NSg/VB P    Nᴹ+        .
> He       spoke   with sadness in        his     voice   .
# NPr/ISg+ NSg/VPt P    Nᴹ+     NPr/J/R/P ISg/D$+ NSg/VB+ .
> The sailors were    infected with malaria .
# D+  NPl+    NSg/VPt NSg/VP/J P    Nᴹ+     .
> overcome with happiness
# VB       P    Nᴹ+
> green       with envy    ; flushed with success
# NPr🅪Sg/VB/J P    NSg/VB+ . VP/J    P    N🅪Sg+
> She  was with Acme for   twenty years before retiring last     fall     .
# ISg+ VPt P    NSg  R/C/P NSg    NPl+  C/P    Nᴹ/Vg/J  NSg/VB/J N🅪Sg/VB+ .
> With your kind  of body    size     , you    shouldn’t be      eating  pizza at    all          .
# P    D$+  NSg/J P  NSg/VB+ N🅪Sg/VB+ . ISgPl+ VXB       NSg/VXB Nᴹ/Vg/J N🅪Sg+ NSg/P NSg/I/J/C/Dq .
> That          was a   lot    to explain ; are you    still      with me       ?
# NSg/I/C/Ddem+ VPt D/P NPr/VB P  VB      . VB  ISgPl+ NSg/VB/J/R P    NPr/ISg+ .
>
#
>              Adverb
# HeadingStart NSg/VB+
>
#
> Do  you    want   to come       with ?
# VXB ISgPl+ NSg/VB P  NSg/VBPp/P P    .



================================================
FILE: harper-core/tests/text/tagged/Part-of-speech tagging.md
================================================
> <!--
# Unlintable
>            source: https://en.wikipedia.org/w/index.php?title=Part-of-speech_tagging&oldid=1275774341
# Unlintable Unlintable
>            license: CC BY-SA 4.0
# Unlintable Unlintable
>            -->
# Unlintable Unlintable
>                         Part      - of - speech   tagging
# Unlintable HeadingStart NSg/VB/J+ . P  . N🅪Sg/VB+ NSg/Vg
>
#
> In        corpus linguistics , part      - of - speech   tagging ( POS  tagging or    PoS  tagging or
# NPr/J/R/P NSg+   Nᴹ+         . NSg/VB/J+ . P  . N🅪Sg/VB+ NSg/Vg  . NSg+ NSg/Vg  NPr/C NSg+ NSg/Vg  NPr/C
> POST         ) , also called grammatical tagging is  the process of marking up         a   word    in        a
# NPr🅪Sg/VB/P+ . . R/C  VP/J   J           NSg/Vg  VL3 D   NSg/VB  P  Nᴹ/Vg/J NSg/VB/J/P D/P NSg/VB+ NPr/J/R/P D/P
> text     ( corpus ) as    corresponding to a   particular part     of speech   , based on  both   its
# N🅪Sg/VB+ . NSg+   . R/C/P Nᴹ/Vg/J       P  D/P NSg/J      NSg/VB/J P  N🅪Sg/VB+ . VP/J  J/P I/C/Dq ISg/D$+
> definition and  its     context  . A   simplified form    of this    is  commonly taught to
# NSg        VB/C ISg/D$+ N🅪Sg/VB+ . D/P VP/J       N🅪Sg/VB P  I/Ddem+ VL3 R        VP     P
> school  - age      children , in        the identification of words   as    nouns  , verbs   , adjectives ,
# N🅪Sg/VB . N🅪Sg/VB+ NPl+     . NPr/J/R/P D   Nᴹ             P  NPl/V3+ R/C/P NPl/V3 . NPl/V3+ . NPl/V3     .
> adverbs , etc.
# NPl/V3  . +
>
#
> Once  performed by    hand    , POS  tagging is  now       done      in        the context of computational
# NSg/C VP/J      NSg/P NSg/VB+ . NSg+ NSg/Vg  VL3 NSg/J/R/C NSg/VPp/J NPr/J/R/P D   N🅪Sg/VB P  J
> linguistics , using   algorithms which associate discrete terms   , as    well       as    hidden
# Nᴹ+         . Nᴹ/Vg/J NPl+       I/C+  NSg/VB/J+ J        NPl/V3+ . R/C/P NSg/VB/J/R R/C/P VB/J
> parts  of speech   , by    a   set       of descriptive tags    . POS  - tagging algorithms fall     into
# NPl/V3 P  N🅪Sg/VB+ . NSg/P D/P NPr/VBP/J P  NSg/J       NPl/V3+ . NSg+ . NSg/Vg  NPl+       N🅪Sg/VB+ P
> two distinctive groups  : rule    - based and  stochastic . E. Brill's tagger , one     of the
# NSg NSg/J       NPl/V3+ . NSg/VB+ . VP/J  VB/C J          . ?  ?       NSg    . NSg/I/J P  D
> first and  most         widely used English      POS  - taggers , employs rule    - based algorithms .
# NSg/J VB/C NSg/I/J/R/Dq R      VP/J NPr🅪Sg/VB/J+ NSg+ . NPl     . NPl/V3  NSg/VB+ . VP/J  NPl+       .
>
#
>              Principle
# HeadingStart N🅪Sg/VB+
>
#
> Part      - of - speech   tagging is  harder than just having  a   list   of words   and  their
# NSg/VB/J+ . P  . N🅪Sg/VB+ NSg/Vg  VL3 JC     C/P  J/R  Nᴹ/Vg/J D/P NSg/VB P  NPl/V3+ VB/C D$+
> parts  of speech   , because some     words   can     represent more         than one     part     of speech
# NPl/V3 P  N🅪Sg/VB+ . C/P     I/J/R/Dq NPl/V3+ NPr/VXB VB        NPr/I/J/R/Dq C/P  NSg/I/J NSg/VB/J P  N🅪Sg/VB+
> at    different times   , and  because some     parts  of speech   are complex  . This    is  not
# NSg/P NSg/J     NPl/V3+ . VB/C C/P     I/J/R/Dq NPl/V3 P  N🅪Sg/VB+ VB  NSg/VB/J . I/Ddem+ VL3 NSg/R/C
> rare     — in        natural languages ( as    opposed to many        artificial languages ) , a   large
# NSg/VB/J . NPr/J/R/P NSg/J+  NPl/V3+   . R/C/P VP/J    P  NSg/I/J/Dq+ J+         NPl/V3+   . . D/P NSg/J
> percentage of word    - forms   are ambiguous . For   example , even       " dogs    " , which is
# N🅪Sg       P  NSg/VB+ . NPl/V3+ VB  J         . R/C/P NSg/VB+ . NSg/VB/J/R . NPl/V3+ . . I/C+  VL3
> usually thought of as    just a    plural noun    , can     also be      a    verb    :
# R       N🅪Sg/VP P  R/C/P J/R  D/P+ NSg/J+ NSg/VB+ . NPr/VXB R/C  NSg/VXB D/P+ NSg/VB+ .
>
#
> The sailor dogs    the hatch   .
# D+  NSg+   NPl/V3+ D+  NSg/VB+ .
>
#
> Correct  grammatical tagging will    reflect that          " dogs    " is  here used as    a   verb    , not
# NSg/VB/J J           NSg/Vg  NPr/VXB VB      NSg/I/C/Ddem+ . NPl/V3+ . VL3 J/R  VP/J R/C/P D/P NSg/VB+ . NSg/R/C
> as    the more         common   plural noun    . Grammatical context  is  one     way   to determine
# R/C/P D   NPr/I/J/R/Dq NSg/VB/J NSg/J  NSg/VB+ . J+          N🅪Sg/VB+ VL3 NSg/I/J NSg/J P  VB
> this    ; semantic analysis can     also be      used to infer that          " sailor " and  " hatch  "
# I/Ddem+ . NSg/J+   N🅪Sg+    NPr/VXB R/C  NSg/VXB VP/J P  VB    NSg/I/C/Ddem+ . NSg+   . VB/C . NSg/VB .
> implicate " dogs    " as    1 ) in        the nautical context  and  2 ) an  action     applied to the
# NSg/VB    . NPl/V3+ . R/C/P # . NPr/J/R/P D   J        N🅪Sg/VB+ VB/C # . D/P N🅪Sg/VB/J+ VP/J    P  D
> object  " hatch  " ( in        this   context  , " dogs    " is  a   nautical term      meaning    " fastens ( a
# NSg/VB+ . NSg/VB . . NPr/J/R/P I/Ddem N🅪Sg/VB+ . . NPl/V3+ . VL3 D/P J        NSg/VB/J+ N🅪Sg/Vg/J+ . V3      . D/P
> watertight door    ) securely " ) .
# J          NSg/VB+ . R        . . .
>
#
>              Tag     sets
# HeadingStart NSg/VB+ NPl/V3
>
#
> Schools commonly teach  that         there are 9 parts  of speech  in        English     : noun    , verb    ,
# NPl/V3+ R        NSg/VB NSg/I/C/Ddem R+    VB  # NPl/V3 P  N🅪Sg/VB NPr/J/R/P NPr🅪Sg/VB/J . NSg/VB+ . NSg/VB+ .
> article , adjective , preposition , pronoun , adverb  , conjunction , and  interjection .
# NSg/VB+ . NSg/VB/J+ . NSg/VB      . NSg/VB+ . NSg/VB+ . NSg/VB+     . VB/C N🅪Sg+        .
> However , there are clearly many        more          categories and  sub      - categories . For   nouns  ,
# C       . R+    VB  R       NSg/I/J/Dq+ NPr/I/J/R/Dq+ NPl+       VB/C NSg/VB/P . NPl+       . R/C/P NPl/V3 .
> the plural , possessive , and  singular forms   can     be      distinguished . In        many
# D   NSg/J  . NSg/J      . VB/C NSg/J    NPl/V3+ NPr/VXB NSg/VXB VP/J          . NPr/J/R/P NSg/I/J/Dq+
> languages words   are also marked for   their " case       " ( role as    subject   , object  ,
# NPl/V3+   NPl/V3+ VB  R/C  VP/J   R/C/P D$+   . NPr🅪Sg/VB+ . . NSg  R/C/P NSg/VB/J+ . NSg/VB+ .
> etc. ) , grammatical gender     , and  so          on  ; while      verbs   are marked for   tense    , aspect   ,
# +    . . J+          N🅪Sg/VB/J+ . VB/C NSg/I/J/R/C J/P . NSg/VB/C/P NPl/V3+ VB  VP/J   R/C/P NSg/VB/J . N🅪Sg/VB+ .
> and  other     things . In        some     tagging systems , different inflections of the same
# VB/C NSg/VB/J+ NPl+   . NPr/J/R/P I/J/R/Dq NSg/Vg  NPl+    . NSg/J     NPl         P  D   I/J
> root    word    will    get    different parts  of speech   , resulting in        a   large number     of
# NPr/VB+ NSg/VB+ NPr/VXB NSg/VB NSg/J     NPl/V3 P  N🅪Sg/VB+ . Nᴹ/Vg/J   NPr/J/R/P D/P NSg/J N🅪Sg/VB/JC P
> tags    . For   example , NN for   singular common   nouns  , NNS for   plural common   nouns  , NP
# NPl/V3+ . R/C/P NSg/VB+ . ?  R/C/P NSg/J    NSg/VB/J NPl/V3 . ?   R/C/P NSg/J  NSg/VB/J NPl/V3 . NPr
> for   singular proper nouns  ( see    the POS  tags    used in        the Brown       Corpus ) . Other
# R/C/P NSg/J    NSg/J  NPl/V3 . NSg/VB D   NSg+ NPl/V3+ VP/J NPr/J/R/P D   NPr🅪Sg/VB/J NSg+   . . NSg/VB/J
> tagging systems use     a   smaller number     of tags    and  ignore fine     differences or
# NSg/Vg  NPl+    N🅪Sg/VB D/P NSg/JC  N🅪Sg/VB/JC P  NPl/V3+ VB/C VB     NSg/VB/J NPl/VB      NPr/C
> model     them     as    features somewhat independent from part      - of - speech   .
# NSg/VB/J+ NSg/IPl+ R/C/P NPl/V3+  NSg/I/R  NSg/J       P    NSg/VB/J+ . P  . N🅪Sg/VB+ .
>
#
> In        part      - of - speech   tagging by    computer , it       is  typical to distinguish from 50 to
# NPr/J/R/P NSg/VB/J+ . P  . N🅪Sg/VB+ NSg/Vg  NSg/P NSg/VB+  . NPr/ISg+ VL3 NSg/J   P  VB          P    #  P
> 150 separate parts  of speech  for   English      . Work    on  stochastic methods for   tagging
# #   NSg/VB/J NPl/V3 P  N🅪Sg/VB R/C/P NPr🅪Sg/VB/J+ . N🅪Sg/VB J/P J          NPl/V3+ R/C/P NSg/Vg
> Koine Greek    ( DeRose 1990 ) has used over    1 , 000 parts  of speech   and  found  that
# ?     NPr/VB/J . ?      #    . V3  VP/J NSg/J/P # . #   NPl/V3 P  N🅪Sg/VB+ VB/C NSg/VP NSg/I/C/Ddem
> about as    many       words   were    ambiguous in        that         language as    in        English      . A
# J/P   R/C/P NSg/I/J/Dq NPl/V3+ NSg/VPt J         NPr/J/R/P NSg/I/C/Ddem N🅪Sg/VB+ R/C/P NPr/J/R/P NPr🅪Sg/VB/J+ . D/P
> morphosyntactic descriptor in        the case      of morphologically rich     languages is
# ?               NSg        NPr/J/R/P D   NPr🅪Sg/VB P  ?               NPr/VB/J NPl/V3+   VL3
> commonly expressed using   very short      mnemonics , such  as    Ncmsan for   Category = Noun    ,
# R        VP/J      Nᴹ/Vg/J J/R  NPr/VB/J/P NPl       . NSg/I R/C/P ?      R/C/P NSg+     . NSg/VB+ .
> Type    = common   , Gender     = masculine , Number      = singular , Case       = accusative , Animate
# NSg/VB+ . NSg/VB/J . N🅪Sg/VB/J+ . NSg/J     . N🅪Sg/VB/JC+ . NSg/J    . NPr🅪Sg/VB+ . NSg/J      . VB/J
> = no       .
# . NSg/Dq/P .
>
#
> The most         popular " tag    set       " for   POS  tagging for   American English      is  probably the
# D   NSg/I/J/R/Dq NSg/J   . NSg/VB NPr/VBP/J . R/C/P NSg+ NSg/Vg  R/C/P NPr/J    NPr🅪Sg/VB/J+ VL3 R        D
> Penn tag     set       , developed in        the Penn Treebank project . It       is  largely similar to
# NPr+ NSg/VB+ NPr/VBP/J . VP/J      NPr/J/R/P D   NPr+ ?        NSg/VB+ . NPr/ISg+ VL3 R       NSg/J   P
> the earlier Brown       Corpus and  LOB    Corpus tag     sets   , though much         smaller . In
# D   JC      NPr🅪Sg/VB/J NSg    VB/C NSg/VB NSg+   NSg/VB+ NPl/V3 . C      NSg/I/J/R/Dq NSg/JC  . NPr/J/R/P
> Europe , tag     sets   from the Eagles Guidelines see    wide  use      and  include versions
# NPr+   . NSg/VB+ NPl/V3 P    D   NPl/V3 NPl+       NSg/VB NSg/J N🅪Sg/VB+ VB/C NSg/VB  NPl/V3+
> for   multiple languages .
# R/C/P NSg/J/Dq NPl/V3+   .
>
#
> POS  tagging work     has been    done      in        a   variety of languages , and  the set       of POS
# NSg+ NSg/Vg  N🅪Sg/VB+ V3  NSg/VPp NSg/VPp/J NPr/J/R/P D/P N🅪Sg    P  NPl/V3+   . VB/C D   NPr/VBP/J P  NSg+
> tags    used varies greatly with language . Tags    usually are designed to include
# NPl/V3+ VP/J NPl/V3 R       P    N🅪Sg/VB+ . NPl/V3+ R       VB  VP/J     P  NSg/VB
> overt  morphological distinctions , although this   leads  to inconsistencies such  as
# NSg/J+ J+            NPl+         . C        I/Ddem NPl/V3 P  NPl             NSg/I R/C/P
> case       - marking for   pronouns but     not     nouns  in        English      , and  much         larger
# NPr🅪Sg/VB+ . Nᴹ/Vg/J R/C/P NPl/V3   NSg/C/P NSg/R/C NPl/V3 NPr/J/R/P NPr🅪Sg/VB/J+ . VB/C NSg/I/J/R/Dq JC
> cross       - language differences . The tag     sets   for   heavily inflected languages such  as
# NPr/VB/J/P+ . N🅪Sg/VB+ NPl/VB+     . D+  NSg/VB+ NPl/V3 R/C/P R       VP/J      NPl/V3+   NSg/I R/C/P
> Greek    and  Latin can     be      very large ; tagging words   in        agglutinative languages such
# NPr/VB/J VB/C NPr/J NPr/VXB NSg/VXB J/R  NSg/J . NSg/Vg  NPl/V3+ NPr/J/R/P J             NPl/V3+   NSg/I
> as    Inuit languages may     be      virtually impossible . At    the other    extreme , Petrov et
# R/C/P NPr/J NPl/V3+   NPr/VXB NSg/VXB R         NSg/J      . NSg/P D   NSg/VB/J NSg/J   . ?      ?
> al. have    proposed a   " universal " tag     set       , with 12 categories ( for   example , no
# ?   NSg/VXB VP/J     D/P . NSg/J     . NSg/VB+ NPr/VBP/J . P    #  NPl+       . R/C/P NSg/VB+ . NSg/Dq/P
> subtypes of nouns  , verbs   , punctuation , and  so          on  ) . Whether a   very small    set       of
# NPl      P  NPl/V3 . NPl/V3+ . Nᴹ+         . VB/C NSg/I/J/R/C J/P . . I/C     D/P J/R  NPr/VB/J NPr/VBP/J P
> very broad tags    or    a   much         larger set       of more         precise ones is  preferable , depends
# J/R  NSg/J NPl/V3+ NPr/C D/P NSg/I/J/R/Dq JC     NPr/VBP/J P  NPr/I/J/R/Dq VB/J+   NPl+ VL3 J          . NPl/V3
> on  the purpose  at    hand    . Automatic tagging is  easier on  smaller tag     - sets   .
# J/P D   N🅪Sg/VB+ NSg/P NSg/VB+ . NSg/J     NSg/Vg  VL3 NSg/JC J/P NSg/JC  NSg/VB+ . NPl/V3 .
>
#
>              History
# HeadingStart N🅪Sg+
>
#
>              The Brown       Corpus
# HeadingStart D+  NPr🅪Sg/VB/J NSg+
>
#
> Research on  part      - of - speech   tagging has been    closely tied to corpus linguistics .
# Nᴹ/VB    J/P NSg/VB/J+ . P  . N🅪Sg/VB+ NSg/Vg  V3  NSg/VPp R       VP/J P  NSg    Nᴹ+         .
> The first major    corpus of English     for   computer analysis was the Brown       Corpus
# D   NSg/J NPr/VB/J NSg    P  NPr🅪Sg/VB/J R/C/P NSg/VB+  N🅪Sg+    VPt D   NPr🅪Sg/VB/J NSg
> developed at    Brown       University by    Henry Kučera and  W. Nelson Francis , in        the
# VP/J      NSg/P NPr🅪Sg/VB/J NSg+       NSg/P NPr+  ?      VB/C ?  NPr+   NPr+    . NPr/J/R/P D
> mid      - 1960s . It       consists of about 1 , 000 , 000 words  of running   English      prose text     ,
# NSg/J/P+ . #d    . NPr/ISg+ NPl/V3   P  J/P   # . #   . #   NPl/V3 P  Nᴹ/Vg/J/P NPr🅪Sg/VB/J+ Nᴹ/VB N🅪Sg/VB+ .
> made up         of 500 samples from randomly chosen   publications . Each sample  is  2 , 000
# VP   NSg/VB/J/P P  #   NPl/V3+ P    R        Nᴹ/VPp/J NPl+         . Dq+  NSg/VB+ VL3 # . #
> or    more         words   ( ending  at    the first sentence - end     after 2 , 000 words   , so          that         the
# NPr/C NPr/I/J/R/Dq NPl/V3+ . Nᴹ/Vg/J NSg/P D   NSg/J NSg/VB+  . NSg/VB+ P     # . #   NPl/V3+ . NSg/I/J/R/C NSg/I/C/Ddem D
> corpus contains only  complete sentences ) .
# NSg+   V3       J/R/C NSg/VB/J NPl/V3+   . .
>
#
> The Brown        Corpus was painstakingly " tagged " with part      - of - speech   markers over
# D+  NPr🅪Sg/VB/J+ NSg+   VPt R             . VP/J   . P    NSg/VB/J+ . P  . N🅪Sg/VB+ NPl/V3  NSg/J/P
> many        years . A    first  approximation was done      with a    program by    Greene and  Rubin ,
# NSg/I/J/Dq+ NPl+  . D/P+ NSg/J+ N🅪Sg+         VPt NSg/VPp/J P    D/P+ NPr/VB+ NSg/P NPr    VB/C NPr   .
> which consisted of a   huge handmade list   of what   categories could   co        - occur at
# I/C+  VP/J      P  D/P J    NSg/J    NSg/VB P  NSg/I+ NPl+       NSg/VXB NPr/I/VB+ . VB    NSg/P
> all          . For   example , article then      noun    can     occur , but     article then      verb    ( arguably )
# NSg/I/J/C/Dq . R/C/P NSg/VB+ . NSg/VB+ NSg/J/R/C NSg/VB+ NPr/VXB VB    . NSg/C/P NSg/VB+ NSg/J/R/C NSg/VB+ . R        .
> cannot  . The program got about 70 % correct  . Its     results were    repeatedly reviewed
# NSg/VXB . D+  NPr/VB+ VP  J/P   #  . NSg/VB/J . ISg/D$+ NPl/V3+ NSg/VPt R          VP/J
> and  corrected by    hand    , and  later users sent   in        errata so          that          by    the late  70 s
# VB/C VP/J      NSg/P NSg/VB+ . VB/C JC    NPl+  NSg/VP NPr/J/R/P NSg    NSg/I/J/R/C NSg/I/C/Ddem+ NSg/P D   NSg/J #  ?
> the tagging was nearly perfect  ( allowing for   some     cases   on  which even       human
# D   NSg/Vg  VPt R      NSg/VB/J . Nᴹ/Vg/J  R/C/P I/J/R/Dq NPl/V3+ J/P I/C+  NSg/VB/J/R NSg/VB/J+
> speakers might    not     agree ) .
# +        Nᴹ/VXB/J NSg/R/C VB    . .
>
#
> This    corpus has been    used for   innumerable studies of word    - frequency and  of
# I/Ddem+ NSg+   V3  NSg/VPp VP/J R/C/P J           NPl/V3  P  NSg/VB+ . NSg       VB/C P
> part      - of - speech   and  inspired the development of similar " tagged " corpora in        many
# NSg/VB/J+ . P  . N🅪Sg/VB+ VB/C VP/J     D   N🅪Sg        P  NSg/J   . VP/J   . NPl+    NPr/J/R/P NSg/I/J/Dq
> other    languages . Statistics derived by    analyzing it       formed the basis for   most
# NSg/VB/J NPl/V3+   . NPl/V3+    VP/J    NSg/P Nᴹ/Vg/J   NPr/ISg+ VP/J   D+  NSg+  R/C/P NSg/I/J/R/Dq
> later part      - of - speech   tagging systems , such  as    CLAWS   and  VOLSUNGA . However , by
# JC    NSg/VB/J+ . P  . N🅪Sg/VB+ NSg/Vg  NPl+    . NSg/I R/C/P NPl/V3+ VB/C ?        . C       . NSg/P
> this    time       ( 2005 ) it       has been    superseded by    larger corpora such  as    the 100
# I/Ddem+ N🅪Sg/VB/J+ . #    . NPr/ISg+ V3  NSg/VPp VP/J       NSg/P JC     NPl+    NSg/I R/C/P D   #
> million word    British National Corpus , even       though larger corpora are rarely so
# NSg     NSg/VB+ NPr/J   NSg/J    NSg+   . NSg/VB/J/R C      JC     NPl+    VB  R      NSg/I/J/R/C
> thoroughly curated .
# R          VP/J    .
>
#
> For   some     time       , part      - of - speech   tagging was considered an  inseparable part     of
# R/C/P I/J/R/Dq N🅪Sg/VB/J+ . NSg/VB/J+ . P  . N🅪Sg/VB+ NSg/Vg  VPt VP/J       D/P NSg/J       NSg/VB/J P
> natural language processing , because there are certain cases   where   the correct
# NSg/J   N🅪Sg/VB+ Nᴹ/Vg/J+   . C/P     R+    VB  I/J     NPl/V3+ NSg/R/C D   NSg/VB/J
> part     of speech   cannot  be      decided  without understanding the semantics or    even       the
# NSg/VB/J P  N🅪Sg/VB+ NSg/VXB NSg/VXB NSg/VP/J C/P     N🅪Sg/Vg/J+    D   NPl+      NPr/C NSg/VB/J/R D
> pragmatics of the context  . This    is  extremely expensive , especially because
# NPl        P  D   N🅪Sg/VB+ . I/Ddem+ VL3 R         J         . R          C/P
> analyzing the higher  levels  is  much         harder when    multiple part     - of - speech
# Nᴹ/Vg/J   D+  NSg/JC+ NPl/V3+ VL3 NSg/I/J/R/Dq JC     NSg/I/C NSg/J/Dq NSg/VB/J . P  . N🅪Sg/VB+
> possibilities must    be      considered for   each word    .
# NPl+          NSg/VXB NSg/VXB VP/J       R/C/P Dq+  NSg/VB+ .
>
#
>              Use     of hidden Markov models
# HeadingStart N🅪Sg/VB P  VB/J   NPr    NPl/V3+
>
#
> In        the mid      - 1980s , researchers in        Europe began to use     hidden Markov models  ( HMMs )
# NPr/J/R/P D   NSg/J/P+ . #d    . NPl         NPr/J/R/P NPr+   VPt   P  N🅪Sg/VB VB/J   NPr    NPl/V3+ . ?    .
> to disambiguate parts  of speech   , when    working to tag    the Lancaster - Oslo - Bergen
# P  VB           NPl/V3 P  N🅪Sg/VB+ . NSg/I/C Nᴹ/Vg/J P  NSg/VB D   NPr       . NPr+ . NPr+
> Corpus of British English      . HMMs involve counting cases   ( such  as    from the Brown
# NSg    P  NPr/J   NPr🅪Sg/VB/J+ . ?    VB      Nᴹ/Vg/J  NPl/V3+ . NSg/I R/C/P P    D   NPr🅪Sg/VB/J
> Corpus ) and  making  a   table  of the probabilities of certain sequences . For
# NSg+   . VB/C Nᴹ/Vg/J D/P NSg/VB P  D   NPl           P  I/J     NPl/V3+   . R/C/P
> example , once  you've seen    an  article such  as    ' the ' , perhaps the next    word    is  a
# NSg/VB+ . NSg/C K      NSg/VPp D/P NSg/VB+ NSg/I R/C/P . D   . . NSg/R   D   NSg/J/P NSg/VB+ VL3 D/P
> noun    40 % of the time       , an  adjective 40 % , and  a   number      20 % . Knowing    this    , a
# NSg/VB+ #  . P  D   N🅪Sg/VB/J+ . D/P NSg/VB/J+ #  . . VB/C D/P N🅪Sg/VB/JC+ #  . . NSg/Vg/J/P I/Ddem+ . D/P+
> program can     decide that          " can     " in        " the can     " is  far      more         likely to be      a   noun   than
# NPr/VB+ NPr/VXB VB     NSg/I/C/Ddem+ . NPr/VXB . NPr/J/R/P . D+  NPr/VXB . VL3 NSg/VB/J NPr/I/J/R/Dq NSg/J  P  NSg/VXB D/P NSg/VB C/P
> a    verb    or    a   modal . The same method  can     , of course  , be      used to benefit from
# D/P+ NSg/VB+ NPr/C D/P NSg/J . D+  I/J+ NSg/VB+ NPr/VXB . P  NSg/VB+ . NSg/VXB VP/J P  NSg/VB  P
> knowledge about the following   words   .
# Nᴹ+       J/P   D+  N🅪Sg/Vg/J/P NPl/V3+ .
>
#
> More         advanced ( " higher - order   " ) HMMs learn  the probabilities not     only  of pairs
# NPr/I/J/R/Dq VP/J     . . NSg/JC . N🅪Sg/VB . . ?    NSg/VB D   NPl+          NSg/R/C J/R/C P  NPl/V3+
> but     triples or    even       larger sequences . So          , for   example , if    you've just seen    a
# NSg/C/P NPl/V3  NPr/C NSg/VB/J/R JC     NPl/V3+   . NSg/I/J/R/C . R/C/P NSg/VB+ . NSg/C K      J/R  NSg/VPp D/P
> noun    followed by    a   verb    , the next    item    may     be      very likely a   preposition ,
# NSg/VB+ VP/J     NSg/P D/P NSg/VB+ . D   NSg/J/P NSg/VB+ NPr/VXB NSg/VXB J/R  NSg/J  D/P NSg/VB      .
> article , or    noun    , but     much         less       likely another verb    .
# NSg/VB+ . NPr/C NSg/VB+ . NSg/C/P NSg/I/J/R/Dq VB/J/R/C/P NSg/J  I/D     NSg/VB+ .
>
#
> When    several ambiguous words   occur together , the possibilities multiply .
# NSg/I/C J/Dq+   J+        NPl/V3+ VB    J        . D+  NPl+          NSg/VB   .
> However , it       is  easy     to enumerate every combination and  to assign a   relative
# C       . NPr/ISg+ VL3 NSg/VB/J P  VB        Dq+   N🅪Sg+       VB/C P  NSg/VB D/P NSg/J
> probability to each one      , by    multiplying together the probabilities of each
# NSg+        P  Dq   NSg/I/J+ . NSg/P Nᴹ/Vg/J     J        D   NPl           P  Dq
> choice  in        turn   . The combination with the highest probability is  then      chosen   . The
# N🅪Sg/J+ NPr/J/R/P NSg/VB . D   N🅪Sg        P    D+  JS+     NSg+        VL3 NSg/J/R/C Nᴹ/VPp/J . D+
> European group   developed CLAWS   , a   tagging program that          did  exactly this   and
# NSg/J+   NSg/VB+ VP/J      NPl/V3+ . D/P NSg/Vg  NPr/VB+ NSg/I/C/Ddem+ VXPt R       I/Ddem VB/C
> achieved accuracy in        the 93 – 95 % range    .
# VP/J     N🅪Sg+    NPr/J/R/P D   #  . #  . N🅪Sg/VB+ .
>
#
> Eugene Charniak points  out          in        Statistical techniques for   natural language
# NPr+   ?        NPl/V3+ NSg/VB/J/R/P NPr/J/R/P J           NPl        R/C/P NSg/J+  N🅪Sg/VB+
> parsing ( 1997 ) that          merely assigning the most         common   tag     to each known word    and
# Nᴹ/Vg/J . #    . NSg/I/C/Ddem+ R      Nᴹ/Vg/J   D   NSg/I/J/R/Dq NSg/VB/J NSg/VB+ P  Dq   VPp/J NSg/VB+ VB/C
> the tag     " proper noun    " to all          unknowns will    approach 90 % accuracy because many
# D   NSg/VB+ . NSg/J  NSg/VB+ . P  NSg/I/J/C/Dq NPl/V3+  NPr/VXB N🅪Sg/VB+ #  . N🅪Sg+    C/P     NSg/I/J/Dq
> words   are unambiguous , and  many       others  only  rarely represent their less       - common
# NPl/V3+ VB  J           . VB/C NSg/I/J/Dq NPl/V3+ J/R/C R      VB        D$+   VB/J/R/C/P . NSg/VB/J
> parts  of speech   .
# NPl/V3 P  N🅪Sg/VB+ .
>
#
> CLAWS   pioneered the field  of HMM - based part     of speech   tagging but     was quite
# NPl/V3+ VP/J      D   NSg/VB P  VB  . VP/J  NSg/VB/J P  N🅪Sg/VB+ NSg/Vg  NSg/C/P VPt R
> expensive since it       enumerated all          possibilities . It       sometimes had to resort to
# J         C/P   NPr/ISg+ VP/J       NSg/I/J/C/Dq NPl+          . NPr/ISg+ R         VP  P  NSg/VB P
> backup methods when    there were    simply too many       options ( the Brown        Corpus
# NSg/J  NPl/V3+ NSg/I/C R+    NSg/VPt R      R   NSg/I/J/Dq NPl/V3  . D+  NPr🅪Sg/VB/J+ NSg+
> contains a   case       with 17 ambiguous words  in        a    row     , and  there are words   such  as
# V3       D/P NPr🅪Sg/VB+ P    #  J         NPl/V3 NPr/J/R/P D/P+ NSg/VB+ . VB/C R+    VB  NPl/V3+ NSg/I R/C/P
> " still      " that          can     represent as    many       as    7 distinct parts  of speech   .
# . NSg/VB/J/R . NSg/I/C/Ddem+ NPr/VXB VB        R/C/P NSg/I/J/Dq R/C/P # VB/J     NPl/V3 P  N🅪Sg/VB+ .
>
#
> HMMs underlie the functioning of stochastic taggers and  are used in        various
# ?    VB       D   Nᴹ/Vg/J+    P  J          NPl     VB/C VB  VP/J NPr/J/R/P J
> algorithms one     of the most         widely used being       the bi    - directional inference
# NPl+       NSg/I/J P  D   NSg/I/J/R/Dq R      VP/J N🅪Sg/Vg/J/C D   NSg/J . NSg/J       NSg+
> algorithm .
# NSg       .
>
#
>              Dynamic programming methods
# HeadingStart NSg/J+  Nᴹ/Vg/J+    NPl/V3+
>
#
> In        1987 , Steven DeRose and  Kenneth W. Church     independently developed dynamic
# NPr/J/R/P #    . NPr+   ?      VB/C NPr+    ?  NPr🅪Sg/VB+ R             VP/J      NSg/J
> programming algorithms to solve  the same problem in        vastly less       time       . Their
# Nᴹ/Vg/J+    NPl+       P  NSg/VB D   I/J  NSg/J+  NPr/J/R/P R      VB/J/R/C/P N🅪Sg/VB/J+ . D$+
> methods were    similar to the Viterbi algorithm known for   some     time       in        other
# NPl/V3+ NSg/VPt NSg/J   P  D   ?       NSg       VPp/J R/C/P I/J/R/Dq N🅪Sg/VB/J+ NPr/J/R/P NSg/VB/J
> fields    . DeRose used a   table  of pairs   , while      Church     used a   table  of triples and  a
# NPrPl/V3+ . ?      VP/J D/P NSg/VB P  NPl/V3+ . NSg/VB/C/P NPr🅪Sg/VB+ VP/J D/P NSg/VB P  NPl/V3  VB/C D/P
> method of estimating the values  for   triples that          were    rare     or    nonexistent in        the
# NSg/VB P  Nᴹ/Vg/J    D   NPl/V3+ R/C/P NPl/V3  NSg/I/C/Ddem+ NSg/VPt NSg/VB/J NPr/C NSg/J       NPr/J/R/P D
> Brown       Corpus ( an  actual measurement of triple   probabilities would require a   much
# NPr🅪Sg/VB/J NSg+   . D/P NSg/J  N🅪Sg        P  NSg/VB/J NPl+          VXB   NSg/VB  D/P NSg/I/J/R/Dq
> larger corpus ) . Both   methods achieved an  accuracy of over    95 % . DeRose's 1990
# JC     NSg+   . . I/C/Dq NPl/V3+ VP/J     D/P N🅪Sg+    P  NSg/J/P #  . . ?        #
> dissertation at    Brown       University included analyses     of the specific error   types   ,
# NSg+         NSg/P NPr🅪Sg/VB/J NSg+       VP/J     NPl/V3/Au/Br P  D   NSg/J    NSg/VB+ NPl/V3+ .
> probabilities , and  other    related data  , and  replicated his     work     for   Greek    , where
# NPl+          . VB/C NSg/VB/J J       N🅪Pl+ . VB/C VP/J       ISg/D$+ N🅪Sg/VB+ R/C/P NPr/VB/J . NSg/R/C
> it       proved similarly effective .
# NPr/ISg+ VP/J   R         NSg/J     .
>
#
> These   findings were    surprisingly disruptive to the field  of natural language
# I/Ddem+ NSg+     NSg/VPt R            J          P  D   NSg/VB P  NSg/J+  N🅪Sg/VB+
> processing . The accuracy reported was higher than the typical accuracy of very
# Nᴹ/Vg/J+   . D+  N🅪Sg+    VP/J     VPt NSg/JC C/P  D   NSg/J   N🅪Sg     P  J/R
> sophisticated algorithms that          integrated part     of speech   choice  with many       higher
# VP/J+         NPl+       NSg/I/C/Ddem+ VP/J       NSg/VB/J P  N🅪Sg/VB+ N🅪Sg/J+ P    NSg/I/J/Dq NSg/JC
> levels of linguistic analysis : syntax , morphology , semantics , and  so          on  . CLAWS   ,
# NPl/V3 P  J          N🅪Sg     . Nᴹ+    . Nᴹ+        . NPl+      . VB/C NSg/I/J/R/C J/P . NPl/V3+ .
> DeRose's and  Church's methods did  fail     for   some     of the known cases   where
# ?        VB/C NPr$     NPl/V3+ VXPt NSg/VB/J R/C/P I/J/R/Dq P  D   VPp/J NPl/V3+ NSg/R/C
> semantics is  required , but     those  proved negligibly rare     . This   convinced many       in
# NPl+      VL3 VP/J     . NSg/C/P I/Ddem VP/J   R          NSg/VB/J . I/Ddem VP/J      NSg/I/J/Dq NPr/J/R/P
> the field   that          part      - of - speech   tagging could   usefully be      separated from the other
# D+  NSg/VB+ NSg/I/C/Ddem+ NSg/VB/J+ . P  . N🅪Sg/VB+ NSg/Vg  NSg/VXB R        NSg/VXB VP/J      P    D   NSg/VB/J
> levels of processing ; this    , in        turn   , simplified the theory and  practice of
# NPl/V3 P  Nᴹ/Vg/J+   . I/Ddem+ . NPr/J/R/P NSg/VB . VP/J       D   N🅪Sg   VB/C NSg/VB   P
> computerized language analysis and  encouraged researchers to find   ways to
# VP/J         N🅪Sg/VB+ N🅪Sg+    VB/C VP/J       NPl+        P  NSg/VB NPl+ P
> separate other    pieces  as    well       . Markov Models  became the standard method  for   the
# NSg/VB/J NSg/VB/J NPl/V3+ R/C/P NSg/VB/J/R . NPr    NPl/V3+ VPt    D   NSg/J    NSg/VB+ R/C/P D
> part      - of - speech   assignment .
# NSg/VB/J+ . P  . N🅪Sg/VB+ NSg+       .
>
#
>              Unsupervised taggers
# HeadingStart VB/J         NPl
>
#
> The methods already discussed involve working from a    pre       - existing corpus to
# D+  NPl/V3+ R       VP/J      VB      Nᴹ/Vg/J P    D/P+ NSg/VB/P+ . Nᴹ/Vg/J  NSg+   P
> learn  tag     probabilities . It       is  , however , also possible to bootstrap using
# NSg/VB NSg/VB+ NPl+          . NPr/ISg+ VL3 . C       . R/C  NSg/J    P  NSg/VB    Nᴹ/Vg/J
> " unsupervised " tagging . Unsupervised tagging techniques use     an  untagged corpus
# . VB/J         . NSg/Vg  . VB/J         NSg/Vg  NPl+       N🅪Sg/VB D/P J        NSg+
> for   their training data  and  produce the tagset by    induction . That          is  , they
# R/C/P D$+   Nᴹ/Vg/J+ N🅪Pl+ VB/C Nᴹ/VB   D   NSg    NSg/P N🅪Sg      . NSg/I/C/Ddem+ VL3 . IPl+
> observe patterns in        word    use     , and  derive part      - of - speech   categories themselves .
# NSg/VB  NPl/V3+  NPr/J/R/P NSg/VB+ N🅪Sg/VB . VB/C NSg/VB NSg/VB/J+ . P  . N🅪Sg/VB+ NPl+       IPl+       .
> For   example , statistics readily reveal that          " the " , " a   " , and  " an  " occur in
# R/C/P NSg/VB+ . NPl/V3+    R       NSg/VB NSg/I/C/Ddem+ . D   . . . D/P . . VB/C . D/P . VB    NPr/J/R/P
> similar contexts , while      " eat " occurs in        very different ones . With sufficient
# NSg/J+  NPl/V3+  . NSg/VB/C/P . VB  . V3     NPr/J/R/P J/R  NSg/J+    NPl+ . P    J
> iteration , similarity classes of words   emerge that          are remarkably similar to
# N🅪Sg      . NSg        NPl/V3  P  NPl/V3+ NSg/VB NSg/I/C/Ddem+ VB  R          NSg/J   P
> those  human    linguists would expect ; and  the differences themselves sometimes
# I/Ddem NSg/VB/J NPl+      VXB   VB     . VB/C D   NPl/VB+     IPl+       R
> suggest valuable new   insights .
# VB      NSg/J    NSg/J NPl+     .
>
#
> These   two  categories can     be      further subdivided into rule    - based , stochastic , and
# I/Ddem+ NSg+ NPl+       NPr/VXB NSg/VXB VB/JC   VP/J       P    NSg/VB+ . VP/J  . J          . VB/C
> neural approaches .
# J      NPl/V3+    .
>
#
>              Other    taggers and  methods
# HeadingStart NSg/VB/J NPl     VB/C NPl/V3+
>
#
> Some     current major    algorithms for   part      - of - speech   tagging include the Viterbi
# I/J/R/Dq NSg/J   NPr/VB/J NPl        R/C/P NSg/VB/J+ . P  . N🅪Sg/VB+ NSg/Vg  NSg/VB  D   ?
> algorithm , Brill tagger , Constraint Grammar  , and  the Baum - Welch algorithm ( also
# NSg       . NSg/J NSg    . NSg+       N🅪Sg/VB+ . VB/C D   NPr  . ?     NSg       . R/C
> known as    the forward  - backward algorithm ) . Hidden Markov model     and  visible Markov
# VPp/J R/C/P D   NSg/VB/J . NSg/J    NSg       . . VB/J   NPr    NSg/VB/J+ VB/C J       NPr
> model     taggers can     both   be      implemented using   the Viterbi algorithm . The
# NSg/VB/J+ NPl     NPr/VXB I/C/Dq NSg/VXB VP/J        Nᴹ/Vg/J D   ?       NSg       . D+
> rule    - based Brill tagger is  unusual in        that         it       learns a   set       of rule    patterns , and
# NSg/VB+ . VP/J  NSg/J NSg    VL3 NSg/J   NPr/J/R/P NSg/I/C/Ddem NPr/ISg+ NPl/V3 D/P NPr/VBP/J P  NSg/VB+ NPl/V3+  . VB/C
> then      applies those  patterns rather     than optimizing a   statistical quantity .
# NSg/J/R/C V3      I/Ddem NPl/V3+  NPr/VB/J/R C/P  Nᴹ/Vg/J    D/P J           N🅪Sg+    .
>
#
> Many        machine learning methods have    also been    applied to the problem of POS
# NSg/I/J/Dq+ NSg/VB+ Nᴹ/Vg/J+ NPl/V3+ NSg/VXB R/C  NSg/VPp VP/J    P  D   NSg/J   P  NSg+
> tagging . Methods such  as    SVM , maximum entropy classifier , perceptron , and
# NSg/Vg  . NPl/V3+ NSg/I R/C/P ?   . NSg/J   NSg     NSg        . NSg        . VB/C
> nearest - neighbor     have    all          been    tried , and  most         can     achieve accuracy above
# JS      . NSg/VB/J/Am+ NSg/VXB NSg/I/J/C/Dq NSg/VPp VP/J  . VB/C NSg/I/J/R/Dq NPr/VXB VB      N🅪Sg+    NSg/J/P
> 95 % . [ citation needed ]
# #  . . . NSg+     VP/J   .
>
#
> A   direct comparison of several methods is  reported ( with references ) at    the ACL
# D/P VB/J   NSg        P  J/Dq+   NPl/V3+ VL3 VP/J     . P    NPl/V3+    . NSg/P D   NSg
> Wiki    . This    comparison uses   the Penn tag     set       on  some     of the Penn Treebank data  ,
# NSg/VB+ . I/Ddem+ NSg+       NPl/V3 D+  NPr+ NSg/VB+ NPr/VBP/J J/P I/J/R/Dq P  D   NPr+ ?        N🅪Pl+ .
> so          the results are directly comparable . However , many       significant taggers are
# NSg/I/J/R/C D   NPl/V3+ VB  R/C      NSg/J      . C       . NSg/I/J/Dq NSg/J       NPl     VB
> not     included ( perhaps because of the labor            involved in        reconfiguring them     for
# NSg/R/C VP/J     . NSg/R   C/P     P  D   NPr🅪Sg/VB/Am/Au+ VP/J     NPr/J/R/P Nᴹ/Vg/J       NSg/IPl+ R/C/P
> this   particular dataset ) . Thus , it       should not     be      assumed that         the results
# I/Ddem NSg/J      NSg     . . NSg  . NPr/ISg+ VXB    NSg/R/C NSg/VXB VP/J    NSg/I/C/Ddem D+  NPl/V3+
> reported here are the best       that          can     be      achieved with a    given        approach ; nor   even
# VP/J     J/R  VB  D   NPr/VXB/JS NSg/I/C/Ddem+ NPr/VXB NSg/VXB VP/J     P    D/P+ NSg/VPp/J/P+ N🅪Sg/VB+ . NSg/C NSg/VB/J/R
> the best        that          have    been    achieved with a    given        approach .
# D+  NPr/VXB/JS+ NSg/I/C/Ddem+ NSg/VXB NSg/VPp VP/J     P    D/P+ NSg/VPp/J/P+ N🅪Sg/VB+ .
>
#
> In        2014 , a    paper      reporting using   the structure regularization method for
# NPr/J/R/P #    . D/P+ N🅪Sg/VB/J+ Nᴹ/Vg/J   Nᴹ/Vg/J D   N🅪Sg/VB+  N🅪Sg           NSg/VB R/C/P
> part      - of - speech   tagging , achieving 97.36 % on  a   standard benchmark dataset .
# NSg/VB/J+ . P  . N🅪Sg/VB+ NSg/Vg  . Nᴹ/Vg/J   #     . J/P D/P NSg/J    NSg/VB    NSg     .



================================================
FILE: harper-core/tests/text/tagged/Spell.md
================================================
>              Spell
# HeadingStart NSg/VB
>
#
> This    document contains example sentences with misspelled words   that          we   want   to test   the spell  checker on  .
# I/Ddem+ NSg/VB+  V3       NSg/VB+ NPl/V3+   P    VP/J       NPl/V3+ NSg/I/C/Ddem+ IPl+ NSg/VB P  NSg/VB D   NSg/VB NSg/VB  J/P .
>
#
>              Example Sentences
# HeadingStart NSg/VB+ NPl/V3+
>
#
> My  favourite      color         is  blu .
# D$+ NSg/VB/J/Comm+ N🅪Sg/VB/J/Am+ VL3 W?  .
> I       must    defend my  honour        !
# ISg/#r+ NSg/VXB NSg/VB D$+ N🅪Sg/VB/Comm+ .
> I       recognize that         you    recognise me       .
# ISg/#r+ VB        NSg/I/C/Ddem ISgPl+ VB/Au/Br  NPr/ISg+ .
> I       analyze how   you    infantilize me       .
# ISg/#r+ VB      NSg/C ISgPl+ VB          NPr/ISg+ .
> I       analyse  how   you    infantilise me       .
# ISg/#r+ VB/Au/Br NSg/C ISgPl+ ?           NPr/ISg+ .
> Careful , traveller !
# J       . NSg/Comm+ .
> At    the centre      of the theatre    I       dropped a   litre    of coke       .
# NSg/P D   NSg/VB/Comm P  D+  N🅪Sg/Comm+ ISg/#r+ VP/J    D/P NSg/Comm P  NPr🅪Sg/VB+ .



================================================
FILE: harper-core/tests/text/tagged/Spell.US.md
================================================
>              Spell
# HeadingStart NSg/VB
>
#
> This    document contains a   list   of words   spelled correctly in        some     dialects of English      , but     not     American English      . This    is  designed to test   the spelling suggestions we   give   for   such   mistakes .
# I/Ddem+ NSg/VB+  V3       D/P NSg/VB P  NPl/V3+ VP/J    R         NPr/J/R/P I/J/R/Dq NPl      P  NPr🅪Sg/VB/J+ . NSg/C/P NSg/R/C NPr/J    NPr🅪Sg/VB/J+ . I/Ddem+ VL3 VP/J     P  NSg/VB D+  Nᴹ/Vg/J+ NPl+        IPl+ NSg/VB R/C/P NSg/I+ NPl/V3+  .
>
#
> To achieve this    , the filename of this   file    contains `.US.`     , which will    tell   the snapshot generator to use     the American dialect , rather     than trying  to use     an  automatically detected dialect .
# P  VB      I/Ddem+ . D   NSg      P  I/Ddem NSg/VB+ V3       Unlintable . I/C+  NPr/VXB NPr/VB D   NSg/VB+  NSg       P  N🅪Sg/VB D   NPr/J    NSg+    . NPr/VB/J/R C/P  Nᴹ/Vg/J P  N🅪Sg/VB D/P R             VP/J     NSg+    .
>
#
>              Words
# HeadingStart NPl/V3+
>
#
>
#
>
#
> Afterwards .
# R/Comm     .
>
#
> Centre       .
# NSg/VB/Comm+ .
>
#
> Labelled  .
# VB/J/Comm .
>
#
> Flavour       .
# N🅪Sg/VB/Comm+ .
>
#
> Favoured  .
# VP/J/Comm .
>
#
> Honour        .
# N🅪Sg/VB/Comm+ .
>
#
> Grey             .
# NPr🅪Sg/VB/J/Comm .
>
#
> Quarrelled .
# VB/Comm    .
>
#
> Quarrelling .
# Nᴹ/VB/Comm  .
>
#
> Recognised .
# VP/J/Au/Br .
>
#
> Neighbour      .
# NSg/VB/J/Comm+ .
>
#
> Neighbouring .
# Nᴹ/Vg/J/Comm .
>
#
> Clamour     .
# NSg/VB/Comm .
>
#
> Theatre    .
# N🅪Sg/Comm+ .
>
#
> Analyse  .
# VB/Au/Br .



================================================
FILE: harper-core/tests/text/tagged/Swear.md
================================================
>              Swears
# HeadingStart NPl/V3
>
#
> This    documents tests   that         different forms   / variations of swears are tagged as    such  .
# I/Ddem+ NPl/V3+   NPl/V3+ NSg/I/C/Ddem NSg/J+    NPl/V3+ . NPl        P  NPl/V3 VB  VP/J   R/C/P NSg/I .
>
#
>              Examples
# HeadingStart NPl/V3+
>
#
> One      turd      , two turds    .
# NSg/I/J+ NSg/VB+/B . NSg NPl/V3/B .
>
#
> I       fart     , you're farting   , he       farts    , she  farted .
# ISg/#r+ NSg/VB/B . +      Nᴹ/Vg/J/B . NPr/ISg+ NPl/V3/B . ISg+ VP/J/B .



================================================
FILE: harper-core/tests/text/tagged/this and that.md
================================================
> " This    " and  " that          " are common   and  fulfill multiple purposes in        everyday English      .
# . I/Ddem+ . VB/C . NSg/I/C/Ddem+ . VB  NSg/VB/J VB/C VB/NoAm NSg/J/Dq NPl/V3   NPr/J/R/P NSg/J+   NPr🅪Sg/VB/J+ .
> As    such  , disambiguating them     is  necessary .
# R/C/P NSg/I . Nᴹ/Vg/J        NSg/IPl+ VL3 NSg/J     .
>
#
> This    document contains various sentences that          use     " this    " , " that          " , " these  " , and
# I/Ddem+ NSg/VB+  V3       J+      NPl/V3+   NSg/I/C/Ddem+ N🅪Sg/VB . I/Ddem+ . . . NSg/I/C/Ddem+ . . . I/Ddem . . VB/C
> " those  " in        different contexts with a   lot    of edge    cases   .
# . I/Ddem . NPr/J/R/P NSg/J     NPl/V3   P    D/P NPr/VB P  NSg/VB+ NPl/V3+ .
>
#
>              Examples
# HeadingStart NPl/V3+
>
#
> This   triangle is  nice  .
# I/Ddem NSg      VL3 NPr/J .
> This    is  nice  .
# I/Ddem+ VL3 NPr/J .
> That          triangle is  nice  .
# NSg/I/C/Ddem+ NSg      VL3 NPr/J .
> That          is  nice  .
# NSg/I/C/Ddem+ VL3 NPr/J .
> These  triangles are nice  .
# I/Ddem NPl       VB  NPr/J .
> These   are nice  .
# I/Ddem+ VB  NPr/J .
> Those  triangles are nice  .
# I/Ddem NPl       VB  NPr/J .
> Those   are nice  .
# I/Ddem+ VB  NPr/J .
>
#
> This    massage is  nice  .
# I/Ddem+ NSg/VB+ VL3 NPr/J .
> That         massage is  nice  .
# NSg/I/C/Ddem NSg/VB+ VL3 NPr/J .
> These   massages are nice  .
# I/Ddem+ NPl/V3+  VB  NPr/J .
> Those   massages are nice  .
# I/Ddem+ NPl/V3+  VB  NPr/J .
> This    massages well       .
# I/Ddem+ NPl/V3+  NSg/VB/J/R .
> That          massages well       .
# NSg/I/C/Ddem+ NPl/V3+  NSg/VB/J/R .
> These   massage well       .
# I/Ddem+ NSg/VB+ NSg/VB/J/R .
> Those   massage well       .
# I/Ddem+ NSg/VB+ NSg/VB/J/R .
>
#
> That          could   be      a    solution .
# NSg/I/C/Ddem+ NSg/VXB NSg/VXB D/P+ N🅪Sg+    .
> Find   all           candidates that          could   be      a    solution .
# NSg/VB NSg/I/J/C/Dq+ NPl/V3+    NSg/I/C/Ddem+ NSg/VXB NSg/VXB D/P+ N🅪Sg+    .
>
#
> This    is  all          that         I       have    .
# I/Ddem+ VL3 NSg/I/J/C/Dq NSg/I/C/Ddem ISg/#r+ NSg/VXB .
> This    is  all          that         solutions can     do  .
# I/Ddem+ VL3 NSg/I/J/C/Dq NSg/I/C/Ddem NPl+      NPr/VXB VXB .
> That         solution can     do  .
# NSg/I/C/Ddem N🅪Sg+    NPr/VXB VXB .
>
#
> We   can     do  this    !
# IPl+ NPr/VXB VXB I/Ddem+ .
> I       can     do  this   and  that          .
# ISg/#r+ NPr/VXB VXB I/Ddem VB/C NSg/I/C/Ddem+ .
>
#
> We   unite  to stand  united in        unity .
# IPl+ NSg/VB P  NSg/VB VP/J   NPr/J/R/P Nᴹ+   .



================================================
FILE: harper-html/Cargo.toml
================================================
[package]
name = "harper-html"
version = "1.5.1"
edition = "2024"
description = "The language checker for developers."
license = "Apache-2.0"
repository = "https://github.com/automattic/harper"

[dependencies]
harper-core = { path = "../harper-core", version = "1.0.0" }
harper-tree-sitter = { path = "../harper-tree-sitter", version = "1.0.0" }
tree-sitter-html = "0.23.2"
tree-sitter = "0.25.10"

[dev-dependencies]
paste = "1.0.15"



================================================
FILE: harper-html/src/lib.rs
================================================
use harper_core::parsers::{self, Parser, PlainEnglish};
use harper_core::{Token, TokenKind};
use harper_tree_sitter::TreeSitterMasker;
use tree_sitter::Node;

pub struct HtmlParser {
    /// Used to grab the text nodes.
    inner: parsers::Mask<TreeSitterMasker, PlainEnglish>,
}

impl HtmlParser {
    fn node_condition(n: &Node) -> bool {
        n.kind() == "text"
    }
}

impl Default for HtmlParser {
    fn default() -> Self {
        Self {
            inner: parsers::Mask::new(
                TreeSitterMasker::new(tree_sitter_html::LANGUAGE.into(), Self::node_condition),
                PlainEnglish,
            ),
        }
    }
}

impl Parser for HtmlParser {
    fn parse(&self, source: &[char]) -> Vec<Token> {
        let mut tokens = self.inner.parse(source);

        for token in &mut tokens {
            if let TokenKind::Space(v) = &mut token.kind {
                *v = (*v).clamp(0, 1);
            }
        }

        tokens
    }
}



================================================
FILE: harper-html/tests/run_tests.rs
================================================
use harper_core::linting::{LintGroup, Linter};
use harper_core::spell::FstDictionary;
use harper_core::{Dialect, Document};

/// Creates a unit test checking that the linting of a Markdown document (in
/// `tests_sources`) produces the expected number of lints.
macro_rules! create_test {
    ($filename:ident.html, $correct_expected:expr) => {
        paste::paste! {
            #[test]
            fn [<lints_ $filename _correctly>](){
                 let source = include_str!(
                    concat!(
                        "./test_sources/",
                        concat!(stringify!($filename), ".html")
                    )
                 );

                 let dict = FstDictionary::curated();
                 let document = Document::new_markdown_default(&source, &dict);

                 let mut linter = LintGroup::new_curated(dict, Dialect::American);
                 let lints = linter.lint(&document);

                 dbg!(&lints);
                 assert_eq!(lints.len(), $correct_expected);

                 // Make sure that all generated tokens span real characters
                 for token in document.tokens(){
                     assert!(token.span.try_get_content(document.get_source()).is_some());
                 }
            }
        }
    };
}

create_test!(run_on.html, 0);
create_test!(issue_156.html, 0);
create_test!(issue_541.html, 0);



================================================
FILE: harper-html/tests/test_sources/issue_156.html
================================================
<p>
  foo
  <b>bar</b>
</p>



================================================
FILE: harper-html/tests/test_sources/issue_541.html
================================================
<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
</head>

<body>
  <p>
    This block contains multiple lines of HTML. If Harper is throwing a "too many spaces" lint, it's
    because <code>harper-html</code> isn't properly parsing the indent.
  </p>
</body>

</html>



================================================
FILE: harper-html/tests/test_sources/run_on.html
================================================
<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">

  <p>Here is a paragraph</p>
  <p>Here is a paragraph</p>
  <p>Here is a paragraph</p>
  <p>Here is a paragraph</p>
  <p>Here is a paragraph</p>
  <p>Here is a paragraph</p>
  <p>Here is a paragraph</p>
  <p>Here is a paragraph</p>
  <p>Here is a paragraph</p>
  <p>Here is a paragraph</p>
  <p>Here is a paragraph</p>
  <p>Here is a paragraph</p>
  <p>Here is a paragraph</p>
  <p>Here is a paragraph</p>
  <p>Here is a paragraph</p>
  <p>Here is a paragraph</p>
  <p>Here is a paragraph</p>
  <p>Here is a paragraph</p>
  <p>Here is a paragraph</p>
  <p>Here is a paragraph</p>
  <p>Here is a paragraph</p>
  <p>Here is a paragraph</p>
  <p>Here is a paragraph</p>
  <p>Here is a paragraph</p>
</head>

<body>
</body>

</html>



================================================
FILE: harper-ink/Cargo.toml
================================================
[package]
name = "harper-ink"
version = "1.5.1"
edition = "2024"
description = "The language checker for developers."
license = "Apache-2.0"
repository = "https://github.com/automattic/harper"

[dependencies]
harper-core = { path = "../harper-core", version = "1.0.0" }
harper-tree-sitter = { path = "../harper-tree-sitter", version = "1.0.0" }
tree-sitter-ink-lbz = "0.0.1"
tree-sitter = "0.25.10"

[dev-dependencies]
paste = "1.0.15"



================================================
FILE: harper-ink/src/lib.rs
================================================
use harper_core::parsers::{self, Parser, PlainEnglish};
use harper_core::{Token, TokenKind};
use harper_tree_sitter::TreeSitterMasker;
use tree_sitter::Node;

pub struct InkParser {
    inner: parsers::Mask<TreeSitterMasker, PlainEnglish>,
}

impl InkParser {
    fn node_condition(n: &Node) -> bool {
        matches!(n.kind(), "contentText" | "blockComment" | "lineComment")
    }
}

impl Default for InkParser {
    fn default() -> Self {
        Self {
            inner: parsers::Mask::new(
                TreeSitterMasker::new(tree_sitter_ink_lbz::LANGUAGE.into(), Self::node_condition),
                PlainEnglish,
            ),
        }
    }
}

impl Parser for InkParser {
    fn parse(&self, source: &[char]) -> Vec<Token> {
        let mut tokens = self.inner.parse(source);

        for token in &mut tokens {
            if let TokenKind::Space(v) = &mut token.kind {
                *v = (*v).clamp(0, 1);
            }
        }

        tokens
    }
}



================================================
FILE: harper-ink/tests/run_tests.rs
================================================
use harper_core::linting::{LintGroup, Linter};
use harper_core::spell::FstDictionary;
use harper_core::{Dialect, Document};
use harper_ink::InkParser;

/// Creates a unit test checking that the linting of a Ink document (in
/// `tests_sources`) produces the expected number of lints.
macro_rules! create_test {
    ($filename:ident.ink, $correct_expected:expr) => {
        paste::paste! {
            #[test]
            fn [<lints_ $filename _correctly>](){
                 let source = include_str!(
                    concat!(
                        "./test_sources/",
                        concat!(stringify!($filename), ".ink")
                    )
                 );

                 let dict = FstDictionary::curated();
                 let document = Document::new(&source, &InkParser::default(),
                      &FstDictionary::curated()
                      );

                 let mut linter = LintGroup::new_curated(dict, Dialect::American);
                 let lints = linter.lint(&document);

                 dbg!(&lints);
                 assert_eq!(lints.len(), $correct_expected);

                 // Make sure that all generated tokens span real characters
                 for token in document.tokens(){
                     assert!(token.span.try_get_content(document.get_source()).is_some());
                 }
            }
        }
    };
}

create_test!(good.ink, 0);
create_test!(bad.ink, 5);



================================================
FILE: harper-ink/tests/test_sources/bad.ink
================================================
=== Knot ===
text here is checked: chungus

= Stitch

~identifiersAreNotchecked = "but strings are: chungus"
// comments are also checked -> chungus

/*
chungus
*/

* choices are checked
+ chungus
+ normal text



================================================
FILE: harper-ink/tests/test_sources/good.ink
================================================
=== Knot ===
    this is a thing

= Stitch
  * an option
  + another option

  + normal text
    + + indented choice
    + + another indented choice

  - gather

= ThreeWordStitch
    test


================================================
FILE: harper-jjdescription/Cargo.toml
================================================
[package]
name = "harper-jjdescription"
version = "1.5.1"
edition = "2024"
description = "The language checker for developers."
license = "Apache-2.0"
repository = "https://github.com/automattic/harper"

[dependencies]
harper-core = { path = "../harper-core", version = "1.0.0" }
harper-tree-sitter = { path = "../harper-tree-sitter", version = "1.0.0" }
tree-sitter-jjdescription = "0.0.1"
tree-sitter = "0.25.10"

[dev-dependencies]
paste = "1.0.15"



================================================
FILE: harper-jjdescription/src/lib.rs
================================================
use harper_core::Token;
use harper_core::parsers::{self, Markdown, MarkdownOptions, Parser};
use harper_tree_sitter::TreeSitterMasker;
use tree_sitter::Node;

pub struct JJDescriptionParser {
    /// Used to grab the text nodes, and parse them as markdown.
    inner: parsers::Mask<TreeSitterMasker, Markdown>,
}

impl JJDescriptionParser {
    fn node_condition(n: &Node) -> bool {
        n.kind() == "text"
    }

    pub fn new(markdown_options: MarkdownOptions) -> Self {
        Self {
            inner: parsers::Mask::new(
                TreeSitterMasker::new(tree_sitter_jjdescription::language(), Self::node_condition),
                Markdown::new(markdown_options),
            ),
        }
    }
}

impl Parser for JJDescriptionParser {
    fn parse(&self, source: &[char]) -> Vec<Token> {
        self.inner.parse(source)
    }
}



================================================
FILE: harper-jjdescription/tests/run_tests.rs
================================================
use harper_core::linting::{LintGroup, Linter};
use harper_core::parsers::MarkdownOptions;
use harper_core::spell::FstDictionary;
use harper_core::{Dialect, Document};
use harper_jjdescription::JJDescriptionParser;

/// Creates a unit test checking that the linting of a git commit document (in
/// `tests_sources`) produces the expected number of lints.
macro_rules! create_test {
    ($filename:ident.txt, $correct_expected:expr) => {
        paste::paste! {
            #[test]
            fn [<lints_ $filename _correctly>](){
                 let source = include_str!(
                    concat!(
                        "./test_sources/",
                        concat!(stringify!($filename), ".txt")
                    )
                 );

                 let dict = FstDictionary::curated();
                 let document = Document::new(source, &JJDescriptionParser::new(MarkdownOptions::default()), &dict);

                 let mut linter = LintGroup::new_curated(dict, Dialect::American);
                 let lints = linter.lint(&document);

                 dbg!(&lints);
                 assert_eq!(lints.len(), $correct_expected);

                 // Make sure that all generated tokens span real characters
                 for token in document.tokens(){
                     assert!(token.span.try_get_content(document.get_source()).is_some());
                 }
            }
        }
    };
}

create_test!(simple_description.txt, 1);
create_test!(complex_verbose_description.txt, 2);
create_test!(conventional_description.txt, 3);



================================================
FILE: harper-jjdescription/tests/test_sources/complex_verbose_description.txt
================================================
This is the the subject

This is a first line without typos
JJ: This is a comment with a typoo that should be ignored
This is a line below the comment with typooos

JJ: This commit contains the following changes:
JJ:     myfile.txt | 1 +
JJ:     1 file changed, 1 insertion(+), 0 deletions(-)

JJ: ignore-rest
diff --git a/myfile.txt b/myfile.txt
new file mode 100644
index 0000000000..54f266d2db
--- /dev/null
+++ b/myfile.txt
@@ -0,0 +1,1 @@
+typooo in the file

JJ: Lines starting with "JJ:" (like this one) will be removed.



================================================
FILE: harper-jjdescription/tests/test_sources/conventional_description.txt
================================================
feat(stuff): use session-based authentiation

BREAKING CHANGE: JWT authentication removed. API clients mustt now use
session cookies instead of Authorization headers with bearer tokens.

Sessions expire after 24 hours of inactvity.

Closes: #247
Reviewed-by: John Doe <john@example.com>

JJ: Change ID: qrutlxlw
JJ: This commit contains the following changes:
JJ:     M Cargo.lock
JJ:     M Cargo.toml
JJ:     A harper-jjdescription/Cargo.toml
JJ:     A harper-jjdescription/src/lib.rs
JJ:     A harper-jjdescription/tests/run_tests.rs
JJ:     A harper-jjdescription/tests/test_sources/complex_verbose_description.txt
JJ:     A harper-jjdescription/tests/test_sources/conventional_description.txt
JJ:     A harper-jjdescription/tests/test_sources/simple_description.txt
JJ:     M harper-ls/Cargo.toml
JJ:     M harper-ls/src/backend.rs
JJ:
JJ: Lines starting with "JJ:" (like this one) will be removed.




================================================
FILE: harper-jjdescription/tests/test_sources/simple_description.txt
================================================
A simple description with a typo: descrption



================================================
FILE: harper-literate-haskell/Cargo.toml
================================================
[package]
name = "harper-literate-haskell"
version = "1.5.1"
edition = "2024"
description = "The language checker for developers."
license = "Apache-2.0"
repository = "https://github.com/automattic/harper"

[dependencies]
harper-core = { path = "../harper-core", version = "1.0.0" }
harper-tree-sitter = { path = "../harper-tree-sitter", version = "1.0.0" }
harper-comments = { path = "../harper-comments", version = "1.0.0" }
itertools = "0.14.0"
paste = "1.0.14"



================================================
FILE: harper-literate-haskell/src/lib.rs
================================================
use harper_comments::CommentParser;
use harper_core::{
    Lrc, Masker, Token,
    parsers::{Markdown, MarkdownOptions, Mask, Parser},
};

mod masker;
use harper_core::spell::MutableDictionary;
use itertools::Itertools;
use masker::LiterateHaskellMasker;

/// Parses a Literate Haskell document by masking out the code and considering text as Markdown.
pub struct LiterateHaskellParser {
    inner: Lrc<dyn Parser>,
}

impl LiterateHaskellParser {
    pub fn new(inner: Lrc<dyn Parser>) -> Self {
        Self { inner }
    }

    pub fn new_markdown(markdown_options: MarkdownOptions) -> Self {
        Self {
            inner: Lrc::new(Markdown::new(markdown_options)),
        }
    }

    pub fn create_ident_dict(
        &self,
        source: &[char],
        markdown_options: MarkdownOptions,
    ) -> Option<MutableDictionary> {
        let parser = CommentParser::new_from_language_id("haskell", markdown_options).unwrap();
        let mask = LiterateHaskellMasker::code_only().create_mask(source);

        let code = mask
            .iter_allowed(source)
            .flat_map(|(_, src)| src.to_owned())
            .collect_vec();
        parser.create_ident_dict(&code)
    }
}

impl Parser for LiterateHaskellParser {
    fn parse(&self, source: &[char]) -> Vec<Token> {
        Mask::new(LiterateHaskellMasker::text_only(), self.inner.clone()).parse(source)
    }
}



================================================
FILE: harper-literate-haskell/src/masker.rs
================================================
use harper_core::{CharStringExt, Mask, Masker, Span};

/// Masker for selecting portions of Literate Haskell documents.
///
/// Based on the specifications outlined at https://wiki.haskell.org/Literate_programming.
pub struct LiterateHaskellMasker {
    text: bool,
    code: bool,
}

impl LiterateHaskellMasker {
    pub fn text_only() -> Self {
        Self {
            text: true,
            code: false,
        }
    }

    pub fn code_only() -> Self {
        Self {
            text: false,
            code: true,
        }
    }
}

impl Masker for LiterateHaskellMasker {
    fn create_mask(&self, source: &[char]) -> harper_core::Mask {
        let mut mask = Mask::new_blank();

        let mut location = 0;
        let mut in_code_env = false;
        let mut last_line_blank = false;

        for line in source.split(|c| *c == '\n') {
            let string_form = line.to_string();
            let trimmed = string_form.trim();
            let line_is_bird = line.first().is_some_and(|c| *c == '>');

            // Code fencing
            let latex_style = matches!(trimmed, r"\begin{code}" | r"\end{code}");
            let code_start = trimmed == r"\begin{code}" || (last_line_blank && line_is_bird);
            let code_end = trimmed == r"\end{code}" || trimmed.is_empty();

            // Toggle on fence
            if (!in_code_env && code_start) || (in_code_env && code_end) {
                in_code_env = !in_code_env;

                // Exclude latex-style fence
                if latex_style {
                    location += line.len() + 1; // +1 for the newline split on
                    last_line_blank = trimmed.is_empty();
                    continue;
                }

                // Exclude newline after code for bird style
                if trimmed.is_empty() {
                    location += line.len() + 1; // +1 for the newline split on
                    last_line_blank = true;
                    continue;
                }
            }

            let end_loc = location + line.len();
            if (!in_code_env && self.text) || (in_code_env && self.code) {
                let start_loc = if line_is_bird { location + 2 } else { location };
                mask.push_allowed(Span::new(start_loc, end_loc));
            }

            location = end_loc + 1; // +1 for the newline split on
            last_line_blank = trimmed.is_empty();
        }

        mask.merge_whitespace_sep(source);
        mask
    }
}

#[cfg(test)]
mod tests {
    use harper_core::{Masker, Span};
    use itertools::Itertools;

    use super::LiterateHaskellMasker;

    #[test]
    fn bird_format() {
        let source = r"Text here

> fact :: Integer -> Integer
> fact 0 = 1
> fact n = n * fact (n-1)

Text here
"
        .chars()
        .collect_vec();

        let text_mask = LiterateHaskellMasker::text_only().create_mask(&source);
        assert_eq!(
            text_mask
                .iter_allowed(&source)
                .map(|(s, _)| s)
                .collect_vec(),
            vec![Span::new(0, 10), Span::new(80, 90)],
        );

        let code_mask = LiterateHaskellMasker::code_only().create_mask(&source);
        assert_eq!(
            code_mask
                .iter_allowed(&source)
                .map(|(s, _)| s)
                .collect_vec(),
            vec![Span::new(13, 39), Span::new(42, 52), Span::new(55, 78)],
        );
    }

    #[test]
    fn latex_format() {
        let source = r#"Text here
\begin{code}
main :: IO ()
main = print "just an example"
\end{code}
Text here
"#
        .chars()
        .collect_vec();

        let text_mask = LiterateHaskellMasker::text_only().create_mask(&source);
        assert_eq!(
            text_mask
                .iter_allowed(&source)
                .map(|(s, _)| s)
                .collect_vec(),
            vec![Span::new(0, 9), Span::new(79, 89)],
        );

        let code_mask = LiterateHaskellMasker::code_only().create_mask(&source);
        assert_eq!(
            code_mask
                .iter_allowed(&source)
                .map(|(s, _)| s)
                .collect_vec(),
            vec![Span::new(23, 67)],
        );
    }
}



================================================
FILE: harper-literate-haskell/tests/run_tests.rs
================================================
use harper_core::linting::{LintGroup, Linter};
use harper_core::parsers::MarkdownOptions;
use harper_core::spell::FstDictionary;
use harper_core::{Dialect, Document};
use harper_literate_haskell::LiterateHaskellParser;

/// Creates a unit test checking that the linting of a Markdown document (in
/// `tests_sources`) produces the expected number of lints.
macro_rules! create_test {
    ($filename:ident.lhs, $correct_expected:expr) => {
        paste::paste! {
            #[test]
            fn [<lints_ $filename _correctly>](){
                 let source = include_str!(
                    concat!(
                        "./test_sources/",
                        concat!(stringify!($filename), ".lhs")
                    )
                 );

                 let dict = FstDictionary::curated();
                 let document = Document::new_curated(&source, &LiterateHaskellParser::new_markdown(MarkdownOptions::default()));

                 let mut linter = LintGroup::new_curated(dict, Dialect::American);
                 let lints = linter.lint(&document);

                 dbg!(&lints);
                 assert_eq!(lints.len(), $correct_expected);

                 // Make sure that all generated tokens span real characters
                 for token in document.tokens(){
                     assert!(token.span.try_get_content(document.get_source()).is_some());
                 }
            }
        }
    };
}

create_test!(bird_format.lhs, 2);
create_test!(latex_format.lhs, 2);
create_test!(mixed_format.lhs, 4);



================================================
FILE: harper-literate-haskell/tests/test_sources/bird_format.lhs
================================================
Sourced from https://wiki.haskell.org/Literate_programming.

In Bird-style you have to leave a blnk before the code.

> fact :: Integer -> Integer
> fact 0 = 1
> fact n = n * fact (n-1)

And you have to leave a blnk line after the code as well.



================================================
FILE: harper-literate-haskell/tests/test_sources/latex_format.lhs
================================================
Sourced from https://wiki.haskell.org/Literate_programming.

And the definition of the following function
would totally screw up my program, so I'm not
definining it:

\begin{code}
main :: IO ()
main = print "just an example"
\end{code}

Seee?



================================================
FILE: harper-literate-haskell/tests/test_sources/mixed_format.lhs
================================================
Sourced from https://wiki.haskell.org/Literate_programming.

In Bird-style you have to leave a blnk before the code.

> fact :: Integer -> Integer
> fact 0 = 1
> fact n = n * fact (n-1)

And you have to leave a blnk line after the code as well.

And the definition of the following function
would totally screw up my program, so I'm not
definining it:

\begin{code}
main :: IO ()
main = print "just an example"
\end{code}

Seee?



================================================
FILE: harper-ls/README.md
================================================
# `harper-ls`

Documentation for `harper-ls` has moved to the main [website](https://writewithharper.com/docs/integrations/language-server).



================================================
FILE: harper-ls/Cargo.toml
================================================
[package]
name = "harper-ls"
version = "1.5.1"
edition = "2024"
description = "The language checker for developers."
license = "Apache-2.0"
readme = "README.md"
repository = "https://github.com/automattic/harper"

[dependencies]
harper-stats = { path = "../harper-stats", version = "1.0.0" }
harper-literate-haskell = { path = "../harper-literate-haskell", version = "1.0.0" }
harper-core = { path = "../harper-core", version = "1.0.0", features = ["concurrent"] }
harper-comments = { path = "../harper-comments", version = "1.0.0" }
harper-jjdescription = { path = "../harper-jjdescription", version = "1.0.0" }
harper-typst = { path = "../harper-typst", version = "1.0.0" }
harper-html = { path = "../harper-html", version = "1.0.0" }
harper-python = { path = "../harper-python", version = "1.0.0" }
harper-asciidoc = { path = "../harper-asciidoc", version = "1.0.0" }
tower-lsp-server = "0.22.1"
tokio = { version = "1.49.0", default-features = false, features = ["fs", "io-std", "io-util", "macros", "net", "rt-multi-thread", "sync"] }
clap = { version = "4.5.54", default-features = false, features = ["derive", "std"] }
dirs = "6.0.0"
anyhow = "1.0.100"
serde_json = "1.0.149"
itertools = "0.14.0"
tracing = { version = "0.1.44", default-features = false, features = ["std"] }
tracing-subscriber = { version = "0.3.22", default-features = false, features = ["fmt", "std"] }
resolve-path = "0.1.0"
open = "5.3.3"
futures = "0.3.31"
serde = { version = "1.0.228", features = ["derive"] }
globset = "0.4.18"
harper-ink = { version = "1.0.0", path = "../harper-ink" }

[features]
default = []
thesaurus = ["harper-core/thesaurus"]



================================================
FILE: harper-ls/src/backend.rs
================================================
use std::collections::HashMap;
use std::fs::OpenOptions;
use std::io::{BufWriter, Write};
use std::path::PathBuf;
use std::sync::Arc;

use crate::config::Config;
use crate::dictionary_io::{load_dict, save_dict};
use crate::document_state::DocumentState;
use crate::git_commit_parser::GitCommitParser;
use crate::ignored_lints_io::{load_ignored_lints, save_ignored_lints};
use crate::io_utils::fileify_path;
use anyhow::{Context, Result, anyhow};
use futures::future::join;
use harper_asciidoc::AsciidocParser;
use harper_comments::CommentParser;
use harper_core::linting::{LintGroup, LintGroupConfig};
use harper_core::parsers::{
    CollapseIdentifiers, IsolateEnglish, Markdown, OrgMode, Parser, PlainEnglish,
};
use harper_core::spell::{Dictionary, FstDictionary, MergedDictionary, MutableDictionary};
use harper_core::{Dialect, DictWordMetadata, Document, IgnoredLints};
use harper_html::HtmlParser;
use harper_ink::InkParser;
use harper_jjdescription::JJDescriptionParser;
use harper_literate_haskell::LiterateHaskellParser;
use harper_python::PythonParser;
use harper_stats::{Record, Stats};
use harper_typst::Typst;
use serde_json::{Value, json};
use tokio::sync::{Mutex, RwLock};
use tower_lsp_server::jsonrpc::Result as JsonResult;
use tower_lsp_server::lsp_types::notification::PublishDiagnostics;
use tower_lsp_server::lsp_types::{
    CodeActionOrCommand, CodeActionParams, CodeActionProviderCapability, CodeActionResponse,
    ConfigurationItem, Diagnostic, DidChangeConfigurationParams, DidChangeTextDocumentParams,
    DidChangeWatchedFilesParams, DidChangeWatchedFilesRegistrationOptions,
    DidCloseTextDocumentParams, DidOpenTextDocumentParams, ExecuteCommandOptions,
    ExecuteCommandParams, FileChangeType, FileSystemWatcher, GlobPattern, InitializeParams,
    InitializeResult, InitializedParams, MessageType, PublishDiagnosticsParams, Range,
    Registration, ServerCapabilities, ServerInfo, TextDocumentSyncCapability, TextDocumentSyncKind,
    TextDocumentSyncOptions, TextDocumentSyncSaveOptions, Uri, WatchKind,
};
use tower_lsp_server::{Client, LanguageServer, UriExt};
use tracing::{error, info, warn};

/// Return harper-ls version
pub fn ls_version() -> &'static str {
    env!("CARGO_PKG_VERSION")
}

pub struct Backend {
    client: Client,
    root: RwLock<PathBuf>,
    config: RwLock<Config>,
    stats: RwLock<Stats>,
    doc_state: Mutex<HashMap<Uri, DocumentState>>,
}

impl Backend {
    pub fn new(client: Client, config: Config) -> Self {
        Self {
            client,
            root: RwLock::new(".".into()),
            stats: RwLock::new(Stats::new()),
            config: RwLock::new(config),
            doc_state: Mutex::new(HashMap::new()),
        }
    }

    /// Load a specific file's dictionary
    async fn load_file_dictionary(&self, uri: &Uri) -> anyhow::Result<MutableDictionary> {
        // VS Code's unsaved documents have "untitled" scheme
        if uri
            .scheme()
            .is_some_and(|scheme| scheme.eq_lowercase("untitled"))
        {
            return Ok(MutableDictionary::new());
        }

        let path = self
            .get_file_dict_path(uri)
            .await
            .context("Unable to get the file path.")?;

        load_dict(path, self.config.read().await.dialect)
            .await
            .map_err(|err| info!("{err}"))
            .or(Ok(MutableDictionary::new()))
    }

    /// Compute the location of the ignored lint's store.
    async fn get_ignored_lints_path(&self, uri: &Uri) -> anyhow::Result<PathBuf> {
        let config = self.config.read().await;

        Ok(config.ignored_lints_path.join(fileify_path(uri)?))
    }

    async fn save_ignored_lints(&self, uri: &Uri, ignored_lints: &IgnoredLints) -> Result<()> {
        save_ignored_lints(
            self.get_ignored_lints_path(uri)
                .await
                .context("Unable to get ignored lints path.")?,
            ignored_lints,
        )
        .await
        .context("Unable to save ignored lints to path.")
    }

    async fn load_ignored_lints(&self, uri: &Uri) -> Result<IgnoredLints> {
        // VS Code's unsaved documents have "untitled" scheme
        if uri
            .scheme()
            .is_some_and(|scheme| scheme.eq_lowercase("untitled"))
        {
            return Ok(IgnoredLints::new());
        }

        Ok(load_ignored_lints(
            self.get_ignored_lints_path(uri)
                .await
                .context("Unable to get ignored lints path.")?,
        )
        .await
        .map_err(|err| info!("{err}"))
        .unwrap_or(IgnoredLints::new()))
    }

    /// Compute the location of the file's specific dictionary
    async fn get_file_dict_path(&self, uri: &Uri) -> anyhow::Result<PathBuf> {
        let config = self.config.read().await;

        Ok(config.file_dict_path.join(fileify_path(uri)?))
    }

    async fn save_file_dictionary(&self, uri: &Uri, dict: impl Dictionary) -> Result<()> {
        save_dict(
            self.get_file_dict_path(uri)
                .await
                .context("Unable to get the file path.")?,
            dict,
        )
        .await
        .context("Unable to save the dictionary to path.")
    }

    async fn load_user_dictionary(&self) -> MutableDictionary {
        let config = self.config.read().await;

        load_dict(&config.user_dict_path, self.config.read().await.dialect)
            .await
            .map_err(|err| info!("{err}"))
            .unwrap_or(MutableDictionary::new())
    }

    async fn save_user_dictionary(&self, dict: impl Dictionary) -> Result<()> {
        let config = self.config.read().await;

        save_dict(&config.user_dict_path, dict)
            .await
            .map_err(|err| anyhow!("Unable to save the dictionary to file: {err}"))
    }

    async fn load_workspace_dictionary(&self) -> MutableDictionary {
        let config = self.config.read().await;
        load_dict(
            &config.workspace_dict_path,
            self.config.read().await.dialect,
        )
        .await
        .map_err(|err| info!("{err}"))
        .unwrap_or(MutableDictionary::new())
    }

    async fn save_workspace_dictionary(&self, dict: impl Dictionary) -> Result<()> {
        let config = self.config.read().await;
        save_dict(&config.workspace_dict_path, dict)
            .await
            .map_err(|err| anyhow!("Unable to save the dictionary to file: {err}"))
    }

    async fn save_stats(&self) -> Result<()> {
        let (config, stats) = join(self.config.read(), self.stats.read()).await;

        if let Some(parent) = config.stats_path.parent() {
            tokio::fs::create_dir_all(parent).await?;
        }

        let mut writer = BufWriter::new(
            OpenOptions::new()
                .read(true)
                .append(true)
                .create(true)
                .open(&config.stats_path)?,
        );
        stats.write(&mut writer)?;
        writer.flush()?;

        Ok(())
    }

    async fn generate_global_dictionary(&self) -> Result<MergedDictionary> {
        let mut dict = MergedDictionary::new();
        dict.add_dictionary(FstDictionary::curated());
        let user_dict = self.load_user_dictionary().await;
        dict.add_dictionary(Arc::new(user_dict));
        let ws_dict = self.load_workspace_dictionary().await;
        dict.add_dictionary(Arc::new(ws_dict));
        Ok(dict)
    }

    async fn generate_file_dictionary(&self, uri: &Uri) -> Result<MergedDictionary> {
        let (global_dictionary, file_dictionary) = tokio::join!(
            self.generate_global_dictionary(),
            self.load_file_dictionary(uri)
        );

        let mut global_dictionary =
            global_dictionary.context("Unable to load the user dictionary.")?;
        global_dictionary.add_dictionary(Arc::new(
            file_dictionary.context("Unable to load the file dictionary.")?,
        ));

        Ok(global_dictionary)
    }

    async fn update_document_from_file(&self, uri: &Uri, language_id: Option<&str>) -> Result<()> {
        let content = tokio::fs::read_to_string(
            uri.to_file_path()
                .ok_or_else(|| anyhow!("Unable to convert URL to file path."))?,
        )
        .await
        .with_context(|| format!("Unable to read from file {uri:?}"))?;

        self.update_document(uri, &content, language_id).await
    }

    async fn update_document(
        &self,
        uri: &Uri,
        text: &str,
        language_id: Option<&str>,
    ) -> Result<()> {
        self.pull_config().await;

        // Copy necessary configuration to avoid holding lock.
        let (
            lint_config,
            markdown_options,
            isolate_english,
            dialect,
            max_file_length,
            exclude_patterns,
        ) = {
            let config = self.config.read().await;
            (
                config.lint_config.clone(),
                config.markdown_options,
                config.isolate_english,
                config.dialect,
                config.max_file_length,
                config.exclude_patterns.clone(),
            )
        };

        let mut doc_lock = self.doc_state.lock().await;

        if !exclude_patterns.is_empty()
            && exclude_patterns.is_match(
                uri.to_file_path()
                    .ok_or_else(|| anyhow!("Unable to convert URI to file path."))?,
            )
        {
            doc_lock.remove(uri);
            return Ok(());
        }

        let ignored_lints = self.load_ignored_lints(uri).await.unwrap_or_default();

        let dict = Arc::new(
            self.generate_file_dictionary(uri)
                .await
                .context("Unable to generate the file dictionary.")?,
        );

        let doc_state = doc_lock.entry(uri.clone()).or_insert_with(|| {
            info!("Constructing new LintGroup for new document.");

            DocumentState {
                ignored_lints,
                linter: LintGroup::new_curated(dict.clone(), dialect)
                    .with_lint_config(lint_config.clone()),
                language_id: language_id.map(|v| v.to_string()),
                dict: dict.clone(),
                uri: uri.clone(),
                ..Default::default()
            }
        });

        if doc_state.dict != dict {
            doc_state.dict = dict.clone();
            info!("Constructing new linter because of modified dictionary.");
            doc_state.linter =
                LintGroup::new_curated(dict.clone(), dialect).with_lint_config(lint_config.clone());
        }

        let Some(language_id) = &doc_state.language_id else {
            doc_lock.remove(uri);
            return Ok(());
        };

        async fn use_ident_dict<'a>(
            backend: &'a Backend,
            new_dict: Arc<MutableDictionary>,
            parser: impl Parser + 'static,
            uri: &'a Uri,
            doc_state: &'a mut DocumentState,
            lint_config: &LintGroupConfig,
            dialect: Dialect,
        ) -> Result<Box<dyn Parser>> {
            if doc_state.ident_dict != new_dict {
                info!("Constructing new linter because of modified ident dictionary.");
                doc_state.ident_dict = new_dict.clone();

                let mut merged = backend.generate_file_dictionary(uri).await?;
                merged.add_dictionary(new_dict);
                let merged = Arc::new(merged);

                doc_state.linter = LintGroup::new_curated(merged.clone(), dialect)
                    .with_lint_config(lint_config.clone());
                doc_state.dict = merged.clone();
            }

            Ok(Box::new(CollapseIdentifiers::new(
                Box::new(parser),
                Box::new(doc_state.dict.clone()),
            )))
        }

        let source: Vec<char> = text.chars().collect();
        let ts_parser = CommentParser::new_from_language_id(language_id, markdown_options);
        let parser: Option<Box<dyn Parser>> = match language_id.as_str() {
            _ if ts_parser.is_some() => {
                let ts_parser = ts_parser.unwrap();

                if let Some(new_dict) = ts_parser.create_ident_dict(&Arc::new(source)) {
                    Some(
                        use_ident_dict(
                            self,
                            Arc::new(new_dict),
                            ts_parser,
                            uri,
                            doc_state,
                            &lint_config,
                            dialect,
                        )
                        .await?,
                    )
                } else {
                    Some(Box::new(ts_parser))
                }
            }
            "git-commit" | "gitcommit" | "octo" => {
                Some(Box::new(GitCommitParser::new_markdown(markdown_options)))
            }
            "html" => Some(Box::new(HtmlParser::default())),
            "asciidoc" => Some(Box::new(AsciidocParser::default())),
            "ink" => Some(Box::new(InkParser::default())),
            "jj-commit" | "jjdescription" => {
                Some(Box::new(JJDescriptionParser::new(markdown_options)))
            }
            "lhaskell" | "literate haskell" => {
                let parser = LiterateHaskellParser::new_markdown(markdown_options);

                if let Some(new_dict) =
                    parser.create_ident_dict(&Arc::new(source), markdown_options)
                {
                    Some(
                        use_ident_dict(
                            self,
                            Arc::new(new_dict),
                            parser,
                            uri,
                            doc_state,
                            &lint_config,
                            dialect,
                        )
                        .await?,
                    )
                } else {
                    Some(Box::new(parser))
                }
            }
            "mail" => Some(Box::new(PlainEnglish)),
            "markdown" => Some(Box::new(Markdown::new(markdown_options))),
            "org" => Some(Box::new(OrgMode)),
            "plaintext" | "text" => Some(Box::new(PlainEnglish)),
            "python" => Some(Box::new(PythonParser::default())),
            "typst" => Some(Box::new(Typst)),
            _ => None,
        };

        match parser {
            None => {
                doc_lock.remove(uri);
            }
            Some(mut parser) => {
                if isolate_english {
                    parser = Box::new(IsolateEnglish::new(parser, doc_state.dict.clone()));
                }

                // Don't lint on documents larger than the configured maximum length.
                if text.len() <= max_file_length {
                    doc_state.document = Document::new(text, &parser, &doc_state.dict);
                } else {
                    // Ensures that existing lints are cleared when we stop linting the file.
                    // Otherwise, prior lints will remain, and they will quickly fall out of sync
                    // with the document when it is edited.
                    doc_state.document = Document::default();
                }
            }
        }

        Ok(())
    }

    async fn generate_code_actions(
        &self,
        uri: &Uri,
        range: Range,
    ) -> JsonResult<Vec<CodeActionOrCommand>> {
        let (config, mut doc_states) = tokio::join!(self.config.read(), self.doc_state.lock());
        let Some(doc_state) = doc_states.get_mut(uri) else {
            return Ok(Vec::new());
        };

        Ok(doc_state.generate_code_actions(range, &config.code_action_config))
    }

    async fn generate_diagnostics(&self, uri: &Uri) -> Vec<Diagnostic> {
        // Copy necessary configuration to avoid holding lock.
        let diagnostic_severity = {
            let config = self.config.read().await;
            config.diagnostic_severity
        };

        let mut doc_states = self.doc_state.lock().await;
        let Some(doc_state) = doc_states.get_mut(uri) else {
            return Vec::new();
        };

        doc_state.generate_diagnostics(diagnostic_severity)
    }

    async fn publish_diagnostics(&self, uri: &Uri) {
        let diagnostics = self.generate_diagnostics(uri).await;

        let result = PublishDiagnosticsParams {
            uri: uri.clone(),
            diagnostics,
            version: None,
        };

        self.client
            .send_notification::<PublishDiagnostics>(result)
            .await;
    }

    /// Update the configuration of the server and publish document updates that
    /// match it.
    async fn update_config_from_obj(&self, json_obj: Value) {
        if let Ok(new_config) = Config::from_lsp_config(&self.root.read().await, json_obj)
            .map_err(|err| error!("{err}"))
        {
            let mut config = self.config.write().await;
            *config = new_config;
        }
    }

    async fn pull_config(&self) {
        let mut new_config = self
            .client
            .configuration(vec![ConfigurationItem {
                scope_uri: None,
                section: None,
            }])
            .await
            .unwrap_or(vec![json!({ "harper-ls": {} })]);

        if let Some(first) = new_config.pop() {
            self.update_config_from_obj(first).await;
        }
    }
}

impl LanguageServer for Backend {
    async fn initialize(&self, params: InitializeParams) -> JsonResult<InitializeResult> {
        if let Some(root) = params
            .workspace_folders
            .as_ref()
            // We take the first workspace folder
            .and_then(|v| v.first())
            .map(|f| &f.uri)
            // Or failing that, the root_uri (which is deprecated in favour of workspace_folders)
            .or(
                #[allow(deprecated)]
                params.root_uri.as_ref(),
            )
            .and_then(|u| u.to_file_path().map(PathBuf::from))
            // Or failing that, the root_path (which is deprecated in favour of root_uri)
            .or(
                #[allow(deprecated)]
                params.root_path.as_deref().map(PathBuf::from),
            )
        {
            // Save the workspace root away for use during the configuration step
            *self.root.write().await = root;
        }

        Ok(InitializeResult {
            server_info: Some(ServerInfo {
                name: "harper-ls".to_owned(),
                version: Some(ls_version().to_owned()),
            }),
            capabilities: ServerCapabilities {
                code_action_provider: Some(CodeActionProviderCapability::Simple(true)),
                execute_command_provider: Some(ExecuteCommandOptions {
                    commands: vec![
                        "HarperRecordLint".to_owned(),
                        "HarperAddToUserDict".to_owned(),
                        "HarperAddToWSDict".to_owned(),
                        "HarperAddToFileDict".to_owned(),
                        "HarperOpen".to_owned(),
                        "HarperIgnoreLint".to_owned(),
                    ],
                    ..Default::default()
                }),
                text_document_sync: Some(TextDocumentSyncCapability::Options(
                    TextDocumentSyncOptions {
                        open_close: Some(true),
                        change: Some(TextDocumentSyncKind::FULL),
                        will_save: None,
                        will_save_wait_until: None,
                        save: Some(TextDocumentSyncSaveOptions::Supported(true)),
                    },
                )),
                ..Default::default()
            },
        })
    }

    async fn initialized(&self, _: InitializedParams) {
        self.client
            .log_message(MessageType::INFO, "Server initialized!")
            .await;

        self.pull_config().await;

        let did_change_watched_files = Registration {
            id: "workspace/didChangeWatchedFiles".to_owned(),
            method: "workspace/didChangeWatchedFiles".to_owned(),
            register_options: Some(
                serde_json::to_value(DidChangeWatchedFilesRegistrationOptions {
                    watchers: vec![FileSystemWatcher {
                        glob_pattern: GlobPattern::String("**/*".to_owned()),
                        kind: Some(WatchKind::Delete),
                    }],
                })
                .unwrap(),
            ),
        };
        if let Err(err) = self
            .client
            .register_capability(vec![did_change_watched_files])
            .await
        {
            warn!("Unable to register watch file capability: {}", err);
        }
    }

    async fn did_open(&self, params: DidOpenTextDocumentParams) {
        self.update_document(
            &params.text_document.uri,
            &params.text_document.text,
            Some(&params.text_document.language_id),
        )
        .await
        .map_err(|err| error!("{err}"))
        .err();

        self.publish_diagnostics(&params.text_document.uri).await;
    }

    async fn did_change(&self, params: DidChangeTextDocumentParams) {
        let Some(last) = params.content_changes.last() else {
            return;
        };

        if let Err(err) = self
            .update_document(&params.text_document.uri, &last.text, None)
            .await
        {
            error!("{err}")
        }

        self.publish_diagnostics(&params.text_document.uri).await;
    }

    async fn did_close(&self, _params: DidCloseTextDocumentParams) {
        let uri = _params.text_document.uri;
        let mut doc_lock = self.doc_state.lock().await;
        doc_lock.remove(&uri);

        self.client
            .send_notification::<PublishDiagnostics>(PublishDiagnosticsParams {
                uri: uri.clone(),
                diagnostics: vec![],
                version: None,
            })
            .await;
    }

    async fn did_change_watched_files(&self, params: DidChangeWatchedFilesParams) {
        let mut doc_lock = self.doc_state.lock().await;
        let mut uris_to_clear = Vec::new();

        for change in &params.changes {
            if change.typ != FileChangeType::DELETED {
                continue;
            }

            doc_lock.retain(|uri, _| {
                // `change.uri` could be a directory so use `starts_with` instead of `==`.
                let to_remove = uri.as_str().starts_with(change.uri.as_str());

                if to_remove {
                    uris_to_clear.push(uri.clone());
                }

                !to_remove
            });
        }

        for uri in &uris_to_clear {
            self.client
                .send_notification::<PublishDiagnostics>(PublishDiagnosticsParams {
                    uri: uri.clone(),
                    diagnostics: vec![],
                    version: None,
                })
                .await;
        }
    }

    async fn execute_command(&self, params: ExecuteCommandParams) -> JsonResult<Option<Value>> {
        let mut string_args = params
            .arguments
            .iter()
            .map(|v| serde_json::from_value::<String>(v.clone()).unwrap());

        let Some(first) = string_args.next() else {
            return Ok(None);
        };

        info!("Received command: \"{}\"", params.command.as_str());

        match params.command.as_str() {
            "HarperRecordLint" => {
                let Ok(kind) = serde_json::from_str(&first) else {
                    error!("Unable to deserialize RecordKind.");
                    return Ok(None);
                };

                let record = Record::now(kind);

                let mut stats = self.stats.write().await;
                stats.records.push(record);
            }
            "HarperAddToUserDict" => {
                let word = &first.chars().collect::<Vec<_>>();

                let Some(second) = string_args.next() else {
                    return Ok(None);
                };

                let file_uri = second.parse().unwrap();

                let mut dict = self.load_user_dictionary().await;
                dict.append_word(word, DictWordMetadata::default());
                self.save_user_dictionary(dict)
                    .await
                    .map_err(|err| error!("{err}"))
                    .err();
                self.update_document_from_file(&file_uri, None)
                    .await
                    .map_err(|err| error!("{err}"))
                    .err();
                self.publish_diagnostics(&file_uri).await;
            }
            "HarperAddToWSDict" => {
                let word = &first.chars().collect::<Vec<_>>();

                let Some(second) = string_args.next() else {
                    return Ok(None);
                };

                let file_uri = second.parse().unwrap();

                let mut dict = self.load_workspace_dictionary().await;
                dict.append_word(word, DictWordMetadata::default());
                self.save_workspace_dictionary(dict)
                    .await
                    .map_err(|err| error!("{err}"))
                    .err();
                self.update_document_from_file(&file_uri, None)
                    .await
                    .map_err(|err| error!("{err}"))
                    .err();
                self.publish_diagnostics(&file_uri).await;
            }
            "HarperAddToFileDict" => {
                let word = &first.chars().collect::<Vec<_>>();

                let Some(second) = string_args.next() else {
                    return Ok(None);
                };

                let file_uri = second.parse().unwrap();

                let mut dict = match self
                    .load_file_dictionary(&file_uri)
                    .await
                    .map_err(|err| error!("{err}"))
                {
                    Ok(dict) => dict,
                    Err(_) => {
                        return Ok(None);
                    }
                };
                dict.append_word(word, DictWordMetadata::default());

                self.save_file_dictionary(&file_uri, dict)
                    .await
                    .map_err(|err| error!("{err}"))
                    .err();
                self.update_document_from_file(&file_uri, None)
                    .await
                    .map_err(|err| error!("{err}"))
                    .err();
                self.publish_diagnostics(&file_uri).await;
            }
            "HarperOpen" => match open::that(&first) {
                Ok(()) => {
                    let message = format!(r#"Opened "{first}""#);

                    self.client.log_message(MessageType::INFO, &message).await;

                    info!("{}", message);
                }
                Err(err) => {
                    self.client
                        .log_message(MessageType::ERROR, "Unable to open URL")
                        .await;
                    error!("Unable to open URL: {}", err);
                }
            },
            "HarperIgnoreLint" => {
                let Ok(uri) = first.parse() else {
                    error!("Unable to parse URL from command: {first}");
                    return Ok(None);
                };

                let Some(second) = params.arguments.into_iter().nth(1) else {
                    error!("Not enough arguments to HarperIgnoreLint");
                    return Ok(None);
                };

                let Ok(lint) = serde_json::from_value(second) else {
                    error!("Unable to parse lint.");
                    return Ok(None);
                };

                let mut doc_lock = self.doc_state.lock().await;
                let Some(doc_state) = doc_lock.get_mut(&uri) else {
                    error!("Requested document has not been loaded.");
                    return Ok(None);
                };

                doc_state.ignore_lint(&lint);
                if let Err(_err) = self
                    .save_ignored_lints(&uri, &doc_state.ignored_lints)
                    .await
                {
                    error!("Unable to save ignored lints.");
                    return Ok(None);
                }

                drop(doc_lock);

                self.publish_diagnostics(&uri).await;
            }
            _ => (),
        }

        Ok(None)
    }

    async fn did_change_configuration(&self, params: DidChangeConfigurationParams) {
        self.update_config_from_obj(params.settings).await;

        let uris: Vec<Uri> = {
            let mut doc_lock = self.doc_state.lock().await;
            let config_lock = self.config.read().await;

            for doc in doc_lock.values_mut() {
                info!("Constructing new LintGroup for updated configuration.");
                doc.linter = LintGroup::new_curated(doc.dict.clone(), config_lock.dialect)
                    .with_lint_config(config_lock.lint_config.clone());
            }

            doc_lock.keys().cloned().collect()
        };

        for uri in uris {
            self.update_document_from_file(&uri, None)
                .await
                .map_err(|err| error!("{err}"))
                .err();
            self.publish_diagnostics(&uri).await;
        }
    }

    async fn code_action(
        &self,
        params: CodeActionParams,
    ) -> JsonResult<Option<CodeActionResponse>> {
        let actions = self
            .generate_code_actions(&params.text_document.uri, params.range)
            .await?;

        Ok(Some(actions))
    }

    async fn shutdown(&self) -> JsonResult<()> {
        let doc_states = self.doc_state.lock().await;

        // Clears the diagnostics for open buffers.
        for uri in doc_states.keys() {
            let result = PublishDiagnosticsParams {
                uri: uri.clone(),
                diagnostics: vec![],
                version: None,
            };

            self.client
                .send_notification::<PublishDiagnostics>(result)
                .await;
        }

        if self.save_stats().await.is_err() {
            error!("Unable to save stats.")
        }

        Ok(())
    }
}



================================================
FILE: harper-ls/src/config.rs
================================================
use std::path::{Path, PathBuf};

use anyhow::{Result, bail};
use dirs::{config_dir, data_local_dir};
use globset::{Glob, GlobSet};
use harper_core::{Dialect, linting::LintGroupConfig, parsers::MarkdownOptions};
use resolve_path::PathResolveExt;
use serde::{Deserialize, Serialize};
use serde_json::Value;

#[derive(Debug, Serialize, Deserialize, Clone, Copy)]
#[serde(rename_all = "camelCase")]
pub enum DiagnosticSeverity {
    Error,
    Warning,
    Information,
    Hint,
}

impl DiagnosticSeverity {
    /// Converts `self` to the equivalent LSP type.
    pub fn to_lsp(self) -> tower_lsp_server::lsp_types::DiagnosticSeverity {
        match self {
            DiagnosticSeverity::Error => tower_lsp_server::lsp_types::DiagnosticSeverity::ERROR,
            DiagnosticSeverity::Warning => tower_lsp_server::lsp_types::DiagnosticSeverity::WARNING,
            DiagnosticSeverity::Information => {
                tower_lsp_server::lsp_types::DiagnosticSeverity::INFORMATION
            }
            DiagnosticSeverity::Hint => tower_lsp_server::lsp_types::DiagnosticSeverity::HINT,
        }
    }
}

/// Configuration for how code actions are displayed.
/// Originally motivated by [#89](https://github.com/automattic/harper/issues/89).
#[derive(Debug, Clone, Default)]
pub struct CodeActionConfig {
    /// Instructs `harper-ls` to place unstable code actions last.
    /// In this case, "unstable" refers to their existence and action.
    ///
    /// For example, we always want to allow users to add "misspelled" elements
    /// to dictionary, regardless of the spelling suggestions.
    pub force_stable: bool,
}

impl CodeActionConfig {
    pub fn from_lsp_config(value: Value) -> Result<Self> {
        let mut base = CodeActionConfig::default();

        let Value::Object(value) = value else {
            bail!("The code action configuration must be an object.");
        };

        if let Some(force_stable_val) = value.get("ForceStable") {
            let Value::Bool(force_stable) = force_stable_val else {
                bail!("ForceStable must be a boolean value.");
            };
            base.force_stable = *force_stable;
        };

        Ok(base)
    }
}

#[derive(Debug, Clone)]
pub struct Config {
    pub user_dict_path: PathBuf,
    pub file_dict_path: PathBuf,
    pub workspace_dict_path: PathBuf,
    pub ignored_lints_path: PathBuf,
    pub stats_path: PathBuf,
    pub lint_config: LintGroupConfig,
    pub diagnostic_severity: DiagnosticSeverity,
    pub code_action_config: CodeActionConfig,
    pub isolate_english: bool,
    pub markdown_options: MarkdownOptions,
    pub dialect: Dialect,
    /// Maximum length (in bytes) a file can have before it's skipped.
    /// Above this limit, the file will not be linted.
    pub max_file_length: usize,
    pub exclude_patterns: GlobSet,
}

impl Config {
    pub fn from_lsp_config(workspace_root: &Path, value: Value) -> Result<Self> {
        let mut base = Config::default();

        let workspace_root = workspace_root.canonicalize()?;
        let workspace_root = workspace_root.as_path();

        let Value::Object(value) = value else {
            bail!("Settings must be an object.");
        };

        let Some(Value::Object(value)) = value.get("harper-ls") else {
            bail!("Settings must contain a \"harper-ls\" key.");
        };

        if let Some(v) = value.get("userDictPath") {
            if !v.is_string() {
                bail!("userDict path must be a string.");
            }

            let path = v.as_str().unwrap();
            if !path.is_empty() {
                base.user_dict_path = path.try_resolve_in(workspace_root)?.to_path_buf();
            }
        }

        if let Some(v) = value.get("fileDictPath") {
            if !v.is_string() {
                bail!("fileDict path must be a string.");
            }

            let path = v.as_str().unwrap();
            if !path.is_empty() {
                base.file_dict_path = path.try_resolve_in(workspace_root)?.to_path_buf();
            }
        }

        if let Some(v) = value.get("workspaceDictPath") {
            if !v.is_string() {
                bail!("workspaceDict path must be a string.");
            }
            let path = v.as_str().unwrap();
            if !path.is_empty() {
                base.workspace_dict_path = path.try_resolve_in(workspace_root)?.to_path_buf();
            }
        } else {
            // Resolve the default path in the project root
            base.workspace_dict_path = base
                .workspace_dict_path
                .try_resolve_in(workspace_root)?
                .to_path_buf();
        }

        if let Some(v) = value.get("ignoredLintsPath") {
            if !v.is_string() {
                bail!("ignoredLintsPath path must be a string.");
            }

            let path = v.as_str().unwrap();
            if !path.is_empty() {
                base.ignored_lints_path = path.try_resolve_in(workspace_root)?.to_path_buf();
            }
        }

        if let Some(v) = value.get("statsPath") {
            if let Value::String(path) = v {
                base.file_dict_path = path.try_resolve_in(workspace_root)?.to_path_buf();
            } else {
                bail!("fileDict path must be a string.");
            }
        }

        if let Some(v) = value.get("linters") {
            base.lint_config = serde_json::from_value(v.clone())?;
        }

        if let Some(v) = value.get("diagnosticSeverity") {
            base.diagnostic_severity = serde_json::from_value(v.clone())?;
        }

        if let Some(v) = value.get("dialect") {
            base.dialect = serde_json::from_value(v.clone())?;
        }

        if let Some(v) = value.get("codeActions") {
            base.code_action_config = CodeActionConfig::from_lsp_config(v.clone())?;
        }

        if let Some(v) = value.get("isolateEnglish") {
            if let Value::Bool(v) = v {
                base.isolate_english = *v;
            } else {
                bail!("isolateEnglish path must be a boolean.");
            }
        }

        if let Some(v) = value.get("maxFileLength") {
            base.max_file_length = serde_json::from_value(v.clone())?;
        }

        if let Some(v) = value.get("markdown")
            && let Some(v) = v.get("IgnoreLinkTitle")
        {
            base.markdown_options.ignore_link_title = serde_json::from_value(v.clone())?;
        }

        if let Some(v) = value.get("excludePatterns") {
            let Some(a) = v.as_array() else {
                bail!("excludePatterns must be an array.");
            };

            let patterns: Vec<Value> = a.to_vec();
            if !patterns.is_empty() {
                let mut builder = GlobSet::builder();

                for pattern in patterns {
                    builder.add(Glob::new(pattern.as_str().unwrap())?);
                }

                base.exclude_patterns = builder.build()?;
            }
        }

        Ok(base)
    }
}

impl Default for Config {
    fn default() -> Self {
        Self {
            user_dict_path: config_dir().unwrap().join("harper-ls/dictionary.txt"),
            file_dict_path: data_local_dir()
                .unwrap()
                .join("harper-ls/file_dictionaries/"),
            workspace_dict_path: ".harper-dictionary.txt".into(),
            ignored_lints_path: data_local_dir().unwrap().join("harper-ls/ignored_lints/"),
            stats_path: data_local_dir().unwrap().join("harper-ls/stats.txt"),
            lint_config: LintGroupConfig::default(),
            diagnostic_severity: DiagnosticSeverity::Hint,
            code_action_config: CodeActionConfig::default(),
            isolate_english: false,
            markdown_options: MarkdownOptions::default(),
            dialect: Dialect::American,
            max_file_length: 120_000,
            exclude_patterns: GlobSet::empty(),
        }
    }
}



================================================
FILE: harper-ls/src/diagnostics.rs
================================================
use std::collections::HashMap;

use harper_core::linting::{Lint, Suggestion};
use harper_core::{CharStringExt, Document};
use harper_stats::RecordKind;
use serde_json::Value;
use tower_lsp_server::lsp_types::{
    CodeAction, CodeActionKind, CodeActionOrCommand, Command, Diagnostic, NumberOrString, TextEdit,
    Uri, WorkspaceEdit,
};

use crate::config::{CodeActionConfig, DiagnosticSeverity};
use crate::pos_conv::span_to_range;

pub fn lints_to_diagnostics<'a>(
    source: &[char],
    lints: impl IntoIterator<Item = (&'a str, &'a [Lint])>,
    severity: DiagnosticSeverity,
) -> Vec<Diagnostic> {
    lints
        .into_iter()
        .flat_map(|(origin_tag, lints)| {
            lints
                .iter()
                .map(|lint| lint_to_diagnostic(lint, source, origin_tag, severity))
        })
        .collect()
}

pub fn lint_to_code_actions<'a>(
    lint: &'a Lint,
    uri: &'a Uri,
    document: &Document,
    config: &CodeActionConfig,
) -> Vec<CodeActionOrCommand> {
    let mut results = Vec::new();
    let source = document.get_source();

    results.extend(
        lint.suggestions
            .iter()
            .flat_map(|suggestion| {
                let range = span_to_range(source, lint.span);

                let replace_string = match suggestion {
                    Suggestion::ReplaceWith(with) => with.iter().collect(),
                    Suggestion::Remove => "".to_string(),
                    Suggestion::InsertAfter(with) => format!(
                        "{}{}",
                        lint.span.get_content_string(source),
                        with.to_string()
                    ),
                };

                Some(CodeAction {
                    title: suggestion.to_string(),
                    kind: Some(CodeActionKind::QUICKFIX),
                    diagnostics: None,
                    edit: Some(WorkspaceEdit {
                        changes: Some(HashMap::from([(
                            uri.clone(),
                            vec![TextEdit {
                                range,
                                new_text: replace_string,
                            }],
                        )])),
                        document_changes: None,
                        change_annotations: None,
                    }),
                    command: Some(Command {
                        title: "Record lint statistic".to_owned(),
                        command: "HarperRecordLint".to_owned(),
                        arguments: Some(vec![Value::String(
                            serde_json::to_string(&RecordKind::from_lint(lint, document)).unwrap(),
                        )]),
                    }),
                    is_preferred: None,
                    disabled: None,
                    data: None,
                })
            })
            .map(CodeActionOrCommand::CodeAction),
    );

    results.push(CodeActionOrCommand::Command(Command {
        title: "Ignore Harper error.".to_owned(),
        command: "HarperIgnoreLint".to_owned(),
        arguments: Some(vec![
            serde_json::Value::String(uri.to_string()),
            serde_json::to_value(lint).unwrap(),
        ]),
    }));

    if lint.lint_kind.is_spelling() {
        let orig = lint.span.get_content_string(source);

        results.push(CodeActionOrCommand::Command(Command::new(
            format!("Add \"{orig}\" to the user dictionary."),
            "HarperAddToUserDict".to_string(),
            Some(vec![orig.clone().into(), uri.to_string().into()]),
        )));

        results.push(CodeActionOrCommand::Command(Command::new(
            format!("Add \"{orig}\" to the workspace dictionary."),
            "HarperAddToWSDict".to_string(),
            Some(vec![orig.clone().into(), uri.to_string().into()]),
        )));

        results.push(CodeActionOrCommand::Command(Command::new(
            format!("Add \"{orig}\" to the file dictionary."),
            "HarperAddToFileDict".to_string(),
            Some(vec![orig.into(), uri.to_string().into()]),
        )));
    }

    if config.force_stable {
        results.reverse();
    }

    results
}

fn lint_to_diagnostic(
    lint: &Lint,
    source: &[char],
    origin_tag: &str,
    severity: DiagnosticSeverity,
) -> Diagnostic {
    let range = span_to_range(source, lint.span);

    Diagnostic {
        range,
        severity: Some(severity.to_lsp()),
        code_description: None,
        source: Some("Harper".to_owned()),
        code: Some(NumberOrString::String(origin_tag.to_string())),
        message: lint.message.clone(),
        related_information: None,
        tags: None,
        data: None,
    }
}



================================================
FILE: harper-ls/src/dictionary_io.rs
================================================
use harper_core::DialectFlags;
use itertools::Itertools;
use std::path::Path;

use harper_core::spell::{Dictionary, MutableDictionary};
use harper_core::{Dialect, DictWordMetadata};
use tokio::fs::{self, File};
use tokio::io::{AsyncRead, AsyncReadExt, AsyncWrite, AsyncWriteExt, BufReader, BufWriter, Result};

/// Save the contents of a dictionary to a file.
/// Ensures that the path to the destination exists.
pub async fn save_dict(path: impl AsRef<Path>, dict: impl Dictionary) -> Result<()> {
    if let Some(parent) = path.as_ref().parent() {
        fs::create_dir_all(parent).await?;
    }

    let file = File::create(path.as_ref()).await?;
    let mut write = BufWriter::new(file);

    write_word_list(dict, &mut write).await?;
    write.flush().await?;

    Ok(())
}

/// Write a dictionary somewhere.
async fn write_word_list(dict: impl Dictionary, mut w: impl AsyncWrite + Unpin) -> Result<()> {
    let mut cur_str = String::new();

    for word in dict.words_iter().sorted() {
        cur_str.clear();
        cur_str.extend(word);

        w.write_all(cur_str.as_bytes()).await?;
        w.write_all(b"\n").await?;
    }

    Ok(())
}

/// Load a dictionary from a file on disk.
pub async fn load_dict(path: impl AsRef<Path>, dialect: Dialect) -> Result<MutableDictionary> {
    let file = File::open(path.as_ref()).await?;
    let read = BufReader::new(file);

    dict_from_word_list(read, dialect).await
}

/// Load a dictionary from a list of words.
/// It could definitely be optimized to use less memory.
/// Right now it isn't an issue.
async fn dict_from_word_list(
    mut r: impl AsyncRead + Unpin,
    dialect: Dialect,
) -> Result<MutableDictionary> {
    let mut str = String::new();

    r.read_to_string(&mut str).await?;

    let mut dict = MutableDictionary::new();
    dict.extend_words(str.lines().map(|l| {
        (
            l.chars().collect::<Vec<char>>(),
            DictWordMetadata {
                dialects: DialectFlags::from_dialect(dialect),
                ..Default::default()
            },
        )
    }));

    Ok(dict)
}

#[cfg(test)]
mod tests {
    use super::*;
    use harper_core::spell::MutableDictionary;
    use std::io::Cursor;

    const TEST_UNSORTED_WORDS: [&str; 10] = [
        "peafowl",
        "housebroken",
        "blackjack",
        "Žižek",
        "BMX",
        "icebox",
        "stetting",
        "ツ",
        "ASCII",
        "link",
    ];
    const TEST_SORTED_WORDS: [&str; 10] = [
        "ASCII",
        "BMX",
        "blackjack",
        "housebroken",
        "icebox",
        "link",
        "peafowl",
        "stetting",
        "Žižek",
        "ツ",
    ];

    /// Creates an unsorted `MutableDictionary` for testing.
    fn get_test_unsorted_dict() -> MutableDictionary {
        let mut test_unsorted_dict = MutableDictionary::new();
        test_unsorted_dict.extend_words(
            TEST_UNSORTED_WORDS
                .map(|w| (w.chars().collect::<Vec<_>>(), DictWordMetadata::default())),
        );
        test_unsorted_dict
    }

    #[tokio::test]
    async fn writes_sorted_word_list() {
        let test_unsorted_dict = get_test_unsorted_dict();
        let mut test_writer = Cursor::new(Vec::new());
        write_word_list(test_unsorted_dict, &mut test_writer)
            .await
            .expect("writing to Vec<u8> should not fail. (Unless OOM?)");
        assert_eq!(
            // Append trailing newline to match write_word_list output format.
            TEST_SORTED_WORDS.join("\n") + "\n",
            String::from_utf8_lossy(&test_writer.into_inner())
        );
    }
}



================================================
FILE: harper-ls/src/document_state.rs
================================================
use crate::config::{CodeActionConfig, DiagnosticSeverity};
use crate::diagnostics::{lint_to_code_actions, lints_to_diagnostics};
use crate::pos_conv::range_to_span;
use harper_core::linting::{Lint, LintGroup, Linter};
use harper_core::spell::{MergedDictionary, MutableDictionary};
use harper_core::{Document, IgnoredLints, TokenKind, remove_overlaps_map};
use harper_core::{Lrc, Token};
use tower_lsp_server::lsp_types::{CodeActionOrCommand, Command, Diagnostic, Range, Uri};

pub struct DocumentState {
    pub document: Document,
    pub ident_dict: Lrc<MutableDictionary>,
    pub dict: Lrc<MergedDictionary>,
    pub linter: LintGroup,
    pub language_id: Option<String>,
    pub ignored_lints: IgnoredLints,
    pub uri: Uri,
}

impl DocumentState {
    pub fn ignore_lint(&mut self, lint: &Lint) {
        self.ignored_lints.ignore_lint(lint, &self.document);
    }

    pub fn generate_diagnostics(&mut self, severity: DiagnosticSeverity) -> Vec<Diagnostic> {
        let temp = self.linter.config.clone();
        self.linter.config.fill_with_curated();

        let mut lints = self.linter.organized_lints(&self.document);

        self.linter.config = temp;

        for value in lints.values_mut() {
            self.ignored_lints.remove_ignored(value, &self.document);
        }

        remove_overlaps_map(&mut lints);

        lints_to_diagnostics(
            self.document.get_full_content(),
            lints
                .iter()
                .map(|(origin_tag, lints)| (origin_tag.as_str(), lints.as_slice())),
            severity,
        )
    }

    /// Generate code actions results for a selected area.
    pub fn generate_code_actions(
        &mut self,
        range: Range,
        code_action_config: &CodeActionConfig,
    ) -> Vec<CodeActionOrCommand> {
        let temp = self.linter.config.clone();
        self.linter.config.fill_with_curated();

        let mut lints = self.linter.lint(&self.document);

        self.linter.config = temp;

        self.ignored_lints
            .remove_ignored(&mut lints, &self.document);

        lints.sort_by_key(|l| l.priority);

        let source_chars = self.document.get_full_content();

        // Find lints whole span overlaps with range
        let span = range_to_span(source_chars, range).with_len(1);

        let mut actions: Vec<CodeActionOrCommand> = lints
            .into_iter()
            .filter(|lint| lint.span.overlaps_with(span))
            .flat_map(|lint| {
                lint_to_code_actions(&lint, &self.uri, &self.document, code_action_config)
            })
            .collect();

        if let Some(Token {
            kind: TokenKind::Url,
            span,
            ..
        }) = self.document.get_token_at_char_index(span.start)
        {
            actions.push(CodeActionOrCommand::Command(Command::new(
                "Open URL".to_string(),
                "HarperOpen".to_string(),
                Some(vec![self.document.get_span_content_str(span).into()]),
            )))
        }

        actions
    }
}

impl Default for DocumentState {
    fn default() -> Self {
        Self {
            document: Default::default(),
            ident_dict: Default::default(),
            dict: Default::default(),
            linter: Default::default(),
            language_id: Default::default(),
            ignored_lints: Default::default(),
            uri: "https://example.net".parse().unwrap(),
        }
    }
}



================================================
FILE: harper-ls/src/git_commit_parser.rs
================================================
use harper_core::Lrc;
use harper_core::parsers::{Markdown, MarkdownOptions, Parser};

/// A Harper parser for Git commit files
#[derive(Clone)]
pub struct GitCommitParser {
    inner: Lrc<dyn Parser>,
}

impl GitCommitParser {
    pub fn new(parser: Lrc<dyn Parser>) -> Self {
        Self { inner: parser }
    }

    pub fn new_markdown(markdown_options: MarkdownOptions) -> Self {
        Self::new(Lrc::new(Markdown::new(markdown_options)))
    }
}

impl Parser for GitCommitParser {
    /// Admittedly a somewhat naive implementation.
    /// We're going to get _something_ to work, before we polish it off.
    fn parse(&self, source: &[char]) -> Vec<harper_core::Token> {
        // Locate the first `#`
        let end = source
            .iter()
            .position(|c| *c == '#')
            .unwrap_or(source.len());

        self.inner.parse(&source[0..end])
    }
}



================================================
FILE: harper-ls/src/ignored_lints_io.rs
================================================
use std::path::Path;

use anyhow::Result;
use harper_core::IgnoredLints;
use tokio::{
    fs::{self, File},
    io::{AsyncReadExt, AsyncWriteExt, BufReader, BufWriter},
};

/// Save the contents of a dictionary to a file.
/// Ensures that the path to the destination exists.
pub async fn save_ignored_lints(
    path: impl AsRef<Path>,
    ignored_lints: &IgnoredLints,
) -> Result<()> {
    if let Some(parent) = path.as_ref().parent() {
        fs::create_dir_all(parent).await?;
    }

    let file = File::create(path.as_ref()).await?;
    let mut write = BufWriter::new(file);

    let json = serde_json::to_string_pretty(ignored_lints)?;
    write.write_all(json.as_bytes()).await?;

    write.flush().await?;

    Ok(())
}

/// Load ignored lints from a file on disk.
pub async fn load_ignored_lints(path: impl AsRef<Path>) -> Result<IgnoredLints> {
    let file = File::open(path.as_ref()).await?;
    let mut read = BufReader::new(file);

    let mut buf = String::new();
    read.read_to_string(&mut buf).await?;

    Ok(serde_json::from_str(&buf)?)
}



================================================
FILE: harper-ls/src/io_utils.rs
================================================
use anyhow::anyhow;
use std::path::{Component, PathBuf};

use tower_lsp_server::{UriExt, lsp_types::Uri};

/// Rewrites a path to a filename using the same conventions as
/// [Neovim's undo-files](https://neovim.io/doc/user/options.html#'undodir').
pub fn fileify_path(uri: &Uri) -> anyhow::Result<PathBuf> {
    let mut rewritten = String::new();

    // We assume all URLs are local files and have a base.
    for seg in uri
        .to_file_path()
        .ok_or_else(|| anyhow!("Unable to convert URI to file path."))?
        .components()
    {
        if !matches!(seg, Component::RootDir) {
            rewritten.push_str(&seg.as_os_str().to_string_lossy());
            rewritten.push('%');
        }
    }

    Ok(rewritten.into())
}



================================================
FILE: harper-ls/src/main.rs
================================================
#![doc = include_str!("../README.md")]

use std::io::stderr;

use config::Config;
use tokio::net::TcpListener;
mod backend;
mod config;
mod diagnostics;
mod dictionary_io;
mod document_state;
mod git_commit_parser;
mod ignored_lints_io;
mod io_utils;
mod pos_conv;

use backend::Backend;
use clap::Parser;
use tower_lsp_server::{LspService, Server};
use tracing::Level;
use tracing_subscriber::FmtSubscriber;

static DEFAULT_ADDRESS: &str = "127.0.0.1:4000";

/// Start a language server to provide grammar checking inside of developer
/// environments.
///
/// Will listen on 127.0.0.1:4000 by default.
#[derive(Debug, Parser)]
#[command(version, about)]
struct Args {
    /// Set to listen on standard input / output rather than TCP.
    #[arg(short, long, default_value_t = false)]
    stdio: bool,
}

// Setting worker threads to four means the process will use about five threads total
// This is because worker threads do not include blocking threads
#[tokio::main(worker_threads = 1)]
async fn main() -> anyhow::Result<()> {
    let subscriber = FmtSubscriber::builder()
        .map_writer(move |_| stderr)
        .with_ansi(false)
        .with_max_level(Level::WARN)
        .finish();

    tracing::subscriber::set_global_default(subscriber)?;

    let args = Args::parse();
    let config = Config::default();

    let (service, socket) = LspService::new(|client| Backend::new(client, config));

    if args.stdio {
        let stdin = tokio::io::stdin();
        let stdout = tokio::io::stdout();
        Server::new(stdin, stdout, socket).serve(service).await;
    } else {
        let listener = TcpListener::bind(DEFAULT_ADDRESS).await.unwrap();
        println!("Listening on {DEFAULT_ADDRESS}");
        let (stream, _) = listener.accept().await.unwrap();
        let (read, write) = tokio::io::split(stream);
        Server::new(read, write, socket).serve(service).await;
    }

    Ok(())
}



================================================
FILE: harper-ls/src/pos_conv.rs
================================================
//! This module includes various conversions from the index-based [`Span`]s that
//! Harper uses, and the Ranges that the LSP uses.

use harper_core::Span;
use tower_lsp_server::lsp_types::{Position, Range};

pub fn span_to_range(source: &[char], span: Span<char>) -> Range {
    let start = index_to_position(source, span.start);
    let end = index_to_position(source, span.end);

    Range { start, end }
}

fn index_to_position(source: &[char], index: usize) -> Position {
    let before = &source[0..index];
    let newline_indices: Vec<_> = before
        .iter()
        .enumerate()
        .filter_map(|(idx, c)| if *c == '\n' { Some(idx + 1) } else { None })
        .collect();

    let lines = newline_indices.len();

    let last_newline_idx = newline_indices.last().copied().unwrap_or(0);

    let cols: usize = source[last_newline_idx..index]
        .iter()
        .map(|c| c.len_utf16())
        .sum();

    Position {
        line: lines as u32,
        character: cols as u32,
    }
}

/// Converts a position to a (zero-based) character index within the source character array.
///
/// The position is converted to an index using saturating arithmetic. If the requested line index
/// is too high, the index of the last character in the source is returned. If the line is
/// in-bounds but the requested character isn't, the last character of that line is returned.
fn position_to_index(source: &[char], position: Position) -> usize {
    // Find target line.
    let Some(target_line) = source
        // Split including the newline character so we don't lose any characters.
        .split_inclusive(|char| *char == '\n')
        .nth(position.line as usize)
    else {
        // Requested line index is too high.
        // Return the last char in `source' as the closest approximation.
        // Uses `saturating_sub` to avoid underflow when `source` is empty.
        return source.len().saturating_sub(1);
    };

    // Get a pointer to the char we seek.
    // Check if specified character index is within bounds of the target line.
    let target_char_pointer = if position.character
        < target_line
            .len()
            .try_into()
            .expect("target_line.len() can fit in u32")
    {
        // Character index is inside the bounds of the specified line.
        // Calculate pointer to the char we're looking for.
        target_line
            .as_ptr()
            .wrapping_add(position.character as usize)
    } else {
        // Character index is outside the bounds of the specified line.
        // Get pointer to the last character of the line.
        target_line.last().expect("line cannot be empty")
    };

    // Convert the char pointer to its index within `source`.
    // Note: this could be simplified with `offset_from`, but that would require `unsafe`.
    (target_char_pointer as usize - source.as_ptr() as usize) / size_of::<char>()
}

pub fn range_to_span(source: &[char], range: Range) -> Span<char> {
    let start = position_to_index(source, range.start);
    let end = position_to_index(source, range.end);

    Span::new(start, end)
}

#[cfg(test)]
mod tests {
    use tower_lsp_server::lsp_types::{Position, Range};

    use super::{index_to_position, position_to_index, range_to_span};

    #[test]
    fn first_line_correct() {
        let source: Vec<_> = "Hello there.".chars().collect();

        let start = Position {
            line: 0,
            character: 4,
        };

        let i = position_to_index(&source, start);

        assert_eq!(i, 4);

        let p = index_to_position(&source, i);

        assert_eq!(p, start)
    }

    #[test]
    fn reversible_position_conv() {
        let source: Vec<_> = "There was a man,\n his voice had timbre,\n unlike a boy."
            .chars()
            .collect();

        let a = Position {
            line: 1,
            character: 2,
        };

        let b = position_to_index(&source, a);

        assert_eq!(b, 19);

        let c = index_to_position(&source, b);

        let d = position_to_index(&source, a);

        assert_eq!(a, c);
        assert_eq!(b, d);
    }

    #[test]
    fn end_of_line() {
        let source: Vec<_> = "This is a short test\n".chars().collect();

        let a = Position {
            line: 0,
            character: 20,
        };

        assert_eq!(position_to_index(&source, a), 20);
    }

    #[test]
    fn end_of_file() {
        let source: Vec<_> = "This is a short test".chars().collect();

        let a = Position {
            line: 0,
            character: 19,
        };

        assert_eq!(position_to_index(&source, a), 19);
    }

    #[test]
    fn issue_250() {
        let source: Vec<_> = "Hello thur\n".chars().collect();

        let range = Range {
            start: Position {
                line: 0,
                character: 9,
            },
            end: Position {
                line: 0,
                character: 10,
            },
        };

        let out = range_to_span(&source, range);
        assert_eq!(out.start, 9);
        assert_eq!(out.end, 10);
    }

    /// Ensures that `position_to_index` does not produce an incorrect index of 0 for an input
    /// `Position` of `{ line: 1, character: 0 }`.
    /// Related to: https://github.com/Automattic/harper/issues/1253
    #[test]
    fn pos_to_index_correct_for_l1_c0() {
        let source: Vec<_> = ". one two three four five six seven eight nine ten eleven twelve thirteen fourteen fifteen sixteen seventeen eighteen nineteen twenty twenty-one twenty-two twenty-three twenty-four twenty-five twenty-six twenty-seven twenty-eight twenty-nine thirty thirty-one\n".chars().collect();
        let position = Position {
            line: 1,
            character: 0,
        };

        let out_index = position_to_index(&source, position);
        assert_ne!(out_index, 0);
    }

    /// Ensures `position_to_index` produces the correct result when indexing line 0 character 0.
    #[test]
    fn pos_to_index_off_by_one_check_l0_c0() {
        let source: Vec<_> = "abc\ndef\nghi\njkl".chars().collect();
        let position = Position {
            line: 0,
            character: 0,
        };

        let out_index = position_to_index(&source, position);
        assert_eq!(source[out_index], 'a');
    }

    /// Ensures `position_to_index` produces the correct result when indexing a non-zero line and
    /// character.
    #[test]
    fn pos_to_index_off_by_one_check_l2_c1() {
        let source: Vec<_> = "abc\ndef\nghi\njkl".chars().collect();
        let position = Position {
            line: 2,
            character: 1,
        };

        let out_index = position_to_index(&source, position);
        assert_eq!(source[out_index], 'h');
    }

    /// Ensures `position_to_index` produces an index of 0 when indexing line 0 character 0 of
    /// a source that contains only a newline (`\n`).
    #[test]
    fn pos_to_index_newline_only_l0_c0() {
        let source: Vec<_> = "\n".chars().collect();
        let position = Position {
            line: 0,
            character: 0,
        };

        let out_index = position_to_index(&source, position);
        assert_eq!(out_index, 0);
    }

    /// Ensures `position_to_index` produces the last character index when indexing an out of
    /// bounds line in a source that contains only newlines (`\n`).
    #[test]
    fn pos_to_index_newlines_only_l7_c0() {
        let source: Vec<_> = "\n\n\n".chars().collect();
        let position = Position {
            line: 7,
            character: 0,
        };

        let out_index = position_to_index(&source, position);
        assert_eq!(out_index, 2);
    }

    /// Ensures `position_to_index` gives the last character of the line when indexing an out of
    /// bounds character.
    #[test]
    fn pos_to_index_out_of_bounds_char() {
        let source: Vec<_> = "abc\ndef\nghi\njkl".chars().collect();
        let position = Position {
            line: 3, // "jkl"
            character: 8,
        };

        let out_index = position_to_index(&source, position);
        assert_eq!(source[out_index], 'l');
    }
}



================================================
FILE: harper-pos-utils/Cargo.toml
================================================
[package]
name = "harper-pos-utils"
version = "1.5.1"
edition = "2024"
description = "The language checker for developers."
license = "Apache-2.0"
repository = "https://github.com/automattic/harper"

[dependencies]
rs-conllu = "0.3.0"
hashbrown = { version = "0.16.1", features = ["serde"] }
strum = "0.27.2"
strum_macros = "0.27.2"
serde = { version = "1.0.228", features = ["derive"] }
is-macro = "0.3.7"
rand = { version = "0.9.1", optional = true }
burn = { version = "0.19.1", default-features = false, features = ["std"] }
burn-ndarray = { version = "0.19.0", default-features = false }
serde_json = "1.0.149"
lru = "0.16.3"
rayon = { version = "1.11.0", optional = true }

[features]
default = []
training = ["dep:rand", "burn/train", "burn/autodiff"]
threaded = ["dep:rayon"]



================================================
FILE: harper-pos-utils/src/conllu_utils.rs
================================================
use std::{fs::File, path::Path};

use rs_conllu::{Sentence, parse_file};

/// Produce an iterator over the sentences in a `.conllu` file.
/// Will panic on error, so this should not be used outside of training.
pub fn iter_sentences_in_conllu(path: impl AsRef<Path>) -> impl Iterator<Item = Sentence> {
    let file = File::open(path).unwrap();
    let doc = parse_file(file);

    doc.map(|v| v.unwrap())
}



================================================
FILE: harper-pos-utils/src/lib.rs
================================================
mod chunker;
#[cfg(feature = "training")]
mod conllu_utils;
mod patch_criteria;
mod tagger;
mod upos;
#[cfg(feature = "training")]
mod word_counter;

pub use chunker::{
    BrillChunker, BurnChunker, BurnChunkerCpu, CachedChunker, Chunker, UPOSFreqDict,
};
pub use tagger::{BrillTagger, FreqDict, FreqDictBuilder, Tagger};
pub use upos::{UPOS, UPOSIter};



================================================
FILE: harper-pos-utils/src/patch_criteria.rs
================================================
use serde::{Deserialize, Serialize};

use crate::UPOS;

#[derive(Debug, Clone, Serialize, Deserialize, Hash, PartialEq, Eq)]
pub enum PatchCriteria {
    WordIsTaggedWith {
        /// Which token to inspect.
        relative: isize,
        is_tagged: UPOS,
    },
    AnyWordIsTaggedWith {
        /// The farthest relative index to look
        max_relative: isize,
        is_tagged: UPOS,
    },
    SandwichTaggedWith {
        prev_word_tagged: UPOS,
        post_word_tagged: UPOS,
    },
    WordIs {
        relative: isize,
        word: String,
    },
    /// Not applicable to the Brill Tagger, only the chunker
    NounPhraseAt {
        is_np: bool,
        relative: isize,
    },
    Combined {
        a: Box<PatchCriteria>,
        b: Box<PatchCriteria>,
    },
}

impl PatchCriteria {
    pub fn fulfils(
        &self,
        tokens: &[String],
        tags: &[Option<UPOS>],
        np_flags: &[bool],
        index: usize,
    ) -> bool {
        match self {
            PatchCriteria::WordIsTaggedWith {
                relative,
                is_tagged,
            } => {
                let Some(index) = add(index, *relative) else {
                    return false;
                };

                tags.get(index)
                    .copied()
                    .flatten()
                    .is_some_and(|t| t == *is_tagged)
            }
            PatchCriteria::AnyWordIsTaggedWith {
                max_relative: relative,
                is_tagged,
            } => {
                let Some(farthest_index) = add(index, *relative) else {
                    return false;
                };

                (farthest_index.min(index)..farthest_index.max(index)).any(|i| {
                    tags.get(i)
                        .copied()
                        .flatten()
                        .is_some_and(|t| t == *is_tagged)
                })
            }
            PatchCriteria::SandwichTaggedWith {
                prev_word_tagged,
                post_word_tagged,
            } => {
                if index == 0 {
                    return false;
                }

                let prev_i = index - 1;
                let post_i = index + 1;

                tags.get(prev_i)
                    .copied()
                    .flatten()
                    .is_some_and(|t| t == *prev_word_tagged)
                    && tags
                        .get(post_i)
                        .copied()
                        .flatten()
                        .is_some_and(|t| t == *post_word_tagged)
            }
            Self::WordIs { relative, word } => {
                let Some(index) = add(index, *relative) else {
                    return false;
                };

                tokens.get(index).is_some_and(|w| {
                    w.chars()
                        .zip(word.chars())
                        .all(|(a, b)| a.eq_ignore_ascii_case(&b))
                })
            }

            Self::NounPhraseAt { is_np, relative } => {
                let Some(index) = add(index, *relative) else {
                    return false;
                };

                np_flags.get(index).is_some_and(|f| *is_np == *f)
            }
            Self::Combined { a, b } => {
                a.fulfils(tokens, tags, np_flags, index) && b.fulfils(tokens, tags, np_flags, index)
            }
        }
    }
}

fn add(u: usize, i: isize) -> Option<usize> {
    if i.is_negative() {
        u.checked_sub(i.wrapping_abs() as u32 as usize)
    } else {
        u.checked_add(i as usize)
    }
}



================================================
FILE: harper-pos-utils/src/upos.rs
================================================
use std::fmt::Display;

use is_macro::Is;
use serde::{Deserialize, Serialize};
use strum_macros::{AsRefStr, EnumIter, EnumString};

/// Represents the universal parts of speech as outlined by [universaldependencies.org](https://universaldependencies.org/u/pos/index.html).
#[derive(
    EnumString,
    Debug,
    Default,
    Hash,
    Eq,
    PartialEq,
    Clone,
    Copy,
    EnumIter,
    AsRefStr,
    Serialize,
    Deserialize,
    PartialOrd,
    Ord,
    Is,
)]
pub enum UPOS {
    /// Adjective
    ADJ,
    /// Adposition
    ADP,
    /// Adverb
    ADV,
    /// Auxiliary
    AUX,
    /// Coordinating conjunction
    CCONJ,
    /// Determiner
    DET,
    /// Interjection
    INTJ,
    /// Noun
    #[default]
    NOUN,
    /// Numeral
    NUM,
    /// Particle
    PART,
    /// Pronoun
    PRON,
    /// Proper noun
    PROPN,
    /// Punctuation
    PUNCT,
    /// Subordinating conjunction
    SCONJ,
    /// Symbol
    SYM,
    /// Verb
    VERB,
}

impl UPOS {
    pub fn from_conllu(other: rs_conllu::UPOS) -> Option<Self> {
        Some(match other {
            rs_conllu::UPOS::ADJ => UPOS::ADJ,
            rs_conllu::UPOS::ADP => UPOS::ADP,
            rs_conllu::UPOS::ADV => UPOS::ADV,
            rs_conllu::UPOS::AUX => UPOS::AUX,
            rs_conllu::UPOS::CCONJ => UPOS::CCONJ,
            rs_conllu::UPOS::DET => UPOS::DET,
            rs_conllu::UPOS::INTJ => UPOS::INTJ,
            rs_conllu::UPOS::NOUN => UPOS::NOUN,
            rs_conllu::UPOS::NUM => UPOS::NUM,
            rs_conllu::UPOS::PART => UPOS::PART,
            rs_conllu::UPOS::PRON => UPOS::PRON,
            rs_conllu::UPOS::PROPN => UPOS::PROPN,
            rs_conllu::UPOS::PUNCT => UPOS::PUNCT,
            rs_conllu::UPOS::SCONJ => UPOS::SCONJ,
            rs_conllu::UPOS::SYM => UPOS::SYM,
            rs_conllu::UPOS::VERB => UPOS::VERB,
            rs_conllu::UPOS::X => return None,
        })
    }

    pub fn is_nominal(&self) -> bool {
        matches!(self, Self::NOUN | Self::PROPN | Self::PRON)
    }
}

impl Display for UPOS {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        let desc = match self {
            UPOS::ADJ => "Adjective",
            UPOS::ADP => "Adposition",
            UPOS::ADV => "Adverb",
            UPOS::AUX => "Auxiliary",
            UPOS::CCONJ => "Coordinating conjunction",
            UPOS::DET => "Determiner",
            UPOS::INTJ => "Interjection",
            UPOS::NOUN => "Noun",
            UPOS::NUM => "Numeral",
            UPOS::PART => "Particle",
            UPOS::PRON => "Pronoun",
            UPOS::PROPN => "Proper noun",
            UPOS::PUNCT => "Punctuation",
            UPOS::SCONJ => "Subordinating conjunction",
            UPOS::SYM => "Symbol",
            UPOS::VERB => "Verb",
        };
        write!(f, "{desc}")
    }
}



================================================
FILE: harper-pos-utils/src/word_counter.rs
================================================
use hashbrown::HashMap;

#[derive(Debug, Default)]
pub struct WordCounter {
    /// The number of times a word is associated with an error.
    pub word_counts: HashMap<String, usize>,
}

impl WordCounter {
    pub fn new() -> Self {
        Self::default()
    }

    /// Increment the count for a particular word.
    pub fn inc(&mut self, word: &str) {
        self.word_counts
            .entry_ref(word)
            .and_modify(|counter| *counter += 1)
            .or_insert(1);
    }

    /// Get an iterator over the most frequent words associated with errors.
    pub fn iter_top_n_words(&self, n: usize) -> impl Iterator<Item = &String> {
        let mut counts: Vec<(&String, &usize)> = self.word_counts.iter().collect();
        counts.sort_unstable_by(|a, b| b.1.cmp(a.1));
        counts.into_iter().take(n).map(|(a, _b)| a)
    }
}



================================================
FILE: harper-pos-utils/src/chunker/burn_chunker.rs
================================================
use crate::{UPOS, chunker::Chunker};
#[cfg(feature = "training")]
use burn::backend::Autodiff;

#[cfg(feature = "training")]
use burn::nn::loss::{MseLoss, Reduction};
use burn::nn::{Dropout, DropoutConfig};
#[cfg(feature = "training")]
use burn::optim::{GradientsParams, Optimizer};
use burn::record::{FullPrecisionSettings, NamedMpkBytesRecorder, NamedMpkFileRecorder, Recorder};
use burn::tensor::TensorData;
#[cfg(feature = "training")]
use burn::tensor::backend::AutodiffBackend;

use burn::{
    module::Module,
    nn::{BiLstmConfig, EmbeddingConfig, LinearConfig},
    tensor::{Int, Tensor, backend::Backend},
};
use burn_ndarray::{NdArray, NdArrayDevice};
use hashbrown::HashMap;
use std::path::Path;

const UNK_IDX: usize = 1;

#[derive(Module, Debug)]
struct NpModel<B: Backend> {
    embedding_words: burn::nn::Embedding<B>,
    embedding_upos: burn::nn::Embedding<B>,
    lstm: burn::nn::BiLstm<B>,
    linear_out: burn::nn::Linear<B>,
    dropout: Dropout,
}

impl<B: Backend> NpModel<B> {
    fn new(vocab: usize, word_embed_dim: usize, dropout: f32, device: &B::Device) -> Self {
        let upos_embed = 8;
        let total_embed = word_embed_dim + upos_embed;

        Self {
            embedding_words: EmbeddingConfig::new(vocab, word_embed_dim).init(device),
            embedding_upos: EmbeddingConfig::new(20, upos_embed).init(device),
            lstm: BiLstmConfig::new(total_embed, total_embed, false).init(device),
            // Multiply by two because the BiLSTM emits double the hidden parameters
            linear_out: LinearConfig::new(total_embed * 2, 1).init(device),
            dropout: DropoutConfig::new(dropout as f64).init(),
        }
    }

    fn forward(
        &self,
        word_tens: Tensor<B, 2, Int>,
        tag_tens: Tensor<B, 2, Int>,
        use_dropout: bool,
    ) -> Tensor<B, 2> {
        let word_embed = self.embedding_words.forward(word_tens);
        let tag_embed = self.embedding_upos.forward(tag_tens);

        let mut x = Tensor::cat(vec![word_embed, tag_embed], 2);

        if use_dropout {
            x = self.dropout.forward(x);
        }

        let (mut x, _) = self.lstm.forward(x, None);

        if use_dropout {
            x = self.dropout.forward(x);
        }

        let x = self.linear_out.forward(x);
        x.squeeze_dim::<2>(2)
    }
}

/// A [`Chunker`] that uses a BiLSTM and the Burn machine learning framework.
///
/// Additional details in this [talk](https://elijahpotter.dev/articles/i-spoke-at-wordcamp-u.s.-in-2025)
pub struct BurnChunker<B: Backend> {
    vocab: HashMap<String, usize>,
    model: NpModel<B>,
    device: B::Device,
}

impl<B: Backend> BurnChunker<B> {
    fn idx(&self, tok: &str) -> usize {
        *self.vocab.get(tok).unwrap_or(&UNK_IDX)
    }

    fn to_tensors(
        &self,
        sent: &[String],
        tags: &[Option<UPOS>],
    ) -> (Tensor<B, 2, Int>, Tensor<B, 2, Int>) {
        // Interleave with UPOS tags
        let idxs: Vec<_> = sent.iter().map(|t| self.idx(t) as i32).collect();

        let upos: Vec<_> = tags
            .iter()
            .map(|t| t.map(|o| o as i32 + 2).unwrap_or(1))
            .collect();

        let word_tensor =
            Tensor::<B, 1, Int>::from_data(TensorData::from(idxs.as_slice()), &self.device)
                .reshape([1, sent.len()]);

        let tag_tensor =
            Tensor::<B, 1, Int>::from_data(TensorData::from(upos.as_slice()), &self.device)
                .reshape([1, sent.len()]);

        (word_tensor, tag_tensor)
    }

    pub fn save_to(&self, dir: impl AsRef<Path>) {
        let dir = dir.as_ref();
        std::fs::create_dir_all(dir).unwrap();

        let recorder = NamedMpkFileRecorder::<FullPrecisionSettings>::new();
        self.model
            .clone()
            .save_file(dir.join("model.mpk"), &recorder)
            .unwrap();

        let vocab_bytes = serde_json::to_vec(&self.vocab).unwrap();
        std::fs::write(dir.join("vocab.json"), vocab_bytes).unwrap();
    }

    pub fn load_from_bytes(
        model_bytes: impl AsRef<[u8]>,
        vocab_bytes: impl AsRef<[u8]>,
        embed_dim: usize,
        dropout: f32,
        device: B::Device,
    ) -> Self {
        let vocab: HashMap<String, usize> = serde_json::from_slice(vocab_bytes.as_ref()).unwrap();

        let recorder = NamedMpkBytesRecorder::<FullPrecisionSettings>::new();

        let owned_data = model_bytes.as_ref().to_vec();
        let record = recorder.load(owned_data, &device).unwrap();

        let model = NpModel::new(vocab.len(), embed_dim, dropout, &device);
        let model = model.load_record(record);

        Self {
            vocab,
            model,
            device,
        }
    }
}

#[cfg(feature = "training")]
struct ExtractedSentences(
    Vec<Vec<String>>,
    Vec<Vec<Option<UPOS>>>,
    Vec<Vec<bool>>,
    HashMap<String, usize>,
);

#[cfg(feature = "training")]
impl<B: Backend + AutodiffBackend> BurnChunker<B> {
    fn to_label(&self, labels: &[bool]) -> Tensor<B, 2> {
        let ys: Vec<_> = labels.iter().map(|b| if *b { 1. } else { 0. }).collect();

        Tensor::<B, 1, _>::from_data(TensorData::from(ys.as_slice()), &self.device)
            .reshape([1, labels.len()])
    }

    pub fn train(
        training_files: &[impl AsRef<Path>],
        test_file: &impl AsRef<Path>,
        word_embed_dim: usize,
        dropout: f32,
        epochs: usize,
        lr: f64,
        device: B::Device,
    ) -> Self {
        use burn::tensor::cast::ToElement;

        println!("Preparing datasets...");
        let ExtractedSentences(sents, tags, labs, vocab) =
            Self::extract_sents_from_files(training_files);

        println!("Preparing model and training config...");

        let mut model = NpModel::<B>::new(vocab.len(), word_embed_dim, dropout, &device);
        let opt_config = burn::optim::AdamConfig::new();
        let mut opt = opt_config.init();

        let util = BurnChunker {
            vocab: vocab.clone(),
            model: model.clone(),
            device: device.clone(),
        };

        let loss_fn = MseLoss::new();
        let mut last_score = 0.;

        println!("Training...");

        for _ in 0..epochs {
            let mut total_loss = 0.;
            let mut total_tokens = 0;
            let mut total_correct: usize = 0;

            for (i, ((x, w), y)) in sents.iter().zip(tags.iter()).zip(labs.iter()).enumerate() {
                let (word_tens, tag_tens) = util.to_tensors(x, w);
                let y_tensor = util.to_label(y);

                let logits = model.forward(word_tens, tag_tens, true);
                total_correct += logits
                    .to_data()
                    .iter()
                    .map(|p: f32| p > 0.5)
                    .zip(y)
                    .map(|(a, b)| if a == *b { 1 } else { 0 })
                    .sum::<usize>();

                let loss = loss_fn.forward(logits, y_tensor, Reduction::Mean);

                let grads = loss.backward();
                let grads = GradientsParams::from_grads(grads, &model);

                model = opt.step(lr, model, grads);

                total_loss += loss.into_scalar().to_f64();
                total_tokens += x.len();

                if i % 1000 == 0 {
                    println!("{i}/{}", sents.len());
                }
            }

            println!(
                "Average loss for epoch: {}",
                total_loss / sents.len() as f64 * 100.
            );

            println!(
                "{}% correct in training dataset",
                total_correct as f32 / total_tokens as f32 * 100.
            );

            let score = util.score_model(&model, test_file);
            println!("{}% correct in test dataset", score * 100.);

            if score < last_score {
                println!("Overfitting detected. Stopping...");
                break;
            }

            last_score = score;
        }

        Self {
            vocab,
            model,
            device,
        }
    }

    fn score_model(&self, model: &NpModel<B>, dataset: &impl AsRef<Path>) -> f32 {
        let ExtractedSentences(sents, tags, labs, _) = Self::extract_sents_from_files(&[dataset]);

        let mut total_tokens = 0;
        let mut total_correct: usize = 0;

        for ((x, w), y) in sents.iter().zip(tags.iter()).zip(labs.iter()) {
            let (word_tens, tag_tens) = self.to_tensors(x, w);

            let logits = model.forward(word_tens, tag_tens, false);
            total_correct += logits
                .to_data()
                .iter()
                .map(|p: f32| p > 0.5)
                .zip(y)
                .map(|(a, b)| if a == *b { 1 } else { 0 })
                .sum::<usize>();

            total_tokens += x.len();
        }

        total_correct as f32 / total_tokens as f32
    }

    fn extract_sents_from_files(files: &[impl AsRef<Path>]) -> ExtractedSentences {
        use super::np_extraction::locate_noun_phrases_in_sent;
        use crate::conllu_utils::iter_sentences_in_conllu;

        let mut vocab: HashMap<String, usize> = HashMap::new();
        vocab.insert("<UNK>".into(), UNK_IDX);

        let mut sents: Vec<Vec<String>> = Vec::new();
        let mut sent_tags: Vec<Vec<Option<UPOS>>> = Vec::new();
        let mut labs: Vec<Vec<bool>> = Vec::new();

        const CONTRACTIONS: &[&str] = &["sn't", "n't", "'ll", "'ve", "'re", "'d", "'m", "'s"];

        for file in files {
            for sent in iter_sentences_in_conllu(file) {
                let spans = locate_noun_phrases_in_sent(&sent);

                let mut original_mask = vec![false; sent.tokens.len()];
                for span in spans {
                    for i in span {
                        original_mask[i] = true;
                    }
                }

                let mut toks: Vec<String> = Vec::new();
                let mut tags: Vec<Option<UPOS>> = Vec::new();
                let mut mask: Vec<bool> = Vec::new();

                for (idx, tok) in sent.tokens.iter().enumerate() {
                    let is_contraction = CONTRACTIONS.contains(&&tok.form[..]);
                    if is_contraction && !toks.is_empty() {
                        let prev_tok = toks.pop().unwrap();
                        let prev_mask = mask.pop().unwrap();
                        toks.push(format!("{prev_tok}{}", tok.form));
                        mask.push(prev_mask || original_mask[idx]);
                    } else {
                        toks.push(tok.form.clone());
                        tags.push(tok.upos.and_then(UPOS::from_conllu));
                        mask.push(original_mask[idx]);
                    }
                }

                for t in &toks {
                    if !vocab.contains_key(t) {
                        let next = vocab.len();
                        vocab.insert(t.clone(), next);
                    }
                }

                sents.push(toks);
                sent_tags.push(tags);
                labs.push(mask);
            }
        }

        ExtractedSentences(sents, sent_tags, labs, vocab)
    }
}

#[cfg(feature = "training")]
pub type BurnChunkerCpu = BurnChunker<burn::backend::Autodiff<NdArray>>;

#[cfg(not(feature = "training"))]
pub type BurnChunkerCpu = BurnChunker<NdArray>;

impl BurnChunkerCpu {
    pub fn load_from_bytes_cpu(
        model_bytes: impl AsRef<[u8]>,
        vocab_bytes: impl AsRef<[u8]>,
        embed_dim: usize,
        dropout: f32,
    ) -> Self {
        Self::load_from_bytes(
            model_bytes,
            vocab_bytes,
            embed_dim,
            dropout,
            NdArrayDevice::Cpu,
        )
    }
}

#[cfg(feature = "training")]
impl BurnChunkerCpu {
    pub fn train_cpu(
        training_files: &[impl AsRef<Path>],
        test_file: &impl AsRef<Path>,
        embed_dim: usize,
        dropout: f32,
        epochs: usize,
        lr: f64,
    ) -> Self {
        BurnChunker::<Autodiff<NdArray>>::train(
            training_files,
            test_file,
            embed_dim,
            dropout,
            epochs,
            lr,
            NdArrayDevice::Cpu,
        )
    }
}

impl<B: Backend> Chunker for BurnChunker<B> {
    fn chunk_sentence(&self, sentence: &[String], tags: &[Option<UPOS>]) -> Vec<bool> {
        // Solves a divide-by-zero error in the linear layer.
        if sentence.is_empty() {
            return Vec::new();
        }

        let (word_tens, tag_tens) = self.to_tensors(sentence, tags);
        let prob = self.model.forward(word_tens, tag_tens, false);
        prob.to_data().iter().map(|p: f32| p > 0.5).collect()
    }
}



================================================
FILE: harper-pos-utils/src/chunker/cached_chunker.rs
================================================
use lru::LruCache;
use std::hash::Hash;
use std::num::NonZeroUsize;
use std::sync::Mutex;

use super::Chunker;
use crate::UPOS;

/// Wraps any chunker implementation to add an LRU Cache.
/// Useful for incremental lints.
pub struct CachedChunker<C: Chunker> {
    inner: C,
    cache: Mutex<LruCache<CacheKey, Vec<bool>>>,
}

impl<C: Chunker> CachedChunker<C> {
    pub fn new(inner: C, capacity: NonZeroUsize) -> Self {
        Self {
            inner,
            cache: Mutex::new(LruCache::new(capacity)),
        }
    }
}

impl<C: Chunker> Chunker for CachedChunker<C> {
    fn chunk_sentence(&self, sentence: &[String], tags: &[Option<UPOS>]) -> Vec<bool> {
        let key = CacheKey::new(sentence, tags);

        // Attempt a cache hit.
        // We put this in the block so `read` gets dropped as early as possible.
        if let Ok(mut read) = self.cache.try_lock()
            && let Some(result) = read.get(&key)
        {
            return result.clone();
        };

        // We don't want to hold the lock since it may take a while to run the chunker.
        let result = self.inner.chunk_sentence(sentence, tags);

        if let Ok(mut cache) = self.cache.try_lock() {
            cache.put(key, result.clone());
        }

        result
    }
}

#[derive(Hash, PartialEq, Eq)]
struct CacheKey {
    sentence: Vec<String>,
    tags: Vec<Option<UPOS>>,
}

impl CacheKey {
    fn new(sentence: &[String], tags: &[Option<UPOS>]) -> Self {
        Self {
            sentence: sentence.to_vec(),
            tags: tags.to_vec(),
        }
    }
}



================================================
FILE: harper-pos-utils/src/chunker/mod.rs
================================================
use crate::UPOS;

mod brill_chunker;
mod burn_chunker;
mod cached_chunker;
#[cfg(feature = "training")]
mod np_extraction;
mod upos_freq_dict;

pub use brill_chunker::BrillChunker;
pub use burn_chunker::{BurnChunker, BurnChunkerCpu};
pub use cached_chunker::CachedChunker;
pub use upos_freq_dict::UPOSFreqDict;

/// An implementer of this trait is capable of identifying the noun phrases in a provided sentence.
/// [See here](https://en.wikipedia.org/wiki/Shallow_parsing) for more details on what this is and how it can work.
pub trait Chunker {
    /// Iterate over the sentence, identifying the noun phrases contained within.
    /// A token marked `true` is a component of a noun phrase.
    /// A token marked `false` is not.
    fn chunk_sentence(&self, sentence: &[String], tags: &[Option<UPOS>]) -> Vec<bool>;
}



================================================
FILE: harper-pos-utils/src/chunker/np_extraction.rs
================================================
//! Methods for extracting nominal phrases from datasets.

use std::collections::VecDeque;

use hashbrown::HashSet;
use rs_conllu::{Sentence, Token, TokenID, UPOS};

pub fn locate_noun_phrases_in_sent(sent: &Sentence) -> Vec<HashSet<usize>> {
    let mut found_noun_phrases = Vec::new();

    for (i, token) in sent.tokens.iter().enumerate() {
        if token.upos.is_some_and(is_root_upos) {
            let noun_phrase = locate_noun_phrase_with_head_at(i, sent);

            found_noun_phrases.push(noun_phrase);
        }
    }

    found_noun_phrases.retain(is_contiguous);

    reduce_to_maximal_nonoverlapping(found_noun_phrases)
}

fn is_contiguous(indices: &HashSet<usize>) -> bool {
    if indices.is_empty() {
        return false;
    }
    let lo = *indices.iter().min().unwrap();
    let hi = *indices.iter().max().unwrap();
    hi - lo + 1 == indices.len()
}

fn reduce_to_maximal_nonoverlapping(mut phrases: Vec<HashSet<usize>>) -> Vec<HashSet<usize>> {
    phrases.sort_by_key(|s| usize::MAX - s.len());
    let mut selected = Vec::new();
    let mut occupied = HashSet::new();

    for p in phrases {
        if p.is_disjoint(&occupied) {
            occupied.extend(&p);
            selected.push(p);
        }
    }

    selected
}

fn locate_noun_phrase_with_head_at(head_index: usize, sent: &Sentence) -> HashSet<usize> {
    let mut children = HashSet::new();
    let mut queue = VecDeque::new();
    queue.push_back(head_index);

    while let Some(c_i) = queue.pop_front() {
        if children.contains(&c_i) {
            continue;
        }

        let tok = &sent.tokens[c_i];

        if is_noun_phrase_constituent(tok) || tok.upos.is_some_and(is_root_upos) {
            children.insert(c_i);
            queue.extend(get_children(sent, c_i));
        }
    }

    children
}

fn is_root_upos(upos: UPOS) -> bool {
    use UPOS::*;
    matches!(upos, NOUN | PROPN | PRON)
}

/// Get the indices of the children of a given node.
fn get_children(sent: &Sentence, of_node: usize) -> Vec<usize> {
    let mut children = Vec::new();

    for (index, token) in sent.tokens.iter().enumerate() {
        if index == of_node {
            continue;
        }

        if let Some(head) = token.head {
            let is_child = match head {
                TokenID::Single(i) => i != 0 && i - 1 == of_node,
                TokenID::Range(start, end) => (start - 1..end - 1).contains(&of_node),
                TokenID::Empty(_, _) => false,
            };

            if is_child {
                children.push(index)
            }
        }
    }

    children
}

fn is_noun_phrase_constituent(token: &Token) -> bool {
    let Some(ref deprel) = token.deprel else {
        return false;
    };

    matches!(
        deprel.as_str(),
        "det" | "amod" | "nummod" | "compound" | "fixed" | "flat" | "acl" | "aux:pass"
    )
}



================================================
FILE: harper-pos-utils/src/chunker/upos_freq_dict.rs
================================================
#[cfg(feature = "training")]
use std::path::Path;

use hashbrown::HashMap;
use serde::{Deserialize, Serialize};

use crate::UPOS;

use super::Chunker;

/// Tracks the number of times any given UPOS is associated with a noun phrase.
/// Used as the baseline for the chunker.
#[derive(Debug, Clone, Serialize, Deserialize, Default)]
pub struct UPOSFreqDict {
    /// The # of times each [`UPOS`] was not part of an NP subtracted from the number of times it
    /// was.
    pub counts: HashMap<UPOS, isize>,
}

impl UPOSFreqDict {
    pub fn is_likely_np_component(&self, upos: &UPOS) -> bool {
        self.counts.get(upos).cloned().unwrap_or_default() > 0
    }
}

impl Chunker for UPOSFreqDict {
    fn chunk_sentence(&self, _sentence: &[String], tags: &[Option<UPOS>]) -> Vec<bool> {
        tags.iter()
            .map(|t| {
                t.as_ref()
                    .map(|t| self.is_likely_np_component(t))
                    .unwrap_or(false)
            })
            .collect()
    }
}

#[cfg(feature = "training")]
impl UPOSFreqDict {
    /// Increment the count for a particular lint kind.
    pub fn inc_is_np(&mut self, upos: UPOS, is_np: bool) {
        self.counts
            .entry(upos)
            .and_modify(|counter| *counter += if is_np { 1 } else { -1 })
            .or_insert(1);
    }

    /// Parse a `.conllu` file and use it to train a frequency dictionary.
    /// For error-handling purposes, this function should not be made accessible outside of training.
    pub fn inc_from_conllu_file(&mut self, path: impl AsRef<Path>) {
        use super::np_extraction::locate_noun_phrases_in_sent;
        use crate::conllu_utils::iter_sentences_in_conllu;

        for sent in iter_sentences_in_conllu(path) {
            use hashbrown::HashSet;

            let noun_phrases = locate_noun_phrases_in_sent(&sent);

            let flat = noun_phrases.into_iter().fold(HashSet::new(), |mut a, b| {
                a.extend(b);
                a
            });

            for (i, token) in sent.tokens.iter().enumerate() {
                if let Some(upos) = token.upos.and_then(UPOS::from_conllu) {
                    self.inc_is_np(upos, flat.contains(&i))
                }
            }
        }
    }
}



================================================
FILE: harper-pos-utils/src/chunker/brill_chunker/mod.rs
================================================
mod patch;

#[cfg(feature = "training")]
use std::path::Path;

#[cfg(feature = "training")]
use crate::word_counter::WordCounter;
use crate::{
    UPOS,
    chunker::{Chunker, upos_freq_dict::UPOSFreqDict},
};

use patch::Patch;
use serde::{Deserialize, Serialize};

/// A [`Chunker`] implementation based on the work by Eric Brill.
///
/// Additional reading:
///
/// - [Continuations on Transformation-based Learning](https://elijahpotter.dev/articles/more-transformation-based-learning)
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct BrillChunker {
    base: UPOSFreqDict,
    patches: Vec<Patch>,
}

impl BrillChunker {
    pub fn new(base: UPOSFreqDict) -> Self {
        Self {
            base,
            patches: Vec::new(),
        }
    }

    fn apply_patches(&self, sentence: &[String], tags: &[Option<UPOS>], np_states: &mut [bool]) {
        for patch in &self.patches {
            for i in 0..sentence.len() {
                if patch.from == np_states[i]
                    && patch.criteria.fulfils(sentence, tags, np_states, i)
                {
                    np_states[i] = !np_states[i];
                }
            }
        }
    }
}

impl Chunker for BrillChunker {
    fn chunk_sentence(&self, sentence: &[String], tags: &[Option<UPOS>]) -> Vec<bool> {
        let mut initial_pass = self.base.chunk_sentence(sentence, tags);

        self.apply_patches(sentence, tags, &mut initial_pass);

        initial_pass
    }
}

#[cfg(feature = "training")]
type CandidateArgs = (Vec<String>, Vec<Option<UPOS>>, Vec<bool>);

#[cfg(feature = "training")]
impl BrillChunker {
    /// Tag a provided sentence with the tagger, providing the "correct" tags (from a dataset or
    /// other source), returning the number of errors.
    pub fn count_patch_errors(
        &self,
        sentence: &[String],
        tags: &[Option<UPOS>],
        base_flags: &[bool],
        correct_np_flags: &[bool],
    ) -> usize {
        let mut flags = base_flags.to_vec();
        self.apply_patches(sentence, tags, &mut flags);

        let mut loss = 0;
        for (a, b) in flags.into_iter().zip(correct_np_flags) {
            if a != *b {
                loss += 1;
            }
        }

        loss
    }

    /// Tag a provided sentence with the tagger, providing the "correct" tags (from a dataset or
    /// other source), returning the number of errors.
    pub fn count_chunk_errors(
        &self,
        sentence: &[String],
        tags: &[Option<UPOS>],
        correct_np_flags: &[bool],
        relevant_words: &mut WordCounter,
    ) -> usize {
        let flags = self.chunk_sentence(sentence, tags);

        let mut loss = 0;
        for ((a, b), word) in flags.into_iter().zip(correct_np_flags).zip(sentence) {
            if a != *b {
                loss += 1;
                relevant_words.inc(word);
            }
        }

        loss
    }

    /// To speed up training, only try a subset of all possible candidates.
    /// How many to select is given by the `candidate_selection_chance`. A higher chance means a
    /// longer training time.
    fn epoch(&mut self, training_files: &[impl AsRef<Path>], candidate_selection_chance: f32) {
        use crate::conllu_utils::iter_sentences_in_conllu;
        use rs_conllu::Sentence;
        use std::time::Instant;

        assert!((0.0..=1.0).contains(&candidate_selection_chance));

        let mut total_tokens = 0;
        let mut error_counter = 0;

        let sentences: Vec<Sentence> = training_files
            .iter()
            .flat_map(iter_sentences_in_conllu)
            .collect();
        let mut sentences_flagged: Vec<CandidateArgs> = Vec::new();

        for sent in &sentences {
            use hashbrown::HashSet;

            use crate::chunker::np_extraction::locate_noun_phrases_in_sent;

            let mut toks: Vec<String> = Vec::new();
            let mut tags = Vec::new();

            for token in &sent.tokens {
                let form = token.form.clone();
                if let Some(last) = toks.last_mut() {
                    match form.as_str() {
                        "sn't" | "n't" | "'ll" | "'ve" | "'re" | "'d" | "'m" | "'s" => {
                            last.push_str(&form);
                            continue;
                        }
                        _ => {}
                    }
                }
                toks.push(form);
                tags.push(token.upos.and_then(UPOS::from_conllu));
            }

            let actual = locate_noun_phrases_in_sent(sent);
            let actual_flat = actual.into_iter().fold(HashSet::new(), |mut a, b| {
                a.extend(b.into_iter());
                a
            });

            let mut actual_seq = Vec::new();

            for el in actual_flat {
                if el >= actual_seq.len() {
                    actual_seq.resize(el + 1, false);
                }
                actual_seq[el] = true;
            }

            sentences_flagged.push((toks, tags, actual_seq));
        }

        let mut relevant_words = WordCounter::default();

        for (tok_buf, tag_buf, flag_buf) in &sentences_flagged {
            total_tokens += tok_buf.len();
            error_counter += self.count_chunk_errors(
                tok_buf.as_slice(),
                tag_buf,
                flag_buf.as_slice(),
                &mut relevant_words,
            );
        }

        println!("=============");
        println!("Total tokens in training set: {total_tokens}");
        println!("Tokens incorrectly flagged: {error_counter}");
        println!(
            "Error rate: {}%",
            error_counter as f32 / total_tokens as f32 * 100.
        );

        // Before adding any patches, let's get a good base.
        let mut base_flags = Vec::new();
        for (toks, tags, _) in &sentences_flagged {
            base_flags.push(self.chunk_sentence(toks, tags));
        }

        let all_candidates = Patch::generate_candidate_patches(&relevant_words);
        let mut pruned_candidates: Vec<Patch> = rand::seq::IndexedRandom::choose_multiple(
            all_candidates.as_slice(),
            &mut rand::rng(),
            (all_candidates.len() as f32 * candidate_selection_chance) as usize,
        )
        .cloned()
        .collect();

        let start = Instant::now();

        #[cfg(feature = "threaded")]
        rayon::slice::ParallelSliceMut::par_sort_by_cached_key(
            pruned_candidates.as_mut_slice(),
            |candidate: &Patch| {
                self.score_candidate(candidate.clone(), &sentences_flagged, &base_flags)
            },
        );

        #[cfg(not(feature = "threaded"))]
        pruned_candidates.sort_by_cached_key(|candidate| {
            self.score_candidate(candidate.clone(), &sentences_flagged, &base_flags)
        });

        let duration = start.elapsed();
        let seconds = duration.as_secs();
        let millis = duration.subsec_millis();

        println!(
            "It took {} seconds and {} milliseconds to search through {} candidates at {} c/sec.",
            seconds,
            millis,
            pruned_candidates.len(),
            pruned_candidates.len() as f32 / seconds as f32
        );

        if let Some(best) = pruned_candidates.first() {
            self.patches.push(best.clone());
        }
    }

    /// Lower is better
    fn score_candidate(
        &self,
        candidate: Patch,
        sentences_flagged: &[CandidateArgs],
        base_flags: &[Vec<bool>],
    ) -> usize {
        let mut tagger = BrillChunker::new(UPOSFreqDict::default());
        tagger.patches.push(candidate);

        let mut errors = 0;

        for ((toks, tags, flags), base) in sentences_flagged.iter().zip(base_flags.iter()) {
            errors += tagger.count_patch_errors(toks.as_slice(), tags.as_slice(), base, flags);
        }

        errors
    }

    /// Train a brand-new tagger on a `.conllu` dataset, provided via a path.
    /// This does not do _any_ error handling, and should not run in production.
    /// It should be used for training a model that _will_ be used in production.
    pub fn train(
        training_files: &[impl AsRef<Path>],
        epochs: usize,
        candidate_selection_chance: f32,
    ) -> Self {
        let mut freq_dict = UPOSFreqDict::default();

        for file in training_files {
            freq_dict.inc_from_conllu_file(file);
        }

        let mut chunker = Self::new(freq_dict);

        for _ in 0..epochs {
            chunker.epoch(training_files, candidate_selection_chance);
        }

        chunker
    }
}



================================================
FILE: harper-pos-utils/src/chunker/brill_chunker/patch.rs
================================================
use serde::{Deserialize, Serialize};

use crate::patch_criteria::PatchCriteria;
#[cfg(feature = "training")]
use crate::word_counter::WordCounter;

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Patch {
    pub from: bool,
    pub criteria: PatchCriteria,
}

#[cfg(feature = "training")]
impl Patch {
    pub fn generate_candidate_patches(relevant_words: &WordCounter) -> Vec<Self> {
        use crate::UPOS;
        use strum::IntoEnumIterator;

        const TOP_N_WORDS: usize = 50;
        const REL_POS: [isize; 7] = [-3, -2, -1, 0, 1, 2, 3];

        let mut atoms: Vec<(bool, PatchCriteria)> = Vec::new();

        for from in [false, true] {
            for rel in REL_POS {
                for tag in UPOS::iter() {
                    atoms.push((
                        from,
                        PatchCriteria::WordIsTaggedWith {
                            relative: rel,
                            is_tagged: tag,
                        },
                    ));
                }
            }
            for max_rel in 1..=5 {
                for tag in UPOS::iter() {
                    atoms.push((
                        from,
                        PatchCriteria::AnyWordIsTaggedWith {
                            max_relative: max_rel,
                            is_tagged: tag,
                        },
                    ));
                }
            }
            for prev in UPOS::iter() {
                for post in UPOS::iter() {
                    atoms.push((
                        from,
                        PatchCriteria::SandwichTaggedWith {
                            prev_word_tagged: prev,
                            post_word_tagged: post,
                        },
                    ));
                }
            }
            for rel in REL_POS {
                for is_np in [false, true] {
                    atoms.push((
                        from,
                        PatchCriteria::NounPhraseAt {
                            is_np,
                            relative: rel,
                        },
                    ));
                }
            }
        }

        let tag_atom_count = atoms.len();

        let mut word_atoms: Vec<(bool, PatchCriteria)> = Vec::new();
        for from in [false, true] {
            for rel in REL_POS {
                for w in relevant_words.iter_top_n_words(TOP_N_WORDS) {
                    word_atoms.push((
                        from,
                        PatchCriteria::WordIs {
                            relative: rel,
                            word: w.clone(),
                        },
                    ));
                }
            }
        }

        atoms.extend(word_atoms);

        let total_atoms = atoms.len();
        let word_start = tag_atom_count;
        let word_atoms_ct = total_atoms - word_start;
        let combos_ct = word_atoms_ct * total_atoms - word_atoms_ct;
        let mut patches = Vec::with_capacity(total_atoms + combos_ct);

        for (from, crit) in &atoms {
            patches.push(Self {
                from: *from,
                criteria: crit.clone(),
            });
        }

        for i in word_start..total_atoms {
            let (from_i, ref crit_i) = atoms[i];
            for (j, (_from_j, crit_j)) in atoms.iter().enumerate() {
                if i == j {
                    continue;
                }
                patches.push(Self {
                    from: from_i,
                    criteria: PatchCriteria::Combined {
                        a: Box::new(crit_i.clone()),
                        b: Box::new(crit_j.clone()),
                    },
                });
            }
        }

        patches
    }
}



================================================
FILE: harper-pos-utils/src/tagger/error_counter.rs
================================================
use hashbrown::HashMap;

use crate::{UPOS, word_counter::WordCounter};

#[derive(Debug, Default, Clone, Hash, PartialEq, Eq)]
pub struct ErrorKind {
    pub was_tagged: UPOS,
    pub correct_tag: UPOS,
}

#[derive(Debug, Default)]
pub struct ErrorCounter {
    pub error_counts: HashMap<ErrorKind, usize>,
    /// The number of times a word is associated with an error.
    pub word_counts: WordCounter,
}

impl ErrorCounter {
    pub fn new() -> Self {
        Self::default()
    }

    /// Increment the count for a particular lint kind.
    pub fn inc(&mut self, kind: ErrorKind, word: &str) {
        self.error_counts
            .entry(kind)
            .and_modify(|counter| *counter += 1)
            .or_insert(1);
        self.word_counts.inc(word)
    }

    pub fn merge_from(&mut self, other: Self) {
        for (key, value) in other.error_counts {
            self.error_counts
                .entry(key)
                .and_modify(|counter| *counter += value)
                .or_insert(value);
        }

        for (key, value) in other.word_counts.word_counts {
            self.word_counts
                .word_counts
                .entry(key)
                .and_modify(|counter| *counter += value)
                .or_insert(value);
        }
    }

    pub fn total_errors(&self) -> usize {
        self.error_counts.values().sum()
    }
}



================================================
FILE: harper-pos-utils/src/tagger/freq_dict.rs
================================================
use hashbrown::HashMap;
use serde::{Deserialize, Serialize};

use super::Tagger;
use crate::upos::UPOS;

/// A mapping between words (normalized to lowercase) and their most common UPOS tag.
/// Can be used as a minimally accurate [`Tagger`].
#[derive(Debug, Default, Serialize, Deserialize, Clone)]
pub struct FreqDict {
    pub mapping: HashMap<String, UPOS>,
}

impl FreqDict {
    pub fn get(&self, word: &str) -> Option<UPOS> {
        let word_lower = word.to_lowercase();
        self.mapping.get(word_lower.as_str()).copied()
    }
}

impl Tagger for FreqDict {
    fn tag_sentence(&self, sentence: &[String]) -> Vec<Option<UPOS>> {
        let mut tags = Vec::new();

        for word in sentence {
            let tag = self.get(word);
            tags.push(tag);
        }

        tags
    }
}



================================================
FILE: harper-pos-utils/src/tagger/freq_dict_builder.rs
================================================
#[cfg(feature = "training")]
use std::path::Path;

use hashbrown::{Equivalent, HashMap};
use strum::IntoEnumIterator;

use crate::{UPOS, tagger::FreqDict};

/// A mapping between words and the frequency of each UPOS.
/// If an element is missing from the map, it's count is assumed to be zero.
#[derive(Debug, Default)]
pub struct FreqDictBuilder {
    mapping: HashMap<FreqDictBuilderKey, usize>,
}

impl FreqDictBuilder {
    pub fn new() -> Self {
        Default::default()
    }

    pub fn inc(&mut self, word: &str, tag: &UPOS) {
        let word_lower = word.to_lowercase();
        let counter = self.mapping.get_mut(&(word_lower.as_str(), tag));

        if let Some(counter) = counter {
            *counter += 1;
        } else {
            self.mapping.insert(
                FreqDictBuilderKey {
                    word: word_lower.to_string(),
                    pos: *tag,
                },
                1,
            );
        }
    }

    // Inefficient, but effective method that gets the most used POS for a word in the map.
    // Returns none if the word does not exist in the map.
    fn most_freq_pos(&self, word: &str) -> Option<UPOS> {
        let word_lower = word.to_lowercase();
        let mut max_found: Option<(UPOS, usize)> = None;

        for pos in UPOS::iter() {
            if let Some(count) = self.mapping.get(&(word_lower.as_str(), &pos)) {
                if let Some((_, max_count)) = max_found {
                    if *count > max_count {
                        max_found = Some((pos, *count))
                    }
                } else {
                    max_found = Some((pos, *count))
                }
            }
        }

        max_found.map(|v| v.0)
    }

    /// Parse a `.conllu` file and use it to train a frequency dictionary.
    /// For error-handling purposes, this function should not be made accessible outside of training.
    #[cfg(feature = "training")]
    pub fn inc_from_conllu_file(&mut self, path: impl AsRef<Path>) {
        use crate::conllu_utils::iter_sentences_in_conllu;

        for sent in iter_sentences_in_conllu(path) {
            for token in sent.tokens {
                if let Some(upos) = token.upos.and_then(UPOS::from_conllu) {
                    self.inc(&token.form, &upos)
                }
            }
        }
    }

    pub fn build(self) -> FreqDict {
        let mut output = HashMap::new();

        for key in self.mapping.keys() {
            if output.contains_key(&key.word) {
                continue;
            }

            output.insert(key.word.to_string(), self.most_freq_pos(&key.word).unwrap());
        }

        FreqDict { mapping: output }
    }
}

#[derive(Debug, Eq, PartialEq, Hash)]
struct FreqDictBuilderKey {
    word: String,
    pos: UPOS,
}

impl Equivalent<FreqDictBuilderKey> for (&str, &UPOS) {
    fn equivalent(&self, key: &FreqDictBuilderKey) -> bool {
        self.0 == key.word && *self.1 == key.pos
    }
}



================================================
FILE: harper-pos-utils/src/tagger/mod.rs
================================================
mod brill_tagger;
#[cfg(feature = "training")]
mod error_counter;
mod freq_dict;
mod freq_dict_builder;

use crate::UPOS;

pub use brill_tagger::BrillTagger;
pub use freq_dict::FreqDict;
pub use freq_dict_builder::FreqDictBuilder;

/// An implementer of this trait is capable of assigned Part-of-Speech tags to a provided sentence.
/// This is widely useful for various applications. [See here.](https://en.wikipedia.org/wiki/Part-of-speech_tagging)
pub trait Tagger {
    fn tag_sentence(&self, sentence: &[String]) -> Vec<Option<UPOS>>;
}



================================================
FILE: harper-pos-utils/src/tagger/brill_tagger/mod.rs
================================================
mod patch;

#[cfg(feature = "training")]
use std::path::Path;

use patch::Patch;
use serde::{Deserialize, Serialize};

#[cfg(feature = "training")]
use super::FreqDict;
#[cfg(feature = "training")]
use super::error_counter::{ErrorCounter, ErrorKind};

use crate::{Tagger, UPOS};

/// A [`Tagger`] implementation based on the work by Eric Brill.
///
/// Additional reading:
///
/// - [Brill tagger](https://en.wikipedia.org/wiki/Brill_tagger)
/// - [Transformation-based Learning for POS Tagging](https://elijahpotter.dev/articles/transformation-based-learning)
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct BrillTagger<B>
where
    B: Tagger,
{
    base: B,
    patches: Vec<Patch>,
}

impl<B> BrillTagger<B>
where
    B: Tagger,
{
    pub fn new(base: B) -> Self {
        Self {
            base,
            patches: Vec::new(),
        }
    }

    fn apply_patches(&self, sentence: &[String], tags: &mut [Option<UPOS>]) {
        for patch in &self.patches {
            for i in 0..sentence.len() {
                let Some(i_tag) = tags.get(i).copied().flatten() else {
                    continue;
                };

                if patch.from == i_tag && patch.criteria.fulfils(sentence, tags, &[], i) {
                    tags[i] = Some(patch.to);
                }
            }
        }
    }
}

impl<B> Tagger for BrillTagger<B>
where
    B: Tagger,
{
    /// Tag a sentence using the provided frequency dictionary and current patch set.
    /// If the tagger is unable to determine a POS, it returns [`None`] in that position.
    fn tag_sentence(&self, sentence: &[String]) -> Vec<Option<UPOS>> {
        let mut tags = self.base.tag_sentence(sentence);
        self.apply_patches(sentence, &mut tags);

        tags
    }
}

#[cfg(feature = "training")]
impl BrillTagger<FreqDict> {
    /// Tag a provided sentence with patches, providing the "correct" tags (from a dataset or
    /// other source), returning the number of errors.
    pub fn locate_patch_errors(
        &self,
        sentence: &[String],
        correct_tags: &[Option<UPOS>],
        base_tags: &[Option<UPOS>],
        errors: &mut ErrorCounter,
    ) {
        let mut base_tags = base_tags.to_vec();
        self.apply_patches(sentence, &mut base_tags);

        for ((tag, correct_tag), word) in base_tags.iter().zip(correct_tags.iter()).zip(sentence) {
            if let Some(tag) = tag
                && let Some(correct_tag) = correct_tag
                && tag != correct_tag
            {
                errors.inc(
                    ErrorKind {
                        was_tagged: *tag,
                        correct_tag: *correct_tag,
                    },
                    word.as_str(),
                )
            }
        }
    }

    /// Tag a provided sentence with the tagger, providing the "correct" tags (from a dataset or
    /// other source), returning the number of errors.
    pub fn locate_tag_errors(
        &self,
        sentence: &[String],
        correct_tags: &[Option<UPOS>],
    ) -> ErrorCounter {
        let tags = self.tag_sentence(sentence);

        let mut errors = ErrorCounter::new();

        for ((tag, correct_tag), word) in tags.iter().zip(correct_tags.iter()).zip(sentence) {
            if let Some(tag) = tag
                && let Some(correct_tag) = correct_tag
                && tag != correct_tag
            {
                errors.inc(
                    ErrorKind {
                        was_tagged: *tag,
                        correct_tag: *correct_tag,
                    },
                    word.as_str(),
                )
            }
        }

        errors
    }

    /// To speed up training, only try a subset of all possible candidates.
    /// How many to select is given by the `candidate_selection_chance`. A higher chance means a
    /// longer training time.
    fn epoch(&mut self, training_files: &[impl AsRef<Path>], candidate_selection_chance: f32) {
        use crate::conllu_utils::iter_sentences_in_conllu;
        use rs_conllu::Sentence;
        use std::time::Instant;

        assert!((0.0..=1.0).contains(&candidate_selection_chance));

        let mut total_tokens = 0;
        let mut error_counter = ErrorCounter::new();

        let sentences: Vec<Sentence> = training_files
            .iter()
            .flat_map(iter_sentences_in_conllu)
            .collect();
        let mut sentences_tagged: Vec<(Vec<String>, Vec<Option<UPOS>>)> = Vec::new();

        for sent in &sentences {
            let mut toks: Vec<String> = Vec::new();
            let mut tags = Vec::new();

            for token in &sent.tokens {
                let form = token.form.clone();
                if let Some(last) = toks.last_mut() {
                    match form.as_str() {
                        "sn't" | "n't" | "'ll" | "'ve" | "'re" | "'d" | "'m" | "'s" => {
                            last.push_str(&form);
                            continue;
                        }
                        _ => {}
                    }
                }
                toks.push(form);
                tags.push(token.upos.and_then(UPOS::from_conllu));
            }

            sentences_tagged.push((toks, tags));
        }

        for (tok_buf, tag_buf) in &sentences_tagged {
            total_tokens += tok_buf.len();
            error_counter
                .merge_from(self.locate_tag_errors(tok_buf.as_slice(), tag_buf.as_slice()));
        }

        println!("=============");
        println!("Total tokens in training set: {total_tokens}");
        println!(
            "Tokens incorrectly tagged: {}",
            error_counter.total_errors()
        );
        println!(
            "Error rate: {}%",
            error_counter.total_errors() as f32 / total_tokens as f32 * 100.
        );

        // Before adding any patches, let's get a good base.
        let mut base_tags = Vec::new();
        for (toks, _) in &sentences_tagged {
            base_tags.push(self.tag_sentence(toks));
        }

        let all_candidates = Patch::generate_candidate_patches(&error_counter);
        let mut pruned_candidates: Vec<Patch> = rand::seq::IndexedRandom::choose_multiple(
            all_candidates.as_slice(),
            &mut rand::rng(),
            (all_candidates.len() as f32 * candidate_selection_chance) as usize,
        )
        .cloned()
        .collect();

        let start = Instant::now();

        #[cfg(feature = "threaded")]
        rayon::slice::ParallelSliceMut::par_sort_by_cached_key(
            pruned_candidates.as_mut_slice(),
            |candidate: &Patch| {
                self.score_candidate(candidate.clone(), &sentences_tagged, &base_tags)
            },
        );

        #[cfg(not(feature = "threaded"))]
        pruned_candidates.sort_by_cached_key(|candidate| {
            self.score_candidate(candidate.clone(), &sentences_tagged, &base_tags)
        });

        let duration = start.elapsed();
        let seconds = duration.as_secs();
        let millis = duration.subsec_millis();

        println!(
            "It took {} seconds and {} milliseconds to search through {} candidates at {} c/sec.",
            seconds,
            millis,
            pruned_candidates.len(),
            pruned_candidates.len() as f32 / seconds as f32
        );

        if let Some(best) = pruned_candidates.first() {
            self.patches.push(best.clone());
        }
    }

    /// Lower is better
    fn score_candidate(
        &self,
        candidate: Patch,
        sentences_tagged: &[(Vec<String>, Vec<Option<UPOS>>)],
        base_tags: &[Vec<Option<UPOS>>],
    ) -> usize {
        let mut tagger = BrillTagger::new(FreqDict::default());
        tagger.patches.push(candidate);

        let mut candidate_errors = ErrorCounter::new();

        for ((toks, tags), base) in sentences_tagged.iter().zip(base_tags.iter()) {
            tagger.locate_patch_errors(
                toks.as_slice(),
                tags.as_slice(),
                base,
                &mut candidate_errors,
            );
        }

        candidate_errors.total_errors()
    }

    /// Train a brand-new tagger on a `.conllu` dataset, provided via a path.
    /// This does not do _any_ error handling, and should not run in production.
    /// It should be used for training a model that _will_ be used in production.
    pub fn train(
        training_files: &[impl AsRef<Path>],
        epochs: usize,
        candidate_selection_chance: f32,
    ) -> Self {
        use crate::FreqDictBuilder;

        let mut freq_dict_builder = FreqDictBuilder::new();

        for file in training_files {
            freq_dict_builder.inc_from_conllu_file(file);
        }

        let freq_dict = freq_dict_builder.build();

        let mut tagger = Self::new(freq_dict);

        for _ in 0..epochs {
            tagger.epoch(training_files, candidate_selection_chance);
        }

        tagger
    }
}



================================================
FILE: harper-pos-utils/src/tagger/brill_tagger/patch.rs
================================================
#[cfg(feature = "training")]
use crate::tagger::error_counter::ErrorCounter;
use crate::{UPOS, patch_criteria::PatchCriteria};
#[cfg(feature = "training")]
use hashbrown::HashSet;
use serde::{Deserialize, Serialize};

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Patch {
    pub from: UPOS,
    pub to: UPOS,
    pub criteria: PatchCriteria,
}

#[cfg(feature = "training")]
impl Patch {
    /// Given a list of tagging errors, generate a collection of candidate patches that _might_ fix
    /// them. Training involves determining which candidates actually work.
    pub fn generate_candidate_patches(error_counter: &ErrorCounter) -> Vec<Patch> {
        let mut candidates = Vec::new();

        for key in error_counter.error_counts.keys() {
            candidates.extend(Self::gen_simple_candidates().into_iter().map(|c| Patch {
                from: key.was_tagged,
                to: key.correct_tag,
                criteria: c,
            }));

            for c in &Self::gen_simple_candidates() {
                for word in error_counter.word_counts.iter_top_n_words(10) {
                    for r in -3..3 {
                        candidates.push(Patch {
                            from: key.was_tagged,
                            to: key.correct_tag,
                            criteria: PatchCriteria::Combined {
                                a: Box::new(PatchCriteria::WordIs {
                                    relative: r,
                                    word: word.to_string(),
                                }),
                                b: Box::new(c.clone()),
                            },
                        })
                    }
                }
            }
        }

        candidates
    }

    /// Candidates to be tested against a dataset during training.
    fn gen_simple_candidates() -> Vec<PatchCriteria> {
        use strum::IntoEnumIterator;

        let mut criteria = HashSet::new();
        for upos in UPOS::iter() {
            for i in -4..=4 {
                criteria.insert(PatchCriteria::WordIsTaggedWith {
                    relative: i,
                    is_tagged: upos,
                });
            }

            for i in -4..=4 {
                criteria.insert(PatchCriteria::AnyWordIsTaggedWith {
                    max_relative: i,
                    is_tagged: upos,
                });
            }

            for upos_b in UPOS::iter() {
                criteria.insert(PatchCriteria::SandwichTaggedWith {
                    prev_word_tagged: upos,
                    post_word_tagged: upos_b,
                });

                criteria.insert(PatchCriteria::Combined {
                    a: Box::new(PatchCriteria::WordIsTaggedWith {
                        relative: 1,
                        is_tagged: upos,
                    }),
                    b: Box::new(PatchCriteria::WordIsTaggedWith {
                        relative: -2,
                        is_tagged: upos_b,
                    }),
                });
            }
        }

        criteria.into_iter().collect()
    }
}



================================================
FILE: harper-python/Cargo.toml
================================================
[package]
name = "harper-python"
version = "1.5.1"
edition = "2024"
description = "The language checker for developers."
license = "Apache-2.0"
repository = "https://github.com/automattic/harper"

[dependencies]
harper-core = { path = "../harper-core", version = "1.0.0" }
harper-tree-sitter = { path = "../harper-tree-sitter", version = "1.0.0" }
tree-sitter-python = "0.25.0"
tree-sitter = "0.25.10"

[dev-dependencies]
paste = "1.0.15"



================================================
FILE: harper-python/src/lib.rs
================================================
use harper_core::parsers::{self, Parser, PlainEnglish};
use harper_core::{Token, TokenKind};
use harper_tree_sitter::TreeSitterMasker;
use tree_sitter::Node;

pub struct PythonParser {
    /// Used to grab the text nodes.
    inner: parsers::Mask<TreeSitterMasker, PlainEnglish>,
}

impl PythonParser {
    fn node_condition(n: &Node) -> bool {
        if n.kind().contains("comment") {
            return true;
        }
        if n.kind() == "string_content"
            && let Some(expr_stmt) = parent_is_expression_statement(n)
            && (is_module_level_docstring(&expr_stmt)
                || is_fn_or_class_docstrings(&expr_stmt)
                || is_attribute_docstring(&expr_stmt))
        {
            return true;
        }
        false
    }
}

impl Default for PythonParser {
    fn default() -> Self {
        Self {
            inner: parsers::Mask::new(
                TreeSitterMasker::new(tree_sitter_python::LANGUAGE.into(), Self::node_condition),
                PlainEnglish,
            ),
        }
    }
}

impl Parser for PythonParser {
    fn parse(&self, source: &[char]) -> Vec<Token> {
        let mut tokens = self.inner.parse(source);

        let mut prev_kind: Option<&TokenKind> = None;

        for token in &mut tokens {
            if let TokenKind::Space(v) = &mut token.kind {
                if let Some(TokenKind::Newline(_)) = &prev_kind {
                    // Lines in multiline docstrings are indented with spaces to match the current level.
                    // We need to remove such spaces to avoid triggering French spaces rule.
                    *v = 0;
                } else {
                    *v = (*v).clamp(0, 1);
                }
            }

            prev_kind = Some(&token.kind);
        }

        tokens
    }
}

fn parent_is_expression_statement<'a>(node: &Node<'a>) -> Option<Node<'a>> {
    node.parent()
        .filter(|n| n.kind() == "string")
        .and_then(|string_node| string_node.parent())
        .filter(|n| n.kind() == "expression_statement")
}

#[inline]
fn is_module_level_docstring(expr_stmt: &Node) -> bool {
    // (module . (expression_statement (string)))
    expr_stmt.parent().is_some_and(|n| n.kind() == "module")
}

#[inline]
fn is_fn_or_class_docstrings(expr_stmt: &Node) -> bool {
    // (class/func_definition body: (block . (expression_statement (string))))
    expr_stmt
        .parent()
        .filter(|n| n.kind() == "block")
        .and_then(|n| n.parent())
        .is_some_and(|n| n.kind() == "function_definition" || n.kind() == "class_definition")
}

#[inline]
fn is_attribute_docstring(expr_stmt: &Node) -> bool {
    // ((expression_statement (assignment)) . (expression_statement (string)))
    expr_stmt
        .prev_sibling()
        .filter(|s| s.kind() == "expression_statement")
        .and_then(|s| s.child(0))
        .is_some_and(|c| c.kind() == "assignment")
}



================================================
FILE: harper-python/tests/run_tests.rs
================================================
use harper_core::linting::{LintGroup, Linter};
use harper_core::spell::FstDictionary;
use harper_core::{Dialect, Document};
use harper_python::PythonParser;

/// Creates a unit test checking Python source code parsing.
macro_rules! create_test {
    ($filename:ident.$ext:ident, $correct_expected:expr) => {
        paste::paste! {
            #[test]
            fn [<lints_$ext _ $filename _correctly>](){
                 let source = include_str!(
                    concat!(
                        "./test_sources/",
                        concat!(
                        stringify!($filename), ".", stringify!($ext))
                    )
                 );

                 let parser = PythonParser::default();
                 let dict = FstDictionary::curated();
                 let document = Document::new(&source, &parser, &dict);

                 let mut linter = LintGroup::new_curated(dict, Dialect::American);
                 let lints = linter.lint(&document);

                 dbg!(&lints);
                 assert_eq!(lints.len(), $correct_expected);

                 // Make sure that all generated tokens span real characters
                 for token in document.tokens(){
                     assert!(token.span.try_get_content(document.get_source()).is_some());
                 }
            }
        }
    };
}

create_test!(docstrings.py, 4);
create_test!(field_docstrings.py, 2);
create_test!(comments.py, 1);



================================================
FILE: harper-python/tests/test_sources/comments.py
================================================

# This is a camment.

header = "This is a haeder."

def main():
    welcome_message = "Hellom World!"


================================================
FILE: harper-python/tests/test_sources/docstrings.py
================================================
"""Errors should never passs silently"""
def main():
    """Beautifull is better than ugly."""


class Main:
    """Explicit is better than implicet."""

    def __init__(self):
        """Flat is bettter than nested."""
        pass



def multiline_docstring(action_name: str):
    """Perform the specified action.

    Available actions:
     - stop
     - start
     - pause
    """


================================================
FILE: harper-python/tests/test_sources/field_docstrings.py
================================================
class Result:
    output_path: str
    """The path to the autput file."""
    status: str
    """The stotus of the job."""



================================================
FILE: harper-stats/README.md
================================================
# `harper-stats`

This crate contains the centralized logic for Harper's statistics logging.



================================================
FILE: harper-stats/Cargo.toml
================================================
[package]
name = "harper-stats"
version = "1.5.1"
edition = "2021"
description = "The language checker for developers."
license = "Apache-2.0"
readme = "README.md"
repository = "https://github.com/automattic/harper"

[dependencies]
serde = { version = "1.0.228", features = ["derive"] }
harper-core = { path = "../harper-core", version = "1.0.0", features = ["concurrent"] }
uuid = { version = "1.20.0", features = ["serde", "v4"] }
serde_json = "1.0.149"
chrono = "0.4.43"

[features]
default = []
js = ["uuid/js"]



================================================
FILE: harper-stats/src/lib.rs
================================================
mod record;
mod summary;

use std::io::{self, Read, Write};
use std::io::{BufRead, BufReader};

use harper_core::TokenKind;
pub use record::Record;
pub use record::RecordKind;
use serde::Serialize;
use serde_json::Serializer;
pub use summary::Summary;

/// A collection of logged statistics for the various Harper frontends.
#[derive(Debug, Clone, Eq, PartialEq)]
pub struct Stats {
    pub records: Vec<Record>,
}

impl Stats {
    pub fn new() -> Self {
        Self {
            records: Vec::new(),
        }
    }

    /// Count the number of each kind of lint applied.
    pub fn summarize(&self) -> Summary {
        let mut summary = Summary::new();

        for record in &self.records {
            match &record.kind {
                RecordKind::Lint { kind, context } => {
                    summary.inc_lint_count(*kind);

                    for tok in context {
                        if let TokenKind::Word(None) = tok.kind {
                            summary.inc_misspelled_count(&tok.content);
                        }
                    }
                }
                RecordKind::LintConfigUpdate(lint_group_config) => {
                    summary.final_config = lint_group_config.clone();
                }
            }
        }

        summary
    }

    /// Write the records from `self`.
    /// Expects the target buffer to either be empty or already be terminated by a newline.
    pub fn write(&self, w: &mut impl Write) -> io::Result<()> {
        for record in &self.records {
            let mut serializer = Serializer::new(&mut *w);
            record.serialize(&mut serializer)?;
            writeln!(w)?;
        }

        Ok(())
    }

    /// Read records from a buffer into `self`.
    /// Assumes the buffer is properly formatted and terminated with a newline.
    /// An empty buffer will result in no mutation to `self`.
    pub fn read(r: &mut impl Read) -> io::Result<Self> {
        let br = BufReader::new(r);
        let mut records = Vec::new();

        for line_res in br.lines() {
            let line = line_res?;

            let record: Record = serde_json::from_str(&line)?;
            records.push(record);
        }

        Ok(Self { records })
    }
}

impl Default for Stats {
    fn default() -> Self {
        Self::new()
    }
}



================================================
FILE: harper-stats/src/record.rs
================================================
use harper_core::{
    linting::{Lint, LintGroupConfig, LintKind},
    Document, FatStringToken,
};
use serde::{Deserialize, Serialize};
use uuid::Uuid;

#[derive(Debug, Deserialize, Serialize, Clone, Eq, PartialEq)]
pub struct Record {
    pub kind: RecordKind,
    /// Recorded as seconds from the Unix Epoch
    pub when: i64,
    pub uuid: Uuid,
}

impl Record {
    /// Record a new instance at the current system time.
    pub fn now(kind: RecordKind) -> Self {
        Self {
            kind,
            when: chrono::Utc::now().timestamp(),
            uuid: Uuid::new_v4(),
        }
    }
}

#[derive(Debug, Deserialize, Serialize, Clone, Eq, PartialEq)]
pub enum RecordKind {
    Lint {
        kind: LintKind,
        context: Vec<FatStringToken>,
    },
    LintConfigUpdate(LintGroupConfig),
}

impl RecordKind {
    pub fn from_lint(lint: &Lint, doc: &Document) -> Self {
        Self::Lint {
            kind: lint.lint_kind,
            context: doc
                .fat_tokens_intersecting(lint.span)
                .into_iter()
                .map(|t| t.into())
                .collect(),
        }
    }
}



================================================
FILE: harper-stats/src/summary.rs
================================================
use std::{collections::HashMap, fmt::Display};

use harper_core::linting::{LintGroupConfig, LintKind};
use serde::{Deserialize, Serialize};

#[derive(Debug, Default, Serialize, Deserialize)]
pub struct Summary {
    pub lint_counts: HashMap<LintKind, u32>,
    pub total_applied: u32,
    pub final_config: LintGroupConfig,
    // The most common misspelled words.
    pub misspelled: HashMap<String, u32>,
}

impl Summary {
    pub fn new() -> Self {
        Self::default()
    }

    /// Increment the count for a particular lint kind.
    pub fn inc_lint_count(&mut self, kind: LintKind) {
        self.lint_counts
            .entry(kind)
            .and_modify(|counter| *counter += 1)
            .or_insert(1);
        self.total_applied += 1;
    }

    /// Increment the count for a particular misspelled word.
    pub fn inc_misspelled_count(&mut self, word: impl AsRef<str>) {
        if let Some(counter) = self.misspelled.get_mut(word.as_ref()) {
            *counter += 1
        } else {
            self.misspelled.insert(word.as_ref().to_owned(), 1);
        }
    }

    /// Get the count for a particular lint kind.
    pub fn get_count(&self, kind: LintKind) -> u32 {
        self.lint_counts.get(&kind).copied().unwrap_or(0)
    }
}

impl Display for Summary {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        writeln!(f, "`LintKind` counts")?;
        writeln!(f, "=================")?;

        for (kind, count) in &self.lint_counts {
            writeln!(f, "{kind}\t{count}")?;
        }

        writeln!(f, "Misspelling counts")?;
        writeln!(f, "=================")?;

        let mut misspelled: Vec<_> = self
            .misspelled
            .iter()
            .map(|(a, b)| (a.clone(), *b))
            .collect();

        misspelled.sort_by_key(|(_a, b)| u32::MAX - b);

        for (kind, count) in &misspelled {
            writeln!(f, "{kind}\t{count}")?;
        }

        Ok(())
    }
}



================================================
FILE: harper-thesaurus/build.rs
================================================
#![warn(clippy::pedantic)]

use std::env;
use std::fs::File;
use std::io::{BufReader, BufWriter};
use std::path::Path;

const THESAURUS_PATH: &str = "thesaurus.txt";

fn main() {
    println!("cargo::rerun-if-changed={THESAURUS_PATH}");
    let out_dir = env::var_os("OUT_DIR").unwrap();
    let dest_path = Path::new(&out_dir).join("compressed-thesaurus.zst");

    let in_file = File::open(THESAURUS_PATH).expect("Thesaurus file exists");
    let out_file = File::create(dest_path).expect("Can create output file");
    let reader = BufReader::new(in_file);
    let writer = BufWriter::new(out_file);

    zstd::stream::copy_encode(reader, writer, zstd::zstd_safe::max_c_level())
        .expect("Able to write compressed thesaurus");
}



================================================
FILE: harper-thesaurus/Cargo.toml
================================================
[package]
name = "harper-thesaurus"
version = "1.5.1"
edition = "2024"
description = "The language checker for developers."
license = "Apache-2.0"
repository = "https://github.com/automattic/harper"

[dependencies]
hashbrown = "0.16.0"
indexmap = "2.13.0"
itertools = "0.14.0"
ruzstd = "0.8.2"

[build-dependencies]
zstd = { version = "0.13.3", default-features = false }



================================================
FILE: harper-thesaurus/clippy.toml
================================================
disallowed-types = ["std::collections::HashMap", "std::collections::HashSet"]



================================================
FILE: harper-thesaurus/src/lib.rs
================================================
#![warn(clippy::pedantic)]

mod thesaurus;

pub use thesaurus::thesaurus;



================================================
FILE: harper-thesaurus/src/thesaurus.rs
================================================
use ruzstd::io::Read;
use std::sync::OnceLock;

use hashbrown::HashMap;
use indexmap::IndexSet;
use ruzstd::decoding::StreamingDecoder;

static COMPRESSED_THESAURUS: &[u8] =
    include_bytes!(concat!(env!("OUT_DIR"), "/compressed-thesaurus.zst"));
static RAW_WORD_FREQUENCY_TEXT: &str = include_str!("../word-freq.txt");

/// Gets a read-only reference to the thesaurus.
pub fn thesaurus() -> &'static Thesaurus {
    static THESAURUS: OnceLock<Thesaurus> = OnceLock::new();
    THESAURUS.get_or_init(Thesaurus::new)
}

/// A list of words numbered by frequency of use. The most common word will have a number of 0, and
/// rarer words count up from there.
fn word_freq_map() -> &'static HashMap<String, u32> {
    static WORD_FREQ_LIST: OnceLock<HashMap<String, u32>> = OnceLock::new();
    WORD_FREQ_LIST.get_or_init(|| {
        RAW_WORD_FREQUENCY_TEXT
            .lines()
            .enumerate()
            .map(|(i, word)| (word.to_owned(), u32::try_from(i).unwrap()))
            .collect()
    })
}

pub struct Thesaurus {
    /// Contains the words in the thesaurus and their corresponding synonyms, both as indices into
    /// [`Self::deduped_word_set`].
    entries: HashMap<usize, Vec<usize>>,
    /// Contains (and holds ownership of) all words that occur in the thesaurus, deduped.
    deduped_word_set: IndexSet<String>,
}
impl Thesaurus {
    fn new() -> Thesaurus {
        let mut entries = HashMap::new();
        let mut deduped_word_set = IndexSet::<String>::new();

        let mut decoder = StreamingDecoder::new(COMPRESSED_THESAURUS).unwrap();
        let mut raw_thesaurus_text = Vec::new();
        decoder
            .read_to_end(&mut raw_thesaurus_text)
            .expect("Compressed thesaurus is a valid ZSTD file");

        let raw_thesaurus_text =
            str::from_utf8(&raw_thesaurus_text).expect("Thesaurus content is valid UTF-8");

        for line in raw_thesaurus_text.lines() {
            let mut words = line.split(',');
            let Some(entry_word) = words.next() else {
                // Skip empty lines in thesaurus.
                continue;
            };
            let word_idx = deduped_word_set.get_or_insert_word(entry_word);
            let synonym_indices = words.map(|word| deduped_word_set.get_or_insert_word(word));
            entries
                .try_insert(word_idx, synonym_indices.collect())
                .expect("Only one entry per word in thesaurus");
        }

        Self {
            entries,
            deduped_word_set,
        }
    }

    /// Retrieves a list of synonyms for a given word.
    pub fn get_synonyms(&self, word: &str) -> Option<Vec<&str>> {
        Some(
            self.entries
                .get(&self.deduped_word_set.get_index_of(word)?)?
                .iter()
                .map(|word_idx| -> &str {
                    self.deduped_word_set
                        .get_index(*word_idx)
                        .expect("Deduped word set contains all words in thesaurus")
                })
                .collect(),
        )
    }

    /// Retrieves a list of synonyms, sorted by the frequency of their use.
    pub fn get_synonyms_freq_sorted(&self, word: &str) -> Option<Vec<&str>> {
        let mut syns = self.get_synonyms(word)?;
        syns.sort_unstable_by_key(|syn| {
            word_freq_map()
                .get(&syn.to_ascii_lowercase())
                .unwrap_or(&u32::MAX)
        });
        Some(syns)
    }
}

trait DedupedWordSetExt {
    /// Gets or insert the provided word.
    ///
    /// Returns the index of the word.
    fn get_or_insert_word(&mut self, word: &str) -> usize;
}
impl DedupedWordSetExt for IndexSet<String> {
    fn get_or_insert_word(&mut self, word: &str) -> usize {
        if let Some(idx) = self.get_index_of(word) {
            idx
        } else {
            // Avoid cloning unless we're inserting a new word.
            self.insert_full(word.to_owned()).0
        }
    }
}

#[cfg(test)]
mod tests {
    #[test]
    fn great_is_synonym_of_large() {
        assert!(
            super::thesaurus()
                .get_synonyms("large")
                .is_some_and(|syns| syns.contains(&"great"))
        );
    }
}



================================================
FILE: harper-tree-sitter/Cargo.toml
================================================
[package]
name = "harper-tree-sitter"
version = "1.5.1"
edition = "2024"
description = "The language checker for developers."
license = "Apache-2.0"
repository = "https://github.com/automattic/harper"

[dependencies]
harper-core = { path = "../harper-core", version = "1.0.0" }
tree-sitter = "0.25.10"



================================================
FILE: harper-tree-sitter/src/lib.rs
================================================
use std::collections::HashSet;

use harper_core::spell::MutableDictionary;
use harper_core::{DictWordMetadata, Mask, Masker, Span};
use tree_sitter::{Language, Node, Tree, TreeCursor};

/// A Harper [`Masker`] that wraps a given tree-sitter language and a condition,
/// allowing you to selectively parse only specific tree-sitter nodes.
pub struct TreeSitterMasker {
    language: Language,
    node_condition: fn(&Node) -> bool,
}

impl TreeSitterMasker {
    pub fn new(language: Language, node_condition: fn(&Node) -> bool) -> Self {
        Self {
            language,
            node_condition,
        }
    }

    fn parse_root(&self, text: &str) -> Option<Tree> {
        let mut parser = tree_sitter::Parser::new();
        parser.set_language(&self.language).unwrap();

        // TODO: Use incremental parsing
        parser.parse(text, None)
    }

    pub fn create_ident_dict(&self, source: &[char]) -> Option<MutableDictionary> {
        let text: String = source.iter().collect();

        // Byte-indexed
        let mut ident_spans = Vec::new();

        let tree = self.parse_root(&text)?;
        Self::visit_nodes(&mut tree.walk(), &mut |node: &Node| {
            if node.child_count() == 0 && node.kind().contains("ident") {
                ident_spans.push(node.byte_range().into())
            }
        });

        let ident_spans = byte_spans_to_char_spans(ident_spans, &text);

        let mut idents = HashSet::new();

        for span in ident_spans {
            idents.insert(span.get_content(source));
        }

        let idents: Vec<_> = idents
            .into_iter()
            .map(|ident| (ident, DictWordMetadata::default()))
            .collect();

        let mut dictionary = MutableDictionary::new();
        dictionary.extend_words(idents);

        Some(dictionary)
    }

    /// Visits the children of a TreeSitter node, searching for comments.
    ///
    /// Returns the BYTE spans of the comment position.
    fn extract_comments(&self, cursor: &mut TreeCursor, comments: &mut Vec<Span<u8>>) {
        Self::visit_nodes(cursor, &mut |node: &Node| {
            if (self.node_condition)(node) {
                comments.push(node.byte_range().into());
            }
        });
    }

    fn visit_nodes(cursor: &mut TreeCursor, visit: &mut impl FnMut(&Node)) {
        if !cursor.goto_first_child() {
            return;
        }

        loop {
            let node = cursor.node();

            visit(&node);

            Self::visit_nodes(cursor, visit);

            if !cursor.goto_next_sibling() {
                break;
            }
        }

        cursor.goto_parent();
    }
}

impl Masker for TreeSitterMasker {
    fn create_mask(&self, source: &[char]) -> Mask {
        let text: String = source.iter().collect();

        let Some(root) = self.parse_root(&text) else {
            return Mask::new_blank();
        };

        let mut comments_spans = Vec::new();

        self.extract_comments(&mut root.walk(), &mut comments_spans);
        let comments_spans = byte_spans_to_char_spans(comments_spans, &text);

        let mut mask = Mask::new_blank();

        for span in comments_spans {
            mask.push_allowed(span);
        }

        mask.merge_whitespace_sep(source);

        mask
    }
}

/// Converts a set of byte-indexed [`Span`]s to char-index Spans and returns them.
/// NOTE: Will sort the given slice by their [`Span::start`].
///
/// If any spans overlap, it will merge them.
fn byte_spans_to_char_spans(mut byte_spans: Vec<Span<u8>>, source: &str) -> Vec<Span<char>> {
    byte_spans.sort_unstable_by_key(|s| s.start);

    // merge overlapping spans
    let mut spans = Vec::with_capacity(byte_spans.len());
    for span in byte_spans {
        match spans.last_mut() {
            Some(last) if !span.overlaps_with(*last) => spans.push(span),
            Some(last) => {
                // ranges overlap, we can merge them
                last.end = span.end;
            }
            None => spans.push(span),
        }
    }

    // Convert byte spans to char spans.
    spans
        .iter()
        .scan((0, 0), |(last_byte_pos, last_char_pos), span| {
            let byte_span = *span;

            *last_char_pos += source[*last_byte_pos..byte_span.start].chars().count();
            let start = *last_char_pos;

            *last_char_pos += source[byte_span.start..byte_span.end].chars().count();
            let end = *last_char_pos;

            *last_byte_pos = byte_span.end;
            Some(Span::new(start, end))
        })
        .collect()
}



================================================
FILE: harper-typst/Cargo.toml
================================================
[package]
name = "harper-typst"
version = "1.5.1"
edition = "2024"
description = "The language checker for developers."
license = "Apache-2.0"
repository = "https://github.com/automattic/harper"

[dependencies]
harper-core = { path = "../harper-core", version = "1.0.0" }
typst-syntax = { version = "0.14.2" }
ordered-float = { version = "5.1.0", features = ["serde"] }
itertools = "0.14.0"
paste = "1.0.14"



================================================
FILE: harper-typst/src/lib.rs
================================================
mod offset_cursor;
mod typst_translator;

use typst_translator::TypstTranslator;

use harper_core::{Token, parsers::Parser};
use itertools::Itertools;
use typst_syntax::{
    Source, SyntaxNode,
    ast::{AstNode, Expr, Markup},
};

/// A parser that wraps Harper's `PlainEnglish` parser allowing one to ingest Typst files.
pub struct Typst;

impl Parser for Typst {
    fn parse(&self, source: &[char]) -> Vec<Token> {
        let source_str: String = source.iter().collect();

        // Transform the source into an AST through the `typst_syntax` crate
        let typst_document = Source::detached(source_str);
        let typst_tree = Markup::from_untyped(typst_document.root())
            .expect("Unable to create typst document from parsed tree!");

        // Recurse through AST to create tokens
        let parse_helper = TypstTranslator::new(&typst_document);
        let mut buf = Vec::new();
        let exprs = typst_tree.exprs().collect_vec();
        let exprs = convert_parbreaks(&mut buf, &exprs);
        parse_helper.parse_exprs(&exprs)
    }
}

/// Converts newlines after certain elements to paragraph breaks
/// This is accomplished here instead of in the translating module because at this point there is
/// still semantic information associated with the elements.
///
/// Newlines are separate expressions in the parse tree (as the Space variant)
fn convert_parbreaks<'a>(buf: &'a mut Vec<SyntaxNode>, exprs: &'a [Expr]) -> Vec<Expr<'a>> {
    // Owned collection of nodes forcibly casted to paragraph breaks
    *buf = exprs
        .iter()
        .map(|e| {
            let mut node = SyntaxNode::placeholder(typst_syntax::SyntaxKind::Parbreak);
            node.synthesize(e.span());
            node
        })
        .collect_vec();

    let should_parbreak = |e1, e2, e3| {
        matches!(e2, Expr::Space(_))
            && (matches!(e1, Expr::Heading(_) | Expr::ListItem(_))
                || matches!(e3, Expr::Heading(_) | Expr::ListItem(_)))
    };

    let mut res: Vec<Expr> = Vec::new();
    let mut last_element: Option<Expr> = None;
    for ((i, expr), (_, next_expr)) in exprs.iter().enumerate().tuple_windows() {
        let mut current_expr = *expr;
        if let Some(last_element) = last_element
            && should_parbreak(last_element, *expr, *next_expr)
        {
            let pbreak = typst_syntax::ast::Parbreak::from_untyped(&buf[i])
                .expect("Unable to convert expression to Parbreak");
            current_expr = Expr::Parbreak(pbreak);
        }
        res.push(current_expr);
        last_element = Some(*expr)
    }
    // Push last element because it will be excluded by tuple_windows() above
    if let Some(last) = exprs.iter().last() {
        res.push(*last);
    }

    res
}

#[cfg(test)]
mod tests {
    use super::*;
    use harper_core::parsers::StrParser;

    #[test]
    fn issue_1898() {
        Typst.parse_str("#for ");
        Typst.parse_str("#(.$#$$$. ");
        Typst.parse_str("=#{m\"\".'m\"\"#p#");
    }
}



================================================
FILE: harper-typst/src/offset_cursor.rs
================================================
use typst_syntax::Source;

/// Encapsulation of the translation between byte-based spans and char-based spans. This is used to
/// avoid recomputing the number of characters between the beginning of the file and the current
/// byte since `typst_syntax` uses byte spans while we use char spans.
#[derive(Debug, Clone, Copy)]
pub struct OffsetCursor<'a> {
    doc: &'a Source,
    pub char: usize,
    pub byte: usize,
}

impl<'a> OffsetCursor<'a> {
    pub fn new(doc: &'a Source) -> Self {
        Self {
            doc,
            char: 0,
            byte: 0,
        }
    }

    /// Returns a new [`OffsetCursor`] at the given byte based on the current cursor.
    pub fn push_to(self, new_byte: usize) -> Option<Self> {
        assert!(new_byte >= self.byte);

        if new_byte == self.byte {
            return Some(self);
        }

        Some(Self {
            char: self.char + self.doc.text().get(self.byte..new_byte)?.chars().count(),
            byte: new_byte,
            ..self
        })
    }

    /// Returns a new [`OffsetCursor`] at the beginning of the given [`typst_syntax::Span`] based
    /// on the current cursor.
    pub fn push_to_span(self, span: typst_syntax::Span) -> Option<Self> {
        let new_byte = self.doc.range(span)?.start;

        self.push_to(new_byte)
    }
}



================================================
FILE: harper-typst/src/typst_translator.rs
================================================
use crate::offset_cursor::OffsetCursor;
use harper_core::{
    Punctuation, Token, TokenKind,
    parsers::{PlainEnglish, StrParser},
};
use itertools::Itertools;
use typst_syntax::{
    Source,
    ast::{
        Arg, ArrayItem, AstNode, DestructuringItem, DictItem, Expr, FuncCall, Ident,
        LetBindingKind, Param, Pattern, Spread,
    },
};

/// Directly translate a span ($a) in a Typst source ($doc) to a token.
macro_rules! def_token {
    ($doc:expr, $a:expr, $kind:expr, $offset:ident) => {{
        let range = $doc.range($a.span())?;
        let start = $offset.push_to(range.start)?;
        let end_char_loc = start.push_to(range.end)?.char;

        Some(vec![Token {
            span: harper_core::Span::new(start.char, end_char_loc),
            kind: $kind,
        }])
    }};
}

/// Combine the results of multiple parsing calls.
macro_rules! merge {
    [$($inner:expr),*] => {
        Some(
            [$($inner),*]
                .into_iter()
                .flatten()
                .flatten()
                .collect_vec(),
        )
    };
}

/// Contains values used in parsing so they don't have to be passed around so much.
#[derive(Clone, Copy)]
pub struct TypstTranslator<'a> {
    doc: &'a Source,
}

impl<'a> TypstTranslator<'a> {
    pub fn new(doc: &'a Source) -> Self {
        Self { doc }
    }

    pub fn parse_exprs(self, exprs: &[Expr]) -> Vec<Token> {
        let base_offset = OffsetCursor::new(self.doc);
        let mut tokens = Vec::new();
        let mut index = 0;

        while index < exprs.len() {
            // Treat Text + apostrophe + Text as a single contraction token stream.
            if let Some((mut parsed, consumed)) = self.parse_contraction(exprs, index) {
                tokens.append(&mut parsed);
                index += consumed;
                continue;
            }

            if let Some(mut parsed) = self.parse_expr(exprs[index], base_offset) {
                tokens.append(&mut parsed);
            }
            index += 1;
        }

        tokens
    }

    fn parse_contraction(self, exprs: &[Expr], index: usize) -> Option<(Vec<Token>, usize)> {
        let exprs = exprs.get(index..index + 3)?;
        let [expr1, expr2, expr3] = exprs else {
            return None;
        };

        let (Expr::Text(left), Expr::SmartQuote(quote), Expr::Text(right)) =
            (*expr1, *expr2, *expr3)
        else {
            return None;
        };

        if quote.double() {
            return None;
        }

        let left_char = left.get().chars().last()?;
        let right_char = right.get().chars().next()?;
        if !left_char.is_alphabetic() || !right_char.is_alphabetic() {
            return None;
        }

        let left_range = self.doc.range(left.span())?;
        let quote_range = self.doc.range(quote.span())?;
        let right_range = self.doc.range(right.span())?;
        if left_range.end != quote_range.start || quote_range.end != right_range.start {
            return None;
        }

        let joined = self.doc.text().get(left_range.start..right_range.end)?;
        let offset = OffsetCursor::new(self.doc).push_to_span(left.span())?;
        let parsed = self.parse_english(joined, offset)?;

        Some((parsed, 3))
    }

    /// Use the [`PlainEnglish`] parser to parse plain text from a Typst expression.
    fn parse_english(self, str: impl Into<String>, offset: OffsetCursor) -> Option<Vec<Token>> {
        Some(
            PlainEnglish
                .parse_str(str.into())
                .into_iter()
                .map(|mut t| {
                    t.span.push_by(offset.char);
                    t
                })
                .collect_vec(),
        )
    }

    /// Parse a pattern, one of the elements of Typst syntax
    fn parse_pattern(self, pat: Pattern, offset: OffsetCursor) -> Option<Vec<Token>> {
        /// Simplification of [`def_token!`] that bakes-in local variables
        macro_rules! token {
            ($a:expr, $kind:expr) => {
                def_token!(self.doc, $a, $kind, offset)
            };
        }

        match pat {
            Pattern::Normal(expr) => self.parse_expr(expr, offset),
            Pattern::Placeholder(underscore) => token!(underscore, TokenKind::Unlintable),
            Pattern::Parenthesized(parenthesized) => merge![
                self.parse_expr(parenthesized.expr(), offset),
                self.parse_pattern(parenthesized.pattern(), offset)
            ],
            Pattern::Destructuring(destructuring) => Some(
                destructuring
                    .items()
                    .filter_map(|item| match item {
                        DestructuringItem::Pattern(pattern) => self.parse_pattern(pattern, offset),
                        DestructuringItem::Named(named) => merge![
                            token!(named.name(), TokenKind::Word(None)),
                            self.parse_pattern(named.pattern(), offset)
                        ],
                        DestructuringItem::Spread(spread) => merge![
                            spread
                                .sink_ident()
                                .and_then(|ident| self.parse_ident(ident, offset)),
                            spread
                                .sink_expr()
                                .and_then(|expr| self.parse_expr(expr, offset))
                        ],
                    })
                    .flatten()
                    .collect(),
            ),
        }
    }

    /// Convenience wrapper of [`Self::parse_expr`] that packages the identifier as an expression
    fn parse_ident(self, ident: Ident, offset: OffsetCursor) -> Option<Vec<Token>> {
        self.parse_expr(Expr::Ident(ident), offset)
    }

    /// Do not use for spreads contained in DestructuringItem
    fn parse_spread(self, spread: Spread, offset: OffsetCursor) -> Option<Vec<Token>> {
        merge![
            self.parse_expr(spread.expr(), offset),
            spread
                .sink_ident()
                .and_then(|ident| self.parse_ident(ident, offset))
        ]
    }

    pub fn parse_expr(self, expr: Expr, offset: OffsetCursor) -> Option<Vec<Token>> {
        // Update the offset that will be passed to other functions by moving it to the beginning
        // of the current expression's span.
        let offset = offset.push_to_span(expr.span())?;

        /// Simplification of [`def_token!`] that bakes-in local variables
        macro_rules! token {
            ($a:expr, $kind:expr) => {
                def_token!(self.doc, $a, $kind, offset)
            };
        }

        /// Quickly recurse without needing to pass in local variables.
        /// Matches both single and many expressions.
        macro_rules! recurse {
            ($inner:expr) => {
                self.parse_expr($inner, offset)
            };
            ($($inner:expr),+) => {
                merge![
                    $(recurse!($inner)),*
                ]
            };
        }

        macro_rules! get_text {
            ($expr:expr) => {
                self.doc
                    .text()
                    .get(self.doc.range($expr.span())?)
                    .expect("Unable to get text from typst document span!")
            };
        }

        fn parbreak(pos: usize) -> Option<Vec<Token>> {
            Some(vec![Token {
                span: harper_core::Span::empty(pos),
                kind: TokenKind::ParagraphBreak,
            }])
        }

        fn isolate(inner: Option<Vec<Token>>) -> Option<Vec<Token>> {
            let start = inner.as_ref()?.first().map_or(0, |token| token.span.start);
            let end = inner.as_ref()?.last().map_or(0, |token| token.span.end);
            merge![parbreak(start), inner, parbreak(end)]
        }

        // Recurse on each element of an iterator
        let iter_recurse = |exprs: &mut dyn Iterator<Item = Expr>| {
            let mut buf = Vec::new();
            let exprs = exprs.collect_vec();
            let exprs = super::convert_parbreaks(&mut buf, &exprs);
            Some(
                exprs
                    .into_iter()
                    .filter_map(|e| recurse!(e))
                    .flatten()
                    .collect_vec(),
            )
        };

        // Parse the parameters of a function or closure
        let parse_params = |params: &mut dyn Iterator<Item = Param>| {
            Some(
                params
                    .filter_map(|p| match p {
                        Param::Pos(pattern) => self.parse_pattern(pattern, offset),
                        Param::Named(named) => merge![
                            self.parse_ident(named.name(), offset),
                            recurse!(named.expr())
                        ],
                        Param::Spread(spread) => self.parse_spread(spread, offset),
                    })
                    .flatten()
                    .collect_vec(),
            )
        };

        // Parse the arguments passed to a function or closure call
        let parse_args = |params: &mut dyn Iterator<Item = Arg>| {
            Some(
                params
                    .filter_map(|a| match a {
                        Arg::Pos(expr) => recurse!(expr),
                        Arg::Named(named) => merge![
                            self.parse_ident(named.name(), offset),
                            recurse!(named.expr())
                        ],
                        Arg::Spread(spread) => self.parse_spread(spread, offset),
                    })
                    .flatten()
                    .collect_vec(),
            )
        };

        // Parse a function call
        let parse_func_call = |func: FuncCall| {
            let parse_args_ignored = |ignore_pos: bool, ignore_nameds: &[&str]| {
                let (dead, alive): (Vec<_>, Vec<_>) = func.args().items().partition(|a| match a {
                    Arg::Pos(_) => ignore_pos,
                    Arg::Named(named) => ignore_nameds.contains(&named.name().as_str()),
                    Arg::Spread(_) => false,
                });

                Some(
                    dead.iter()
                        .flat_map(|a| token!(a, TokenKind::Unlintable))
                        .chain(parse_args(&mut alive.into_iter()))
                        .flatten()
                        .collect_vec(),
                )
            };

            let text = get_text!(func.callee());
            merge![
                token!(func.callee(), TokenKind::Unlintable),
                match text {
                    "std.rgb" | "color.rgb" | "rgb" => parse_args_ignored(true, &[]),
                    "std.plugin" | "plugin" => parse_args_ignored(true, &[]),
                    "std.bibliography" | "bibliography" => parse_args_ignored(true, &["style"]),
                    "std.cite" | "cite" => parse_args_ignored(true, &["style"]),
                    "std.raw" | "raw" => parse_args_ignored(false, &["syntaxes", "theme"]),
                    "std.image" | "image" => parse_args_ignored(true, &[]),
                    "std.regex" | "regex" => parse_args_ignored(true, &[]),
                    _ if text.ends_with(".display") => parse_args_ignored(true, &[]),
                    _ => parse_args(&mut func.args().items()),
                }
            ]
        };

        // Delegate parsing based on the kind of Typst expression.
        // Not all expression kinds have defined behavior, so the default behavior is
        // an [`harper_core::TokenKind::Unlintable`] token.
        //
        // A full list of variants is available in the [typst_syntax docs](https://docs.rs/typst/latest/typst/syntax/ast/enum.Expr.html)
        match expr {
            Expr::Text(text) => self.parse_english(text.get(), offset.push_to_span(text.span())?),
            Expr::Space(a) => {
                let mut chars = get_text!(a).chars();
                let first_char = chars.next().unwrap();
                let length = chars.count() + 1;

                if first_char == '\n' {
                    token!(a, TokenKind::Newline(1))
                } else {
                    token!(a, TokenKind::Space(length))
                }
            }
            Expr::Linebreak(a) => token!(a, TokenKind::Newline(1)),
            Expr::Parbreak(a) => token!(a, TokenKind::ParagraphBreak),
            Expr::SmartQuote(quote) => {
                if quote.double() {
                    token!(
                        quote,
                        TokenKind::Punctuation(Punctuation::Quote(harper_core::Quote {
                            twin_loc: None
                        }))
                    )
                } else {
                    token!(quote, TokenKind::Punctuation(Punctuation::Apostrophe))
                }
            }
            Expr::Strong(strong) => iter_recurse(&mut strong.body().exprs()),
            Expr::Emph(emph) => iter_recurse(&mut emph.body().exprs()),
            Expr::Link(a) => token!(a, TokenKind::Url),
            Expr::Heading(heading) => iter_recurse(&mut heading.body().exprs()),
            Expr::ListItem(list_item) => iter_recurse(&mut list_item.body().exprs()),
            Expr::EnumItem(enum_item) => iter_recurse(&mut enum_item.body().exprs()),
            Expr::TermItem(term_item) => iter_recurse(
                &mut term_item
                    .term()
                    .exprs()
                    .chain(term_item.description().exprs()),
            ),
            Expr::Str(text) => {
                let offset = offset.push_to_span(text.span())?.char + 1;
                let string = text.to_untyped().text();

                Some(
                    PlainEnglish
                        .parse_str(&string[1..string.len() - 1])
                        .into_iter()
                        .map(|mut t| {
                            t.span.push_by(offset);
                            t
                        })
                        .collect_vec(),
                )
            }
            Expr::ContentBlock(content_block) => {
                isolate(iter_recurse(&mut content_block.body().exprs()))
            }
            Expr::Parenthesized(parenthesized) => recurse!(parenthesized.expr()),
            Expr::Array(array) => Some(
                array
                    .items()
                    .filter_map(|i| {
                        if let ArrayItem::Pos(e) = i {
                            recurse!(e)
                        } else {
                            None
                        }
                    })
                    .flatten()
                    .collect_vec(),
            ),
            Expr::Dict(dict) => Some(
                dict.items()
                    .filter_map(|di| match di {
                        DictItem::Named(named) => {
                            merge![
                                self.parse_ident(named.name(), offset),
                                recurse!(named.expr())
                            ]
                        }
                        DictItem::Keyed(keyed) => recurse!(keyed.key(), keyed.expr()),
                        DictItem::Spread(spread) => self.parse_spread(spread, offset),
                    })
                    .flatten()
                    .collect_vec(),
            ),
            Expr::FieldAccess(field_access) => merge![
                recurse!(field_access.target()),
                token!(field_access.field(), TokenKind::Word(None))
            ],
            Expr::LetBinding(let_binding) => merge![
                match let_binding.kind() {
                    LetBindingKind::Normal(pattern) => self.parse_pattern(pattern, offset),
                    LetBindingKind::Closure(ident) => self.parse_ident(ident, offset),
                },
                let_binding.init().and_then(|e| recurse!(e))
            ],
            Expr::DestructAssignment(destruct_assignment) => {
                recurse!(destruct_assignment.value())
            }
            Expr::SetRule(set_rule) => merge![
                recurse!(set_rule.target()),
                set_rule.condition().and_then(|expr| recurse!(expr)),
                parse_args(&mut set_rule.args().items())
            ],
            Expr::ShowRule(show_rule) => merge![
                recurse!(show_rule.transform()),
                show_rule.selector().and_then(|expr| recurse!(expr))
            ],
            Expr::Contextual(contextual) => recurse!(contextual.body()),
            Expr::Conditional(conditional) => merge![
                recurse!(conditional.condition(), conditional.if_body()),
                conditional.else_body().and_then(|expr| recurse!(expr))
            ],
            Expr::WhileLoop(while_loop) => recurse!(while_loop.condition(), while_loop.body()),
            Expr::ForLoop(for_loop) => recurse!(for_loop.iterable(), for_loop.body()),
            Expr::CodeBlock(code) => iter_recurse(&mut code.body().exprs()),
            Expr::Closure(closure) => merge![
                closure
                    .name()
                    .and_then(|ident| self.parse_ident(ident, offset)),
                parse_params(&mut closure.params().children()),
                recurse!(closure.body())
            ],
            Expr::FuncCall(func) => parse_func_call(func),
            a => token!(a, TokenKind::Unlintable),
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use typst_syntax::ast::None;

    #[test]
    fn parse_none_returns_none() {
        let source = Source::detached("");
        let translator = TypstTranslator::new(&source);

        assert!(
            translator
                .parse_expr(Expr::None(None::default()), OffsetCursor::new(&source))
                .is_none()
        )
    }
}



================================================
FILE: harper-typst/tests/run_tests.rs
================================================
use harper_core::linting::{LintGroup, Linter};
use harper_core::spell::FstDictionary;
use harper_core::{Dialect, Document};
use harper_typst::Typst;

/// Creates a unit test checking that the linting of a document in
/// `tests_sources` produces the expected number of lints.
macro_rules! create_test {
    ($filename:ident.$ext:ident, $correct_expected:expr) => {
        paste::paste! {
            #[test]
            fn [<lints_ $filename _correctly>](){
                 let source = include_str!(
                    concat!(
                        "./test_sources/",
                        concat!(stringify!($filename), ".", stringify!($ext))
                    )
                 );

                 let dict = FstDictionary::curated();
                 let document = Document::new(&source, &Typst, &dict);

                 let mut linter = LintGroup::new_curated(dict, Dialect::American);
                 let lints = linter.lint(&document);

                 dbg!(&lints);
                 assert_eq!(lints.len(), $correct_expected);

                 // Make sure that all generated tokens span real characters
                 for token in document.tokens(){
                     assert!(token.span.try_get_content(document.get_source()).is_some());
                 }
            }
        }
    };
}

create_test!(complex_document.typ, 0);
create_test!(simplified_document.typ, 0);
create_test!(complex_document_with_spelling_mistakes.typ, 4);
// create_test!(issue_399.typ, 3);
create_test!(function_with_ignorable_args.typ, 9);
create_test!(issue_1926.typ, 1);
create_test!(contractions.typ, 0);



================================================
FILE: harper-typst/tests/tests.rs
================================================
use itertools::Itertools;
use ordered_float::OrderedFloat;

use harper_core::{DictWordMetadata, Document, NounData, Number, Punctuation, TokenKind};
use harper_typst::Typst;

#[test]
fn number() {
    let source = "12 is larger than 11, but much less than 11!";

    let document = Document::new_curated(source, &Typst);
    let token_kinds = document.tokens().map(|t| t.kind.clone()).collect_vec();
    dbg!(&token_kinds);

    assert!(matches!(
        token_kinds.as_slice(),
        &[
            TokenKind::Number(Number {
                value: OrderedFloat(12.0),
                suffix: None,
                ..
            }),
            TokenKind::Space(1),
            TokenKind::Word(_),
            TokenKind::Space(1),
            TokenKind::Word(_),
            TokenKind::Space(1),
            TokenKind::Word(_),
            TokenKind::Space(1),
            TokenKind::Number(Number {
                value: OrderedFloat(11.0),
                suffix: None,
                ..
            }),
            TokenKind::Punctuation(Punctuation::Comma),
            TokenKind::Space(1),
            TokenKind::Word(_),
            TokenKind::Space(1),
            TokenKind::Word(_),
            TokenKind::Space(1),
            TokenKind::Word(_),
            TokenKind::Space(1),
            TokenKind::Word(_),
            TokenKind::Space(1),
            TokenKind::Number(Number {
                value: OrderedFloat(11.0),
                suffix: None,
                ..
            }),
            TokenKind::Punctuation(Punctuation::Bang),
        ]
    ))
}

#[test]
fn math_unlintable() {
    let source = "$12 > 11$, $12 << 11!$";

    let document = Document::new_curated(source, &Typst);
    let token_kinds = document.tokens().map(|t| t.kind.clone()).collect_vec();
    dbg!(&token_kinds);

    assert!(matches!(
        token_kinds.as_slice(),
        &[
            TokenKind::Unlintable,
            TokenKind::Punctuation(Punctuation::Comma),
            TokenKind::Space(1),
            TokenKind::Unlintable,
        ]
    ))
}

#[test]
fn dict_parsing() {
    let source = r#"#let dict = (
                          name: "Typst",
                          born: 2019,
                        )"#;

    let document = Document::new_curated(source, &Typst);
    let token_kinds = document.tokens().map(|t| t.kind.clone()).collect_vec();
    dbg!(&token_kinds);

    let charslice = source.chars().collect_vec();
    let tokens = document.tokens().collect_vec();
    assert_eq!(tokens[2].span.get_content_string(&charslice), "Typst");

    assert!(matches!(
        token_kinds.as_slice(),
        &[
            TokenKind::Unlintable, // dict
            TokenKind::Unlintable, // name (key 1)
            TokenKind::Word(_),    // Typst (value 1)
            TokenKind::Unlintable, // born (key 2)
            TokenKind::Unlintable, // 2019 (value 2)
        ]
    ))
}

#[test]
fn str_parsing() {
    let source = r#"#let ident = "This is a string""#;

    let document = Document::new_curated(source, &Typst);
    let token_kinds = document.tokens().map(|t| t.kind.clone()).collect_vec();
    dbg!(&token_kinds);

    assert!(matches!(
        &token_kinds.as_slice(),
        &[
            TokenKind::Unlintable, // ident
            TokenKind::Word(_),    // This
            TokenKind::Space(1),   //
            TokenKind::Word(_),    // is
            TokenKind::Space(1),   //
            TokenKind::Word(_),    // a
            TokenKind::Space(1),   //
            TokenKind::Word(_),    // string
        ]
    ))
}

#[test]
fn non_adjacent_spaces_not_condensed() {
    let source = r#"#authors_slice.join(", ", last: ", and ")  bob"#;

    let document = Document::new_curated(source, &Typst);
    let token_kinds = document.tokens().map(|t| t.kind.clone()).collect_vec();
    dbg!(&token_kinds);

    assert!(matches!(
        &token_kinds.as_slice(),
        &[
            TokenKind::Unlintable, // authors_slice.join
            TokenKind::Punctuation(Punctuation::Comma),
            TokenKind::Space(1),
            TokenKind::Unlintable, // last
            TokenKind::Punctuation(Punctuation::Comma),
            TokenKind::Space(1),
            TokenKind::Word(_), // and
            TokenKind::Space(1),
            TokenKind::Space(2),
            TokenKind::Word(_), // bob
        ]
    ))
}

#[test]
fn header_parsing() {
    let source = "= Header
                      Paragraph";

    let document = Document::new_curated(source, &Typst);
    let token_kinds = document.tokens().map(|t| t.kind.clone()).collect_vec();
    dbg!(&token_kinds);

    let charslice = source.chars().collect_vec();
    let tokens = document.tokens().collect_vec();
    assert_eq!(tokens[0].span.get_content_string(&charslice), "Header");
    assert_eq!(tokens[2].span.get_content_string(&charslice), "Paragraph");

    assert!(matches!(
        &token_kinds.as_slice(),
        &[
            TokenKind::Word(_),
            TokenKind::ParagraphBreak,
            TokenKind::Word(_)
        ]
    ))
}

#[test]
fn parbreak() {
    let source = "Paragraph

                      Paragraph";

    let document = Document::new_curated(source, &Typst);
    let token_kinds = document.tokens().map(|t| t.kind.clone()).collect_vec();
    dbg!(&token_kinds);

    assert!(matches!(
        &token_kinds.as_slice(),
        &[
            TokenKind::Word(_),
            TokenKind::ParagraphBreak,
            TokenKind::Word(_),
        ]
    ))
}

#[test]
fn label_ref_unlintable() {
    let source = "= Header
                      <label>
                      Paragraph @label";

    let document = Document::new_curated(source, &Typst);
    let token_kinds = document.tokens().map(|t| t.kind.clone()).collect_vec();
    dbg!(&token_kinds);

    assert!(matches!(
        &token_kinds.as_slice(),
        &[
            TokenKind::Word(_),
            TokenKind::ParagraphBreak,
            TokenKind::Unlintable,
            TokenKind::Newline(_),
            TokenKind::Word(_),
            TokenKind::Space(_),
            TokenKind::Unlintable,
        ]
    ))
}

#[test]
fn sentence() {
    let source = "This is a sentence, it is not interesting.";

    let document = Document::new_curated(source, &Typst);
    let token_kinds = document.tokens().map(|t| t.kind.clone()).collect_vec();
    dbg!(&token_kinds);

    assert!(matches!(
        token_kinds.as_slice(),
        &[
            TokenKind::Word(_),
            TokenKind::Space(1),
            TokenKind::Word(_),
            TokenKind::Space(1),
            TokenKind::Word(_),
            TokenKind::Space(1),
            TokenKind::Word(_),
            TokenKind::Punctuation(Punctuation::Comma),
            TokenKind::Space(1),
            TokenKind::Word(_),
            TokenKind::Space(1),
            TokenKind::Word(_),
            TokenKind::Space(1),
            TokenKind::Word(_),
            TokenKind::Space(1),
            TokenKind::Word(_),
            TokenKind::Punctuation(Punctuation::Period),
        ]
    ))
}

#[test]
fn smart_apostrophe_newline() {
    let source = "group’s
                      writing";

    let document = Document::new_curated(source, &Typst);
    let token_kinds = document.tokens().map(|t| t.kind.clone()).collect_vec();
    dbg!(&token_kinds);

    let charslice = source.chars().collect_vec();
    let tokens = document.tokens().collect_vec();
    assert_eq!(tokens[2].span.get_content_string(&charslice), "writing");

    assert!(matches!(
        token_kinds.as_slice(),
        &[
            TokenKind::Word(Some(DictWordMetadata {
                noun: Some(NounData {
                    is_possessive: Some(true),
                    ..
                }),
                ..
            })),
            TokenKind::Newline(1),
            TokenKind::Word(_),
        ]
    ));
}

#[test]
fn newline_in_paragraph() {
    let source = "Paragraph with
newlines
not paragraph breaks";

    let document = Document::new_curated(source, &Typst);
    let token_kinds = document.tokens().map(|t| t.kind.clone()).collect_vec();
    dbg!(&token_kinds);

    assert!(matches!(
        &token_kinds.as_slice(),
        &[
            TokenKind::Word(_), // Paragraph
            TokenKind::Space(_),
            TokenKind::Word(_), // with
            TokenKind::Newline(1),
            TokenKind::Word(_), // newlines
            TokenKind::Newline(1),
            TokenKind::Word(_), // not
            TokenKind::Space(_),
            TokenKind::Word(_), // paragraph
            TokenKind::Space(_),
            TokenKind::Word(_), // breaks
        ]
    ))
}

#[test]
fn parbreaks_in_list() {
    let source = "This is a list:
- p1
- p2
- p3";

    let document = Document::new_curated(source, &Typst);
    let token_kinds = document.tokens().map(|t| t.kind.clone()).collect_vec();
    dbg!(&token_kinds);

    assert!(matches!(
        &token_kinds.as_slice(),
        &[
            TokenKind::Word(_), // This
            TokenKind::Space(_),
            TokenKind::Word(_), // is
            TokenKind::Space(_),
            TokenKind::Word(_), // a
            TokenKind::Space(_),
            TokenKind::Word(_), // list
            TokenKind::Punctuation(Punctuation::Colon),
            TokenKind::ParagraphBreak,
            TokenKind::Word(_),
            TokenKind::ParagraphBreak,
            TokenKind::Word(_),
            TokenKind::ParagraphBreak,
            TokenKind::Word(_)
        ]
    ))
}



================================================
FILE: harper-typst/tests/test_sources/complex_document.typ
================================================
#set page(
  paper: "us-letter",
  columns: 2,
)

#let titleblock(
  title: "Default Title",
  authors: ("Author 1", "Author 2"),
  abstract: [*This is content*],
  body,
) = {
  set document(date: none)
  set par(justify: true)
  set page(
    header: context {
      if counter(page).get().first() > 1 [
        #counter(page).get().first() of #counter(page).final().at(0)
        #h(1fr)
        #title
      ]
    },
  )
  place(
    top + center,
    float: true,
    scope: "parent",
    clearance: 2em,
  )[
    #align(center, text(17pt)[
      *#title*
    ])

    #let authors = authors.filter(x => x.len() > 0)
    #let count = authors.len()
    #let authors_slice = authors.slice(0, calc.min(count, 3))
    _#if count > 3 {
        // et al. isn't parsed properly, but this isn't the fault of the Typst
        // parser
        // authors_slice.push("et al.")
        authors_slice.join(", ")
      } else {
        authors_slice.join(", ", last: ", and ")
      }
    _

    #par(justify: false)[
      *Abstract* \
      #abstract
    ]
  ]
  body
}

#show: doc => [
  #titleblock(
    title: "A fluid dynamic model for glacier flow",
    authors: ("Grant Lemons", "John Doe", "Jane Doe"),
    abstract: lorem(80),
    doc,
  )
]

= Introduction
#lorem(300)

= Related Work
#lorem(200)



================================================
FILE: harper-typst/tests/test_sources/complex_document_with_spelling_mistakes.typ
================================================
#set page(
  paper: "us-letter",
  columns: 2,
)

#let titleblock(
  title: "Defalt Title",
  authors: ("Author 1", "Author 2"),
  abstract: [*This is contnt*],
  body,
) = {
  set document(date: none)
  set par(justify: true)
  set page(
    header: context {
      if counter(page).get().first() > 1 [
        #counter(page).get().first() of #counter(page).final().at(0)
        #h(1fr)
        #title
      ]
    },
  )
  place(
    top + center,
    float: true,
    scope: "parent",
    clearance: 2em,
  )[
    #align(center, text(17pt)[
      *#title*
    ])

    #let authors = authors.filter(x => x.len() > 0)
    #let count = authors.len()
    #let authors_slice = authors.slice(0, calc.min(count, 3))
    _#if count > 3 {
        // et al. isn't parsed properly, but this isn't the fault of the Typst
        // parser
        // authors_slice.push("et al.")
        authors_slice.join(", ")
      } else {
        authors_slice.join(", ", last: ", and ")
      }
    _

    #par(justify: false)[
      *Abstract* \
      #abstract
    ]
  ]
  body
}

#show: doc => [
  #titleblock(
    title: "A fluid dynamic model for glaier flow",
    authors: ("Grant Lemons", "John Doe", "Jane Doe"),
    abstract: lorem(80),
    doc,
  )
]

= Introduction
#lorem(300)

= Related ork
#lorem(200)



================================================
FILE: harper-typst/tests/test_sources/contractions.typ
================================================
Typst used to have problems with contractions. Doesn't it still?



================================================
FILE: harper-typst/tests/test_sources/function_with_ignorable_args.typ
================================================
#rgb("ffffff")
#plugin("../a.wasm")
#bibliography(("../a.bib", "../b.bib"), style: "../c.csl", title: [Errorz])
#cite(style: "../a.csl", supplement: [Errorz])
#raw(syntaxes: ("../a", "../b"), theme: "../c", [Errorz])
#image("../a", caption: [Errorz])
#regex("(?i)")
#std.rgb("ffffff")
#color.rgb("ffffff")
#std.plugin("../a.wasm")
#std.bibliography(("../a.bib", "../b.bib"), style: "../c.csl", title: [Errorz])
#std.cite(style: "../a.csl", supplement: [Errorz])
#std.raw(syntaxes: ("../a", "../b"), theme: "../c", [Errorz])
#std.image("../a", caption: [Errorz])
#std.regex("(?i)")
#datetime.today().display("y:[year repr:last_two]")
#context counter(heading).display("i", both: [Errorz])



================================================
FILE: harper-typst/tests/test_sources/issue_1926.typ
================================================
No No
#table(
  columns: 2,
  [No], [No]
)



================================================
FILE: harper-typst/tests/test_sources/issue_399.typ
================================================
#problem[
	4. Find all the $x$ values where the following function is discontinuous.
]

#solution[
	$x=-2,0,3$
]

#aside[
	at $x=-2$ jump discontinuity. 

	at $x=0$ infinite discontinuity.

	at $x=3$ removable discontinuity. (can be removed via re-defining the domain to exclude that)
]



================================================
FILE: harper-typst/tests/test_sources/simplified_document.typ
================================================
#let template(
  title: "Default Title",
  authors: ("Author 1", "Author 2"),
  abstract: [*This is content*],
  body,
) = {
  set document(date: none)
  set par(justify: true)
  set page(
    paper: "us-letter",
    columns: 2,
    number-align: top,
    numbering: (..n) => if n.pos().first() > 1 {
      n.pos().map(str).join(" of ") + h(1fr) + title
    },
  )

  place(
    top + center,
    float: true,
    scope: "parent",
    clearance: 2em,
  )[
    #text(17pt, strong(title))

    #let authors-line = if authors.len() > 3 {
      // "et al." isn't parsed properly, but this isn't the fault of the Typst
      // parser.
      // authors-max3.push("et al.")
      authors => authors.join(", ")
    } else {
      authors => authors.join(", ", last: ", and ")
    }
    #emph(authors-line(authors.slice(0, calc.min(authors.len(), 3))))

    #par(justify: false)[
      *Abstract* \
      #abstract
    ]
  ]

  body
}

#show: template.with(
  title: "A fluid dynamic model for glacier flow",
  authors: ("Grant Lemons", "John Doe", "Jane Doe"),
  abstract: lorem(80),
)

= Introduction
#lorem(300)

= Related Work
#lorem(200)



================================================
FILE: harper-wasm/README.md
================================================
# `harper-wasm`

`harper-wasm` is the WebAssembly-compiled version of the [Harper](https://github.com/automattic/harper) grammar checker.

Currently, the API exists to meet the needs of both the [web demo](https://writewithharper.com) and the Obsidian plugin.



================================================
FILE: harper-wasm/Cargo.toml
================================================
[package]
name = "harper-wasm"
version = "0.1.0"
edition = "2024"
publish = false
repository = "https://github.com/automattic/harper"

[lib]
crate-type = ["cdylib", "rlib"]

[dependencies]
console_error_panic_hook = "0.1.7"
tracing = "0.1.44"
tracing-wasm = "0.2.1"
wasm-bindgen = "0.2.97"
harper-core = { path = "../harper-core", version = "1.0.0", features = ["concurrent"] }
harper-typst = { path = "../harper-typst", version = "1.0.0" }
once_cell = "1.21.3"
serde-wasm-bindgen = "0.6.5"
serde_json = "1.0.149"
serde = { version = "1.0.228", features = ["derive"] }
getrandom = { version = "0.3.4", default-features = false, features = ["wasm_js"] }
harper-stats = { path = "../harper-stats", version = "1.0.0", features = ["js"] }

[dev-dependencies]
sysinfo = { version = "0.38.0", default-features = false, features = [ "system" ] }



================================================
FILE: harper-wasm/src/lib.rs
================================================
#![doc = include_str!("../README.md")]

use std::convert::Into;
use std::io::Cursor;
use std::sync::Arc;

use harper_core::DialectFlags;
use harper_core::language_detection::is_doc_likely_english;
use harper_core::linting::{LintGroup, Linter as _};
use harper_core::parsers::{IsolateEnglish, Markdown, OopsAllHeadings, Parser, PlainEnglish};
use harper_core::remove_overlaps_map;
use harper_core::{
    CharString, DictWordMetadata, Document, IgnoredLints, LintContext, Lrc, remove_overlaps,
    spell::{Dictionary, FstDictionary, MergedDictionary, MutableDictionary},
};
use harper_stats::{Record, RecordKind, Stats};
use harper_typst::Typst;
use serde::{Deserialize, Serialize};
use serde_wasm_bindgen::Serializer;
use wasm_bindgen::JsValue;
use wasm_bindgen::prelude::wasm_bindgen;

/// Setup the WebAssembly module's logging.
#[wasm_bindgen(start)]
pub fn setup() {
    console_error_panic_hook::set_once();

    // If `setup` gets called more than once, we want to allow this error to fall through.
    let _ = tracing_wasm::try_set_as_global_default();
}

macro_rules! make_serialize_fns_for {
    ($name:ident) => {
        #[wasm_bindgen]
        impl $name {
            pub fn to_json(&self) -> String {
                serde_json::to_string(&self).unwrap()
            }

            pub fn from_json(json: String) -> Result<Self, String> {
                serde_json::from_str(&json).map_err(|err| err.to_string())
            }
        }
    };
}

make_serialize_fns_for!(Suggestion);
make_serialize_fns_for!(Lint);
make_serialize_fns_for!(Span);

#[wasm_bindgen]
#[derive(Serialize, Deserialize, Debug, Copy, Clone)]
pub enum Language {
    Plain,
    Markdown,
    Typst,
}

impl Language {
    fn create_parser(&self) -> Box<dyn Parser> {
        match self {
            Language::Plain => Box::new(PlainEnglish),
            // TODO: Have a way to configure the Markdown parser
            Language::Markdown => Box::new(Markdown::default()),
            Language::Typst => Box::new(Typst),
        }
    }
}

/// Specifies an English Dialect, often used for linting.
#[wasm_bindgen]
#[derive(Serialize, Deserialize, Debug, Clone, Copy)]
pub enum Dialect {
    American,
    British,
    Australian,
    Canadian,
    Indian,
}

impl From<Dialect> for harper_core::Dialect {
    fn from(dialect: Dialect) -> Self {
        match dialect {
            Dialect::American => harper_core::Dialect::American,
            Dialect::Canadian => harper_core::Dialect::Canadian,
            Dialect::Australian => harper_core::Dialect::Australian,
            Dialect::British => harper_core::Dialect::British,
            Dialect::Indian => harper_core::Dialect::Indian,
        }
    }
}

#[wasm_bindgen]
pub struct Linter {
    lint_group: LintGroup,
    /// The user-supplied dictionary.
    ///
    /// To make changes affect linting, run [`Self::synchronize_lint_dict`].
    user_dictionary: MutableDictionary,
    dictionary: Arc<MergedDictionary>,
    ignored_lints: IgnoredLints,
    dialect: Dialect,
    stats: Stats,
}

#[wasm_bindgen]
impl Linter {
    /// Construct a new `Linter`.
    /// Note that this can mean constructing the curated dictionary, which is the most expensive operation
    /// in Harper.
    pub fn new(dialect: Dialect) -> Self {
        let dictionary = Self::construct_merged_dict(MutableDictionary::default());
        let lint_group = LintGroup::new_curated_empty_config(dictionary.clone(), dialect.into());

        Self {
            lint_group,
            user_dictionary: MutableDictionary::new(),
            dictionary,
            ignored_lints: IgnoredLints::default(),
            dialect,
            stats: Stats::default(),
        }
    }

    /// Update the dictionary inside [`Self::lint_group`] to include [`Self::user_dictionary`].
    /// This clears any linter caches, so use it sparingly.
    fn synchronize_lint_dict(&mut self) {
        let mut lint_config = self.lint_group.config.clone();
        self.dictionary = Self::construct_merged_dict(self.user_dictionary.clone());
        self.lint_group =
            LintGroup::new_curated_empty_config(self.dictionary.clone(), self.dialect.into());
        self.lint_group.config.merge_from(&mut lint_config);
    }

    /// Construct the actual dictionary to be used for linting and parsing from the curated dictionary
    /// and [`Self::user_dictionary`].
    fn construct_merged_dict(user_dictionary: MutableDictionary) -> Arc<MergedDictionary> {
        let mut lint_dict = MergedDictionary::new();

        lint_dict.add_dictionary(FstDictionary::curated());
        lint_dict.add_dictionary(Arc::new(user_dictionary));

        Arc::new(lint_dict)
    }

    /// Helper method to quickly check if a plain string is likely intended to be English
    pub fn is_likely_english(&self, text: String) -> bool {
        let document = Document::new_plain_english(&text, &self.dictionary);
        is_doc_likely_english(&document, &self.dictionary)
    }

    /// Helper method to remove non-English text from a plain English document.
    pub fn isolate_english(&self, text: String) -> String {
        let document = Document::new(
            &text,
            &IsolateEnglish::new(Box::new(PlainEnglish), self.dictionary.clone()),
            &self.dictionary,
        );

        document.to_string()
    }

    /// Get a JSON map containing the descriptions of all the linting rules, formatted as HTML.
    pub fn get_lint_descriptions_html_as_json(&self) -> String {
        serde_json::to_string(&self.lint_group.all_descriptions_html()).unwrap()
    }

    /// Get a Record containing the descriptions of all the linting rules, formatted as HTML.
    pub fn get_lint_descriptions_html_as_object(&self) -> JsValue {
        let serializer = Serializer::json_compatible();
        self.lint_group
            .all_descriptions_html()
            .serialize(&serializer)
            .unwrap()
    }

    /// Get a JSON map containing the descriptions of all the linting rules, formatted as Markdown.
    pub fn get_lint_descriptions_as_json(&self) -> String {
        serde_json::to_string(&self.lint_group.all_descriptions()).unwrap()
    }

    /// Get a Record containing the descriptions of all the linting rules, formatted as Markdown.
    pub fn get_lint_descriptions_as_object(&self) -> JsValue {
        let serializer = Serializer::json_compatible();
        self.lint_group
            .all_descriptions()
            .serialize(&serializer)
            .unwrap()
    }

    pub fn get_lint_config_as_json(&self) -> String {
        serde_json::to_string(&self.lint_group.config).unwrap()
    }

    pub fn set_lint_config_from_json(&mut self, json: String) -> Result<(), String> {
        self.lint_group.config = serde_json::from_str(&json).map_err(|v| v.to_string())?;
        Ok(())
    }

    pub fn summarize_stats(&self, start_time: Option<i64>, end_time: Option<i64>) -> JsValue {
        let mut operable_copy = self.stats.clone();

        if let Some(start_time) = start_time {
            operable_copy.records.retain(|i| i.when > start_time);
        }

        if let Some(end_time) = end_time {
            operable_copy.records.retain(|i| i.when < end_time);
        }

        operable_copy
            .summarize()
            .serialize(&Serializer::json_compatible())
            .unwrap()
    }

    pub fn get_lint_config_as_object(&self) -> JsValue {
        // Important for downstream JSON serialization
        let serializer = Serializer::json_compatible();

        self.lint_group.config.serialize(&serializer).unwrap()
    }

    pub fn set_lint_config_from_object(&mut self, object: JsValue) -> Result<(), String> {
        self.lint_group.config =
            serde_wasm_bindgen::from_value(object).map_err(|v| v.to_string())?;
        Ok(())
    }

    pub fn ignore_lint(&mut self, source_text: String, lint: Lint) {
        let source: Vec<_> = source_text.chars().collect();

        let document = Document::new_from_vec(
            source.into(),
            &lint.language.create_parser(),
            &self.dictionary,
        );

        self.ignored_lints.ignore_lint(&lint.inner, &document);
    }

    /// Add a specific context hash to the ignored lints list.
    pub fn ignore_hash(&mut self, hash: u64) {
        self.ignored_lints.ignore_hash(hash);
    }

    /// Compute the context hash of a given lint.
    pub fn context_hash(&self, source_text: String, lint: &Lint) -> u64 {
        let source: Vec<_> = source_text.chars().collect();

        let document = Document::new_from_vec(
            source.into(),
            &lint.language.create_parser(),
            &self.dictionary,
        );

        let ctx = LintContext::from_lint(&lint.inner, &document);
        ctx.default_hash()
    }

    pub fn organized_lints(
        &mut self,
        text: String,
        language: Language,
        all_headings: bool,
    ) -> Vec<OrganizedGroup> {
        let source: Vec<_> = text.chars().collect();
        let source = Lrc::new(source);

        let mut parser = language.create_parser();

        if all_headings {
            parser = Box::new(OopsAllHeadings::new(parser));
        }

        let document = Document::new_from_vec(source.clone(), &parser, &self.dictionary);

        let temp = self.lint_group.config.clone();
        self.lint_group.config.fill_with_curated();

        let mut lints = self.lint_group.organized_lints(&document);

        self.lint_group.config = temp;

        for value in lints.values_mut() {
            self.ignored_lints.remove_ignored(value, &document);
        }

        remove_overlaps_map(&mut lints);

        lints
            .into_iter()
            .map(|(s, ls)| OrganizedGroup {
                group: s,
                lints: ls
                    .into_iter()
                    .map(|l| {
                        let problem_text = l.span.get_content_string(&source);
                        let span = Into::<Span>::into(l.span).to_js_indices(source.as_slice());

                        Lint::new(l, span, problem_text, language)
                    })
                    .collect(),
            })
            .collect()
    }

    /// Perform the configured linting on the provided text.
    pub fn lint(&mut self, text: String, language: Language, all_headings: bool) -> Vec<Lint> {
        let source: Vec<_> = text.chars().collect();
        let source = Lrc::new(source);

        let mut parser = language.create_parser();

        if all_headings {
            parser = Box::new(OopsAllHeadings::new(parser));
        }

        let document = Document::new_from_vec(source.clone(), &parser, &self.dictionary);

        let temp = self.lint_group.config.clone();
        self.lint_group.config.fill_with_curated();

        let mut lints = self.lint_group.lint(&document);

        self.lint_group.config = temp;

        self.ignored_lints.remove_ignored(&mut lints, &document);
        remove_overlaps(&mut lints);

        lints
            .into_iter()
            .map(|l| {
                let problem_text = l.span.get_content_string(&source);
                let span = Into::<Span>::into(l.span).to_js_indices(source.as_slice());
                Lint::new(l, span, problem_text, language)
            })
            .collect()
    }

    /// Export the linter's ignored lints as a privacy-respecting JSON list of hashes.
    pub fn export_ignored_lints(&self) -> String {
        serde_json::to_string(&self.ignored_lints).unwrap()
    }

    /// Import into the linter's ignored lints from a privacy-respecting JSON list of hashes.
    pub fn import_ignored_lints(&mut self, json: String) -> Result<(), String> {
        let list: IgnoredLints = serde_json::from_str(&json).map_err(|err| err.to_string())?;

        self.ignored_lints.append(list);

        Ok(())
    }

    pub fn clear_ignored_lints(&mut self) {
        self.ignored_lints = IgnoredLints::new();
    }

    /// Clear the user dictionary.
    pub fn clear_words(&mut self) {
        self.user_dictionary = MutableDictionary::new();
        self.synchronize_lint_dict();
    }

    /// Import words into the dictionary.
    pub fn import_words(&mut self, additional_words: Vec<String>) {
        let init_len = self.user_dictionary.word_count();

        self.user_dictionary
            .extend_words(additional_words.iter().map(|word| {
                (
                    word.chars().collect::<CharString>(),
                    DictWordMetadata {
                        dialects: DialectFlags::from_dialect(self.dialect.into()),
                        ..Default::default()
                    },
                )
            }));

        // Only synchronize if we added words that were not there before.
        if self.user_dictionary.word_count() > init_len {
            self.synchronize_lint_dict();
        }
    }

    /// Export words from the dictionary.
    /// Note: this will only return words previously added by [`Self::import_words`].
    pub fn export_words(&mut self) -> Vec<String> {
        self.user_dictionary
            .words_iter()
            .map(|v| v.iter().collect())
            .collect()
    }

    /// Get the dialect this struct was constructed for.
    pub fn get_dialect(&self) -> Dialect {
        self.dialect
    }

    /// Apply a suggestion from a given lint.
    /// This action will be logged to the Linter's statistics.
    pub fn apply_suggestion(
        &mut self,
        source_text: String,
        lint: &Lint,
        suggestion: &Suggestion,
    ) -> Result<String, String> {
        let mut source: Vec<_> = source_text.chars().collect();

        let doc = Document::new_from_vec(
            source.clone().into(),
            &lint.language.create_parser(),
            &self.dictionary,
        );

        self.stats
            .records
            .push(Record::now(RecordKind::from_lint(&lint.inner, &doc)));

        suggestion.inner.apply(lint.inner.span, &mut source);

        Ok(source.iter().collect())
    }

    pub fn generate_stats_file(&self) -> String {
        let mut output = Vec::new();
        self.stats.write(&mut output).unwrap();

        String::from_utf8(output).unwrap()
    }

    pub fn import_stats_file(&mut self, file: String) -> Result<(), String> {
        let data = file.as_bytes();
        let mut read = Cursor::new(data);

        let mut new_stats = Stats::read(&mut read).map_err(|err| err.to_string())?;
        self.stats.records.append(&mut new_stats.records);

        Ok(())
    }
}

#[wasm_bindgen]
pub fn to_title_case(text: String) -> String {
    harper_core::make_title_case_str(&text, &PlainEnglish, &FstDictionary::curated())
}

/// A suggestion to fix a Lint.
#[derive(Debug, Serialize, Deserialize)]
#[wasm_bindgen]
pub struct Suggestion {
    inner: harper_core::linting::Suggestion,
}

/// Tags the variant of suggestion.
#[derive(Debug, Serialize, Deserialize)]
#[wasm_bindgen]
pub enum SuggestionKind {
    /// Replace the problematic text.
    Replace = 0,
    /// Remove the problematic text.
    Remove = 1,
    /// Insert additional text after the error.
    InsertAfter = 2,
}

#[wasm_bindgen]
impl Suggestion {
    pub(crate) fn new(inner: harper_core::linting::Suggestion) -> Self {
        Self { inner }
    }

    /// Get the text that is going to replace the problematic section.
    /// If [`Self::kind`] is `SuggestionKind::Remove`, this will return an empty
    /// string.
    pub fn get_replacement_text(&self) -> String {
        match &self.inner {
            harper_core::linting::Suggestion::Remove => "".to_string(),
            harper_core::linting::Suggestion::ReplaceWith(chars) => chars.iter().collect(),
            harper_core::linting::Suggestion::InsertAfter(chars) => chars.iter().collect(),
        }
    }

    pub fn kind(&self) -> SuggestionKind {
        match &self.inner {
            harper_core::linting::Suggestion::Remove => SuggestionKind::Remove,
            harper_core::linting::Suggestion::ReplaceWith(_) => SuggestionKind::Replace,
            harper_core::linting::Suggestion::InsertAfter(_) => SuggestionKind::InsertAfter,
        }
    }
}

/// An error found in provided text.
///
/// May include zero or more suggestions that may fix the problematic text.
#[derive(Debug, Deserialize, Serialize, Clone)]
#[wasm_bindgen]
pub struct Lint {
    inner: harper_core::linting::Lint,
    /// Indexed in a proverbial JS string
    span: Span,
    /// The problematic text that produced this lint.
    problem_text: String,
    language: Language,
}

#[wasm_bindgen]
impl Lint {
    pub(crate) fn new(
        inner: harper_core::linting::Lint,
        span: Span,
        problem_text: String,
        language: Language,
    ) -> Self {
        Self {
            inner,
            span,
            problem_text,
            language,
        }
    }

    /// Get the content of the source material pointed to by [`Self::span`]
    pub fn get_problem_text(&self) -> String {
        self.problem_text.clone()
    }

    /// Get a string representing the general category of the lint.
    pub fn lint_kind(&self) -> String {
        self.inner.lint_kind.to_string_key()
    }

    /// Get a string representing the general category of the lint.
    pub fn lint_kind_pretty(&self) -> String {
        self.inner.lint_kind.to_string()
    }

    /// Equivalent to calling `.length` on the result of `suggestions()`.
    pub fn suggestion_count(&self) -> usize {
        self.inner.suggestions.len()
    }

    /// Get an array of any suggestions that may resolve the issue.
    pub fn suggestions(&self) -> Vec<Suggestion> {
        self.inner
            .suggestions
            .iter()
            .map(|s| Suggestion::new(s.clone()))
            .collect()
    }

    /// Get the location of the problematic text.
    pub fn span(&self) -> Span {
        self.span
    }

    /// Get a description of the error.
    pub fn message(&self) -> String {
        self.inner.message.clone()
    }

    /// Get a description of the error as HTML.
    pub fn message_html(&self) -> String {
        self.inner.message_html()
    }
}

/// Convert Harper's character index into a UTF-16 code unit index understood by JS.
fn char_idx_to_js_str_idx(char_idx: usize, char_str: &[char]) -> usize {
    char_str.iter().take(char_idx).fold(0usize, |acc, ch| {
        acc + if (*ch as u32) <= 0xFFFF { 1 } else { 2 }
    })
}

#[wasm_bindgen]
pub fn get_default_lint_config_as_json() -> String {
    let config =
        LintGroup::new_curated(MutableDictionary::new().into(), Dialect::American.into()).config;

    serde_json::to_string(&config).unwrap()
}

#[wasm_bindgen]
pub fn get_default_lint_config() -> JsValue {
    let config =
        LintGroup::new_curated(MutableDictionary::new().into(), Dialect::American.into()).config;

    // Important for downstream JSON serialization
    let serializer = Serializer::json_compatible();

    config.serialize(&serializer).unwrap()
}

/// A struct that represents two character indices in a string: a start and an end.
#[derive(Debug, Clone, Copy, Serialize, Deserialize)]
#[wasm_bindgen]
pub struct Span {
    pub start: usize,
    pub end: usize,
}

#[wasm_bindgen]
impl Span {
    pub fn new(start: usize, end: usize) -> Self {
        Self { start, end }
    }

    pub fn is_empty(&self) -> bool {
        self.len() == 0
    }

    pub fn len(&self) -> usize {
        Into::<harper_core::Span<char>>::into(*self).len()
    }
}

impl Span {
    pub fn to_js_indices(&self, source: &[char]) -> Self {
        Self::new(
            char_idx_to_js_str_idx(self.start, source),
            char_idx_to_js_str_idx(self.end, source),
        )
    }
}

impl From<Span> for harper_core::Span<char> {
    fn from(value: Span) -> Self {
        harper_core::Span::new(value.start, value.end)
    }
}

impl From<harper_core::Span<char>> for Span {
    fn from(value: harper_core::Span<char>) -> Self {
        Span::new(value.start, value.end)
    }
}

/// Used exclusively for [`Linter::organized_lints`]
#[wasm_bindgen]
#[derive(Serialize, Deserialize, Clone)]
pub struct OrganizedGroup {
    #[wasm_bindgen(getter_with_clone)]
    pub group: String,
    #[wasm_bindgen(getter_with_clone)]
    pub lints: Vec<Lint>,
}

#[cfg(test)]
mod tests {
    use super::*;
    use sysinfo::{Pid, ProcessRefreshKind, ProcessesToUpdate, System};

    /// Get memory usage for the process with the given PID, in bytes.
    ///
    /// This will fail if the requested process does not exist.
    #[must_use]
    fn get_mem_usage_of_process(sys: &mut System, pid: Pid) -> Option<u64> {
        sys.refresh_processes_specifics(
            ProcessesToUpdate::Some(&[pid]),
            false,
            ProcessRefreshKind::nothing().with_memory(),
        );
        sys.process(pid).map(|process| process.memory())
    }

    /// If a word from another dialect is added to the user dictionary, it should be considered
    /// part of the user's dialect as well.
    #[test]
    fn issue_2216() {
        let text = "Aeon".to_owned();
        let mut linter = Linter::new(Dialect::American);

        linter.import_words(vec![text.clone()]);
        dbg!(linter.dictionary.get_word_metadata_str(&text));

        let lints = linter.lint(text, Language::Plain, false);
        assert!(lints.is_empty());
    }

    #[test]
    fn no_memory_leak_with_repeated_lints() {
        let pid = Pid::from_u32(std::process::id());
        let mut sys = System::new();

        let mut prev_memory_usage = get_mem_usage_of_process(&mut sys, pid).unwrap();

        if (0..10).all(|_| {
            // Run a few times.
            for _ in 0..10 {
                let mut linter = Linter::new(Dialect::American);

                let results = linter.lint(
                    "This is a grammatically correct sentence.".to_string(),
                    Language::Plain,
                    false,
                );

                assert!(results.is_empty())
            }
            // Check if our process' memory usage increased.
            let curr_memory_usage = get_mem_usage_of_process(&mut sys, pid).unwrap();
            let memory_usage_increased = curr_memory_usage > prev_memory_usage;
            prev_memory_usage = curr_memory_usage;
            memory_usage_increased
        }) {
            panic!("Memory leak!");
        }
    }
}



================================================
FILE: packages/chrome-plugin/app.css
================================================
@import "tailwindcss";
@import "components/components.css";

@custom-variant dark (&:where(.dark, .dark *));

@theme {
	--font-sans: "Atkinson Hyperlegible", sans-serif;
	--font-serif: Domine, serif;

	--color-primary-50: #fef4e7; /* honey bronze */
	--color-primary-100: #fce9cf;
	--color-primary-200: #f9d49f;
	--color-primary-300: #f7be6e;
	--color-primary-400: #f4a83e;
	--color-primary: #f1920e;
	--color-primary-600: #c1750b;
	--color-primary-700: #915808;
	--color-primary-800: #603b06;
	--color-primary-900: #301d03;
	--color-primary-950: #221402;

	--color-accent-50: #fee7e9; /* hot fuchsia */
	--color-accent-100: #fccfd3;
	--color-accent-200: #f99fa6;
	--color-accent-300: #f76e7a;
	--color-accent-400: #f43e4d;
	--color-accent: #f10e21;
	--color-accent-600: #c10b1a;
	--color-accent-700: #910814;
	--color-accent-800: #60060d;
	--color-accent-900: #300307;
	--color-accent-950: #220205;

	--color-cream: #fef4e7; /* simple cream */
	--color-cream-100: #fce9cf;
	--color-cream-200: #f9d49f;
	--color-cream-300: #f7be6e;
	--color-cream-400: #f4a83e;
	--color-cream-500: #f1920e;
	--color-cream-600: #c1750b;
	--color-cream-700: #915808;
	--color-cream-800: #603b06;
	--color-cream-900: #301d03;
	--color-cream-950: #221402;

	--color-champagne-mist-50: #fef4e7;
	--color-champagne-mist-100: #fce9cf;
	--color-champagne-mist-200: #fad49e;
	--color-champagne-mist-300: #f7be6e;
	--color-champagne-mist-400: #f5a83d;
	--color-champagne-mist-500: #f2930d;
	--color-champagne-mist-600: #c2750a;
	--color-champagne-mist-700: #915808;
	--color-champagne-mist-800: #613b05;
	--color-champagne-mist-900: #301d03;
	--color-champagne-mist-950: #221502;

	--color-white: #fffdfa;
	--color-white-100: #fceacf;
	--color-white-200: #fad59e;
	--color-white-300: #f7c06e;
	--color-white-400: #f5ab3d;
	--color-white-500: #f2960d;
	--color-white-600: #c2780a;
	--color-white-700: #915a08;
	--color-white-800: #613c05;
	--color-white-900: #301e03;
	--color-white-950: #221502;
}

code {
	@apply bg-primary-100 rounded p-1 dark:text-black;
}

#app {
	@apply min-h-screen bg-white text-black dark:bg-black dark:text-white transition-colors duration-150;

	font-family:
		Atkinson Hyperlegible,
		sans-serif;
}

h1,
h2,
h3,
h4 {
	font-family: Domine, serif;
}



================================================
FILE: packages/chrome-plugin/CHANGELOG.md
================================================
# CHANGELOG

```txt
Summary
  1. document grouping follow 'SemVer2.0' protocol
  2. use 'PATCH' as a minimum granularity
  3. use concise descriptions
  4. type: feat \ fix \ update \ perf \ remove \ docs \ chore
  5. version timestamp follow the yyyy.MM.dd format
```

## 0.0.0 [2025.04.07]

- feat: initial
- feat: generator by ![create-chrome-ext](https://github.com/guocaoyi/create-chrome-ext)



================================================
FILE: packages/chrome-plugin/LICENSE
================================================
The MIT License (MIT)

Copyright (c) 2025-present, no one

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in
all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
THE SOFTWARE.



================================================
FILE: packages/chrome-plugin/options.html
================================================
<!doctype html>
<html lang="en">

<head>
  <meta charset="UTF-8" />
  <link rel="icon" href="/logo.png" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Harper Settings</title>

<link rel="preconnect" href="https://fonts.googleapis.com" />
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
<link
	href="https://fonts.googleapis.com/css2?family=Atkinson+Hyperlegible:ital,wght@0,400;0,700;1,400;1,700&family=Domine:wght@400..700&display=swap"
	rel="stylesheet"
/>

<link
	href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:ital,wght@0,100..800;1,100..800&display=swap"
	rel="stylesheet"
/>
</head>

<body>
  <div id="app"></div>
  <script type="module" src="/src/options/index.ts"></script>
</body>

</html>



================================================
FILE: packages/chrome-plugin/package.json
================================================
{
	"name": "chrome-plugin",
	"displayName": "chrome-plugin",
	"version": "1.5.1",
	"author": "no one",
	"description": "The private grammar checker for 21st Century English",
	"type": "module",
	"license": "Apache-2.0",
	"keywords": [
		"chrome-extension",
		"svelte",
		"vite",
		"create-chrome-ext"
	],
	"engines": {
		"node": ">=14.18.0"
	},
	"scripts": {
		"dev": "vite",
		"build": "vite build -l warn",
		"preview": "vite preview",
		"fmt": "prettier --write '**/*.{svelte,ts,json,css,scss,md}'",
		"zip-for-chrome": "TARGET_BROWSER=chrome npm run build && node src/zip.js harper-chrome-plugin.zip",
		"zip-for-firefox": "TARGET_BROWSER=firefox npm run build && node src/zip.js harper-firefox-plugin.zip",
		"test": "playwright test --headed --reporter=dot"
	},
	"devDependencies": {
		"@crxjs/vite-plugin": "^2.0.0-beta.26",
		"@playwright/test": "^1.58.0",
		"@sveltejs/vite-plugin-svelte": "^4.0.0",
		"@types/chrome": "^0.0.246",
		"@types/lodash-es": "^4.17.12",
		"@types/node": "catalog:",
		"flowbite": "^3.1.2",
		"gulp": "^5.0.0",
		"gulp-zip": "^6.0.0",
		"http-server": "^14.1.1",
		"playwright-webextext": "^0.0.4",
		"prettier": "^3.1.0",
		"prettier-plugin-svelte": "^3.2.6",
		"rollup-plugin-copy": "^3.5.0",
		"svelte": "^5.0.0",
		"svelte-preprocess": "^6.0.0",
		"tslib": "^2.6.2",
		"typescript": "^5.5.0",
		"vite": "^5.4.10",
		"@tailwindcss/vite": "^4.1.4",
		"tailwindcss": "^4.1.4"
	},
	"dependencies": {
		"@fortawesome/free-solid-svg-icons": "^7.1.0",
		"@webcomponents/custom-elements": "^1.6.0",
		"components": "workspace:*",
		"harper.js": "workspace:*",
		"lint-framework": "workspace:*",
		"lodash-es": "^4.17.21",
		"lru-cache": "^11.1.0",
		"svelte-fa": "^4.0.4"
	}
}



================================================
FILE: packages/chrome-plugin/playwright.config.ts
================================================
import { defineConfig, devices } from '@playwright/test';

/**
 * See https://playwright.dev/docs/test-configuration.
 */
export default defineConfig({
	testDir: './tests',
	fullyParallel: true,
	/* Fail the build on CI if you accidentally left test.only in the source code. */
	forbidOnly: !!process.env.CI,
	/* Retry on CI only */
	retries: process.env.CI ? 4 : 0,
	/* Opt out of parallel tests on CI. */
	workers: process.env.CI ? 1 : undefined,
	/* Reporter to use. See https://playwright.dev/docs/test-reporters */
	reporter: 'html',
	use: {
		/* Collect trace when retrying the failed test. See https://playwright.dev/docs/trace-viewer */
		trace: 'on-first-retry',
	},
	/** A half hour */
	globalTimeout: 1800000,
	webServer: {
		command: 'pnpm exec http-server ./tests/pages -p 8081 -a 127.0.0.1',
		url: 'http://127.0.0.1:8081',
		reuseExistingServer: true,
		stdout: 'pipe',
		stderr: 'pipe',
	},
	/* Configure projects for major browsers */
	projects: [
		{
			name: 'chromium',
			use: { ...devices['Desktop Chrome'] },
		},
		{
			name: 'firefox',
			use: { ...devices['Desktop Firefox'] },
		},
	],
});



================================================
FILE: packages/chrome-plugin/popup.html
================================================
<!doctype html>
<html lang="en">

<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Harper: The Private Grammar Checker</title>

<link rel="preconnect" href="https://fonts.googleapis.com" />
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
<link
	href="https://fonts.googleapis.com/css2?family=Atkinson+Hyperlegible:ital,wght@0,400;0,700;1,400;1,700&family=Domine:wght@400..700&display=swap"
	rel="stylesheet"
/>

<link
	href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:ital,wght@0,100..800;1,100..800&display=swap"
	rel="stylesheet"
/>
</head>

<body>
  <div id="app"></div>
  <script type="module" src="/src/popup/index.ts"></script>
</body>

</html>



================================================
FILE: packages/chrome-plugin/sidepanel.html
================================================
<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <link rel="icon" href="/icons/logo.ico" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Chrome Extension + Svelte + TS + Vite</title>
  </head>
  <body>
    <div id="app"></div>
    <script type="module" src="/src/sidepanel/index.ts"></script>
  </body>
</html>



================================================
FILE: packages/chrome-plugin/tsconfig.json
================================================
{
	"compilerOptions": {
		"target": "ESNext",
		"useDefineForClassFields": true,
		"lib": ["DOM", "DOM.Iterable", "ESNext"],
		"allowJs": false,
		"skipLibCheck": true,
		"verbatimModuleSyntax": true,
		"esModuleInterop": false,
		"allowSyntheticDefaultImports": true,
		"strict": true,
		"forceConsistentCasingInFileNames": true,
		"module": "ESNext",
		"moduleResolution": "Node",
		"resolveJsonModule": true,
		"isolatedModules": true,
		"noEmit": true,
		"jsx": "react-jsx"
	},
	"include": ["src"],
	"references": [
		{
			"path": "./tsconfig.node.json"
		}
	]
}



================================================
FILE: packages/chrome-plugin/tsconfig.node.json
================================================
{
	"compilerOptions": {
		"composite": true,
		"module": "ESNext",
		"moduleResolution": "Node"
	},
	"include": ["vite.config.ts"]
}



================================================
FILE: packages/chrome-plugin/vite.config.ts
================================================
import { crx } from '@crxjs/vite-plugin';
import { svelte } from '@sveltejs/vite-plugin-svelte';
import tailwindcss from '@tailwindcss/vite';
import path from 'path';
import copy from 'rollup-plugin-copy';
import sveltePreprocess from 'svelte-preprocess';
import { defineConfig, loadEnv } from 'vite';
import manifest from './src/manifest';

export default defineConfig(({ mode }) => {
	const env = loadEnv(mode, process.cwd(), '');

	const browser = env.TARGET_BROWSER ?? 'chrome';

	if (!['chrome', 'firefox'].includes(browser)) {
		throw new Error('UNSUPPORTED BROWSER TYPE');
	}

	console.log(`Building for ${browser}`);

	const production = mode === 'production';

	return {
		build: {
			minify: false,
			outDir: 'build',
			rollupOptions: {
				output: {
					chunkFileNames: 'assets/chunk-[hash].js',
				},
			},
		},
		plugins: [
			copy({
				hook: 'buildStart',
				targets: [
					{
						src: '../harper.js/dist/harper_wasm_bg.wasm',
						dest: './public/wasm',
					},
				],
			}),
			tailwindcss(),
			crx({ manifest, browser }),
			svelte({
				compilerOptions: {
					dev: !production,
				},
				preprocess: sveltePreprocess(),
			}),
		],
		resolve: {
			alias: {
				'@': path.resolve(__dirname, 'src'),
			},
		},
		legacy: {
			skipWebSocketTokenCheck: true,
		},
	};
});



================================================
FILE: packages/chrome-plugin/.editorconfig
================================================
# EditorConfig is awesome: https://EditorConfig.org

# top-most EditorConfig file
root = true

# Unix-style newlines with a newline ending every file
[*]
end_of_line = lf
insert_final_newline = true

# Matches multiple files with brace expansion notation
# Set default charset
[*.{js,jsx,ts,tsx,md}]
charset = utf-8
indent_style = space
indent_size = 2
tab_width = 2
end_of_line = lf
insert_final_newline = true
trim_trailing_whitespace = true


# Matches the exact files either package.json or .travis.yml
[{package.json,.travis.yml}]
indent_style = space
indent_size = 2



================================================
FILE: packages/chrome-plugin/.npmignore
================================================
# OS 
.DS_Store

# ignore node dependency directories & lock
node_modules
yarn.lock
pnpm-lock.yaml
package-lock.json

# ignore log files and local
*.log
*.local
.env.local
.env.development.local
.env.test.local
.env.production.local
.history

# ignore compiled files
build
types
coverage

# ignore ide settings
.idea
.vscode



================================================
FILE: packages/chrome-plugin/src/generateGreeting.ts
================================================
export default function generateGreeting(): string {
	const timeOfDay = getTimeOfDay();

	switch (timeOfDay) {
		case TimeOfDay.Morning:
			return 'Good morning!';
		case TimeOfDay.Afternoon:
			return 'Good afternoon!';
		case TimeOfDay.Evening:
			return 'Good evening!';
	}
}

enum TimeOfDay {
	Morning = 0,
	Afternoon = 1,
	Evening = 2,
}

function getTimeOfDay(date: Date = new Date()): TimeOfDay {
	const hour = date.getHours();

	if (hour >= 5 && hour < 12) return TimeOfDay.Morning;
	if (hour >= 12 && hour < 18) return TimeOfDay.Afternoon;
	return TimeOfDay.Evening;
}



================================================
FILE: packages/chrome-plugin/src/global.d.ts
================================================
/// <reference types="svelte" />
/// <reference types="vite/client" />

declare const __APP_VERSION__: string;



================================================
FILE: packages/chrome-plugin/src/isWordPress.ts
================================================
/** Does a rough estimate of whether the current page is a WordPress page. */
export default function isWordPress(): boolean {
	if (document.querySelector('meta[name="generator"][content*="WordPress"]')) {
		return true;
	}

	if (document.querySelector('link[rel="https://api.w.org/"][href]')) {
		return true;
	}

	return false;
}



================================================
FILE: packages/chrome-plugin/src/manifest.ts
================================================
import { defineManifest } from '@crxjs/vite-plugin';
import packageData from '../package.json';

//@ts-expect-error
const isDev = process.env.NODE_ENV == 'development';

/**
 * Builds a CSP string that:
 *   • always meets the MV3 minimum (`'self' 'wasm-unsafe-eval'`)
 *   • whitelists the Vite HMR server only when `isDev` is true
 *
 * NOTE: `'unsafe-eval'` is *omitted* because Chrome blocks it outright.
 */
export function makeExtensionCSP(isDev: boolean): string {
	const scriptSrc = ["'self'", "'wasm-unsafe-eval'"]; // minimum, cannot add more
	const objectSrc = ["'self'"]; // standard
	const connectSrc = ["'self'"]; // WebSocket goes here
	const styleSrc = ["'self'", "'unsafe-inline'", 'https://fonts.googleapis.com'];
	const fontSrc = ["'self'", 'https://fonts.gstatic.com', 'data:'];

	if (isDev) {
		// `ws://` and `http://` use the same host:port → list both
		connectSrc.push('http://localhost:5173', 'ws://localhost:5173');
		// include the 127.0.0.1 loopback in case you switch hosts
		connectSrc.push('http://127.0.0.1:*', 'ws://127.0.0.1:*');
		styleSrc.push('http://localhost:5173', 'http://127.0.0.1:*');
	}

	connectSrc.push('https://writewithharper.com');

	// Assemble the semicolon-delimited CSP
	return `${[
		`script-src ${scriptSrc.join(' ')}`,
		`object-src ${objectSrc.join(' ')}`,
		`connect-src ${connectSrc.join(' ')}`,
		`style-src ${styleSrc.join(' ')}`,
		`font-src ${fontSrc.join(' ')}`,
	].join('; ')};`;
}

export default defineManifest({
	name: `Private Grammar Checker - Harper${isDev ? ' ➡️ Dev' : ''}`,
	description: packageData.description,
	version: packageData.version,
	manifest_version: 3,
	action: {
		default_popup: 'popup.html',
	},
	options_page: 'options.html',
	browser_specific_settings: {
		gecko: {
			id: 'harper@writewithharper.com',
			strict_min_version: '146.0',
		},
	},
	background: {
		service_worker: 'src/background/index.ts',
		scripts: ['src/background/index.ts'],
		type: 'module',
	},
	content_scripts: [
		{
			matches: ['<all_urls>'],
			all_frames: true,
			match_about_blank: true,
			js: ['src/contentScript/index.ts'],
			run_at: 'document_idle',
		},
	],
	web_accessible_resources: [
		{
			matches: ['<all_urls>'],
			resources: ['wasm/harper_wasm_bg.wasm'],
		},
	],
	icons: {
		'512': 'logo.png',
	},
	permissions: ['storage', 'tabs'],
	content_security_policy: {
		extension_pages: makeExtensionCSP(isDev),
	},
	host_permissions: ['https://writewithharper.com/*'],
});



================================================
FILE: packages/chrome-plugin/src/PopupState.ts
================================================
export type PopupState =
	| {
			page: 'onboarding';
	  }
	| {
			page: 'main';
	  }
	| {
			page: 'report-error';
			feedback: string;
			example: string;
			rule_id: string;
	  };

export function main(): PopupState {
	return { page: 'main' };
}



================================================
FILE: packages/chrome-plugin/src/protocol.ts
================================================
import type { Dialect, LintConfig, LintOptions } from 'harper.js';
import type { UnpackedLintGroups } from 'lint-framework';

export type Request =
	| LintRequest
	| GetConfigRequest
	| SetConfigRequest
	| GetLintDescriptionsRequest
	| SetDialectRequest
	| GetDialectRequest
	| SetDomainStatusRequest
	| SetDefaultStatusRequest
	| GetDomainStatusRequest
	| GetDefaultStatusRequest
	| GetEnabledDomainsRequest
	| AddToUserDictionaryRequest
	| SetUserDictionaryRequest
	| IgnoreLintRequest
	| GetUserDictionaryRequest
	| GetActivationKeyRequest
	| SetActivationKeyRequest
	| GetHotkeyRequest
	| SetHotkeyRequest
	| OpenOptionsRequest
	| GetInstalledOnRequest
	| GetReviewedRequest
	| SetReviewedRequest
	| OpenReportErrorRequest
	| PostFormDataRequest;

export type Response =
	| LintResponse
	| GetConfigResponse
	| UnitResponse
	| GetLintDescriptionsResponse
	| GetDialectResponse
	| GetDomainStatusResponse
	| GetDefaultStatusResponse
	| GetEnabledDomainsResponse
	| GetUserDictionaryResponse
	| GetHotkeyResponse
	| GetActivationKeyResponse
	| GetInstalledOnResponse
	| GetReviewedResponse
	| PostFormDataResponse;

export type LintRequest = {
	kind: 'lint';
	domain: string;
	text: string;
	options: LintOptions;
};

export type LintResponse = {
	kind: 'lints';
	lints: UnpackedLintGroups;
};

export type GetConfigRequest = {
	kind: 'getConfig';
};

export type GetConfigResponse = {
	kind: 'getConfig';
	config: LintConfig;
};

export type SetConfigRequest = {
	kind: 'setConfig';
	config: LintConfig;
};

export type SetDialectRequest = {
	kind: 'setDialect';
	dialect: Dialect;
};

export type GetLintDescriptionsRequest = {
	kind: 'getLintDescriptions';
};

export type GetLintDescriptionsResponse = {
	kind: 'getLintDescriptions';
	descriptions: Record<string, string>;
};

export type GetDialectRequest = {
	kind: 'getDialect';
};

export type GetDialectResponse = {
	kind: 'getDialect';
	dialect: Dialect;
};

export type GetDomainStatusRequest = {
	kind: 'getDomainStatus';
	domain: string;
};

export type GetDomainStatusResponse = {
	kind: 'getDomainStatus';
	domain: string;
	enabled: boolean;
};

export type GetDefaultStatusRequest = {
	kind: 'getDefaultStatus';
};

export type GetDefaultStatusResponse = {
	kind: 'getDefaultStatus';
	enabled: boolean;
};

export type GetEnabledDomainsRequest = {
	kind: 'getEnabledDomains';
};

export type GetEnabledDomainsResponse = {
	kind: 'getEnabledDomains';
	domains: string[];
};

export type SetDomainStatusRequest = {
	kind: 'setDomainStatus';
	domain: string;
	enabled: boolean;
	/** Dictates whether this should override a previous setting. */
	overrideValue: boolean;
};

export type SetDefaultStatusRequest = {
	kind: 'setDefaultStatus';
	enabled: boolean;
};

export type AddToUserDictionaryRequest = {
	kind: 'addToUserDictionary';
	words: string[];
};

export type SetUserDictionaryRequest = {
	kind: 'setUserDictionary';
	words: string[];
};

export type GetUserDictionaryRequest = {
	kind: 'getUserDictionary';
};

export type GetUserDictionaryResponse = {
	kind: 'getUserDictionary';
	words: string[];
};

export type GetInstalledOnRequest = {
	kind: 'getInstalledOn';
};

export type GetInstalledOnResponse = {
	kind: 'getInstalledOn';
	installedOn: string | null;
};

export type GetReviewedRequest = {
	kind: 'getReviewed';
};

export type GetReviewedResponse = {
	kind: 'getReviewed';
	reviewed: boolean;
};

export type SetReviewedRequest = {
	kind: 'setReviewed';
	reviewed: boolean;
};

export type IgnoreLintRequest = {
	kind: 'ignoreLint';
	contextHash: string;
};

/** Similar to returning void. */
export type UnitResponse = {
	kind: 'unit';
};

export function createUnitResponse(): UnitResponse {
	return { kind: 'unit' };
}

export enum ActivationKey {
	Off = 'off',
	Shift = 'shift',
	Control = 'control',
}

export type GetActivationKeyRequest = {
	kind: 'getActivationKey';
};

export type GetHotkeyRequest = {
	kind: 'getHotkey';
};

export type GetActivationKeyResponse = {
	kind: 'getActivationKey';
	key: ActivationKey;
};

export type PostFormDataResponse = {
	kind: 'postFormData';
	success: boolean;
};

export type SetActivationKeyRequest = {
	kind: 'setActivationKey';
	key: ActivationKey;
};

export type OpenOptionsRequest = {
	kind: 'openOptions';
};

export type GetHotkeyResponse = {
	kind: 'getHotkey';
	hotkey: Hotkey;
};

export type SetHotkeyRequest = {
	kind: 'setHotkey';
	hotkey: Hotkey;
};

export type Modifier = 'Ctrl' | 'Shift' | 'Alt';

export type Hotkey = {
	modifiers: Modifier[];
	key: string;
};
export type OpenReportErrorRequest = {
	kind: 'openReportError';
	example: string;
	rule_id: string;
	feedback: string;
};

export type PostFormDataRequest = {
	kind: 'postFormData';
	url: string;
	formData: Record<string, string>;
};



================================================
FILE: packages/chrome-plugin/src/ProtocolClient.ts
================================================
import type { Dialect, LintConfig, LintOptions } from 'harper.js';
import type { UnpackedLintGroups } from 'lint-framework';
import { LRUCache } from 'lru-cache';
import type { ActivationKey, Hotkey } from './protocol';

export default class ProtocolClient {
	private static readonly lintCache = new LRUCache<string, Promise<UnpackedLintGroups>>({
		max: 5000,
		ttl: 5_000,
	});

	private static cacheKey(text: string, domain: string, options?: LintOptions): string {
		return `${domain}:${text}:${options?.forceAllHeadings ?? ''}:${options?.language ?? ''}`;
	}

	public static async lint(
		text: string,
		domain: string,
		options?: LintOptions,
	): Promise<UnpackedLintGroups> {
		const key = this.cacheKey(text, domain, options);
		let p = this.lintCache.get(key);
		if (!p) {
			p = chrome.runtime
				.sendMessage({ kind: 'lint', text, domain, options })
				.then((r) => r.lints as UnpackedLintGroups);
			this.lintCache.set(key, p);
		}
		return p;
	}

	public static async getLintConfig(): Promise<LintConfig> {
		return (await chrome.runtime.sendMessage({ kind: 'getConfig' })).config;
	}

	public static async setLintConfig(lintConfig: LintConfig): Promise<void> {
		this.lintCache.clear();
		await chrome.runtime.sendMessage({ kind: 'setConfig', config: lintConfig });
	}

	public static async setRuleEnabled(ruleId: string, enabled: boolean): Promise<void> {
		const config = await this.getLintConfig();
		const nextConfig: LintConfig = { ...config, [ruleId]: enabled };
		await this.setLintConfig(nextConfig);
	}

	public static async getLintDescriptions(): Promise<Record<string, string>> {
		return (await chrome.runtime.sendMessage({ kind: 'getLintDescriptions' })).descriptions;
	}

	public static async getDialect(): Promise<Dialect> {
		return (await chrome.runtime.sendMessage({ kind: 'getDialect' })).dialect;
	}

	public static async setDialect(dialect: Dialect): Promise<void> {
		await chrome.runtime.sendMessage({ kind: 'setDialect', dialect });
	}

	public static async getDomainEnabled(domain: string): Promise<boolean> {
		this.lintCache.clear();
		return (await chrome.runtime.sendMessage({ kind: 'getDomainStatus', domain })).enabled;
	}

	/** Set whether Harper is enabled for a given domain.
	 *
	 * @param overrideValue dictates whether this should override a previous setting.
	 * */
	public static async setDomainEnabled(
		domain: string,
		enabled: boolean,
		overrideValue = true,
	): Promise<void> {
		await chrome.runtime.sendMessage({ kind: 'setDomainStatus', enabled, domain, overrideValue });
	}

	public static async getDefaultEnabled(): Promise<boolean> {
		this.lintCache.clear();
		return (await chrome.runtime.sendMessage({ kind: 'getDefaultStatus' })).enabled;
	}

	public static async getEnabledDomains(): Promise<string[]> {
		return (await chrome.runtime.sendMessage({ kind: 'getEnabledDomains' })).domains;
	}

	public static async setDefaultEnabled(enabled: boolean): Promise<void> {
		await chrome.runtime.sendMessage({ kind: 'setDefaultStatus', enabled });
	}

	public static async getActivationKey(): Promise<ActivationKey> {
		return (await chrome.runtime.sendMessage({ kind: 'getActivationKey' })).key;
	}

	public static async getHotkey(): Promise<Hotkey> {
		return (await chrome.runtime.sendMessage({ kind: 'getHotkey' })).hotkey;
	}

	public static async setHotkey(hotkey: Hotkey): Promise<void> {
		const modifiers = hotkey.modifiers;
		const hotkeyCopy = {
			modifiers: [...modifiers], // Create a new array
			key: hotkey.key,
		};
		await chrome.runtime.sendMessage({ kind: 'setHotkey', hotkey: hotkeyCopy });
	}

	public static async setActivationKey(key: ActivationKey): Promise<void> {
		await chrome.runtime.sendMessage({ kind: 'setActivationKey', key });
	}

	public static async addToUserDictionary(words: string[]): Promise<void> {
		this.lintCache.clear();
		await chrome.runtime.sendMessage({ kind: 'addToUserDictionary', words });
	}

	public static async setUserDictionary(words: string[]): Promise<void> {
		this.lintCache.clear();
		await chrome.runtime.sendMessage({ kind: 'setUserDictionary', words });
	}

	public static async getUserDictionary(): Promise<string[]> {
		return (await chrome.runtime.sendMessage({ kind: 'getUserDictionary' })).words;
	}

	public static async getInstalledOn(): Promise<string | null> {
		return (await chrome.runtime.sendMessage({ kind: 'getInstalledOn' })).installedOn;
	}

	public static async getReviewed(): Promise<boolean> {
		return (await chrome.runtime.sendMessage({ kind: 'getReviewed' })).reviewed;
	}

	public static async setReviewed(reviewed: boolean): Promise<void> {
		await chrome.runtime.sendMessage({ kind: 'setReviewed', reviewed });
	}

	public static async ignoreHash(hash: string): Promise<void> {
		await chrome.runtime.sendMessage({ kind: 'ignoreLint', contextHash: hash });
		this.lintCache.clear();
	}

	public static async openReportError(
		example: string,
		ruleId: string,
		feedback: string,
	): Promise<void> {
		await chrome.runtime.sendMessage({
			kind: 'openReportError',
			example,
			rule_id: ruleId,
			feedback,
		});
	}

	public static async openOptions(): Promise<void> {
		// Use background to open options to support content scripts reliably
		await chrome.runtime.sendMessage({ kind: 'openOptions' });
	}

	public static async postFormData(
		url: string,
		formData: Record<string, string>,
	): Promise<boolean> {
		return (await chrome.runtime.sendMessage({ kind: 'postFormData', url, formData })).success;
	}
}



================================================
FILE: packages/chrome-plugin/src/theme.ts
================================================
const QUERY = '(prefers-color-scheme: dark)';

function applyDarkTheme(shouldUseDark: boolean) {
	const root = document.documentElement;
	const body = document.body;

	root.classList.toggle('dark', shouldUseDark);
	body?.classList.toggle('dark', shouldUseDark);
}

export function setupTheme() {
	if (typeof window === 'undefined' || typeof document === 'undefined') {
		return;
	}

	const mediaQuery = window.matchMedia(QUERY);

	applyDarkTheme(mediaQuery.matches);

	const listener = (event: MediaQueryListEvent) => {
		applyDarkTheme(event.matches);
	};

	if ('addEventListener' in mediaQuery) {
		mediaQuery.addEventListener('change', listener);
	} else {
		mediaQuery.addListener(listener);
	}
}



================================================
FILE: packages/chrome-plugin/src/zip.js
================================================
import gulp from 'gulp';
import zip from 'gulp-zip';
import { createRequire } from 'module';

const require = createRequire(import.meta.url);
const manifest = require('../build/manifest.json');

const [, , target] = process.argv;
if (!target) {
	process.stderr.write('Specify a target filename as the first argument.\n');
	process.exit(1);
}

gulp.src('build/**', { encoding: false }).pipe(zip(target)).pipe(gulp.dest('package'));



================================================
FILE: packages/chrome-plugin/src/background/detectDialect.ts
================================================
import { Dialect } from 'harper.js';

/** Detect English dialect from browser language settings */
export function detectBrowserDialect(): Dialect {
	// Try chrome.i18n API first
	if (chrome.i18n?.getUILanguage) {
		const locale = chrome.i18n.getUILanguage();
		return localeToDialect(locale);
	}

	// Fallback to navigator.language
	const lang = navigator.language || navigator.languages?.[0] || 'en-US';
	return localeToDialect(lang);
}

/** Map locale string to Dialect */
function localeToDialect(locale: string): Dialect {
	const lower = locale.toLowerCase();

	// Explicit matches
	if (lower.includes('en-gb') || lower.includes('en_gb')) return Dialect.British;
	if (lower.includes('en-au') || lower.includes('en_au')) return Dialect.Australian;
	if (lower.includes('en-ca') || lower.includes('en_ca')) return Dialect.Canadian;
	if (lower.includes('en-in') || lower.includes('en_in')) return Dialect.Indian;

	// Fallback for English variants
	if (lower.startsWith('en')) {
		// New Zealand → Australian (closest match)
		if (lower.includes('en-nz') || lower.includes('en_nz')) return Dialect.Australian;
		// American
		if (lower.includes('en-us') || lower.includes('en_us')) return Dialect.American;
		// Other English variants → British as fallback
		if (lower.match(/^en[-_]/)) return Dialect.British;
		// Plain 'en' → American (default)
		return Dialect.American;
	}

	// Non-English languages → American (fallback)
	return Dialect.American;
}



================================================
FILE: packages/chrome-plugin/src/background/index.ts
================================================
import { BinaryModule, type Dialect, type LintConfig, LocalLinter } from 'harper.js';
import { type UnpackedLintGroups, unpackLint } from 'lint-framework';
import type { PopupState } from '../PopupState';
import {
	ActivationKey,
	type AddToUserDictionaryRequest,
	createUnitResponse,
	type GetActivationKeyResponse,
	type GetConfigRequest,
	type GetConfigResponse,
	type GetDefaultStatusResponse,
	type GetDialectRequest,
	type GetDialectResponse,
	type GetDomainStatusRequest,
	type GetDomainStatusResponse,
	type GetEnabledDomainsResponse,
	type GetHotkeyResponse,
	type GetInstalledOnRequest,
	type GetInstalledOnResponse,
	type GetLintDescriptionsRequest,
	type GetLintDescriptionsResponse,
	type GetReviewedRequest,
	type GetReviewedResponse,
	type GetUserDictionaryResponse,
	type Hotkey,
	type IgnoreLintRequest,
	type LintRequest,
	type LintResponse,
	type OpenReportErrorRequest,
	type PostFormDataRequest,
	type PostFormDataResponse,
	type Request,
	type Response,
	type SetActivationKeyRequest,
	type SetConfigRequest,
	type SetDefaultStatusRequest,
	type SetDialectRequest,
	type SetDomainStatusRequest,
	type SetHotkeyRequest,
	type SetReviewedRequest,
	type SetUserDictionaryRequest,
	type UnitResponse,
} from '../protocol';
import { detectBrowserDialect } from './detectDialect';

console.log('background is running');

chrome.runtime.onInstalled.addListener((details) => {
	if (details.reason === chrome.runtime.OnInstalledReason.INSTALL) {
		chrome.runtime.setUninstallURL('https://writewithharper.com/uninstall-browser-extension');
		chrome.tabs.create({ url: 'https://writewithharper.com/install-browser-extension' });
	}
});

chrome.runtime.onMessage.addListener((request, _sender, sendResponse) => {
	handleRequest(request).then(sendResponse);

	return true;
});

let linter: LocalLinter;

getDialect()
	.then(setDialect)
	.catch((err) => console.error('Failed to initialize linter:', err));
setInstalledOnIfMissing();

async function enableDefaultDomains() {
	const defaultEnabledDomains = [
		'old.reddit.com',
		'sh.reddit.com',
		'www.reddit.com',
		'chatgpt.com',
		'www.perplexity.ai',
		'textarea.online',
		'webmail.porkbun.com',
		'mail.google.com',
		'trix-editor.org',
		'github.com',
		'messages.google.com',
		'blank.page',
		'blankpage.im',
		'froala.com',
		'playground.lexical.dev',
		'discord.com',
		'www.youtube.com',
		'www.instagram.com',
		'web.whatsapp.com',
		'outlook.live.com',
		'www.linkedin.com',
		'bsky.app',
		'pootlewriter.com',
		'www.tumblr.com',
		'dayone.me',
		'medium.com',
		'x.com',
		'www.notion.so',
		'hashnode.com',
		'www.slatejs.org',
		'localhost',
		'writewithharper.com',
		'prosemirror.net',
		'draftjs.org',
		'gitlab.com',
		'core.trac.wordpress.org',
		'write.ellipsus.com',
		'www.facebook.com',
		'www.upwork.com',
		'news.ycombinator.com',
		'classroom.google.com',
		'quilljs.com',
		'www.wattpad.com',
		'ckeditor.com',
		'app.slack.com',
		'openrouter.ai',
	];

	for (const item of defaultEnabledDomains) {
		if (!(await isDomainSet(item))) {
			setDomainEnable(item, true);
		}
	}
}

enableDefaultDomains();

function handleRequest(message: Request): Promise<Response> {
	console.log(`Handling ${message.kind} request`);

	switch (message.kind) {
		case 'lint':
			return handleLint(message);
		case 'getConfig':
			return handleGetConfig(message);
		case 'setConfig':
			return handleSetConfig(message);
		case 'getLintDescriptions':
			return handleGetLintDescriptions(message);
		case 'setDialect':
			return handleSetDialect(message);
		case 'getDialect':
			return handleGetDialect(message);
		case 'getDomainStatus':
			return handleGetDomainStatus(message);
		case 'setDomainStatus':
			return handleSetDomainStatus(message);
		case 'addToUserDictionary':
			return handleAddToUserDictionary(message);
		case 'ignoreLint':
			return handleIgnoreLint(message);
		case 'setDefaultStatus':
			return handleSetDefaultStatus(message);
		case 'getDefaultStatus':
			return handleGetDefaultStatus();
		case 'getEnabledDomains':
			return handleGetEnabledDomains();
		case 'getUserDictionary':
			return handleGetUserDictionary();
		case 'setUserDictionary':
			return handleSetUserDictionary(message);
		case 'getActivationKey':
			return handleGetActivationKey();
		case 'setActivationKey':
			return handleSetActivationKey(message);
		case 'getHotkey':
			return handleGetHotkey();
		case 'setHotkey':
			return handleSetHotkey(message);
		case 'openReportError':
			return handleOpenReportError(message);
		case 'openOptions':
			chrome.runtime.openOptionsPage();
			return Promise.resolve(createUnitResponse());
		case 'postFormData':
			return handlePostFormData(message);
		case 'getInstalledOn':
			return handleGetInstalledOn(message);
		case 'getReviewed':
			return handleGetReviewed(message);
		case 'setReviewed':
			return handleSetReviewed(message);
	}
}

/** Handle a request for linting. */
async function handleLint(req: LintRequest): Promise<LintResponse> {
	if (!(await enabledForDomain(req.domain))) {
		return { kind: 'lints', lints: {} };
	}

	const grouped = await linter.organizedLints(req.text, req.options);
	const unpackedEntries = await Promise.all(
		Object.entries(grouped).map(async ([source, lints]) => {
			const unpacked = await Promise.all(lints.map((lint) => unpackLint(req.text, lint, linter)));
			return [source, unpacked] as const;
		}),
	);
	const unpackedBySource = Object.fromEntries(unpackedEntries) as UnpackedLintGroups;
	return { kind: 'lints', lints: unpackedBySource };
}

async function handleGetConfig(_req: GetConfigRequest): Promise<GetConfigResponse> {
	return { kind: 'getConfig', config: await getLintConfig() };
}

async function handleSetConfig(req: SetConfigRequest): Promise<UnitResponse> {
	await setLintConfig(req.config);

	return createUnitResponse();
}

async function handleSetDialect(req: SetDialectRequest): Promise<UnitResponse> {
	await setDialect(req.dialect);

	return createUnitResponse();
}

async function handleGetDialect(_req: GetDialectRequest): Promise<GetDialectResponse> {
	return { kind: 'getDialect', dialect: await getDialect() };
}

async function handleIgnoreLint(req: IgnoreLintRequest): Promise<UnitResponse> {
	await linter.ignoreLintHash(BigInt(req.contextHash));
	await setIgnoredLints(await linter.exportIgnoredLints());

	return createUnitResponse();
}

async function handleGetDefaultStatus(): Promise<GetDefaultStatusResponse> {
	return {
		kind: 'getDefaultStatus',
		enabled: await enabledByDefault(),
	};
}

async function handleGetEnabledDomains(): Promise<GetEnabledDomainsResponse> {
	const all = await chrome.storage.local.get(null as any);
	const prefix = formatDomainKey(''); // yields 'domainStatus '
	const domains = Object.entries(all)
		.filter(([k, v]) => typeof v === 'boolean' && v === true && k.startsWith(prefix))
		.map(([k]) => k.substring(prefix.length))
		.sort((a, b) => a.localeCompare(b));

	return { kind: 'getEnabledDomains', domains };
}

async function handleGetDomainStatus(
	req: GetDomainStatusRequest,
): Promise<GetDomainStatusResponse> {
	return {
		kind: 'getDomainStatus',
		domain: req.domain,
		enabled: await enabledForDomain(req.domain),
	};
}

async function handleSetDomainStatus(req: SetDomainStatusRequest): Promise<UnitResponse> {
	await setDomainEnable(req.domain, req.enabled, req.overrideValue);

	return createUnitResponse();
}

async function handleSetDefaultStatus(req: SetDefaultStatusRequest): Promise<UnitResponse> {
	await setDefaultEnable(req.enabled);

	return createUnitResponse();
}

async function handleGetLintDescriptions(
	_req: GetLintDescriptionsRequest,
): Promise<GetLintDescriptionsResponse> {
	return { kind: 'getLintDescriptions', descriptions: await linter.getLintDescriptionsHTML() };
}

async function handleSetUserDictionary(req: SetUserDictionaryRequest): Promise<UnitResponse> {
	await resetDictionary();
	await addToDictionary(req.words);

	return createUnitResponse();
}

async function handleAddToUserDictionary(req: AddToUserDictionaryRequest): Promise<UnitResponse> {
	await addToDictionary(req.words);

	return createUnitResponse();
}

async function handleGetUserDictionary(): Promise<GetUserDictionaryResponse> {
	const dict = await getUserDictionary();

	return { kind: 'getUserDictionary', words: dict };
}

async function handleGetActivationKey(): Promise<GetActivationKeyResponse> {
	const key = await getActivationKey();

	return { kind: 'getActivationKey', key };
}

async function handleSetActivationKey(req: SetActivationKeyRequest): Promise<UnitResponse> {
	if (!Object.values(ActivationKey).includes(req.key)) {
		throw new Error(`Invalid activation key: ${req.key}`);
	}
	await setActivationKey(req.key);

	return createUnitResponse();
}

async function handleGetHotkey(): Promise<GetHotkeyResponse> {
	const hotkey = await getHotkey();

	return { kind: 'getHotkey', hotkey };
}

async function handleSetHotkey(req: SetHotkeyRequest): Promise<UnitResponse> {
	// Create a plain object to avoid proxy cloning issues
	const hotkey = {
		modifiers: [...req.hotkey.modifiers],
		key: req.hotkey.key,
	};
	await setHotkey(hotkey);
}

async function handleOpenReportError(req: OpenReportErrorRequest): Promise<UnitResponse> {
	const popupState: PopupState = {
		page: 'report-error',
		example: req.example,
		rule_id: req.rule_id,
		feedback: req.feedback,
	};

	await chrome.storage.local.set({ popupState });

	if (chrome.action?.openPopup) {
		try {
			await chrome.action.openPopup();
		} catch (error) {
			console.error('Failed to open popup for report error', error);
		}
	}

	return createUnitResponse();
}

async function handlePostFormData(req: PostFormDataRequest): Promise<PostFormDataResponse> {
	const formData = new FormData();
	for (const [key, value] of Object.entries(req.formData)) {
		formData.append(key, value);
	}

	try {
		const response = await fetch(req.url, {
			method: 'POST',
			body: formData,
		});

		return { kind: 'postFormData', success: response.ok };
	} catch (error) {
		console.error('Failed to post form data', error);
		return { kind: 'postFormData', success: false };
	}
}

async function handleGetInstalledOn(_req: GetInstalledOnRequest): Promise<GetInstalledOnResponse> {
	return { kind: 'getInstalledOn', installedOn: await getInstalledOn() };
}

async function handleGetReviewed(_req: GetReviewedRequest): Promise<GetReviewedResponse> {
	return { kind: 'getReviewed', reviewed: await getReviewed() };
}

async function handleSetReviewed(req: SetReviewedRequest): Promise<UnitResponse> {
	await setReviewed(req.reviewed);
	return createUnitResponse();
}

/** Set the lint configuration inside the global `linter` and in permanent storage. */
async function setLintConfig(lintConfig: LintConfig): Promise<void> {
	await linter.setLintConfig(lintConfig);

	const json = await linter.getLintConfigAsJSON();

	await chrome.storage.local.set({ lintConfig: json });
}

/** Get the lint configuration from permanent storage. */
async function getLintConfig(): Promise<LintConfig> {
	const json = await linter.getLintConfigAsJSON();
	const resp = await chrome.storage.local.get({ lintConfig: json });
	return JSON.parse(resp.lintConfig);
}

/** Get the ignored lint state from permanent storage. */
async function setIgnoredLints(state: string): Promise<void> {
	await linter.importIgnoredLints(state);

	const json = await linter.exportIgnoredLints();

	await chrome.storage.local.set({ ignoredLints: json });
}

/** Get the ignored lint state from permanent storage. */
async function getIgnoredLints(): Promise<string> {
	const state = await linter.exportIgnoredLints();
	const resp = await chrome.storage.local.get({ ignoredLints: state });
	return resp.ignoredLints;
}

async function getDialect(): Promise<Dialect> {
	const resp = await chrome.storage.local.get('dialect');

	// If user hasn't set a dialect, try to detect from browser language
	if (resp.dialect === undefined) {
		return detectBrowserDialect();
	}

	return resp.dialect;
}

async function getActivationKey(): Promise<ActivationKey> {
	const resp = await chrome.storage.local.get({ activationKey: ActivationKey.Off });
	return resp.activationKey;
}

async function getHotkey(): Promise<Hotkey> {
	const resp = await chrome.storage.local.get({ hotkey: { modifiers: ['Ctrl'], key: 'e' } });
	return resp.hotkey;
}

async function setActivationKey(key: ActivationKey) {
	await chrome.storage.local.set({ activationKey: key });
}

async function setHotkey(hotkey: Hotkey) {
	await chrome.storage.local.set({ hotkey: hotkey });
}

function initializeLinter(dialect: Dialect) {
	if (linter != null) {
		linter.dispose();
	}

	linter = new LocalLinter({
		binary: BinaryModule.create(chrome.runtime.getURL('./wasm/harper_wasm_bg.wasm')),
		dialect,
	});

	getIgnoredLints().then((i) => linter.importIgnoredLints(i));
	getUserDictionary().then((u) => linter.importWords(u));
	getLintConfig().then((c) => linter.setLintConfig(c));
	linter.setup();
}

async function setDialect(dialect: Dialect) {
	await chrome.storage.local.set({ dialect });
	initializeLinter(dialect);
}

/** Format the key to be used in local storage to store domain status. */
function formatDomainKey(domain: string): string {
	return `domainStatus ${domain}`;
}

/** Check if Harper has been enabled for a given domain. */
async function enabledForDomain(domain: string): Promise<boolean | null> {
	const req = await chrome.storage.local.get({
		[formatDomainKey(domain)]: await enabledByDefault(),
	});
	return req[formatDomainKey(domain)];
}

/** Set whether Harper is enabled for a given domain.
 *
 * @param overrideValue dictates whether this should override a previous setting.
 * */
async function setDomainEnable(domain: string, status: boolean, overrideValue = true) {
	let shouldSet = !(await isDomainSet(domain));

	if (overrideValue) {
		shouldSet = true;
	}

	if (shouldSet) {
		await chrome.storage.local.set({ [formatDomainKey(domain)]: status });
	}
}

/** Set whether Harper is enabled by default. */
async function setDefaultEnable(status: boolean) {
	await chrome.storage.local.set({ defaultEnable: status });
}

/** Check if Harper has been enabled by default. */
async function enabledByDefault(): Promise<boolean> {
	const req = await chrome.storage.local.get({ defaultEnable: false });
	return req.defaultEnable;
}

/** Check whether Harper's state has been set for a given domain. */
async function isDomainSet(domain: string): Promise<boolean> {
	const resp = await chrome.storage.local.get(formatDomainKey(domain));
	return typeof resp[formatDomainKey(domain)] == 'boolean';
}

/** Reset the persistent user dictionary. */
async function resetDictionary(): Promise<void> {
	await chrome.storage.local.set({ userDictionary: null });

	initializeLinter(await linter.getDialect());
}

/** Add words to the persistent user dictionary. */
async function addToDictionary(words: string[]): Promise<void> {
	const exported = await linter.exportWords();
	exported.push(...words);

	await Promise.all([
		linter.importWords(exported),
		chrome.storage.local.set({ userDictionary: exported }),
	]);
}

/** Grab the user dictionary from persistent storage. */
async function getUserDictionary(): Promise<string[]> {
	const resp = await chrome.storage.local.get({ userDictionary: [] });
	return resp.userDictionary;
}

/** Record the date the extension was installed, if it's missing. */
async function setInstalledOnIfMissing(): Promise<void> {
	const current = await getInstalledOn();
	if (current !== null) {
		return;
	}

	const installedOn = new Date().toISOString();
	await chrome.storage.local.set({ installedOn });
}

async function getInstalledOn(): Promise<string | null> {
	const resp = await chrome.storage.local.get({ installedOn: null });
	return resp.installedOn;
}

async function getReviewed(): Promise<boolean> {
	const resp = await chrome.storage.local.get({ reviewed: false });
	return Boolean(resp.reviewed);
}

async function setReviewed(reviewed: boolean): Promise<void> {
	await chrome.storage.local.set({ reviewed });
}



================================================
FILE: packages/chrome-plugin/src/contentScript/index.ts
================================================
import '@webcomponents/custom-elements';
import {
	getClosestBlockAncestor,
	isVisible,
	LintFramework,
	leafNodes,
	type UnpackedLint,
} from 'lint-framework';
import isWordPress from '../isWordPress';
import ProtocolClient from '../ProtocolClient';

if (isWordPress()) {
	ProtocolClient.setDomainEnabled(window.location.hostname, true, false);
}

const fw = new LintFramework(
	(text, domain, options) => ProtocolClient.lint(text, domain, options),
	{
		ignoreLint: (hash) => ProtocolClient.ignoreHash(hash),
		getActivationKey: () => ProtocolClient.getActivationKey(),
		getHotkey: () => ProtocolClient.getHotkey(),
		openOptions: () => ProtocolClient.openOptions(),
		addToUserDictionary: (words) => ProtocolClient.addToUserDictionary(words),
		reportError: (lint: UnpackedLint, ruleId: string) =>
			ProtocolClient.openReportError(
				padWithContext(lint.source, lint.span.start, lint.span.end, 15),
				ruleId,
				'',
			),
		setRuleEnabled: async (ruleId, enabled) => {
			await ProtocolClient.setRuleEnabled(ruleId, enabled);
			fw.update();
		},
	},
);

function padWithContext(source: string, start: number, end: number, contextLength: number): string {
	const normalizedStart = Math.max(0, Math.min(start, source.length));
	const normalizedEnd = Math.max(normalizedStart, Math.min(end, source.length));
	const contextStart = Math.max(0, normalizedStart - contextLength);
	const contextEnd = Math.min(source.length, normalizedEnd + contextLength);

	return source.slice(contextStart, contextEnd);
}

const keepAliveCallback = () => {
	ProtocolClient.lint('', 'example.com', {});

	setTimeout(keepAliveCallback, 400);
};

keepAliveCallback();

function scan() {
	document.querySelectorAll<HTMLTextAreaElement>('textarea').forEach((element) => {
		if (
			!isVisible(element) ||
			element.getAttribute('data-enable-grammarly') === 'false' ||
			element.disabled ||
			element.readOnly
		) {
			return;
		}

		fw.addTarget(element);
	});

	document
		.querySelectorAll<HTMLInputElement>('input[type="text"][spellcheck="true"]')
		.forEach((element) => {
			if (element.disabled || element.readOnly) {
				return;
			}

			fw.addTarget(element);
		});

	document.querySelectorAll('[data-testid="gutenberg-editor"]').forEach((element) => {
		const leafs = leafNodes(element);

		const seenBlockContainers = new Set<Element>();

		for (const leaf of leafs) {
			const blockContainer = getClosestBlockAncestor(leaf, element);

			if (!blockContainer || seenBlockContainers.has(blockContainer)) {
				continue;
			}

			seenBlockContainers.add(blockContainer);

			if (!isVisible(blockContainer)) {
				continue;
			}

			fw.addTarget(blockContainer);
		}
	});

	document.querySelectorAll('[contenteditable="true"],[contenteditable]').forEach((element) => {
		if (
			element.matches('[role="combobox"]') ||
			element.getAttribute('data-enable-grammarly') === 'false' ||
			(element.getAttribute('spellcheck') === 'false' &&
				element.getAttribute('data-language') !== 'markdown')
		) {
			return;
		}

		if (element.classList.contains('ck-editor__editable')) {
			element.querySelectorAll('p').forEach((paragraph) => {
				if (paragraph.closest('[contenteditable="false"],[disabled],[readonly]') != null) {
					return;
				}

				if (!isVisible(paragraph)) {
					return;
				}

				fw.addTarget(paragraph);
			});

			return;
		}

		const leafs = leafNodes(element);

		const seenBlockContainers = new Set<Element>();

		for (const leaf of leafs) {
			if (leaf.parentElement?.closest('[contenteditable="false"],[disabled],[readonly]') != null) {
				continue;
			}

			const blockContainer = getClosestBlockAncestor(leaf, element);

			if (!blockContainer || seenBlockContainers.has(blockContainer)) {
				continue;
			}

			seenBlockContainers.add(blockContainer);

			if (!isVisible(blockContainer)) {
				continue;
			}

			fw.addTarget(blockContainer);
		}
	});
}

scan();
new MutationObserver(scan).observe(document.body, { childList: true, subtree: true });

setTimeout(scan, 1000);



================================================
FILE: packages/chrome-plugin/src/options/index.ts
================================================
import '../../app.css';
import { mount } from 'svelte';
import { setupTheme } from '../theme';
import App from './Options.svelte';

setupTheme();
const app = mount(App, {
	target: document.getElementById('app')!,
});

export default app;



================================================
FILE: packages/chrome-plugin/src/options/Options.svelte
================================================
<script lang="ts">
import { Button, Card, Input, Select, Textarea } from 'components';
import { Dialect, type LintConfig } from 'harper.js';
import logo from '/logo.png';
import ProtocolClient from '../ProtocolClient';
import type { Hotkey, Modifier } from '../protocol';
import { ActivationKey } from '../protocol';

let lintConfig: LintConfig = $state({});
let lintDescriptions: Record<string, string> = $state({});
let searchQuery = $state('');
let searchQueryLower = $derived(searchQuery.toLowerCase());
let dialect = $state(Dialect.American);
let defaultEnabled = $state(false);
let activationKey: ActivationKey = $state(ActivationKey.Off);
let userDict = $state('');
let modifyHotkeyButton: Button;
let hotkey: Hotkey = $state({ modifiers: ['Ctrl'], key: 'e' });
let anyRulesEnabled = $derived(Object.values(lintConfig ?? {}).some((value) => value !== false));

$effect(() => {
	ProtocolClient.setLintConfig($state.snapshot(lintConfig));
});

$effect(() => {
	ProtocolClient.setDialect(dialect);
});

$effect(() => {
	ProtocolClient.setDefaultEnabled(defaultEnabled);
});

$effect(() => {
	ProtocolClient.setActivationKey(activationKey);
});

$effect(() => {
	ProtocolClient.setUserDictionary(stringToDict(userDict));
});

ProtocolClient.getLintConfig().then((l) => {
	lintConfig = l;
});

ProtocolClient.getLintDescriptions().then((d) => {
	lintDescriptions = d;
});

ProtocolClient.getDialect().then((d) => {
	dialect = d;
});

ProtocolClient.getDefaultEnabled().then((d) => {
	defaultEnabled = d;
});

ProtocolClient.getActivationKey().then((d) => {
	activationKey = d;
});

ProtocolClient.getHotkey().then((d) => {
	// Ensure we have a plain object, not a Proxy
	hotkey = {
		modifiers: [...d.modifiers],
		key: d.key,
	};
	buttonText = `Hotkey: ${d.modifiers.join('+')}+${d.key}`;
});

ProtocolClient.getUserDictionary().then((d) => {
	userDict = dictToString(d.toSorted());
});

function configValueToString(value: boolean | undefined): string {
	switch (value) {
		case true:
			return 'enable';
		case false:
			return 'disable';
		case undefined:
		case null:
			return 'default';
	}
}

function configStringToValue(str: string): boolean | undefined | null {
	switch (str) {
		case 'enable':
			return true;
		case 'disable':
			return false;
		case 'default':
			return null;
	}

	throw 'Fell through case';
}

/** Converts the content of a text area to viable dictionary values. */
export function stringToDict(s: string): string[] {
	return s
		.split('\n')
		.map((s) => s.trim())
		.filter((v) => v.length > 0);
}

/** Converts the content of a text area to viable dictionary values. */
export function dictToString(values: string[]): string {
	return values.map((v) => v.trim()).join('\n');
}

function resetRulesToDefaults(): void {
	const keys = Object.keys(lintConfig ?? {});
	if (keys.length === 0) return;

	const nextConfig: LintConfig = { ...lintConfig };
	for (const key of keys) {
		nextConfig[key] = null;
	}
	lintConfig = nextConfig;
}

function updateAllRules(enabled: boolean): void {
	const keys = Object.keys(lintConfig ?? {});
	if (keys.length === 0) {
		return;
	}

	const nextConfig: LintConfig = { ...lintConfig };
	for (const key of keys) {
		nextConfig[key] = enabled;
	}
	lintConfig = nextConfig;
}

function toggleAllRules(): void {
	updateAllRules(!anyRulesEnabled);
}

async function exportEnabledDomainsCSV() {
	try {
		const enabledDomains = await ProtocolClient.getEnabledDomains();
		const json = JSON.stringify(enabledDomains, null, 2);

		const blob = new Blob([json], { type: 'application/json;charset=utf-8' });
		const url = URL.createObjectURL(blob);
		const a = document.createElement('a');
		a.href = url;
		a.download = 'enabled-domains.json';
		document.body.appendChild(a);
		a.click();
		a.remove();
		URL.revokeObjectURL(url);
	} catch (e) {
		console.error('Failed to export enabled domains JSON:', e);
	}
}

let buttonText = $state('Set Hotkey');
let isBlue = $state(false); // modify color of hotkey button once it is pressed
function startHotkeyCapture(_modifyHotkeyButton: Button) {
	buttonText = 'Press desired hotkey combination now.';

	const handleKeydown = (event: KeyboardEvent) => {
		event.preventDefault();

		const modifiers: Modifier[] = [];
		if (event.ctrlKey) modifiers.push('Ctrl');
		if (event.shiftKey) modifiers.push('Shift');
		if (event.altKey) modifiers.push('Alt');

		let key = event.key;

		if (key !== 'Control' && key !== 'Shift' && key !== 'Alt') {
			if (modifiers.length === 0) {
				return;
			}
			buttonText = `Hotkey: ${modifiers.join('+')}+${key}`;
			// Create a plain object to avoid proxy cloning issues
			const newHotkey = {
				modifiers: [...modifiers],
				key: key,
			};

			hotkey = newHotkey;

			// Call ProtocolClient directly with the plain object to avoid proxy issues
			ProtocolClient.setHotkey(newHotkey);

			// Remove listener
			window.removeEventListener('keydown', handleKeydown);

			// change button color
			isBlue = !isBlue;
		}
	};

	// Add temporary key listener
	window.addEventListener('keydown', handleKeydown);
}

// Import removed
</script>

<!-- centered wrapper with side gutters -->
<div class="min-h-screen px-4 py-10">
  <div class="mx-auto max-w-screen-lg space-y-4">
    <Card class="flex items-center gap-3">
      <div class="flex h-9 w-9 items-center justify-center rounded-xl">
        <img src={logo} alt="Harper logo" class="h-5 w-auto" />
      </div>
      <div class="flex flex-col">
        <h1 class="text-base tracking-wide font-serif">Harper</h1>
        <p class="text-xs">Settings</p>
      </div>
    </Card>

    <!-- ── GENERAL ───────────────────────────── -->
    <Card class="space-y-6">
      <h2 class="pb-1 text-xs uppercase tracking-wider">General</h2>

      <div class="space-y-5">
        <div class="flex items-center justify-between">
          <h3 class="text-sm">English Dialect</h3>
          <Select
            size="sm"
            class="w-44"
            bind:value={dialect}
          >
            <option value={Dialect.American}>🇺🇸 American</option>
            <option value={Dialect.British}>🇬🇧 British</option>
            <option value={Dialect.Australian}>🇦🇺 Australian</option>
            <option value={Dialect.Canadian}>🇨🇦 Canadian</option>
            <option value={Dialect.Indian}>🇮🇳 Indian</option>
          </Select>
        </div>
      </div>

      <div class="space-y-5">
        <div class="flex items-center justify-between">
          <div class="flex flex-col">
            <h3 class="text-sm">Enable on New Sites by Default</h3>
            <p class="text-xs text-gray-600 dark:text-gray-400">Can make some apps behave abnormally.</p>
          </div>
          <input type="checkbox" bind:checked={defaultEnabled} class="h-5 w-5" />
        </div>
      </div>

      <div class="space-y-5">
        <div class="flex items-center justify-between">
          <div class="flex flex-col">
            <h3 class="text-sm">Export Enabled Domains</h3>
            <p class="text-xs text-gray-600 dark:text-gray-400">Downloads JSON of domains explicitly enabled.</p>
          </div>
          <Button size="sm" on:click={exportEnabledDomainsCSV}>Export JSON</Button>
        </div>
      </div>

      <div class="space-y-5">
        <div class="flex items-center justify-between">
          <div class="flex flex-col">
            <h3 class="text-sm">Activation Key</h3>
            <p class="text-xs text-gray-600 dark:text-gray-400">
              If you're finding that you're accidentally triggering Harper.
            </p>
          </div>
          <Select
            size="sm"
            class="w-44"
            bind:value={activationKey}
          >
            <option value={ActivationKey.Shift}>Double Shift</option>
            <option value={ActivationKey.Control}>Double Control</option>
            <option value={ActivationKey.Off}>Off</option>
          </Select>
        </div>
      </div>

      <div class="space-y-5">
        <div class="flex items-center justify-between">
          <div class="flex flex-col">
            <h3 class="text-sm">Apply Last Suggestion Hotkey</h3>
            <p class="text-xs text-gray-600 dark:text-gray-400">Applies suggestion to last highlighted word.</p>
          </div>
          <Textarea readonly bind:value={buttonText} />
          <Button size="sm" color="light" style="background-color: {isBlue ? 'blue' : ''}" bind:this={modifyHotkeyButton} on:click={() => {startHotkeyCapture(modifyHotkeyButton); isBlue = !isBlue}}>Modify Hotkey</Button>

        </div>
      </div>

      <div class="space-y-5">
        <div class="flex items-center justify-between">
          <div class="flex flex-col">
            <h3 class="text-sm">User Dictionary</h3>
            <p class="text-xs text-gray-600 dark:text-gray-400">Each word should be on its own line.</p>
          </div>
          <Textarea
            bind:value={userDict}
          ></Textarea>
        </div>
      </div>

    </Card>

    <!-- ── RULES ─────────────────────────────── -->
    <Card class="space-y-4">
      <div class="flex items-center justify-between gap-4">
        <h2 class="text-xs uppercase tracking-wider">Rules</h2>
        <Input
          bind:value={searchQuery}
          placeholder="Search for a rule…"
          size="sm"
          class="w-60"
        />
      </div>
      <div class="flex flex-wrap gap-3">
        <Button size="sm" on:click={resetRulesToDefaults}>Reset to Default Rules</Button>
        <Button size="sm" on:click={toggleAllRules}>
          {anyRulesEnabled ? 'Disable All Rules' : 'Enable All Rules'}
        </Button>
      </div>

      {#each Object.entries(lintConfig).filter(
        ([key]) =>
          (lintDescriptions[key] ?? '').toLowerCase().includes(searchQueryLower) ||
          key.toLowerCase().includes(searchQueryLower)
      ) as [key, value]}
        <div class="rule-scroll space-y-4 max-h-80 overflow-y-auto pr-1">
          <!-- rule card sample -->
            <div class="flex items-start justify-between gap-4">
              <div class="space-y-0.5">
                <h3 class="text-sm">{key}</h3>
                <p class="text-xs">{@html lintDescriptions[key]}</p>
              </div>
              <Select
                size="md"
                value={configValueToString(value)}
                on:change={(e) => {
                  lintConfig[key] = configStringToValue(e.target.value);
                }}
              >
                <option value="default">⚙️ Default</option>
                <option value="enable">✅ On</option>
                <option value="disable">🚫 Off</option>
              </Select>
            </div>
          </div>
      {/each}

    </Card>
  </div>
</div>



================================================
FILE: packages/chrome-plugin/src/popup/index.ts
================================================
import '../../app.css';
import { mount } from 'svelte';
import { setupTheme } from '../theme';
import App from './Popup.svelte';

setupTheme();
const app = mount(App, {
	target: document.getElementById('app')!,
});

export default app;



================================================
FILE: packages/chrome-plugin/src/popup/Main.svelte
================================================
<script lang="ts">
import { Button } from 'components';
import generateGreeting from '../generateGreeting';
import ProtocolClient from '../ProtocolClient';

let enabled = $state(true);
let domain = $state('');

let installDate: Date | null = $state(null);
let hasBeenReviewed: boolean | null = $state(null);
const REVIEW_URL =
	'https://chromewebstore.google.com/detail/private-grammar-checker-h/lodbfhdipoipcjmlebjbgmmgekckhpfb/reviews';

const isFirefox = isFirefoxExtension();

if (!isFirefox) {
	ProtocolClient.getInstalledOn().then((d) => {
		if (d == null) {
			return;
		}

		installDate = new Date(d);
	});

	ProtocolClient.getReviewed().then((r) => {
		hasBeenReviewed = r;
	});
}

getCurrentTabDomain().then((d) => {
	domain = d ?? '';
});

$effect(() => {
	ProtocolClient.getDomainEnabled(domain).then((e) => {
		enabled = e;
	});
});

/**
 * Returns the registrable domain (e.g.  "example.com") of the
 * tab that the user had open when they clicked the extension icon.
 * If the URL is unavailable (about:blank, chrome://…) it resolves to undefined.
 */
export async function getCurrentTabDomain(): Promise<string | undefined> {
	const [tab] = await chrome.tabs.query({ active: true, currentWindow: true });

	if (!tab?.url) return undefined;

	try {
		const { hostname } = new URL(tab.url);
		return hostname.replace(/^www\\./, '');
	} catch {
		return undefined;
	}
}

function toggleDomainEnabled() {
	console.log('toggle');
	enabled = !enabled;
	ProtocolClient.setDomainEnabled(domain, enabled);
}

function openReviewPage() {
	ProtocolClient.setReviewed(true);
	chrome.tabs.create({ url: REVIEW_URL });
}

function isFirefoxExtension(): boolean {
	try {
		return new URL(chrome.runtime.getURL('')).protocol === 'moz-extension:';
	} catch {
		return false;
	}
}

/** Get the number of days since a given Date. */
function daysSince(date: Date): number {
	let now = Date.now();
	let then = date.getTime();

	let msDiff = now - then;
	return msDiff / 86400000;
}
</script>

<main>
  <section class="p-6 space-y-5 text-gray-800 flex flex-row">
      <Button
        size="lg"
        class="rounded-full! aspect-square h-24 w-24 p-0 shadow-lg transition-colors flex! flex-row justify-center"
        color={enabled ? 'var(--color-primary)' : 'var(--color-cream-50)'}
        on:click={toggleDomainEnabled}
      >
        <svg
          xmlns="http://www.w3.org/2000/svg"
          class="h-9 w-9"
          fill="none"
          viewBox="0 0 24 24"
          stroke="currentColor"
          stroke-width="2"
        >
          <path
          color={enabled ? 'var(--color-cream-50)' : 'var(--color-primary)'}
            stroke-linecap="round"
            stroke-linejoin="round"
            d="M12 5v7m5.657-4.657a8 8 0 11-11.314 0"
          />
        </svg>
      </Button>
  
    <section class="items-end p-2">
      <h1 class="text-2xl dark:text-white text-right">
        {generateGreeting()}
      </h1>
  
      <p class="text-sm font-medium font-sans dark:text-white text-right">
        Harper is {enabled ? 'enabled on ' : 'disabled on '}{domain}
      </p>
    </section>
  </section>
  
  {#if !isFirefox && installDate != null && daysSince(installDate) > 7 && hasBeenReviewed === false}
    <section class="bg-primary flex flex-row justify-between p-4">
      <div class="font-bold">
        It looks like you're enjoying Harper.<br>
        Would you mind giving us a review?
      </div>
      <Button on:click={openReviewPage}>
        Review
      </Button>
    </section>
  {/if}
</main>



================================================
FILE: packages/chrome-plugin/src/popup/Onboarding.svelte
================================================
<script lang="ts">
import { Badge, Button } from 'components';

let { onConfirm }: { onConfirm: () => void } = $props();

const steps = [
	'Start typing in any large text box — emails, docs, blog posts, you name it.',
	'Keep writing — Harper quietly highlights potential hiccups as you go.',
	'Click a highlight to open focused, context‑aware suggestions.',
];
</script>

<main class="p-6 space-y-6">
  <h2 class="text-base font-semibold">
    Welcome! Let’s see Harper in action:
  </h2>

  <ul class="space-y-6">
    {#each steps as line, i}
      <li class="flex gap-4 items-start">
        <Badge class="w-8 h-8 bg-primary-300 text-primary-900 font-semibold flex items-center justify-center rounded-lg dark:bg-slate-900 dark:text-slate-100">
          {i + 1}
        </Badge>
        <p class="text-sm text-gray-700 dark:text-slate-300">{line}</p>
      </li>
    {/each}
  </ul>

  <Button color="primary"  class="w-full h-10" on:click={onConfirm}>
    Let's start writing
  </Button>
</main>



================================================
FILE: packages/chrome-plugin/src/popup/Popup.svelte
================================================
<script lang="ts">
import { faArrowLeft } from '@fortawesome/free-solid-svg-icons';
import { Button, Link } from 'components';
import { onMount } from 'svelte';
import Fa from 'svelte-fa';
import logo from '/logo.png';
import { main, type PopupState } from '../PopupState';
import Main from './Main.svelte';
import Onboarding from './Onboarding.svelte';
import ReportProblematicLint from './ReportProblematicLint.svelte';

let popupState: PopupState = $state({ page: 'main' });

let version = `v${chrome.runtime.getManifest().version}`;
let latestVersion: string | null = $state(null);
let versionMismatch = $state(false);

onMount(async () => {
	try {
		const response = await fetch('https://writewithharper.com/latestversion');
		if (!response.ok) return;

		const fetchedVersion = (await response.text()).trim();
		latestVersion = fetchedVersion;
		versionMismatch = !!fetchedVersion && fetchedVersion !== version;
	} catch (err) {
		console.error('Failed to fetch latest version', err);
	}
});

$effect(() => {
	chrome.storage.local.get({ popupState: { page: 'onboarding' } }).then((result) => {
		popupState = result.popupState;
	});
});

$effect(() => {
	chrome.storage.local.set({ popupState: $state.snapshot(popupState) });
});

function openSettings() {
	chrome.runtime?.openOptionsPage?.();
}
</script>

<div class="w-[340px] border border-gray-200 font-sans flex flex-col rounded-lg shadow-sm select-none dark:border-slate-800 dark:text-slate-100">
  <header class="flex flex-row justify-between items-center gap-2 px-3 py-2 rounded-t-lg">
    <div class="flex flex-row justify-start items-center gap-1">
      <img src={logo} alt="Harper logo" class="h-6 w-auto rounded-lg mx-2" />
      <span class="font-semibold text-sm">Harper</span>
    </div>

    {#if popupState.page != "main"}
       <Button on:click={() => { 
          popupState = main();
       }}><Fa icon={faArrowLeft}/></Button>
    {:else}
      <div>
        {#if versionMismatch}
          <span class="ml-1" title={`Newer version available: ${latestVersion ?? ''}`}>⚠️</span>
        {/if}
        <span class="text-sm font-mono">{version}</span>
      </div>
    {/if}
  </header>

  {#if popupState.page == "onboarding"}
    <Onboarding onConfirm={() => { popupState = main();}} />
  {:else if popupState.page == "main"}
    <Main /> 
  {:else if popupState.page == 'report-error'}
    <ReportProblematicLint example={popupState.example} rule_id={popupState.rule_id} feedback={popupState.feedback} onSubmit={() => { popupState = main();}} />
  {/if}

  <footer class="flex items-center justify-center gap-6 px-3 py-2 text-sm border-t border-gray-100 rounded-b-lg bg-white/60 dark:border-slate-800 dark:bg-slate-900/70 dark:text-slate-100">
    <Link href="https://github.com/Automattic/harper" target="_blank" rel="noopener" class="text-primary">GitHub</Link>
    <Link href="https://discord.com/invite/JBqcAaKrzQ" target="_blank" rel="noopener" class="text-primary">Discord</Link>
    <Link href="https://writewithharper.com" target="_blank" rel="noopener" class="text-primary">Discover</Link>
    <Link on:click={openSettings}>Settings</Link>
  </footer>
</div>



================================================
FILE: packages/chrome-plugin/src/popup/ReportProblematicLint.svelte
================================================
<script lang="ts">
import { Button, Checkbox, Input, Label } from 'components';
import ProtocolClient from '../ProtocolClient';

let {
	rule_id,
	feedback,
	example,
	onSubmit,
}: { rule_id: string; feedback: string; example: string; onSubmit: () => void } = $props();

let submitting = $state(false);

async function handleSubmit(event: SubmitEvent) {
	event.preventDefault();

	submitting = true;

	const success = await ProtocolClient.postFormData(
		'https://writewithharper.com/api/problematic-lints',
		{
			example,
			rule_id,
			feedback,
			is_false_positive: 'true',
		},
	);

	submitting = false;

	if (success) {
		onSubmit();
	}
}
</script>

<div class="p-5">
	<h1 class="text-2xl font-semibold">Report Problematic Lint</h1>
	<p class="text-sm">
		Only the data you enter below will be sent to the Harper maintainer.
	</p>
	<form class="mt-4 space-y-6" onsubmit={handleSubmit}>
		<div class="space-y-3">
			<div class="flex items-baseline gap-2">
				<Label class=" ">What text caused (or should cause) feedback from Harper?</Label>
			</div>
			<Input
				name="example"
				bind:value={example}
				placeholder="Give us an example."
				class="dark:bg-slate-900 dark:border-slate-700 "
			/>

			<Checkbox name="is_false_positive" value="true" hidden />

			<div class="flex items-baseline gap-2">
				<Label class=" ">What rule caused (or should cause) feedback from Harper?</Label>
			</div>
			<Input
				name="rule_id"
				placeholder="We'd appreciate the specific rule ID, if applicable."
				bind:value={rule_id}
				class="dark:bg-slate-900 dark:border-slate-700 "
			/>

			<div class="flex items-baseline gap-2">
				<Label class=" ">Additional Feedback</Label>
			</div>
			<Input
				name="feedback"
				placeholder="Anything you want to add?"
				bind:value={feedback}
				class="dark:bg-slate-900 dark:border-slate-700 "
			/>

			<div class="flex items-center justify-between pt-2">
				<Button type="submit" disabled={submitting}>Submit</Button>
			</div>
		</div>
	</form>
</div>



================================================
FILE: packages/chrome-plugin/tests/draft.spec.ts
================================================
import { expect, test } from './fixtures';
import {
	clickHarperHighlight,
	getDraftEditor,
	getHarperHighlights,
	randomString,
	replaceEditorContent,
	testMultipleSuggestionsAndUndo,
} from './testUtils';

const TEST_PAGE_URL = 'https://draftjs.org/';

test('Can apply basic suggestion.', async ({ page }) => {
	await page.goto(TEST_PAGE_URL);

	const draft = getDraftEditor(page);
	await draft.scrollIntoViewIfNeeded();
	await draft.click();
	await replaceEditorContent(draft, 'This is an test');

	await page.waitForTimeout(3000);

	await clickHarperHighlight(page);
	await page.getByTitle('Replace with "a"').click();

	await page.waitForTimeout(3000);

	await expect(draft).toContainText('This is a test');

	// Verify editor state is preserved: arrow keys and backspace must work.
	// Position cursor before 's' in 'test', then backspace to delete 'e'.
	await draft.press('End');
	await draft.press('ArrowLeft');
	await draft.press('ArrowLeft');
	await draft.press('Backspace');
	await expect(draft).toContainText('This is a tst');

	// Verify typing still works.
	await draft.pressSequentially('e');
	await expect(draft).toContainText('This is a test');
});

testMultipleSuggestionsAndUndo(TEST_PAGE_URL, getDraftEditor, async (editor) => {
	await editor.scrollIntoViewIfNeeded();
	await editor.click();
});

test('Can ignore suggestion.', async ({ page }) => {
	await page.goto(TEST_PAGE_URL);
	const draft = getDraftEditor(page);

	await draft.scrollIntoViewIfNeeded();
	await draft.click();

	const cacheSalt = randomString(5);
	await replaceEditorContent(draft, cacheSalt);

	await page.waitForTimeout(3000);

	const opened = await clickHarperHighlight(page);
	expect(opened).toBe(true);
	await page.getByTitle('Ignore this lint').click();

	await expect(getHarperHighlights(page)).toHaveCount(0);

	// Nothing should change.
	await expect(draft).toContainText(cacheSalt);
	expect(await clickHarperHighlight(page)).toBe(false);
});



================================================
FILE: packages/chrome-plugin/tests/fixtures.ts
================================================
import path from 'path';
import { createFixture } from 'playwright-webextext';

const pathToExtension = path.join(import.meta.dirname, '../build');
const { test, expect } = createFixture(pathToExtension);

test.afterEach(async ({ context }) => {
	const bg = context.serviceWorkers()[0] ?? context.backgroundPages()[0];
	if (bg) await bg.evaluate(() => chrome?.storage?.local.clear?.());
});

export { test, expect };



================================================
FILE: packages/chrome-plugin/tests/github.spec.ts
================================================
import { test } from './fixtures';
import {
	assertHarperHighlightBoxes,
	getTextarea,
	replaceEditorContent,
	testBasicSuggestionTextarea,
	testCanBlockRuleTextareaSuggestion,
	testCanIgnoreTextareaSuggestion,
} from './testUtils';

const TEST_PAGE_URL = 'http://localhost:8081/github_textarea.html';

testBasicSuggestionTextarea(TEST_PAGE_URL);
testCanIgnoreTextareaSuggestion(TEST_PAGE_URL);
testCanBlockRuleTextareaSuggestion(TEST_PAGE_URL);

test('Wraps correctly', async ({ page }) => {
	await page.goto(TEST_PAGE_URL);

	await page.waitForTimeout(2000);
	await page.reload();

	const editor = getTextarea(page);
	await replaceEditorContent(
		editor,
		'This is a test of the Harper grammar checker, specifically   if \nit is wrapped around a line weirdl y',
	);

	await page.waitForTimeout(6000);

	await assertHarperHighlightBoxes(page, [
		{ x: 260.234375, y: 103, width: 67.21875, height: 18 },
		{ x: 512.28125, y: 63, width: 25.21875, height: 18 },
	]);
});

test('Scrolls correctly', async ({ page }) => {
	await page.goto(TEST_PAGE_URL);

	await page.waitForTimeout(2000);
	await page.reload();

	const editor = getTextarea(page);
	await replaceEditorContent(
		editor,
		'This is a test of the the Harper grammar checker, specifically if \n\n\n\n\n\n\n\n\n\n\n\n\nit scrolls beyo nd the height of the buffer.',
	);

	await page.waitForTimeout(6000);

	await assertHarperHighlightBoxes(page, [{ width: 58.828125, x: 117.40625, y: 161, height: 18 }]);
});



================================================
FILE: packages/chrome-plugin/tests/hn.spec.ts
================================================
import type { Page } from '@playwright/test';
import { test } from './fixtures';
import {
	assertHarperHighlightBoxes,
	getTextarea,
	replaceEditorContent,
	testBasicSuggestionTextarea,
	testCanBlockRuleTextareaSuggestion,
	testCanIgnoreTextareaSuggestion,
} from './testUtils';

/** Must be computed. */
async function getTestPageUrl(page: Page) {
	await page.goto('https://news.ycombinator.com');

	const firstLink = page.locator('.subline').first().locator('a').last();
	await firstLink.click();

	return page.url();
}

testBasicSuggestionTextarea(getTestPageUrl);
testCanIgnoreTextareaSuggestion(getTestPageUrl);
testCanBlockRuleTextareaSuggestion(getTestPageUrl);

test('Hacker News wraps correctly', async ({ page }) => {
	await page.goto(await getTestPageUrl(page));

	await page.waitForTimeout(2000);
	await page.reload();

	// Needed because this element has a variable height and may offset the highlight boxes by an unknown amount.
	await page.locator('.toptext').evaluate((el) => el.remove());

	const editor = getTextarea(page);
	await replaceEditorContent(
		editor,
		'This is a test of the Harper grammar checker, specifically   if \nit is wrapped around a line weirdl y',
	);

	await page.waitForTimeout(6000);

	await assertHarperHighlightBoxes(page, [
		{ x: 352.578125, y: 113, width: 63.984375, height: 19 },
		{ x: 592.484375, y: 96, width: 24, height: 19 },
	]);
});

test('Hacker News scrolls correctly', async ({ page }) => {
	await page.goto(await getTestPageUrl(page));

	await page.waitForTimeout(2000);
	await page.reload();

	// Needed because this element has a variable height and may offset the highlight boxes by an unknown amount.
	await page.locator('.toptext').evaluate((el) => el.remove());

	const editor = getTextarea(page);
	await replaceEditorContent(
		editor,
		'This is a test of the the Harper grammar checker, specifically if \n\n\n\n\n\n\n\n\n\n\n\n\nit scrolls beyo nd the height of the buffer.',
	);

	await page.waitForTimeout(6000);

	await assertHarperHighlightBoxes(page, [{ x: 216.625, y: 217, width: 56, height: 19 }]);
});



================================================
FILE: packages/chrome-plugin/tests/lexical.spec.ts
================================================
import { expect, test } from './fixtures';
import {
	clickHarperHighlight,
	getHarperHighlights,
	getLexicalEditor,
	randomString,
	replaceEditorContent,
	testMultipleSuggestionsAndUndo,
} from './testUtils';

const TEST_PAGE_URL = 'https://playground.lexical.dev/';

test('Can apply basic suggestion.', async ({ page }) => {
	await page.goto(TEST_PAGE_URL);

	const lexical = getLexicalEditor(page);
	await replaceEditorContent(lexical, 'This is an test');

	await page.waitForTimeout(3000);

	await clickHarperHighlight(page);
	await page.getByTitle('Replace with "a"').click();

	await page.waitForTimeout(3000);

	await expect(lexical).toContainText('This is a test');

	// Verify editor state is preserved: arrow keys and backspace must work.
	await lexical.press('End');
	await lexical.press('ArrowLeft');
	await lexical.press('ArrowLeft');
	await lexical.press('Backspace');
	await expect(lexical).toContainText('This is a tst');

	// Verify typing still works.
	await lexical.pressSequentially('e');
	await expect(lexical).toContainText('This is a test');
});

testMultipleSuggestionsAndUndo(TEST_PAGE_URL, getLexicalEditor);

test('Can ignore suggestion.', async ({ page }) => {
	await page.goto(TEST_PAGE_URL);
	const lexical = getLexicalEditor(page);

	const cacheSalt = randomString(5);
	await replaceEditorContent(lexical, cacheSalt);

	await page.waitForTimeout(3000);

	const opened = await clickHarperHighlight(page);
	expect(opened).toBe(true);
	await page.getByTitle('Ignore this lint').click();

	await expect(getHarperHighlights(page)).toHaveCount(0);

	// Nothing should change.
	await expect(lexical).toContainText(cacheSalt);
	expect(await clickHarperHighlight(page)).toBe(false);
});



================================================
FILE: packages/chrome-plugin/tests/lexical_webcomponent.spec.ts
================================================
import { expect, test } from './fixtures';
import {
	clickHarperHighlight,
	getHarperHighlights,
	getLexicalEditor,
	replaceEditorContent,
} from './testUtils';

const TEST_PAGE_URL = 'http://localhost:8081/lexical_webcomponent.html';

test.describe('Lexical webcomponent regression', () => {
	test.skip(
		({ browserName }) => browserName === 'firefox',
		'Firefox extension build lacks background scripts',
	);
	test('Applying a suggestion does not duplicate text', async ({ page }) => {
		await page.goto(TEST_PAGE_URL);

		const lexical = getLexicalEditor(page);
		const mirror = page.locator('#lexical-mirror');
		const initialText = 'This is an test. This is an test again.';
		await replaceEditorContent(lexical, initialText);

		await page.waitForTimeout(6000);
		await expect(mirror).toHaveText(initialText);

		await clickHarperHighlight(page);
		await page.getByTitle('Replace with "a"').click();

		await page.waitForTimeout(3000);
		const afterFirst = 'This is a test. This is an test again.';
		await expect(lexical).toHaveText(afterFirst);
		await expect(mirror).toHaveText(afterFirst);
		await expect(getHarperHighlights(page)).toHaveCount(1);

		await clickHarperHighlight(page);
		await page.getByTitle('Replace with "a"').click();

		await page.waitForTimeout(3000);
		const finalText = 'This is a test. This is a test again.';
		await expect(lexical).toHaveText(finalText);
		await expect(mirror).toHaveText(finalText);
		await expect(getHarperHighlights(page)).toHaveCount(0);

		const lexicalText = (await lexical.textContent()) ?? '';
		const mirrorText = (await mirror.textContent()) ?? '';
		expect(lexicalText.trim()).toBe(mirrorText.trim());

		// Verify editor state is preserved: arrow keys and backspace must work.
		await lexical.press('End');
		await lexical.press('Backspace');
		await expect(lexical).toContainText('This is a test. This is a test again');

		// Verify typing still works.
		await lexical.pressSequentially('.');
		await expect(lexical).toContainText('This is a test. This is a test again.');
	});
});



================================================
FILE: packages/chrome-plugin/tests/lint-kinds.spec.ts
================================================
import { test } from '@playwright/test';
import { LINT_KINDS, lintKindColor } from 'lint-framework';

// biome-ignore lint/correctness/noEmptyPattern: Playwright requires an object destruction
test('display lint kind colors', async ({}, testInfo) => {
	// Generate color boxes for each lint kind
	const colorBoxes = LINT_KINDS.map((kind) => {
		const color = lintKindColor(kind);
		return `<div class="color-box" style="background-color: ${color}">${kind}</div>`;
	}).join('\n');

	const htmlContent = `
    <!DOCTYPE html>
    <html>
    <head>
      <title>Lint Kind Colors</title>
      <style>
        body {
          font-family: Arial, sans-serif;
          padding: 20px;
          background: #f5f5f5;
        }
        h1 {
          color: #333;
          margin-top: 0;
        }
        .container {
          display: flex;
          flex-wrap: wrap;
          gap: 10px;
          margin-top: 20px;
        }
        .color-box {
          padding: 10px 20px;
          border-radius: 4px;
          color: white;
          font-weight: bold;
          box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
      </style>
    </head>
    <body>
      <h1>Lint Kind Colors</h1>
      <div class="container">
        ${colorBoxes}
      </div>
    </body>
    </html>
  `;

	// Attach the HTML report
	await testInfo.attach('lint-colors.html', {
		body: htmlContent,
		contentType: 'text/html',
	});
});



================================================
FILE: packages/chrome-plugin/tests/nested_elements.spec.ts
================================================
import { test } from './fixtures';
import { assertHarperHighlightBoxes, getTextarea, replaceEditorContent } from './testUtils';

const TEST_PAGE_URL = 'http://localhost:8081/nested_elements.html';

test('Positions properly in oddly nested page.', async ({ page }, _testInfo) => {
	await page.goto(TEST_PAGE_URL);

	const editor = getTextarea(page);
	await replaceEditorContent(
		editor,
		'This is an test of the Harper grammar checker, specifically   if \n the highlights are positionasd properly.',
	);

	await page.waitForTimeout(6000);

	await assertHarperHighlightBoxes(page, [
		{ x: 396.390625, y: 243, width: 15.625, height: 19 },
		{ x: 794.1875, y: 243, width: 23.421875, height: 19 },
		{ x: 490, y: 260, width: 85.828125, height: 19 },
	]);
});



================================================
FILE: packages/chrome-plugin/tests/prosemirror.spec.ts
================================================
import { expect, test } from './fixtures';
import {
	clickHarperHighlight,
	getHarperHighlights,
	getProseMirrorEditor,
	randomString,
	replaceEditorContent,
	testMultipleSuggestionsAndUndo,
} from './testUtils';

const TEST_PAGE_URL = 'https://prosemirror.net/';

test('Can apply basic suggestion.', async ({ page }) => {
	await page.goto(TEST_PAGE_URL);

	const pm = getProseMirrorEditor(page);
	await replaceEditorContent(pm, 'This is an test');

	await page.waitForTimeout(3000);

	await clickHarperHighlight(page);
	await page.getByTitle('Replace with "a"').click();

	await page.waitForTimeout(3000);

	await expect(pm).toContainText('This is a test');
	await pm.press('Control+ArrowDown');

	await pm.pressSequentially(' of Harper’s grammar checking.');
	await expect(pm).toContainText('This is a test of Harper’s grammar checking.');
});

testMultipleSuggestionsAndUndo(TEST_PAGE_URL, getProseMirrorEditor);

test('Can ignore suggestion.', async ({ page }) => {
	await page.goto(TEST_PAGE_URL);
	const pm = getProseMirrorEditor(page);

	const cacheSalt = randomString(5);
	await replaceEditorContent(pm, cacheSalt);

	await page.waitForTimeout(3000);

	const opened = await clickHarperHighlight(page);
	expect(opened).toBe(true);
	await page.getByTitle('Ignore this lint').click();

	await expect(getHarperHighlights(page)).toHaveCount(0);

	// Nothing should change.
	await expect(pm).toContainText(cacheSalt);
	expect(await clickHarperHighlight(page)).toBe(false);
});



================================================
FILE: packages/chrome-plugin/tests/quill.spec.ts
================================================
import { testPageHasNHighlights } from './testUtils';

const TEST_PAGE_URL = 'http://localhost:8081/quill_simple.html';

testPageHasNHighlights(TEST_PAGE_URL, 1);



================================================
FILE: packages/chrome-plugin/tests/review_banner.spec.ts
================================================
import { expect, test } from './fixtures';

test.describe('review banner', () => {
	test.skip(({ browserName }) => browserName === 'firefox', 'Review prompt disabled in Firefox');

	test('review request hidden before 7 days', async ({ context, page }) => {
		const background = context.serviceWorkers()[0] ?? (await context.waitForEvent('serviceworker'));
		const extensionId = background.url().split('/')[2];

		const popupUrl = `chrome-extension://${extensionId}/popup.html`;
		await page.goto(popupUrl);

		await page.getByText("Let's start writing").click();

		await expect(page.getByText('Harper is')).toBeVisible();
		await expect(page.getByText('Would you mind giving us a review?')).toHaveCount(0);
	});

	test('review request shown after 7 days', async ({ context, page }) => {
		const background = context.serviceWorkers()[0] ?? (await context.waitForEvent('serviceworker'));
		const extensionId = background.url().split('/')[2];

		const popupUrl = `chrome-extension://${extensionId}/popup.html`;
		await page.goto(popupUrl);

		// 8 days
		await page.clock.install();
		await page.clock.fastForward(8 * 1000 * 60 * 60 * 24);

		await page.getByText("Let's start writing").click();

		await expect(page.getByText('Harper is')).toBeVisible();
		await expect(page.getByText('Would you mind giving us a review?')).toHaveCount(1);
	});
});



================================================
FILE: packages/chrome-plugin/tests/simple_inputs_disabled.spec.ts
================================================
import { test } from './fixtures';
import { assertHarperHighlightBoxes } from './testUtils';

const TEST_PAGE_URL = 'http://localhost:8081/simple_inputs_disabled.html';

test('Ignores disabled and readonly inputs', async ({ page }) => {
	await page.goto(TEST_PAGE_URL);

	await page.waitForTimeout(6000);

	// All inputs on this page are disabled or read-only, so no lint boxes should be drawn.
	await assertHarperHighlightBoxes(page, []);
});



================================================
FILE: packages/chrome-plugin/tests/simple_textarea.spec.ts
================================================
import { test } from './fixtures';
import {
	assertHarperHighlightBoxes,
	assertLocatorIsFocused,
	clickHarperHighlight,
	getTextarea,
	replaceEditorContent,
	testBasicSuggestionTextarea,
	testCanBlockRuleTextareaSuggestion,
	testCanIgnoreTextareaSuggestion,
} from './testUtils';

const TEST_PAGE_URL = 'http://localhost:8081/simple_textarea.html';

testBasicSuggestionTextarea(TEST_PAGE_URL);
testCanIgnoreTextareaSuggestion(TEST_PAGE_URL);
testCanBlockRuleTextareaSuggestion(TEST_PAGE_URL);

test('Wraps correctly', async ({ page }, testInfo) => {
	await page.goto(TEST_PAGE_URL);

	const editor = getTextarea(page);
	await replaceEditorContent(
		editor,
		'This is a test of the Harper grammar checker, specifically   if \nit is wrapped around a line weirdl y',
	);

	await page.waitForTimeout(6000);

	if (testInfo.project.name == 'chromium') {
		await assertHarperHighlightBoxes(page, [
			{ x: 233.90625, y: 44, width: 48, height: 19 },
			{ x: 281.90625, y: 44, width: 8, height: 19 },
			{ x: 10, y: 61, width: 8, height: 19 },
			{ x: 241.90625, y: 27, width: 24, height: 19 },
		]);
	} else {
		await assertHarperHighlightBoxes(page, [
			{ x: 10, y: 71, width: 57.599998474121094, height: 17 },
			{ x: 218.8000030517578, y: 26, width: 21.600006103515625, height: 17 },
		]);
	}
});

test('Scrolls correctly', async ({ page }) => {
	await page.goto(TEST_PAGE_URL);

	const editor = getTextarea(page);
	await replaceEditorContent(
		editor,
		'This is a test of the the Harper grammar checker, specifically if \n\n\n\n\n\n\n\n\n\n\n\n\nit scrolls beyo nd the height of the buffer.',
	);

	await page.waitForTimeout(6000);

	await assertHarperHighlightBoxes(page, [{ height: 19, width: 56, x: 97.953125, y: 63 }]);
});

test('Can dismiss with escape key', async ({ page }) => {
	await page.goto(TEST_PAGE_URL);

	const editor = getTextarea(page);
	await replaceEditorContent(
		editor,
		'This is a test of the Harper grammar checker, specifically   if it is wrapped around a line weirdl y',
	);

	await page.waitForTimeout(6000);

	await clickHarperHighlight(page);

	await page.locator('.harper-container').waitFor({ state: 'visible' });

	await page.keyboard.press('Escape');

	await page.locator('.harper-container').waitFor({ state: 'hidden' });

	await assertLocatorIsFocused(page, editor);
});



================================================
FILE: packages/chrome-plugin/tests/slate.spec.ts
================================================
import { expect, test } from './fixtures';
import {
	clickHarperHighlight,
	getHarperHighlights,
	getSlateEditor,
	randomString,
	replaceEditorContent,
	testMultipleSuggestionsAndUndo,
} from './testUtils';

const TEST_PAGE_URL = 'https://slatejs.org';

test('Can apply basic suggestion.', async ({ page }) => {
	await page.goto(TEST_PAGE_URL);

	const slate = getSlateEditor(page);
	await replaceEditorContent(slate, 'This is an test');

	await page.waitForTimeout(3000);

	await clickHarperHighlight(page);
	await page.getByTitle('Replace with "a"').click();

	await page.waitForTimeout(3000);

	await expect(slate).toContainText('This is a test');

	// Verify editor state is preserved: arrow keys and backspace must work.
	// Position cursor before 's' in 'test', then backspace to delete 'e'.
	await page.press('body', 'End');
	await page.press('body', 'ArrowLeft');
	await page.press('body', 'ArrowLeft');
	await page.press('body', 'Backspace');
	await expect(slate).toContainText('This is a tst');

	// Verify typing still works.
	await slate.pressSequentially('e');
	await expect(slate).toContainText('This is a test');
});

testMultipleSuggestionsAndUndo(TEST_PAGE_URL, getSlateEditor);

test('Can ignore suggestion.', async ({ page }) => {
	await page.goto(TEST_PAGE_URL);
	const slate = getSlateEditor(page);

	const cacheSalt = randomString(5);
	await replaceEditorContent(slate, cacheSalt);

	await page.waitForTimeout(3000);

	const opened = await clickHarperHighlight(page);
	expect(opened).toBe(true);
	await page.getByTitle('Ignore this lint').click();

	await expect(getHarperHighlights(page)).toHaveCount(0);

	// Nothing should change.
	await expect(slate).toContainText(cacheSalt);
	expect(await clickHarperHighlight(page)).toBe(false);
});



================================================
FILE: packages/chrome-plugin/tests/testUtils.ts
================================================
import type { Locator, Page } from '@playwright/test';
import type { Box } from 'lint-framework';
import { expect, test } from './fixtures';

export function randomString(length: number): string {
	const chars = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz';
	let result = '';
	for (let i = 0; i < length; i++) {
		result += chars.charAt(Math.floor(Math.random() * chars.length));
	}
	return result;
}

/** Locate the [`Slate`](https://www.slatejs.org/examples/richtext) editor on the page.  */
export function getSlateEditor(page: Page): Locator {
	return page.locator('[data-slate-editor="true"]');
}

/** Locate the [`Lexical`](https://lexical.dev/) editor on the page.  */
export function getLexicalEditor(page: Page): Locator {
	return page.locator('[data-lexical-editor="true"]');
}

/** Locate the ProseMirror editor on the page.  */
export function getProseMirrorEditor(page: Page): Locator {
	return page.locator('.ProseMirror');
}

/** Locate the Draft.js editor on the page (targets #rich-example on draftjs.org). */
export function getDraftEditor(page: Page): Locator {
	return page.locator('#rich-example .public-DraftEditor-content');
}

/** Replace the content of a text editor. Handles newlines by pressing Enter. */
export async function replaceEditorContent(editorEl: Locator, text: string) {
	await editorEl.selectText();
	await editorEl.press('Backspace');

	const lines = text.split('\n');
	for (let i = 0; i < lines.length; i++) {
		await editorEl.pressSequentially(lines[i]);
		if (i < lines.length - 1) {
			await editorEl.press('Enter');
		}
	}
}

/** Locate the Harper highlights on a page. */
export function getHarperHighlights(page: Page): Locator {
	return page.locator('#harper-highlight');
}

export async function assertLocatorIsFocused(page: Page, loc: Locator) {
	await assertLocatorsResolveEqually(page, loc, page.locator(':focus'));
}

/**  Checks that the two provided locators resolve to the same element. */
export async function assertLocatorsResolveEqually(page: Page, a: Locator, b: Locator) {
	const areSame = await page.evaluate(
		([a, b]) => a === b,
		[await a.elementHandle(), await b.elementHandle()],
	);

	expect(areSame).toBe(true);
}

/** Locates the first Harper highlight on the page and clicks it.
 * It should result in the popup opening.
 * Returns whether the highlight was found. */
export async function clickHarperHighlight(page: Page): Promise<boolean> {
	const highlights = getHarperHighlights(page);

	// Wait briefly for at least one highlight to appear.
	// If none appear within a reasonable time, return false.
	try {
		await highlights.first().waitFor({ state: 'visible', timeout: 5000 });
	} catch {
		return false;
	}

	const box = await highlights.first().boundingBox();
	if (box == null) return false;

	// Locate the center of the element and click to open the popup.
	const cx = box.x + box.width / 2;
	const cy = box.y + box.height / 2;
	await page.mouse.click(cx, cy);
	return true;
}

/** Grab the first `<textarea />` on a page. */
export function getTextarea(page: Page): Locator {
	return page.locator('textarea');
}

/** A string or function that resolves to a test page. */
export type TestPageUrlProvider = string | ((page: Page) => Promise<string>);

/** A function that returns an editor locator. */
export type EditorLocatorProvider = (page: Page) => Locator;

async function resolveTestPage(prov: TestPageUrlProvider, page: Page): Promise<string> {
	if (typeof prov === 'string') {
		return prov;
	} else {
		return await prov(page);
	}
}

export async function testBasicSuggestionTextarea(testPageUrl: TestPageUrlProvider) {
	test('Can apply basic suggestion.', async ({ page }) => {
		const url = await resolveTestPage(testPageUrl, page);
		await page.goto(url);

		await page.waitForTimeout(2000);
		await page.reload();

		const editor = getTextarea(page);
		await replaceEditorContent(editor, 'This is an test');

		await page.waitForTimeout(6000);

		await clickHarperHighlight(page);
		await page.getByTitle('Replace with "a"').click();

		await page.waitForTimeout(3000);

		expect(editor).toHaveValue('This is a test');
		await assertLocatorIsFocused(page, editor);
	});
}

export async function testCanIgnoreTextareaSuggestion(testPageUrl: TestPageUrlProvider) {
	test('Can ignore suggestion.', async ({ page }) => {
		const url = await resolveTestPage(testPageUrl, page);
		await page.goto(url);

		await page.waitForTimeout(2000);
		await page.reload();

		const editor = getTextarea(page);

		const cacheSalt = randomString(5);
		await replaceEditorContent(editor, cacheSalt);

		await page.waitForTimeout(6000);

		// Open the popup for the first highlight and click Ignore.
		const opened = await clickHarperHighlight(page);
		expect(opened).toBe(true);
		await page.getByTitle('Ignore this lint').click();

		// Wait for highlights to disappear after ignoring.
		await expect(getHarperHighlights(page)).toHaveCount(0);

		// Nothing should change.
		expect(editor).toHaveValue(cacheSalt);
		expect(await clickHarperHighlight(page)).toBe(false);
		await assertLocatorIsFocused(page, editor);
	});
}

export async function testCanBlockRuleTextareaSuggestion(testPageUrl: TestPageUrlProvider) {
	test('Can hide with rule block button', async ({ page }) => {
		const url = await resolveTestPage(testPageUrl, page);
		await page.goto(url);

		const editor = getTextarea(page);
		await replaceEditorContent(editor, 'This is an test.');

		await page.waitForTimeout(6000);

		await clickHarperHighlight(page);

		await page.getByTitle('Disable the AnA rule').click();

		await page.waitForTimeout(1000);

		await assertHarperHighlightBoxes(page, []);
		await assertLocatorIsFocused(page, editor);
	});
}

/** Get highlight bounding boxes sorted by visual position (top to bottom, left to right). */
async function getSortedHighlightBoxes(page: Page) {
	const highlights = getHarperHighlights(page);
	const count = await highlights.count();
	const boxes: NonNullable<Awaited<ReturnType<Locator['boundingBox']>>>[] = [];

	for (let i = 0; i < count; i++) {
		const box = await highlights.nth(i).boundingBox();
		if (box) {
			boxes.push(box);
		}
	}

	boxes.sort((a, b) => (Math.abs(a.y - b.y) > 5 ? a.y - b.y : a.x - b.x));

	return boxes;
}

/** Test multiline suggestion replacement and undo. */
export async function testMultipleSuggestionsAndUndo(
	testPageUrl: TestPageUrlProvider,
	getEditor: EditorLocatorProvider,
	setup?: (editor: Locator) => Promise<void>,
) {
	test('Multiple suggestions and undo.', async ({ page }) => {
		const url = await resolveTestPage(testPageUrl, page);
		await page.goto(url);

		const editor = getEditor(page);
		if (setup) {
			await setup(editor);
		}
		await replaceEditorContent(editor, 'The first tset.\nThe second tset.\nThe third tset.');

		await page.waitForTimeout(3000);

		const highlights = getHarperHighlights(page);
		await expect(highlights).toHaveCount(3);

		// Get highlights sorted by visual position and click on the middle one
		const sortedBoxes = await getSortedHighlightBoxes(page);
		expect(sortedBoxes.length).toBe(3);
		const box = sortedBoxes[1];
		await page.mouse.click(box.x + box.width / 2, box.y + box.height / 2);

		// Move cursor away to test whether it handles race condition
		await editor.press('End');

		await page.getByTitle('Replace with "test"').click();
		await page.waitForTimeout(500);

		// Verify only second "tset" was corrected
		await expect(editor).toContainText('first tset');
		await expect(editor).toContainText('second test');
		await expect(editor).toContainText('third tset');

		// Undo
		await editor.press('Control+z');
		await page.waitForTimeout(300);
		await expect(editor).toContainText('The second tset');
	});
}

export async function assertHarperHighlightBoxes(page: Page, boxes: Box[]): Promise<void> {
	const highlights = getHarperHighlights(page);
	await expect(highlights).toHaveCount(boxes.length);

	for (let i = 0; i < (await highlights.count()); i++) {
		const box = await highlights.nth(i).boundingBox();
		expect(box).not.toBeNull();

		console.log(`Expected: ${JSON.stringify(boxes[i])}`);
		console.log(`Got: ${JSON.stringify(box)}`);

		assertBoxesClose(box!, boxes[i]);
	}
}

/** Create a test to assert that a page has a certain number highlights.
 * Wraps `assertPageHasNHighlights` */
export async function testPageHasNHighlights(testPageUrl: TestPageUrlProvider, n: number) {
	test(`Page has ${n} highlights`, async ({ page }) => {
		const url = await resolveTestPage(testPageUrl, page);
		await page.goto(url);

		await page.waitForTimeout(6000);

		assertPageHasNHighlights(page, n);
	});
}

/** Assert that the page has a specific number of highlights.
 * Useful for making sure certain patterns are ignored. */
export async function assertPageHasNHighlights(page: Page, n: number) {
	const highlights = getHarperHighlights(page);
	expect(await highlights.count()).toBe(n);
}

/** An assertion that checks to ensure that two boxes are _approximately_ equal.
 * Leaves wiggle room for floating point error. */
export function assertBoxesClose(a: Box, b: Box) {
	assertClose(a.x, b.x);
	assertClose(a.y, b.y);
	assertClose(a.width, b.width);
	assertClose(a.height, b.height);
}

function assertClose(actual: number, expected: number) {
	expect(Math.abs(actual - expected)).toBeLessThanOrEqual(15);
}



================================================
FILE: packages/chrome-plugin/tests/pages/lexical_webcomponent.html
================================================
<!DOCTYPE html>
<html>
  <head>
    <meta charset="UTF-8" />
    <title>Lexical Webcomponent Test</title>
    <style>
      body {
        font-family: sans-serif;
        padding: 2rem;
      }
      reddit-lexical-editor {
        display: block;
        max-width: 600px;
      }
      [data-lexical-editor="true"] {
        border: 1px solid #ccc;
        padding: 1rem;
        min-height: 150px;
        border-radius: 8px;
      }
    </style>
  </head>
  <body>
    <h1>Lexical Editor Inside Webcomponent</h1>
    <reddit-lexical-editor></reddit-lexical-editor>
    <section aria-live="polite" id="lexical-mirror" style="margin-top: 1rem; font-weight: bold;"></section>

    <script type="module">
      class RedditLexicalEditor extends HTMLElement {
        constructor() {
          super();
          this._init();
        }

        _init() {
          const editor = document.createElement('div');
          editor.setAttribute('contenteditable', 'true');
          editor.setAttribute('data-lexical-editor', 'true');
          editor.textContent = 'This is an test';

          const mirror = document.getElementById('lexical-mirror');
          const syncMirror = () => {
            if (mirror) mirror.textContent = editor.textContent ?? '';
          };

          // Simulates WhatsApp's Lexical: tracks cursor internally, ignores programmatic selection
          let internalCursorPosition = 0;

          editor.addEventListener('click', () => {
            const sel = window.getSelection();
            if (sel && sel.rangeCount > 0) {
              const range = sel.getRangeAt(0);
              const preRange = document.createRange();
              preRange.selectNodeContents(editor);
              preRange.setEnd(range.startContainer, range.startOffset);
              internalCursorPosition = preRange.toString().length;
            }
          });

          editor.addEventListener('beforeinput', (event) => {
            if (
              event.isTrusted === false &&
              event.inputType === 'insertText' &&
              typeof event.data === 'string'
            ) {
              event.preventDefault();
              // Mimic Reddit's Lexical behaviour that applies the full change
              // in response to synthetic beforeinput events emitted by our
              // extension when a suggestion is accepted.
              setTimeout(() => {
                const currentText = editor.textContent ?? '';
                const newText =
                  currentText.slice(0, internalCursorPosition) +
                  event.data +
                  currentText.slice(internalCursorPosition);
                editor.textContent = newText;
                syncMirror();
              }, 0);
            }
          });

          editor.addEventListener('input', syncMirror);
          editor.addEventListener('keyup', syncMirror);

          syncMirror();

          this.append(editor);
        }
      }

      customElements.define('reddit-lexical-editor', RedditLexicalEditor);
    </script>
  </body>
</html>



================================================
FILE: packages/chrome-plugin/tests/pages/nested_elements.html
================================================
<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>Textarea Ancestor Positioning Hierarchy Test</title>
    <style>
      html,
      body {
        height: 100%;
        margin: 0;
      }

      #hgl-container {
        position: fixed;
        top: 50%;
        left: 50%;
        transform: translate(-50%, -50%);
        width: 50vw;
        height: 50vh;
        z-index: 2147483647;
        background: rgb(255, 255, 255);
        color: rgb(0, 0, 0);
        border: 1px solid #ccc;
        padding: 0;
        box-shadow: 0 4px 16px rgba(0, 0, 0, 0.25);
        box-sizing: border-box;
        display: flex;
        flex-direction: column;
        font-family: system-ui, -apple-system, sans-serif;
      }

      #hgl-titlebar {
        background-color: #f0f0f0;
        color: rgb(0, 0, 0);
        padding: 8px 12px;
        display: flex;
        justify-content: space-between;
        align-items: center;
        cursor: move;
        user-select: none;
        border-bottom: 1px solid #ccc;
        font-size: 13px;
        font-weight: 500;
        min-height: 32px;
        box-sizing: border-box;
      }

      #hgl-close {
        background: none;
        border: none;
        cursor: pointer;
        font-size: 20px;
        padding: 0 4px;
        color: rgb(0, 0, 0);
        min-width: 32px;
        min-height: 32px;
        display: flex;
        align-items: center;
        justify-content: center;
        flex: 0 0 auto;
      }

      #hgl-wrapper {
        flex: 1;
        overflow: hidden;
        padding: 4px;
        box-sizing: border-box;
        position: relative;
      }

      #hgl-textarea {
        width: 100%;
        height: 100%;
        box-sizing: border-box;
        border: none;
        font-family: monospace;
        font-size: 13px;
        resize: none;
        padding: 8px;
        color: rgb(0, 0, 0);
        background-color: rgb(255, 255, 255);
      }

      #hgl-resize {
        position: absolute;
        bottom: 0;
        right: 0;
        width: 16px;
        height: 16px;
        cursor: nwse-resize;
        display: flex;
        align-items: center;
        justify-content: center;
        font-size: 14px;
        color: #999;
        pointer-events: none;
        user-select: none;
      }
    </style>
  </head>
  <body>
    <div id="hgl-container">
      <div id="hgl-titlebar">
        <span>Layout test</span>
        <button id="hgl-close" type="button" aria-label="Close">✕</button>
      </div>

      <div id="hgl-wrapper">
        <textarea id="hgl-textarea" spellcheck="false">Textarea content…</textarea>
        <div id="hgl-resize">⋱</div>
      </div>
    </div>
  </body>
</html>



================================================
FILE: packages/chrome-plugin/tests/pages/simple_inputs_disabled.html
================================================
<!DOCTYPE html>
<html>

<body>
  <h1>disabled Textarea</h1>
  <textarea rows="5" cols="33" disabled>tis iss a mispeled sentce</textarea>

  <h1>readonly Textarea</h1>
  <textarea rows="5" cols="33" readonly>tis iss a mispeled sentce</textarea>

  <h1>readonly + disabled Textarea</h1>
  <textarea rows="5" cols="33" disabled readonly>tis iss a mispeled sentce</textarea>

  <h1>disabled Input</h1>
  <input type="text" spellcheck="true" disabled value="This is an test">

  <h1>readonly Input</h1>
  <input type="text" spellcheck="true" readonly value="This is an test">

  <h1>readonly + disabled Input</h1>
  <input type="text" spellcheck="true" readonly disabled value="This is an test">
</body>

</html>



================================================
FILE: packages/chrome-plugin/tests/pages/simple_textarea.html
================================================
<!DOCTYPE html>
<html>
  <body>
    <textarea rows="5" cols="33"></textarea>
  </body>
</html> 



================================================
FILE: packages/components/package.json
================================================
{
	"name": "components",
	"version": "0.0.1",
	"scripts": {
		"dev": "vite dev",
		"build": "vite build && npm run prepack",
		"build:css": "TAILWIND_MODE=build tailwindcss -i ./src/lib/styles.css -o ./dist/components.css --minify",
		"preview": "vite preview",
		"prepare": "svelte-kit sync || echo ''",
		"prepack": "svelte-kit sync && svelte-package && pnpm run build:css && publint",
		"check": "svelte-kit sync && svelte-check --tsconfig ./tsconfig.json",
		"check:watch": "svelte-kit sync && svelte-check --tsconfig ./tsconfig.json --watch"
	},
	"files": [
		"dist",
		"!dist/**/*.test.*",
		"!dist/**/*.spec.*"
	],
	"style": "./dist/components.css",
	"sideEffects": [
		"**/*.css"
	],
	"svelte": "./dist/index.js",
	"types": "./dist/index.d.ts",
	"type": "module",
	"exports": {
		".": {
			"types": "./dist/index.d.ts",
			"svelte": "./dist/index.js"
		},
		"./components.css": "./dist/components.css",
		"./style.css": "./dist/components.css"
	},
	"peerDependencies": {
		"svelte": "^5.0.0"
	},
	"dependencies": {
		"flowbite-svelte": "^0.44.24"
	},
	"devDependencies": {
		"@sveltejs/adapter-auto": "^7.0.0",
		"@sveltejs/kit": "^2.47.1",
		"@sveltejs/package": "^2.5.4",
		"@sveltejs/vite-plugin-svelte": "^6.2.1",
		"@tailwindcss/cli": "^4.1.16",
		"@tailwindcss/vite": "^4.1.14",
		"flowbite": "^3.1.2",
		"publint": "^0.3.14",
		"svelte": "^5.41.0",
		"svelte-check": "^4.3.3",
		"tailwindcss": "^4.1.14",
		"typescript": "catalog:",
		"vite": "^7.1.10"
	},
	"keywords": [
		"svelte"
	]
}



================================================
FILE: packages/components/svelte.config.js
================================================
import adapter from '@sveltejs/adapter-auto';
import { vitePreprocess } from '@sveltejs/vite-plugin-svelte';

/** @type {import('@sveltejs/kit').Config} */
const config = {
	// Consult https://svelte.dev/docs/kit/integrations
	// for more information about preprocessors
	preprocess: vitePreprocess(),

	kit: {
		// adapter-auto only supports some environments, see https://svelte.dev/docs/kit/adapter-auto for a list.
		// If your environment is not supported, or you settled on a specific environment, switch out the adapter.
		// See https://svelte.dev/docs/kit/adapters for more information about adapters.
		adapter: adapter(),
	},
};

export default config;



================================================
FILE: packages/components/tsconfig.json
================================================
{
	"extends": "./.svelte-kit/tsconfig.json",
	"compilerOptions": {
		"allowImportingTsExtensions": true,
		"allowJs": true,
		"checkJs": true,
		"esModuleInterop": true,
		"forceConsistentCasingInFileNames": true,
		"resolveJsonModule": true,
		"skipLibCheck": true,
		"sourceMap": true,
		"strict": true,
		"module": "NodeNext",
		"moduleResolution": "NodeNext"
	}
}



================================================
FILE: packages/components/vite.config.ts
================================================
import { sveltekit } from '@sveltejs/kit/vite';
import tailwindcss from '@tailwindcss/vite';
import { defineConfig } from 'vite';

export default defineConfig({
	plugins: [tailwindcss(), sveltekit()],
});



================================================
FILE: packages/components/.npmrc
================================================
engine-strict=true



================================================
FILE: packages/components/src/app.d.ts
================================================
// See https://svelte.dev/docs/kit/types#app.d.ts
// for information about these interfaces
declare global {
	namespace App {
		// interface Error {}
		// interface Locals {}
		// interface PageData {}
		// interface PageState {}
		// interface Platform {}
	}
}

export {};



================================================
FILE: packages/components/src/app.html
================================================
<!doctype html>
<html lang="en">
	<head>
		<meta charset="utf-8" />
		<link rel="icon" href="%sveltekit.assets%/favicon.svg" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		%sveltekit.head%
	</head>
	<body data-sveltekit-preload-data="hover">
		<div style="display: contents">%sveltekit.body%</div>
	</body>
</html>



================================================
FILE: packages/components/src/lib/Button.svelte
================================================
<script lang="ts">
import { createEventDispatcher } from 'svelte';
import type { AnchorHTMLAttributes, ButtonHTMLAttributes } from 'svelte/elements';
import Link from './Link.svelte';

type ButtonSize = 'xs' | 'sm' | 'md' | 'lg';
type ButtonColor = 'primary' | 'light' | 'gray' | 'white' | 'dark';

export let size: ButtonSize = 'md';
export let color: ButtonColor | string = 'primary';
export let textColor: string | undefined = undefined;
export let pill = false;
export let href: AnchorHTMLAttributes['href'] = undefined;
export let target: AnchorHTMLAttributes['target'] = undefined;
export let rel: AnchorHTMLAttributes['rel'] = undefined;
export let type: ButtonHTMLAttributes['type'] = 'button';
export let disabled: boolean | undefined = undefined;
// Alias for the `class` attribute since `class` is a reserved TS keyword
export let className: string | undefined = undefined;

let restClass: string | undefined;
let restProps: Record<string, unknown> = {};
const dispatch = createEventDispatcher();

const sizeClasses: Record<ButtonSize, string> = {
	xs: 'px-3 py-2 text-xs',
	sm: 'px-3 py-2 text-sm',
	md: 'px-4 py-2.5 text-sm',
	lg: 'px-5 py-3 text-base',
};

const colorClasses: Record<ButtonColor, string> = {
	primary:
		'text-white bg-primary-600 hover:bg-primary-700 focus:ring-primary-300 dark:bg-primary-500 dark:hover:bg-primary-600 dark:focus:ring-primary-700',
	light:
		'text-gray-900 bg-white border border-gray-200 hover:bg-gray-100 focus:ring-gray-200 dark:bg-gray-800 dark:text-gray-300 dark:border-gray-600 dark:hover:bg-gray-700 dark:focus:ring-gray-700',
	gray: 'text-white bg-gray-800 hover:bg-gray-900 focus:ring-gray-300 dark:bg-gray-700 dark:hover:bg-gray-800 dark:focus:ring-gray-900',
	white:
		'text-gray-900 bg-white border border-gray-200 hover:bg-gray-100 focus:ring-gray-200 dark:bg-gray-800 dark:text-gray-300 dark:border-gray-600 dark:hover:bg-gray-700 dark:focus:ring-gray-700',
	dark: 'text-white bg-gray-900 hover:bg-black focus:ring-gray-300 dark:bg-gray-800 dark:hover:bg-black dark:focus:ring-gray-900',
};
const baseClasses =
	'cursor-pointer inline-flex items-center gap-2 justify-center font-medium text-center transition-colors focus:outline-none focus:ring-4 disabled:opacity-50 disabled:cursor-not-allowed';

$: toneClass = colorClasses[color as ButtonColor] ?? colorClasses.primary;
$: shapeClass = pill ? 'rounded-full' : 'rounded-lg';
$: sizeClass = sizeClasses[size] ?? sizeClasses.md;
$: ({ class: restClass, ...restProps } = $$restProps);
$: classes = [baseClasses, shapeClass, sizeClass, toneClass, restClass, className]
	.filter(Boolean)
	.join(' ');

$: colorOverride = colorClasses[color as ButtonColor] == null ? color : undefined;
$: inlineStyle =
	colorOverride || textColor
		? [
				colorOverride ? `background-color: ${colorOverride} !important;` : null,
				textColor ? `color: ${textColor} !important;` : null,
			]
				.filter(Boolean)
				.join(' ')
		: undefined;

function handleClick(event: MouseEvent) {
	if (disabled) {
		event.preventDefault();
		event.stopPropagation();
		return;
	}

	dispatch('click', event);
}
</script>

{#if href}
	<Link
		class={classes}
		style={inlineStyle}
		href={disabled ? undefined : href}
		aria-disabled={disabled}
		role={disabled ? 'link' : undefined}
		tabindex={disabled ? -1 : undefined}
		rel={rel}
		target={target}
		on:click={handleClick}
		{...restProps}
	>
		<slot />
	</Link>
{:else}
	<button
		class={classes}
		type={type}
		{disabled}
		{...restProps}
		style={inlineStyle}
		on:click={handleClick}
	>
		<slot />
	</button>
{/if}



================================================
FILE: packages/components/src/lib/Card.svelte
================================================
<script lang="ts">
export let className: string | undefined = undefined;

let restClass: string | undefined;
let restProps: Record<string, unknown> = {};

const baseClasses =
	'rounded-lg px-4 py-3 shadow-lg backdrop-blur border border-cream-100 dark:border-cream-700';

$: ({ class: restClass, ...restProps } = $$restProps);
$: classes = [baseClasses, restClass, className].filter(Boolean).join(' ');
</script>

<div class={classes} {...restProps}>
	<slot />
</div>



================================================
FILE: packages/components/src/lib/Collapsible.svelte
================================================
<script lang="ts">
export let title: string;
export let open = false;
export let className = '';

const baseClasses =
	'group rounded-lg border border-neutral-200 bg-white p-4 shadow-sm open:shadow-md dark:border-neutral-800 dark:bg-neutral-900';

$: detailsClass = `${baseClasses} ${className}`.trim();
</script>

<details class={detailsClass} {open}>
	<summary class="cursor-pointer font-semibold marker:text-neutral-400">{title}</summary>
	<div class="mt-3">
		<slot />
	</div>
</details>



================================================
FILE: packages/components/src/lib/index.ts
================================================
export {
	Badge,
	Checkbox,
	Fileupload,
	Label,
	Radio,
	Spinner,
	Table,
	TableBody,
	TableBodyCell,
	TableBodyRow,
	TableHead,
	TableHeadCell,
	Toggle,
} from 'flowbite-svelte';

export { default as Button } from './Button.svelte';
export { default as Card } from './Card.svelte';
export { default as Collapsible } from './Collapsible.svelte';
export { default as Input } from './Input.svelte';
export { default as Link } from './Link.svelte';
export { default as Select } from './Select.svelte';
export { default as Textarea } from './Textarea.svelte';



================================================
FILE: packages/components/src/lib/Input.svelte
================================================
<script lang="ts">
import type { InputHTMLAttributes } from 'svelte/elements';

type InputSize = 'sm' | 'md' | 'lg';

export let type: InputHTMLAttributes['type'] = 'text';
export let value: InputHTMLAttributes['value'] = undefined;
export let placeholder: InputHTMLAttributes['placeholder'] = undefined;
export let className: string | undefined = undefined;
export let size: InputSize = 'md';

let restClass: string | undefined;
let restProps: Record<string, unknown> = {};

const baseClasses =
	'rounded-lg border border-cream-200 bg-white text-gray-900 placeholder-gray-500 shadow-sm outline-none transition focus:ring-2 focus:ring-primary-300 focus:border-cream-300 dark:border-cream-700 dark:bg-cream-900 dark:text-white dark:placeholder-cream-200 dark:focus:border-cream-600 dark:focus:ring-primary-600';
const sizeClasses: Record<InputSize, string> = {
	sm: 'px-3 py-2 text-sm',
	md: 'px-3 py-2.5 text-sm',
	lg: 'px-4 py-3 text-base',
};

$: ({ class: restClass, ...restProps } = $$restProps);
$: classes = [baseClasses, sizeClasses[size] ?? sizeClasses.md, restClass, className]
	.filter(Boolean)
	.join(' ');
</script>

<input
	class={classes}
	type={type}
	placeholder={placeholder}
	bind:value
	{...restProps}
/>



================================================
FILE: packages/components/src/lib/Link.svelte
================================================
<script lang="ts">
import { createEventDispatcher } from 'svelte';
import type { AnchorHTMLAttributes } from 'svelte/elements';

export let href: AnchorHTMLAttributes['href'] = undefined;
export let target: AnchorHTMLAttributes['target'] = undefined;
export let rel: AnchorHTMLAttributes['rel'] = undefined;
// Alias for the `class` attribute since `class` is a reserved TS keyword
export let className: string | undefined = undefined;
export let underline = false;

let restClass: string | undefined;
let restProps: Record<string, unknown> = {};

const dispatch = createEventDispatcher();

function handleClick(event: MouseEvent) {
	dispatch('click', event);
}

$: baseClasses = 'hover:underline text-primary dark:text-white';
$: ({ class: restClass, ...restProps } = $$restProps);
$: classes =
	[baseClasses, restClass, className, underline ? 'underline' : undefined]
		.filter(Boolean)
		.join(' ') || undefined;
$: resolvedRel = target === '_blank' && !rel ? 'noreferrer noopener' : rel;
</script>

<a href={href} target={target} rel={resolvedRel} class={classes} {...restProps}
		on:click={handleClick}
>
	<slot />
</a>



================================================
FILE: packages/components/src/lib/Select.svelte
================================================
<script lang="ts">
import type { SelectHTMLAttributes } from 'svelte/elements';

type SelectSize = 'sm' | 'md' | 'lg';
type SelectItem = {
	value: SelectHTMLAttributes['value'];
	name?: string;
	label?: string;
	disabled?: boolean;
	selected?: boolean;
};

export let size: SelectSize = 'md';
export let items: SelectItem[] | undefined = undefined;
export let className: string | undefined = undefined;
export let value: SelectHTMLAttributes['value'] = undefined;

let restClass: string | undefined;
let restProps: Record<string, unknown> = {};

const baseClasses =
	'rounded-lg border border-cream-200 bg-white shadow-sm outline-none transition focus:ring-2 focus:ring-primary-300 focus:border-cream-300 dark:border-cream-700 dark:bg-cream-900 dark:text-white dark:focus:border-cream-600 dark:focus:ring-primary-600 text-left';
const sizeClasses: Record<SelectSize, string> = {
	sm: 'pl-3 pr-8 py-2 text-sm',
	md: 'pl-3 pr-8 py-2.5 text-sm',
	lg: 'pl-4 pr-8 py-3 text-base',
};

$: ({ class: restClass, ...restProps } = $$restProps);
$: classes = [baseClasses, sizeClasses[size] ?? sizeClasses.md, restClass, className]
	.filter(Boolean)
	.join(' ');
</script>

<select class={classes} bind:value {...restProps}>
	{#if items?.length}
		{#each items as item (item.value)}
			<option value={item.value} disabled={item.disabled} selected={item.selected}>
				{item.name ?? item.label ?? item.value}
			</option>
		{/each}
	{:else}
		<slot />
	{/if}
</select>



================================================
FILE: packages/components/src/lib/styles.css
================================================
@import "tailwindcss";

@plugin "flowbite/plugin";

@custom-variant dark (&:where(.dark, .dark *));

@source "./src/lib/**/*.{svelte,ts}";
@source "./node_modules/flowbite-svelte/**/*.{svelte,ts,js}";

@theme {
	--color-primary-50: #fef4e7; /* honey bronze */
	--color-primary-100: #fce9cf;
	--color-primary-200: #f9d49f;
	--color-primary-300: #f7be6e;
	--color-primary-400: #f4a83e;
	--color-primary: #f1920e;
	--color-primary-600: #c1750b;
	--color-primary-700: #915808;
	--color-primary-800: #603b06;
	--color-primary-900: #301d03;
	--color-primary-950: #221402;

	--color-accent-50: #fee7e9; /* hot fuchsia */
	--color-accent-100: #fccfd3;
	--color-accent-200: #f99fa6;
	--color-accent-300: #f76e7a;
	--color-accent-400: #f43e4d;
	--color-accent: #f10e21;
	--color-accent-600: #c10b1a;
	--color-accent-700: #910814;
	--color-accent-800: #60060d;
	--color-accent-900: #300307;
	--color-accent-950: #220205;

	--color-cream: #fef4e7; /* simple cream */
	--color-cream-100: #fce9cf;
	--color-cream-200: #f9d49f;
	--color-cream-300: #f7be6e;
	--color-cream-400: #f4a83e;
	--color-cream-500: #f1920e;
	--color-cream-600: #c1750b;
	--color-cream-700: #915808;
	--color-cream-800: #603b06;
	--color-cream-900: #301d03;
	--color-cream-950: #221402;

	--color-champagne-mist-50: #fef4e7;
	--color-champagne-mist-100: #fce9cf;
	--color-champagne-mist-200: #fad49e;
	--color-champagne-mist-300: #f7be6e;
	--color-champagne-mist-400: #f5a83d;
	--color-champagne-mist-500: #f2930d;
	--color-champagne-mist-600: #c2750a;
	--color-champagne-mist-700: #915808;
	--color-champagne-mist-800: #613b05;
	--color-champagne-mist-900: #301d03;
	--color-champagne-mist-950: #221502;

	--color-white: #fffdfa;
	--color-white-100: #fceacf;
	--color-white-200: #fad59e;
	--color-white-300: #f7c06e;
	--color-white-400: #f5ab3d;
	--color-white-500: #f2960d;
	--color-white-600: #c2780a;
	--color-white-700: #915a08;
	--color-white-800: #613c05;
	--color-white-900: #301e03;
	--color-white-950: #221502;
}

body {
	@apply bg-white dark:bg-white-900 dark:text-white;
}



================================================
FILE: packages/components/src/lib/Textarea.svelte
================================================
<script lang="ts">
import type { TextareaHTMLAttributes } from 'svelte/elements';

export let className: string | undefined = undefined;
export let value: TextareaHTMLAttributes['value'] = undefined;
export let rows: TextareaHTMLAttributes['rows'] = undefined;
export let cols: TextareaHTMLAttributes['cols'] = undefined;

let restClass: string | undefined;
let restProps: Record<string, unknown> = {};

const baseClasses =
	'rounded-lg border border-cream-200 bg-white text-gray-900 shadow-sm placeholder-gray-500 outline-none transition focus:ring-2 focus:ring-primary-300 focus:border-cream-300 dark:border-cream-700 dark:bg-cream-900 dark:text-white dark:placeholder-cream-200 dark:focus:border-cream-600 dark:focus:ring-primary-600';

// Align with Svelte's `class` handling while allowing `className` as an alias.
$: ({ class: restClass, ...restProps } = $$restProps);
$: classes = [baseClasses, restClass, className].filter(Boolean).join(' ');
</script>

<textarea class={classes} bind:value rows={rows} cols={cols} {...restProps}>
	<slot />
</textarea>



================================================
FILE: packages/components/src/routes/+layout.svelte
================================================
<script lang="ts">
import './layout.css';

let { children } = $props();
</script>

{@render children()}



================================================
FILE: packages/components/src/routes/+page.svelte
================================================
<script lang="ts">
import Link from '$lib/Link.svelte';
</script>

<h1>Welcome to your library project</h1>
<p>Create your package using @sveltejs/package and preview/showcase your work with SvelteKit</p>
<p>Visit <Link href="https://svelte.dev/docs/kit">svelte.dev/docs/kit</Link> to read the documentation</p>



================================================
FILE: packages/components/src/routes/layout.css
================================================
@import "tailwindcss";



================================================
FILE: packages/harper.js/README.md
================================================
# Harper

Harper is a grammar checker designed to be easy to consume and integrate into your products.
**It always runs on-device**, which means there aren't any privacy considerations or servers to run.

[Read the documentation to learn more.](https://writewithharper.com/docs/harperjs/introduction)

Wondering how good our algorithm is? [Give it a whirl.](https://writewithharper.com)



================================================
FILE: packages/harper.js/api-extractor.json
================================================
{
	"mainEntryPointFilePath": "./dist/harper.d.ts",
	"apiReport": {
		"enabled": false
	},
	"docModel": {
		"enabled": true
	},
	"dtsRollup": {
		"enabled": false
	},
	"bundledPackages": ["harper-wasm"],
	"messages": {
		"extractorMessageReporting": {
			"ae-missing-release-tag": {
				"logLevel": "none"
			},
			"ae-forgotten-export": {
				"logLevel": "none"
			}
		}
	}
}



================================================
FILE: packages/harper.js/docs.sh
================================================
#!/usr/bin/env bash

set -eo pipefail

pnpm api-extractor run
pnpm api-documenter markdown -i temp

html_dir="./html"
if [[ -d "$html_dir" ]]; then
	echo "Deleting old output from ${html_dir}"
	rm -r "$html_dir" || true
fi
mkdir "$html_dir" || true

harperjs_docs_dir="../web/static/docs/harperjs"
if [[ -d "$harperjs_docs_dir" ]]; then
	echo "Deleting old output from ${harperjs_docs_dir}"
	rm -r "$harperjs_docs_dir" || true
fi
mkdir -p "$harperjs_docs_dir" || true

echo "Rendering HTML..."
if command -v parallel &> /dev/null; then
	parallel '
        base=$(basename {} .md)
        node renderPage.js "${base#"harper.js."} - Harper" "API reference documentation for harper.js" {} "html/${base}.html"
    ' ::: ./markdown/*.md
else
	echo "parallel not found, falling back to sequential processing"
	for file in ./markdown/*.md; do
		base=$(basename "$file" .md)
    node renderPage.js "${base#"harper.js."} - Harper" "API reference documentation for harper.js" "$file" "html/${base}.html"
	done
fi
mv -f "$html_dir" "${harperjs_docs_dir}/ref"



================================================
FILE: packages/harper.js/package.json
================================================
{
	"name": "harper.js",
	"version": "1.5.1",
	"license": "Apache-2.0",
	"author": "Elijah Potter",
	"description": "The grammar checker that respects your privacy.",
	"repository": {
		"type": "git",
		"url": "git+https://github.com/automattic/harper.git",
		"directory": "packages/harper.js"
	},
	"bugs": {
		"url": "https://github.com/automattic/harper/issues"
	},
	"homepage": "https://writewithharper.com",
	"type": "module",
	"scripts": {
		"dev": "vite",
		"build": "tsc && vite build -l warn",
		"test": "vitest run",
		"test:debug": "vitest run --browser.headless false --testTimeout 0",
		"api:extractor": "api-extractor run",
		"api:documenter": "api-documenter markdown -i temp"
	},
	"devDependencies": {
		"@microsoft/api-documenter": "^7.28.1",
		"@microsoft/api-extractor": "^7.55.1",
		"@types/node": "catalog:",
		"@vitest/browser": "^4.0.16",
		"@vitest/browser-playwright": "^4.0.16",
		"@vitest/ui": "4.0.16",
		"harper-wasm": "workspace:*",
		"marked": "^16.4.1",
		"p-lazy": "^5.0.0",
		"p-memoize": "^7.1.1",
		"playwright": "^1.58.0",
		"type-fest": "^4.37.0",
		"typescript": "catalog:",
		"vite": "^6.1.0",
		"vite-plugin-dts": "^4.5.0",
		"vite-plugin-virtual": "^0.3.0",
		"vitest": "^4.0.16"
	},
	"main": "dist/harper.js",
	"types": "dist/harper.d.ts",
	"sideEffects": false,
	"files": [
		"dist"
	]
}



================================================
FILE: packages/harper.js/renderPage.js
================================================
import fs from 'fs';
import { marked } from 'marked';

const pageTitle = process.argv[2];
const description = process.argv[3];
const input = process.argv[4];
const output = process.argv[5];

const renderer = new marked.Renderer();

renderer.link = ({ href, title, text }) => {
	if (href.endsWith('.md')) {
		href = `${href.slice(0, href.length - 3)}.html`;
	}
	const titleAttr = title ? ` title="${title}"` : '';
	return `<a href="${href}" ${titleAttr}>${text.replaceAll('\\_', '_')}</a>`;
};

const markdown = fs.readFileSync(input, 'utf8');
const body = marked.parse(markdown, { async: false, renderer });

const html = `<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<title>${pageTitle}</title>
<meta name="description" content="${description}">
<link
  rel="stylesheet"
  href="https://cdn.jsdelivr.net/npm/@picocss/pico@2/css/pico.min.css"
>
</head>
<body class="container">
${body}
</body>
</html>
`;

fs.writeFileSync(output, html);



================================================
FILE: packages/harper.js/tsconfig.json
================================================
{
	"compilerOptions": {
		"target": "ES2020",
		"useDefineForClassFields": true,
		"module": "ESNext",
		"lib": ["ES2020", "DOM", "DOM.Iterable"],
		"skipLibCheck": true,
		/* Bundler mode */
		"moduleResolution": "bundler",
		"allowImportingTsExtensions": true,
		"isolatedModules": true,
		"moduleDetection": "force",
		"noEmit": true,
		/* Linting */
		"strict": true,
		"noUnusedLocals": true,
		"noUnusedParameters": true,
		"noFallthroughCasesInSwitch": true,
		"types": ["vite/client", "node"],
		"paths": {
			"harper-wasm": ["../../harper-wasm/pkg"]
		}
	},
	"include": ["src"]
}



================================================
FILE: packages/harper.js/vite.config.ts
================================================
/// <reference types="vitest" />
import { playwright } from '@vitest/browser-playwright';
import { resolve } from 'path';
import { defineConfig, type Plugin } from 'vite';
import dts from 'vite-plugin-dts';
import apiExtractorConfig from './api-extractor.json';

function removeAssetsPlugin(options: { test: RegExp }): Plugin {
	return {
		name: 'remove-wasm',
		generateBundle(_, bundle) {
			for (const file in bundle) {
				if (options.test.test(file)) {
					delete bundle[file];
				}
			}
		},
	};
}

export default defineConfig({
	build: {
		lib: {
			entry: resolve(__dirname, 'src/main.ts'),
			fileName: 'harper',
			name: 'harper',
			formats: ['es'],
		},
		minify: false,
		assetsInlineLimit: 0,
		rollupOptions: {
			external: [/^node:/, 'fs'],
			output: {
				minifyInternalExports: false,
				inlineDynamicImports: true,
			},
			treeshake: {
				moduleSideEffects: false,
				propertyReadSideEffects: false,
			},
		},
	},
	base: './',
	plugins: [
		dts({
			...apiExtractorConfig,
			rollupTypes: true,
			tsconfigPath: './tsconfig.json',
		}),
	],
	worker: {
		format: 'es',
		plugins: () => [removeAssetsPlugin({ test: /\.wasm$/ })],
		rollupOptions: {
			output: {
				inlineDynamicImports: true,
			},
		},
	},
	server: {
		fs: {
			allow: ['../../harper-wasm/pkg'],
		},
	},
	test: {
		retry: process.env.CI ? 5 : 0,
		browser: {
			provider: playwright(),
			enabled: true,
			headless: true,
			screenshotFailures: false,
			instances: [{ browser: 'chromium' }, { browser: 'firefox' }],
		},
	},
	assetsInclude: ['**/*.wasm'],
});



================================================
FILE: packages/harper.js/examples/commonjs-simple/README.md
================================================
# `commonjs-simple`

An example of using `harper.js` in a Node.js application.
Read the source code in `index.cjs` to see what's going on.

You can run it using pnpm:

```
pnpm install
pnpm start
```



================================================
FILE: packages/harper.js/examples/commonjs-simple/index.js
================================================
async function main() {
	const harper = await import('harper.js');
	// We cannot use `WorkerLinter` on Node.js since it relies on web-specific APIs.
	// This constructs the linter to consume American English.
	const linter = new harper.LocalLinter({
		binary: harper.binary,
		dialect: harper.Dialect.American,
	});

	const lints = await linter.lint('This is a example of how to use `harper.js`.');

	console.log('Here are the results of linting the above text:');

	for (const lint of lints) {
		console.log(' - ', lint.span().start, ':', lint.span().end, lint.message());

		if (lint.suggestion_count() !== 0) {
			console.log('Suggestions:');

			for (const sug of lint.suggestions()) {
				console.log(
					'\t - ',
					sug.kind() === 1 ? 'Remove' : 'Replace with',
					sug.get_replacement_text(),
				);
			}
		}
	}
}

main();



================================================
FILE: packages/harper.js/examples/commonjs-simple/package.json
================================================
{
	"name": "commonjs-simple",
	"version": "0.0.1",
	"private": true,
	"scripts": {
		"start": "node index.js"
	},
	"dependencies": {
		"harper.js": "workspace:*"
	}
}



================================================
FILE: packages/harper.js/examples/raw-web/README.md
================================================
# `raw-web`

An example of using `harper.js` in a raw HTML webpage.
You can open it using [`microserver`](https://crates.io/crates/microserver):



================================================
FILE: packages/harper.js/examples/raw-web/index.html
================================================
<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8" />
  <script type="module">
    // We can import `harper.js` using native ECMAScript syntax.
    // TODO: Update to the latest version.
    import {binaryInlined, WorkerLinter } from 'https://unpkg.com/harper.js@0.54.0/dist/harper.js';

    // Since we are working in the browser, we can use either `WorkerLinter`, which doesn't block the event loop, or `LocalLinter`, which does.
    const linter = new WorkerLinter({binary: binaryInlined});

    // Every time the `<textarea/>` received an input, we process it and update our list.
    async function onInput(e) {
      const lints = await linter.lint(e.target.value);

      const list = document.getElementById('errorlist');
      // Clear previous results
      list.innerHTML = '';

      for (const lint of lints) {
        const item = document.createElement('LI');
        const text = document.createTextNode(lint.message());
        item.appendChild(text);
        list.appendChild(item);
      }
    }

    const inputField = document.getElementById('maininput');
    inputField.addEventListener('input', onInput);
    onInput({target: inputField});
  </script>

  <!--Make the page look good using SimpleCSS-->
  <link rel="stylesheet" href="https://cdn.simplecss.org/simple.min.css" />
</head>

<body>
  <h1>Demo</h1>

  <p>
    This page is a simple example of using <code>harper.js</code> on a plain HTML page with a CDN.
    It isn't pretty, but it demonstrates the fundamentals of using Harper. Start typing in the
    text box below to start getting suggestions right in your browser.
  </p>

  <!--This is an intentional mistake to highlight the technology.-->
  <textarea id="maininput">This is an test</textarea>

  <h2>Errors</h2>

  <ul id="errorlist">
    Loading...
  </ul>
</body>

</html>



================================================
FILE: packages/harper.js/src/binary.ts
================================================
import { Dialect, type InitInput, type Linter as WasmLinter } from 'harper-wasm';
import { default as binaryInlinedUrl } from 'harper-wasm/harper_wasm_bg.wasm?inline';
import { default as binaryUrl } from 'harper-wasm/harper_wasm_bg.wasm?no-inline';
import LazyPromise from 'p-lazy';
import pMemoize from 'p-memoize';
import type { LintConfig } from './main';

const loadBinary = pMemoize(async (binary: string) => {
	const exports = await import('harper-wasm');

	let input: InitInput;
	if (typeof process !== 'undefined' && binary.startsWith('file://')) {
		const fs = await import(/* webpackIgnore: true */ /* @vite-ignore */ 'fs');
		input = new Promise((resolve, reject) => {
			fs.readFile(new URL(binary).pathname, (err, data) => {
				if (err) reject(err);
				resolve(data);
			});
		});
	} else {
		input = binary;
	}
	await exports.default({ module_or_path: input });

	return exports;
});

/** A wrapper around the underlying WebAssembly module that contains Harper's core code. Used to construct a `Linter`, as well as access some miscellaneous other functions. */
export class BinaryModule {
	public url: string | URL = '';
	private inner: Promise<typeof import('harper-wasm')> | null = null;

	/** Load a binary from a specified URL. This is the only recommended way to construct this type. */
	public static create(url: string | URL): BinaryModule {
		const module = new SuperBinaryModule();

		module.url = url;
		module.inner = LazyPromise.from(() =>
			loadBinary(typeof module.url === 'string' ? module.url : module.url.href),
		);

		return module;
	}

	public async getDefaultLintConfigAsJSON(): Promise<string> {
		const exported = await this.inner!;
		return exported.get_default_lint_config_as_json();
	}

	public async getDefaultLintConfig(): Promise<LintConfig> {
		const exported = await this.inner!;
		return exported.get_default_lint_config();
	}

	public async toTitleCase(text: string): Promise<string> {
		const exported = await this.inner!;
		return exported.to_title_case(text);
	}

	public async setup(): Promise<void> {
		const exported = await this.inner!;
		exported.setup();
	}
}

export class SuperBinaryModule extends BinaryModule {
	async createLinter(dialect?: Dialect): Promise<WasmLinter> {
		const exported = await this.getBinaryModule();
		return exported.Linter.new(dialect ?? Dialect.American);
	}

	async getBinaryModule(): Promise<any> {
		return await LazyPromise.from(() =>
			loadBinary(typeof this.url === 'string' ? this.url : this.url.href),
		);
	}
}

/** A version of the Harper WebAssembly binary stored inline as a data URL.
 * Can be tree-shaken if unused. */
export const binary = /*@__PURE__*/ BinaryModule.create(binaryUrl);

/** A version of the Harper WebAssembly binary stored inline as a data URL.
 * Can be tree-shaken if unused. */
export const binaryInlined = /*@__PURE__*/ BinaryModule.create(binaryInlinedUrl);



================================================
FILE: packages/harper.js/src/Linter.bench.ts
================================================
import { bench } from 'vitest';
import { binary } from './binary';
import LocalLinter from './LocalLinter';
import WorkerLinter from './WorkerLinter';

const linters = {
	WorkerLinter: WorkerLinter,
	LocalLinter: LocalLinter,
};

for (const [linterName, Linter] of Object.entries(linters)) {
	const linter = new Linter({ binary });

	// Prime caches
	linter.setup();

	const defaultConfig = await linter.getDefaultLintConfig();
	const emptyIgnoreState = await linter.exportIgnoredLints();

	bench(`${linterName} set lint configuration`, async () => {
		await linter.setLintConfig(defaultConfig);
	});

	bench(`${linterName} get lint configuration`, async () => {
		await linter.getLintConfig();
	});

	bench(`${linterName} reset ignore state`, async () => {
		await linter.clearIgnoredLints();
		await linter.importIgnoredLints(emptyIgnoreState);
	});
}



================================================
FILE: packages/harper.js/src/Linter.test.ts
================================================
import { expect, test } from 'vitest';
import { binary } from './binary';
import LocalLinter from './LocalLinter';
import WorkerLinter from './WorkerLinter';

function randomString(length: number): string {
	const chars = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz';
	let result = '';
	for (let i = 0; i < length; i++) {
		result += chars.charAt(Math.floor(Math.random() * chars.length));
	}
	return result;
}

const linters = {
	WorkerLinter: WorkerLinter,
	LocalLinter: LocalLinter,
};

for (const [linterName, Linter] of Object.entries(linters)) {
	test(`${linterName} detects repeated words`, async () => {
		const linter = new Linter({ binary });

		const lints = await linter.lint('The the problem is...');

		expect(lints.length).toBe(1);

		await linter.dispose();
	});

	test(`${linterName} emits organized lints the same as it emits normal lints`, async () => {
		const linter = new Linter({ binary });
		const source = 'The the problem is...';

		const lints = await linter.lint(source);
		expect(lints.length).toBeGreaterThan(0);

		const organized = await linter.organizedLints(source);
		const normal = await linter.lint(source);

		const flattened = [];
		for (const [_, value] of Object.entries(organized)) {
			flattened.push(...value);
		}

		expect(flattened.length).toBe(1);
		expect(flattened.length).toBe(normal.length);

		const item = flattened[0];
		expect(item.message().length).not.toBe(0);

		await linter.dispose();
	});

	test(`${linterName} detects repeated words with multiple synchronous requests`, async () => {
		const linter = new Linter({ binary });

		const promises = [
			linter.lint('The problem is that that...'),
			linter.lint('The problem is...'),
			linter.lint('The the problem is...'),
		];

		const results = await Promise.all(promises);

		expect(results[0].length).toBe(1);
		expect(results[0][0].suggestions().length).toBe(1);
		expect(results[1].length).toBe(0);
		expect(results[2].length).toBe(1);

		await linter.dispose();
	});

	test(`${linterName} detects repeated words with concurrent requests`, async () => {
		const linter = new Linter({ binary });

		const promises = [
			linter.lint('The problem is that that...'),
			linter.lint('The problem is...'),
			linter.lint('The the problem is...'),
		];

		const results = await Promise.all(promises);

		expect(results[0].length).toBe(1);
		expect(results[0][0].suggestions().length).toBe(1);
		expect(results[1].length).toBe(0);
		expect(results[2].length).toBe(1);

		await linter.dispose();
	});

	test(`${linterName} detects lorem ipsum paragraph as not english`, async () => {
		const linter = new Linter({ binary });

		const result = await linter.isLikelyEnglish(
			'Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.',
		);

		expect(result).toBeTypeOf('boolean');
		expect(result).toBe(false);

		await linter.dispose();
	});

	test(`${linterName} can run setup without issues`, async () => {
		const linter = new Linter({ binary });

		await linter.setup();
	});

	test(`${linterName} contains configuration option for repetition`, async () => {
		const linter = new Linter({ binary });

		const lintConfig = await linter.getLintConfig();
		expect(lintConfig).toHaveProperty('RepeatedWords');

		await linter.dispose();
	});

	test(`${linterName} can set its configuration away and to default`, async () => {
		const linter = new Linter({ binary });

		let lintConfig = await linter.getLintConfig();

		for (const key of Object.keys(lintConfig)) {
			lintConfig[key] = true;
		}

		await linter.setLintConfig(lintConfig);
		lintConfig = await linter.getLintConfig();

		for (const key of Object.keys(lintConfig)) {
			lintConfig[key] = null;
		}

		await linter.setLintConfig(lintConfig);
		lintConfig = await linter.getLintConfig();

		for (const key of Object.keys(lintConfig)) {
			expect(lintConfig[key]).toBe(null);
		}

		await linter.dispose();
	});

	test(`${linterName} can both get and set its configuration`, async () => {
		const linter = new Linter({ binary });

		let lintConfig = await linter.getLintConfig();

		for (const key of Object.keys(lintConfig)) {
			lintConfig[key] = true;
		}

		await linter.setLintConfig(lintConfig);
		lintConfig = await linter.getLintConfig();

		for (const key of Object.keys(lintConfig)) {
			expect(lintConfig[key]).toBe(true);
		}

		await linter.dispose();
	});

	test(`${linterName} can make things title case`, async () => {
		const linter = new Linter({ binary });

		const titleCase = await linter.toTitleCase('this is a test for making titles');

		expect(titleCase).toBe('This Is a Test for Making Titles');

		await linter.dispose();
	});

	test(`${linterName} can get rule descriptions`, async () => {
		const linter = new Linter({ binary });

		const descriptions = await linter.getLintDescriptions();

		expect(descriptions).toBeTypeOf('object');

		await linter.dispose();
	});

	test(`${linterName} can get rule descriptions in HTML.`, async () => {
		const linter = new Linter({ binary });

		const descriptions = await linter.getLintDescriptionsHTML();

		expect(descriptions).toBeTypeOf('object');

		await linter.dispose();
	});

	test(`${linterName} rule descriptions are not empty`, async () => {
		const linter = new Linter({ binary });

		const descriptions = await linter.getLintDescriptions();

		for (const value of Object.values(descriptions)) {
			expect(value).toBeTypeOf('string');
			expect(value).not.toHaveLength(0);
		}

		await linter.dispose();
	});

	test(`${linterName} default lint config has no null values`, async () => {
		const linter = new Linter({ binary });

		const lintConfig = await linter.getDefaultLintConfig();

		for (const value of Object.values(lintConfig)) {
			expect(value).not.toBeNull();
		}

		await linter.dispose();
	});

	test(`${linterName} can generate lint context hashes`, async () => {
		const linter = new Linter({ binary });
		const source = 'This is an test.';

		const lints = await linter.lint(source);

		expect(lints.length).toBeGreaterThanOrEqual(1);

		await linter.contextHash(source, lints[0]);

		await linter.dispose();
	});

	test(`${linterName} can ignore lints`, async () => {
		const linter = new Linter({ binary });
		const source = 'This is an test.';

		const firstRound = await linter.lint(source);

		expect(firstRound.length).toBeGreaterThanOrEqual(1);

		await linter.ignoreLint(source, firstRound[0]);

		const secondRound = await linter.lint(source);

		expect(secondRound.length).toBeLessThan(firstRound.length);
		await linter.dispose();
	});

	test(`${linterName} can ignore lints with hashes`, async () => {
		const linter = new Linter({ binary });
		const source = 'This is an test.';

		const firstRound = await linter.lint(source);

		expect(firstRound.length).toBeGreaterThanOrEqual(1);

		const hash = await linter.contextHash(source, firstRound[0]);
		await linter.ignoreLintHash(hash);

		const secondRound = await linter.lint(source);

		expect(secondRound.length).toBeLessThan(firstRound.length);
		await linter.dispose();
	});

	test(`${linterName} can ignore larger lints to reveal smaller ones`, async () => {
		const linter = new Linter({ binary });
		const source = `This is a really long sentensd with some errorz in it, which in an old version of Harper, would get removedd when the bigger "Long Sentences" lint was ignored, that isn't what we woant, so we are writing a test for that exact problem.`;

		const firstRound = await linter.lint(source);

		expect(firstRound.length).toBeGreaterThanOrEqual(1);

		await linter.ignoreLint(source, firstRound[0]);

		const secondRound = await linter.lint(source);

		expect(secondRound.length).toBe(4);

		await linter.dispose();
	});

	test(`${linterName} can reimport ignored lints.`, async () => {
		const source = 'This is an test of xporting lints.';

		const firstLinter = new Linter({ binary });

		const firstLints = await firstLinter.lint(source);

		for (const lint of firstLints) {
			await firstLinter.ignoreLint(source, lint);
		}

		const exported = await firstLinter.exportIgnoredLints();

		/// Create a new instance and reimport the lints.
		const secondLinter = new Linter({ binary });
		await secondLinter.importIgnoredLints(exported);

		const secondLints = await secondLinter.lint(source);

		expect(firstLints.length).toBeGreaterThan(secondLints.length);
		expect(secondLints.length).toBe(0);

		await firstLinter.dispose();
		await secondLinter.dispose();
	});

	test(`${linterName} can add words to the dictionary`, async () => {
		const source = 'asdf is not a word';

		const linter = new Linter({ binary });
		let lints = await linter.lint(source);

		expect(lints).toHaveLength(1);

		await linter.importWords(['asdf']);
		lints = await linter.lint(source);

		expect(lints).toHaveLength(0);

		await linter.dispose();
	});

	test(`${linterName} allows correct capitalization of "United States"`, async () => {
		const linter = new Linter({ binary });
		const lints = await linter.lint('The United States is a big country.');

		expect(lints).toHaveLength(0);

		await linter.dispose();
	});

	test(`${linterName} can summarize simple stat records`, async () => {
		const linter = new Linter({ binary });
		linter.setup();

		const source = 'This is an test.';

		const lints = await linter.lint(source);

		const lint = lints[0];

		expect(lint).not.toBeNull();

		const sug = lint.suggestions()[0];

		expect(sug).not.toBeNull();

		const applied = await linter.applySuggestion(source, lint, sug);

		expect(applied).toBe('This is a test.');

		const summary = await linter.summarizeStats();
		expect(summary).toBeTypeOf('object');

		await linter.dispose();
	});

	test(`${linterName} can save and restore stat records`, async () => {
		const linter = new Linter({ binary });
		linter.setup();

		const source = 'This is an test.';

		const lints = await linter.lint(source);

		const lint = lints[0];

		expect(lint).not.toBeNull();

		const sug = lint.suggestions()[0];

		expect(sug).not.toBeNull();

		const applied = await linter.applySuggestion(source, lint, sug);

		expect(applied).toBe('This is a test.');

		const stats = await linter.generateStatsFile();

		const newLinter = new Linter({ binary });
		await newLinter.importStatsFile(stats);

		await linter.dispose();
	});

	test(`${linterName} emits the correct span indices`, async () => {
		const text = '✉️👋👍✉️🚀✉️🌴 This is to show the offset issue sdssda is it there?';

		const linter = new LocalLinter({ binary });
		const lints = await linter.lint(text);

		const span = lints[0].span();

		expect(span.start).toBe(48);
		expect(span.end).toBe(54);

		expect(text.slice(span.start, span.end)).toBe('sdssda');

		await linter.dispose();
	});

	test(`${linterName} lints headings when forced to mark them as such`, async () => {
		const text = 'This sentences should be forced to title case.';

		const linter = new LocalLinter({ binary });
		const lints = await linter.lint(text, { forceAllHeadings: true });

		expect(lints.length).toBe(1);

		const lint = lints[0];
		expect(lint.lint_kind()).toBe('Capitalization');
		expect(lint.get_problem_text()).toBe(text);

		await linter.dispose();
	});

	test(`${linterName} lints headings when forced to mark them as such with organized mode`, async () => {
		const text = 'This sentences should be forced to title case.';

		const linter = new LocalLinter({ binary });
		const lints = await linter.organizedLints(text, { forceAllHeadings: true });

		const titleCaseLints = lints.UseTitleCase;
		expect(titleCaseLints).not.toBeUndefined();
		expect(titleCaseLints.length).toBe(1);

		const lint = titleCaseLints[0];
		expect(lint.lint_kind()).toBe('Capitalization');
		expect(lint.get_problem_text()).toBe(text);

		await linter.dispose();
	});

	test(`${linterName} will lint many random strings with a single instance`, async () => {
		const linter = new Linter({ binary });

		for (let i = 0; i < 250; i++) {
			const text = randomString(10);
			const lints = await linter.organizedLints(text);

			expect(lints).not.toBeNull();
		}

		await linter.dispose();
	}, 120000);
}

// Disabled because it significantly slows down CI
// test('LocalLinters will lint many times with fresh instances', async () => {
// 	for (let i = 0; i < 300; i++) {
// 		const linter = new LocalLinter({ binary });
//
// 		const text = 'This is a grammatically correct sentence.';
// 		const lints = await linter.organizedLints(text);
// 		expect(lints).not.toBeNull();
//
// 		await linter.dispose();
// 	}
// }, 120000);

test('Linters have the same config format', async () => {
	const configs = [];

	for (const Linter of Object.values(linters)) {
		const linter = new Linter({ binary });

		configs.push(await linter.getLintConfig());

		await linter.dispose();
	}

	for (const config of configs) {
		expect(config).toEqual(configs[0]);
		expect(config).toBeTypeOf('object');
	}
});

test('Linters have the same JSON config format', async () => {
	const configs = [];

	for (const Linter of Object.values(linters)) {
		const linter = new Linter({ binary });

		configs.push(await linter.getLintConfigAsJSON());
		await linter.dispose();
	}

	for (const config of configs) {
		expect(config).toEqual(configs[0]);
		expect(config).toBeTypeOf('string');
	}
});



================================================
FILE: packages/harper.js/src/Linter.ts
================================================
import type { Dialect, Lint, Suggestion } from 'harper-wasm';
import type { BinaryModule } from './binary';
import type { LintConfig, LintOptions } from './main';
import type Summary from './Summary';

/** An interface for an object that can perform linting actions. */
export default interface Linter {
	/** Complete any setup that is necessary before linting. This may include downloading and compiling the WebAssembly binary.
	 * This setup will complete when needed regardless of whether you call this function.
	 * This function exists to allow you to do this work when it is of least impact to the user experiences (i.e. while you're loading something else). */
	setup(): Promise<void>;

	/** Lint the provided text. */
	lint(text: string, options?: LintOptions): Promise<Lint[]>;

	/** Lint the provided text, maintaining the relationship with the source rule. */
	organizedLints(text: string, options?: LintOptions): Promise<Record<string, Lint[]>>;

	/** Apply a suggestion from a lint to text, returning the changed text. */
	applySuggestion(text: string, lint: Lint, suggestion: Suggestion): Promise<string>;

	/** Determine if the provided text is likely to be intended to be English.
	 * The algorithm can be described as "proof of concept" and as such does not work terribly well.*/
	isLikelyEnglish(text: string): Promise<boolean>;

	/** Determine which parts of a given string are intended to be English, returning those bits.
	 * The algorithm can be described as "proof of concept" and as such does not work terribly well.*/
	isolateEnglish(text: string): Promise<string>;

	/** Get the linter's current configuration. */
	getLintConfig(): Promise<LintConfig>;

	/** Get the default (unset) linter configuration as JSON.
	 * This method does not affect the caller's lint configuration, nor does it return the current one. */
	getDefaultLintConfigAsJSON(): Promise<string>;

	/** Get the default (unset) linter configuration.
	 * This method does not affect the caller's lint configuration, nor does it return the current one. */
	getDefaultLintConfig(): Promise<LintConfig>;

	/** Set the linter's current configuration. */
	setLintConfig(config: LintConfig): Promise<void>;

	/** Get the linter's current configuration as JSON. */
	getLintConfigAsJSON(): Promise<string>;

	/** Set the linter's current configuration from JSON. */
	setLintConfigWithJSON(config: string): Promise<void>;

	/** Get the linting rule descriptions as a JSON map, formatted in Markdown. */
	getLintDescriptionsAsJSON(): Promise<string>;

	/** Get the linting rule descriptions as an object, formatted in Markdown. */
	getLintDescriptions(): Promise<Record<string, string>>;

	/** Get the linting rule descriptions as a JSON map, formatted in HTML.
	 * Wraps the function on the BinaryModule by the same name. */
	getLintDescriptionsHTMLAsJSON(): Promise<string>;

	/** Get the linting rule descriptions as an object, formatted in HTML.
	 * Wraps the function on the BinaryModule by the same name. */
	getLintDescriptionsHTML(): Promise<Record<string, string>>;

	/** Convert a string to Chicago-style title case. 
	 Wraps the function on the BinaryModule by the same name. */
	toTitleCase(text: string): Promise<string>;

	/** Release resources held by this linter instance. */
	dispose(): Promise<void>;

	/** Ignore future instances of a lint from a previous linting run in future invocations. */
	ignoreLint(source: string, lint: Lint): Promise<void>;

	/** Ignore future instances of a lint from a previous linting run in future invocations using its hash. */
	ignoreLintHash(hash: bigint): Promise<void>;

	/** Export the ignored lints to a JSON list of privacy-respecting hashes. */
	exportIgnoredLints(): Promise<string>;

	/** Import ignored lints from a JSON list to the linter.
	 * This function appends to the existing lints, if any. */
	importIgnoredLints(json: string): Promise<void>;

	/** Produce a context-sensitive hash that represents a lint.  */
	contextHash(source: string, lint: Lint): Promise<bigint>;

	/** Clear records of all previously ignored lints. */
	clearIgnoredLints(): Promise<void>;

	/** Clear the words which have been added to the dictionary. This will not clear words from the curated dictionary. */
	clearWords(): Promise<void>;

	/** Import words into the dictionary. This is a significant operation, so try to batch words. */
	importWords(words: string[]): Promise<void>;

	/** Export all added words from the dictionary. Note that this will NOT export anything from the curated dictionary,
	 * only words from previous calls to `this.importWords`. */
	exportWords(): Promise<string[]>;

	/** Get the dialect of English this linter was constructed for. */
	getDialect(): Promise<Dialect>;

	/** Get the dialect of English this linter was constructed for. */
	setDialect(dialect: Dialect): Promise<void>;

	/** Summarize the linter's usage statistics.
	 * You may optionally pass in a start and/or end time.
	 *
	 * If so, the summary with only include data from _after_ the start time but _before_ the end time. */
	summarizeStats(start?: bigint, end?: bigint): Promise<Summary>;

	/** Generate a statistics log file you can save to permanent storage. */
	generateStatsFile(): Promise<string>;

	/** Import a statistics log file. */
	importStatsFile(statsFile: string): Promise<void>;
}

/** The properties and information needed to construct a Linter. */
export interface LinterInit {
	/** The module or path to the WebAssembly binary. */
	binary: BinaryModule;
	/** The dialect of English Harper should use. If omitted, Harper will default to American English. */
	dialect?: Dialect;
}



================================================
FILE: packages/harper.js/src/LocalLinter.ts
================================================
import type { Dialect, Lint, Suggestion, Linter as WasmLinter } from 'harper-wasm';
import { Language } from 'harper-wasm';
import LazyPromise from 'p-lazy';
import type { SuperBinaryModule } from './binary';
import type Linter from './Linter';
import type { LinterInit } from './Linter';
import type { LintConfig, LintOptions } from './main';

/** A Linter that runs in the current JavaScript context (meaning it is allowed to block the event loop).
 * See the interface definition for more details. */
export default class LocalLinter implements Linter {
	binary: SuperBinaryModule;
	private inner: Promise<WasmLinter>;
	private disposed = false;

	constructor(init: LinterInit) {
		this.binary = init.binary as SuperBinaryModule;
		this.binary.setup();
		this.inner = this.createInner(init.dialect);
	}

	private createInner(dialect?: Dialect): Promise<WasmLinter> {
		return LazyPromise.from(async () => {
			await this.binary.setup();
			return this.binary.createLinter(dialect);
		});
	}

	async setup(): Promise<void> {
		await this.lint('', { language: 'plaintext' });

		const exported = await this.exportIgnoredLints();
		await this.importIgnoredLints(exported);
	}

	async lint(text: string, options?: LintOptions): Promise<Lint[]> {
		const inner = await this.inner;

		let language = Language.Markdown;

		switch (options?.language) {
			case 'plaintext':
				language = Language.Plain;
				break;
			case 'markdown':
				language = Language.Markdown;
				break;
			case 'typst':
				language = Language.Typst;
		}

		const lints = inner.lint(text, language, options?.forceAllHeadings ?? false);

		return lints;
	}

	async organizedLints(text: string, options?: LintOptions): Promise<Record<string, Lint[]>> {
		const inner = await this.inner;
		const language = options?.language === 'plaintext' ? Language.Plain : Language.Markdown;
		const lintGroups = inner.organized_lints(text, language, options?.forceAllHeadings ?? false);

		const output: Record<string, Lint[]> = {};

		for (const group of lintGroups) {
			output[group.group] = group.lints;
			group.free();
		}

		return output;
	}

	async applySuggestion(text: string, lint: Lint, suggestion: Suggestion): Promise<string> {
		const inner = await this.inner;
		return inner.apply_suggestion(text, lint, suggestion);
	}

	async isLikelyEnglish(text: string): Promise<boolean> {
		const inner = await this.inner;
		return inner.is_likely_english(text);
	}

	async isolateEnglish(text: string): Promise<string> {
		const inner = await this.inner;
		return inner.isolate_english(text);
	}

	async getLintConfig(): Promise<LintConfig> {
		const inner = await this.inner;
		return inner.get_lint_config_as_object();
	}

	async getDefaultLintConfigAsJSON(): Promise<string> {
		return await this.binary.getDefaultLintConfigAsJSON();
	}

	async getDefaultLintConfig(): Promise<LintConfig> {
		return await this.binary.getDefaultLintConfig();
	}

	async setLintConfig(config: LintConfig): Promise<void> {
		const inner = await this.inner;
		inner.set_lint_config_from_object(config);
	}

	async getLintConfigAsJSON(): Promise<string> {
		const inner = await this.inner;
		return inner.get_lint_config_as_json();
	}

	async setLintConfigWithJSON(config: string): Promise<void> {
		const inner = await this.inner;
		inner.set_lint_config_from_json(config);
	}

	async toTitleCase(text: string): Promise<string> {
		return await this.binary.toTitleCase(text);
	}

	async getLintDescriptions(): Promise<Record<string, string>> {
		const inner = await this.inner;
		return inner.get_lint_descriptions_as_object();
	}

	async getLintDescriptionsAsJSON(): Promise<string> {
		const inner = await this.inner;
		return inner.get_lint_descriptions_as_json();
	}

	async getLintDescriptionsHTML(): Promise<Record<string, string>> {
		const inner = await this.inner;
		return inner.get_lint_descriptions_html_as_object();
	}

	async getLintDescriptionsHTMLAsJSON(): Promise<string> {
		const inner = await this.inner;
		return inner.get_lint_descriptions_html_as_json();
	}

	async ignoreLint(source: string, lint: Lint): Promise<void> {
		const inner = await this.inner;
		inner.ignore_lint(source, lint);
	}

	async ignoreLintHash(hash: bigint): Promise<void> {
		const inner = await this.inner;
		inner.ignore_hash(hash);
	}

	async exportIgnoredLints(): Promise<string> {
		const inner = await this.inner;
		return inner.export_ignored_lints();
	}

	async importIgnoredLints(json: string): Promise<void> {
		const inner = await this.inner;
		inner.import_ignored_lints(json);
	}

	async contextHash(source: string, lint: Lint): Promise<bigint> {
		const inner = await this.inner;
		return inner.context_hash(source, lint);
	}

	async clearIgnoredLints(): Promise<void> {
		const inner = await this.inner;
		inner.clear_ignored_lints();
	}

	async clearWords(): Promise<void> {
		const inner = await this.inner;

		return inner.clear_words();
	}

	async importWords(words: string[]): Promise<void> {
		const inner = await this.inner;

		return inner.import_words(words);
	}

	async exportWords(): Promise<string[]> {
		const inner = await this.inner;

		return inner.export_words();
	}

	async getDialect(): Promise<Dialect> {
		const inner = await this.inner;

		return inner.get_dialect();
	}

	async setDialect(dialect: Dialect): Promise<void> {
		const inner = await this.inner;

		if (inner.get_dialect() !== dialect) {
			inner.free();
			this.inner = this.createInner(dialect);
		}

		return Promise.resolve();
	}

	async summarizeStats(start?: bigint, end?: bigint): Promise<any> {
		const inner = await this.inner;
		return inner.summarize_stats(start, end);
	}

	async generateStatsFile(): Promise<string> {
		const inner = await this.inner;
		return inner.generate_stats_file();
	}

	async importStatsFile(statsFile: string): Promise<void> {
		const inner = await this.inner;
		return inner.import_stats_file(statsFile);
	}

	async dispose(): Promise<void> {
		if (this.disposed) {
			return;
		}

		this.disposed = true;
		const inner = await this.inner;
		inner.free();
	}
}



================================================
FILE: packages/harper.js/src/main.ts
================================================
export type { Lint, Span, Suggestion } from 'harper-wasm';
export { Dialect, SuggestionKind } from 'harper-wasm';
export {
	BinaryModule,
	binary,
	binaryInlined,
} from './binary';
export type { default as Linter, LinterInit } from './Linter';
export { default as LocalLinter } from './LocalLinter';
export type { default as Summary } from './Summary';
export { default as WorkerLinter } from './WorkerLinter';
/** A linting rule configuration dependent on upstream Harper's available rules.
 * This is a record, since you shouldn't hard-code the existence of any particular rules and should generalize based on this struct. */
export type LintConfig = Record<string, boolean | null>;

/**  Options available to configure Harper's parser for an individual linting operation. */
export interface LintOptions {
	/** The markup language that is being passed. Defaults to `markdown`. */
	language?: 'plaintext' | 'markdown' | 'typst';

	/** Force the entirety of the document to be composed of headings. An undefined value is assumed to be false.*/
	forceAllHeadings?: boolean;
}



================================================
FILE: packages/harper.js/src/Serializer.test.ts
================================================
import { Span } from 'harper-wasm';
import { beforeEach, describe, expect, test } from 'vitest';
import { binary } from './binary';
import LocalLinter from './LocalLinter';
import Serializer from './Serializer';

describe('Serializer', () => {
	let serializer = new Serializer(binary);

	beforeEach(() => {
		serializer = new Serializer(binary);
	});

	test('works with strings', async () => {
		const start = 'This is a string';

		const end = await serializer.deserializeArg(
			structuredClone(await serializer.serializeArg(start)),
		);

		expect(end).toBe(start);
		expect(typeof end).toBe(typeof start);
	});

	test('works with false booleans', async () => {
		const start = false;

		const end = await serializer.deserializeArg(
			structuredClone(await serializer.serializeArg(start)),
		);

		expect(end).toBe(start);
		expect(typeof end).toBe(typeof start);
	});

	test('works with true booleans', async () => {
		const start = true;

		const end = await serializer.deserializeArg(
			structuredClone(await serializer.serializeArg(start)),
		);

		expect(end).toBe(start);
		expect(typeof end).toBe(typeof start);
	});

	test('works with numbers', async () => {
		const start = 123;

		const end = await serializer.deserializeArg(
			structuredClone(await serializer.serializeArg(start)),
		);

		expect(end).toBe(start);
		expect(typeof end).toBe(typeof start);
	});

	test('works with Spans', async () => {
		const start = Span.new(123, 321);

		const end = await serializer.deserializeArg(
			structuredClone(await serializer.serializeArg(start)),
		);

		expect(end.start).toBe(start.start);
		expect(end.len()).toBe(start.len());
		expect(typeof end).toBe(typeof start);
	});

	test('works with Lints', async () => {
		const linter = new LocalLinter({ binary });
		const lints = await linter.lint('This is an test.');
		const start = lints[0];

		expect(start).not.toBeNull();

		const end = await serializer.deserializeArg(
			structuredClone(await serializer.serializeArg(start)),
		);

		expect(end.message()).toBe(start.message());
		expect(end.lint_kind()).toBe(start.lint_kind());

		await linter.dispose();
	});
});



================================================
FILE: packages/harper.js/src/Serializer.ts
================================================
import type { BinaryModule, SuperBinaryModule } from './binary';
import { assert } from './utils';

export type SerializableTypes =
	| 'string'
	| 'number'
	| 'boolean'
	| 'object'
	| 'Suggestion'
	| 'Lint'
	| 'Span'
	| 'Array'
	| 'undefined'
	| 'bigint';

/** Serializable argument to a procedure to be run on the web worker. */
export interface RequestArg {
	json: string;
	type: SerializableTypes;
}

/** An object that is sent to the web worker to request work to be done. */
export interface SerializedRequest {
	/** The procedure to be executed. */
	procName: string;
	/** The arguments to the procedure */
	args: RequestArg[];
}

/** An object that is received by the web worker to request work to be done. */
export interface DeserializedRequest {
	/** The procedure to be executed. */
	procName: string;
	/** The arguments to the procedure */
	args: any[];
}

export function isSerializedRequest(v: unknown): v is SerializedRequest {
	return typeof v === 'object' && v !== null && 'procName' in v && 'args' in v;
}

/** An internal class that helps the `WorkerLinter` shuffle data across a messaging channel. */
export default class Serializer {
	binary: SuperBinaryModule;

	constructor(binary: BinaryModule) {
		this.binary = binary as SuperBinaryModule;
		this.binary.setup();
	}

	async serializeArg(arg: any): Promise<RequestArg> {
		const { Lint, Span, Suggestion } = await this.binary.getBinaryModule();

		if (Array.isArray(arg)) {
			return {
				json: JSON.stringify(await Promise.all(arg.map((a) => this.serializeArg(a)))),
				type: 'Array',
			};
		}

		const argType = typeof arg;
		switch (argType) {
			case 'string':
			case 'number':
			case 'boolean':
			case 'undefined':
				return { json: JSON.stringify(arg), type: argType };
			case 'bigint':
				return { json: arg.toString(), type: argType };
		}

		if (arg.to_json !== undefined) {
			const json = arg.to_json();
			let type: SerializableTypes | undefined;

			if (arg instanceof Lint) {
				type = 'Lint';
			} else if (arg instanceof Suggestion) {
				type = 'Suggestion';
			} else if (arg instanceof Span) {
				type = 'Span';
			}

			if (type === undefined) {
				throw new Error('Unhandled case: type undefined');
			}

			return { json, type };
		}

		if (argType == 'object') {
			return {
				json: JSON.stringify(
					await Promise.all(
						Object.entries(arg).map(([key, value]) => this.serializeArg([key, value])),
					),
				),
				type: 'object',
			};
		}

		throw new Error(`Unhandled case: ${arg}`);
	}

	async serialize(req: DeserializedRequest): Promise<SerializedRequest> {
		return {
			procName: req.procName,
			args: await Promise.all(req.args.map((arg) => this.serializeArg(arg))),
		};
	}

	async deserializeArg(requestArg: RequestArg): Promise<any> {
		const { Lint, Span, Suggestion } = await this.binary.getBinaryModule();

		switch (requestArg.type) {
			case 'bigint':
				return BigInt(requestArg.json);
			case 'undefined':
				return undefined;
			case 'boolean':
			case 'number':
			case 'string':
				return JSON.parse(requestArg.json);
			case 'Suggestion':
				return Suggestion.from_json(requestArg.json);
			case 'Lint':
				return Lint.from_json(requestArg.json);
			case 'Span':
				return Span.from_json(requestArg.json);
			case 'Array': {
				const parsed = JSON.parse(requestArg.json);
				assert(Array.isArray(parsed));
				return await Promise.all(parsed.map((arg) => this.deserializeArg(arg)));
			}
			case 'object': {
				const parsed = JSON.parse(requestArg.json);
				return Object.fromEntries(
					await Promise.all(parsed.map((val: any) => this.deserializeArg(val))),
				);
			}
			default:
				throw new Error(`Unhandled case: ${requestArg.type}`);
		}
	}

	async deserialize(request: SerializedRequest): Promise<DeserializedRequest> {
		return {
			procName: request.procName,
			args: await Promise.all(request.args.map((arg) => this.deserializeArg(arg))),
		};
	}
}



================================================
FILE: packages/harper.js/src/Summary.ts
================================================
/**
 * Represents the summary of linting results and history.
 * Useful to show linting statistics or insights to the user.
 */
export default interface Summary {
	/**
	 * An object mapping each lint type to its count.
	 * Example: `{ "Spelling": 4, "Capitalization": 1 }`
	 */
	lint_counts: Record<string, number>;

	/**
	 * The total number of fixes applied.
	 */
	total_applied: number;

	/**
	 * An object mapping misspelled words to their occurrence counts.
	 * Example: `{ "mispelled": 1, "mispell": 1, "thigs": 2 }`
	 */
	misspelled: Record<string, number>;
}



================================================
FILE: packages/harper.js/src/utils.ts
================================================
export function assert(condition: unknown, message?: string): asserts condition {
	if (!condition) {
		throw new Error(message ?? 'Assertion failed');
	}
}



================================================
FILE: packages/harper.js/src/WorkerLinter/index.ts
================================================
import type { Dialect, Lint, Suggestion } from 'harper-wasm';
import type { BinaryModule } from '../binary';
import type Linter from '../Linter';
import type { LinterInit } from '../Linter';
import type { LintConfig, LintOptions } from '../main';
import type { DeserializedRequest } from '../Serializer';
import Serializer from '../Serializer';
import Worker from './worker.ts?worker&inline';

/** The data necessary to complete a request once the worker has responded. */
export interface RequestItem {
	resolve: (item: unknown) => void;
	reject: (item: unknown) => void;
	request: DeserializedRequest;
}

/** A Linter that spins up a dedicated web worker to do processing on a separate thread.
 * Main benefit: this Linter will not block the event loop for large documents.
 *
 * NOTE: This class will not work properly in Node. In that case, just use `LocalLinter`. */
export default class WorkerLinter implements Linter {
	private binary: BinaryModule;
	private serializer: Serializer;
	private dialect?: Dialect;
	private worker: Worker;
	private requestQueue: RequestItem[];
	private working = true;
	private disposed = false;

	constructor(init: LinterInit) {
		this.binary = init.binary;
		this.serializer = new Serializer(this.binary);
		this.dialect = init.dialect;
		this.worker = new Worker();
		this.requestQueue = [];

		// Fires when the worker sends 'ready'.
		this.worker.onmessage = () => {
			this.setupMainEventListeners();

			this.worker.postMessage([this.binary.url, this.dialect]);

			this.working = false;
			this.submitRemainingRequests();
		};
	}

	private setupMainEventListeners() {
		this.worker.onmessage = (e: MessageEvent) => {
			const { resolve } = this.requestQueue.shift()!;
			this.serializer.deserializeArg(e.data).then((v) => {
				resolve(v);

				this.working = false;

				this.submitRemainingRequests();
			});
		};

		this.worker.onmessageerror = (e: MessageEvent) => {
			const { reject } = this.requestQueue.shift()!;
			reject(e.data);
			this.working = false;

			this.submitRemainingRequests();
		};
	}

	setup(): Promise<void> {
		return this.rpc('setup', []);
	}

	lint(text: string, options?: LintOptions): Promise<Lint[]> {
		return this.rpc('lint', [text, options]);
	}

	organizedLints(text: string, options?: LintOptions): Promise<Record<string, Lint[]>> {
		return this.rpc('organizedLints', [text, options]);
	}

	applySuggestion(text: string, lint: Lint, suggestion: Suggestion): Promise<string> {
		return this.rpc('applySuggestion', [text, lint, suggestion]);
	}

	isLikelyEnglish(text: string): Promise<boolean> {
		return this.rpc('isLikelyEnglish', [text]);
	}

	isolateEnglish(text: string): Promise<string> {
		return this.rpc('isolateEnglish', [text]);
	}

	async getLintConfig(): Promise<LintConfig> {
		return JSON.parse(await this.getLintConfigAsJSON());
	}

	setLintConfig(config: LintConfig): Promise<void> {
		return this.setLintConfigWithJSON(JSON.stringify(config));
	}

	getLintConfigAsJSON(): Promise<string> {
		return this.rpc('getLintConfigAsJSON', []);
	}

	setLintConfigWithJSON(config: string): Promise<void> {
		return this.rpc('setLintConfigWithJSON', [config]);
	}

	toTitleCase(text: string): Promise<string> {
		return this.rpc('toTitleCase', [text]);
	}

	getLintDescriptionsAsJSON(): Promise<string> {
		return this.rpc('getLintDescriptionsAsJSON', []);
	}

	async getLintDescriptions(): Promise<Record<string, string>> {
		return JSON.parse(await this.getLintDescriptionsAsJSON()) as Record<string, string>;
	}

	getLintDescriptionsHTMLAsJSON(): Promise<string> {
		return this.rpc('getLintDescriptionsHTMLAsJSON', []);
	}

	async getLintDescriptionsHTML(): Promise<Record<string, string>> {
		return JSON.parse(await this.getLintDescriptionsHTMLAsJSON()) as Record<string, string>;
	}

	getDefaultLintConfigAsJSON(): Promise<string> {
		return this.rpc('getDefaultLintConfigAsJSON', []);
	}

	async getDefaultLintConfig(): Promise<LintConfig> {
		return JSON.parse(await this.getDefaultLintConfigAsJSON()) as LintConfig;
	}

	async dispose(): Promise<void> {
		if (this.disposed) {
			return;
		}

		await this.rpc('dispose', []);

		this.disposed = true;
		this.requestQueue = [];
		this.worker.terminate();
	}

	ignoreLint(source: string, lint: Lint): Promise<void> {
		return this.rpc('ignoreLint', [source, lint]);
	}

	ignoreLintHash(hash: bigint): Promise<void> {
		return this.rpc('ignoreLintHash', [hash]);
	}

	exportIgnoredLints(): Promise<string> {
		return this.rpc('exportIgnoredLints', []);
	}

	importIgnoredLints(json: string): Promise<void> {
		return this.rpc('importIgnoredLints', [json]);
	}

	contextHash(source: string, lint: Lint): Promise<bigint> {
		return this.rpc('contextHash', [source, lint]);
	}

	clearIgnoredLints(): Promise<void> {
		return this.rpc('clearIgnoredLints', []);
	}

	clearWords(): Promise<void> {
		return this.rpc('clearWords', []);
	}

	importWords(words: string[]): Promise<void> {
		return this.rpc('importWords', [words]);
	}

	exportWords(): Promise<string[]> {
		return this.rpc('exportWords', []);
	}

	getDialect(): Promise<Dialect> {
		return this.rpc('getDialect', []);
	}

	setDialect(dialect: Dialect): Promise<void> {
		return this.rpc('setDialect', [dialect]);
	}

	summarizeStats(start?: bigint, end?: bigint): Promise<any> {
		return this.rpc('summarizeStats', [start, end]);
	}

	generateStatsFile(): Promise<string> {
		return this.rpc('generateStatsFile', []);
	}

	importStatsFile(statsFile: string): Promise<void> {
		return this.rpc('importStatsFile', [statsFile]);
	}

	/** Run a procedure on the remote worker. */
	private async rpc(procName: string, args: unknown[]): Promise<any> {
		if (this.disposed) {
			throw new Error('WorkerLinter has been disposed.');
		}

		const promise = new Promise((resolve, reject) => {
			this.requestQueue.push({
				resolve,
				reject,
				request: { procName, args },
			});

			this.submitRemainingRequests();
		});

		return promise;
	}

	private async submitRemainingRequests() {
		if (this.working) {
			return;
		}

		this.working = true;

		if (this.requestQueue.length > 0) {
			const { request } = this.requestQueue[0];
			const serialized = await this.serializer.serialize(request);
			this.worker.postMessage(serialized);
		} else {
			this.working = false;
		}
	}
}



================================================
FILE: packages/harper.js/src/WorkerLinter/shims.ts
================================================
if (import.meta.env.MODE === 'test') {
	// @ts-expect-error
	globalThis.__vitest_browser_runner__ = { wrapDynamicImport: (f) => f() };
}



================================================
FILE: packages/harper.js/src/WorkerLinter/worker.ts
================================================
/// <reference lib="webworker" />
import './shims';
import { SuperBinaryModule } from '../binary';
import LocalLinter from '../LocalLinter';
import Serializer, { isSerializedRequest, type SerializedRequest } from '../Serializer';

// Notify the main thread that we are ready
self.postMessage('ready');

self.onmessage = (e) => {
	const [binaryUrl, dialect] = e.data;
	if (typeof binaryUrl !== 'string') {
		throw new TypeError(`Expected binary to be a string of url but got ${typeof binaryUrl}.`);
	}
	const binary = SuperBinaryModule.create(binaryUrl);
	const serializer = new Serializer(binary);
	const linter = new LocalLinter({ binary, dialect });

	async function processRequest(v: SerializedRequest) {
		const { procName, args } = await serializer.deserialize(v);

		if (procName in linter) {
			// @ts-expect-error
			const res = await linter[procName](...args);
			postMessage(await serializer.serializeArg(res));
		}
	}

	self.onmessage = (e) => {
		if (isSerializedRequest(e.data)) {
			processRequest(e.data);
		}
	};
};



================================================
FILE: packages/lint-framework/README.md
================================================
# `lint-framework`

The `lint-framework` serves one specific purpose.
It contains all the logic needed to read and write text to a text editor on a web page to perform linting actions, as well as all logic needed to render underlines and UI for reviewing those actions.
It exists separate from the Chrome/Firefox extensions because there are places where we wish to perform linting actions outside of the Chrome extension (for example, in the demo on the Harper website).



================================================
FILE: packages/lint-framework/package.json
================================================
{
	"name": "lint-framework",
	"version": "0.0.1",
	"license": "Apache-2.0",
	"type": "module",
	"private": false,
	"main": "dist/index.js",
	"types": "dist/index.d.ts",
	"exports": {
		".": {
			"types": "./dist/index.d.ts",
			"default": "./dist/index.js"
		}
	},
	"files": [
		"dist"
	],
	"scripts": {
		"build": "tsc && vite build -l warn",
		"dev": "vite",
		"test": "echo 'no tests'"
	},
	"dependencies": {
		"@fortawesome/fontawesome-svg-core": "^7.1.0",
		"@fortawesome/free-solid-svg-icons": "^7.1.0",
		"colorjs.io": "^0.5.2",
		"virtual-dom": "^2.1.1"
	},
	"peerDependencies": {
		"harper.js": "workspace:*"
	},
	"devDependencies": {
		"@types/chrome": "0.1.27",
		"@types/virtual-dom": "^2.1.4",
		"type-fest": "^4.37.0",
		"typescript": "catalog:",
		"vite": "^6.1.0",
		"vite-plugin-dts": "^4.5.0"
	}
}



================================================
FILE: packages/lint-framework/tsconfig.json
================================================
{
	"compilerOptions": {
		"target": "ES2020",
		"useDefineForClassFields": true,
		"module": "ESNext",
		"lib": ["ES2020", "DOM", "DOM.Iterable"],
		"skipLibCheck": true,
		"resolveJsonModule": true,
		/* Bundler mode */
		"moduleResolution": "bundler",
		"allowImportingTsExtensions": true,
		"isolatedModules": true,
		"moduleDetection": "force",
		"noEmit": true,
		/* Linting */
		"strict": true,
		"noUnusedLocals": true,
		"noUnusedParameters": true,
		"noFallthroughCasesInSwitch": true
	},
	"include": ["src"]
}



================================================
FILE: packages/lint-framework/vite.config.ts
================================================
import { resolve } from 'path';
import { defineConfig } from 'vite';
import dts from 'vite-plugin-dts';

export default defineConfig({
	build: {
		lib: {
			entry: resolve(__dirname, 'src/index.ts'),
			name: 'lintFramework',
			fileName: 'index',
			formats: ['es'],
		},
		minify: true,
		rollupOptions: {
			external: ['harper.js'],
			output: {
				inlineDynamicImports: true,
				minifyInternalExports: true,
			},
			treeshake: {
				moduleSideEffects: false,
				propertyReadSideEffects: false,
			},
		},
	},
	plugins: [
		dts({
			rollupTypes: true,
			tsconfigPath: './tsconfig.json',
		}),
	],
});



================================================
FILE: packages/lint-framework/src/index.ts
================================================
export * from './lint/Box';
export { default as computeLintBoxes } from './lint/computeLintBoxes';
export * from './lint/domUtils';
export * from './lint/editorUtils';
export { default as Highlights } from './lint/Highlights';
export { default as LintFramework } from './lint/LintFramework';
export * from './lint/lintKindColor';
export { default as PopupHandler } from './lint/PopupHandler';
export { default as RenderBox } from './lint/RenderBox';
export * from './lint/unpackLint';
export { default as unpackLint } from './lint/unpackLint';



================================================
FILE: packages/lint-framework/src/assets/bookDownSvg.ts
================================================
export default `<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-book-down-icon lucide-book-down"><path d="M12 13V7"/><path d="M4 19.5v-15A2.5 2.5 0 0 1 6.5 2H19a1 1 0 0 1 1 1v18a1 1 0 0 1-1 1H6.5a1 1 0 0 1 0-5H20"/><path d="m9 10 3 3 3-3"/></svg>`;



================================================
FILE: packages/lint-framework/src/assets/hints.json
================================================
[
	"Vary sentence length to keep readers engaged.",
	"Replace clichés with fresh, precise wording.",
	"Check subject‑verb agreement, especially in long sentences.",
	"Keep consistent terminology across the document.",
	"Read aloud to catch awkward phrasing.",
	"You can easily write em-dashes by typing out three hyphens in a row.",
	"You can easily write en-dashes by typing out two hyphens in a row.",
	"Harper can be configured to open with a hotkey. Check the extension's settings.",
	"Don't agree with a suggestion? Click 'Ignore' and Harper will adapt to your writing style.",
	"You can add specialized terms, names, or acronyms to your personal dictionary in Harper's settings.",
	"Check your language preferences in Settings to get suggestions for different dialects (e.g., American vs. British English)."
]



================================================
FILE: packages/lint-framework/src/lint/Box.ts
================================================
import type SourceElement from './SourceElement';
import type { UnpackedLint, UnpackedSuggestion } from './unpackLint';

export type Box = {
	/** Horizontal position in pixels */
	x: number;
	/** Vertical position in pixels */
	y: number;
	/** Width in pixels */
	width: number;
	/** Height in pixels */
	height: number;
};

export type LintBox = Box & {
	lint: UnpackedLint;
	source: SourceElement;
	/** Optionally provided to improve highlight rendering performance. */
	range?: Range;
	applySuggestion: (sug: UnpackedSuggestion) => void;
};

export type IgnorableLintBox = LintBox & {
	/** The rule that produced the lint */
	rule: string;
	ignoreLint?: () => Promise<void>;
};

/** Get a box that represents the screen. */
export function screenBox(): Box {
	return {
		x: 0,
		y: 0,
		width: window.innerWidth,
		height: window.innerHeight,
	};
}

export function isPointInBox(point: [number, number], box: Box) {
	const [x, y] = point;

	return x >= box.x && x <= box.x + box.width && y >= box.y && y <= box.y + box.height;
}

/** Check if a box would be visible on the screen if drawn. */
export function isBoxInScreen(box: Box): boolean {
	const screen = screenBox();

	// If any corner is in the screen, the box is visible.
	if (isPointInBox([box.x, box.y], screen)) {
		return true;
	}

	if (isPointInBox([box.x + box.width, box.y], screen)) {
		return true;
	}

	if (isPointInBox([box.x + box.width, box.y + box.height], screen)) {
		return true;
	}

	if (isPointInBox([box.x, box.y + box.height], screen)) {
		return true;
	}

	return false;
}

export function boxesOverlap(a: Box, b: Box): boolean {
	return a.x < b.x + b.width && a.x + a.width > b.x && a.y < b.y + b.height && a.y + a.height > b.y;
}

export function domRectToBox(rect: DOMRect): Box {
	return {
		x: rect.x,
		y: rect.y,
		width: rect.width,
		height: rect.height,
	};
}

export function isBottomEdgeInBox(inner: Box, outer: Box): boolean {
	const leftBottom: [number, number] = [inner.x, inner.y + inner.height];
	const rightBottom: [number, number] = [inner.x + inner.width, inner.y + inner.height];
	return isPointInBox(leftBottom, outer) && isPointInBox(rightBottom, outer);
}

export function closestBox(target: Box, boxes: Box[]): number {
	const cx = target.x + target.width / 2;
	const cy = target.y + target.height / 2;

	let min = Number.POSITIVE_INFINITY;
	let idx = -1;

	for (let i = 0; i < boxes.length; i++) {
		const b = boxes[i];
		if (boxesOverlap(target, b)) return i;
		const bx = b.x + b.width / 2;
		const by = b.y + b.height / 2;
		const dist = Math.hypot(bx - cx, by - cy);
		if (dist < min) {
			min = dist;
			idx = i;
		}
	}
	return idx;
}

export function shrinkBoxToFit(inner: Box, outer: Box): Box {
	const nx = Math.max(inner.x, outer.x);
	const ny = Math.max(inner.y, outer.y);
	const rx = Math.min(inner.x + inner.width, outer.x + outer.width);
	const by = Math.min(inner.y + inner.height, outer.y + outer.height);
	return { x: nx, y: ny, width: Math.max(0, rx - nx), height: Math.max(0, by - ny) };
}



================================================
FILE: packages/lint-framework/src/lint/computeLintBoxes.ts
================================================
import type { Span } from 'harper.js';
import { domRectToBox, type IgnorableLintBox, isBottomEdgeInBox, shrinkBoxToFit } from './Box';
import { getRangeForTextSpan } from './domUtils';
import {
	getCkEditorRoot,
	getDraftRoot,
	getLexicalRoot,
	getSlateRoot,
	isFormEl,
} from './editorUtils';
import TextFieldRange from './TextFieldRange';
import { applySuggestion, type UnpackedLint, type UnpackedSuggestion } from './unpackLint';

export default function computeLintBoxes(
	el: HTMLElement,
	lint: UnpackedLint,
	rule: string,
	opts: { ignoreLint?: (hash: string) => Promise<void> },
): IgnorableLintBox[] {
	try {
		let range: Range | TextFieldRange | null = null;

		if (isFormEl(el)) {
			range = new TextFieldRange(el, lint.span.start, lint.span.end);
		} else {
			range = getRangeForTextSpan(el, lint.span as Span);
		}

		if (!range) {
			return [];
		}

		const targetRects = Array.from(
			(range as Range).getClientRects ? (range as Range).getClientRects() : [],
		);
		const elBox = domRectToBox((range as Range).getBoundingClientRect());
		(range as any).detach?.();

		const boxes: IgnorableLintBox[] = [];

		let source: HTMLElement | null = null;

		if (el.tagName == undefined) {
			source = el.parentElement;
		} else {
			source = el;
		}

		if (source == null) {
			return [];
		}

		for (const targetRect of targetRects as DOMRect[]) {
			if (!isBottomEdgeInBox(targetRect, elBox)) {
				continue;
			}

			const shrunkBox = shrinkBoxToFit(targetRect, elBox);

			boxes.push({
				x: shrunkBox.x,
				y: shrunkBox.y,
				width: shrunkBox.width,
				height: shrunkBox.height,
				lint,
				source,
				rule,
				range: range instanceof Range ? range : undefined,
				applySuggestion: (sug: UnpackedSuggestion) => {
					const current = isFormEl(el)
						? (el as HTMLInputElement | HTMLTextAreaElement).value
						: (el.textContent ?? '');
					const newValue = applySuggestion(current, lint.span, sug);
					replaceValue(el, newValue, lint.span, sug.replacement_text);
				},
				ignoreLint: opts.ignoreLint ? () => opts.ignoreLint!(lint.context_hash) : undefined,
			});
		}
		return boxes;
	} catch (e) {
		// If there's an error, it's likely because the element no longer exists
		return [];
	}
}

function replaceValue(
	el: HTMLElement,
	value: string,
	span?: { start: number; end: number },
	replacementText?: string,
) {
	if (isFormEl(el)) {
		replaceFormElementValue(el as HTMLTextAreaElement | HTMLInputElement, value);
	} else if (getLexicalRoot(el) != null && span && replacementText !== undefined) {
		replaceLexicalValue(el, span, replacementText);
	} else if (getDraftRoot(el) != null && span && replacementText !== undefined) {
		replaceDraftValue(el, span, replacementText);
	} else if (
		(getSlateRoot(el) != null || getCkEditorRoot(el) != null) &&
		span &&
		replacementText !== undefined
	) {
		replaceRichTextEditorValue(el, span, replacementText);
	} else {
		replaceGenericContentEditable(el, value);
	}

	el.dispatchEvent(new Event('change', { bubbles: true }));
}

function replaceFormElementValue(el: HTMLTextAreaElement | HTMLInputElement, value: string) {
	el.dispatchEvent(new InputEvent('beforeinput', { bubbles: true, data: value }));
	el.value = value;
	el.dispatchEvent(new InputEvent('input', { bubbles: true }));
}

function replaceLexicalValue(
	el: HTMLElement,
	span: { start: number; end: number },
	replacementText: string,
) {
	const setup = selectSpanInEditor(el, span);
	if (!setup) return;

	const { doc, sel, range } = setup;

	// Direct DOM replacement
	replaceTextInRange(doc, sel, range, replacementText);

	// Notify
	el.dispatchEvent(new InputEvent('input', { bubbles: true, cancelable: false }));
}

function replaceDraftValue(
	el: HTMLElement,
	span: { start: number; end: number },
	replacementText: string,
) {
	const setup = selectSpanInEditor(el, span);
	if (!setup) return;

	const { doc, sel, range } = setup;

	setTimeout(() => {
		const beforeEvt = new InputEvent('beforeinput', {
			bubbles: true,
			cancelable: true,
			inputType: 'insertText',
			data: replacementText,
		});
		el.dispatchEvent(beforeEvt);

		if (!beforeEvt.defaultPrevented) {
			replaceTextInRange(doc, sel, range, replacementText);
		}

		el.dispatchEvent(new InputEvent('input', { bubbles: true, inputType: 'insertText' }));
	}, 0);
}

function selectSpanInEditor(el: HTMLElement, span: { start: number; end: number }) {
	const doc = el.ownerDocument;
	const sel = doc.defaultView?.getSelection();

	if (!sel) {
		return null;
	}

	el.focus();

	const range = getRangeForTextSpan(el, span as Span);
	if (!range) {
		return null;
	}

	sel.removeAllRanges();
	sel.addRange(range);

	return { doc, sel, range };
}

function replaceRichTextEditorValue(
	el: HTMLElement,
	span: { start: number; end: number },
	replacementText: string,
) {
	const setup = selectSpanInEditor(el, span);
	if (!setup) return;

	const { doc, sel, range } = setup;

	const evInit: InputEventInit = {
		bubbles: true,
		cancelable: true,
		inputType: 'insertReplacementText',
		data: replacementText,
	};

	if ('StaticRange' in self) {
		evInit.targetRanges = [new StaticRange(range)];
	}

	const beforeEvt = new InputEvent('beforeinput', evInit);
	el.dispatchEvent(beforeEvt);

	if (!beforeEvt.defaultPrevented) {
		replaceTextInRange(doc, sel, range, replacementText);
		el.dispatchEvent(new InputEvent('input', { bubbles: true, cancelable: false }));
	}
}

function replaceTextInRange(doc: Document, sel: Selection, range: Range, replacementText: string) {
	const startContainer = range.startContainer;
	const endContainer = range.endContainer;

	if (startContainer === endContainer && startContainer.nodeType === Node.TEXT_NODE) {
		const textNode = startContainer as Text;
		const startOffset = range.startOffset;
		const endOffset = range.endOffset;

		const oldText = textNode.textContent || '';
		const newText =
			oldText.substring(0, startOffset) + replacementText + oldText.substring(endOffset);

		textNode.textContent = newText;

		// Set cursor after replacement
		const newRange = doc.createRange();
		const cursorPosition = startOffset + replacementText.length;
		newRange.setStart(textNode, cursorPosition);
		newRange.setEnd(textNode, cursorPosition);
		sel.removeAllRanges();
		sel.addRange(newRange);
	} else {
		// Multi node range fallback
		range.deleteContents();
		const textNode = doc.createTextNode(replacementText);
		range.insertNode(textNode);

		const newRange = doc.createRange();
		newRange.setStartAfter(textNode);
		newRange.setEndAfter(textNode);
		sel.removeAllRanges();
		sel.addRange(newRange);
	}
}

function replaceGenericContentEditable(el: HTMLElement, value: string) {
	el.textContent = value;
	el.dispatchEvent(new InputEvent('beforeinput', { bubbles: true, data: value }));
	el.dispatchEvent(new InputEvent('input', { bubbles: true }));
}



================================================
FILE: packages/lint-framework/src/lint/domUtils.ts
================================================
import type { Span } from 'harper.js';
import { isBoxInScreen } from './Box';

/**
 * Turn a `NodeList` into a normal JavaScript array.
 * @param collection
 */
export function extractFromHTMLCollection(collection: HTMLCollection): Element[] {
	const elements: Element[] = [];
	for (let i = 0; i < collection.length; i++) {
		const el = collection.item(i);
		if (el) elements.push(el);
	}
	return elements;
}

/**
 * Turn a `NodeList` into a normal JavaScript array.
 * @param list
 */
export function extractFromNodeList<T extends Node>(list: NodeListOf<T>): T[] {
	const elements: T[] = [];

	for (let i = 0; i < list.length; i++) {
		const item = list[i];
		elements.push(item);
	}

	return elements;
}

export function getNodesFromQuerySelector(element: Element, query: string) {
	return extractFromNodeList(element.querySelectorAll(query));
}

/** Get a node's closest ancestor that has `display: block`. */
export function getClosestBlockAncestor(leaf: Node, root: Element): Element | null {
	let current: Node | null = leaf;

	while (current) {
		if (current instanceof Element) {
			if (getComputedStyle(current).display === 'block') {
				return current;
			}

			if (current === root) {
				break;
			}
		}

		current = current.parentNode;
	}

	return null;
}

/**
 * Flatten a provided node, and its children into a single array.
 * @param node
 */
export function leafNodes(node: Node): Node[] {
	const out: Node[] = [];

	const children = extractFromNodeList(node.childNodes);

	if (children.length === 0) {
		return [node];
	}

	for (const child of children) {
		const sub = leafNodes(child);
		sub.forEach((v) => {
			out.push(v);
		});
	}

	return out;
}

/**
 * Given an element and a Span of text inside it, compute the Range that represents the region of the DOM represented.
 * @param target
 * @param span
 */
export function getRangeForTextSpan(target: Element, span: Span): Range | null {
	const children = leafNodes(target);

	const range = document.createRange();
	let traversed = 0;

	let startFound = false;

	for (let i = 0; i < children.length; i++) {
		const child = children[i] as HTMLElement;
		const childText = child.textContent ?? '';

		if (traversed + childText.length > span.start && !startFound) {
			range.setStart(child, span.start - traversed);
			startFound = true;
		}

		if (startFound && traversed + childText.length >= span.end) {
			range.setEnd(child, span.end - traversed);
			return range;
		}

		traversed += childText?.length ?? 0;
	}

	return null;
}

const sharedRange: Range | null = typeof document !== 'undefined' ? document.createRange() : null;

/** Check if a node represents a heading (native heading tags or role="heading"). */
export function isHeading(node: Node): boolean {
	if (!(node instanceof Element)) return false;

	const tag = node.tagName.toLowerCase();
	if (/^h[1-6]$/.test(tag)) return true;

	const role = node.getAttribute('role');
	return role?.toLowerCase() === 'heading';
}

/** Check if an element is visible to the user.
 *
 * It is coarse and meant for performance improvements, not precision.*/
export function isVisible(node: Node): boolean {
	try {
		if (!node || !(node as any).ownerDocument) return false;

		if (node instanceof Element) {
			if (!node.isConnected) return false;
			const rect = node.getBoundingClientRect();
			if (!isBoxInScreen(rect)) return false;
			const cv = (node as any).checkVisibility;
			if (typeof cv === 'function') return cv.call(node);
			const cs = getComputedStyle(node);
			if (cs.display === 'none' || cs.visibility === 'hidden' || cs.opacity === '0') return false;
			return true;
		}

		if (!sharedRange) return false;
		const parent = (node as any).parentElement as Element | null;
		if (parent && !parent.isConnected) return false;
		sharedRange.selectNode(node);
		const rect = sharedRange.getBoundingClientRect();
		return isBoxInScreen(rect);
	} catch {
		return false;
	}
}



================================================
FILE: packages/lint-framework/src/lint/editorUtils.ts
================================================
import { type Box, domRectToBox } from './Box';
import type SourceElement from './SourceElement';
import TextFieldRange from './TextFieldRange';

export function findAncestor(
	el: SourceElement,
	predicate: (el: SourceElement) => boolean,
): SourceElement | null {
	let current: SourceElement | null = el;
	while (current != null) {
		if (predicate(current)) return current;
		current = current.parentElement;
	}
	return null;
}

export function getGhostRoot(el: SourceElement): SourceElement | null {
	return findAncestor(
		el,
		(node: SourceElement) => !isTextNode(node) && node.closest('article, main, section') != null,
	);
}

export function getDraftRoot(el: SourceElement): SourceElement | null {
	return findAncestor(
		el,
		(node: SourceElement) =>
			!isTextNode(node) && node.classList.contains('public-DraftEditor-content'),
	);
}

export function getPMRoot(el: SourceElement): SourceElement | null {
	return findAncestor(
		el,
		(node: SourceElement) => !isTextNode(node) && node.classList.contains('ProseMirror'),
	);
}

export function getCMRoot(el: SourceElement): SourceElement | null {
	return findAncestor(
		el,
		(node: SourceElement) => !isTextNode(node) && node.classList.contains('cm-editor'),
	);
}

export function getNotionRoot(): SourceElement | null {
	return document.getElementById('notion-app');
}

export function getSlateRoot(el: SourceElement): SourceElement | null {
	return findAncestor(
		el,
		(node: SourceElement) => !isTextNode(node) && node.getAttribute('data-slate-editor') === 'true',
	);
}

export function getLexicalRoot(el: SourceElement): SourceElement | null {
	return findAncestor(
		el,
		(node: SourceElement) =>
			!isTextNode(node) && node.getAttribute('data-lexical-editor') === 'true',
	);
}

export function getCkEditorRoot(el: SourceElement): SourceElement | null {
	return findAncestor(
		el,
		(node: SourceElement) => !isTextNode(node) && node.classList.contains('ck-editor__editable'),
	);
}

export function getLexicalEditable(el: SourceElement): SourceElement | null {
	return findAncestor(
		el,
		(node: SourceElement) => !isTextNode(node) && node.getAttribute('contenteditable') === 'true',
	);
}

export function getMediumRoot(el: SourceElement): SourceElement | null {
	return findAncestor(
		el,
		(node: SourceElement) => node.nodeName == 'MAIN' && location.hostname == 'medium.com',
	);
}

export function getShredditComposerRoot(el: SourceElement): SourceElement | null {
	return findAncestor(
		el,
		(node: SourceElement) => !isTextNode(node) && node.nodeName == 'SHREDDIT-COMPOSER',
	);
}

export function getQuillJsRoot(el: SourceElement): SourceElement | null {
	return findAncestor(
		el,
		(node: SourceElement) => !isTextNode(node) && node.classList.contains('ql-container'),
	);
}

export function getP2Root(el: SourceElement): SourceElement | null {
	return findAncestor(
		el,
		(node: SourceElement) =>
			!isTextNode(node) && (node.id === 'p2' || node.classList.contains('p2')),
	);
}

export function getGutenbergRoot(el: SourceElement): SourceElement | null {
	return findAncestor(
		el,
		(node: SourceElement) =>
			!isTextNode(node) &&
			(node.id === 'editor' || node.classList.contains('editor-styles-wrapper')),
	);
}

export function getTrixRoot(el: SourceElement): SourceElement | null {
	return findAncestor(el, (node: SourceElement) => node.nodeName == 'TRIX-EDITOR');
}

export function getCaretPosition(): Box | null {
	const active = document.activeElement;

	if (
		active instanceof HTMLTextAreaElement ||
		(active instanceof HTMLInputElement && active.type === 'text')
	) {
		if (
			active.selectionStart == null ||
			active.selectionEnd == null ||
			active.selectionStart !== active.selectionEnd
		) {
			return null;
		}

		const offset = active.selectionStart;
		const tfRange = new TextFieldRange(active, offset, offset);
		const rects = tfRange.getClientRects();
		tfRange.detach();

		return rects.length ? domRectToBox(rects[0]) : null;
	}

	const selection = window.getSelection();
	if (!selection || selection.rangeCount === 0) return null;

	const range = selection.getRangeAt(0);
	if (!range.collapsed) return null;

	return domRectToBox(range.getBoundingClientRect());
}

export function isFormEl(el: any): el is HTMLInputElement | HTMLTextAreaElement {
	return el instanceof HTMLInputElement || el instanceof HTMLTextAreaElement;
}

export function isTextNode(el: SourceElement): el is Text {
	return el.nodeType === Node.TEXT_NODE;
}



================================================
FILE: packages/lint-framework/src/lint/Highlights.ts
================================================
import type { VNode } from 'virtual-dom';
import h from 'virtual-dom/h';
import type { LintBox } from './Box';
import {
	getCMRoot,
	getDraftRoot,
	getGhostRoot,
	getGutenbergRoot,
	getLexicalRoot,
	getMediumRoot,
	getNotionRoot,
	getP2Root,
	getPMRoot,
	getQuillJsRoot,
	getShredditComposerRoot,
	getSlateRoot,
	getTrixRoot,
} from './editorUtils';
import { type LintKind, lintKindColor } from './lintKindColor';
import RenderBox from './RenderBox';
import type SourceElement from './SourceElement';
import type { UnpackedLint } from './unpackLint';

/** A class that renders highlights to a page and nothing else. Uses a virtual DOM to minimize jitter. */
export default class Highlights {
	renderBoxes: Map<SourceElement, RenderBox>;
	highlights: Map<LintKind, Highlight> | null;

	constructor() {
		this.renderBoxes = new Map();
		this.highlights = supportsCustomHighlights() ? new Map() : null;
	}

	/** Used for CSS highlight API */
	private insertHighlightStyle(tag: string, lint: UnpackedLint) {
		const color = lintKindColor(lint.lint_kind);
		const textDecor = `underline ${color} solid 2px`;
		const backgroundColor = `${color}22`;

		const styleId = `harper-highlight-style-${lint.lint_kind}`;
		if (document.getElementById(styleId)) return;

		const style = document.createElement('style');
		style.id = styleId;
		style.textContent = `
      ::highlight(${tag}) {
        text-decoration: ${textDecor};
        background-color: ${backgroundColor};
      }
    `;
		document.head.appendChild(style);
	}

	public renderLintBoxes(boxes: LintBox[]) {
		// Sort the lint boxes based on their source, so we can render them all together.
		const sourceToBoxes: Map<SourceElement, { boxes: LintBox[]; cpa: DOMRect | null }> = new Map();

		// Clear old highlights if they exist
		if (this.highlights) {
			for (const [_, highlight] of this.highlights) {
				highlight.clear();
			}
		}

		for (const box of boxes) {
			if (box.range && this.highlights != null) {
				let highlight = this.highlights.get(box.lint.lint_kind);

				if (highlight != null) {
					highlight.add(box.range);
				} else {
					highlight = new Highlight();
					const tag = `harper-${box.lint.lint_kind}`;
					CSS.highlights.set(tag, highlight);
					this.insertHighlightStyle(tag, box.lint);
					highlight.add(box.range);
					this.highlights.set(box.lint.lint_kind, highlight);
				}

				continue;
			}

			let renderBox = this.renderBoxes.get(box.source);

			if (renderBox == null) {
				renderBox = new RenderBox(this.computeRenderTarget(box.source));
				this.renderBoxes.set(box.source, renderBox);
			}

			const value = sourceToBoxes.get(box.source);
			const icr = getInitialContainingRect(renderBox.getShadowHost());

			let cpa = null;

			if (cpa == null) {
				if (icr != null) {
					cpa = icr;
				}
			}

			if (value == null) {
				sourceToBoxes.set(box.source, { boxes: [box], cpa });
			} else {
				sourceToBoxes.set(box.source, { boxes: [...value.boxes, box], cpa });
			}
		}

		const updated = new Set();

		for (const [source, { boxes, cpa }] of sourceToBoxes.entries()) {
			const renderBox = this.renderBoxes.get(source)!;

			const host = renderBox.getShadowHost();
			host.id = 'harper-highlight-host';

			if (cpa != null) {
				const hostStyle = host.style;

				hostStyle.position = 'absolute';
				hostStyle.top = '0px';
				hostStyle.left = '0px';
				hostStyle.inset = '0';
				hostStyle.pointerEvents = 'none';
				hostStyle.width = '0px';
				hostStyle.height = '0px';
				hostStyle.contain = 'none';
				hostStyle.transform = 'none';
			} else if (host.hasAttribute('style')) {
				host.removeAttribute('style');
			}

			renderBox.render(
				this.renderTree(
					boxes,
					cpa
						? {
								x: cpa.x,
								y: cpa.y,
							}
						: null,
				),
			);
			updated.add(source);
		}

		for (const [source, box] of this.renderBoxes.entries()) {
			if (!updated.has(source)) {
				box.render(h('div', {}, []));
			}
		}

		this.pruneDetachedSources();
	}

	/** Remove the render boxes for sources that aren't attached any longer. */
	private pruneDetachedSources() {
		for (const [source, box] of this.renderBoxes.entries()) {
			if (!document.contains(source)) {
				box.remove();
				this.renderBoxes.delete(source);
			}
		}
	}

	private renderTree(boxes: LintBox[], offset: { x: number; y: number } | null): VNode {
		const elements = [];
		const offsetX = offset?.x ?? 0;
		const offsetY = offset?.y ?? 0;

		for (const box of boxes) {
			const boxEl = h(
				'div',
				{
					style: {
						position: 'fixed',
						left: '0px',
						top: '0px',
						transform: `translate(${box.x - offsetX}px, ${box.y - offsetY}px)`,
						width: `${box.width}px`,
						height: `${box.height}px`,
						pointerEvents: 'none',
						borderBottom: `2px solid ${lintKindColor(box.lint.lint_kind)}`,
						backgroundColor: `${lintKindColor(box.lint.lint_kind)}22`,
					},
					id: 'harper-highlight',
				},
				[],
			);

			elements.push(boxEl);
		}

		return h('div', {}, elements);
	}

	/** Determines which target the render boxes should be attached to.
	 * Depends on text editor. */
	private computeRenderTarget(el: SourceElement): HTMLElement {
		if (el.parentElement?.classList.contains('ProseMirror')) {
			return el.parentElement.parentElement!;
		}

		const queries = [
			getQuillJsRoot,
			getNotionRoot,
			getGhostRoot,
			getDraftRoot,
			getPMRoot,
			getCMRoot,
			getSlateRoot,
			getMediumRoot,
			getShredditComposerRoot,
			getLexicalRoot,
			getP2Root,
			getGutenbergRoot,
			getTrixRoot,
		];

		for (const query of queries) {
			const root = query(el);
			if (root != null) {
				return root.parentElement!;
			}
		}

		return el.parentElement!;
	}
}

function getInitialContainingRect(el: HTMLElement): DOMRect | null {
	let node = el.parentElement;

	while (node && node.nodeType === 1) {
		if (isContainingBlock(node)) {
			return node.getBoundingClientRect();
		}
		node = node.parentElement;
	}

	return null;
}

/**
 * Determines whether a given element would form the containing block
 * for a descendant with `position: fixed`, based on CSS transforms,
 * filters, containment, container queries, will-change, and
 * content-visibility.
 *
 * Logs the element and the precise reason it qualifies.
 */
function isContainingBlock(el: Element): boolean {
	if (!(el instanceof Element)) {
		throw new TypeError('Expected a DOM Element');
	}

	const style = window.getComputedStyle(el);

	const filter = style.getPropertyValue('filter');
	if (filter !== 'none') {
		return true;
	}

	const backdrop = style.getPropertyValue('backdrop-filter');
	if (backdrop !== 'none') {
		return true;
	}

	const transform = style.getPropertyValue('transform');
	if (transform !== 'none') {
		return true;
	}

	const perspective = style.getPropertyValue('perspective');
	if (perspective !== 'none') {
		return true;
	}

	const contain = style.getPropertyValue('contain');
	const containMatch = contain.match(/\b(layout|paint|strict|content)\b/);
	if (containMatch) {
		return true;
	}

	const willChange = style.getPropertyValue('will-change');
	if (willChange && willChange.trim() !== 'auto') {
		const declared = willChange.split(',').map((p) => p.trim());
		const triggers = ['filter', 'backdrop-filter', 'transform', 'perspective'];
		const intersection = declared.filter((p) => triggers.includes(p));
		if (intersection.length) {
			return true;
		}
	}

	const contentVis = style.getPropertyValue('content-visibility');
	if (contentVis === 'auto') {
		return true;
	}

	return false;
}

export function supportsCustomHighlights() {
	const root = globalThis.document?.documentElement;
	const disableFlag =
		root?.getAttribute?.('data-harper-disable-css-highlights') === 'true' ||
		root?.dataset?.harperDisableCssHighlights === 'true';
	if (disableFlag) {
		return false;
	}
	const isAutomated = globalThis.navigator?.webdriver === true;
	if (isAutomated) {
		return false;
	}
	if (!('CSS' in window) || typeof CSS.supports !== 'function') return false;
	const supportsSelector = CSS.supports('selector(::highlight(__x))');
	const reg = CSS?.highlights as any;
	const hasRegistry =
		!!reg && ['get', 'set', 'has', 'delete', 'clear'].every((m) => typeof reg[m] === 'function');
	const hasCtor = typeof window.Highlight === 'function';
	let canRegister = false;
	if (hasRegistry && hasCtor) {
		try {
			const h = new Highlight();
			CSS.highlights.set('__probe__', h);
			canRegister = CSS.highlights.has('__probe__');
			CSS.highlights.delete('__probe__');
		} catch {}
	}
	return supportsSelector && hasRegistry && hasCtor && canRegister;
}



================================================
FILE: packages/lint-framework/src/lint/LintFramework.ts
================================================
import type { LintOptions } from 'harper.js';
import { closestBox, type IgnorableLintBox } from './Box';
import computeLintBoxes from './computeLintBoxes';
import { isHeading, isVisible } from './domUtils';
import { getCaretPosition } from './editorUtils';
import Highlights from './Highlights';
import PopupHandler from './PopupHandler';
import type { UnpackedLint, UnpackedLintGroups } from './unpackLint';

type ActivationKey = 'off' | 'shift' | 'control';

type Modifier = 'Ctrl' | 'Shift' | 'Alt';

type Hotkey = {
	modifiers: Modifier[];
	key: string;
};

/** Events on an input (any kind) that can trigger a re-render. */
const INPUT_EVENTS = ['focus', 'keyup', 'paste', 'change', 'scroll'];
/** Events on the window that can trigger a re-render. */
const PAGE_EVENTS = ['resize', 'scroll'];

/** Orchestrates linting and rendering in response to events on the page. */
export default class LintFramework {
	private highlights: Highlights;
	private popupHandler: PopupHandler;
	private targets: Set<Node>;
	private scrollableAncestors: Set<HTMLElement>;
	private lintRequested = false;
	private renderRequested = false;
	private lastLints: { target: HTMLElement; lints: UnpackedLintGroups }[] = [];
	private lastBoxes: IgnorableLintBox[] = [];
	private lastLintBoxes: IgnorableLintBox[] = [];

	/** The function to be called to re-render the highlights. This is a variable because it is used to register/deregister event listeners. */
	private updateEventCallback: () => void;

	/** Function used to fetch lints for a given text/domain. */
	private lintProvider: (
		text: string,
		domain: string,
		options?: LintOptions,
	) => Promise<UnpackedLintGroups>;
	/** Actions wired by host environment (extension/app). */
	private actions: {
		ignoreLint?: (hash: string) => Promise<void>;
		getActivationKey?: () => Promise<ActivationKey>;
		getHotkey?: () => Promise<Hotkey>;
		openOptions?: () => Promise<void>;
		addToUserDictionary?: (words: string[]) => Promise<void>;
		reportError?: (lint: UnpackedLint, ruleId: string) => Promise<void>;
		setRuleEnabled?: (ruleId: string, enabled: boolean) => Promise<void> | void;
	};

	constructor(
		lintProvider: (
			text: string,
			domain: string,
			options?: LintOptions,
		) => Promise<UnpackedLintGroups>,
		actions: {
			ignoreLint?: (hash: string) => Promise<void>;
			getActivationKey?: () => Promise<ActivationKey>;
			getHotkey?: () => Promise<Hotkey>;
			openOptions?: () => Promise<void>;
			addToUserDictionary?: (words: string[]) => Promise<void>;
			reportError?: (lint: UnpackedLint, ruleId: string) => Promise<void>;
			setRuleEnabled?: (ruleId: string, enabled: boolean) => Promise<void> | void;
		},
	) {
		this.lintProvider = lintProvider;
		this.actions = actions;
		this.highlights = new Highlights();
		this.popupHandler = new PopupHandler({
			getActivationKey: actions.getActivationKey,
			openOptions: actions.openOptions,
			addToUserDictionary: actions.addToUserDictionary,
			reportError: actions.reportError,
			setRuleEnabled: actions.setRuleEnabled,
		});
		this.targets = new Set();
		this.scrollableAncestors = new Set();
		this.lastLints = [];

		this.updateEventCallback = () => {
			this.update();
		};

		const timeoutCallback = () => {
			this.update();

			setTimeout(timeoutCallback, 100);
		};

		timeoutCallback();

		this.attachWindowListeners();
	}

	/** Returns the currents targets that are visible on-screen. */
	onScreenTargets(): Node[] {
		const onScreen = [] as Node[];

		for (const target of this.targets) {
			if (isVisible(target)) {
				onScreen.push(target);
			}
		}

		return onScreen;
	}

	async update() {
		this.requestRender();
		this.requestLintUpdate();
	}

	async requestLintUpdate() {
		if (this.lintRequested) {
			return;
		}

		// Avoid duplicate requests in the queue
		this.lintRequested = true;

		const lintResults = await Promise.all(
			this.onScreenTargets().map(async (target) => {
				if (!document.contains(target)) {
					this.targets.delete(target);
					return { target: null as HTMLElement | null, lints: {} };
				}

				const text =
					target instanceof HTMLTextAreaElement || target instanceof HTMLInputElement
						? target.value
						: target.textContent;

				if (!text || text.length > 120000) {
					return { target: null as HTMLElement | null, lints: {} };
				}

				const lintsBySource = await this.lintProvider(text, window.location.hostname, {
					forceAllHeadings: isHeading(target),
				});
				return { target: target as HTMLElement, lints: lintsBySource };
			}),
		);

		this.lastLints = lintResults.filter((r) => r.target != null) as any;
		this.lintRequested = false;
		this.requestRender();
	}

	/**
	 * Hotkey to apply the suggestion of the most likely word
	 */
	public async lintHotkey() {
		const hotkey = await this.actions.getHotkey?.();

		document.addEventListener(
			'keydown',
			(event: KeyboardEvent) => {
				if (!hotkey) return;

				const key = event.key.toLowerCase();
				const expectedKey = hotkey.key.toLowerCase();

				const hasCtrl = event.ctrlKey === hotkey.modifiers.includes('Ctrl');
				const hasAlt = event.altKey === hotkey.modifiers.includes('Alt');
				const hasShift = event.shiftKey === hotkey.modifiers.includes('Shift');

				const match = key === expectedKey && hasCtrl && hasAlt && hasShift;

				if (match) {
					event.preventDefault();
					event.stopImmediatePropagation();

					const caretPosition = getCaretPosition();

					if (caretPosition != null) {
						const closestIdx = closestBox(caretPosition, this.lastBoxes);

						const previousBox = this.lastBoxes[closestIdx];
						const suggestions = previousBox.lint.suggestions;
						if (suggestions.length > 0) {
							previousBox.applySuggestion(suggestions[0]);
						} else {
							previousBox.ignoreLint?.();
						}
					}
				}
			},
			{ capture: true },
		);
	}

	public async addTarget(target: Node) {
		if (!this.targets.has(target)) {
			this.targets.add(target);
			this.update();
			this.attachTargetListeners(target);
		}
	}

	public async removeTarget(target: HTMLElement) {
		if (this.targets.has(target)) {
			this.targets.delete(target);
			this.update();
			this.detachTargetListeners(target);
		} else {
			throw new Error('HTMLElement not added.');
		}
	}

	/** Return the last known ignorable lint boxes rendered on-screen. */
	public getLastIgnorableLintBoxes(): IgnorableLintBox[] {
		return this.lastLintBoxes;
	}

	private attachTargetListeners(target: Node) {
		for (const event of INPUT_EVENTS) {
			target.addEventListener(event, this.updateEventCallback);
		}

		const observer = new MutationObserver(this.updateEventCallback);
		const config = { subtree: true, characterData: true };

		if ((target as any).tagName == undefined) {
			observer.observe((target as any).parentElement!, config);
		} else {
			observer.observe(target as Element, config);
		}

		const scrollableAncestors = getScrollableAncestors(target);

		for (const el of scrollableAncestors) {
			if (!this.scrollableAncestors.has(el as HTMLElement)) {
				this.scrollableAncestors.add(el as HTMLElement);
				(el as HTMLElement).addEventListener('scroll', this.updateEventCallback, {
					capture: true,
					passive: true,
				});
			}
		}
	}

	private detachTargetListeners(target: HTMLElement) {
		for (const event of INPUT_EVENTS) {
			target.removeEventListener(event, this.updateEventCallback);
		}
	}

	private attachWindowListeners() {
		this.lintHotkey();
		for (const event of PAGE_EVENTS) {
			window.addEventListener(event, this.updateEventCallback);
		}
	}

	private requestRender() {
		if (this.renderRequested) {
			return;
		}

		this.renderRequested = true;

		requestAnimationFrame(() => {
			const boxes = this.lastLints.flatMap(({ target, lints }) =>
				target
					? Object.entries(lints).flatMap(([ruleName, ls]) =>
							ls.flatMap((l) =>
								computeLintBoxes(target, l as any, ruleName, {
									ignoreLint: this.actions.ignoreLint,
								}),
							),
						)
					: [],
			);
			this.lastLintBoxes = boxes;
			this.highlights.renderLintBoxes(boxes);
			this.popupHandler.updateLintBoxes(boxes);

			this.renderRequested = false;
			this.lastBoxes = boxes;
		});
	}
}

/**
 * Returns all scrollable ancestor elements of a given element,
 * ordered from nearest to furthest (ending with the page scroller).
 */
function getScrollableAncestors(element: Node): Element[] {
	const scrollables: Element[] = [];
	const root = document.scrollingElement || document.documentElement;
	let parent = (element as any).parentElement;

	while (parent) {
		const style = window.getComputedStyle(parent);
		const { overflowY, overflowX } = style;
		const canScrollY = overflowY.includes('auto') || overflowY.includes('scroll');
		const canScrollX = overflowX.includes('auto') || overflowX.includes('scroll');

		if (canScrollY || canScrollX) {
			scrollables.push(parent);
		}
		parent = parent.parentElement;
	}

	// Always include the document scroller at the end
	if (root && scrollables[scrollables.length - 1] !== root) {
		scrollables.push(root);
	}

	return scrollables;
}



================================================
FILE: packages/lint-framework/src/lint/lintKindColor.ts
================================================
import { getContrastingTextColor } from './utils';

// First, define the color map as a constant
const LINT_KIND_COLORS = {
	Agreement: '#228B22', // Forest green
	BoundaryError: '#8B4513', // Saddle brown
	Capitalization: '#540D6E', // Deep purple
	Eggcorn: '#FF8C00', // Dark orange
	Enhancement: '#0EAD69', // Green
	Formatting: '#7D3C98', // Amethyst purple
	Grammar: '#9B59B6', // Medium purple
	Malapropism: '#C71585', // Medium violet red
	Miscellaneous: '#3BCEAC', // Turquoise
	Nonstandard: '#008B8B', // Dark cyan
	Punctuation: '#D4850F', // Dark orange
	Readability: '#2E8B57', // Sea green
	Redundancy: '#4682B4', // Steel blue
	Regionalism: '#C061CB', // Vibrant purple
	Repetition: '#00A67C', // Green-cyan
	Spelling: '#EE4266', // Pink-red
	Style: '#FFD23F', // Yellow
	Typo: '#FF6B35', // Vibrant orange-red
	Usage: '#1E90FF', // Dodger blue
	WordChoice: '#228B22', // Forest green
} as const;

// Export the type for the lint kind keys
export type LintKind = keyof typeof LINT_KIND_COLORS;

// Export the array of all lint kind names
export const LINT_KINDS = Object.keys(LINT_KIND_COLORS) as LintKind[];

// The main function that uses the map
export function lintKindColor(lintKindKey: string): string {
	const color = LINT_KIND_COLORS[lintKindKey as LintKind];
	if (!color) {
		throw new Error(`Unexpected lint kind: ${lintKindKey}`);
	}
	return color;
}

export function lintKindTextColor(lintKindKeyOrColor: string): 'black' | 'white' {
	const color = LINT_KIND_COLORS[lintKindKeyOrColor as LintKind] ?? lintKindKeyOrColor;
	return getContrastingTextColor(color);
}



================================================
FILE: packages/lint-framework/src/lint/PopupHandler.ts
================================================
import h from 'virtual-dom/h';
import { closestBox, type IgnorableLintBox, isPointInBox } from './Box';
import { getCaretPosition } from './editorUtils';
import type { UnpackedLint } from './unpackLint';

type ActivationKey = 'off' | 'shift' | 'control';

import hintsData from '../assets/hints.json';
import RenderBox from './RenderBox';
import SuggestionBox from './SuggestionBox';

type ActivationHandler = () => void;

function monitorActivationKey(
	onActivation: ActivationHandler,
	key: string,
	interval = 300,
): () => void {
	let lastTime = 0;
	const handler = (e: KeyboardEvent) => {
		if (e.key.toLowerCase() !== key.toLowerCase()) return;
		const now = performance.now();
		const diff = now - lastTime;
		if (diff <= interval && diff > 10) onActivation();
		lastTime = now;
	};
	window.addEventListener('keydown', handler);
	return () => window.removeEventListener('keydown', handler);
}

export default class PopupHandler {
	private currentLintBoxes: IgnorableLintBox[];
	private popupLint: number | undefined;
	private currentHint: string | null | undefined;
	private currentHintFor: number | undefined;
	private renderBox: RenderBox;
	private pointerDownCallback: (e: PointerEvent) => void;
	private activationKeyListener: (() => void) | undefined;
	private readonly actions: {
		getActivationKey?: () => Promise<ActivationKey>;
		openOptions?: () => Promise<void>;
		addToUserDictionary?: (words: string[]) => Promise<void>;
		reportError?: (lint: UnpackedLint, ruleId: string) => Promise<void>;
		setRuleEnabled?: (ruleId: string, enabled: boolean) => Promise<void> | void;
	};

	constructor(actions: {
		getActivationKey?: () => Promise<ActivationKey>;
		openOptions?: () => Promise<void>;
		addToUserDictionary?: (words: string[]) => Promise<void>;
		reportError?: (lint: UnpackedLint, ruleId: string) => Promise<void>;
		setRuleEnabled?: (ruleId: string, enabled: boolean) => Promise<void> | void;
	}) {
		this.actions = actions;
		this.currentLintBoxes = [];
		this.currentHint = undefined;
		this.currentHintFor = undefined;
		this.renderBox = new RenderBox(document.body);
		this.renderBox.getShadowHost().popover = 'manual';
		this.renderBox.getShadowHost().style.pointerEvents = 'none';
		this.renderBox.getShadowHost().style.border = 'none';
		this.pointerDownCallback = (e) => {
			this.onPointerDown(e);
		};

		this.updateActivationKeyListener();
	}

	private updateActivationKeyListener() {
		if (this.activationKeyListener) {
			this.activationKeyListener();
			this.activationKeyListener = undefined;
		}

		const getKey = this.actions.getActivationKey;
		if (getKey) {
			getKey().then((key) => {
				if (key !== 'off') {
					this.activationKeyListener = monitorActivationKey(() => this.openClosestToCaret(), key);
				}
			});
		}
	}

	/** Tries to get the current caret position.
	 * If successful, opens the popup closes to it. */
	private openClosestToCaret() {
		const caretPosition = getCaretPosition();

		if (caretPosition != null) {
			const closestIdx = closestBox(caretPosition, this.currentLintBoxes);

			if (closestIdx >= 0) {
				this.popupLint = closestIdx;
			}
		}
	}

	private onPointerDown(e: PointerEvent) {
		for (let i = 0; i < this.currentLintBoxes.length; i++) {
			const box = this.currentLintBoxes[i];

			if (isPointInBox([e.x, e.y], box)) {
				this.popupLint = i;
				this.render();
				return;
			}
		}

		this.popupLint = undefined;
		this.render();
	}

	private render() {
		let tree = h('div', {}, []);

		this.updateHint();

		if (this.popupLint != null && this.popupLint < this.currentLintBoxes.length) {
			const box = this.currentLintBoxes[this.popupLint];

			tree = SuggestionBox(box, this.actions, this.currentHint ?? null, () => {
				this.popupLint = undefined;
				this.updateHint();
			});
			this.renderBox.getShadowHost().style.setProperty('visibility', 'visible', 'important');
			this.renderBox.getShadowHost().showPopover();
		} else {
			this.renderBox.getShadowHost().hidePopover();
		}

		this.renderBox.render(tree);
	}

	/** Synchronize the hint with the currently focused lint.
	 * - If no lint is open, clear the hint state.
	 * - If a different lint opens, or the hint is uninitialized, decide once (~10%).
	 */
	private updateHint() {
		if (this.popupLint == null) {
			this.currentHint = undefined;
			this.currentHintFor = undefined;
			return;
		}

		if (this.currentHintFor !== this.popupLint || this.currentHint === undefined) {
			const hints: string[] = Array.isArray(hintsData)
				? ((hintsData as unknown[]).filter((v) => typeof v === 'string') as string[])
				: [];
			const show = Math.random() < 0.1 && hints.length > 0;
			this.currentHint = show ? hints[Math.floor(Math.random() * hints.length)] : null;
			this.currentHintFor = this.popupLint;
		}
	}

	public updateLintBoxes(boxes: IgnorableLintBox[]) {
		this.currentLintBoxes.forEach((b) => {
			b.source.removeEventListener('pointerdown', this.pointerDownCallback as EventListener);
		});

		if (boxes.length != this.currentLintBoxes.length) {
			this.popupLint = undefined;
		}

		this.currentLintBoxes = boxes;
		this.currentLintBoxes.forEach((b) => {
			b.source.addEventListener('pointerdown', this.pointerDownCallback as EventListener);
		});

		this.render();
	}
}



================================================
FILE: packages/lint-framework/src/lint/RenderBox.ts
================================================
import type { VNode } from 'virtual-dom';
import createElement from 'virtual-dom/create-element';
import diff from 'virtual-dom/diff';
import patch from 'virtual-dom/patch';

/** Wraps `virtual-dom` to create a box that is unaffected by the style of the rest of the page. */
export default class RenderBox {
	/** The element our virtual DOM is attached to. */
	private virtualRoot: Element | undefined;
	/** The current state of the virtual DOM */
	private virtualTree: VNode | undefined;
	/** The shadow DOM the `virtualRoot` is attached to. */
	private shadowHost: HTMLElement;

	constructor(parent: Node) {
		this.shadowHost = document.createElement('harper-render-box');
		parent.appendChild(this.shadowHost);
	}

	/** Render to the box. */
	public render(node: VNode) {
		if (!this.virtualRoot || !this.virtualTree) {
			this.virtualRoot = createElement(node);
			const shadow = this.shadowHost.attachShadow({ mode: 'open' });
			shadow.appendChild(this.virtualRoot);
		} else {
			const patches = diff(this.virtualTree, node);
			this.virtualRoot = patch(this.virtualRoot, patches);
		}
		this.virtualTree = node;
	}

	/** Remove the box from the DOM. */
	public remove() {
		try {
			this.shadowHost.outerHTML = this.shadowHost.outerHTML;
		} catch (e) {
			console.error(e);
		}
		this.virtualRoot = undefined;
		this.virtualTree = undefined;
	}

	public getShadowHost(): HTMLElement {
		return this.shadowHost;
	}
}



================================================
FILE: packages/lint-framework/src/lint/SourceElement.ts
================================================
/** An element that could be considered a _source_ for text to be linted.*/
type SourceElement = HTMLElement | Text;

export default SourceElement;



================================================
FILE: packages/lint-framework/src/lint/SuggestionBox.ts
================================================
/** biome-ignore-all lint/complexity/useArrowFunction: It cannot be an arrow function for the logic to work. */
import { type IconDefinition, icon } from '@fortawesome/fontawesome-svg-core';
import { faBan, faGear } from '@fortawesome/free-solid-svg-icons';
import type { VNode } from 'virtual-dom';
import h from 'virtual-dom/h';
import bookDownSvg from '../assets/bookDownSvg';
import type { IgnorableLintBox, LintBox } from './Box';
import { type LintKind, lintKindColor, lintKindTextColor } from './lintKindColor';
// Decoupled: actions passed in by framework consumer
import type { UnpackedLint, UnpackedSuggestion } from './unpackLint';

function iconSvg(definition: IconDefinition): string {
	return icon(definition).html.join('');
}

const settingsIconSvg = iconSvg(faGear);
const disableIconSvg = iconSvg(faBan);

let previouslyActiveElement: null | HTMLElement = null;

var FocusHook: any = function () {};
FocusHook.prototype.hook = function (node: any, _propertyName: any, _previousValue: any) {
	if ((node as any).__harperAutofocused) {
		return;
	}

	requestAnimationFrame(() => {
		if (document.activeElement?.tagName.toLowerCase() != 'harper-render-box') {
			previouslyActiveElement = document.activeElement as HTMLElement;
		}

		node.focus();
		Object.defineProperty(node, '__harperAutofocused', {
			value: true,
			enumerable: false,
			configurable: false,
		});
	});
};

var CloseOnEscapeHook: any = function (this: any, onClose: () => void) {
	this.onClose = onClose;
};

CloseOnEscapeHook.prototype.hook = function (this: { onClose: () => void }, node: HTMLElement) {
	const handler = (e: KeyboardEvent) => {
		if (e.key === 'Escape') {
			this.onClose();
		}
	};
	window.addEventListener('keydown', handler);
	(node as any).__harperCloseOnEscapeHandler = handler;
};

CloseOnEscapeHook.prototype.unhook = function (this: any, node: HTMLElement) {
	const handler = (node as any).__harperCloseOnEscapeHandler;
	if (handler) {
		window.removeEventListener('keydown', handler);
		delete (node as any).__harperCloseOnEscapeHandler;
	}
};

function header(
	title: string,
	color: string,
	onClose: () => void,
	openOptions?: () => Promise<void>,
	rule?: string,
	setRuleEnabled?: (ruleId: string, enabled: boolean) => Promise<void> | void,
): any {
	const closeButton = h(
		'button',
		{
			className: 'harper-close-btn',
			onclick: onClose,
			title: 'Close',
			'aria-label': 'Close',
		},
		'×',
	);

	const settingsButton = openOptions
		? h(
				'button',
				{
					className: 'harper-gear-btn',
					onclick: () => {
						openOptions();
					},
					title: 'Settings',
					'aria-label': 'Settings',
					innerHTML: settingsIconSvg,
				},
				[],
			)
		: undefined;

	const disableRuleButton =
		setRuleEnabled && rule
			? h(
					'button',
					{
						className: 'harper-disable-btn',
						onclick: () => {
							Promise.resolve(setRuleEnabled(rule, false)).finally(() => {
								onClose();
							});
						},
						title: `Disable the ${rule} rule`,
						'aria-label': 'Disable this lint rule',
						innerHTML: disableIconSvg,
					},
					[],
				)
			: undefined;

	const controlsChildren = [disableRuleButton, settingsButton, closeButton].filter(
		(node): node is VNode => node != null,
	);
	const controls = h('div', { className: 'harper-controls' }, controlsChildren);
	const titleEl = h('span', { className: 'harper-title' }, [title]);

	return h(
		'div',
		{
			className: 'harper-header',
			style: { borderBottom: `2px solid ${color}` },
		},
		[titleEl, controls],
	);
}

function body(message_html: string): any {
	return h('div', { className: 'harper-body', innerHTML: message_html }, []);
}

function button(
	label: string,
	extraStyle: { [key: string]: string },
	onClick: (event: Event) => void,
	description?: string,
	extraProps: Record<string, unknown> = {},
): any {
	const desc = description || label;
	return h(
		'button',
		{
			className: 'harper-btn',
			style: extraStyle,
			onclick: onClick,
			title: desc,
			type: 'button',
			'aria-label': desc,
			...extraProps,
		},
		label,
	);
}

function footer(leftChildren: any, rightChildren: any) {
	const left = h('div', { className: 'harper-child-cont' }, leftChildren);
	const right = h('div', { className: 'harper-child-cont' }, rightChildren);
	return h('div', { className: 'harper-footer' }, [left, right]);
}

function hintDrawer(hint: string | null): any {
	if (!hint) return undefined;
	return h('div', { className: 'harper-hint-drawer', role: 'note', 'aria-live': 'polite' }, [
		h('div', { className: 'harper-hint-content' }, [
			h('div', { className: 'harper-hint-icon', 'aria-hidden': 'true' }, '💡'),
			h('div', {}, [
				h('div', { className: 'harper-hint-title' }, 'Tip'),
				h('div', {}, String(hint)),
			]),
		]),
	]);
}

function addToDictionary(
	box: LintBox,
	addToUserDictionary?: (words: string[]) => Promise<void>,
): any {
	return h(
		'button',
		{
			className: 'harper-btn',
			onclick: () => {
				addToUserDictionary?.([box.lint.problem_text]);
			},
			title: 'Add word to user dictionary',
			'aria-label': 'Add word to user dictionary',
			innerHTML: bookDownSvg,
		},
		[],
	);
}

function suggestions(
	lintKind: LintKind,
	suggestions: UnpackedSuggestion[],
	apply: (s: UnpackedSuggestion) => void,
): any {
	return suggestions.map((s: UnpackedSuggestion, i: number) => {
		const label = s.replacement_text !== '' ? s.replacement_text : String(s.kind);
		const desc = `Replace with "${label}"`;
		const props = i === 0 ? { hook: new FocusHook() } : {};
		return button(
			label,
			{ background: lintKindColor(lintKind), color: lintKindTextColor(lintKind) },
			() => apply(s),
			desc,
			props,
		);
	});
}

function reportProblemButton(reportError?: () => Promise<void>): any {
	if (!reportError) {
		return undefined;
	}

	return h(
		'button',
		{
			className: 'harper-report-link',
			type: 'button',
			onclick: () => {
				reportError();
			},
			title: 'Report an issue with this lint',
			'aria-label': 'Report an issue with this lint',
		},
		'Report',
	);
}

function styleTag(lintKind: LintKind) {
	return h('style', { id: 'harper-suggestion-style' }, [
		`code{
      text-decoration: underline solid ${lintKindColor(lintKind)} 2px;
      padding:0.125rem;
      border-radius:0.25rem
      }
      .harper-container{
      max-width:420px;
      max-height:400px;
      overflow-y:auto;
      background:#ffffff;
      border:1px solid #d0d7de;
      border-radius:8px;
      box-shadow:0 4px 12px rgba(140,149,159,0.3);
      padding:8px;
      display:flex;
      flex-direction:column;
      z-index:5000;
      font-family:-apple-system,BlinkMacSystemFont,"Segoe UI",Helvetica,Arial,sans-serif;
      pointer-events:auto
      }
      .harper-header{
      display:flex;
      align-items:center;
      justify-content:space-between;
      font-weight:600;
      font-size:14px;
      line-height:20px;
      color:#1f2328;
      padding-bottom:4px;
      margin-bottom:4px;
      user-select:none
      }
      .harper-title{
      display:flex;
      align-items:center;
      gap:6px;
      }
      .harper-body{
      font-size:14px;
      line-height:20px;
      color:#57606a
      }
      .harper-btn{
      display:inline-flex;
      align-items:center;
      justify-content:center;
      gap:4px;
      cursor:pointer;
      border:none;
      border-radius:6px;
      padding:3px 6px;
      min-height:28px;
      font-size:13px;
      font-weight:600;
      line-height:20px;
      transition:background 120ms ease,transform 80ms ease
      }
      .harper-btn:hover{filter:brightness(0.92)}
      .harper-btn:active{transform:scale(0.97)}
      .harper-close-btn{background:transparent;border:none;cursor:pointer;font-size:20px;line-height:1;color:#57606a;padding:0 4px;}
      .harper-close-btn:hover{color:#1f2328;}
      .harper-disable-btn,
      .harper-gear-btn{
      background:transparent;
      border:none;
      cursor:pointer;
      font-size:18px;
      line-height:1;
      color:#57606a;
      padding:0 4px;
      display:inline-flex;
      align-items:center;
      justify-content:center;
      }
      .harper-disable-btn:hover,
      .harper-gear-btn:hover{color:#1f2328;}
      .harper-disable-btn svg,
      .harper-gear-btn svg{
      width:18px;
      height:18px;
      display:block;
      }
      .harper-controls{display:flex;align-items:center;gap:3px;}
      .harper-child-cont{
      display:flex;
      flex-wrap:wrap;
      justify-content:flex-end;
      gap:8px
      }
      .harper-footer{
      display:flex;
      flex-wrap:wrap;
      justify-content:space-between;
      padding:2px;
      gap:16px
      }

      /* Hint drawer styles */
      .harper-hint-drawer{
        margin-top:6px;
        border-top:1px solid #eaeef2;
        background:#f6f8fa;
        color:#3e4c59;
        border-radius:0 0 6px 6px;
      }
      .harper-hint-content{
        display:flex;
        gap:8px;
        align-items:flex-start;
        padding:8px 10px;
        font-size:13px;
        line-height:18px;
      }
      .harper-hint-icon{
        flex:0 0 auto;
        width:18px;height:18px;
        border-radius:50%;
        background:#fff3c4;
        color:#7c5e10;
        display:flex;align-items:center;justify-content:center;
        font-weight:700;
      }
      .harper-hint-title{ font-weight:600; margin-right:6px; color:#1f2328; }

    .fade-in {
      animation: fadeIn 100ms ease-in-out forwards;
    }

      @keyframes fadeIn {
        from {
          opacity: 0;
          transform: scale(0.95);
        }
        to {
          opacity: 1;
          transform: scale(1);
        }
      }

      @media (prefers-color-scheme:dark){
      code{background-color:#1f2d3d;color:#c9d1d9}
      .harper-container{
      background:#0d1117;
      border-color:#30363d;
      box-shadow:0 4px 12px rgba(1,4,9,0.85)
      }
      .harper-header{color:#e6edf3}
      .harper-body{color:#8b949e}
      .harper-btn{
      background:#21262d;
      color:#c9d1d9
      }
      .harper-btn:hover{filter:brightness(1.15)}
      .harper-close-btn{color:#8b949e;}
      .harper-close-btn:hover{color:#e6edf3;}
      .harper-disable-btn,
      .harper-gear-btn{color:#8b949e;}
      .harper-disable-btn:hover,
      .harper-gear-btn:hover{color:#e6edf3;}
      .harper-btn[style*="background: #2DA44E"]{background:#238636}
      .harper-btn[style*="background: #e5e5e5"]{
      background:#4b4b4b;
      color:#ffffff
      }
      .harper-hint-drawer{ border-top-color:#30363d; background:#151b23; color:#9aa4af; }
      .harper-hint-icon{ background:#3a2f0b; color:#f2cc60; }
      .harper-hint-title{ color:#e6edf3; }
      }
      .harper-report-link{
      margin-top:8px;
      align-self:flex-start;
      background:none;
      border:none;
      padding:0;
      color:#0969da;
      font-size:13px;
      font-weight:600;
      cursor:pointer;
      }
      .harper-report-link:hover{text-decoration:underline;}
      .harper-report-link:focus{outline:2px solid #0969da; outline-offset:2px;}
      @media (prefers-color-scheme:dark){
      .harper-report-link{color:#58a6ff;}
      }`,
	]);
}

function ignoreLint(onIgnore: () => void | Promise<void>): any {
	return button(
		'Dismiss',
		{ background: '#e5e5e5', color: '#000000', fontWeight: 'lighter' },
		onIgnore,
		'Ignore this lint',
	);
}

export default function SuggestionBox(
	box: IgnorableLintBox,
	actions: {
		openOptions?: () => Promise<void>;
		addToUserDictionary?: (words: string[]) => Promise<void>;
		reportError?: (lint: UnpackedLint, ruleId: string) => Promise<void>;
		setRuleEnabled?: (ruleId: string, enabled: boolean) => Promise<void> | void;
	},
	hint: string | null,
	close: () => void,
) {
	const top = box.y + box.height + 3;
	let bottom: number | undefined;
	const left = box.x;

	if (top + 400 > window.innerHeight) {
		bottom = window.innerHeight - box.y - 3;
	}

	const positionStyle: { [key: string]: string } = {
		position: 'fixed',
		top: bottom ? '' : `${top}px`,
		bottom: bottom ? `${bottom}px` : '',
		left: `${left}px`,
		transformOrigin: `${bottom ? 'bottom' : 'top'} left`,
	};

	const ignoreLintCallback = box.ignoreLint;

	const refocusClose = () => {
		previouslyActiveElement?.focus();
		close();
	};

	return h(
		'div',
		{
			className: 'harper-container fade-in',
			style: positionStyle,
			'harper-close-on-escape': new CloseOnEscapeHook(refocusClose),
		},
		[
			styleTag(box.lint.lint_kind),
			header(
				box.lint.lint_kind_pretty,
				lintKindColor(box.lint.lint_kind),
				refocusClose,
				actions.openOptions,
				box.rule,
				actions.setRuleEnabled,
			),
			body(box.lint.message_html),
			footer(
				suggestions(box.lint.lint_kind, box.lint.suggestions, (v) => {
					box.applySuggestion(v);
					refocusClose();
				}),
				[
					box.lint.lint_kind === 'Spelling' && actions.addToUserDictionary
						? addToDictionary(box, actions.addToUserDictionary)
						: undefined,
					ignoreLintCallback
						? ignoreLint(() => ignoreLintCallback().then(refocusClose))
						: undefined,
				],
			),
			hintDrawer(hint),
			actions.reportError
				? reportProblemButton(() => actions.reportError!(box.lint, box.rule))
				: undefined,
		],
	);
}



================================================
FILE: packages/lint-framework/src/lint/TextFieldRange.ts
================================================
import type { ConditionalKeys, WritableKeysOf } from 'type-fest';
import { boxesOverlap, domRectToBox } from './Box';

/** A version of the `Range` object that works for `<textarea />` and `<input />` elements. */
export default class TextFieldRange {
	field: HTMLTextAreaElement | HTMLInputElement;
	startOffset: number;
	endOffset: number;

	// Shared arena per field to avoid repeated layout work
	private static arenas: WeakMap<
		HTMLTextAreaElement | HTMLInputElement,
		{
			mirror: HTMLDivElement;
			text: Text;
			refs: number;
		}
	> = new WeakMap();

	private arena: { mirror: HTMLDivElement; text: Text; refs: number };

	/**
	 * Create a range-like object for a given text input field.
	 * @param field - A HTMLTextAreaElement or a HTMLInputElement (of type "text").
	 * @param startOffset - The starting character index.
	 * @param endOffset - The ending character index.
	 */
	constructor(
		field: HTMLTextAreaElement | HTMLInputElement,
		startOffset: number,
		endOffset: number,
	) {
		// In this case we assume the caller provided a text field
		if (!(field instanceof HTMLTextAreaElement || field instanceof HTMLInputElement)) {
			throw new Error('TextFieldRange expects an HTMLTextAreaElement or HTMLInputElement');
		}
		this.field = field;
		this.startOffset = startOffset;
		this.endOffset = endOffset;
		this.arena = TextFieldRange.ensureArena(this.field);
		this.arena.refs++;
	}

	/**
	 * Creates (or reuses) an off-screen mirror element that mimics the field's styles
	 * and positions it exactly over the field.
	 */
	private static ensureArena(field: HTMLTextAreaElement | HTMLInputElement): {
		mirror: HTMLDivElement;
		text: Text;
		refs: number;
	} {
		const existing = TextFieldRange.arenas.get(field);
		if (existing) return existing;

		const mirror = document.createElement('div');
		mirror.className = 'harper-textfield-mirror';

		// Copy necessary computed styles from the field (affecting text layout)
		const computed: CSSStyleDeclaration = window.getComputedStyle(field);
		const propertiesToCopy: Array<
			ConditionalKeys<Pick<CSSStyleDeclaration, WritableKeysOf<CSSStyleDeclaration>>, string>
		> = [
			'fontFamily',
			'fontSize',
			'fontWeight',
			'fontStyle',
			'letterSpacing',
			'lineHeight',
			'textTransform',
			'paddingTop',
			'paddingRight',
			'paddingBottom',
			'paddingLeft',
			'borderTopWidth',
			'borderRightWidth',
			'borderBottomWidth',
			'borderLeftWidth',
			'boxSizing',
			'overflowX',
			'overflowY',
		];

		propertiesToCopy.forEach((prop) => {
			(mirror.style as any)[prop] = (computed as any)[prop];
		});

		if (field instanceof HTMLTextAreaElement) {
			mirror.style.overflowX = 'auto';
			mirror.style.overflowY = 'auto';
		}

		// Position the mirror exactly over the field.
		TextFieldRange.positionMirror(mirror, field);

		Object.assign(mirror.style, {
			boxSizing: 'border-box',
			whiteSpace: field.tagName.toLowerCase() === 'textarea' ? 'pre-wrap' : 'pre',
			wordWrap: 'break-word',
			visibility: 'hidden',
			position: 'absolute',
			pointerEvents: 'none',
		});

		const text = document.createTextNode('');
		mirror.appendChild(text);

		// Initialize text + scroll
		text.nodeValue = field.value;
		document.body.appendChild(mirror);
		mirror.scrollTop = field.scrollTop;
		mirror.scrollLeft = field.scrollLeft;

		const arena = { mirror, text, refs: 0 } as const;
		TextFieldRange.arenas.set(field, arena);
		return arena;
	}

	private static positionMirror(
		mirror: HTMLDivElement,
		field: HTMLTextAreaElement | HTMLInputElement,
	) {
		const fieldRect = field.getBoundingClientRect();
		const scrollTop = window.scrollY || document.documentElement.scrollTop;
		const scrollLeft = window.scrollX || document.documentElement.scrollLeft;
		Object.assign(mirror.style, {
			top: `${fieldRect.top + scrollTop}px`,
			left: `${fieldRect.left + scrollLeft}px`,
			width: `${fieldRect.width}px`,
			height: `${fieldRect.height}px`,
		});
	}

	/**
	 * Updates the mirror's text node with the current value of the field.
	 */
	private syncMirror(): void {
		// Ensure text, scroll, and position reflect the current field
		this.arena.text.nodeValue = this.field.value;
		this.arena.mirror.scrollTop = this.field.scrollTop;
		this.arena.mirror.scrollLeft = this.field.scrollLeft;
		TextFieldRange.positionMirror(this.arena.mirror, this.field);
	}

	/**
	 * Returns an array of DOMRect objects corresponding to the range's visual segments.
	 * This mimics the native Range.getClientRects() method.
	 * @returns {DOMRect[]} An array of DOMRect objects.
	 */
	getClientRects(): DOMRect[] {
		this.syncMirror();

		const range = document.createRange();
		range.setStart(this.arena.text, this.startOffset);
		range.setEnd(this.arena.text, this.endOffset);

		let arr = Array.from(range.getClientRects());

		const fieldBox = domRectToBox(this.field.getBoundingClientRect());

		// Filter out rectangles that should be hidden
		arr = arr.filter((rect) => {
			const box = domRectToBox(rect);
			return boxesOverlap(box, fieldBox);
		});

		return arr;
	}

	getBoundingClientRect(): DOMRect | null {
		this.syncMirror();
		return this.arena.mirror.getBoundingClientRect();
	}

	/**
	 * Detaches (removes) the mirror element from the document.
	 */
	detach(): void {
		// Release this handle; keep the shared mirror for reuse unless the field is gone.
		this.arena.refs = Math.max(0, this.arena.refs - 1);
		// If the field is no longer in the document, clean up the arena.
		if (!document.contains(this.field)) {
			try {
				this.arena.mirror.parentNode?.removeChild(this.arena.mirror);
			} catch {}
			TextFieldRange.arenas.delete(this.field);
		}
	}
}



================================================
FILE: packages/lint-framework/src/lint/unpackLint.ts
================================================
import { type Lint, type Linter, SuggestionKind } from 'harper.js';
import type { LintKind } from './lintKindColor';

export type UnpackedSpan = {
	start: number;
	end: number;
};

export type UnpackedLint = {
	span: UnpackedSpan;
	message_html: string;
	problem_text: string;
	lint_kind: LintKind;
	lint_kind_pretty: string;
	suggestions: UnpackedSuggestion[];
	context_hash: string;
	source: string;
};

export type UnpackedLintGroups = Record<string, UnpackedLint[]>;

export type UnpackedSuggestion = {
	kind: SuggestionKind;
	/// An empty string if replacement text is not applicable.
	replacement_text: string;
};

export default async function unpackLint(
	text: string,
	lint: Lint,
	linter: Linter,
): Promise<UnpackedLint> {
	const span = lint.span();

	return {
		span: { start: span.start, end: span.end },
		message_html: lint.message_html(),
		problem_text: lint.get_problem_text(),
		lint_kind: lint.lint_kind() as LintKind,
		lint_kind_pretty: lint.lint_kind_pretty(),
		suggestions: lint.suggestions().map((sug) => {
			return { kind: sug.kind(), replacement_text: sug.get_replacement_text() };
		}),
		context_hash: (await linter.contextHash(text, lint)).toString(),
		source: text,
	};
}

export function applySuggestion(text: string, span: UnpackedSpan, sug: UnpackedSuggestion): string {
	switch (sug.kind) {
		case SuggestionKind.Remove:
			return text.slice(0, span.start) + text.slice(span.end);
		case SuggestionKind.Replace:
			return text.slice(0, span.start) + sug.replacement_text + text.slice(span.end);
		case SuggestionKind.InsertAfter:
			return text.slice(0, span.end) + sug.replacement_text + text.slice(span.end);
	}
}



================================================
FILE: packages/lint-framework/src/lint/utils.ts
================================================
import Color from 'colorjs.io';

/** Get the text color that best contrasts with a background of the provided color. */
export function getContrastingTextColor(color: string): 'black' | 'white' {
	const c = new Color(color);
	const luminance = c.luminance;

	if (luminance > 0.5) {
		return 'black';
	} else {
		return 'white';
	}
}



================================================
FILE: packages/obsidian-plugin/README.md
================================================
# Obsidian Plugin

This directory contains the source code for the [Obsidian](https://obsidian.md/) plugin.

The full documentation can be found [here](https://github.com/automattic/harper-obsidian-plugin).

## Building

In order to build the plugin, you may use `just` like so:

```bash
just build-obsidian
```



================================================
FILE: packages/obsidian-plugin/package.json
================================================
{
	"name": "obsidian-plugin",
	"private": true,
	"version": "1.5.1",
	"main": "main.js",
	"devDependencies": {
		"@playwright/test": "^1.58.0",
		"@rollup/plugin-node-resolve": "^16.0.0",
		"@types/lodash-es": "^4.17.12",
		"@vitest/browser": "^4.0.16",
		"@vitest/browser-playwright": "^4.0.16",
		"obsidian": "^1.7.2",
		"rollup-plugin-peer-deps-external": "^2.2.4",
		"rollup-plugin-svg-import": "^3.0.0",
		"vite": "^6.3.5",
		"vitest": "^4.0.16"
	},
	"scripts": {
		"build": "vite build -l warn",
		"dev": "vite build --watch",
		"test": "vitest run"
	},
	"peerDependencies": {
		"@codemirror/autocomplete": "^6.16.3",
		"@codemirror/collab": "^6.1.1",
		"@codemirror/commands": "^6.6.0",
		"@codemirror/language": "^6.10.2",
		"@codemirror/lint": "^6.8.1",
		"@codemirror/search": "^6.5.6",
		"@codemirror/state": "^6.4.1",
		"@codemirror/view": "^6.28.3",
		"@lezer/common": "^1.2.1",
		"@lezer/highlight": "^1.2.0",
		"@lezer/lr": "^1.4.1"
	},
	"dependencies": {
		"crelt": "^1.0.5",
		"harper.js": "workspace:*",
		"lodash-es": "^4.17.21",
		"minimatch": "^10.0.3",
		"tslib": "catalog:"
	}
}



================================================
FILE: packages/obsidian-plugin/vite.config.ts
================================================
import { playwright } from '@vitest/browser-playwright';
import external from 'rollup-plugin-peer-deps-external';
import svg from 'rollup-plugin-svg-import';
import { defineConfig } from 'vite';

export default defineConfig({
	plugins: [svg({ stringify: true }), external()],
	build: {
		outDir: '.',
		target: 'es6',
		lib: {
			entry: 'src/index.ts',
			formats: ['cjs'],
			fileName: 'main',
		},
		rollupOptions: {
			external: ['obsidian', 'electron'],
			output: {
				inlineDynamicImports: true,
			},
		},
	},
	test: {
		retry: process.env.CI ? 5 : 0,
		browser: {
			provider: playwright(),
			enabled: true,
			headless: true,
			screenshotFailures: false,
			instances: [{ browser: 'chromium' }],
		},
	},
});



================================================
FILE: packages/obsidian-plugin/src/HarperSettingTab.ts
================================================
import './index.js';
import { Dialect } from 'harper.js';
import { startCase } from 'lodash-es';
import type { ButtonComponent } from 'obsidian';
import { type App, Notice, PluginSettingTab, Setting } from 'obsidian';
import type HarperPlugin from './index.js';
import type State from './State.js';
import type { Settings } from './State.js';
import { linesToString, stringToLines } from './textUtils';

const LintSettingId = 'HarperLintSettings';

export class HarperSettingTab extends PluginSettingTab {
	private settings: Settings;
	private descriptionsHTML: Record<string, string>;
	private defaultLintConfig: Record<string, boolean>;
	private currentRuleSearchQuery = '';
	private plugin: HarperPlugin;
	private toggleAllButton?: ButtonComponent;

	private get state() {
		return this.plugin.state;
	}

	constructor(app: App, plugin: HarperPlugin) {
		super(app, plugin);
		this.plugin = plugin;
	}

	update() {
		this.updateDescriptions();
		this.updateSettings();
		this.updateDefaults();
	}

	updateSettings() {
		this.state.getSettings().then((v) => {
			this.settings = v;
			this.updateToggleAllRulesButton();
		});
	}

	updateDescriptions() {
		this.state.getDescriptionHTML().then((v) => {
			this.descriptionsHTML = v;
		});
	}

	updateDefaults() {
		this.state.getDefaultLintConfig().then((v) => {
			this.defaultLintConfig = v as unknown as Record<string, boolean>;
			this.updateToggleAllRulesButton();
		});
	}

	display(update = true) {
		if (update) {
			this.update();
			this.display(false);
		}

		const { containerEl } = this;
		containerEl.empty();

		new Setting(containerEl)
			.setName('Use Web Worker')
			.setDesc(
				'Whether to run the Harper engine in a separate thread. Improves stability and speed at the cost of memory.',
			)
			.addToggle((toggle) =>
				toggle.setValue(this.settings.useWebWorker).onChange(async (value) => {
					this.settings.useWebWorker = value;
					await this.state.initializeFromSettings(this.settings);
				}),
			);

		new Setting(containerEl).setName('English Dialect').addDropdown((dropdown) => {
			dropdown
				.addOption(Dialect.American.toString(), 'American')
				.addOption(Dialect.Canadian.toString(), 'Canadian')
				.addOption(Dialect.British.toString(), 'British')
				.addOption(Dialect.Australian.toString(), 'Australian')
				.addOption(Dialect.Indian.toString(), 'Indian')
				.setValue((this.settings.dialect ?? Dialect.American).toString())
				.onChange(async (value) => {
					const dialect = Number.parseInt(value, 10);
					this.settings.dialect = dialect;
					await this.state.initializeFromSettings(this.settings);
					this.plugin.updateStatusBar(dialect);
				});
		});

		new Setting(containerEl)
			.setName('Activate Harper')
			.setDesc('Enable or disable Harper with this option.')
			.addToggle((toggle) =>
				toggle.setValue(this.settings.lintEnabled).onChange(async (_value) => {
					this.state.toggleAutoLint();
					this.plugin.updateStatusBar();
				}),
			);

		new Setting(containerEl)
			.setName('Personal Dictionary')
			.setDesc(
				'Make edits to your personal dictionary. Add names, places, or terms you use often. Each line should contain its own word.',
			)
			.addTextArea((ta) => {
				ta.inputEl.cols = 20;
				ta.setValue(linesToString(this.settings.userDictionary ?? [''])).onChange(async (v) => {
					const dict = stringToLines(v);
					this.settings.userDictionary = dict;
					await this.state.initializeFromSettings(this.settings);
				});
			});

		new Setting(containerEl)
			.setName('Ignored Files')
			.setDesc(
				'Instruct Harper to ignore certain files in your vault. Accepts glob matches (`folder/**`, etc.)',
			)
			.addTextArea((ta) => {
				ta.inputEl.cols = 20;
				ta.setValue(linesToString(this.settings.ignoredGlobs ?? [''])).onChange(async (v) => {
					const lines = stringToLines(v);
					this.settings.ignoredGlobs = lines;
					await this.state.initializeFromSettings(this.settings);
				});
			});

		new Setting(containerEl)
			.setName('Delay')
			.setDesc(
				'Set the delay (in milliseconds) before Harper checks your work after you make a change. Set to -1 for no delay.',
			)
			.addSlider((slider) => {
				slider
					.setDynamicTooltip()
					.setLimits(-1, 10000, 50)
					.setValue(this.settings.delay ?? -1)
					.onChange(async (value) => {
						this.settings.delay = value;
						await this.state.initializeFromSettings(this.settings);
					});
			});

		new Setting(containerEl).setName('The Danger Zone').addButton((button) => {
			button
				.setButtonText('Forget Ignored Suggestions')
				.onClick(() => {
					this.settings.ignoredLints = undefined;
					this.state.initializeFromSettings(this.settings);
				})
				.setWarning();
		});

		new Setting(containerEl)
			.setName('Rules')
			.setDesc('Search for a specific Harper rule.')
			.addSearch((search) => {
				search.setPlaceholder('Search for a rule...').onChange((query) => {
					this.currentRuleSearchQuery = query;
					this.renderLintSettingsToId(query, LintSettingId);
				});
			});

		// Global reset for rule overrides
		new Setting(containerEl)
			.setName('Reset Rules to Defaults')
			.setDesc(
				'Restore all rule overrides back to their default values. This does not affect other settings.',
			)
			.addButton((button) => {
				button
					.setButtonText('Reset All to Defaults')
					.onClick(async () => {
						const confirmed = confirm(
							'Reset all rule overrides to their defaults? This cannot be undone.',
						);
						if (!confirmed) return;
						await this.state.resetAllRulesToDefaults();
						this.settings = await this.state.getSettings();
						this.renderLintSettingsToId(this.currentRuleSearchQuery, LintSettingId);
						this.updateToggleAllRulesButton();
						new Notice('Harper rules reset to defaults');
					})
					.setWarning();
			});

		// Single bulk toggle button: If any rules are enabled, turn all off; otherwise turn all on.
		new Setting(containerEl)
			.setName('Toggle All Rules')
			.setDesc(
				'Enable or disable all rules in bulk. Overrides individual rule settings until changed again.',
			)
			.addButton((button) => {
				this.toggleAllButton = button;
				this.updateToggleAllRulesButton();
				button.setWarning().onClick(async () => {
					const anyEnabledNow = await this.state.areAnyRulesEnabled();
					const action = anyEnabledNow ? 'Disable' : 'Enable';
					const confirmed = confirm(`${action} all rules? This will override individual settings.`);
					if (!confirmed) return;

					await this.state.setAllRulesEnabled(!anyEnabledNow);
					this.settings = await this.state.getSettings();
					this.renderLintSettingsToId(this.currentRuleSearchQuery, LintSettingId);
					this.updateToggleAllRulesButton();
					new Notice(`All Harper rules ${anyEnabledNow ? 'disabled' : 'enabled'}`);
				});
			});

		const lintSettings = document.createElement('DIV');
		lintSettings.id = LintSettingId;
		containerEl.appendChild(lintSettings);

		// Ensure default config is loaded before initial render so values reflect defaults.
		this.state.getDefaultLintConfig().then((v) => {
			this.defaultLintConfig = v as unknown as Record<string, boolean>;
			this.renderLintSettingsToId(this.currentRuleSearchQuery, lintSettings.id);
		});
	}

	private async updateToggleAllRulesButton() {
		if (!this.toggleAllButton) return;
		const anyEnabled = await this.state.areAnyRulesEnabled();
		this.toggleAllButton.setButtonText(anyEnabled ? 'Disable All Rules' : 'Enable All Rules');
	}

	async renderLintSettingsToId(searchQuery: string, id: string) {
		const el = document.getElementById(id);
		if (!el) return;
		const effective = await this.state.getEffectiveLintConfig();
		this.renderLintSettings(searchQuery, el, effective);
	}

	private renderLintSettings(
		searchQuery: string,
		containerEl: HTMLElement,
		effectiveConfig: Record<string, boolean>,
	) {
		containerEl.innerHTML = '';

		const queryLower = searchQuery.toLowerCase();

		for (const setting of Object.keys(this.settings.lintSettings)) {
			const value = this.settings.lintSettings[setting];
			const descriptionHTML = this.descriptionsHTML[setting];

			if (
				searchQuery !== '' &&
				!(
					descriptionHTML?.toLowerCase().contains(queryLower) ||
					setting.toLowerCase().contains(queryLower)
				)
			) {
				continue;
			}

			const fragment = document.createDocumentFragment();
			const template = document.createElement('template');
			template.innerHTML = descriptionHTML;
			fragment.appendChild(template.content);

			// Determine default for this rule (if available)
			const defaultVal = this.defaultLintConfig?.[setting];

			new Setting(containerEl)
				.setName(startCase(setting))
				.setDesc(fragment)
				.addDropdown((dropdown) => {
					const effective: boolean | undefined = effectiveConfig[setting];
					const usingDefault = value === null;
					const onLabel = usingDefault && defaultVal === true ? 'On (default)' : 'On';
					const offLabel = usingDefault && defaultVal === false ? 'Off (default)' : 'Off';
					dropdown
						.addOption('enable', onLabel)
						.addOption('disable', offLabel)
						.setValue(effective ? 'enable' : 'disable')
						.onChange(async (v) => {
							this.settings.lintSettings[setting] = v === 'enable';
							await this.state.initializeFromSettings(this.settings);
							// Re-render to update labels (remove "(default)" once overridden)
							this.renderLintSettingsToId(this.currentRuleSearchQuery, LintSettingId);
							this.updateToggleAllRulesButton();
						});
				});
		}
	}
}

// Note: dropdowns present only On/Off. When using defaults (unset),
// the matching option label includes "(default)".



================================================
FILE: packages/obsidian-plugin/src/index.ts
================================================
import { Dialect } from 'harper.js';
import { type App, editorInfoField, Menu, Notice, Plugin, type PluginManifest } from 'obsidian';
import logoSvg from '../logo.svg?raw';
import logoSvgDisabled from '../logo-disabled.svg?raw';
import { HarperSettingTab } from './HarperSettingTab';
import State from './State';

export default class HarperPlugin extends Plugin {
	state: State;
	private dialectSpan: HTMLSpanElement | null = null;
	private logo: HTMLSpanElement | null = null;
	private settings: HarperSettingTab | null = null;

	constructor(app: App, manifest: PluginManifest) {
		super(app, manifest);
	}

	async onload() {
		if (typeof Response === 'undefined') {
			new Notice('Please update your Electron version before running Harper.', 0);
			return;
		}

		const data = await this.loadData();

		this.app.workspace.onLayoutReady(async () => {
			this.state = new State(
				(n) => this.saveData(n),
				() => this.app.workspace.updateOptions(),
				editorInfoField,
			);

			await this.state.initializeFromSettings(data);
			this.registerEditorExtension(this.state.getCMEditorExtensions());
			if (!(data?.lintEnabled ?? true)) {
				this.state.disableEditorLinter(false);
			} else this.state.enableEditorLinter(false);
			this.settings?.update();

			this.setupStatusBar();
		});

		this.settings = new HarperSettingTab(this.app, this);
		this.addSettingTab(this.settings);

		this.setupCommands();
	}

	private getDialectStatus(dialectNum: Dialect): string {
		const code = {
			American: 'US',
			British: 'GB',
			Australian: 'AU',
			Canadian: 'CA',
		}[Dialect[dialectNum]];
		if (code === undefined) {
			return '';
		}
		return `${code
			.split('')
			.map((c) => String.fromCodePoint(c.charCodeAt(0) + 127397))
			.join('')}${code}`;
	}

	private setupStatusBar() {
		const statusBarItem: HTMLElement = this.addStatusBarItem();
		statusBarItem.className += ' mod-clickable';

		const button = document.createElement('span');
		button.style.display = 'flex';
		button.style.alignItems = 'center';

		const logo = document.createElement('span');
		logo.style.width = '24px';
		logo.innerHTML = this.state.hasEditorLinter() ? logoSvg : logoSvgDisabled;
		this.logo = logo;
		button.appendChild(logo);

		const dialect = document.createElement('span');
		this.dialectSpan = dialect;

		this.state.getSettings().then((settings) => {
			const dialectNum = settings.dialect ?? Dialect.American;
			this.updateStatusBar(dialectNum);
			button.appendChild(dialect);
		});

		button.addEventListener('click', (event) => {
			const menu = new Menu();

			menu.addItem((item) =>
				item
					.setTitle(`${this.state.hasEditorLinter() ? 'Disable' : 'Enable'} automatic checking`)
					.setIcon('documents')
					.onClick(() => {
						this.toggleAutoLint();
					}),
			);

			menu.addItem((item) =>
				item
					.setTitle('Ignore all errors in file')
					.setIcon('eraser')
					.onClick(() => {
						this.doIgnoreAllFlow();
					}),
			);

			menu.showAtMouseEvent(event);
		});

		statusBarItem.appendChild(button);
	}

	/** Preferred over directly calling `this.state.toggleAutoLint()` */
	private toggleAutoLint() {
		this.state.toggleAutoLint();
		this.updateStatusBar();
	}

	private setupCommands() {
		this.addCommand({
			id: 'harper-toggle-auto-lint',
			name: 'Toggle automatic grammar checking',
			callback: () => {
				this.toggleAutoLint();
			},
		});

		this.addCommand({
			id: 'harper-ignore-all-in-buffer',
			name: 'Ignore all errors in the open file',
			callback: async () => {
				await this.doIgnoreAllFlow();
			},
		});
	}

	/** Trigger the flow for ignoring all files in a document, including a confirmation modal. */
	public async doIgnoreAllFlow() {
		const file = this.app.workspace.getActiveFile();
		if (file != null) {
			const text = await this.app.vault.read(file);

			const lints = await this.state.getLinter().lint(text);
			const confirmation = confirm(
				`Are you sure you want to ignore ${lints.length} errors from Harper?`,
			);

			if (confirmation) {
				await this.state.ignoreLints(text, lints);
			}
		} else {
			new Notice('No file currently open.');
		}
	}

	public updateStatusBar(dialect?: Dialect) {
		if (this.logo != null) {
			this.logo.innerHTML = this.state.hasEditorLinter() ? logoSvg : logoSvgDisabled;
		}
		if (typeof dialect !== 'undefined') {
			if (this.dialectSpan != null) {
				this.dialectSpan.innerHTML = this.getDialectStatus(dialect);
			}
		}
	}
}



================================================
FILE: packages/obsidian-plugin/src/lint.ts
================================================
import {
	combineConfig,
	type EditorState,
	type Extension,
	Facet,
	RangeSet,
	StateEffect,
	StateField,
	type Transaction,
	type TransactionSpec,
} from '@codemirror/state';
import {
	Decoration,
	type DecorationSet,
	EditorView,
	hoverTooltip,
	logException,
	type Tooltip,
	ViewPlugin,
	type ViewUpdate,
	WidgetType,
} from '@codemirror/view';
import elt from 'crelt';

type Severity = 'hint' | 'info' | 'warning' | 'error';

/// Describes a problem or hint for a piece of code.
export interface Diagnostic {
	/// The start position of the relevant text.
	from: number;
	/// The end position. May be equal to `from`, though actually
	/// covering text is preferable.
	to: number;
	/// The severity of the problem. This will influence how it is
	/// displayed.
	severity: Severity;
	/// When given, add an extra CSS class to parts of the code that
	/// this diagnostic applies to.
	markClass?: string;
	/// An optional source string indicating where the diagnostic is
	/// coming from. You can put the name of your linter here, if
	/// applicable.
	source?: string;
	title?: string;
	/// The message associated with this diagnostic.
	message: string;
	/// An optional custom rendering function that displays the message
	/// as a DOM node.
	renderMessage?: (view: EditorView) => Node;
	/// An optional array of actions that can be taken on this
	/// diagnostic.
	actions?: readonly Action[];
	/// A callback for when the user selects to "ignore" the diagnostic.
	ignore?: () => void;
	/// A callback for when the user selects to "disable" the source of the diagnostic.
	disable?: () => void;
}

/// An action associated with a diagnostic.
export interface Action {
	/// The label to show to the user. Should be relatively short.
	name: string;
	/// The value to pass the title property of the button.
	title: string;
	/// The function to call when the user activates this action. Is
	/// given the diagnostic's _current_ position, which may have
	/// changed since the creation of the diagnostic, due to editing.
	apply: (view: EditorView, from: number, to: number) => void;
}

type DiagnosticFilter = (diagnostics: readonly Diagnostic[], state: EditorState) => Diagnostic[];

interface LintConfig {
	/// Time to wait (in milliseconds) after a change before running
	/// the linter. Defaults to 750ms.
	delay?: number;
	/// Optional predicate that can be used to indicate when diagnostics
	/// need to be recomputed. Linting is always re-done on document
	/// changes.
	needsRefresh?: null | ((update: ViewUpdate) => boolean);
	/// Optional filter to determine which diagnostics produce markers
	/// in the content.
	markerFilter?: null | DiagnosticFilter;
	/// Filter applied to a set of diagnostics shown in a tooltip. No
	/// tooltip will appear if the empty set is returned.
	tooltipFilter?: null | DiagnosticFilter;
	/// Can be used to control what kind of transactions cause lint
	/// hover tooltips associated with the given document range to be
	/// hidden. By default any transaction that changes the line
	/// around the range will hide it. Returning null falls back to this
	/// behavior.
	hideOn?: (tr: Transaction, from: number, to: number) => boolean | null;
	/// When enabled (defaults to off), this will cause the lint panel
	/// to automatically open when diagnostics are found, and close when
	/// all diagnostics are resolved or removed.
	autoPanel?: boolean;
}

class SelectedDiagnostic {
	constructor(
		readonly from: number,
		readonly to: number,
		readonly diagnostic: Diagnostic,
	) {}
}

class LintState {
	constructor(
		readonly diagnostics: DecorationSet,
		readonly selected: SelectedDiagnostic | null,
	) {}

	static init(diagnostics: readonly Diagnostic[], state: EditorState) {
		// Filter the list of diagnostics for which to create markers
		let markedDiagnostics = diagnostics;
		const diagnosticFilter = state.facet(lintConfig).markerFilter;
		if (diagnosticFilter) markedDiagnostics = diagnosticFilter(markedDiagnostics, state);

		const ranges = Decoration.set(
			markedDiagnostics.map((d: Diagnostic) => {
				// For zero-length ranges or ranges covering only a line break, create a widget
				return d.from == d.to || (d.from == d.to - 1 && state.doc.lineAt(d.from).to == d.from)
					? Decoration.widget({
							widget: new DiagnosticWidget(d),
							diagnostic: d,
						}).range(d.from)
					: Decoration.mark({
							attributes: {
								class: `cm-lintRange cm-lintRange-${d.severity}${d.markClass ? ` ${d.markClass}` : ''}`,
							},
							diagnostic: d,
						}).range(d.from, d.to);
			}),
			true,
		);
		return new LintState(ranges, findDiagnostic(ranges));
	}
}

function findDiagnostic(
	diagnostics: DecorationSet,
	diagnostic: Diagnostic | null = null,
	after = 0,
): SelectedDiagnostic | null {
	let found: SelectedDiagnostic | null = null;
	diagnostics.between(after, 1e9, (from, to, { spec }) => {
		if (diagnostic && spec.diagnostic != diagnostic) return;
		found = new SelectedDiagnostic(from, to, spec.diagnostic);
		return false;
	});
	return found;
}

function hideTooltip(tr: Transaction, tooltip: Tooltip) {
	const from = tooltip.pos;
	const to = tooltip.end || from;
	const result = tr.state.facet(lintConfig).hideOn(tr, from, to);
	if (result != null) return result;
	const line = tr.startState.doc.lineAt(tooltip.pos);
	return !!(
		tr.effects.some((e) => e.is(setDiagnosticsEffect)) ||
		tr.changes.touchesRange(line.from, Math.max(line.to, to))
	);
}

function maybeEnableLint(state: EditorState, effects: readonly StateEffect<unknown>[]) {
	return state.field(lintState, false)
		? effects
		: effects.concat(StateEffect.appendConfig.of(lintExtensions));
}

/// Returns a transaction spec which updates the current set of
/// diagnostics, and enables the lint extension if if wasn't already
/// active.
export function setDiagnostics(
	state: EditorState,
	diagnostics: readonly Diagnostic[],
): TransactionSpec {
	return {
		effects: maybeEnableLint(state, [setDiagnosticsEffect.of(diagnostics)]),
	};
}

/// The state effect that updates the set of active diagnostics. Can
/// be useful when writing an extension that needs to track these.
export const setDiagnosticsEffect = StateEffect.define<readonly Diagnostic[]>();

const movePanelSelection = StateEffect.define<SelectedDiagnostic>();

const lintState = StateField.define<LintState>({
	create() {
		return new LintState(Decoration.none, null);
	},
	update(value, tr) {
		if (tr.docChanged && value.diagnostics.size) {
			const mapped = value.diagnostics.map(tr.changes);
			let selected: SelectedDiagnostic | null = null;
			if (value.selected) {
				const selPos = tr.changes.mapPos(value.selected.from, 1);
				selected =
					findDiagnostic(mapped, value.selected.diagnostic, selPos) ||
					findDiagnostic(mapped, null, selPos);
			}
			value = new LintState(mapped, selected);
		}

		for (const effect of tr.effects) {
			if (effect.is(setDiagnosticsEffect)) {
				value = LintState.init(effect.value, tr.state);
			} else if (effect.is(movePanelSelection)) {
				value = new LintState(value.diagnostics, effect.value);
			}
		}

		return value;
	},
	provide: (f) => [EditorView.decorations.from(f, (s) => s.diagnostics)],
});

const activeMark = Decoration.mark({ class: 'cm-lintRange cm-lintRange-active' });

function lintTooltip(view: EditorView, pos: number, side: -1 | 1) {
	const { diagnostics } = view.state.field(lintState);
	let found: Diagnostic[] = [];
	let stackStart = 2e8;
	let stackEnd = 0;
	diagnostics.between(pos - (side < 0 ? 1 : 0), pos + (side > 0 ? 1 : 0), (from, to, { spec }) => {
		if (
			pos >= from &&
			pos <= to &&
			(from == to || ((pos > from || side > 0) && (pos < to || side < 0)))
		) {
			found.push(spec.diagnostic);
			stackStart = Math.min(from, stackStart);
			stackEnd = Math.max(to, stackEnd);
		}
	});

	const diagnosticFilter = view.state.facet(lintConfig).tooltipFilter;
	if (diagnosticFilter) found = diagnosticFilter(found, view.state);

	if (!found.length) return null;

	return {
		pos: stackStart,
		end: stackEnd,
		above: view.state.doc.lineAt(stackStart).to < stackEnd,
		create() {
			return { dom: diagnosticsTooltip(view, found) };
		},
	};
}

function diagnosticsTooltip(view: EditorView, diagnostics: readonly Diagnostic[]) {
	return elt(
		'ul',
		{ class: 'cm-tooltip-lint' },
		diagnostics.map((d) => renderDiagnostic(view, d, false)),
	);
}

/// The type of a function that produces diagnostics.
export type LintSource = (
	view: EditorView,
) => readonly Diagnostic[] | Promise<readonly Diagnostic[]>;

const lintPlugin = ViewPlugin.fromClass(
	class {
		lintTime: number;
		timeout = -1;
		set = true;

		constructor(readonly view: EditorView) {
			const { delay } = view.state.facet(lintConfig);
			this.lintTime = Date.now() + delay;
			this.run = this.run.bind(this);
			this.timeout = setTimeout(this.run, delay);
		}

		run() {
			clearTimeout(this.timeout);
			const now = Date.now();
			if (now < this.lintTime - 10) {
				this.timeout = setTimeout(this.run, this.lintTime - now);
			} else {
				this.set = false;
				const { state } = this.view;
				const { sources } = state.facet(lintConfig);
				if (sources.length)
					Promise.all(sources.map((source) => Promise.resolve(source(this.view)))).then(
						(annotations) => {
							const all = annotations.reduce((a, b) => a.concat(b));
							if (this.view.state.doc == state.doc)
								this.view.dispatch(setDiagnostics(this.view.state, all));
						},
						(error) => {
							logException(this.view.state, error);
						},
					);
			}
		}

		update(update: ViewUpdate) {
			const config = update.state.facet(lintConfig);
			if (
				update.docChanged ||
				config != update.startState.facet(lintConfig) ||
				config.needsRefresh?.(update)
			) {
				this.lintTime = Date.now() + config.delay;
				if (!this.set) {
					this.set = true;
					this.timeout = setTimeout(this.run, config.delay);
				}
			}
		}

		force() {
			if (this.set) {
				this.lintTime = Date.now();
				this.run();
			}
		}

		destroy() {
			clearTimeout(this.timeout);
		}
	},
);

const lintConfig = Facet.define<
	{ source: LintSource | null; config: LintConfig },
	Required<LintConfig> & { sources: readonly LintSource[] }
>({
	combine(input) {
		return {
			sources: input.map((i) => i.source).filter((x) => x != null) as readonly LintSource[],
			...combineConfig(
				input.map((i) => i.config),
				{
					delay: 750,
					markerFilter: null,
					tooltipFilter: null,
					needsRefresh: null,
					hideOn: () => null,
				},
				{
					needsRefresh: (a, b) => (!a ? b : !b ? a : (u) => a(u) || b(u)),
				},
			),
		};
	},
});

/// Given a diagnostic source, this function returns an extension that
/// enables linting with that source. It will be called whenever the
/// editor is idle (after its content changed). If `null` is given as
/// source, this only configures the lint extension.
export function linter(source: LintSource | null, config: LintConfig = {}): Extension {
	return [lintConfig.of({ source, config }), lintPlugin, lintExtensions];
}

/// Forces any linters [configured](#lint.linter) to run when the
/// editor is idle to run right away.
export function forceLinting(view: EditorView) {
	const plugin = view.plugin(lintPlugin);
	if (plugin) plugin.force();
}

function assignKeys(actions: readonly Action[] | undefined) {
	const assigned: string[] = [];
	if (actions)
		// biome-ignore lint/suspicious/noLabelVar: reasons
		actions: for (const { name } of actions) {
			for (let i = 0; i < name.length; i++) {
				const ch = name[i];
				if (/[a-zA-Z]/.test(ch) && !assigned.some((c) => c.toLowerCase() == ch.toLowerCase())) {
					assigned.push(ch);
					continue actions;
				}
			}
			assigned.push('');
		}
	return assigned;
}

function renderDiagnostic(view: EditorView, diagnostic: Diagnostic, inPanel: boolean) {
	const keys = inPanel ? assignKeys(diagnostic.actions) : [];
	return elt(
		'li',
		{ class: `cm-diagnostic cm-diagnostic-${diagnostic.severity}` },
		elt('span', { class: 'cm-diagnosticTitle' }, diagnostic.title),
		elt(
			'span',
			{ class: 'cm-diagnosticText' },
			diagnostic.renderMessage ? diagnostic.renderMessage(view) : diagnostic.message,
		),
		elt(
			'span',
			{ class: 'cm-diagnosticActionCont' },
			diagnostic.actions?.map((action, i) => {
				let fired = false;
				const click = (e: Event) => {
					e.preventDefault();
					if (fired) return;
					fired = true;
					const found = findDiagnostic(view.state.field(lintState).diagnostics, diagnostic);
					if (found) action.apply(view, found.from, found.to);
				};
				const { name, title } = action;
				const keyIndex = keys[i] ? name.indexOf(keys[i]) : -1;
				const nameElt =
					keyIndex < 0
						? name
						: [
								name.slice(0, keyIndex),
								elt('u', name.slice(keyIndex, keyIndex + 1)),
								name.slice(keyIndex + 1),
							];
				return elt(
					'button',
					{
						type: 'button',
						class: 'cm-diagnosticAction',
						onclick: click,
						onmousedown: click,
						'aria-label': ` ${title}${keyIndex < 0 ? '' : ` (access key "${keys[i]})"`}.`,
					},
					nameElt,
				);
			}),
		),
		elt('div', { class: 'cm-diagnosticRow' }, [
			diagnostic.ignore &&
				elt(
					'div',
					{
						class: 'cm-diagnosticIgnore',
						onclick: (e) => {
							e.preventDefault();
							if (diagnostic.ignore) {
								diagnostic.ignore();
							}
						},
					},
					'Ignore Diagnostic',
				),
			diagnostic.disable &&
				elt(
					'div',
					{
						class: 'cm-diagnosticDisable',
						onclick: (e) => {
							e.preventDefault();
							if (diagnostic.disable) {
								diagnostic.disable();
							}
						},
						title: `Disable ${diagnostic.source}`,
					},
					'Disable Rule',
				),
		]),
	);
}

class DiagnosticWidget extends WidgetType {
	constructor(readonly diagnostic: Diagnostic) {
		super();
	}

	eq(other: DiagnosticWidget) {
		return other.diagnostic == this.diagnostic;
	}

	toDOM() {
		return elt('span', { class: `cm-lintPoint cm-lintPoint-${this.diagnostic.severity}` });
	}
}

function svg(content: string, attrs = `viewBox="0 0 40 40"`) {
	return `url('data:image/svg+xml,<svg xmlns="http://www.w3.org/2000/svg" ${attrs}>${encodeURIComponent(content)}</svg>')`;
}

function underline(color: string) {
	return svg(
		`<path d="m0 2.5 l2 -1.5 l1 0 l2 1.5 l1 0" stroke="${color}" fill="none" stroke-width="1"/>`,
		`width="6" height="3"`,
	);
}

const baseTheme = EditorView.baseTheme({
	'.cm-diagnostic': {
		padding: '4px',
		marginLeft: '0px',
		display: 'flex',
		flexDirection: 'column',
		whiteSpace: 'pre-wrap',
		maxHeight: 'calc(100% - var(--header-height)) !important',
	},

	'.cm-diagnosticTitle': {
		boxShadow: 'inset 0 -2px #DB2B39',
		width: 'max-content',
		fontWeight: 'bold',
	},

	'.cm-diagnosticText': {
		marginTop: '8px',
	},

	'.cm-diagnosticText p': {
		margin: '0px',
		padding: '0px',
		display: 'inline',
	},

	'.cm-diagnosticText code': {
		borderRadius: '0.25rem',
		backgroundColor: 'var(--background-secondary) !important',
		border:
			'1px solid rgb(from var(--background-secondary) calc(255 - r) calc(255 - g) calc(255 - b))',
		padding: '0.25rem',
	},

	'.cm-diagnosticActionCont': {
		display: 'flex',
		flexWrap: 'wrap',
		justifyContent: 'flex-start',
		alignItems: 'flex-start',
		alignContent: 'flex-start',
		gap: 'var(--size-4-2)',
	},

	'.cm-diagnosticRow': {
		display: 'flex',
		flexDirection: 'row',
		justifyContent: 'space-between',
	},

	'.cm-diagnosticAction': {
		font: 'inherit',
		border: 'none',
		marginTop: '8px',
		display: 'flex',
		alignItems: 'center',
		gap: 'var(--size-4-2)',
		padding: 'var(--size-4-1) var(--size-4-2)',
		cursor: 'var(--cursor)',
		fontSize: 'var(--font-ui-small)',
		borderRadius: 'var(--radius-s)',
		whiteSpace: 'nowrap',
	},

	'.cm-tooltip': {
		padding: 'var(--size-2-3) !important',
		border: '1px solid var(--background-modifier-border-hover) !important',
		backgroundColor: 'var(--background-secondary) !important',
		borderRadius: 'var(--radius-m) !important',
		boxShadow: 'var(--shadow-s) !important',
		zIndex: 'var(--layer-menu) !important',
		userSelect: 'none !important',
		overflow: 'hidden !important',
	},

	'.cm-diagnosticSource': {
		fontSize: '70%',
		opacity: 0.7,
	},

	'.cm-diagnosticIgnore': {
		padding: 'var(--size-4-1) 0px',
		fontSize: 'var(--font-ui-small)',
	},

	'.cm-diagnosticIgnore:hover': {
		textDecoration: 'underline',
	},

	'.cm-diagnosticDisable': {
		padding: 'var(--size-4-1) 0px',
		fontSize: 'var(--font-ui-small)',
	},

	'.cm-diagnosticDisable:hover': {
		textDecoration: 'underline',
	},

	'.cm-lintRange': {
		backgroundPosition: 'left bottom',
		backgroundRepeat: 'repeat-x',
		paddingBottom: '0.7px',
	},

	'.cm-lintRange-error': { backgroundImage: underline('#d11') },
	'.cm-lintRange-warning': { backgroundImage: underline('orange') },
	'.cm-lintRange-info': { backgroundImage: underline('#999') },
	'.cm-lintRange-hint': { backgroundImage: underline('#66d') },
	'.cm-lintRange-active': { backgroundColor: '#ffdd9980' },

	'.cm-tooltip-lint': {
		padding: 0,
		margin: 0,
	},

	'.cm-lintPoint': {
		position: 'relative',

		'&:after': {
			content: '""',
			position: 'absolute',
			bottom: 0,
			left: '-2px',
			borderLeft: '3px solid transparent',
			borderRight: '3px solid transparent',
			borderBottom: '4px solid #d11',
		},
	},

	'.cm-lintPoint-warning': {
		'&:after': { borderBottomColor: 'orange' },
	},
	'.cm-lintPoint-info': {
		'&:after': { borderBottomColor: '#999' },
	},
	'.cm-lintPoint-hint': {
		'&:after': { borderBottomColor: '#66d' },
	},

	'.cm-panel.cm-panel-lint': {
		position: 'relative',
		'& ul': {
			maxHeight: '100px',
			overflowY: 'auto',
			'& [aria-selected]': {
				backgroundColor: '#ddd',
				'& u': { textDecoration: 'underline' },
			},
			'&:focus [aria-selected]': {
				background_fallback: '#bdf',
				backgroundColor: 'Highlight',
				color_fallback: 'white',
				color: 'HighlightText',
			},
			'& u': { textDecoration: 'none' },
			padding: 0,
			margin: 0,
		},
		'& [name=close]': {
			position: 'absolute',
			top: '0',
			right: '2px',
			background: 'inherit',
			border: 'none',
			font: 'inherit',
			padding: 0,
			margin: 0,
		},
	},
});

const lintExtensions = [
	lintState,
	EditorView.decorations.compute([lintState], (state) => {
		const { selected, panel } = state.field(lintState);
		return !selected || !panel || selected.from == selected.to
			? Decoration.none
			: Decoration.set([activeMark.range(selected.from, selected.to)]);
	}),
	hoverTooltip(lintTooltip, { hideOn: hideTooltip }),
	baseTheme,
];

/// Iterate over the marked diagnostics for the given editor state,
/// calling `f` for each of them. Note that, if the document changed
/// since the diagnostics were created, the `Diagnostic` object will
/// hold the original outdated position, whereas the `to` and `from`
/// arguments hold the diagnostic's current position.
export function forEachDiagnostic(
	state: EditorState,
	f: (d: Diagnostic, from: number, to: number) => void,
) {
	const lState = state.field(lintState, false);
	if (lState?.diagnostics.size)
		for (let iter = RangeSet.iter([lState.diagnostics]); iter.value; iter.next())
			f(iter.value.spec.diagnostic, iter.from, iter.to);
}



================================================
FILE: packages/obsidian-plugin/src/State.test.ts
================================================
import { shuffle } from 'lodash-es';
import { expect, test } from 'vitest';
import State from './State';

function randomString(length: number): string {
	const chars = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz';
	let result = '';
	for (let i = 0; i < length; i++) {
		result += chars.charAt(Math.floor(Math.random() * chars.length));
	}
	return result;
}

/** Create an instance of the test class that doesn't use external persistence. */
function createEphemeralState(): State {
	return new State(
		(_) => Promise.resolve(),
		() => {},
		undefined,
	);
}

test('Toggling linting should change extension array.', () => {
	const state = createEphemeralState();

	const editorExtensions = state.getCMEditorExtensions();
	state.enableEditorLinter();

	expect(editorExtensions.length).toBe(1);

	state.disableEditorLinter();

	expect(editorExtensions.length).toBe(0);
});

test('Passing default settings back in should have a null net change.', async () => {
	const state = createEphemeralState();

	const initialSettings = await state.getSettings();
	await state.initializeFromSettings(initialSettings);
	const reinitSettings = await state.getSettings();

	expect(reinitSettings).toStrictEqual(initialSettings);
});

test('Default settings should have null linter configs', async () => {
	const state = createEphemeralState();

	const defaultSettings = await state.getSettings();

	const linterKeys = Object.keys(defaultSettings.lintSettings);

	expect(linterKeys.length).toBeGreaterThan(0);

	for (const key of linterKeys) {
		const setting = defaultSettings.lintSettings[key];
		expect(setting).toBeNull();
	}
});

test('Lint keys are not undefined', async () => {
	const state = createEphemeralState();

	const defaultSettings = await state.getSettings();

	expect(defaultSettings.lintSettings.ThisKeyDoesNotExist).toBeUndefined();
	expect(defaultSettings.lintSettings.RepeatedWords).toBeNull();
});

test('Lint keys can be enabled, then set to default.', async () => {
	const state = createEphemeralState();

	let settings = await state.getSettings();

	settings.lintSettings.RepeatedWords = true;
	await state.initializeFromSettings(settings);
	settings = await state.getSettings();
	expect(settings.lintSettings.RepeatedWords).toBe(true);

	settings.lintSettings.RepeatedWords = null;
	await state.initializeFromSettings(settings);
	settings = await state.getSettings();
	expect(settings.lintSettings.RepeatedWords).toBe(null);
});

test('Lint settings and descriptions have the same keys', async () => {
	const state = createEphemeralState();

	const settings = await state.getSettings();
	const descriptions = await state.getDescriptionHTML();

	expect(Object.keys(descriptions).sort()).toStrictEqual(Object.keys(settings.lintSettings).sort());
});

test('Can be initialized with incomplete lint settings and retain default state.', async () => {
	const state = createEphemeralState();

	// Get the default settings
	const defaultSettings = await state.getSettings();

	// Pick just a few lint settings to keep.
	const numberToKeep = 5;
	const reducedLintSettings = Object.fromEntries(
		shuffle(Object.entries(defaultSettings.lintSettings)).slice(0, numberToKeep),
	);
	expect(Object.keys(reducedLintSettings).length).toBe(numberToKeep);

	await state.initializeFromSettings({ ...defaultSettings, lintSettings: reducedLintSettings });

	expect(await state.getSettings()).toStrictEqual(defaultSettings);
});

test('resetAllRulesToDefaults sets all overrides to null', async () => {
	const state = createEphemeralState();

	// Start with all enabled, then reset
	let settings = await state.getSettings();
	for (const key of Object.keys(settings.lintSettings)) {
		settings.lintSettings[key] = true;
	}
	await state.initializeFromSettings(settings);

	await state.resetAllRulesToDefaults();
	settings = await state.getSettings();
	for (const key of Object.keys(settings.lintSettings)) {
		expect(settings.lintSettings[key]).toBeNull();
	}
});

test('setAllRulesEnabled toggles all rules on and off', async () => {
	const state = createEphemeralState();

	await state.setAllRulesEnabled(true);
	let settings = await state.getSettings();
	for (const key of Object.keys(settings.lintSettings)) {
		expect(settings.lintSettings[key]).toBe(true);
	}

	await state.setAllRulesEnabled(false);
	settings = await state.getSettings();
	for (const key of Object.keys(settings.lintSettings)) {
		expect(settings.lintSettings[key]).toBe(false);
	}
});

test('getEffectiveLintConfig matches defaults after reset', async () => {
	const state = createEphemeralState();
	await state.resetAllRulesToDefaults();
	const effective = await state.getEffectiveLintConfig();
	const defaults = (await state.getDefaultLintConfig()) as Record<string, boolean>;
	expect(Object.keys(effective).sort()).toStrictEqual(Object.keys(defaults).sort());
	for (const k of Object.keys(defaults)) {
		expect(effective[k]).toBe(defaults[k]);
	}
});

test('getEffectiveLintConfig reflects explicit overrides', async () => {
	const state = createEphemeralState();
	const settings = await state.getSettings();
	for (const key of Object.keys(settings.lintSettings)) {
		settings.lintSettings[key] = true;
	}
	await state.initializeFromSettings(settings);
	const effective = await state.getEffectiveLintConfig();
	for (const k of Object.keys(effective)) {
		expect(effective[k]).toBe(true);
	}
});

test('can persist dictionary words in settings', async () => {
	const state = createEphemeralState();
	let settings = await state.getSettings();

	const testWord = 'ajhsbdajshdb';
	settings.userDictionary = [testWord];

	await state.initializeFromSettings(settings);

	settings = await state.getSettings();

	expect(settings.userDictionary).toStrictEqual([testWord]);
});

test('can persist dictionary order in settings', async () => {
	const state = createEphemeralState();
	let settings = await state.getSettings();

	const testDictionary: string[] = [];
	for (let i = 0; i < 200; i++) {
		testDictionary.push(randomString(10));
	}

	settings.userDictionary = testDictionary;
	await state.initializeFromSettings(settings);

	settings = await state.getSettings();

	const roundOne = settings.userDictionary;

	await state.initializeFromSettings(settings);
	settings = await state.getSettings();
	const roundTwo = settings.userDictionary;

	expect(roundOne).toStrictEqual(roundTwo);
});

test('can overwrite dictionary words in settings', async () => {
	const state = createEphemeralState();
	let settings = await state.getSettings();

	const testWord = 'ajhsbdajshdb';
	settings.userDictionary = [testWord];

	await state.initializeFromSettings(settings);
	settings = await state.getSettings();

	expect(settings.userDictionary).toStrictEqual([testWord]);

	settings.userDictionary = [];

	await state.initializeFromSettings(settings);
	settings = await state.getSettings();

	expect(settings.userDictionary).toStrictEqual([]);
});



================================================
FILE: packages/obsidian-plugin/src/State.ts
================================================
import type { Extension, StateField } from '@codemirror/state';
import type { Lint, LintConfig, Linter, Suggestion } from 'harper.js';
import { binaryInlined, type Dialect, LocalLinter, SuggestionKind, WorkerLinter } from 'harper.js';
import { minimatch } from 'minimatch';
import type { MarkdownFileInfo, Workspace } from 'obsidian';
import { linter } from './lint';

export type Settings = {
	ignoredLints?: string;
	useWebWorker: boolean;
	dialect?: Dialect;
	lintSettings: LintConfig;
	userDictionary?: string[];
	delay?: number;
	ignoredGlobs?: string[];
	lintEnabled?: boolean;
};

const DEFAULT_DELAY = -1;

/** The centralized state for the entire Obsidian plugin.
 * Since it also contains most business logic, for testing purpose it should not interact with Obsidian directly.*/
export default class State {
	private harper: Linter;
	private saveData: (data: any) => Promise<void>;
	private delay: number;
	private workspace: Workspace;
	private onExtensionChange: () => void;
	private ignoredGlobs?: string[];
	private editorInfoField?: StateField<MarkdownFileInfo>;
	private lintEnabled?: boolean;

	/** The CodeMirror extension objects that should be inserted by the host. */
	private editorExtensions: Extension[];

	/** @param saveDataCallback A callback which will be used to save data on disk.
	 * @param onExtensionChange A callback this class will run when the extension array is modified.
	 * @param editorViewField Needed to provide support for ignoring files based on path.*/
	constructor(
		saveDataCallback: (data: any) => Promise<void>,
		onExtensionChange: () => void,
		_editorInfoField?: StateField<MarkdownFileInfo>,
	) {
		this.harper = new WorkerLinter({ binary: binaryInlined });
		this.delay = DEFAULT_DELAY;
		this.saveData = saveDataCallback;
		this.onExtensionChange = onExtensionChange;
		this.editorExtensions = [];

		this.editorInfoField = _editorInfoField;
	}

	public async initializeFromSettings(settings: Settings | null) {
		if (settings == null) {
			settings = {
				useWebWorker: true,
				lintEnabled: true,
				lintSettings: {},
			};
		}

		const defaultConfig = await this.harper.getDefaultLintConfig();
		for (const key of Object.keys(defaultConfig)) {
			if (settings.lintSettings[key] == undefined) {
				settings.lintSettings[key] = null;
			}
		}

		const oldSettings = await this.getSettings();

		if (
			settings.useWebWorker !== oldSettings.useWebWorker ||
			settings.dialect !== oldSettings.dialect
		) {
			if (settings.useWebWorker) {
				this.harper.dispose();
				this.harper = new WorkerLinter({ binary: binaryInlined, dialect: settings.dialect });
			} else {
				this.harper.dispose();
				this.harper = new LocalLinter({ binary: binaryInlined, dialect: settings.dialect });
			}
		} else {
			await this.harper.clearIgnoredLints();
		}

		if (settings.ignoredLints !== undefined) {
			await this.harper.importIgnoredLints(settings.ignoredLints);
		}

		if (settings.userDictionary != null) {
			await this.harper.clearWords();
			if (settings.userDictionary.length > 0) {
				await this.harper.importWords(settings.userDictionary);
			}
		}

		await this.harper.setLintConfig(settings.lintSettings);
		this.harper.setup();

		this.delay = settings.delay ?? DEFAULT_DELAY;
		this.ignoredGlobs = settings.ignoredGlobs;
		this.lintEnabled = settings.lintEnabled;

		// Reinitialize it.
		if (this.hasEditorLinter()) {
			this.disableEditorLinter(false);
			this.enableEditorLinter(false);
		}

		await this.saveData(settings);
	}

	/** Construct the linter plugin that actually shows the errors. */
	private constructEditorLinter(): Extension {
		return linter(
			async (view) => {
				const ignoredGlobs = this.ignoredGlobs ?? [];

				if (this.editorInfoField != null) {
					const mdView = view.state.field(this.editorInfoField, false);
					const file = mdView?.file;

					if (file != null) {
						const path = file.path;
						for (const glob of ignoredGlobs) {
							if (minimatch(path, glob)) {
								return [];
							}
						}
					}
				}

				const text = view.state.doc.sliceString(-1);
				const chars = Array.from(text);

				const lints = await this.harper.organizedLints(text);

				return Object.entries(lints).flatMap(([linterName, lints]) =>
					lints.map((lint) => {
						const span = lint.span();

						const actions = lint.suggestions().map((sug) => {
							return {
								name:
									sug.kind() == SuggestionKind.Replace
										? sug.get_replacement_text()
										: suggestionToLabel(sug),
								title: suggestionToLabel(sug),
								apply: (view) => {
									if (sug.kind() === SuggestionKind.Remove) {
										view.dispatch({
											changes: {
												from: span.start,
												to: span.end,
												insert: '',
											},
										});
									} else if (sug.kind() === SuggestionKind.Replace) {
										view.dispatch({
											changes: {
												from: span.start,
												to: span.end,
												insert: sug.get_replacement_text(),
											},
										});
									} else if (sug.kind() === SuggestionKind.InsertAfter) {
										view.dispatch({
											changes: {
												from: span.end,
												to: span.end,
												insert: sug.get_replacement_text(),
											},
										});
									}
								},
							};
						});

						if (lint.lint_kind() === 'Spelling') {
							const word = lint.get_problem_text();

							actions.push({
								name: '📖',
								title: `Add “${word}” to your dictionary`,
								apply: (_view) => {
									this.harper.importWords([word]);
									this.reinitialize();
								},
							});
						}

						return {
							from: span.start,
							to: span.end,
							source: linterName,
							severity: 'error',
							title: lint.lint_kind_pretty(),
							renderMessage: (_view) => {
								const node = document.createElement('template');
								node.innerHTML = lint.message_html();
								return node.content;
							},
							ignore: async () => {
								await this.ignoreLints(text, [lint]);
							},
							disable: async () => {
								const lintConfig = await this.harper.getLintConfig();
								lintConfig[linterName] = false;
								await this.harper.setLintConfig(lintConfig);

								await this.reinitialize();
							},

							actions,
						};
					}),
				);
			},
			{
				delay: this.delay,
			},
		);
	}

	/** Use this method instead of interacting with the linter directly. */
	public async ignoreLints(text: string, lints: Lint[]) {
		for (const lint of lints) {
			await this.harper.ignoreLint(text, lint);
		}

		await this.reinitialize();
	}

	public async reinitialize() {
		const settings = await this.getSettings();
		await this.initializeFromSettings(settings);
	}

	public async getSettings(): Promise<Settings> {
		const usingWebWorker = this.harper instanceof WorkerLinter;

		const userDictionary = await this.harper.exportWords();
		userDictionary.sort();

		return {
			ignoredLints: await this.harper.exportIgnoredLints(),
			useWebWorker: usingWebWorker,
			lintSettings: await this.harper.getLintConfig(),
			userDictionary,
			dialect: await this.harper.getDialect(),
			delay: this.delay,
			ignoredGlobs: this.ignoredGlobs,
			lintEnabled: this.lintEnabled,
		};
	}

	/**
	 * Reset all lint rule overrides back to their defaults (null).
	 * Persists and reinitializes state to apply changes.
	 */
	public async resetAllRulesToDefaults(): Promise<void> {
		const settings = await this.getSettings();
		for (const key of Object.keys(settings.lintSettings)) {
			settings.lintSettings[key] = null;
		}
		await this.initializeFromSettings(settings);
	}

	/**
	 * Enable or disable all lint rules in bulk by setting explicit values.
	 * This overrides individual rule settings until changed again.
	 */
	public async setAllRulesEnabled(enabled: boolean): Promise<void> {
		const settings = await this.getSettings();
		for (const key of Object.keys(settings.lintSettings)) {
			settings.lintSettings[key] = enabled;
		}
		await this.initializeFromSettings(settings);
	}

	public async getDescriptionHTML(): Promise<Record<string, string>> {
		return await this.harper.getLintDescriptionsHTML();
	}

	/** Expose the default lint configuration for UI rendering. */
	public async getDefaultLintConfig(): Promise<LintConfig> {
		return await this.harper.getDefaultLintConfig();
	}

	/** Effective config: merges defaults with overrides (null/undefined uses default). */
	public async getEffectiveLintConfig(): Promise<Record<string, boolean>> {
		const defaults = (await this.getDefaultLintConfig()) as Record<string, boolean>;
		const overrides = (await this.getSettings()).lintSettings as Record<
			string,
			boolean | null | undefined
		>;
		const effective: Record<string, boolean> = {};
		for (const key of Object.keys(defaults)) {
			const v = overrides[key];
			effective[key] = v === null || v === undefined ? defaults[key] : Boolean(v);
		}
		return effective;
	}

	/** Determine if any rules are effectively enabled, considering defaults. */
	public async areAnyRulesEnabled(): Promise<boolean> {
		const settings = await this.getSettings();
		const defaults = await this.getDefaultLintConfig();
		for (const key of Object.keys(settings.lintSettings)) {
			const v = settings.lintSettings[key] as boolean | null | undefined;
			const def = (defaults as Record<string, boolean | undefined>)[key];
			const effective = v === null || v === undefined ? def : v;
			if (effective) return true;
		}
		return false;
	}

	/** Get a reference to the CM editor extensions.
	 * Do not mutate the returned value, except via methods on this class. */
	public getCMEditorExtensions(): Extension[] {
		return this.editorExtensions;
	}

	/** Enables the editor linter by adding an extension to the editor extensions array. */
	public enableEditorLinter(reinit = true) {
		if (!this.hasEditorLinter()) {
			this.editorExtensions.push(this.constructEditorLinter());
			this.lintEnabled = true;
			this.onExtensionChange();
			if (reinit) this.reinitialize();
			console.log('Enabled');
		}
	}

	/** Disables the editor linter by removing the extension from the editor extensions array. */
	public disableEditorLinter(reinit = true) {
		while (this.hasEditorLinter()) {
			this.editorExtensions.pop();
		}
		this.lintEnabled = false;
		this.onExtensionChange();
		if (reinit) this.reinitialize();
		console.log('Disabled');
	}

	public hasEditorLinter(): boolean {
		return this.editorExtensions.length !== 0;
	}

	public toggleAutoLint() {
		if (this.hasEditorLinter()) {
			this.disableEditorLinter();
		} else {
			this.enableEditorLinter();
		}
	}

	/** Get a reference to the current linter.
	 * It's best not to hold on to this type and to instead use this function again if another reference is needed. */
	public getLinter(): Linter {
		return this.harper;
	}
}

function suggestionToLabel(sug: Suggestion) {
	if (sug.kind() === SuggestionKind.Remove) {
		return 'Remove';
	} else if (sug.kind() === SuggestionKind.Replace) {
		return `Replace with “${sug.get_replacement_text()}”`;
	} else if (sug.kind() === SuggestionKind.InsertAfter) {
		return `Insert “${sug.get_replacement_text()}” after this.`;
	}
}



================================================
FILE: packages/obsidian-plugin/src/textUtils.test.ts
================================================
import { expect, test } from 'vitest';
import { linesToString, stringToLines } from './textUtils';

test('Dictionary values are reversible', () => {
	const possibleDicts = [
		[
			'lynx',
			'capybara',
			'ibex',
			'wombat',
			'ocelot',
			'pangolin',
			'stoat',
			'vole',
			'caracal',
			'gazelle',
		],
		[
			'azurite',
			'feldspar',
			'gabbro',
			'peridot',
			'chalcedony',
			'rutile',
			'aragonite',
			'spinel',
			'pyrite',
			'malachite',
		],
		[
			'auscultation',
			'phlebotomy',
			'sutures',
			'anticoagulant',
			'intubation',
			'tachycardia',
			'catheter',
			'defibrillator',
			'ischemia',
			'hematoma',
		],
		[
			'fennel',
			'sunchoke',
			'burrata',
			'tamarind',
			'sumac',
			'cassava',
			'farro',
			'durian',
			'romanesco',
			'chicory',
		],
		[
			'taciturn',
			'indelible',
			'verdant',
			'oblique',
			'incisive',
			'mellifluous',
			'crepuscular',
			'effulgent',
			'sinistral',
			'pellucid',
		],
	];

	for (const set of possibleDicts) {
		const text = linesToString(set);
		const back = stringToLines(text);

		expect(back).toStrictEqual(set);
	}
});

test('Can handle multiple newlines', () => {
	const dictText = 'worda\n\nwordb';

	expect(stringToLines(dictText)).toStrictEqual(['worda', 'wordb']);
});

test('Can handle carriage returns', () => {
	const dictText = 'worda\r\n\r\nwordb\r\nwordc';
	expect(stringToLines(dictText)).toStrictEqual(['worda', 'wordb', 'wordc']);
});



================================================
FILE: packages/obsidian-plugin/src/textUtils.ts
================================================
/** Converts the content of a text area to individual lines. */
export function stringToLines(s: string): string[] {
	return s
		.split('\n')
		.map((s) => s.trim())
		.filter((v) => v.length > 0);
}

/** Converts the content of a text area to viable dictionary values. */
export function linesToString(values: string[]): string {
	return values.map((v) => v.trim()).join('\n');
}



================================================
FILE: packages/vscode-plugin/README.md
================================================
# Harper for VS Code

Harper is the next-generation grammar checker for your code. You can think of it as an alternative to Grammarly. It catches common stylistic errors, as well as complex grammatical or layout-related problems. It works for almost [all common programming languages](https://writewithharper.com/docs/integrations/language-server#Supported-Languages) and a number of markup formats.

If you use Rust, Java, JavaScript, or any number of other programming languages, your comments may end up as part of your API's documentation. If that's the case, grammatical mistakes in your code could be down-ranking your site on search results and tarnishing your reputation for quality.

Most importantly, Harper runs on-device and uses barely any memory at all. That means you can get feedback on your work in milliseconds, dramatically increasing your iteration speed.

You can learn more about [this extension](https://writewithharper.com/docs/integrations/visual-studio-code) and [Harper](https://writewithharper.com/docs/about) over at our [official website](https://writewithharper.com).



================================================
FILE: packages/vscode-plugin/development-guide.md
================================================
# Development Guide

This document has been moved to the [official documentation](https://writewithharper.com/docs/contributors/visual-studio-code).



================================================
FILE: packages/vscode-plugin/esbuild.cjs
================================================
const esbuild = require('esbuild');

const production = process.argv.includes('--production');
const watch = process.argv.includes('--watch');

/**
 * @type {import('esbuild').Plugin}
 */
const esbuildProblemMatcherPlugin = {
	name: 'esbuild-problem-matcher',

	setup(build) {
		build.onStart(() => {
			console.log('[watch] build started');
		});
		build.onEnd((result) => {
			result.errors.forEach(({ text, location }) => {
				console.error(`✘ [ERROR] ${text}`);
				console.error(`    ${location.file}:${location.line}:${location.column}:`);
			});
			console.log('[watch] build finished');
		});
	},
};

async function main() {
	const ctx = await esbuild.context({
		entryPoints: ['src/extension.ts'],
		bundle: true,
		format: 'cjs',
		minify: production,
		sourcemap: !production,
		sourcesContent: false,
		platform: 'node',
		outfile: 'build/extension.js',
		external: ['vscode'],
		logLevel: 'silent',
		plugins: [
			/* Add to the end of plugins array */
			esbuildProblemMatcherPlugin,
		],
	});
	if (watch) {
		await ctx.watch();
	} else {
		await ctx.rebuild();
		await ctx.dispose();
	}
}

main().catch((e) => {
	console.error(e);
	process.exit(1);
});



================================================
FILE: packages/vscode-plugin/tsconfig.json
================================================
{
	"exclude": ["src/tests/fixtures"],
	"compilerOptions": {
		"module": "Node16",
		"target": "ES2022",
		"lib": ["ES2022", "DOM"],
		"sourceMap": true,
		"rootDir": "src",
		"outDir": "build",
		"strict": true,
		"skipLibCheck": true
	}
}



================================================
FILE: packages/vscode-plugin/.vscodeignore
================================================
**/**
!build/extension.js
!package.json
!LICENSE
!CHANGELOG.md
!bin
!icon.png
!media/



================================================
FILE: packages/vscode-plugin/media/harper.woff
================================================
[Binary file]


================================================
FILE: packages/vscode-plugin/src/extension.ts
================================================
import type { ExtensionContext, QuickPickItem, StatusBarItem } from 'vscode';
import { ConfigurationTarget, commands, StatusBarAlignment, Uri, window, workspace } from 'vscode';
import type { Executable, LanguageClientOptions } from 'vscode-languageclient/node';
import { LanguageClient, ResponseError, TransportKind } from 'vscode-languageclient/node';

// There's no publicly available extension manifest type except for the internal one from VS Code's
// codebase. So, we declare our own with only the fields we need and have. See:
// https://stackoverflow.com/a/78536803
type ExtensionManifest = {
	activationEvents: string[];
	contributes: { configuration: { properties: { [key: string]: object } } };
};

let client: LanguageClient | undefined;
const serverOptions: Executable = { command: '', transport: TransportKind.stdio };
const clientOptions: LanguageClientOptions = {
	middleware: {
		workspace: {
			async configuration(params, token, next) {
				const response = await next(params, token);

				if (response instanceof ResponseError) {
					return response;
				}

				return [{ 'harper-ls': response[0].harper }];
			},
		},
		executeCommand(command, args, next) {
			if (
				[
					'HarperAddToUserDict',
					'HarperAddToWSDict',
					'HarperAddToFileDict',
					'HarperIgnoreLint',
				].includes(command) &&
				args.find((a) => typeof a === 'string' && a.startsWith('untitled:'))
			) {
				window
					.showInformationMessage('Save the file to execute this command.', 'Save File', 'Dismiss')
					.then((selected) => {
						if (selected === 'Save File') {
							commands.executeCommand('workbench.action.files.save');
						}
					});
				return;
			}

			next(command, args);
		},
	},
};

let dialectStatusBarItem: StatusBarItem | undefined;

export async function activate(context: ExtensionContext): Promise<void> {
	serverOptions.command = getExecutablePath(context);

	let manifest: ExtensionManifest;
	try {
		manifest = JSON.parse(
			(await workspace.fs.readFile(Uri.joinPath(context.extensionUri, 'package.json'))).toString(),
		);
	} catch (error) {
		showError('Failed to read manifest file', error);
		return;
	}

	clientOptions.documentSelector = manifest.activationEvents
		.filter((e) => e.startsWith('onLanguage:'))
		.flatMap((e) => {
			const language = e.split(':')[1];
			return [
				{ language, scheme: 'file' },
				{ language, scheme: 'untitled' },
			];
		});

	clientOptions.outputChannel = window.createOutputChannel('Harper');
	context.subscriptions.push(clientOptions.outputChannel);

	const configs = Object.keys(manifest.contributes.configuration.properties);
	context.subscriptions.push(
		workspace.onDidChangeConfiguration(async (event) => {
			if (event.affectsConfiguration('harper.path')) {
				serverOptions.command = getExecutablePath(context);
				await startLanguageServer();
				return;
			}

			if (configs.find((c) => event.affectsConfiguration(c))) {
				await client?.sendNotification('workspace/didChangeConfiguration', {
					settings: { 'harper-ls': workspace.getConfiguration('harper') },
				});
			}
		}),
	);

	context.subscriptions.push(
		commands.registerCommand('harper.languageserver.restart', startLanguageServer),
	);

	context.subscriptions.push(commands.registerCommand('harper.changeDialect', changeDialect));

	await startLanguageServer();

	// VS Code:
	// <= 100 is between Copilot and Notifications.
	// 101..102 is between the magnifying glass and encoding
	// >= 103 is left of the magnifying glass
	// Windsurf:
	// 100 is just to the right of programming language - perfect!
	// 101 is left of line/column
	dialectStatusBarItem = window.createStatusBarItem(StatusBarAlignment.Right, 100);
	dialectStatusBarItem.tooltip = 'Harper English dialect';
	dialectStatusBarItem.command = 'harper.changeDialect';
	context.subscriptions.push(dialectStatusBarItem);

	context.subscriptions.push(
		workspace.onDidChangeConfiguration(async (event) => {
			if (event.affectsConfiguration('harper.dialect')) {
				updateDialectStatusBar();
			}
		}),
	);

	updateDialectStatusBar();
}

function getExecutablePath(context: ExtensionContext): string {
	const path = workspace.getConfiguration('harper').get<string>('path', '');

	if (path !== '') {
		return path;
	}

	return Uri.joinPath(
		context.extensionUri,
		'bin',
		`harper-ls${process.platform === 'win32' ? '.exe' : ''}`,
	).fsPath;
}

async function startLanguageServer(): Promise<void> {
	if (client?.needsStop()) {
		if (client.diagnostics) {
			client.diagnostics.clear();
		}

		try {
			await client.stop(2000);
		} catch (error) {
			showError('Failed to stop harper-ls', error);
			return;
		}
	}

	try {
		client = new LanguageClient('harper', 'Harper', serverOptions, clientOptions);
		await client.start();
	} catch (error) {
		showError('Failed to start harper-ls', error);
		client = undefined;
	}
}

function showError(message: string, error: Error | unknown): void {
	let info = '';
	if (error instanceof Error) {
		info = error.stack ? error.stack : error.message;
	}

	window.showErrorMessage(message, 'Show Info', 'Dismiss').then((selected) => {
		if (selected === 'Show Info') {
			clientOptions.outputChannel?.appendLine('---');
			clientOptions.outputChannel?.appendLine(message);
			clientOptions.outputChannel?.appendLine(info);
			clientOptions.outputChannel?.appendLine(
				'If the issue persists, please report at https://github.com/automattic/harper/issues',
			);
			clientOptions.outputChannel?.appendLine('---');
			clientOptions.outputChannel?.show();
		}
	});
}

function updateDialectStatusBar(): void {
	if (!dialectStatusBarItem) return;

	const dialect = workspace.getConfiguration('harper').get<string>('dialect', '');
	if (dialect === '') return;

	const flagAndCode = getFlagAndCode(dialect);
	if (!flagAndCode) return;

	dialectStatusBarItem.text = `$(harper-logo) ${flagAndCode.join(' ')}`;
	dialectStatusBarItem.show();
	console.log(`** dialect set to ${dialect} **`, dialect);
}

async function changeDialect(): Promise<void> {
	const dialectNames = ['American', 'British', 'Australian', 'Canadian', 'Indian'];
	const dialects: QuickPickItem[] = dialectNames.map((name) => ({
		label: name,
	}));

	const selected = await window.showQuickPick(dialects, {
		placeHolder: 'Select Harper dialect',
	});

	if (selected && typeof selected !== 'string') {
		await workspace
			.getConfiguration('harper')
			.update('dialect', selected.label, ConfigurationTarget.Global);
	}
}

export function deactivate(): Thenable<void> | undefined {
	if (!client) {
		return undefined;
	}

	return client.stop();
}

function getFlagAndCode(dialect: string): string[] | undefined {
	return {
		American: ['🇺🇸', 'US'],
		Australian: ['🇦🇺', 'AU'],
		British: ['🇬🇧', 'GB'],
		Canadian: ['🇨🇦', 'CA'],
		Indian: ['🇮🇳', 'IN'],
	}[dialect];
}



================================================
FILE: packages/vscode-plugin/src/tests/runTests.ts
================================================
import path from 'node:path';
import { runTests } from '@vscode/test-electron';

(async () => {
	try {
		await runTests({
			extensionDevelopmentPath: path.join(__dirname, '..', '..'),
			extensionTestsPath: path.join(__dirname, 'suite'),
			launchArgs: [
				'--disable-extensions',
				path.join(__dirname, '..', '..', 'src', 'tests', 'fixtures'),
			],
		});
	} catch (error) {
		console.error('Failed to run tests', error);
		process.exit(1);
	}
})();



================================================
FILE: packages/vscode-plugin/src/tests/fixtures/integration.md
================================================
# Integration

This sentence has grammar errorz, like this this one.

On the other hand, you'll realise that this sentence doesn't have an error if you're using British English.



================================================
FILE: packages/vscode-plugin/src/tests/fixtures/languages/c.c
================================================
#include <stdio.h>

// Errorz
int main() {
  printf("Hello World!\n");
  return 0;
}



================================================
FILE: packages/vscode-plugin/src/tests/fixtures/languages/CMakeLists.txt
================================================
cmake_minimum_required(VERSION 3.10)
project(HelloWorld)
add_executable(HelloWorld #[[ Errorz ]] cpp.cpp)


================================================
FILE: packages/vscode-plugin/src/tests/fixtures/languages/cpp.cpp
================================================
import module std;

int main() {
  /* Errorz */
  std::print("Hello World!\n");
}



================================================
FILE: packages/vscode-plugin/src/tests/fixtures/languages/cpp.h
================================================
// Errorz


================================================
FILE: packages/vscode-plugin/src/tests/fixtures/languages/csharp.cs
================================================
/*

		Errorz

*/
System.Console.WriteLine("Hello World!");



================================================
FILE: packages/vscode-plugin/src/tests/fixtures/languages/dart.dart
================================================
void main() { /*
                             Errorz
 */
  print("Hello, World!");
}



================================================
FILE: packages/vscode-plugin/src/tests/fixtures/languages/git-commit
================================================
Errorz

# Please enter the commit message for your changes. Lines starting
# with '#' will be ignored, and an empty message aborts the commit.
#
# On branch main
# Changes to be committed:
#       modified:   hello-world
#



================================================
FILE: packages/vscode-plugin/src/tests/fixtures/languages/go.go
================================================
package main

import "fmt"

//		Errorz
func main() {
	fmt.Println("Hello World!")
}



================================================
FILE: packages/vscode-plugin/src/tests/fixtures/languages/haskell.hs
================================================
main :: IO ()
-- Errorz
main = putStrLn "Hello World!"



================================================
FILE: packages/vscode-plugin/src/tests/fixtures/languages/html.html
================================================
<!doctype html>
<html lang="en">
	<head>
		<meta charset="UTF-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1.0" />
		<title>Hello World!</title>
	</head>
	<body>
		<h1>Errorz</h1>
	</body>
</html>



================================================
FILE: packages/vscode-plugin/src/tests/fixtures/languages/java.java
================================================
public class HelloWorld {
  /**
   * @param args Errorz
   */
  public static void main(String[] args) {
    System.out.println("Hello World!");
  }
}



================================================
FILE: packages/vscode-plugin/src/tests/fixtures/languages/javascript.js
================================================
console.log('Hello World!');
// Errorz



================================================
FILE: packages/vscode-plugin/src/tests/fixtures/languages/javascriptreact.jsx
================================================
/**
 * @param {{message: string}} props Errorz
 */
export default function Main(props = { message: 'Hello World!' }) {
	return <h1>{props.message}</h1>;
}



================================================
FILE: packages/vscode-plugin/src/tests/fixtures/languages/literate-haskell.lhs
================================================
\begin{code}
main :: IO ()
main = putStrLn "Hello World!"
\end{code}

Errorz




================================================
FILE: packages/vscode-plugin/src/tests/fixtures/languages/lua.lua
================================================
print "Hello World!" -- Errorz


================================================
FILE: packages/vscode-plugin/src/tests/fixtures/languages/nix.nix
================================================
"Hello World!"
# Errorz



================================================
FILE: packages/vscode-plugin/src/tests/fixtures/languages/php.php
================================================
<?php

echo "Hello World!"; //        Errorz


================================================
FILE: packages/vscode-plugin/src/tests/fixtures/languages/plaintext
================================================
Errorz


================================================
FILE: packages/vscode-plugin/src/tests/fixtures/languages/plaintext.txt
================================================




Errorz



================================================
FILE: packages/vscode-plugin/src/tests/fixtures/languages/python.py
================================================
print("Hello World!")
# Errorz


================================================
FILE: packages/vscode-plugin/src/tests/fixtures/languages/ruby.rb
================================================
puts "Hello World!" =begin


                Errorz


=end


================================================
FILE: packages/vscode-plugin/src/tests/fixtures/languages/rust.rs
================================================
/// Errorz
fn main() {
  println!("Hello World!");
}



================================================
FILE: packages/vscode-plugin/src/tests/fixtures/languages/shellscript
================================================
#!/usr/bin/env bash

echo "Hello World!"
# Errorz



================================================
FILE: packages/vscode-plugin/src/tests/fixtures/languages/shellscript.bash
================================================
echo "Hello World!"






#        Errorz



================================================
FILE: packages/vscode-plugin/src/tests/fixtures/languages/shellscript.sh
================================================
echo "Hello World!" # Errorz



================================================
FILE: packages/vscode-plugin/src/tests/fixtures/languages/solidity.sol
================================================
// SPDX-License-Identifier: UNLICENSED
pragma solidity ^0.8.20;

/// Errorz
contract Test {
    uint256 internal test;
}



================================================
FILE: packages/vscode-plugin/src/tests/fixtures/languages/swift.swift
================================================









                       // Errorz











print("Hello, World!")


================================================
FILE: packages/vscode-plugin/src/tests/fixtures/languages/toml.toml
================================================
[hello-world]
# Errorz
output = "Hello World!"



================================================
FILE: packages/vscode-plugin/src/tests/fixtures/languages/typescript.ts
================================================
console.log('Hello World!'); // Errorz



================================================
FILE: packages/vscode-plugin/src/tests/fixtures/languages/typescriptreact.tsx
================================================
export default function Main({ message = 'Hello World!' }: { message: string }) {
	return (
		<h1>
			{/* Errorz */}
			{message}
		</h1>
	);
}



================================================
FILE: packages/vscode-plugin/src/tests/fixtures/languages/typst.typ
================================================
= Title

*Errorz*




================================================
FILE: packages/vscode-plugin/src/tests/suite/helper.ts
================================================
import type { Diagnostic, Extension } from 'vscode';

import {
	DiagnosticSeverity,
	extensions,
	languages,
	Position,
	Range,
	Uri,
	window,
	workspace,
} from 'vscode';

export async function closeAll(): Promise<void> {
	for (const tabGroup of window.tabGroups.all) {
		await window.tabGroups.close(tabGroup);
	}
}

export async function activateHarper(): Promise<Extension<void>> {
	const harper = extensions.getExtension('elijah-potter.harper')!;

	if (!harper.isActive) {
		await harper.activate();
	}

	return harper;
}

export function getUri(...pathSegments: string[]): Uri {
	return Uri.joinPath(Uri.file(workspace.workspaceFolders![0].uri.path), ...pathSegments);
}

export async function openUri(uri: Uri): Promise<void> {
	await window.showTextDocument(await workspace.openTextDocument(uri));
}

export async function openUntitled(text: string): Promise<Uri> {
	const document = await workspace.openTextDocument();
	const editor = await window.showTextDocument(document);
	await editor.edit((editBuilder) => editBuilder.insert(new Position(0, 0), text));
	return document.uri;
}

export async function setTextDocumentLanguage(uri: Uri, languageId: string): Promise<void> {
	const document = await workspace.openTextDocument(uri);
	await languages.setTextDocumentLanguage(document, languageId);
}

export function createExpectedDiagnostics(
	...data: { message: string; range: Range; source: string; code: string }[]
): Diagnostic[] {
	return data.map((d) => ({ ...d, severity: DiagnosticSeverity.Information }));
}

export function compareActualVsExpectedDiagnostics(
	actual: Diagnostic[],
	expected: Diagnostic[],
): void {
	if (actual.length !== expected.length) {
		throw new Error(`Expected ${expected.length} diagnostics, got ${actual.length}.`);
	}

	for (let i = 0; i < actual.length; i++) {
		expect(actual[i].source).toBe(expected[i].source);
		expect(actual[i].message).toBe(expected[i].message);
		expect(actual[i].severity).toBe(expected[i].severity);
		expect(actual[i].range).toEqual(expected[i].range);
	}
}

export function createRange(
	startRow: number,
	startColumn: number,
	endRow: number,
	endColumn: number,
): Range {
	return new Range(new Position(startRow, startColumn), new Position(endRow, endColumn));
}

function getActualDiagnostics(resource: Uri): Diagnostic[] {
	return languages.getDiagnostics(resource).filter((d) => d.source?.includes('Harper'));
}

/** Note that this function times out if there is no change detected. */
export function waitForDiagnosticsChange(
	uri: Uri,
	func?: () => Promise<void>,
): Promise<Diagnostic[]> {
	return new Promise((resolve, reject) => {
		const before = func ? getActualDiagnostics(uri) : [];

		(func || (async () => {}))().then(() => {
			const delay = 50;
			const limit = 20;
			let counter = 0;

			const tryCompare = () => {
				const after = getActualDiagnostics(uri);
				try {
					compareActualVsExpectedDiagnostics(before, after);

					// after didn't change, try again
					counter = 0;
					tryAgain();
				} catch (e) {
					// after did change, try until stabilized
					counter++;
					if (counter < limit) {
						tryAgain();
					} else {
						clearTimeout(rejectTimer);
						resolve(after);
					}
				}
			};
			let tryTimer = setTimeout(tryCompare);
			const tryAgain = () => {
				tryTimer = setTimeout(tryCompare, delay);
			};

			const rejectTimer = setTimeout(() => {
				clearTimeout(tryTimer);
				reject('No change of diagnostics detected.');
			}, 4000);
		});
	});
}



================================================
FILE: packages/vscode-plugin/src/tests/suite/index.ts
================================================
import path from 'node:path';
import Jasmine from 'jasmine';

export async function run(): Promise<void> {
	const jasmine = new Jasmine();
	jasmine.exitOnCompletion = false;
	jasmine.loadConfig({
		spec_dir: path.relative(process.cwd(), __dirname),
		spec_files: ['*.test.js'],
		random: false,
	});

	const result = await jasmine.execute();
	if (result.overallStatus !== 'passed') {
		throw new Error('Tests failed');
	}
}



================================================
FILE: packages/vscode-plugin/src/tests/suite/integration.test.ts
================================================
import type { Extension, Uri } from 'vscode';

import { ConfigurationTarget, commands, workspace } from 'vscode';

import {
	activateHarper,
	closeAll,
	compareActualVsExpectedDiagnostics,
	createExpectedDiagnostics,
	createRange,
	getUri,
	openUntitled,
	openUri,
	setTextDocumentLanguage,
	waitForDiagnosticsChange,
} from './helper';

describe('Integration >', () => {
	let harper: Extension<void>;
	let markdownUri: Uri;

	beforeAll(async () => {
		await closeAll();
		harper = await activateHarper();
		markdownUri = getUri('integration.md');
		await openUri(markdownUri);
	});

	it('runs', () => {
		expect(harper.isActive).toBe(true);
	});

	it('gives correct diagnostics for files', async () => {
		compareActualVsExpectedDiagnostics(
			await waitForDiagnosticsChange(markdownUri),
			createExpectedDiagnostics(
				{
					message: 'Did you mean to repeat this word?',
					range: createRange(2, 39, 2, 48),
					source: 'Harper',
					code: 'RepeatedWords',
				},
				{
					message: 'Did you mean to spell `errorz` this way?',
					range: createRange(2, 26, 2, 32),
					source: 'Harper',
					code: 'SpellCheck',
				},
				{
					message: 'Did you mean to spell `realise` this way?',
					range: createRange(4, 26, 4, 33),
					source: 'Harper',
					code: 'SpellCheck',
				},
			),
		);
	});

	it('gives correct diagnostics for untitled', async () => {
		const untitledUri = await openUntitled('Errorz');

		compareActualVsExpectedDiagnostics(
			await waitForDiagnosticsChange(untitledUri),
			createExpectedDiagnostics({
				message: 'Did you mean to spell `Errorz` this way?',
				range: createRange(0, 0, 0, 6),
				source: 'Harper',
				code: 'SpellCheck',
			}),
		);
	});

	it('gives correct diagnostics when language is changed', async () => {
		const untitledUri = await openUntitled('Errorz # Errorz');

		compareActualVsExpectedDiagnostics(
			await waitForDiagnosticsChange(
				untitledUri,
				async () => await setTextDocumentLanguage(untitledUri, 'plaintext'),
			),
			createExpectedDiagnostics(
				{
					message: 'Did you mean to spell `Errorz` this way?',
					range: createRange(0, 0, 0, 6),
					source: 'Harper',
					code: 'SpellCheck',
				},
				{
					message: 'Did you mean to spell `Errorz` this way?',
					range: createRange(0, 9, 0, 15),
					source: 'Harper',
					code: 'SpellCheck',
				},
			),
		);

		compareActualVsExpectedDiagnostics(
			await waitForDiagnosticsChange(
				untitledUri,
				async () => await setTextDocumentLanguage(untitledUri, 'shellscript'),
			),
			createExpectedDiagnostics({
				message: 'Did you mean to spell `Errorz` this way?',
				range: createRange(0, 9, 0, 15),
				source: 'Harper',
				code: 'SpellCheck',
			}),
		);
	});

	it('updates diagnostics on configuration change', async () => {
		const config = workspace.getConfiguration('harper.linters');

		compareActualVsExpectedDiagnostics(
			await waitForDiagnosticsChange(
				markdownUri,
				async () => await config.update('RepeatedWords', false, ConfigurationTarget.Workspace),
			),
			createExpectedDiagnostics(
				{
					message: 'Did you mean to spell `errorz` this way?',
					range: createRange(2, 26, 2, 32),
					source: 'Harper',
					code: 'SpellCheck',
				},
				{
					message: 'Did you mean to spell `realise` this way?',
					range: createRange(4, 26, 4, 33),
					source: 'Harper',
					code: 'SpellCheck',
				},
			),
		);

		// Set config back to default value
		await waitForDiagnosticsChange(
			markdownUri,
			async () => await config.update('RepeatedWords', true, ConfigurationTarget.Workspace),
		);
	});

	it('accepts British spellings when dialect is set to British', async () => {
		const config = workspace.getConfiguration('harper');

		compareActualVsExpectedDiagnostics(
			await waitForDiagnosticsChange(
				markdownUri,
				async () => await config.update('dialect', 'British', ConfigurationTarget.Workspace),
			),
			createExpectedDiagnostics(
				{
					message: 'Did you mean to repeat this word?',
					range: createRange(2, 39, 2, 48),
					source: 'Harper',
					code: 'RepeatedWords',
				},
				{
					message: 'Did you mean to spell `errorz` this way?',
					range: createRange(2, 26, 2, 32),
					source: 'Harper',
					code: 'SpellCheck',
				},
			),
		);

		// Set config back to default value
		await waitForDiagnosticsChange(
			markdownUri,
			async () => await config.update('dialect', 'American', ConfigurationTarget.Workspace),
		);
	});

	it('excludes Markdown files when excludePatterns include *.md', async () => {
		const config = workspace.getConfiguration('harper');

		compareActualVsExpectedDiagnostics(
			await waitForDiagnosticsChange(markdownUri, async () => {
				await config.update('excludePatterns', ['*.md'], ConfigurationTarget.Workspace);
			}),
			createExpectedDiagnostics(),
		);

		await waitForDiagnosticsChange(markdownUri, async () => {
			// Set config back to default value
			await config.update('excludePatterns', [], ConfigurationTarget.Workspace);

			// Ideally, we can just execute `workbench.action.closeActiveEditor` then
			// `workbench.action.reopenClosedEditor` here and the diagnostics should reset since that
			// works when done manually as that triggers `textDocument/didOpen`, but when done automated,
			// it won't work. So, we delete, restore, then reopen the file instead.
			const markdownContent = await workspace.fs.readFile(markdownUri);
			await commands.executeCommand('workbench.files.action.showActiveFileInExplorer');
			await commands.executeCommand('deleteFile');
			await workspace.fs.writeFile(markdownUri, markdownContent);
			await openUri(markdownUri);
		});
	});

	it('updates diagnostics when files are deleted', async () => {
		const markdownContent = await workspace.fs.readFile(markdownUri);

		// Delete file through VS Code
		await commands.executeCommand('workbench.files.action.showActiveFileInExplorer');

		compareActualVsExpectedDiagnostics(
			await waitForDiagnosticsChange(
				markdownUri,
				async () => await commands.executeCommand('deleteFile'),
			),
			createExpectedDiagnostics(),
		);

		// Restore and reopen deleted file
		await workspace.fs.writeFile(markdownUri, markdownContent);
		await waitForDiagnosticsChange(markdownUri, async () => await openUri(markdownUri));

		// Delete file directly
		compareActualVsExpectedDiagnostics(
			await waitForDiagnosticsChange(
				markdownUri,
				async () => await workspace.fs.delete(markdownUri),
			),
			createExpectedDiagnostics(),
		);

		// Restore and reopen deleted file
		await workspace.fs.writeFile(markdownUri, markdownContent);
	});
});



================================================
FILE: packages/vscode-plugin/src/tests/suite/languages.test.ts
================================================
import {
	compareActualVsExpectedDiagnostics,
	createExpectedDiagnostics,
	createRange,
	getUri,
	openUri,
	waitForDiagnosticsChange,
} from './helper';

describe('Languages >', () => {
	// NOTE: There's no need to activate Harper here since it was already activated in
	// `integration.test.ts`, which runs first.

	[
		// Uncomment when #265 is fixed.
		// { type: 'JavaScript JSX', file: 'javascriptreact.jsx', row: 1, column: 36 },

		// VS Code doesn't support CMake, Haskell, Literate Haskell, Nix, Solidity, TOML, and Typst files out of
		// the box. Uncomment when you figure out how to support them during testing.
		// { type: 'CMake', file: 'CMakeLists.txt', row: 2, column: 30 },
		// { type: 'Haskell', file: 'haskell.hs', row: 1, column: 3 },
		// { type: 'Literate Haskell', file: 'literate-haskell.lhs', row: 5, column: 0 },
		// { type: 'Nix', file: 'nix.nix', row: 1, column: 2 },
		// { type: 'TOML', file: 'toml.toml', row: 1, column: 2 },
		// { type: 'Typst', file: 'typst.typ', row: 2, column: 1 },
		// { type: 'Solidity', file: 'solidity.sol', row: 3, column: 4 },

		{ type: 'C', file: 'c.c', row: 2, column: 3 },
		{ type: 'C++', file: 'cpp.cpp', row: 3, column: 5 },
		{ type: 'H', file: 'cpp.h', row: 0, column: 3 },
		{ type: 'C#', file: 'csharp.cs', row: 2, column: 2 },
		{ type: 'Dart', file: 'dart.dart', row: 1, column: 29 },
		{ type: 'Git Commit', file: 'git-commit', row: 0, column: 0 },
		{ type: 'Go', file: 'go.go', row: 4, column: 4 },
		{ type: 'HTML', file: 'html.html', row: 8, column: 6 },
		{ type: 'Java', file: 'java.java', row: 2, column: 17 },
		{ type: 'JavaScript', file: 'javascript.js', row: 1, column: 3 },
		{ type: 'Lua', file: 'lua.lua', row: 0, column: 24 },
		{ type: 'PHP', file: 'php.php', row: 2, column: 31 },
		{ type: 'Plaintext without extension', file: 'plaintext', row: 0, column: 0 },
		{ type: 'Plaintext with extension', file: 'plaintext.txt', row: 4, column: 0 },
		{ type: 'Python', file: 'python.py', row: 1, column: 2 },
		{ type: 'Ruby', file: 'ruby.rb', row: 3, column: 16 },
		{ type: 'Rust', file: 'rust.rs', row: 0, column: 4 },
		{ type: 'Shellscript without extension', file: 'shellscript', row: 3, column: 2 },
		{ type: 'Shellscript with .bash extension', file: 'shellscript.bash', row: 7, column: 9 },
		{ type: 'Shellscript with .sh extension', file: 'shellscript.sh', row: 0, column: 22 },
		{ type: 'Swift', file: 'swift.swift', row: 9, column: 26 },
		{ type: 'TypeScript', file: 'typescript.ts', row: 0, column: 32 },
		{ type: 'TypeScript JSX', file: 'typescriptreact.tsx', row: 3, column: 7 },
	].forEach((testCase) => {
		it(`gives correct diagnostics for ${testCase.type} files`, async () => {
			const uri = getUri('languages', testCase.file);

			compareActualVsExpectedDiagnostics(
				await waitForDiagnosticsChange(uri, async () => await openUri(uri)),
				createExpectedDiagnostics({
					message: 'Did you mean to spell `Errorz` this way?',
					range: createRange(testCase.row, testCase.column, testCase.row, testCase.column + 6),
					source: 'Harper',
					code: 'SpellCheck',
				}),
			);
		});
	});
});



================================================
FILE: packages/web/README.md
================================================
# Web

This directory contains the source code for [https://writewithharper.com].

## Building

In order to build the site, you must first compile `harper-wasm` with:

```bash
wasm-pack build --target bundler
```



================================================
FILE: packages/web/demo_wp_blueprint.json
================================================
{
	"$schema": "https://playground.wordpress.net/blueprint-schema.json",
	"preferredVersions": {
		"php": "8.0",
		"wp": "6.7"
	},
	"meta": {
		"title": "Demo of Harper for WordPress",
		"description": "Harper is a grammar checker for people who want to write, without any fuss.",
		"author": "elijah-potter",
		"categories": []
	},
	"landingPage": "/wp-admin/post.php?post=4&action=edit",
	"steps": [
		{
			"step": "login",
			"username": "admin",
			"password": "password"
		},
		{
			"step": "installPlugin",
			"pluginData": {
				"resource": "url",
				"url": "https://github.com/Automattic/harper/releases/download/v0.27.0/harper.zip"
			},
			"options": {
				"activate": true
			}
		},
		{
			"step": "installTheme",
			"themeData": {
				"resource": "wordpress.org/themes",
				"slug": "twentytwentyfour"
			}
		},
		{
			"step": "runPHP",
			"code": "<?php require_once 'wordpress/wp-load.php'; wp_insert_post(array('post_title' => 'Harper, in WordPress', 'post_content' => '<!-- wp:paragraph --><p><strong>Click on the Harper button on the top right of this page to get started.</strong></p><!-- /wp:paragraph --><!-- wp:paragraph --><p>Writing on the web can be scary. Theres a lot of competition for traffic and even a small grammatical mstake can be costly to your reputation and search rankings.</p><!-- /wp:paragraph --><!-- wp:paragraph --><p>That\\'s why we created Harper: an plugin to save you the embarassment. it can fix typos, serial commas and overall just make your life better.</p><!-- /wp:paragraph --><!-- wp:paragraph --><p>All that while respecting your privacy. You data should never leave Wordpress until you hit \"Publish\".</p><!-- /wp:paragraph -->'));"
		}
	]
}



================================================
FILE: packages/web/drizzle.config.ts
================================================
import { defineConfig } from 'drizzle-kit';

export default defineConfig({
	out: './drizzle',
	schema: './src/lib/db/schema.ts',
	dialect: 'mysql',
	dbCredentials: {
		url: process.env.DATABASE_URL!,
	},
});



================================================
FILE: packages/web/package.json
================================================
{
	"name": "harper-web",
	"version": "0.0.1",
	"private": true,
	"scripts": {
		"dev": "vite dev",
		"build": "vite build -l warn",
		"preview": "vite preview",
		"check": "svelte-kit sync && svelte-check --tsconfig ./tsconfig.json",
		"check:watch": "svelte-kit sync && svelte-check --tsconfig ./tsconfig.json --watch",
		"start": "node build"
	},
	"devDependencies": {
		"@sveltejs/adapter-node": "^5.2.12",
		"@sveltejs/kit": "^2.37.1",
		"@sveltejs/vite-plugin-svelte": "^5.0.3",
		"@tailwindcss/vite": "^4.1.4",
		"@types/reveal.js": "^5.0.3",
		"autoprefixer": "^10.4.21",
		"drizzle-kit": "^0.31.5",
		"flowbite": "^3.1.2",
		"svelte": "^5.15.0",
		"svelte-check": "^4.1.5",
		"tailwindcss": "^4.1.16",
		"tslib": "catalog:",
		"tsx": "^4.20.6",
		"typescript": "catalog:",
		"vite": "^6.1.0",
		"vite-plugin-top-level-await": "^1.5.0",
		"vite-plugin-wasm": "^3.4.1"
	},
	"type": "module",
	"dependencies": {
		"@sveltepress/theme-default": "^5.0.7",
		"@sveltepress/vite": "^1.1.5",
		"chart.js": "^4.4.8",
		"components": "workspace:*",
		"drizzle-orm": "^0.44.6",
		"drizzle-zod": "^0.8.3",
		"harper.js": "workspace:*",
		"lint-framework": "workspace:*",
		"lodash-es": "^4.17.21",
		"mysql2": "^3.15.2",
		"posthog-js": "^1.245.1",
		"quill": "^2.0.3",
		"reveal.js": "^5.1.0",
		"svelte-intersection-observer": "^1.0.0",
		"typed.js": "^2.1.0",
		"zod": "^4.1.12"
	}
}



================================================
FILE: packages/web/svelte.config.js
================================================
import adapter from '@sveltejs/adapter-node';
import { vitePreprocess } from '@sveltejs/vite-plugin-svelte';

/** @type {import('@sveltejs/kit').Config} */
const config = {
	extensions: ['.svelte', '.md'],
	preprocess: vitePreprocess(),
	kit: {
		csrf: {
			trustedOrigins: [
				'chrome-extension://lodbfhdipoipcjmlebjbgmmgekckhpfb',
				'chrome-extension://hkjdmakdmihopipoiplebkelbhebigea',
				'chrome-extension://ihjkkjfembmnjldmdchmadigpmapkpdh',
			],
		},
		prerender: {
			entries: [],
		},
		adapter: adapter({
			out: 'build',
		}),
	},
};

export default config;



================================================
FILE: packages/web/tailwind.config.js
================================================
export default {
	content: ['./src/**/*.{html,js,svelte,ts}', './node_modules/components/**/*.{html,js,svelte,ts}'],
	plugins: [],
};



================================================
FILE: packages/web/tsconfig.json
================================================
{
	"extends": "./.svelte-kit/tsconfig.json",
	"compilerOptions": {
		"allowJs": true,
		"checkJs": true,
		"esModuleInterop": true,
		"forceConsistentCasingInFileNames": true,
		"resolveJsonModule": true,
		"skipLibCheck": true,
		"sourceMap": true,
		"strict": true
	}
	// Path aliases are handled by https://kit.svelte.dev/docs/configuration#alias
	//
	// If you want to overwrite includes/excludes, make sure to copy over the relevant includes/excludes
	// from the referenced tsconfig.json - TypeScript does not merge them in
}



================================================
FILE: packages/web/vite.config.ts
================================================
import tailwindcss from '@tailwindcss/vite';
import { defineConfig } from 'vite';
import topLevelAwait from 'vite-plugin-top-level-await';
import wasm from 'vite-plugin-wasm';

const prod = process.env.APP_ENV === 'production';

export default defineConfig(async () => {
	const [{ defaultTheme }, { sveltepress }] = await Promise.all([
		import('@sveltepress/theme-default'),
		import('@sveltepress/vite'),
	]);

	return {
		ssr: {
			noExternal: prod ? ['mysql2', 'drizzle-orm', 'posthog-js', 'drizzle-zod', 'zod'] : [],
		},
		server: {
			port: 3000,
			fs: {
				allow: ['../harper.js/dist'],
			},
		},
		plugins: [
			sveltepress({
				siteConfig: {
					title: 'Harper: The Private Grammar Checker',
					description: 'The Free Grammar Checker That Respects Your Privacy',
				},
				theme: defaultTheme({
					editLink:
						'https://github.com/automattic/harper/edit/master/packages/web/src/routes/:route',
					logo: '/circle-logo.png',
					github: 'https://github.com/automattic/harper',
					discord: 'https://discord.gg/invite/JBqcAaKrzQ',
					themeColor: {
						primary: '#f1920e',
						dark: '#301d03',
						gradient: {
							start: '#355280',
							end: '#818eae',
						},
					},
					navbar: [
						{ title: 'Documentation', to: '/docs/about' },
						{ title: 'Obsidian', to: '/docs/integrations/obsidian' },
						{
							title: 'Chrome Extension',
							to: 'https://chromewebstore.google.com/detail/private-grammar-checking/lodbfhdipoipcjmlebjbgmmgekckhpfb',
						},
					],
					docsearch: {
						indexName: 'Documentation',
						appId: 'YIV4D9QMR0',
						apiKey: 'ff521ad7f129e4f4defe97dce3c923ad',
					},
					sidebar: {
						'/docs/': [
							{
								items: [
									{
										title: 'About',
										to: '/docs/about',
									},
								],
							},
							{
								items: [
									{
										title: 'Weir',
										to: '/docs/weir',
									},
								],
							},
							{
								title: 'Integrations',
								items: [
									{
										title: 'Obsidian',
										to: '/docs/integrations/obsidian',
									},
									{
										title: 'Chrome Extension',
										to: '/docs/integrations/chrome-extension',
									},
									{
										title: 'Firefox Extension',
										to: '/docs/integrations/firefox-extension',
									},
									{
										title: 'WordPress',
										to: '/docs/integrations/wordpress',
									},
									{
										title: 'Language Server',
										to: '/docs/integrations/language-server',
									},
									{
										title: 'Visual Studio Code',
										to: '/docs/integrations/visual-studio-code',
									},
									{
										title: 'Neovim',
										to: '/docs/integrations/neovim',
									},
									{
										title: 'Helix',
										to: '/docs/integrations/helix',
									},
									{
										title: 'Emacs',
										to: '/docs/integrations/emacs',
									},
									{
										title: 'Zed',
										to: '/docs/integrations/zed',
									},
									{
										title: 'Sublime Text',
										to: '/docs/integrations/sublime-text',
									},
								],
							},
							{
								title: 'harper.js',
								items: [
									{
										title: 'Introduction',
										to: '/docs/harperjs/introduction',
									},
									{
										title: 'Linting',
										to: '/docs/harperjs/linting',
									},
									{
										title: 'Spans',
										to: '/docs/harperjs/spans',
									},
									{
										title: 'Configure Rules',
										to: '/docs/harperjs/configurerules',
									},
									{
										title: 'Node.js',
										to: '/docs/harperjs/node',
									},
									{
										title: 'CDN',
										to: '/docs/harperjs/CDN',
									},
									{
										title: 'API Reference',
										to: '/docs/harperjs/ref/index.html',
									},
								],
							},
							{
								title: 'Contributors',
								items: [
									{
										title: 'Introduction',
										to: '/docs/contributors/introduction',
									},
									{
										title: 'Environment',
										to: '/docs/contributors/environment',
									},
									{
										title: 'Committing',
										to: '/docs/contributors/committing',
									},
									{
										title: 'Architecture',
										to: '/docs/contributors/architecture',
									},
									{
										title: 'Dictionary',
										to: '/docs/contributors/dictionary',
									},
									{
										title: 'Test Suite',
										to: '/docs/contributors/tests',
									},
									{
										title: 'Author a Rule',
										to: '/docs/contributors/author-a-rule',
									},
									{
										title: 'Visual Studio Code',
										to: '/docs/contributors/visual-studio-code',
									},
									{
										title: 'Chrome Extension',
										to: '/docs/contributors/chrome-extension',
									},
									{
										title: 'WordPress',
										to: '/docs/contributors/wordpress',
									},
									{
										title: 'Obsidian',
										to: '/docs/contributors/obsidian',
									},
									{
										title: 'Reviewing Pull Requests',
										to: '/docs/contributors/review',
									},
									{
										title: 'Local Statistics',
										to: '/docs/contributors/local-stats',
									},
									{
										title: 'Brill Tagging',
										to: '/docs/contributors/brill',
									},
									{
										title: 'FAQ',
										to: '/docs/contributors/faq',
									},
								],
							},
							{
								title: 'Rust Reference',
								to: 'https://docs.rs/harper-core/latest/harper_core/',
							},
							{
								title: 'Rules',
								to: '/docs/rules',
							},
						],
					},
					highlighter: {
						languages: [
							'svelte',
							'sh',
							'js',
							'html',
							'ts',
							'md',
							'css',
							'scss',
							'toml',
							'rust',
							'lua',
							'json',
							'elisp',
						],
					},
				}),
			}),
			wasm(),
			topLevelAwait(),
			tailwindcss(),
		],
	};
});



================================================
FILE: packages/web/.dockerignore
================================================
.DS_Store
node_modules
/build
/.svelte-kit
/package
.env
.env.*
!.env.example
vite.config.js.timestamp-*
vite.config.ts.timestamp-*



================================================
FILE: packages/web/drizzle/0000_cute_zuras.sql
================================================
CREATE TABLE `uninstall_feedback` (
	`id` int AUTO_INCREMENT NOT NULL,
	`feedback` text NOT NULL,
	`timestamp` timestamp NOT NULL DEFAULT (now()),
	CONSTRAINT `uninstall_feedback_id` PRIMARY KEY(`id`)
);



================================================
FILE: packages/web/drizzle/0001_blushing_corsair.sql
================================================
CREATE TABLE `problematic_lint` (
	`id` int AUTO_INCREMENT NOT NULL,
	`is_false_positive` boolean NOT NULL,
	`example` text NOT NULL,
	`feedback` text NOT NULL,
	`timestamp` timestamp NOT NULL DEFAULT (now()),
	CONSTRAINT `problematic_lint_id` PRIMARY KEY(`id`)
);



================================================
FILE: packages/web/drizzle/0002_blushing_chameleon.sql
================================================
ALTER TABLE `problematic_lint` ADD `rule_id` text;


================================================
FILE: packages/web/drizzle/meta/0000_snapshot.json
================================================
{
	"version": "5",
	"dialect": "mysql",
	"id": "c5978949-00ad-4366-8af4-31ca63a60f87",
	"prevId": "00000000-0000-0000-0000-000000000000",
	"tables": {
		"uninstall_feedback": {
			"name": "uninstall_feedback",
			"columns": {
				"id": {
					"name": "id",
					"type": "int",
					"primaryKey": false,
					"notNull": true,
					"autoincrement": true
				},
				"feedback": {
					"name": "feedback",
					"type": "text",
					"primaryKey": false,
					"notNull": true,
					"autoincrement": false
				},
				"timestamp": {
					"name": "timestamp",
					"type": "timestamp",
					"primaryKey": false,
					"notNull": true,
					"autoincrement": false,
					"default": "(now())"
				}
			},
			"indexes": {},
			"foreignKeys": {},
			"compositePrimaryKeys": {
				"uninstall_feedback_id": {
					"name": "uninstall_feedback_id",
					"columns": ["id"]
				}
			},
			"uniqueConstraints": {},
			"checkConstraint": {}
		}
	},
	"views": {},
	"_meta": {
		"schemas": {},
		"tables": {},
		"columns": {}
	},
	"internal": {
		"tables": {},
		"indexes": {}
	}
}



================================================
FILE: packages/web/drizzle/meta/0001_snapshot.json
================================================
{
	"version": "5",
	"dialect": "mysql",
	"id": "a13c6522-4577-4493-a811-fc9a29305fcb",
	"prevId": "c5978949-00ad-4366-8af4-31ca63a60f87",
	"tables": {
		"problematic_lint": {
			"name": "problematic_lint",
			"columns": {
				"id": {
					"name": "id",
					"type": "int",
					"primaryKey": false,
					"notNull": true,
					"autoincrement": true
				},
				"is_false_positive": {
					"name": "is_false_positive",
					"type": "boolean",
					"primaryKey": false,
					"notNull": true,
					"autoincrement": false
				},
				"example": {
					"name": "example",
					"type": "text",
					"primaryKey": false,
					"notNull": true,
					"autoincrement": false
				},
				"feedback": {
					"name": "feedback",
					"type": "text",
					"primaryKey": false,
					"notNull": true,
					"autoincrement": false
				},
				"timestamp": {
					"name": "timestamp",
					"type": "timestamp",
					"primaryKey": false,
					"notNull": true,
					"autoincrement": false,
					"default": "(now())"
				}
			},
			"indexes": {},
			"foreignKeys": {},
			"compositePrimaryKeys": {
				"problematic_lint_id": {
					"name": "problematic_lint_id",
					"columns": ["id"]
				}
			},
			"uniqueConstraints": {},
			"checkConstraint": {}
		},
		"uninstall_feedback": {
			"name": "uninstall_feedback",
			"columns": {
				"id": {
					"name": "id",
					"type": "int",
					"primaryKey": false,
					"notNull": true,
					"autoincrement": true
				},
				"feedback": {
					"name": "feedback",
					"type": "text",
					"primaryKey": false,
					"notNull": true,
					"autoincrement": false
				},
				"timestamp": {
					"name": "timestamp",
					"type": "timestamp",
					"primaryKey": false,
					"notNull": true,
					"autoincrement": false,
					"default": "(now())"
				}
			},
			"indexes": {},
			"foreignKeys": {},
			"compositePrimaryKeys": {
				"uninstall_feedback_id": {
					"name": "uninstall_feedback_id",
					"columns": ["id"]
				}
			},
			"uniqueConstraints": {},
			"checkConstraint": {}
		}
	},
	"views": {},
	"_meta": {
		"schemas": {},
		"tables": {},
		"columns": {}
	},
	"internal": {
		"tables": {},
		"indexes": {}
	}
}



================================================
FILE: packages/web/drizzle/meta/0002_snapshot.json
================================================
{
	"version": "5",
	"dialect": "mysql",
	"id": "fbee3b57-d046-43fc-aa34-a2ef07e19993",
	"prevId": "a13c6522-4577-4493-a811-fc9a29305fcb",
	"tables": {
		"problematic_lint": {
			"name": "problematic_lint",
			"columns": {
				"id": {
					"name": "id",
					"type": "int",
					"primaryKey": false,
					"notNull": true,
					"autoincrement": true
				},
				"is_false_positive": {
					"name": "is_false_positive",
					"type": "boolean",
					"primaryKey": false,
					"notNull": true,
					"autoincrement": false
				},
				"example": {
					"name": "example",
					"type": "text",
					"primaryKey": false,
					"notNull": true,
					"autoincrement": false
				},
				"feedback": {
					"name": "feedback",
					"type": "text",
					"primaryKey": false,
					"notNull": true,
					"autoincrement": false
				},
				"rule_id": {
					"name": "rule_id",
					"type": "text",
					"primaryKey": false,
					"notNull": false,
					"autoincrement": false
				},
				"timestamp": {
					"name": "timestamp",
					"type": "timestamp",
					"primaryKey": false,
					"notNull": true,
					"autoincrement": false,
					"default": "(now())"
				}
			},
			"indexes": {},
			"foreignKeys": {},
			"compositePrimaryKeys": {
				"problematic_lint_id": {
					"name": "problematic_lint_id",
					"columns": ["id"]
				}
			},
			"uniqueConstraints": {},
			"checkConstraint": {}
		},
		"uninstall_feedback": {
			"name": "uninstall_feedback",
			"columns": {
				"id": {
					"name": "id",
					"type": "int",
					"primaryKey": false,
					"notNull": true,
					"autoincrement": true
				},
				"feedback": {
					"name": "feedback",
					"type": "text",
					"primaryKey": false,
					"notNull": true,
					"autoincrement": false
				},
				"timestamp": {
					"name": "timestamp",
					"type": "timestamp",
					"primaryKey": false,
					"notNull": true,
					"autoincrement": false,
					"default": "(now())"
				}
			},
			"indexes": {},
			"foreignKeys": {},
			"compositePrimaryKeys": {
				"uninstall_feedback_id": {
					"name": "uninstall_feedback_id",
					"columns": ["id"]
				}
			},
			"uniqueConstraints": {},
			"checkConstraint": {}
		}
	},
	"views": {},
	"_meta": {
		"schemas": {},
		"tables": {},
		"columns": {}
	},
	"internal": {
		"tables": {},
		"indexes": {}
	}
}



================================================
FILE: packages/web/drizzle/meta/_journal.json
================================================
{
	"version": "7",
	"dialect": "mysql",
	"entries": [
		{
			"idx": 0,
			"version": "5",
			"when": 1760386452851,
			"tag": "0000_cute_zuras",
			"breakpoints": true
		},
		{
			"idx": 1,
			"version": "5",
			"when": 1760545628828,
			"tag": "0001_blushing_corsair",
			"breakpoints": true
		},
		{
			"idx": 2,
			"version": "5",
			"when": 1760546819156,
			"tag": "0002_blushing_chameleon",
			"breakpoints": true
		}
	]
}



================================================
FILE: packages/web/src/app.css
================================================
@import "tailwindcss";
@import "components/components.css";

@custom-variant dark (&:where(.dark, .dark *));

@theme {
	--color-primary-50: #fef4e7; /* honey bronze */
	--color-primary-100: #fce9cf;
	--color-primary-200: #f9d49f;
	--color-primary-300: #f7be6e;
	--color-primary-400: #f4a83e;
	--color-primary: #f1920e;
	--color-primary-600: #c1750b;
	--color-primary-700: #915808;
	--color-primary-800: #603b06;
	--color-primary-900: #301d03;
	--color-primary-950: #221402;

	--color-accent-50: #fee7e9; /* hot fuchsia */
	--color-accent-100: #fccfd3;
	--color-accent-200: #f99fa6;
	--color-accent-300: #f76e7a;
	--color-accent-400: #f43e4d;
	--color-accent: #f10e21;
	--color-accent-600: #c10b1a;
	--color-accent-700: #910814;
	--color-accent-800: #60060d;
	--color-accent-900: #300307;
	--color-accent-950: #220205;

	--color-cream: #fef4e7; /* simple cream */
	--color-cream-100: #fce9cf;
	--color-cream-200: #f9d49f;
	--color-cream-300: #f7be6e;
	--color-cream-400: #f4a83e;
	--color-cream-500: #f1920e;
	--color-cream-600: #c1750b;
	--color-cream-700: #915808;
	--color-cream-800: #603b06;
	--color-cream-900: #301d03;
	--color-cream-950: #221402;

	--color-champagne-mist-50: #fef4e7;
	--color-champagne-mist-100: #fce9cf;
	--color-champagne-mist-200: #fad49e;
	--color-champagne-mist-300: #f7be6e;
	--color-champagne-mist-400: #f5a83d;
	--color-champagne-mist-500: #f2930d;
	--color-champagne-mist-600: #c2750a;
	--color-champagne-mist-700: #915808;
	--color-champagne-mist-800: #613b05;
	--color-champagne-mist-900: #301d03;
	--color-champagne-mist-950: #221502;

	--color-white: #fffdfa;
	--color-white-100: #fceacf;
	--color-white-200: #fad59e;
	--color-white-300: #f7c06e;
	--color-white-400: #f5ab3d;
	--color-white-500: #f2960d;
	--color-white-600: #c2780a;
	--color-white-700: #915a08;
	--color-white-800: #613c05;
	--color-white-900: #301e03;
	--color-white-950: #221502;
}

body {
	@apply bg-white text-black dark:bg-black dark:text-white;

	font-family:
		Atkinson Hyperlegible,
		sans-serif;
}

ul {
	@apply list-disc pl-4;
}

ol {
	@apply list-decimal pl-4;
}

h1 {
	@apply text-4xl font-extrabold tracking-tight lg:text-5xl py-4;
	font-family: Domine, serif;
}

h2 {
	@apply text-3xl font-semibold tracking-tight py-4;
	font-family: Domine, serif;
}

h3 {
	@apply text-2xl font-semibold tracking-tight py-4;
	font-family: Domine, serif;
}

h4 {
	@apply text-xl font-semibold tracking-tight;
	font-family: Domine, serif;
}

p {
	@apply leading-[130%] [&:not(:first-child)]:mt-6;
}

a {
	@apply underline-offset-4 text-black dark:text-white;
}

blockquote {
	@apply mt-6 border-l-2 border-gray-200 pl-6 italic dark:border-gray-700;
}

code {
	font-family: "JetBrains Mono", monospace;
	word-break: keep-all;
}

code * {
	font-family: "JetBrains Mono", monospace;
}

.underlinespecial {
	position: relative;
	background-color: var(--bg-color);
}

.underlinespecial::after {
	transition-property: all;
	transition-timing-function: cubic-bezier(0.4, 0, 0.2, 1);
	transition-duration: 150ms;
	content: "";
	display: block;
	width: 100%;
	height: var(--line-width);
	border-radius: 1000px;
	background: var(--line-color);
	position: absolute;
	bottom: -3px;
	left: 0;
}

textarea {
	--tw-ring-shadow: 0 0 #000;
}

.animate-bigbounce {
	animation: bigbounce 1s infinite;
}

.animate-after-bigbounce::after {
	animation: bigbounce 1s infinite;
}

@keyframes bigbounce {
	0%,
	100% {
		transform: translateY(-40%);
		animation-timing-function: cubic-bezier(0.8, 0, 1, 1);
	}
	50% {
		transform: none;
		animation-timing-function: cubic-bezier(0, 0, 0.2, 1);
	}
}

.header {
	padding-top: 6px;
}

th[align="center"] {
	text-align: center;
}

th[align="right"] {
	text-align: right;
}

.skew-hover {
	@apply transition-all hover:rotate-3 hover:scale-105;
}

.skew-hover-left {
	@apply transition-all hover:-rotate-3 hover:scale-105;
}



================================================
FILE: packages/web/src/app.d.ts
================================================
// See https://kit.svelte.dev/docs/types#app
// for information about these interfaces
declare global {
	namespace App {
		// interface Error {}
		// interface Locals {}
		// interface PageData {}
		// interface Platform {}
	}
}

export {};



================================================
FILE: packages/web/src/app.html
================================================
<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="language" content="en" />
  <meta name="robots" content="index,follow" />

  <title>Harper | Privacy-First Offline Grammar Checker for Developers & Writers</title>

  <meta name="description"
    content="Harper is a blazing-fast, open-source grammar & spell checker that runs entirely on your device, covering US, UK, Canadian & Australian English—no data ever leaves your machine. Harper is the only grammar checker that doesn't use AI." />

  <meta name="keywords"
    content="Harper, grammar checker, spell checker, privacy-first, offline, open source, fast grammar tool, developer writing, markdown checker" />
  <meta name="author" content="Elijah Potter" />

  <link rel="canonical" href="https://writewithharper.com/" />

  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png" />
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png" />
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png" />
  <link rel="manifest" href="/site.webmanifest" />
  <link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5" />
  <meta name="msapplication-TileColor" content="#da532c" />
  <meta name="theme-color" content="#ffffff" />

  <meta property="og:type" content="website" />
  <meta property="og:site_name" content="Harper" />
  <meta property="og:locale" content="en_US" />
  <meta property="og:url" content="https://writewithharper.com/" />
  <meta property="og:title" content="Harper | Privacy-First Offline Grammar Checker" />
  <meta property="og:description"
    content="Harper checks your writing instantly—fast, lightweight and utterly private—so you can polish every clause without surrendering a single keystroke." />

  <meta name="twitter:card" content="summary_large_image" />
  <meta name="twitter:title" content="Harper | Privacy-First Offline Grammar Checker" />
  <meta name="twitter:description"
    content="Blazing-fast, open-source grammar & spell checking that never sends your words to the cloud." />
  <meta property="og:image" content="https://writewithharper.com/social_image.png" />
  <meta property="og:image:alt" content="Stylised ‘Harper’ wordmark on a clean pastel backdrop" />
  <meta property="og:image:type" content="image/png" />
  <meta property="og:image:width" content="1200" />
  <meta property="og:image:height" content="630" />

  <meta name="twitter:image" content="https://writewithharper.com/social_image.png" />
  <meta name="twitter:image:alt" content="Stylised ‘Harper’ wordmark on a clean pastel backdrop" />

  <meta name="algolia-site-verification" content="3129E6D505B8ED8A" />

  <script type="application/ld+json">
    {
      "@context":"https://schema.org",
      "@type":"SoftwareApplication",
      "name":"Harper",
      "url":"https://writewithharper.com",
      "applicationCategory":"WritingApplication",
      "operatingSystem":"Web, Browser Extension, Node.js",
      "offers": { "@type":"Offer", "price":"0", "priceCurrency":"USD" },
      "author":  { "@type":"Person", "name":"Elijah Potter", "url":"https://elijahpotter.dev" },
      "description":"Harper is a privacy-first, offline grammar and spell checker that covers multiple English dialects and runs entirely on-device."
    }
  </script>

  <title>Harper: Free, Open Source Grammar Checker</title>
  <meta name="description" content="Harper checks your writing fast, without compromising your privacy." />
  <link rel="canonical" href="https://writewithharper.com" />
  <meta property="og:title" content="Harper: Free, Open Source Grammar Checker" />
  <meta property="og:description" content="Harper checks your writing fast, without compromising your privacy." />
  <meta property="og:url" content="https://writewithharper.com" />

  <link rel="preconnect" href="https://fonts.googleapis.com" />
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
  <link
    href="https://fonts.googleapis.com/css2?family=Atkinson+Hyperlegible:ital,wght@0,400;0,700;1,400;1,700&family=Domine:wght@400..700&display=swap"
    rel="stylesheet" />

  <link href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:ital,wght@0,100..800;1,100..800&display=swap"
    rel="stylesheet" />

  %sveltekit.head%
</head>

<body data-sveltekit-preload-data="false" class="m-0 p-0 w-full h-full">
  <div style="display: contents" class="m-0 p-0 h-full">%sveltekit.body%</div>
</body>

</html>



================================================
FILE: packages/web/src/hooks.server.ts
================================================
import { migrate } from 'drizzle-orm/mysql2/migrator';
import { db } from '$lib/db';

// Migrate exactly once at startup
try {
	await migrate(db, { migrationsFolder: './drizzle', migrationsTable: '__drizzle_migrations' });
} catch (e: any) {
	console.log('Failed to migrate database.');
	console.error(e);
}



================================================
FILE: packages/web/src/lib/GitHubClient.ts
================================================
export class GithubClient {
	/// Map of string -> [content, expiration time]
	private static versionCache: Map<string, [string, number]> = new Map();

	public static async getLatestReleaseFromCache(
		repoOwner: string,
		repoName: string,
	): Promise<string | null> {
		const key = `${repoOwner}/${repoName}`;

		const val = this.versionCache.get(key);

		if (val == null) {
			const updatedValue = await this.getLatestRelease(repoOwner, repoName);
			this.versionCache.set(key, [updatedValue, Date.now() + 3600 * 3000]);
			return updatedValue;
		}

		const [value, expiry] = val;

		if (expiry - Date.now() < 0) {
			this.versionCache.delete(key);
			const updatedValue = await this.getLatestRelease(repoOwner, repoName);
			this.versionCache.set(key, [updatedValue, Date.now() + 3600 * 3000]);
			return updatedValue;
		}

		return value;
	}

	public static async getLatestRelease(repoOwner: string, repoName: string): Promise<string> {
		const resp = await fetch(
			`https://api.github.com/repos/${encodeURIComponent(repoOwner)}/${encodeURIComponent(repoName)}/releases/latest`,
			{
				headers: {
					ContentType: 'application/json',
				},
			},
		);

		const body = await resp.json();

		return body.name;
	}
}



================================================
FILE: packages/web/src/lib/components/AutomatticLogo.svelte
================================================
<script lang="ts">
export let width = '100%';
export let height = '100%';
</script>

<svg
	{width}
	{height}
	viewBox="0 0 1080 200"
	fill="none"
	xmlns="http://www.w3.org/2000/svg"
	class="fill-black dark:fill-white"
>
	<path
		d="M414.223 134.241C390.908 134.241 375.797 117.463 375.797 99.9815V97.7964C375.797 80.0186 390.908 63.5371 414.223 63.5371C437.538 63.5371 452.741 80.0186 452.741 97.7964V99.9815C452.741 117.407 437.63 134.241 414.223 134.241ZM440.297 98.0001C440.297 85.2593 431.038 73.926 414.223 73.926C397.408 73.926 388.297 85.2778 388.297 98.0001V99.5741C388.297 112.315 397.556 123.87 414.223 123.87C430.889 123.87 440.297 112.315 440.297 99.5741V98.0001Z"
	/>
	<path
		d="M151.112 131.682L142.408 115.386H103.704L95.2969 131.682H82.334L117.778 65.9043H128.056L164.204 131.682H151.112ZM122.667 78.7376L108.353 106.386H137.482L122.667 78.7376Z"
	/>
	<path
		d="M220.333 134.238C196.74 134.238 185.777 121.404 185.777 104.312V65.9043H198.018V104.441C198.018 116.589 206.018 123.793 221.222 123.793C236.833 123.793 243.259 116.589 243.259 104.441V65.9043H255.592V104.312C255.592 120.608 245.129 134.238 220.333 134.238Z"
	/>
	<path d="M324.352 76.1636V131.719H312.001V76.1636H283.26V65.9043H353.093V76.1636H324.352Z" />
	<path
		d="M562.759 131.682V79.6265L559.5 85.3487L531.944 131.645H525.926L498.666 85.3487L495.407 79.6265V131.682H483.352V65.9043H500.444L526.37 111.034L529.426 116.589L532.481 111.034L558.166 65.9043H575.185V131.682H562.759Z"
	/>
	<path
		d="M668.444 131.682L659.759 115.386H621.129L612.74 131.682H599.777L635.333 65.9043H645.555L681.703 131.682H668.444ZM640.092 78.7376L625.777 106.386H654.907L640.092 78.7376Z"
	/>
	<path d="M731.464 76.1636V131.719H719.112V76.1636H690.371V65.9043H760.204V76.1636H731.464Z" />
	<path d="M822.019 76.1636V131.719H809.686V76.1636H780.945V65.9043H850.779V76.1636H822.019Z" />
	<path
		d="M881.186 131.682V72.1265C886.13 72.1265 888.093 69.4599 888.093 65.9043H893.334V131.682H881.186Z"
	/>
	<path
		d="M990 84.462C982.881 77.7046 973.446 73.9278 963.63 73.9065C946.037 73.9065 936.167 85.9435 936.167 98.4991V99.7768C936.167 112.221 946.13 123.851 964.5 123.851C974.115 123.676 983.317 119.911 990.297 113.295L997.704 121.092C988.477 129.66 976.313 134.359 963.723 134.221C938.834 134.221 923.723 118.036 923.723 100.258V98.0731C923.723 80.2953 940.204 63.5176 964.315 63.5176C978.241 63.5176 990.889 69.3324 997.649 76.6472L990 84.462Z"
	/>
	<path
		d="M415.726 87.83L404.415 105.348C402.984 107.564 403.62 110.522 405.837 111.953L405.853 111.963C408.069 113.394 411.027 112.758 412.458 110.541L423.769 93.0234C425.2 90.8066 424.564 87.8493 422.347 86.418L422.331 86.4079C420.115 84.9766 417.157 85.6133 415.726 87.83Z"
	/>
</svg>



================================================
FILE: packages/web/src/lib/components/ChromeLogo.svelte
================================================
<script lang="ts">
export let width = '100%';
export let height = '100%';
</script>

<svg {width} {height} viewBox="0 0 32 32" data-name="Layer 1" id="Layer_1" xmlns="http://www.w3.org/2000/svg"><path d="M4.7434,22.505A12.9769,12.9769,0,0,0,14.88,28.949l5.8848-10.1927L16,16.0058,11.2385,18.755l-1.5875-2.75L8.4885,13.9919,5.3553,8.5649A12.9894,12.9894,0,0,0,4.7434,22.505Z" fill="#00ac47"/><path d="M16,3.0072A12.9769,12.9769,0,0,0,5.3507,8.5636l5.8848,10.1927L16,16.0057V10.5072H27.766A12.99,12.99,0,0,0,16,3.0072Z" fill="#ea4435"/><path d="M27.2557,22.505a12.9772,12.9772,0,0,0,.5124-12H15.9986v5.5011l4.7619,2.7492-1.5875,2.75-1.1625,2.0135-3.1333,5.4269A12.99,12.99,0,0,0,27.2557,22.505Z" fill="#ffba00"/><circle cx="15.9995" cy="16.0072" fill="#ffffff" r="5.5"/><circle cx="15.9995" cy="16.0072" fill="#4285f4" r="4.25"/></svg>



================================================
FILE: packages/web/src/lib/components/CodeLogo.svelte
================================================
<script lang="ts">
export let width = '100%';
export let height = '100%';
</script>

<svg {width} {height} viewBox="0 0 100 100" fill="none" xmlns="http://www.w3.org/2000/svg">
	<mask id="mask0" maskUnits="userSpaceOnUse" x="0" y="0" width="100" height="100">
		<path
			fill-rule="evenodd"
			clip-rule="evenodd"
			d="M70.9119 99.3171C72.4869 99.9307 74.2828 99.8914 75.8725 99.1264L96.4608 89.2197C98.6242 88.1787 100 85.9892 100 83.5872V16.4133C100 14.0113 98.6243 11.8218 96.4609 10.7808L75.8725 0.873756C73.7862 -0.130129 71.3446 0.11576 69.5135 1.44695C69.252 1.63711 69.0028 1.84943 68.769 2.08341L29.3551 38.0415L12.1872 25.0096C10.589 23.7965 8.35363 23.8959 6.86933 25.2461L1.36303 30.2549C-0.452552 31.9064 -0.454633 34.7627 1.35853 36.417L16.2471 50.0001L1.35853 63.5832C-0.454633 65.2374 -0.452552 68.0938 1.36303 69.7453L6.86933 74.7541C8.35363 76.1043 10.589 76.2037 12.1872 74.9905L29.3551 61.9587L68.769 97.9167C69.3925 98.5406 70.1246 99.0104 70.9119 99.3171ZM75.0152 27.2989L45.1091 50.0001L75.0152 72.7012V27.2989Z"
			fill="white"
		/>
	</mask>
	<g mask="url(#mask0)">
		<path
			d="M96.4614 10.7962L75.8569 0.875542C73.4719 -0.272773 70.6217 0.211611 68.75 2.08333L1.29858 63.5832C-0.515693 65.2373 -0.513607 68.0937 1.30308 69.7452L6.81272 74.754C8.29793 76.1042 10.5347 76.2036 12.1338 74.9905L93.3609 13.3699C96.086 11.3026 100 13.2462 100 16.6667V16.4275C100 14.0265 98.6246 11.8378 96.4614 10.7962Z"
			fill="#0065A9"
		/>
		<g filter="url(#filter0_d)">
			<path
				d="M96.4614 89.2038L75.8569 99.1245C73.4719 100.273 70.6217 99.7884 68.75 97.9167L1.29858 36.4169C-0.515693 34.7627 -0.513607 31.9063 1.30308 30.2548L6.81272 25.246C8.29793 23.8958 10.5347 23.7964 12.1338 25.0095L93.3609 86.6301C96.086 88.6974 100 86.7538 100 83.3334V83.5726C100 85.9735 98.6246 88.1622 96.4614 89.2038Z"
				fill="#007ACC"
			/>
		</g>
		<g filter="url(#filter1_d)">
			<path
				d="M75.8578 99.1263C73.4721 100.274 70.6219 99.7885 68.75 97.9166C71.0564 100.223 75 98.5895 75 95.3278V4.67213C75 1.41039 71.0564 -0.223106 68.75 2.08329C70.6219 0.211402 73.4721 -0.273666 75.8578 0.873633L96.4587 10.7807C98.6234 11.8217 100 14.0112 100 16.4132V83.5871C100 85.9891 98.6234 88.1786 96.4586 89.2196L75.8578 99.1263Z"
				fill="#1F9CF0"
			/>
		</g>
		<g style="mix-blend-mode:overlay" opacity="0.25">
			<path
				fill-rule="evenodd"
				clip-rule="evenodd"
				d="M70.8511 99.3171C72.4261 99.9306 74.2221 99.8913 75.8117 99.1264L96.4 89.2197C98.5634 88.1787 99.9392 85.9892 99.9392 83.5871V16.4133C99.9392 14.0112 98.5635 11.8217 96.4001 10.7807L75.8117 0.873695C73.7255 -0.13019 71.2838 0.115699 69.4527 1.44688C69.1912 1.63705 68.942 1.84937 68.7082 2.08335L29.2943 38.0414L12.1264 25.0096C10.5283 23.7964 8.29285 23.8959 6.80855 25.246L1.30225 30.2548C-0.513334 31.9064 -0.515415 34.7627 1.29775 36.4169L16.1863 50L1.29775 63.5832C-0.515415 65.2374 -0.513334 68.0937 1.30225 69.7452L6.80855 74.754C8.29285 76.1042 10.5283 76.2036 12.1264 74.9905L29.2943 61.9586L68.7082 97.9167C69.3317 98.5405 70.0638 99.0104 70.8511 99.3171ZM74.9544 27.2989L45.0483 50L74.9544 72.7012V27.2989Z"
				fill="url(#paint0_linear)"
			/>
		</g>
	</g>
	<defs>
		<filter
			id="filter0_d"
			x="-8.39411"
			y="15.8291"
			width="116.727"
			height="92.2456"
			filterUnits="userSpaceOnUse"
			color-interpolation-filters="sRGB"
		>
			<feFlood flood-opacity="0" result="BackgroundImageFix" />
			<feColorMatrix
				in="SourceAlpha"
				type="matrix"
				values="0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 127 0"
			/>
			<feOffset />
			<feGaussianBlur stdDeviation="4.16667" />
			<feColorMatrix type="matrix" values="0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0.25 0" />
			<feBlend mode="overlay" in2="BackgroundImageFix" result="effect1_dropShadow" />
			<feBlend mode="normal" in="SourceGraphic" in2="effect1_dropShadow" result="shape" />
		</filter>
		<filter
			id="filter1_d"
			x="60.4167"
			y="-8.07558"
			width="47.9167"
			height="116.151"
			filterUnits="userSpaceOnUse"
			color-interpolation-filters="sRGB"
		>
			<feFlood flood-opacity="0" result="BackgroundImageFix" />
			<feColorMatrix
				in="SourceAlpha"
				type="matrix"
				values="0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 127 0"
			/>
			<feOffset />
			<feGaussianBlur stdDeviation="4.16667" />
			<feColorMatrix type="matrix" values="0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0.25 0" />
			<feBlend mode="overlay" in2="BackgroundImageFix" result="effect1_dropShadow" />
			<feBlend mode="normal" in="SourceGraphic" in2="effect1_dropShadow" result="shape" />
		</filter>
		<linearGradient
			id="paint0_linear"
			x1="49.9392"
			y1="0.257812"
			x2="49.9392"
			y2="99.7423"
			gradientUnits="userSpaceOnUse"
		>
			<stop stop-color="white" />
			<stop offset="1" stop-color="white" stop-opacity="0" />
		</linearGradient>
	</defs>
</svg>



================================================
FILE: packages/web/src/lib/components/DefaultNeovimConfig.svelte
================================================
<script>
import { Button } from 'components';
import { binary, LocalLinter } from 'harper.js';

let linter = new LocalLinter({ binary });

let head = `lspconfig.harper_ls.setup {
  settings = {
    ["harper-ls"] = {
      linters = {
`;

let tail = `      }
    }
  },
}`;

async function generateConfig() {
	let default_config = await linter.getDefaultLintConfig();

	let rows = Object.entries(default_config)
		.map(([key, value]) => `\t\t\t${key} = ${value},`)
		.reduce((prev, cur) => `${prev}\n${cur}`);

	return head + rows + tail;
}

async function copyConfig() {
	let defaultConfig = await generateConfig();
	navigator.clipboard.writeText(defaultConfig);
}
</script>

<Button onclick={copyConfig}>Copy Default Config to Clipboard</Button>



================================================
FILE: packages/web/src/lib/components/EdgeLogo.svelte
================================================
<script lang="ts">
export let width = '100%';
export let height = '100%';
</script>

<svg {width} {height} xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 256"><defs><radialGradient id="b" cx="161.8" cy="68.9" r="95.4" gradientTransform="matrix(1 0 0 -.95 0 248.8)" gradientUnits="userSpaceOnUse"><stop offset=".7" stop-opacity="0"/><stop offset=".9" stop-opacity=".5"/><stop offset="1"/></radialGradient><radialGradient id="d" cx="-340.3" cy="63" r="143.2" gradientTransform="matrix(.15 -.99 -.8 -.12 176.6 -125.4)" gradientUnits="userSpaceOnUse"><stop offset=".8" stop-opacity="0"/><stop offset=".9" stop-opacity=".5"/><stop offset="1"/></radialGradient><radialGradient id="e" cx="113.4" cy="570.2" r="202.4" gradientTransform="matrix(-.04 1 2.13 .08 -1179.5 -106.7)" gradientUnits="userSpaceOnUse"><stop offset="0" stop-color="#35c1f1"/><stop offset=".1" stop-color="#34c1ed"/><stop offset=".2" stop-color="#2fc2df"/><stop offset=".3" stop-color="#2bc3d2"/><stop offset=".7" stop-color="#36c752"/></radialGradient><radialGradient id="f" cx="376.5" cy="568" r="97.3" gradientTransform="matrix(.28 .96 .78 -.23 -303.8 -148.5)" gradientUnits="userSpaceOnUse"><stop offset="0" stop-color="#66eb6e"/><stop offset="1" stop-color="#66eb6e" stop-opacity="0"/></radialGradient><linearGradient id="a" x1="63.3" y1="84" x2="241.7" y2="84" gradientTransform="matrix(1 0 0 -1 0 266)" gradientUnits="userSpaceOnUse"><stop offset="0" stop-color="#0c59a4"/><stop offset="1" stop-color="#114a8b"/></linearGradient><linearGradient id="c" x1="157.3" y1="161.4" x2="46" y2="40.1" gradientTransform="matrix(1 0 0 -1 0 266)" gradientUnits="userSpaceOnUse"><stop offset="0" stop-color="#1b9de2"/><stop offset=".2" stop-color="#1595df"/><stop offset=".7" stop-color="#0680d7"/><stop offset="1" stop-color="#0078d4"/></linearGradient></defs><path d="M235.7 195.5a93.7 93.7 0 0 1-10.6 4.7 101.9 101.9 0 0 1-35.9 6.4c-47.3 0-88.5-32.5-88.5-74.3a31.5 31.5 0 0 1 16.4-27.3c-42.8 1.8-53.8 46.4-53.8 72.5 0 74 68.1 81.4 82.8 81.4 7.9 0 19.8-2.3 27-4.6l1.3-.4a128.3 128.3 0 0 0 66.6-52.8 4 4 0 0 0-5.3-5.6Z" transform="translate(-4.6 -5)" style="fill:url(#a)"/><path d="M235.7 195.5a93.7 93.7 0 0 1-10.6 4.7 101.9 101.9 0 0 1-35.9 6.4c-47.3 0-88.5-32.5-88.5-74.3a31.5 31.5 0 0 1 16.4-27.3c-42.8 1.8-53.8 46.4-53.8 72.5 0 74 68.1 81.4 82.8 81.4 7.9 0 19.8-2.3 27-4.6l1.3-.4a128.3 128.3 0 0 0 66.6-52.8 4 4 0 0 0-5.3-5.6Z" transform="translate(-4.6 -5)" style="isolation:isolate;opacity:.35;fill:url(#b)"/><path d="M110.3 246.3A79.2 79.2 0 0 1 87.6 225a80.7 80.7 0 0 1 29.5-120c3.2-1.5 8.5-4.1 15.6-4a32.4 32.4 0 0 1 25.7 13 31.9 31.9 0 0 1 6.3 18.7c0-.2 24.5-79.6-80-79.6-43.9 0-80 41.6-80 78.2a130.2 130.2 0 0 0 12.1 56 128 128 0 0 0 156.4 67 75.5 75.5 0 0 1-62.8-8Z" transform="translate(-4.6 -5)" style="fill:url(#c)"/><path d="M110.3 246.3A79.2 79.2 0 0 1 87.6 225a80.7 80.7 0 0 1 29.5-120c3.2-1.5 8.5-4.1 15.6-4a32.4 32.4 0 0 1 25.7 13 31.9 31.9 0 0 1 6.3 18.7c0-.2 24.5-79.6-80-79.6-43.9 0-80 41.6-80 78.2a130.2 130.2 0 0 0 12.1 56 128 128 0 0 0 156.4 67 75.5 75.5 0 0 1-62.8-8Z" transform="translate(-4.6 -5)" style="opacity:.41;fill:url(#d);isolation:isolate"/><path d="M157 153.8c-.9 1-3.4 2.5-3.4 5.6 0 2.6 1.7 5.2 4.8 7.3 14.3 10 41.4 8.6 41.5 8.6a59.6 59.6 0 0 0 30.3-8.3 61.4 61.4 0 0 0 30.4-52.9c.3-22.4-8-37.3-11.3-43.9C228 28.8 182.3 5 132.6 5a128 128 0 0 0-128 126.2c.5-36.5 36.8-66 80-66 3.5 0 23.5.3 42 10a72.6 72.6 0 0 1 30.9 29.3c6.1 10.6 7.2 24.1 7.2 29.5s-2.7 13.3-7.8 19.9Z" transform="translate(-4.6 -5)" style="fill:url(#e)"/><path d="M157 153.8c-.9 1-3.4 2.5-3.4 5.6 0 2.6 1.7 5.2 4.8 7.3 14.3 10 41.4 8.6 41.5 8.6a59.6 59.6 0 0 0 30.3-8.3 61.4 61.4 0 0 0 30.4-52.9c.3-22.4-8-37.3-11.3-43.9C228 28.8 182.3 5 132.6 5a128 128 0 0 0-128 126.2c.5-36.5 36.8-66 80-66 3.5 0 23.5.3 42 10a72.6 72.6 0 0 1 30.9 29.3c6.1 10.6 7.2 24.1 7.2 29.5s-2.7 13.3-7.8 19.9Z" transform="translate(-4.6 -5)" style="fill:url(#f)"/></svg>



================================================
FILE: packages/web/src/lib/components/Editor.svelte
================================================
<script lang="ts">
import { Card } from 'components';
import { type WorkerLinter } from 'harper.js';
import {
	type IgnorableLintBox,
	LintFramework,
	type UnpackedLintGroups,
	unpackLint,
} from 'lint-framework';
import LintSidebar from '$lib/components/LintSidebar.svelte';
import demo from '../../../../../demo.md?raw';

export let content = demo.trim();
export let onReady: () => void = () => null;

let editor: HTMLDivElement | null;
let linter: WorkerLinter;
let quill: any;
let lintBoxes: IgnorableLintBox[] = [];

$: if (linter != null && quill != null) {
	onReady();
}

let lfw = new LintFramework(
	async (text) => {
		if (!linter) return {};

		const raw = await linter.organizedLints(text);
		// The framework expects grouped lints keyed by source
		const entries = await Promise.all(
			Object.entries(raw).map(async ([source, lintGroup]) => {
				const unpacked = await Promise.all(lintGroup.map((lint) => unpackLint(text, lint, linter)));
				return [source, unpacked] as const;
			}),
		);

		const grouped: UnpackedLintGroups = Object.fromEntries(entries);

		lintBoxes = lfw.getLastIgnorableLintBoxes();

		return grouped;
	},
	{
		ignoreLint: async (hash: string) => {
			if (!linter) return;
			try {
				await linter.ignoreLintHash(BigInt(hash));
				console.log(`Ignored ${hash}`);
				// Re-run linting to hide ignored lint immediately
				lfw.update();
			} catch (e) {
				console.error('Failed to ignore lint', e);
			}
		},
	},
);

(async () => {
	let { WorkerLinter, binary } = await import('harper.js');
	let newLinter = new WorkerLinter({ binary });

	newLinter.setup();
	await newLinter.lint(content);
	linter = newLinter;
})();

async function updateLintFrameworkElements() {
	if (editor == null) {
		return;
	}

	if (quill == null) {
		let { default: Quill } = await import('quill');
		quill = new Quill(editor, {});
		const container = quill.container ?? quill.root?.parentElement;
		container?.classList.add('h-full', 'min-h-0');

		quill.root?.classList.add('flex', 'flex-col', 'h-full', 'min-h-0', 'outline-transparent');
		quill.root?.setAttribute('data-enable-grammarly', 'false');
	}

	for (let el of editor.getElementsByTagName('p')) {
		lfw.addTarget(el);
	}
}

$: if (editor != null) {
	let mo = new MutationObserver(updateLintFrameworkElements);
	mo.observe(editor, { childList: true, subtree: true });
	updateLintFrameworkElements();
}

function jumpTo(lintBox: IgnorableLintBox) {
	if (typeof window === 'undefined') {
		return;
	}

	const range = lintBox.range;
	if (!range) {
		return;
	}

	try {
		const rect = range.getBoundingClientRect();

		const selection = window.getSelection();
		if (selection) {
			selection.removeAllRanges();
			selection.addRange(range.cloneRange());
		}

		const margin = Math.max(10, window.innerHeight * 0.2);
		const target = Math.max(0, window.scrollY + rect.top - margin);
		window.scrollTo({ top: target, behavior: 'smooth' });
	} catch (error) {
		console.error('Failed to jump to lint', error);
	}
}
</script>

<div class="flex flex-row h-full w-full [&_*]:outline-none">
	<Card class="flex-1 h-full p-5 z-10 max-w-full text-lg mr-5 bg-white dark:bg-black overflow-auto">
    <div bind:this={editor} spellcheck="false">
    {@html content.replace(/\n\n/g, '<br>')}
    </div>
	</Card>

	<LintSidebar
		lintBoxes={lintBoxes}
		focusLint={jumpTo}
	/>
</div>



================================================
FILE: packages/web/src/lib/components/EmacsLogo.svelte
================================================
<script lang="ts">
export let width = '100%';
export let height = '100%';
</script>

<svg {width} {height} xmlns="http://www.w3.org/2000/svg" viewBox="0 0 128 128">
	<circle cx="64" cy="64" r="64" fill="#ffffff" />
	<path
		fill="#421f5f"
		d="M60.613 8.012a56.04 56.04 0 0 0-27.34 9.062c-3.437 2.262-5.847 4.238-8.91 7.29-4.652 4.66-8.011 9.363-10.863 15.198-7.938 16.313-7.375 35.938 1.488 51.75 2.598 4.626 5.512 8.461 9.375 12.325 3.063 3.05 5.473 5.039 8.899 7.277a56.014 56.014 0 0 0 61.476 0c3.426-2.238 5.836-4.227 8.899-7.277 3.863-3.864 6.777-7.7 9.375-12.325 8.863-15.812 9.425-35.437 1.488-51.75-2.852-5.835-6.21-10.539-10.863-15.199-3.063-3.05-5.473-5.027-8.91-7.289a55.965 55.965 0 0 0-34.114-9.062Zm27.325 21.914c4.574 1.187 7.55 4.523 7.773 8.699.187 3.336-1.563 5.96-4.625 6.95-.848.277-1.262.323-2.398.323-1.665.016-2.551-.109-6.665-.898-3.875-.75-5.41-.96-8.46-1.125-7.461-.398-11.461.262-12.387 2.023-.477.914.086 2.204 1.648 3.852.84.863 3.2 2.738 11.176 8.836 5.574 4.25 10.05 7.738 9.96 7.75-.073.027-4.698.203-10.272.414-10.227.387-11.239.46-13.551 1.012-4.285 1.011-8.364 2.925-10.035 4.715-2.227 2.375-1.551 4.734 2.023 7.136 3.5 2.336 9.313 4.301 19.688 6.637 9.726 2.188 14.062 3.602 16.949 5.477.988.648 1.55 1.21 1.812 1.859.688 1.613-1.836 3.176-6.597 4.102-3.188.613-5.29.75-11.727.75-10.336-.012-20.613-.836-26.46-2.137-2.767-.614-2.704-.664.71-.59 6.676.152 23.324-.586 26.05-1.148 1.575-.325 2.063-.864 1.337-1.477-.801-.672-2.098-.984-4.95-1.211-5.55-.438-11.726-1.852-17.148-3.95C43.637 84.79 37.352 80.314 34 75.274c-3.602-5.41-1.563-10.023 5.7-12.937 4.788-1.922 11.76-3 18.175-2.785 4.836.148 8.074.71 11.75 2.035.102.039-.512-.348-1.375-.86-10.324-6.124-16.188-11.5-19.313-17.714-.624-1.25-1.062-2.723-1.062-3.575 0-1.437.8-2.648 2.176-3.3 1.363-.649 2.472-.825 5.136-.825 2.637.012 3.239.075 8.188.876 4.512.726 7.398 1.136 9.625 1.363 4.773.5 9.602.562 10.96.148.79-.25 1.29-.785 1.29-1.398 0-1.664-4.96-3.54-13.875-5.239-3.54-.675-3.914-.789-2.75-.812.45-.012 3.762-.176 7.375-.375 7.938-.438 10.113-.426 11.938.05Zm0 0"
	/>
</svg>



================================================
FILE: packages/web/src/lib/components/FirefoxLogo.svelte
================================================
<script lang="ts">
export let width = '100%';
export let height = '100%';
</script>

<svg width={width} height={height} viewBox="0 0 32 32" fill="none" xmlns="http://www.w3.org/2000/svg">
<path d="M28.9905 10.7265C28.3816 9.2574 27.1473 7.67139 26.1784 7.17039C26.967 8.72015 27.4232 10.2746 27.5976 11.4344C27.5976 11.4344 27.5976 11.4426 27.6005 11.4578C26.0156 7.49777 23.3277 5.90065 21.1327 2.42407C21.0213 2.24869 20.9105 2.07331 20.802 1.88566C20.7407 1.77985 20.6911 1.68397 20.648 1.59336C20.557 1.41757 20.4867 1.23179 20.4386 1.03975C20.439 1.03063 20.4359 1.02169 20.4301 1.01467C20.4243 1.00765 20.4161 1.00305 20.4071 1.00175C20.3985 0.999416 20.3894 0.999416 20.3808 1.00175C20.3785 1.00281 20.3763 1.00419 20.3744 1.00584C20.3709 1.00584 20.3674 1.00994 20.3639 1.0111L20.3697 1.0035C16.8483 3.07063 15.6536 6.89446 15.544 8.80784C14.1368 8.90428 12.7913 9.42358 11.683 10.298C11.5672 10.1998 11.4461 10.1081 11.3202 10.0232C11.0008 8.9027 10.9873 7.71683 11.2811 6.58931C9.84091 7.24697 8.72095 8.28463 7.90664 9.20303H7.90023C7.34433 8.49742 7.38341 6.17015 7.41491 5.68435C7.40849 5.65395 7.00076 5.89656 6.94826 5.93339C6.45773 6.2841 5.9992 6.67771 5.57805 7.1096C5.0988 7.59655 4.66096 8.12276 4.26909 8.68274C3.36752 9.96323 2.72814 11.4101 2.3879 12.9398C2.38149 12.9702 2.37565 13.0017 2.36924 13.0327C2.34299 13.1561 2.24791 13.7751 2.23099 13.9096V13.9406C2.10704 14.5803 2.02984 15.2282 2 15.8791V15.951C2 23.7097 8.27646 30 16.0182 30C22.9521 30 28.7088 24.9549 29.8364 18.328C29.8597 18.1485 29.8789 17.9673 29.8999 17.786C30.1788 15.3763 29.869 12.8439 28.9905 10.7265ZM12.8327 21.7239C12.8981 21.7549 12.9599 21.7894 13.027 21.8197L13.0363 21.8256C12.9692 21.7929 12.901 21.759 12.8333 21.7239H12.8327ZM27.6017 11.4642V11.4508V11.466V11.4642Z" fill="url(#paint0_linear_87_7118)"/>
<path d="M28.9907 10.7265C28.3818 9.25741 27.1475 7.67141 26.1786 7.17041C26.9672 8.72017 27.4234 10.2746 27.5978 11.4344V11.4631C28.9208 15.0572 28.1998 18.7121 27.1615 20.9452C25.555 24.4002 21.6661 27.9416 15.578 27.7692C9.00581 27.5821 3.21175 22.6885 2.1297 16.2842C1.93254 15.2735 2.1297 14.7608 2.22886 13.9406C2.10812 14.5725 2.06203 14.7555 2.00195 15.8791V15.951C2.00195 23.7098 8.27842 30 16.0202 30C22.954 30 28.7108 24.9549 29.8383 18.328C29.8616 18.1485 29.8809 17.9673 29.9019 17.7861C30.179 15.3764 29.8692 12.8439 28.9907 10.7265Z" fill="url(#paint1_radial_87_7118)"/>
<path d="M28.9907 10.7265C28.3818 9.25741 27.1475 7.67141 26.1786 7.17041C26.9672 8.72017 27.4234 10.2746 27.5978 11.4344V11.4631C28.9208 15.0572 28.1998 18.7121 27.1615 20.9452C25.555 24.4002 21.6661 27.9416 15.578 27.7692C9.00581 27.5821 3.21175 22.6885 2.1297 16.2842C1.93254 15.2735 2.1297 14.7608 2.22886 13.9406C2.10812 14.5725 2.06203 14.7555 2.00195 15.8791V15.951C2.00195 23.7098 8.27842 30 16.0202 30C22.954 30 28.7108 24.9549 29.8383 18.328C29.8616 18.1485 29.8809 17.9673 29.9019 17.7861C30.179 15.3764 29.8692 12.8439 28.9907 10.7265Z" fill="url(#paint2_radial_87_7118)"/>
<path d="M22.1776 12.3773C22.2085 12.3989 22.2359 12.4205 22.2651 12.4422C21.9133 11.8161 21.4749 11.243 20.9631 10.7398C16.6058 6.37292 19.821 1.27058 20.3629 1.01102L20.3687 1.00342C16.8473 3.07054 15.6526 6.89438 15.543 8.80776C15.7063 8.79665 15.869 8.78262 16.0353 8.78262C18.6631 8.78262 20.952 10.2312 22.1776 12.3773Z" fill="url(#paint3_radial_87_7118)"/>
<path d="M16.0446 13.2499C16.0219 13.6006 14.7899 14.8049 14.3589 14.8049C10.3725 14.8049 9.72559 17.2216 9.72559 17.2216C9.90058 19.2572 11.3157 20.9332 13.0277 21.82C13.1059 21.8604 13.1846 21.8966 13.2611 21.9329C13.3981 21.9913 13.5358 22.0498 13.6729 22.1018C14.26 22.3094 14.8748 22.4276 15.4969 22.4526C22.4838 22.7811 23.8383 14.08 18.7955 11.5534C20.0864 11.3283 21.4269 11.8492 22.1753 12.3759C20.9503 10.2299 18.6608 8.78125 16.033 8.78125C15.8667 8.78125 15.704 8.79528 15.5406 8.80639C14.1345 8.90403 12.7903 9.4239 11.6832 10.2983C11.8973 10.4801 12.1388 10.7221 12.6468 11.2237C13.6 12.1661 16.0394 13.1359 16.0446 13.2499Z" fill="url(#paint4_radial_87_7118)"/>
<path d="M16.0446 13.2499C16.0219 13.6006 14.7899 14.8049 14.3589 14.8049C10.3725 14.8049 9.72559 17.2216 9.72559 17.2216C9.90058 19.2572 11.3157 20.9332 13.0277 21.82C13.1059 21.8604 13.1846 21.8966 13.2611 21.9329C13.3981 21.9913 13.5358 22.0498 13.6729 22.1018C14.26 22.3094 14.8748 22.4276 15.4969 22.4526C22.4838 22.7811 23.8383 14.08 18.7955 11.5534C20.0864 11.3283 21.4269 11.8492 22.1753 12.3759C20.9503 10.2299 18.6608 8.78125 16.033 8.78125C15.8667 8.78125 15.704 8.79528 15.5406 8.80639C14.1345 8.90403 12.7903 9.4239 11.6832 10.2983C11.8973 10.4801 12.1388 10.7221 12.6468 11.2237C13.6 12.1661 16.0394 13.1359 16.0446 13.2499Z" fill="url(#paint5_radial_87_7118)"/>
<path d="M11.0311 9.83093C11.1448 9.90459 11.2382 9.96656 11.3227 10.0233C11.0034 8.90275 10.9899 7.71688 11.2837 6.58936C9.84345 7.24702 8.72349 8.28468 7.90918 9.20308C7.97509 9.20132 10.0085 9.16449 11.0311 9.83093Z" fill="url(#paint6_radial_87_7118)"/>
<path d="M2.1297 16.284C3.21175 22.6883 9.00581 27.5819 15.5827 27.769C21.6707 27.9414 25.5574 24.4 27.1661 20.945C28.2044 18.7113 28.9254 15.057 27.6025 11.4629V11.436C27.6025 11.4395 27.6025 11.4442 27.6054 11.4594C28.1024 14.7138 26.451 17.8665 23.8692 19.9986C23.8666 20.0045 23.8641 20.0106 23.8617 20.0167C18.8306 24.1223 14.0165 22.4936 13.0418 21.8289C12.9741 21.7962 12.9059 21.7623 12.8382 21.7272C9.9047 20.3242 8.69316 17.6438 8.95273 15.3469C6.47656 15.3469 5.63192 13.2529 5.63192 13.2529C5.63192 13.2529 7.85552 11.664 10.7861 13.046C13.5003 14.3262 16.0493 13.2535 16.0493 13.2529C16.0441 13.1389 13.6047 12.1662 12.6533 11.2267C12.1452 10.7251 11.9037 10.4831 11.6896 10.3013C11.5738 10.2031 11.4527 10.1114 11.3268 10.0265C11.2434 9.96809 11.1518 9.90963 11.0352 9.83421C10.0126 9.16778 7.97918 9.20461 7.9121 9.20636H7.90568C7.34978 8.50076 7.38886 6.17348 7.42036 5.68769C7.41395 5.65729 7.00621 5.89989 6.95371 5.93672C6.46318 6.28743 6.00465 6.68104 5.58351 7.11293C5.10426 7.59988 4.66642 8.12609 4.27455 8.68607C3.37298 9.96657 2.7336 11.4134 2.39336 12.9431C2.38228 12.97 1.88354 15.1523 2.1297 16.284Z" fill="url(#paint7_radial_87_7118)"/>
<path d="M20.9634 10.7399C21.4752 11.2431 21.9135 11.8162 22.2653 12.4423C22.3383 12.4971 22.4083 12.5557 22.4753 12.6176C25.6532 15.55 23.9908 19.7012 23.8642 19.9993C26.446 17.8673 28.0973 14.7146 27.6003 11.4601C26.0155 7.49777 23.3276 5.90065 21.1325 2.42407C21.0211 2.24869 20.9103 2.07331 20.8018 1.88566C20.7406 1.77985 20.691 1.68397 20.6478 1.59336C20.5569 1.41757 20.4866 1.23179 20.4384 1.03975C20.4388 1.03063 20.4358 1.02169 20.43 1.01467C20.4241 1.00765 20.4159 1.00305 20.4069 1.00175C20.3983 0.999416 20.3893 0.999416 20.3807 1.00175C20.3783 1.00281 20.3762 1.00419 20.3742 1.00584C20.3707 1.00584 20.3672 1.00994 20.3637 1.0111C19.8213 1.27066 16.606 6.37301 20.9634 10.7399Z" fill="url(#paint8_radial_87_7118)"/>
<path d="M22.4743 12.6146C22.4073 12.5526 22.3372 12.4941 22.2643 12.4392C22.2357 12.4176 22.206 12.396 22.1768 12.3743C21.4284 11.8482 20.088 11.3267 18.7971 11.5518C23.8393 14.0784 22.4854 22.7795 15.4985 22.451C14.8764 22.426 14.2616 22.3078 13.6744 22.1002C13.5374 22.0488 13.3997 21.9921 13.2626 21.9313C13.1833 21.895 13.1045 21.8588 13.0293 21.8185L13.0386 21.8243C14.0133 22.4908 18.8274 24.1194 23.8585 20.0121C23.8585 20.0121 23.8614 20.0045 23.8661 19.9939C23.9909 19.7011 25.6534 15.5499 22.4743 12.6146Z" fill="url(#paint9_radial_87_7118)"/>
<path d="M9.72532 17.2215C9.72532 17.2215 10.3722 14.8048 14.3586 14.8048C14.7897 14.8048 16.0216 13.5994 16.0444 13.2498C16.0671 12.9002 13.4953 14.3231 10.7811 13.0428C7.85055 11.6608 5.62695 13.2498 5.62695 13.2498C5.62695 13.2498 6.47159 15.3438 8.94776 15.3438C8.68819 17.6407 9.89973 20.3187 12.8332 21.7241C12.8986 21.755 12.9604 21.7895 13.0275 21.8199C11.3154 20.9349 9.90207 19.2571 9.72532 17.2215Z" fill="url(#paint10_radial_87_7118)"/>
<path d="M28.9905 10.7265C28.3816 9.2574 27.1473 7.67139 26.1784 7.17039C26.967 8.72015 27.4232 10.2746 27.5976 11.4344C27.5976 11.4344 27.5976 11.4426 27.6005 11.4578C26.0156 7.49777 23.3277 5.90065 21.1327 2.42407C21.0213 2.24869 20.9105 2.07331 20.802 1.88566C20.7407 1.77985 20.6911 1.68397 20.648 1.59336C20.557 1.41757 20.4867 1.23179 20.4386 1.03975C20.439 1.03063 20.4359 1.02169 20.4301 1.01467C20.4243 1.00765 20.4161 1.00305 20.4071 1.00175C20.3985 0.999416 20.3894 0.999416 20.3808 1.00175C20.3785 1.00281 20.3763 1.00419 20.3744 1.00584C20.3709 1.00584 20.3674 1.00994 20.3639 1.0111L20.3697 1.0035C16.8483 3.07063 15.6536 6.89446 15.544 8.80784C15.7073 8.79673 15.8701 8.78271 16.0363 8.78271C18.6641 8.78271 20.9531 10.2313 22.1786 12.3774C21.4302 11.8512 20.0898 11.3298 18.7989 11.5549C23.841 14.0815 22.4872 22.7826 15.5002 22.454C14.8782 22.429 14.2633 22.3108 13.6762 22.1033C13.5391 22.0518 13.4015 21.9951 13.2644 21.9343C13.1851 21.8981 13.1063 21.8618 13.0311 21.8215L13.0404 21.8273C12.9727 21.7946 12.9045 21.7607 12.8368 21.7256C12.9021 21.7566 12.964 21.7911 13.0311 21.8215C11.3155 20.9347 9.90216 19.2569 9.72542 17.2213C9.72542 17.2213 10.3723 14.8046 14.3587 14.8046C14.7898 14.8046 16.0217 13.5992 16.0445 13.2496C16.0392 13.1356 13.5998 12.1628 12.6484 11.2234C12.1403 10.7218 11.8988 10.4798 11.6848 10.298C11.5689 10.1998 11.4478 10.1081 11.3219 10.0232C11.0026 8.9027 10.9891 7.71683 11.2829 6.58931C9.84266 7.24697 8.7227 8.28463 7.90839 9.20303H7.90198C7.34608 8.49742 7.38516 6.17015 7.41666 5.68435C7.41024 5.65395 7.00251 5.89656 6.95001 5.93339C6.45948 6.2841 6.00095 6.67771 5.5798 7.1096C5.10055 7.59655 4.66271 8.12276 4.27084 8.68274C3.36927 9.96323 2.72989 11.4101 2.38965 12.9398C2.38324 12.9702 2.3774 13.0017 2.37099 13.0327C2.34474 13.1561 2.22574 13.7839 2.20941 13.9184C2.20941 13.9289 2.20941 13.9084 2.20941 13.9184C2.10019 14.5671 2.03026 15.2219 2 15.8791V15.951C2 23.7097 8.27646 30 16.0182 30C22.9521 30 28.7088 24.9549 29.8364 18.328C29.8597 18.1485 29.8789 17.9673 29.8999 17.786C30.1788 15.3763 29.869 12.8439 28.9905 10.7265ZM27.5999 11.4479V11.4631V11.4479Z" fill="url(#paint11_linear_87_7118)"/>
<defs>
<linearGradient id="paint0_linear_87_7118" x1="27.135" y1="5.49261" x2="3.81392" y2="27.9437" gradientUnits="userSpaceOnUse">
<stop offset="0.05" stop-color="#FFF44F"/>
<stop offset="0.11" stop-color="#FFE847"/>
<stop offset="0.22" stop-color="#FFC830"/>
<stop offset="0.37" stop-color="#FF980E"/>
<stop offset="0.4" stop-color="#FF8B16"/>
<stop offset="0.46" stop-color="#FF672A"/>
<stop offset="0.53" stop-color="#FF3647"/>
<stop offset="0.7" stop-color="#E31587"/>
</linearGradient>
<radialGradient id="paint1_radial_87_7118" cx="0" cy="0" r="1" gradientUnits="userSpaceOnUse" gradientTransform="translate(26.0596 4.21879) scale(29.2246 29.2888)">
<stop offset="0.13" stop-color="#FFBD4F"/>
<stop offset="0.19" stop-color="#FFAC31"/>
<stop offset="0.25" stop-color="#FF9D17"/>
<stop offset="0.28" stop-color="#FF980E"/>
<stop offset="0.4" stop-color="#FF563B"/>
<stop offset="0.47" stop-color="#FF3750"/>
<stop offset="0.71" stop-color="#F5156C"/>
<stop offset="0.78" stop-color="#EB0878"/>
<stop offset="0.86" stop-color="#E50080"/>
</radialGradient>
<radialGradient id="paint2_radial_87_7118" cx="0" cy="0" r="1" gradientUnits="userSpaceOnUse" gradientTransform="translate(15.3809 16.1925) scale(29.2246 29.2888)">
<stop offset="0.3" stop-color="#960E18"/>
<stop offset="0.35" stop-color="#B11927" stop-opacity="0.74"/>
<stop offset="0.43" stop-color="#DB293D" stop-opacity="0.34"/>
<stop offset="0.5" stop-color="#F5334B" stop-opacity="0.09"/>
<stop offset="0.53" stop-color="#FF3750" stop-opacity="0"/>
</radialGradient>
<radialGradient id="paint3_radial_87_7118" cx="0" cy="0" r="1" gradientUnits="userSpaceOnUse" gradientTransform="translate(18.904 -2.42815) scale(21.172 21.2184)">
<stop offset="0.13" stop-color="#FFF44F"/>
<stop offset="0.25" stop-color="#FFDC3E"/>
<stop offset="0.51" stop-color="#FF9D12"/>
<stop offset="0.53" stop-color="#FF980E"/>
</radialGradient>
<radialGradient id="paint4_radial_87_7118" cx="0" cy="0" r="1" gradientUnits="userSpaceOnUse" gradientTransform="translate(12.1487 23.8433) scale(13.915 13.9455)">
<stop offset="0.35" stop-color="#3A8EE6"/>
<stop offset="0.47" stop-color="#5C79F0"/>
<stop offset="0.67" stop-color="#9059FF"/>
<stop offset="1" stop-color="#C139E6"/>
</radialGradient>
<radialGradient id="paint5_radial_87_7118" cx="0" cy="0" r="1" gradientUnits="userSpaceOnUse" gradientTransform="translate(15.8005 12.7119) rotate(-13.9265) scale(7.37316 8.67852)">
<stop offset="0.21" stop-color="#9059FF" stop-opacity="0"/>
<stop offset="0.28" stop-color="#8C4FF3" stop-opacity="0.06"/>
<stop offset="0.75" stop-color="#7716A8" stop-opacity="0.45"/>
<stop offset="0.97" stop-color="#6E008B" stop-opacity="0.6"/>
</radialGradient>
<radialGradient id="paint6_radial_87_7118" cx="0" cy="0" r="1" gradientUnits="userSpaceOnUse" gradientTransform="translate(15.011 3.02041) scale(10.0108 10.0328)">
<stop stop-color="#FFE226"/>
<stop offset="0.12" stop-color="#FFDB27"/>
<stop offset="0.3" stop-color="#FFC82A"/>
<stop offset="0.5" stop-color="#FFA930"/>
<stop offset="0.73" stop-color="#FF7E37"/>
<stop offset="0.79" stop-color="#FF7139"/>
</radialGradient>
<radialGradient id="paint7_radial_87_7118" cx="0" cy="0" r="1" gradientUnits="userSpaceOnUse" gradientTransform="translate(22.8805 -3.34313) scale(42.7109 42.8046)">
<stop offset="0.11" stop-color="#FFF44F"/>
<stop offset="0.46" stop-color="#FF980E"/>
<stop offset="0.62" stop-color="#FF5634"/>
<stop offset="0.72" stop-color="#FF3647"/>
<stop offset="0.9" stop-color="#E31587"/>
</radialGradient>
<radialGradient id="paint8_radial_87_7118" cx="0" cy="0" r="1" gradientUnits="userSpaceOnUse" gradientTransform="translate(18.7517 1.33374) rotate(84.2447) scale(31.1996 20.4543)">
<stop stop-color="#FFF44F"/>
<stop offset="0.06" stop-color="#FFE847"/>
<stop offset="0.17" stop-color="#FFC830"/>
<stop offset="0.3" stop-color="#FF980E"/>
<stop offset="0.36" stop-color="#FF8B16"/>
<stop offset="0.45" stop-color="#FF672A"/>
<stop offset="0.57" stop-color="#FF3647"/>
<stop offset="0.74" stop-color="#E31587"/>
</radialGradient>
<radialGradient id="paint9_radial_87_7118" cx="0" cy="0" r="1" gradientUnits="userSpaceOnUse" gradientTransform="translate(14.7757 6.73593) scale(26.6644 26.723)">
<stop offset="0.14" stop-color="#FFF44F"/>
<stop offset="0.48" stop-color="#FF980E"/>
<stop offset="0.59" stop-color="#FF5634"/>
<stop offset="0.66" stop-color="#FF3647"/>
<stop offset="0.9" stop-color="#E31587"/>
</radialGradient>
<radialGradient id="paint10_radial_87_7118" cx="0" cy="0" r="1" gradientUnits="userSpaceOnUse" gradientTransform="translate(21.8145 8.30059) scale(29.1844 29.2484)">
<stop offset="0.09" stop-color="#FFF44F"/>
<stop offset="0.23" stop-color="#FFE141"/>
<stop offset="0.51" stop-color="#FFAF1E"/>
<stop offset="0.63" stop-color="#FF980E"/>
</radialGradient>
<linearGradient id="paint11_linear_87_7118" x1="26.855" y1="5.37218" x2="7.01043" y2="25.1739" gradientUnits="userSpaceOnUse">
<stop offset="0.17" stop-color="#FFF44F" stop-opacity="0.8"/>
<stop offset="0.27" stop-color="#FFF44F" stop-opacity="0.63"/>
<stop offset="0.49" stop-color="#FFF44F" stop-opacity="0.22"/>
<stop offset="0.6" stop-color="#FFF44F" stop-opacity="0"/>
</linearGradient>
</defs>
</svg>



================================================
FILE: packages/web/src/lib/components/GitHubLogo.svelte
================================================
<script lang="ts">
export let width = '100%';
export let height = '100%';
</script>

<svg {width} {height} viewBox="0 0 32 32" xmlns="http://www.w3.org/2000/svg">
	<circle cx="16" cy="17" r="15" fill="#fff"></circle>
	<path
		d="M16 0.396c-8.839 0-16 7.167-16 16 0 7.073 4.584 13.068 10.937 15.183 0.803 0.151 1.093-0.344 1.093-0.772 0-0.38-0.009-1.385-0.015-2.719-4.453 0.964-5.391-2.151-5.391-2.151-0.729-1.844-1.781-2.339-1.781-2.339-1.448-0.989 0.115-0.968 0.115-0.968 1.604 0.109 2.448 1.645 2.448 1.645 1.427 2.448 3.744 1.74 4.661 1.328 0.14-1.031 0.557-1.74 1.011-2.135-3.552-0.401-7.287-1.776-7.287-7.907 0-1.751 0.62-3.177 1.645-4.297-0.177-0.401-0.719-2.031 0.141-4.235 0 0 1.339-0.427 4.4 1.641 1.281-0.355 2.641-0.532 4-0.541 1.36 0.009 2.719 0.187 4 0.541 3.043-2.068 4.381-1.641 4.381-1.641 0.859 2.204 0.317 3.833 0.161 4.235 1.015 1.12 1.635 2.547 1.635 4.297 0 6.145-3.74 7.5-7.296 7.891 0.556 0.479 1.077 1.464 1.077 2.959 0 2.14-0.020 3.864-0.020 4.385 0 0.416 0.28 0.916 1.104 0.755 6.4-2.093 10.979-8.093 10.979-15.156 0-8.833-7.161-16-16-16z"
	/>
</svg>



================================================
FILE: packages/web/src/lib/components/Graph.svelte
================================================
<script lang="ts">
import IntersectionObserver from 'svelte-intersection-observer';

let data = new Map<string, number>();
data.set('Harper', 10);
data.set('LanguageTool', 650);
data.set('Grammarly', 4000);

let maxW = 0;

for (let val of data.values()) {
	if (val > maxW) {
		maxW = val;
	}
}

let scaledData = new Map();

for (let [key, val] of data.entries()) {
	scaledData.set(key, val / maxW);
}

let els: Record<string, HTMLElement> = {};

function expand(_node: HTMLElement, { width, duration }: { width: number; duration: number }) {
	return {
		duration,
		css: (t: number) => {
			return `width: ${width * 100 * t}%;`;
		},
	};
}
</script>

<div class="flex flex-col justify-start w-full h-full">
	{#each scaledData as [name, width] (name)}
		<IntersectionObserver element={els[name]} let:intersecting>
			<div bind:this={els[name]}>
				{#if intersecting}
					<div class="relative w-full h-full">
						{name} - {width * maxW} ms
						<div
							class="rounded transition-all mb-4 p-2 font-bold bg-gray-200"
							in:expand={{ width, duration: width * maxW }}
							style={`width: ${width * 100}%;`}
						></div>
					</div>
				{/if}
			</div>
		</IntersectionObserver>
	{/each}
</div>



================================================
FILE: packages/web/src/lib/components/GutterCenter.svelte
================================================
<div class="flex flex-row justify-center h-full">
	<div class="lg:w-[1024px] w-full h-full">
		<slot />
	</div>
</div>



================================================
FILE: packages/web/src/lib/components/HelixLogo.svelte
================================================
<script lang="ts">
export let width = '100%';
export let height = '100%';
</script>

<svg {width} {height} xmlns="http://www.w3.org/2000/svg" xml:space="preserve" style="fill-rule:evenodd;clip-rule:evenodd;stroke-linejoin:round;stroke-miterlimit:2" viewBox="663.38 37.57 575.35 903.75"><path d="m1083.58 1875.72 551.48 318.4a47.66 47.66 0 0 1 23.82 41.27v105.94c0 8.51-2.27 16.7-6.38 23.83 0 0-437.8-252.76-545.3-314.83a47.245 47.245 0 0 1-23.62-40.92z" style="fill:#706bc8" transform="translate(-420.173 -1838.145)"/><path d="M1635.26 2604.84a47.228 47.228 0 0 1 23.62 40.91v133.69l-551.47-318.39a47.66 47.66 0 0 1-23.83-41.27v-105.94c0-8.52 2.27-16.71 6.38-23.83 0 0 437.8 252.76 545.3 314.83" style="fill:#55c5e4" transform="translate(-420.173 -1838.145)"/><path d="M790.407 1432.56a35.033 35.033 0 0 0-12.898 12.9c-9.647 16.7-4.036 38.3 12.495 48.13h-.006l-28.825-16.64a47.644 47.644 0 0 1-23.829-41.27v-105.94c0-17.03 9.083-32.76 23.829-41.27l498.417-287.73.24-.14a34.962 34.962 0 0 0 12.65-12.756c9.65-16.708 4.04-38.3-12.49-48.137h.01l28.82 16.642a47.648 47.648 0 0 1 23.83 41.273v105.938c0 17.03-9.08 32.76-23.83 41.27l-29.63 17.11.4-.26z" style="fill:#84ddea" transform="translate(-73.938 -854.05)"/><path d="M790.407 1686.24a35.08 35.08 0 0 0-12.898 12.89c-9.647 16.71-4.036 38.3 12.495 48.14h-.006l-28.825-16.64a47.656 47.656 0 0 1-23.829-41.27v-105.94c0-17.03 9.083-32.76 23.829-41.27l498.417-287.73.24-.14c5.09-2.99 9.5-7.29 12.65-12.76 9.65-16.71 4.04-38.3-12.49-48.14h.01l28.82 16.65a47.636 47.636 0 0 1 23.83 41.27v105.94c0 17.02-9.08 32.76-23.83 41.27l-29.63 17.1.4-.25z" style="fill:#997bc8" transform="translate(-73.938 -854.05)"/></svg>



================================================
FILE: packages/web/src/lib/components/Isolate.svelte
================================================
<div class="fixed left-0 top-0 w-screen h-screen bg-white dark:bg-black z-1000">
    <slot />
</div>



================================================
FILE: packages/web/src/lib/components/LazyEditor.svelte
================================================
<script lang="ts">
import { Spinner } from 'components';
export let content: string | undefined = undefined;

let editor = import('./Editor.svelte');
let loading = true;

function onReady() {
	loading = false;
}
</script>

{#await editor then { default: Editor}}
  <div class={`flex-row h-full w-full ${loading ? "hidden" : "flex"}`}>
		<Editor content={content} {onReady}/>
  </div>
{/await}

{#if loading}
  <div class="flex flex-row h-full max-w-full items-center justify-center">
    <Spinner color="green" />
  </div>
{/if}



================================================
FILE: packages/web/src/lib/components/LintCard.svelte
================================================
<script lang="ts">
import { Button } from 'components';
import {
	lintKindColor,
	lintKindTextColor,
	type UnpackedLint,
	type UnpackedSuggestion,
} from 'lint-framework';
import { slide } from 'svelte/transition';

export let lint: UnpackedLint;
export let open = false;
export let onToggleOpen: () => void;
export let focusError: () => void;
export let onApply: (s: UnpackedSuggestion) => void;
export let snippet: {
	prefix: string;
	problem: string;
	suffix: string;
	prefixEllipsis: boolean;
	suffixEllipsis: boolean;
};

function suggestionText(s: UnpackedSuggestion): string {
	return s.replacement_text !== '' ? s.replacement_text : String(s.kind);
}
</script>

<div
  class="rounded-lg border border-gray-300 dark:border-gray-700 shadow-sm bg-white dark:bg-[#0d1117]"
  on:click={() => focusError?.()}
>
  <div
    role="button"
    tabindex="0"
    class="flex items-center justify-between p-3 cursor-pointer select-none"
    aria-expanded={open}
    on:click={() => onToggleOpen?.()}
    on:keydown={(e) => (e.key === 'Enter' || e.key === ' ') && (e.preventDefault(), onToggleOpen?.())}
  >
    <div
      class="text-sm font-semibold pb-1"
      style={`border-bottom: 2px solid ${lintKindColor(lint.lint_kind)}`}
    >
      {lint.lint_kind_pretty}
    </div>
    <svg
      class={`ml-3 h-4 w-4 transform transition-transform duration-200 ${open ? 'rotate-180' : ''}`}
      viewBox="0 0 20 20"
      fill="currentColor"
      aria-hidden="true"
    >
      <path fill-rule="evenodd" d="M5.23 7.21a.75.75 0 011.06.02L10 11.127l3.71-3.896a.75.75 0 111.08 1.04l-4.243 4.46a.75.75 0 01-1.08 0L5.25 8.27a.75.75 0 01-.02-1.06z" clip-rule="evenodd" />
    </svg>
  </div>
  {#if open}
    <div class="px-3 pb-3" in:slide={{ duration: 150 }} out:slide={{ duration: 150 }}>
      <div class="text-sm text-gray-700 dark:text-gray-300 mb-2 break-words">
        {@html lint.message_html}
      </div>
      <div class="text-xs font-mono mb-2 p-2 rounded border border-gray-200 dark:border-gray-800 bg-gray-50 dark:bg-[#0b0f14] text-gray-800 dark:text-gray-200 leading-snug">
        <span class="text-gray-500">{snippet.prefixEllipsis ? '…' : ''}{snippet.prefix}</span>
        <span class="px-0.5 rounded bg-yellow-200 text-black dark:bg-yellow-800 dark:text-yellow-100">{snippet.problem}</span>
        <span class="text-gray-500">{snippet.suffix}{snippet.suffixEllipsis ? '…' : ''}</span>
      </div>
      {#if lint.suggestions && lint.suggestions.length > 0}
        <div class="flex flex-wrap gap-2 justify-end">
          {#each lint.suggestions as s}
            <Button
              size="xs"
              color={lintKindColor(lint.lint_kind)}
              textColor={lintKindTextColor(lint.lint_kind)}
              class="!px-2 !py-1 text-xs font-semibold"
              title={`Replace with \"${suggestionText(s)}\"`}
              on:click={() => onApply?.(s)}
            >
              {suggestionText(s)}
            </Button>
          {/each}
        </div>
      {:else}
        <div class="text-xs text-gray-400">No suggestions available.</div>
      {/if}
    </div>
  {/if}
</div>



================================================
FILE: packages/web/src/lib/components/LintKindChart.svelte
================================================
<script lang="ts">
import Chart from 'chart.js/auto';
import { lintKindColor } from 'lint-framework';
import { onMount } from 'svelte';

// Receive lint counts from the parent component
export let lintCounts: Record<string, number> = {};

let chartCanvas: HTMLCanvasElement;
let lintChart: Chart | null = null;

// Update the chart data with new lint counts
function updateChart() {
	if (lintChart) {
		lintChart.data.labels = Object.keys(lintCounts);
		lintChart.data.datasets[0].data = Object.values(lintCounts);
		lintChart.update();
	}
}

onMount(() => {
	// Create a new Chart.js bar chart on mount
	lintChart = new Chart(chartCanvas, {
		type: 'bar',
		data: {
			labels: Object.keys(lintCounts),
			datasets: [
				{
					label: 'Number of Corrections Applied',
					data: Object.values(lintCounts),
					backgroundColor: Object.keys(lintCounts).map(lintKindColor),
					borderColor: 'rgba(80, 80, 80, 1)',
					borderWidth: 2,
					borderRadius: 6, // Rounded corners
					barPercentage: 0.6, // Thicker bars
				},
			],
		},
		options: {
			responsive: true,
			maintainAspectRatio: false,
			plugins: {
				title: {
					display: true,
					text: 'Most Common Kinds of Corrections',
					color: '#444', // Dark gray text
					font: {
						size: 18,
						weight: 'bold',
					},
				},
				legend: {
					display: false,
				},
			},
			scales: {
				x: {
					grid: {
						color: '#ddd',
					},
					ticks: {
						color: '#333',
						font: {
							size: 14,
						},
					},
				},
				y: {
					beginAtZero: true,
					grid: {
						color: '#ddd',
					},
					ticks: {
						stepSize: 1,
						color: '#333',
						font: {
							size: 14,
						},
					},
				},
			},
		},
	});
});

// Whenever lintCounts changes, update the chart
$: if (lintChart) {
	updateChart();
}
</script>

<style>
  /* Wrap the chart in a container to control layout and background */
  .chart-container {
    background: #f9f9f9;       /* Subtle off-white background */
    border: 1px solid #ccc;    /* Light gray border */
    border-radius: 8px;        /* Rounded corners */
    padding: 1rem;
    width: 100%;
    max-width: 700px;          /* Adjust as needed */
    height: 400px;             /* Fixed height for the chart area */
    margin: 0 auto;            /* Center horizontally */
  }

  canvas {
    width: 100%;
    height: 100%;
  }
</style>

<div class="chart-container">
  <canvas bind:this={chartCanvas}></canvas>
</div>



================================================
FILE: packages/web/src/lib/components/LintSidebar.svelte
================================================
<script lang="ts">
import { Button, Card } from 'components';
import { type IgnorableLintBox, type LintBox, type UnpackedLint } from 'lint-framework';
import LintCard from '$lib/components/LintCard.svelte';

export let lintBoxes: IgnorableLintBox[] = [];
export let focusLint: (lintBox: IgnorableLintBox) => void = () => {};

async function ignoreAll() {
	await Promise.all(lintBoxes.map((b) => (b.ignoreLint ? b.ignoreLint() : Promise.resolve())));
}

let openSet: Set<number> = new Set();

$: allOpen = lintBoxes.length > 0 && openSet.size === lintBoxes.length;

function toggleCard(i: number) {
	const wasOpen = openSet.has(i);
	if (wasOpen) {
		const ns = new Set(openSet);
		ns.delete(i);
		openSet = ns;
	} else {
		const ns = new Set(openSet);
		ns.add(i);
		openSet = ns;
	}
}

function toggleAll() {
	if (allOpen) {
		openSet = new Set();
	} else {
		openSet = new Set(lintBoxes.map((_, i) => i));
	}
}

function collapse(contents: string) {
	return contents.replace(/\s+/g, ' ').trim();
}

function createSnippetFor(lintBox: LintBox) {
	let lint = lintBox.lint;
	let content = lintBox.source.textContent ?? '';

	const CONTEXT = 60;
	const start = Math.max(0, lint.span.start - CONTEXT);
	const end = Math.min(content.length, lint.span.end + CONTEXT);

	let prefix = content.slice(start, lint.span.start);
	let suffix = content.slice(lint.span.end, end);

	prefix = collapse(prefix);
	const problem = collapse(lint.problem_text);
	suffix = collapse(suffix);

	return {
		prefix,
		problem,
		suffix,
		prefixEllipsis: start > 0,
		suffixEllipsis: end < content.length,
	};
}

$: if (openSet.size > 0) {
	const max = lintBoxes.length;
	const next = new Set<number>();
	for (const idx of openSet) {
		if (idx >= 0 && idx < max) next.add(idx);
	}
	if (next.size !== openSet.size) openSet = next;
}
</script>

<Card class="hidden md:flex md:flex-col md:w-1/3 h-full p-5 z-10 bg-white dark:bg-black">
	<div class="flex items-center justify-between mb-3">
		<div class="text-base font-semibold">Problems</div>
		<div class="flex items-center gap-2">
			<Button
				size="xs"
				color="light"
				class="text-xs"
				on:click={toggleAll}
				aria-label={allOpen ? 'Collapse all lint cards' : 'Open all lint cards'}
			>
				{allOpen ? 'Collapse all' : 'Open all'}
			</Button>
			<Button
				size="xs"
				color="light"
				class="text-xs"
				on:click={ignoreAll}
				disabled={lintBoxes.length === 0}
				aria-label="Ignore all current lints"
			>
				Ignore all
			</Button>
		</div>
	</div>
	<div class="flex-1 overflow-y-auto pr-1">
		{#if lintBoxes.length === 0}
			<p class="text-sm text-gray-500">No lints yet.</p>
		{:else}
			<div class="space-y-3">
				{#each lintBoxes as lintBox, i}
					<LintCard
						lint={lintBox.lint}
						snippet={createSnippetFor(lintBox)}
						open={openSet.has(i)}
						onToggleOpen={() => toggleCard(i)}
						focusError={() => focusLint(lintBox)}
						onApply={(s) => lintBox.applySuggestion(s)}
					/>
				{/each}
			</div>
		{/if}
	</div>
</Card>



================================================
FILE: packages/web/src/lib/components/Logo.svelte
================================================
<script lang="ts">
export let width = '100%';
export let height = '100%';
</script>

<svg
	{width}
	{height}
	viewBox="0 0 695 411"
	version="1.1"
	xmlns="http://www.w3.org/2000/svg"
	xmlns:xlink="http://www.w3.org/1999/xlink"
	xml:space="preserve"
	style="fill-rule:evenodd;clip-rule:evenodd;stroke-linecap:round;stroke-linejoin:round;stroke-miterlimit:1.5;"
	class="dark:text-white text-black"
>
	<g transform="matrix(1,0,0,1,-5,-1720)">
		<g id="Artboard1" transform="matrix(0.824576,0,0,0.749254,0.365685,430.856)">
			<rect x="5.62" y="1720.57" width="842.425" height="547.24" style="fill:none;" />
			<g transform="matrix(1.21274,0,0,1.33466,-2183.71,393.157)">
				<g transform="matrix(1,0,0,1,-22.3927,1.08043)">
					<path
						d="M1930.93,1121.75C1930.93,1121.75 1974.66,1080.73 2041.34,1094.1C2086.61,1103.18 2122.83,1145.4 2122.83,1145.4"
						stroke="currentcolor"
						fill="transparent"
						stroke-width="22.92px"
					/>
				</g>
				<g transform="matrix(1,0,0,1,-47.3485,12.3935)">
					<path
						d="M2250.3,1107.1C2250.3,1107.1 2261.8,1065.58 2311.59,1047.05C2361.62,1028.44 2422.42,1051.13 2422.42,1051.13"
						stroke="currentcolor"
						fill="transparent"
						stroke-width="22.92px"
					/>
					/>
				</g>
				<g transform="matrix(1.10085,0,0,1.10085,-212.096,-122.054)">
					<g transform="matrix(1,0,0,1,14.3186,-0.853887)">
						<ellipse
							cx="1981.62"
							cy="1247.49"
							rx="87.401"
							ry="87.881"
							stroke="currentcolor"
							fill="transparent"
							stroke-width="22.92px"
						/>
					</g>
					<rect
						x="2083.34"
						y="1231.11"
						width="66.702"
						height="15.521"
						stroke="currentcolor"
						fill="transparent"
						stroke-width="22.92px"
					/>
					<rect
						x="1892.23"
						y="1208.69"
						width="16.306"
						height="30.182"
						stroke="currentcolor"
						fill="transparent"
						stroke-width="22.92px"
					/>
					<g transform="matrix(-1,0,0,1,4281.79,-0.853887)">
						<ellipse
							cx="1981.62"
							cy="1247.49"
							rx="87.401"
							ry="87.881"
							stroke="currentcolor"
							fill="transparent"
							stroke-width="22.92px"
						/>
					</g>
					<g transform="matrix(-1,0,0,1,4296.11,0)">
						<rect
							x="2083.34"
							y="1231.11"
							width="66.702"
							height="15.521"
							stroke="currentcolor"
							fill="transparent"
							stroke-width="22.92px"
						/>
					</g>
					<g transform="matrix(-1,0,0,1,4296.11,0)">
						<rect
							x="1892.23"
							y="1208.69"
							width="16.306"
							height="30.182"
							stroke="currentcolor"
							fill="transparent"
							stroke-width="22.92px"
						/>
					</g>
				</g>
			</g>
		</g>
	</g>
</svg>



================================================
FILE: packages/web/src/lib/components/NeovimLogo.svelte
================================================
<script lang="ts">
export let width = '100%';
export let height = '100%';
</script>

<svg {width} {height} viewBox="0 0 602 734" xmlns="http://www.w3.org/2000/svg">
  <defs>
    <linearGradient id="g1" x1="50%" y1="0%" x2="50%" y2="100%">
      <stop offset="0%"  stop-color="#16B0ED" stop-opacity="0.80"/>
      <stop offset="100%" stop-color="#0F59B2" stop-opacity="0.84"/>
    </linearGradient>
    <linearGradient id="g2" x1="50%" y1="0%" x2="50%" y2="100%">
      <stop offset="0%" stop-color="#7DB643"/>
      <stop offset="100%" stop-color="#367533"/>
    </linearGradient>
    <linearGradient id="g3" x1="50%" y1="0%" x2="50%" y2="100%">
      <stop offset="0%" stop-color="#88C649" stop-opacity="0.8"/>
      <stop offset="100%" stop-color="#439240" stop-opacity="0.84"/>
    </linearGradient>
  </defs>
  <g fill="none" stroke="none" fill-rule="evenodd">
    <!-- left green section -->
    <path d="M0 155.57 155 0v733.43L0 578.24V155.57z" fill="url(#g1)"/>
    <!-- right green section -->
    <path d="M598 155.57 443 0v733.43l155-155.19V155.57z" fill="url(#g2)" transform="translate(598 366.71) scale(-1 1) translate(0px -366.71)"/>
    <!-- central cross -->
    <path d="M155 0l403 615.19-112.78 112.81L42 114.17z" fill="url(#g3)"/>
    <!-- subtle shadow -->
    <path d="M155 283.83l-.21 24.17L31 124.71l11.46-11.71z" fill="#000" opacity="0.13"/>
  </g>
</svg>



================================================
FILE: packages/web/src/lib/components/ObsidianLogo.svelte
================================================
<script lang="ts">
export let width = '100%';
export let height = '100%';
</script>

<svg {width} {height} viewBox="0 0 512 512" fill="none" xmlns="http://www.w3.org/2000/svg">
	<defs>
		<radialGradient
			id="b"
			cx="0"
			cy="0"
			r="1"
			gradientUnits="userSpaceOnUse"
			gradientTransform="matrix(-48 -185 123 -32 179 429.7)"
		>
			<stop stop-color="#fff" stop-opacity=".4" />
			<stop offset="1" stop-opacity=".1" />
		</radialGradient>
		<radialGradient
			id="c"
			cx="0"
			cy="0"
			r="1"
			gradientUnits="userSpaceOnUse"
			gradientTransform="matrix(41 -310 229 30 341.6 351.3)"
		>
			<stop stop-color="#fff" stop-opacity=".6" />
			<stop offset="1" stop-color="#fff" stop-opacity=".1" />
		</radialGradient>
		<radialGradient
			id="d"
			cx="0"
			cy="0"
			r="1"
			gradientUnits="userSpaceOnUse"
			gradientTransform="matrix(57 -261 178 39 190.5 296.3)"
		>
			<stop stop-color="#fff" stop-opacity=".8" />
			<stop offset="1" stop-color="#fff" stop-opacity=".4" />
		</radialGradient>
		<radialGradient
			id="e"
			cx="0"
			cy="0"
			r="1"
			gradientUnits="userSpaceOnUse"
			gradientTransform="matrix(-79 -133 153 -90 321.4 464.2)"
		>
			<stop stop-color="#fff" stop-opacity=".3" />
			<stop offset="1" stop-opacity=".3" />
		</radialGradient>
		<radialGradient
			id="f"
			cx="0"
			cy="0"
			r="1"
			gradientUnits="userSpaceOnUse"
			gradientTransform="matrix(-29 136 -92 -20 300.7 149.9)"
		>
			<stop stop-color="#fff" stop-opacity="0" />
			<stop offset="1" stop-color="#fff" stop-opacity=".2" />
		</radialGradient>
		<radialGradient
			id="g"
			cx="0"
			cy="0"
			r="1"
			gradientUnits="userSpaceOnUse"
			gradientTransform="matrix(72 73 -155 153 137.8 225.2)"
		>
			<stop stop-color="#fff" stop-opacity=".2" />
			<stop offset="1" stop-color="#fff" stop-opacity=".4" />
		</radialGradient>
		<radialGradient
			id="h"
			cx="0"
			cy="0"
			r="1"
			gradientUnits="userSpaceOnUse"
			gradientTransform="matrix(20 118 -251 43 215.1 273.7)"
		>
			<stop stop-color="#fff" stop-opacity=".1" />
			<stop offset="1" stop-color="#fff" stop-opacity=".3" />
		</radialGradient>
		<radialGradient
			id="i"
			cx="0"
			cy="0"
			r="1"
			gradientUnits="userSpaceOnUse"
			gradientTransform="matrix(-162 -85 268 -510 374.4 371.7)"
		>
			<stop stop-color="#fff" stop-opacity=".2" />
			<stop offset=".5" stop-color="#fff" stop-opacity=".2" />
			<stop offset="1" stop-color="#fff" stop-opacity=".3" />
		</radialGradient>
		<filter
			id="a"
			x="80.1"
			y="37"
			width="351.1"
			height="443.2"
			filterUnits="userSpaceOnUse"
			color-interpolation-filters="sRGB"
		>
			<feFlood flood-opacity="0" result="BackgroundImageFix" />
			<feBlend in="SourceGraphic" in2="BackgroundImageFix" result="shape" />
			<feGaussianBlur stdDeviation="6.5" result="effect1_foregroundBlur_744_9191" />
		</filter>
	</defs>
	<rect id="logo-bg" fill="#262626" width="512" height="512" rx="100" />
	<g filter="url(#a)">
		<path
			d="M359.2 437.5c-2.6 19-21.3 33.9-40 28.7-26.5-7.2-57.2-18.6-84.8-20.7l-42.4-3.2a28 28 0 0 1-18-8.3l-73-74.8a27.7 27.7 0 0 1-5.4-30.7s45-98.6 46.8-103.7c1.6-5.1 7.8-49.9 11.4-73.9a28 28 0 0 1 9-16.5L249 57.2a28 28 0 0 1 40.6 3.4l72.6 91.6a29.5 29.5 0 0 1 6.2 18.3c0 17.3 1.5 53 11.2 76a301.3 301.3 0 0 0 35.6 58.2 14 14 0 0 1 1 15.6c-6.3 10.7-18.9 31.3-36.6 57.6a142.2 142.2 0 0 0-20.5 59.6Z"
			fill="#000"
			fill-opacity=".3"
		/>
	</g>
	<path
		id="arrow"
		d="M359.9 434.3c-2.6 19.1-21.3 34-40 28.9-26.4-7.3-57-18.7-84.7-20.8l-42.3-3.2a27.9 27.9 0 0 1-18-8.4l-73-75a27.9 27.9 0 0 1-5.4-31s45.1-99 46.8-104.2c1.7-5.1 7.8-50 11.4-74.2a28 28 0 0 1 9-16.6l86.2-77.5a28 28 0 0 1 40.6 3.5l72.5 92a29.7 29.7 0 0 1 6.2 18.3c0 17.4 1.5 53.2 11.1 76.3a303 303 0 0 0 35.6 58.5 14 14 0 0 1 1.1 15.7c-6.4 10.8-18.9 31.4-36.7 57.9a143.3 143.3 0 0 0-20.4 59.8Z"
		fill="#6C31E3"
	/>
	<path
		d="M182.7 436.4c33.9-68.7 33-118 18.5-153-13.2-32.4-37.9-52.8-57.3-65.5-.4 1.9-1 3.7-1.8 5.4L96.5 324.8a27.9 27.9 0 0 0 5.5 31l72.9 75c2.3 2.3 5 4.2 7.8 5.6Z"
		fill="url(#b)"
	/>
	<path
		d="M274.9 297c9.1.9 18 2.9 26.8 6.1 27.8 10.4 53.1 33.8 74 78.9 1.5-2.6 3-5.1 4.6-7.5a1222 1222 0 0 0 36.7-57.9 14 14 0 0 0-1-15.7 303 303 0 0 1-35.7-58.5c-9.6-23-11-58.9-11.1-76.3 0-6.6-2.1-13.1-6.2-18.3l-72.5-92-1.2-1.5c5.3 17.5 5 31.5 1.7 44.2-3 11.8-8.6 22.5-14.5 33.8-2 3.8-4 7.7-5.9 11.7a140 140 0 0 0-15.8 58c-1 24.2 3.9 54.5 20 95Z"
		fill="url(#c)"
	/>
	<path
		d="M274.8 297c-16.1-40.5-21-70.8-20-95 1-24 8-42 15.8-58l6-11.7c5.8-11.3 11.3-22 14.4-33.8a78.5 78.5 0 0 0-1.7-44.2 28 28 0 0 0-39.4-2l-86.2 77.5a28 28 0 0 0-9 16.6L144.2 216c0 .7-.2 1.3-.3 2 19.4 12.6 44 33 57.3 65.3 2.6 6.4 4.8 13.1 6.4 20.4a200 200 0 0 1 67.2-6.8Z"
		fill="url(#d)"
	/>
	<path
		d="M320 463.2c18.6 5.1 37.3-9.8 39.9-29a153 153 0 0 1 15.9-52.2c-21-45.1-46.3-68.5-74-78.9-29.5-11-61.6-7.3-94.2.6 7.3 33.1 3 76.4-24.8 132.7 3.1 1.6 6.6 2.5 10.1 2.8l43.9 3.3c23.8 1.7 59.3 14 83.2 20.7Z"
		fill="url(#e)"
	/>
	<path
		fill-rule="evenodd"
		clip-rule="evenodd"
		d="M255 200.5c-1.1 24 1.9 51.4 18 91.8l-5-.5c-14.5-42.1-17.7-63.7-16.6-88 1-24.3 8.9-43 16.7-59 2-4 6.6-11.5 8.6-15.3 5.8-11.3 9.7-17.2 13-27.5 4.8-14.4 3.8-21.2 3.2-28 3.7 24.5-10.4 45.8-21 67.5a145 145 0 0 0-17 59Z"
		fill="url(#f)"
	/>
	<path
		fill-rule="evenodd"
		clip-rule="evenodd"
		d="M206 285.1c2 4.4 3.7 8 4.9 13.5l-4.3 1c-1.7-6.4-3-11-5.5-16.5-14.6-34.3-38-52-57-65 23 12.4 46.7 31.9 61.9 67Z"
		fill="url(#g)"
	/>
	<path
		fill-rule="evenodd"
		clip-rule="evenodd"
		d="M211.1 303c8 37.5-1 85.2-27.5 131.6 22.2-46 33-90.1 24-131l3.5-.7Z"
		fill="url(#h)"
	/>
	<path
		fill-rule="evenodd"
		clip-rule="evenodd"
		d="M302.7 299.5c43.5 16.3 60.3 52 72.8 81.9-15.5-31.2-37-65.7-74.4-78.5-28.4-9.8-52.4-8.6-93.5.7l-.9-4c43.6-10 66.4-11.2 96 0Z"
		fill="url(#i)"
	/>
</svg>



================================================
FILE: packages/web/src/lib/components/Section.svelte
================================================
<script lang="ts">
export let layout: 'single' | 'split' = 'single';
export let reverse = false;

const hasSubtitle = Boolean($$slots.subtitle);
const hasAside = Boolean($$slots.aside);

const { class: extraClass = '', ...restProps } = $$restProps;
</script>

<section
	{...restProps}
	class={`w-full px-4 md:px-6 ${extraClass}`.trim()}
>
	{#if layout === 'split'}
		<div class={`grid gap-8 md:grid-cols-2 ${hasAside ? 'md:items-start' : ''}`}>
			<div class={`space-y-4 ${reverse ? 'md:order-2' : ''}`}>
				{#if $$slots.title}
					<h3 class="font-semibold">
						<slot name="title" />
					</h3>
				{/if}
				{#if hasSubtitle}
					<p class="text-gray-600 dark:text-gray-300">
						<slot name="subtitle" />
					</p>
				{/if}
				{#if $$slots.default}
					<div class="space-y-3">
						<slot />
					</div>
				{/if}
			</div>
			{#if hasAside}
				<div class={`${reverse ? 'md:order-1' : ''}`}>
					<slot name="aside" />
				</div>
			{/if}
		</div>
	{:else}
		<div class="space-y-4">
			{#if $$slots.title}
				<h3 class="font-semibold">
					<slot name="title" />
				</h3>
			{/if}
			{#if hasSubtitle}
				<p class="text-gray-600 dark:text-gray-300">
					<slot name="subtitle" />
				</p>
			{/if}
			{#if $$slots.default}
				<div class="space-y-3">
					<slot />
				</div>
			{/if}
		</div>
	{/if}
</section>



================================================
FILE: packages/web/src/lib/components/SublimeLogo.svelte
================================================
<script lang="ts">
export let width = '100%';
export let height = '100%';
</script>

<svg {width} {height} id="Layer_1" data-name="Layer 1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 512.23 512.12"><defs><style>.cls-1{fill:#4d4d4e;}.cls-2{fill:#f89820;}.cls-3{fill:url(#linear-gradient);}</style><linearGradient id="linear-gradient" x1="45.04" y1="421.1" x2="93.51" y2="437.87" gradientTransform="matrix(5.59, 0, 0, -5.59, -126.58, 2748.7)" gradientUnits="userSpaceOnUse"><stop offset="0.23" stop-color="#f89822"/><stop offset="1" stop-color="#c27818"/></linearGradient></defs><title>sublime-text</title><path class="cls-1" d="M492.17,511.79H19.6A19.91,19.91,0,0,1-.23,492V19.5A19.91,19.91,0,0,1,19.6-.33H492.17A19.91,19.91,0,0,1,512,19.5V492.07a19.89,19.89,0,0,1-19.83,19.72Z" transform="translate(0.23 0.33)"/><path class="cls-2" d="M117.85,154.33l268-85.07s19-10,14.45,8.48l.68,82s3.33,12-13.18,15L278.93,208.78Z" transform="translate(0.23 0.33)"/><path class="cls-2" d="M117.85,154.33s-10.55,2.52-7.45,20.52l-.57,79s-.92,10,18,14l265.64,85.52s8.94,3.55,7.91-7.45l.11-88s2.52-9.06-14-15L278.93,208.78Z" transform="translate(0.23 0.33)"/><path class="cls-3" d="M234.9,302.22l-113,34.51s-13.64.46-12,26-.12,77-.12,77,1.15,9.52,14.22,4l268-85.53s9.51-2.41,1.49-5S234.9,302.22,234.9,302.22Z" transform="translate(0.23 0.33)"/></svg>



================================================
FILE: packages/web/src/lib/components/Testimonial.svelte
================================================
<script lang="ts">
import { Card } from 'components';

export let authorName: string;
export let authorSubtitle: string;
export let testimonial: string;
</script>

<Card class="flex h-full flex-col justify-between gap-6">
	<p class="text-base text-neutral-700 dark:text-neutral-200">
		&ldquo;{testimonial}&rdquo;
	</p>
	<footer class="flex flex-col gap-1">
		<span class="font-semibold text-neutral-900 dark:text-neutral-50">{authorName}</span>
		<span class="text-sm text-neutral-600 dark:text-neutral-400">{authorSubtitle}</span>
	</footer>
</Card>



================================================
FILE: packages/web/src/lib/components/TestimonialCollection.svelte
================================================
<script lang="ts">
import { Link } from 'components';
import Testimonial from './Testimonial.svelte';

type TestimonialItem = {
	authorName: string;
	authorSubtitle: string;
	testimonial: string;
	/** The URL the testimonial was sourced from. */
	source: string;
};

export let testimonials: TestimonialItem[] = [];

const { class: extraClass = '', ...restProps } = $$restProps;
</script>

<section
	{...restProps}
	class={`mx-auto w-full max-w-6xl ${extraClass}`.trim()}
>
	<div class="columns-1 gap-6 sm:columns-2 lg:columns-3">
		{#each testimonials as item, index (item.authorName + index)}
			<Link href={item.source} class={`block mb-6 break-inside-avoid ${index % 2 == 0 ? "skew-hover" : "skew-hover-left"}`}>
				<Testimonial
					authorName={item.authorName}
					authorSubtitle={item.authorSubtitle}
					testimonial={item.testimonial}
				/>
			</Link>
		{/each}
	</div>
</section>



================================================
FILE: packages/web/src/lib/components/WordPressLogo.svelte
================================================
<script lang="ts">
export let width = '100%';
export let height = '100%';
</script>

<svg
	{width}
	{height}
	version="1.1"
	id="Layer_1"
	xmlns="http://www.w3.org/2000/svg"
	xmlns:xlink="http://www.w3.org/1999/xlink"
	x="0px"
	y="0px"
	viewBox="0 0 122.88 122.88"
	style="enable-background:new 0 0 122.88 122.88"
	xml:space="preserve"
>
	<style type="text/css">.st0{fill:#32373C;}</style>
	<g>
		<circle cx="61.44" cy="61.44" r="61.44" fill="#ffffff" />
		<path
			class="st0"
			d="M61.44,0C27.51,0,0,27.51,0,61.44c0,33.93,27.51,61.44,61.44,61.44c33.93,0,61.44-27.51,61.44-61.44 C122.88,27.51,95.37,0,61.44,0L61.44,0z M106.37,36.88c0.22,1.63,0.34,3.38,0.34,5.26c0,5.19-0.97,11.03-3.89,18.34l-15.64,45.21 c15.22-8.87,25.46-25.37,25.46-44.25C112.64,52.54,110.37,44.17,106.37,36.88L106.37,36.88z M62.34,65.92l-15.36,44.64 c4.59,1.35,9.44,2.09,14.46,2.09c5.96,0,11.68-1.03,17-2.9c-0.14-0.22-0.26-0.45-0.37-0.71L62.34,65.92L62.34,65.92z M96,58.86 c0-6.33-2.27-10.71-4.22-14.12c-2.6-4.22-5.03-7.79-5.03-12.01c0-4.71,3.57-9.09,8.6-9.09c0.23,0,0.44,0.03,0.66,0.04 c-9.11-8.35-21.25-13.44-34.57-13.44c-17.89,0-33.62,9.18-42.78,23.08c1.2,0.04,2.33,0.06,3.3,0.06c5.35,0,13.65-0.65,13.65-0.65 c2.76-0.16,3.08,3.89,0.33,4.22c0,0-2.77,0.32-5.86,0.49l18.64,55.46l11.21-33.6l-7.98-21.86c-2.76-0.16-5.37-0.49-5.37-0.49 c-2.76-0.16-2.44-4.38,0.32-4.22c0,0,8.45,0.65,13.48,0.65c5.35,0,13.65-0.65,13.65-0.65c2.76-0.16,3.08,3.89,0.33,4.22 c0,0-2.78,0.32-5.86,0.49L87,92.47l5.28-16.74C94.63,68.42,96,63.24,96,58.86L96,58.86z M10.24,61.44 c0,20.27,11.78,37.78,28.86,46.08L14.67,40.6C11.83,46.97,10.24,54.01,10.24,61.44L10.24,61.44z M61.44,3.69 c7.8,0,15.36,1.53,22.48,4.54c3.42,1.45,6.72,3.24,9.81,5.32c3.06,2.07,5.94,4.44,8.55,7.05c2.61,2.61,4.99,5.49,7.05,8.55 c2.09,3.09,3.88,6.39,5.32,9.81c3.01,7.12,4.54,14.68,4.54,22.48c0,7.8-1.53,15.36-4.54,22.48c-1.45,3.42-3.24,6.72-5.32,9.81 c-2.07,3.06-4.44,5.94-7.05,8.55c-2.61,2.61-5.49,4.99-8.55,7.05c-3.09,2.09-6.39,3.88-9.81,5.32c-7.12,3.01-14.68,4.54-22.48,4.54 c-7.8,0-15.36-1.53-22.48-4.54c-3.42-1.45-6.72-3.24-9.81-5.32c-3.06-2.07-5.94-4.44-8.55-7.05c-2.61-2.61-4.99-5.49-7.05-8.55 c-2.09-3.09-3.88-6.39-5.32-9.81C5.21,76.8,3.69,69.24,3.69,61.44c0-7.8,1.53-15.36,4.54-22.48c1.45-3.42,3.24-6.72,5.32-9.81 c2.07-3.06,4.44-5.94,7.05-8.55c2.61-2.61,5.49-4.99,8.55-7.05c3.09-2.09,6.39-3.88,9.81-5.32C46.08,5.21,53.64,3.69,61.44,3.69 L61.44,3.69z"
		/>
	</g>
</svg>



================================================
FILE: packages/web/src/lib/components/ZedLogo.svelte
================================================
<script lang="ts">
export let width = '100%';
export let height = '100%';
</script>

<svg
	class="block dark:hidden"
	{width}
	{height}
	viewBox="0 0 90 90"
	fill="none"
	xmlns="http://www.w3.org/2000/svg"
>
<path fill-rule="evenodd" clip-rule="evenodd" d="M8.4375 5.625C6.8842 5.625 5.625 6.8842 5.625 8.4375V70.3125H0V8.4375C0 3.7776 3.7776 0 8.4375 0H83.7925C87.551 0 89.4333 4.5442 86.7756 7.20186L40.3642 53.6133H53.4375V47.8125H59.0625V55.0195C59.0625 57.3495 57.1737 59.2383 54.8438 59.2383H34.7392L25.0712 68.9062H68.9062V33.75H74.5312V68.9062C74.5312 72.0128 72.0128 74.5312 68.9062 74.5312H19.4462L9.60248 84.375H81.5625C83.1158 84.375 84.375 83.1158 84.375 81.5625V19.6875H90V81.5625C90 86.2224 86.2224 90 81.5625 90H6.20749C2.44898 90 0.566723 85.4558 3.22438 82.7981L49.46 36.5625H36.5625V42.1875H30.9375V35.1562C30.9375 32.8263 32.8263 30.9375 35.1562 30.9375H55.085L64.9288 21.0938H21.0938V56.25H15.4688V21.0938C15.4688 17.9871 17.9871 15.4688 21.0938 15.4688H70.5538L80.3975 5.625H8.4375Z" fill="black"/>
</svg>

<svg
	class="hidden dark:block"
	{width}
	{height}
	viewBox="0 0 90 90"
	fill="none"
	xmlns="http://www.w3.org/2000/svg"
>
<path fill-rule="evenodd" clip-rule="evenodd" d="M8.4375 5.625C6.8842 5.625 5.625 6.8842 5.625 8.4375V70.3125H0V8.4375C0 3.7776 3.7776 0 8.4375 0H83.7925C87.551 0 89.4333 4.5442 86.7756 7.20186L40.3642 53.6133H53.4375V47.8125H59.0625V55.0195C59.0625 57.3495 57.1737 59.2383 54.8438 59.2383H34.7392L25.0712 68.9062H68.9062V33.75H74.5312V68.9062C74.5312 72.0128 72.0128 74.5312 68.9062 74.5312H19.4462L9.60248 84.375H81.5625C83.1158 84.375 84.375 83.1158 84.375 81.5625V19.6875H90V81.5625C90 86.2224 86.2224 90 81.5625 90H6.20749C2.44898 90 0.566723 85.4558 3.22438 82.7981L49.46 36.5625H36.5625V42.1875H30.9375V35.1562C30.9375 32.8263 32.8263 30.9375 35.1562 30.9375H55.085L64.9288 21.0938H21.0938V56.25H15.4688V21.0938C15.4688 17.9871 17.9871 15.4688 21.0938 15.4688H70.5538L80.3975 5.625H8.4375Z" fill="white"/>
</svg>



================================================
FILE: packages/web/src/lib/db/index.ts
================================================
import { drizzle } from 'drizzle-orm/mysql2';

export const db = drizzle({ connection: { uri: process.env.DATABASE_URL } });



================================================
FILE: packages/web/src/lib/db/schema.ts
================================================
import { boolean, int, mysqlTable, text, timestamp } from 'drizzle-orm/mysql-core';

export const uninstallFeedbackTable = mysqlTable('uninstall_feedback', {
	id: int().autoincrement().primaryKey(),
	feedback: text().notNull(),
	timestamp: timestamp().notNull().defaultNow(),
});

export const problematicLintTable = mysqlTable('problematic_lint', {
	id: int().autoincrement().primaryKey(),
	/** If false, implied to be a false-negative. */
	is_false_positive: boolean().notNull(),
	example: text().notNull(),
	feedback: text().notNull(),
	rule_id: text(),
	timestamp: timestamp().notNull().defaultNow(),
});



================================================
FILE: packages/web/src/lib/db/models/ProblematicLints.ts
================================================
import { createInsertSchema, createSelectSchema } from 'drizzle-zod';
import { db } from '..';
import { problematicLintTable } from '../schema';

export type ProblematicLintRow = typeof problematicLintTable.$inferSelect;
const ProblematicLintRowParser = createSelectSchema(problematicLintTable);

export type ProblematicLintSubmission = typeof problematicLintTable.$inferInsert;
const ProblematicLintSubmissionParser = createInsertSchema(problematicLintTable);

export default class ProblematicLints {
	public static async validateAndCreate(rec: any) {
		const parsed = ProblematicLintSubmissionParser.parse(rec);
		await this.create(parsed);
	}

	public static async create(rec: ProblematicLintSubmission) {
		await db.insert(problematicLintTable).values(rec);
	}
}



================================================
FILE: packages/web/src/lib/db/models/UninstallFeedback.ts
================================================
import { createInsertSchema, createSelectSchema } from 'drizzle-zod';
import { db } from '..';
import { uninstallFeedbackTable } from '../schema';

export type UninstallFeedbackRow = typeof uninstallFeedbackTable.$inferSelect;
const UninstallFeedbackRowParser = createSelectSchema(uninstallFeedbackTable);

export type UninstallFeedbackSubmission = typeof uninstallFeedbackTable.$inferInsert;
const UninstallFeedbackSubmissionParser = createInsertSchema(uninstallFeedbackTable);

export default class UninstallFeedback {
	public static async validateAndCreate(rec: any) {
		const parsed = UninstallFeedbackSubmissionParser.parse(rec);
		await this.create(parsed);
	}

	public static async create(rec: UninstallFeedbackSubmission) {
		await db.insert(uninstallFeedbackTable).values(rec);
	}
}



================================================
FILE: packages/web/src/routes/+layout.svelte
================================================
<script lang="ts">
import '../app.css';

import { Link } from 'components';
import posthog from 'posthog-js';
import { onMount } from 'svelte';
import { browser } from '$app/environment';
import AutomatticLogo from '$lib/components/AutomatticLogo.svelte';
import GutterCenter from '$lib/components/GutterCenter.svelte';

onMount(() => {
	if (browser) {
		posthog.init('phc_ghFPi5nkwgxTGU9VEHflX8QCXlfrdxFD4skfb6lpH4y', {
			api_host: 'https://us.i.posthog.com',
			persistence: 'sessionStorage',
			person_profiles: 'always',
		});
	}
});

let names = ['Grammar Guru', 'Grammar Checker', 'Grammar Savior'];
let displayName = names[Math.floor(Math.random() * names.length)];
</script>

<div class="flex flex-col h-full">
	<div class="flex-1">
		<GutterCenter>
			<slot />
		</GutterCenter>
	</div>

	<div class="w-full flex flex-row justify-center h-12">
		<Link href="https://automattic.com/">
			<div class="flex items-center">
				An
				<div class="inline-block"><AutomatticLogo height="32px" width="140px" /></div>
				{displayName}
			</div>
		</Link>
	</div>
</div>



================================================
FILE: packages/web/src/routes/+page.svelte
================================================
<script module>
export const frontmatter = {
	home: false,
};
</script>

<script lang="ts">
import ChromeLogo from '$lib/components/ChromeLogo.svelte';
import CodeLogo from '$lib/components/CodeLogo.svelte';
import LazyEditor from '$lib/components/LazyEditor.svelte';
import FirefoxLogo from '$lib/components/FirefoxLogo.svelte';
import GitHubLogo from '$lib/components/GitHubLogo.svelte';
import ObsidianLogo from '$lib/components/ObsidianLogo.svelte';
import Logo from '$lib/components/Logo.svelte';
import Graph from '$lib/components/Graph.svelte';
import Section from '$lib/components/Section.svelte';
import TestimonialCollection from '$lib/components/TestimonialCollection.svelte';
import EmacsLogo from '$lib/components/EmacsLogo.svelte';
import HelixLogo from '$lib/components/HelixLogo.svelte';
import NeovimLogo from '$lib/components/NeovimLogo.svelte';
import SublimeLogo from '$lib/components/SublimeLogo.svelte';
import WordPressLogo from '$lib/components/WordPressLogo.svelte';
import ZedLogo from '$lib/components/ZedLogo.svelte';
import EdgeLogo from '$lib/components/EdgeLogo.svelte';
import { Card, Collapsible, Link } from 'components';
import { browser } from '$app/environment';

/**
 * @param {string} keyword
 */
function agentHas(keyword: string): boolean | undefined {
	if (!browser) {
		return false;
	}

	return navigator.userAgent.toLowerCase().includes(keyword.toLowerCase());
}


const testimonials = [
  {
    authorName: "Rich Edmonds",
    authorSubtitle: "Lead PC Hardware Editor, XDA Developers",
    testimonial: "Written in Rust, everything is processed in an instant and I find it neat to see the browser extension highlight words as I type, effectively checking per letter. And no account is required, allowing me to get up and running in no time.",
    source: "https://www.xda-developers.com/ditched-grammarly-for-this-amazing-open-source-alternative/"
  },
  {
    authorName: "Justin Pot",
    authorSubtitle: "Tech journalist, Lifehacker",
    testimonial: "Obsidian is my favorite productivity app, and Harper is a grammar checking tool that works well with it.",
    source: "https://lifehacker.com/tech/harper-offline-alternative-to-grammarly?test_uuid=02DN02BmbRCcASIX6xMQtY9&test_variant=B"
  },
  {
    authorName: "Filip Cujanovic",
    authorSubtitle: "Chrome Extension Review",
    testimonial: "Awesome extension! It's privacy focused, that means that every check it done locally on your computer, there is no server where your data goes! And because of that it's blazingly fast compared to Grammarly.",
    source: "https://chromewebstore.google.com/detail/private-grammar-checker-h/lodbfhdipoipcjmlebjbgmmgekckhpfb/reviews"
  },
  {
    authorName: "Tim Miller",
    authorSubtitle: "Author, Obsidian Rocks",
    testimonial: "Harper is great: it is discreet, fast, powerful, and private.",
    source: "https://obsidian.rocks/resource-harper/"
  },
  {
    authorName: "Prakash Joshi Pax",
    authorSubtitle: "Writer, Medium",
    testimonial: "What I loved about this tool is that it's private, and open source and really fast.",
    source: "https://beingpax.medium.com/9-new-obsidian-plugins-you-need-to-check-out-today-d55dba29bfb8"
  },
  {
    authorName: "imbolc",
    authorSubtitle: "Chrome Extension Review",
    testimonial: "I've been using Harper in Neovim for a long time and am glad to see it as an extension!",
    source: "https://chromewebstore.google.com/detail/private-grammar-checker-h/lodbfhdipoipcjmlebjbgmmgekckhpfb/reviews"

  },
  {
    authorName: "Martijn Gribnau",
    authorSubtitle: "Software Engineer",
    testimonial: "What a delightful way to check for flagrant spelling errors in markdown files. Thanks Harper authors!",
    source: "https://gribnau.dev/posts/harper-cli/"
  },
  {
    authorName: "Chloe Ferguson",
    authorSubtitle: "Writer, We Are Founders",
    testimonial: "Harper excels at catching the kinds of mistakes that matter in technical writing – improper capitalization, misspelled words, and awkward phrasing that can make documentation unclear.",
    source: "https://www.wearefounders.uk/the-grammar-checker-that-actually-gets-developers-meet-harper/"
  },
  {
    authorName: "Rogerio Taques",
    authorSubtitle: "Chrome Extension Review",
    testimonial: "I've been using Harper instead of Grammarly for a few months already, and I can't be happier! I can't wait to see the great improvement when this tool reaches version 1.0.0! Great job! I hope that, eventually, it will also support languages other than English.",
    source: "https://chromewebstore.google.com/detail/private-grammar-checker-h/lodbfhdipoipcjmlebjbgmmgekckhpfb/reviews"
  },
];
</script>

<main class="mx-auto flex w-full max-w-5xl flex-col gap-12 py-12">
	<div class="space-y-6 px-4 md:px-6">
		<div class="flex w-full flex-col items-center">
			<Logo width="200px" />
		</div>
		<div class="space-y-2 text-center">
			<h1 class="font-bold">Hi. I'm Harper.</h1>
			<h2>
				The <strong class="bg-primary-100 dark:bg-primary-800 p-1 inline-block -rotate-1">Free</strong> Grammar Checker That Respects Your Privacy
			</h2>
		</div>

		<div
			class="md:flex md:flex-row grid grid-cols-2 items-center justify-evenly place-items-center gap-2 pt-2 text-center"
		>
			<Link
				href="https://github.com/automattic/harper"
				class="flex flex-row items-center [&>*]:m-2 skew-hover-left"
			>
				<GitHubLogo width="40px" height="40px" />GitHub
			</Link>

      {#if agentHas("firefox")}
	      <Link href="https://addons.mozilla.org/en-US/firefox/addon/private-grammar-checker-harper/" class="flex flex-row items-center [&>*]:m-2 skew-hover"
	      	><FirefoxLogo width="40px" height="40px" />Add to Firefox</Link
	      >
      {:else if agentHas("Edg")}
	      <Link href="https://microsoftedge.microsoft.com/addons/detail/private-grammar-checker-/ihjkkjfembmnjldmdchmadigpmapkpdh" class="flex flex-row items-center [&>*]:m-2 skew-hover-left"
	      	><EdgeLogo width="40px" height="40px" />Add to Edge</Link
	      >
      {:else}
	      <Link href="https://chromewebstore.google.com/detail/private-grammar-checking/lodbfhdipoipcjmlebjbgmmgekckhpfb?utm_source=harper-homepage&utm_medium=referral" class="flex flex-row items-center [&>*]:m-2 skew-hover"
	      	><ChromeLogo width="40px" height="40px" />Add to Chrome</Link
	      >
      {/if}
			<Link
				href="https://marketplace.visualstudio.com/items?itemName=elijah-potter.harper"
				class="flex flex-row items-center [&>*]:m-2 skew-hover-left"
			>
				<CodeLogo width="40px" height="40px" />Install in VS Code
			</Link>
			<Link
				href="/docs/integrations/obsidian"
				class="flex flex-row items-center [&>*]:m-2 skew-hover"
			>
				<ObsidianLogo width="40px" height="40px" />Install in Obsidian
			</Link>
      <Link href="https://elijahpotter.dev" class="flex flex-row items-center [&>*]:m-2 skew-hover-left"
		><img
			width="40"
			height="40"
			src="/icons/profile.svg"
			alt="Author"
		/>Author</Link
	>
		</div>

		<div class="h-[800px] w-full">
      {#if browser}
			  <LazyEditor />
      {/if}
		</div>
	</div>

	<Section>
		<svelte:fragment slot="title">What is it?</svelte:fragment>
		<p>
			Harper is a free English grammar checker designed to be just right. You can think of it as an
			open-source alternative to Grammarly. I created it after years of dealing with the shortcomings
			of the competition.
		</p>
	</Section>

	<Section layout="split">
		<svelte:fragment slot="title">Private</svelte:fragment>
		<p>Harper is completely private, in every sense of the word.</p>
		<p>Since Harper runs on-device, your data doesn't go anywhere you don't want it to.</p>
		<p>
			That means you have 100% certainty we don't violate your copyright by training large language
			models.
		</p>
		<p>
			Harper also intentionally avoids including any kind of generative AI in any part of our processing pipeline.
		</p>
		<svelte:fragment slot="aside">
			<img
				src="/images/camera.webp"
				class="w-full rounded-xl object-cover shadow-sm"
				alt="Graffiti of a camera."
			/>
		</svelte:fragment>
	</Section>

	<Section layout="split" reverse>
		<svelte:fragment slot="title">Native Everywhere</svelte:fragment>
		<p>
			Harper is available as a
			<Link class="text-blue-600 dark:text-blue-400" href="/docs/integrations/language-server">language server</Link>,
			<Link class="text-blue-600 dark:text-blue-400" href="/docs/harperjs/introduction">JavaScript library</Link>
			through WebAssembly, and
			<Link class="text-blue-600 dark:text-blue-400" href="https://crates.io/crates/harper-core">Rust crate</Link>,
			so you can get fantastic grammar checking anywhere you work.
		</p>
		<p>
			That said, we take extra care to make sure the
			<Link class="text-blue-600 dark:text-blue-400" href="/docs/integrations/visual-studio-code">Visual Studio Code</Link>,
			<Link class="text-blue-600 dark:text-blue-400" href="/docs/integrations/neovim">Neovim</Link>,
			<Link class="text-blue-600 dark:text-blue-400" href="/docs/integrations/obsidian">Obsidian</Link>, and
			<Link class="text-blue-600 dark:text-blue-400" href="https://chromewebstore.google.com/detail/private-grammar-checking/lodbfhdipoipcjmlebjbgmmgekckhpfb">Chrome</Link>
			extensions are amazing.
		</p>
		<svelte:fragment slot="aside">
			<div class="grid gap-2 sm:grid-cols-2">
				<Link
					href="/docs/integrations/obsidian"
					class="skew-hover-left"
				>
					<Card class="flex items-center gap-3">
						<ObsidianLogo width="40" height="40" />
						<span class="font-medium">Obsidian</span>
					</Card>
				</Link>
				<Link
					href="/docs/integrations/visual-studio-code"
					class="skew-hover"
				>
					<Card class="flex items-center gap-3">
						<CodeLogo width="40" height="40" />
						<span class="font-medium">Visual Studio Code</span>
					</Card>
				</Link>
				<Link
					href="/docs/integrations/neovim"
					class="skew-hover"
				>
					<Card class="flex items-center gap-3">
						<NeovimLogo width="40" height="40" />
						<span class="font-medium">Neovim</span>
					</Card>
				</Link>
				<Link
					href="https://chromewebstore.google.com/detail/private-grammar-checking/lodbfhdipoipcjmlebjbgmmgekckhpfb"
					class="skew-hover-left"
				>
					<Card class="flex items-center gap-3">
						<ChromeLogo width="40" height="40" />
						<span class="font-medium">Chrome</span>
					</Card>
				</Link>
				<Link
					href="https://addons.mozilla.org/en-US/firefox/addon/private-grammar-checker-harper/"
					class="skew-hover"
				>
					<Card class="flex items-center gap-3">
						<FirefoxLogo width="40" height="40" />
						<span class="font-medium">Firefox</span>
					</Card>
				</Link>
				<Link
					href="/docs/integrations/helix"
					class="skew-hover-left"
				>
					<Card class="flex items-center gap-3">
						<HelixLogo width="40" height="40" />
						<span class="font-medium">Helix</span>
					</Card>
				</Link>
				<Link
					href="/docs/integrations/wordpress"
					class="skew-hover-left"
				>
					<Card class="flex items-center gap-3">
						<WordPressLogo width="40" height="40" />
						<span class="font-medium">WordPress</span>
					</Card>
				</Link>
				<Link
					href="/docs/integrations/zed"
					class="skew-hover"
				>
					<Card class="flex items-center gap-3">
						<ZedLogo width="40" height="40" />
						<span class="font-medium">Zed</span>
					</Card>
				</Link>
				<Link
					href="/docs/integrations/emacs"
					class="skew-hover-left"
				>
					<Card class="flex items-center gap-3">
						<EmacsLogo width="40" height="40" />
						<span class="font-medium">Emacs</span>
					</Card>
				</Link>
				<Link
					href="/docs/integrations/sublime-text"
					class="skew-hover"
				>
					<Card class="flex items-center gap-3">
						<SublimeLogo width="40" height="40" />
						<span class="font-medium">Sublime Text</span>
					</Card>
				</Link>
			</div>
		</svelte:fragment>
	</Section>

	<Section layout="split">
		<svelte:fragment slot="title">Wicked Fast</svelte:fragment>
		<p>
			Since Harper runs on your devices, it's able to serve up suggestions in under 10 milliseconds.
		</p>
		<p>No network request, no massive language models, no fuss.</p>
		<svelte:fragment slot="aside">
			<Card>
				<Graph />
			</Card>
		</svelte:fragment>
	</Section>

	<Section>
		<svelte:fragment slot="title">Loved by Thousands</svelte:fragment>
		<TestimonialCollection testimonials={testimonials} />
	</Section>

	<Section id="faqs">
		<svelte:fragment slot="title">FAQs</svelte:fragment>
		<div class="space-y-4">
			<Collapsible title="Is Harper Free?">
				<p>
					Yes. Harper is free in every sense of the word. You don't need a credit card to start using
					Harper, and the source code is freely available under the Apache-2.0 license.
				</p>
			</Collapsible>
			<Collapsible title="How Does Harper Work?">
				<p>
					Harper watches your writing and provides instant suggestions when it notices a grammatical
					error. When you see an underline, it's probably because Harper has something to say.
				</p>
			</Collapsible>
			<Collapsible title="Does Harper Change The Meaning of My Words?">
				<p>
					No. Harper will never intentionally suggest an edit that might change your meaning. Harper
					strives to never make it harder to express your creativity.
				</p>
			</Collapsible>
			<Collapsible title="Is Harper Really Private?">
				<p>
					Harper is the only widespread and comprehensive grammar checker that is truly private. Your
					data never leaves your device. Your writing should remain just that: <strong>yours.</strong>
				</p>
			</Collapsible>
			<Collapsible title="How Do I Use or Integrate Harper?">
				<div class="space-y-3">
					<p>
						That depends on your use case. Do you want to use it within Obsidian? We have an
						<Link class="text-blue-600 dark:text-blue-400" href="/docs/integrations/obsidian">Obsidian plugin</Link>. Do you want to use it within WordPress? We have a
						<Link class="text-blue-600 dark:text-blue-400" href="/docs/integrations/wordpress">WordPress plugin</Link>. Do you want to use it within your Browser? We have a
						<Link class="text-blue-600 dark:text-blue-400" href="/docs/integrations/chrome-extension">Chrome extension</Link> and a
						<Link class="text-blue-600 dark:text-blue-400" href="/docs/integrations/firefox-extension">Firefox plugin</Link>. Do you want to use it within your code editor? We have documentation on how you can integrate with
						<Link class="text-blue-600 dark:text-blue-400" href="/docs/integrations/visual-studio-code">Visual Studio Code and its forks</Link>,
						<Link class="text-blue-600 dark:text-blue-400" href="/docs/integrations/neovim">Neovim</Link>,
						<Link class="text-blue-600 dark:text-blue-400" href="/docs/integrations/helix">Helix</Link>,
						<Link class="text-blue-600 dark:text-blue-400" href="/docs/integrations/emacs">Emacs</Link>,
						<Link class="text-blue-600 dark:text-blue-400" href="/docs/integrations/zed">Zed</Link> and
						<Link class="text-blue-600 dark:text-blue-400" href="/docs/integrations/sublime-text">Sublime Text</Link>. If you're using a different code editor, then you can integrate directly with our language server,
						<Link class="text-blue-600 dark:text-blue-400" href="/docs/integrations/language-server">harper-ls</Link>. Do you want to integrate it in your web app or your JavaScript/TypeScript codebase? You can use
						<Link class="text-blue-600 dark:text-blue-400" href="/docs/harperjs/introduction">harper.js</Link>. Do you want to integrate it in your Rust program or codebase? You can use
						<Link class="text-blue-600 dark:text-blue-400" href="https://crates.io/crates/harper-core">harper-core</Link>.
					</p>
				</div>
			</Collapsible>
			<Collapsible title="What Human Languages Do You Support?">
				<p>
					We currently only support English and its dialects British, American, Canadian,
					Australian, and Indian. Other languages are on the horizon, but we want our English support to be truly
					amazing before we diversify.
				</p>
			</Collapsible>
			<Collapsible title="What Programming Languages Do You Support?">
				<div class="space-y-3">
					<p>
						For <code>harper-ls</code> and our code editor integrations, we support a wide variety of
						programming languages. You can view all of them over at the
						<Link class="text-blue-600 dark:text-blue-400" href="/docs/integrations/language-server#Supported-Languages">harper-ls documentation</Link>.
						We are entirely open to PRs that add support. If you just want to be able to run grammar checking
						on your code's comments, you can use
						<Link class="text-blue-600 dark:text-blue-400" href="https://github.com/Automattic/harper/pull/332">this PR as a model for what to do</Link>.
					</p>
					<p>
						For <code>harper.js</code> and those that use it under the hood like our Obsidian plugin, we
						support plaintext and/or Markdown.
					</p>
				</div>
			</Collapsible>
			<Collapsible title="Where Did the Name Harper Come From?">
				<p>
					See <Link class="text-blue-600 dark:text-blue-400" href="https://elijahpotter.dev/articles/naming_harper">this blog post</Link>.
				</p>
			</Collapsible>
			<Collapsible title="Do I Need a GPU?">
				<p>No. Harper runs on-device, no matter what. There are no special hardware requirements. No GPU, no additional memory, no fuss.</p>
			</Collapsible>
			<Collapsible title="What Do I Do If My Question Isn't Here?">
				<p>
					You can join our
					<Link class="text-blue-600 dark:text-blue-400" href="https://discord.gg/invite/JBqcAaKrzQ">Discord</Link>
					and ask your questions there or you can start a discussion over at
					<Link class="text-blue-600 dark:text-blue-400" href="https://github.com/Automattic/harper/discussions">GitHub</Link>.
				</p>
			</Collapsible>
			<Collapsible title="Why Isn't Harper Working in Gmail?">
				<p>
          Harper will not run in Gmail unless the built-in grammar checker is disabled. If you wish to use Harper in Gmail, please <Link class="text-blue-600 dark:text-blue-400" href="https://support.google.com/mail/answer/7987?hl=en">disable the built-in grammar checker.</Link>
				</p>
			</Collapsible>
		</div>
	</Section>

	<Section>
		<svelte:fragment slot="title">Open Source</svelte:fragment>
		<p>Harper is completely open source under the Apache-2.0 license.</p>
		<p>
			Come pay us a visit on
			<Link class="text-blue-600 dark:text-blue-400" href="https://github.com/automattic/harper">GitHub</Link>.
		</p>
	</Section>
</main>



================================================
FILE: packages/web/src/routes/api/problematic-lints/+server.ts
================================================
import { type RequestEvent, redirect } from '@sveltejs/kit';
import ProblematicLints from '$lib/db/models/ProblematicLints';

export const POST = async ({ request }: RequestEvent) => {
	const data = await request.formData();

	await ProblematicLints.validateAndCreate({
		is_false_positive: data.get('is_false_positive') === 'true',
		example: data.get('example'),
		rule_id: data.get('rule_id'),
		feedback: data.get('feedback'),
	});

	throw redirect(303, '/');
};



================================================
FILE: packages/web/src/routes/api/uninstall-feedback/+server.ts
================================================
import { type RequestEvent, redirect } from '@sveltejs/kit';
import UninstallFeedback from '$lib/db/models/UninstallFeedback';

export const POST = async ({ request }: RequestEvent) => {
	const data = await request.formData();

	await UninstallFeedback.validateAndCreate({
		feedback: data.get('feedback'),
	});
	throw redirect(303, '/');
};



================================================
FILE: packages/web/src/routes/cache-healthcheck/+server.ts
================================================
export async function GET() {
	return new Response('OK', {
		headers: {
			'Cache-Control': 'no-cache',
		},
	});
}



================================================
FILE: packages/web/src/routes/docs/about/+page.md
================================================
---
title: What Is Harper?
---

Harper is a grammar checker designed to run anywhere there is text (so really, anywhere).
Most Harper users are catching their mistakes in [Neovim](./integrations/neovim), [Obsidian](./integrations/obsidian), or [Visual Studio Code](./integrations/visual-studio-code).

<script>
    import Editor from "$lib/components/Editor.svelte"
</script>

<div class="h-96">
    <Editor content={`You can try out a editor that uses\nHarper under the hood here.\n\nIt is rnning in your browser right now. \n\nNo server required!`}/>
</div>

## How Does It Work?

Harper takes advantage of decades of natural language research to analyze exactly how your words come together.
If something is off, Harper lets you know.

In a way, Harper is an error-tolerant parser for English.

## Versioning Policy

Harper uses [semantic versioning](https://semver.org/).

All components and integrations of Harper stay in version sync, including but not limited to:

- `harper.js`
- `harper-core`
- `harper-comments`
- `harper-ls`
- The Obsidian Plugin
- The VS Code Plugin
- The Chrome Extension

That means that a change in `harper.js` can cause a release of the Obsidian plugin with a version bump, even if nothing has directly changed in the Obsidian plugin.
We do this because we view Harper not as a disparate set of integrations, but as a holistic system accessible in a wide variety of places.

For the time being, we only actively develop and maintain the latest version of Harper (seen in the `master` branch on GitHub). 
If long-term support for older versions is desired, please let us know and we will do our best to accommodate you.

## Projects Using Harper

Some of the open-source projects using Harper include:

- [Gherlint](https://github.com/gherlint/gherlint)
- [walletbeat](https://github.com/walletbeat/walletbeat)
- [Stencila](https://github.com/stencila/stencila)
- [fixmyspelling](https://github.com/samedwardes/fixmyspelling)

Are you using Harper in your open source work and want to be included in this list?
If so, please open a PR. 
We would be happy to add it.



================================================
FILE: packages/web/src/routes/docs/about/+page.ts
================================================
export const ssr = false;



================================================
FILE: packages/web/src/routes/docs/contributors/architecture/+page.md
================================================
---
title: Harper's Architecture
---

This document seeks to solve one simple problem:

> "Roughly, it takes 2x more time to write a patch if you are unfamiliar with the project, but it takes 10x more time to figure out **where** you should change the code." - [Alex Kladov](https://matklad.github.io/2021/02/06/ARCHITECTURE.md.html)

This document is meant to serve as a kind of table of contents for the Harper project.
Hopefully, we can reduce that 10x down to something a little more reasonable.

## What does Harper do?

Harper tries to do one thing well: find grammatical and spelling errors in English text.
If possible, provide suggestions to correct those errors.
An error and its possible corrections together form what we call a lint.

In this vein, Harper serves the role of a [Linter](<https://en.wikipedia.org/wiki/Lint_(software)>) for English.

## `harper-core`

`harper-core` is where all the magic happens.
It contains the code needed to tokenize, parse, analyze and lint English text.

At a high level, there are just a couple types you need to worry about.

- [Document](https://docs.rs/harper-core/latest/harper_core/struct.Document.html): A representation of an English document. Implements [`TokenStringExt`](https://docs.rs/harper-core/latest/harper_core/trait.TokenStringExt.html) to make it easier to query.
- [Parser](https://docs.rs/harper-core/latest/harper_core/parsers/trait.Parser.html): A trait that describes an object that consumes text and emits tokens. The name is somewhat of a misnomer since it is supposed to only lex English (and emit [Tokens](https://docs.rs/harper-core/latest/harper_core/struct.Token.html)), not parse it. It is called a parser since most types that implement this trait parse _other_ languages (JavaScript) to extract the English text.
  - The [Markdown parser](https://docs.rs/harper-core/latest/harper_core/parsers/struct.Markdown.html) is a great example.
- [Linter](https://docs.rs/harper-core/latest/harper_core/linting/trait.Linter.html): A trait that, provided a document, will produce zero or more [Lints](https://docs.rs/harper-core/latest/harper_core/linting/struct.Lint.html#). This is usually done using direct queries on the document or by implementing a [`PatternLinter`](https://docs.rs/harper-core/latest/harper_core/linting/trait.PatternLinter.html).

If you want to add a linter to Harper, create a new file under the `linters` module in `harper-core` and create a public struct that implements the `Linter` trait.
There are a couple places in other parts of the codebase you'll need to update before it will show up in editors and have persistent settings, but that's a problem for after you've opened your pull request.

## `harper-ls`

`harper-ls` is a language server that wraps around `harper-core`.
In essence, it enables text editors and IDEs to access the capabilities of Harper over a network or via standard input/output.

If you aren't familiar with what a language server does, I would suggest reading [this](https://tamerlan.dev/an-introduction-to-the-language-server-protocol/) or the [official language server protocol documentation](https://microsoft.github.io/language-server-protocol/).

When Harper is used through Neovim, Visual Studio Code, Helix, Emacs or Sublime Text, `harper-ls` is the interface.

You can read more about it [here](../integrations/language-server).

## `harper.js`

`harper.js` is a JavaScript/TypeScript module that enables developers to use Harper on any platform that supports JavaScript and WebAssembly.
Most of the JavaScript code in `harper.js` exists to load and manage the underlying WebAssembly module (otherwise known as `harper-wasm`).

[There are more details about it in the documentation.](../harperjs/introduction)



================================================
FILE: packages/web/src/routes/docs/contributors/author-a-rule/+page.md
================================================
---
title: Author a Rule
---

[Harper's grammatical rules are many](../rules), but most are relatively easy to understand.
Before we get into how to write a rule, it is important that we get some of the language cleared up.

When we refer to a Harper rule, we are talking about [an implementation of the Linter trait](https://docs.rs/harper-core/latest/harper_core/linting/trait.Linter.html).
As you can see, there is an enormous amount of flexibility in this trait and a wide variety of potential strategies for querying the provided document to locate errors.

This guide will go through one easy way to add a complex rule to Harper.
The lofty goal is for this to be doable by someone with little to no Rust experience.
You should, however, be able to figure out how to use Git.

While this guide should be enough to get stared, [others](https://elijahpotter.dev/articles/writing_a_grammatical_rule_for_harper) have been written.

## Fork the Harper Monorepo

Before you can open a pull request or modify any code, you need a mutable copy of our monorepo.
The best way to do that is to [fork it in GitHub](https://github.com/Automattic/harper/fork).

Next, you'll want to copy this fork onto your computer and create a new branch.
GitHub has an [excellent page explaining how to clone repositories](https://docs.github.com/en/repositories/creating-and-managing-repositories/cloning-a-repository).

## Get Your Environment Set Up

Please read our [guide for getting your environment set up](./environment).

## Open a Draft Pull Request

Next, you'll want to open a draft pull request.
This gives us (the Harper maintainers) a better view of what is actively being worked on.
It also makes it much easier to ask questions about how Harper works while you're working on your rule.
[This page has more detail on why we want draft pull requests as early as possible.](https://elijahpotter.dev/articles/never_wait).

GitHub has some [good documentation on how to create a draft PR](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/creating-a-pull-request-from-a-fork) if this is your first time.

## Determine Your Rule's Needed Complexity

A vast plurality of potential grammatical rules are pretty simple.
If you're trying to extend Harper to identify a given phrase (like "all of the sudden") and replace it with something else (like "all of a sudden"), you can do this without any complex programming at all.
All you have to do is add a line to `harper-core/src/linting/phrase_corrections/mod.rs`:

```rust
"AllOfASudden" => (
    // The offending phrase
    ["all of the sudden"],
    // The correct phrase
    ["all of a sudden"],
    // The message to notify the user of the error
    "The phrase is `all of a sudden`, meaning `unexpectedly`.",
    // A description of the rule.
    "Corrects `all of the sudden` to `all of a sudden`."
),
```

This method also covers more complex cases, like if one of the words contains capitalization or the phrase is split by a line break.

You can actually add multiple offending phrases and correct phrases to the same rule:

```rust
"EnMasse" => (
    // Multiple offending phrases
    ["on mass", "on masse", "in mass"],
    ["en masse"],
```
```rust
"InOfItself" => (
    ["in of itself"],
    // Multiple correct phrases
    ["in itself", "in and of itself"],
```

For more complex corrections with multiple variants, singular and plural, or multiple verb tenses, you can use `harper-core/src/linting/phrase_set_corrections/mod.rs`.

It has two sections. The `add_1_to_1_mappings` section is simpler, supporting sets of corrections with a single name, where each pair is a single offending phrase and a single correct phrase.
```rust
"Ado" => (
    &[
        // Multiple variants but only one offending phrase
        // and one correct phrase
        ("further adieu", "further ado"),
        ("much adieu", "much ado"),
    ],
    "Use `ado` (meaning 'fuss') not `adieu` (meaning 'farewell').",
    "Corrects `adieu` to `ado` in common phrases."
),
```

The `add_many_to_many_mappings` section is more complex. Each set still has a single name, but each pair can have multiple offending phrases and multiple correct phrases.
```rust
"ChangeTack" => (
    &[
        // Both multiple variants and also multiple offending
        // phrases and/or correct phrases
        (&["change tact", "change tacks"], &["change tack"]),
        (&["changed tact", "changed tacks"], &["changed tack"]),
    ],
    "A change in direction is a change of `tack` (not `tact`).",
    "Corrects the idiom `change tack`."
),
```


Similarly, if you just want Harper to enforce proper capitalization of a multi-token proper noun (like "Tumblr Blaze") you just need to add an entry to `harper-core/proper_noun_rules.json`.

```javascript
// The name of the rule
"TumblrNames": {
    // The canonical capitalization of the proper noun.
	"canonical": [
		"Tumblr Blaze",
		"Tumblr Pro",
		"Tumblr Live",
		"Tumblr Ads",
		"Tumblr Communities",
		"Tumblr Shop",
		"Tumblr Dashboard"
	],
    // A description to be shown to the user when they make a mistake.
	"description": "Ensure proper capitalization of Tumblr-related terms."
},
```

If neither of those work for the rule you have in mind, continue on to the next section.

## Create Your Rule's Module

Now that we've established that your rule is of a non-trivial level of complexity, here is what you need to do.

We separate each rule into its own file inside the `harper-core/src/linting` [directory.](https://github.com/Automattic/harper/tree/master/harper-core/src/linting)
Create a new file under that directory with the name of your rule in `snake_case`.
If you can't decide yet, just call it `my_rule.rs`.

Don't put anything in this file yet, there's some bookkeeping we have to do first.

## Register Your Rule

Before we start describing to Harper what grammatical errors to look for, we need to register your rule within the system.

First, add your rule's module to the tree by adding it to [the top of the mod file](https://github.com/Automattic/harper/blob/master/harper-core/src/linting/mod.rs).
It should look something like this:

```rust title="harper-core/src/linting/mod.rs"
mod an_a;
mod avoid_curses;
mod boring_words;
mod capitalize_personal_pronouns;
// [svp! df:+]mod my_rule;
```

Next, we need to configure whether your rule will be enabled by default.
While you're working on it, we **highly suggest** you enable it to avoid confusion.

To do that, import your rule at the top of the `lint_group` [file](https://github.com/Automattic/harper/blob/master/harper-core/src/linting/mod.rs).

```rust title="harper-core/src/linting/lint_group.rs"
use super::an_a::AnA;
use super::avoid_curses::AvoidCurses;
use super::boring_words::BoringWords;
use super::capitalize_personal_pronouns::CapitalizePersonalPronouns;
use super::correct_number_suffix::CorrectNumberSuffix;
// [svp! df:+]use super::my_rule::MyRule;
```

Finally, enable it in a macro invocation near the bottom:

```rust title="harper-core/src/linting/lint_group.rs"
insert_struct_rule!(AdjectiveOfA, true);
insert_expr_rule!(BackInTheDay, true);
insert_struct_rule!(WordPressDotcom, true);
insert_expr_rule!(OutOfDate, true);
// [svp! df:+]insert_expr_rule!(MyRule, true);
```

If you use a `ExprLinter`, use `insert_expr_rule` to take advantage of Harper's aggressive caching.
Otherwise, use `insert_struct_rule`.

## Write Your Rule

Defining an expression and [implementing the ExprLinter trait](https://docs.rs/harper-core/latest/harper_core/linting/trait.ExprLinter.html) is the easiest way to define a new rule for Harper.
Here's a template to get you started:

```rust title="my_rule.rs"
use crate::{
    Lrc, Token
};

use super::{Lint, ExprLinter};

pub struct MyRule {
    expr: Box<dyn Expr>,
}

impl Default for MyRule {
    fn default() -> Self {
        // Define the grammatical expr the rule should look for in user text.
        let mut expr = todo!();

        Self {
            expr: Box::new(expr),
        }
    }
}

impl ExprLinter for ThatWhich {
    /// Pass the expr to the ExprLinter framework.
    fn expr(&self) -> &dyn Expr {
        self.expr.as_ref()
    }

    /// Any series of tokens that match the expr provided in the `default()` method above will
    /// be provided to this function, which you are required to map into a [`Lint`] object.
    fn match_to_lint(&self, matched_tokens: &[Token], source: &[char]) -> Option<Lint> {
        unimplemented!();
    }

    fn description(&self) -> &'static str {
        "Replace this text with a description of what your rule looks for."
    }
}
```

## Test Your Changes

To test your rule, first write out an example of the error it looks for in a test file at the root of the Harper monorepo.

```markdown title="test.md"
This is an test of the `an_a` rule.
Your test should look different.
```

### Using the Command Line

From there, you can run `just lint <test filename>`.
It should emit a readable report of the grammatical errors in the document.
If the error your rule looks for does _not_ appear in this list, something is wrong.

If you need any help writing or debugging rules, don't be afraid to contact the Harper team in your draft pull request.

> **Note:** if two lints (or suggestions) overlap or address the same problem, this command will only display the first one.
> In that case, you might want to use another method of debugging.

### Using Visual Studio Code

First make sure you have [the extension installed from the marketplace](https://marketplace.visualstudio.com/items?itemName=elijah-potter.harper).
Then, configure the path of the `harper-ls` binary the Visual Studio Code extension uses in the settings page.
Set it to `<harper repo>/target/release/harper-ls`.

![How to change the `harper-ls` path](/images/vscode_harper_path.webp)

Every time you want to test a change, you'll have to recompile `harper-ls` and reload Visual Studio Code with the `Developer: Reload Window` command in the command palette.

```bash
cargo build --release # Run in the monorepo to compile `harper-ls`.
```

:::note
This workflow only works if all you're changing is the Rust code. If your changes include updates to the VS Code extension or if you'd like to test your new rule's setting in VS Code by adding it to `package.json`, then you'd need to open the extension in an [Extension Development Host](./visual-studio-code#Running-the-Extension).
:::

## Elevate Your Pull Request

Once you're satisfied with your rule, you can go ahead and elevate your pull request to mark it as "ready for review."
At that point, a maintainer on the Harper team take a look at it and (hopefully) merge it.



================================================
FILE: packages/web/src/routes/docs/contributors/brill/+page.md
================================================
---
title: Brill Tagging
---

Harper uses Brill tagging as a refinement step to a dictionary-based [POS tagging](https://en.wikipedia.org/wiki/Part-of-speech_tagging) approach.
This method retains low-latency and high-throughput without bundling a large, high-entropy language model.

While documentation on this site is sparse, initial development was accompanied by [a blog post](https://elijahpotter.dev/articles/transformation-based_learning), which can hopefully explain some of the more abstract details of the process.



================================================
FILE: packages/web/src/routes/docs/contributors/chrome-extension/+page.md
================================================
---
title: Chrome Extension
---

Harper's Chrome extension is still in its infancy.
At a high level, there are just three components: the content script, the options page and the popup "page".

At the moment, this document is also in its infancy.
It is incomplete, and we would _really appreciate_ contributions to make it better.

![The Chrome extension's high-level architecture.](/images/chrome_extension_diagram.png)

## The Content Script

The content script has three responsibilities:

- Reading text from the user's currently open web page.
- Writing text back to the user's web page (after applying a suggestion to it).
- Rendering underlines over their text (this is the hard part).

All three of these responsibilities are handled by the `lint-framework` package.

Notably, it does not do any linting itself.
Instead, it submits requests to the background worker to do so, since instantiating a WebAssembly module on every page load is expensive.

## Popup Page

![The Chrome extension's popup page](/images/chrome_extension_popup.png)

At the moment, the popup page has just one functional button that toggles Harper on the current domain.
Again, it doesn't interact with local storage itself to do this.
Rather, it initiated requests to the background worker, which then interfaces with local storage.

## Options Page

![The Chrome extension's popup page](/images/chrome_extension_options.png)

Similar to the popup page, the options page initiates requests to the background worker to change the extensions configuration.
It has settings for:

- Changing the English dialect Harper lints for.
- Enabling/disabling individual rules

It will eventually allow users to clear ignored suggestions and configure their dictionary.

## The Background Worker

This is the location of a lot of centralized "business" logic.
It:

- Loads `harper.js` and performs linting
- Handles persistent storage and configuration of:
    - Dialect
    - Rules
    - Domain toggling

## The Firefox Extension

Despite the name of the package, the `chrome-plugin` also supports Firefox. 
To build for Firefox, just use `pnpm zip-for-firefox` or otherwise compile with the environment variable `TARGET_BROWSER=firefox`.

## Other Reading

- [Putting Harper in the Browser: Technical Details](https://elijahpotter.dev/articles/putting_harper_in_your_browser)
- [The Art of Exception](https://elijahpotter.dev/articles/the_art_of_exception)



================================================
FILE: packages/web/src/routes/docs/contributors/committing/+page.md
================================================
---
title: Committing
---

Harper follows [conventional commit practices](https://www.conventionalcommits.org/en/v1.0.0/).
Before creating a pull request, please make sure all your commits follow the linked conventions.

Additionally, to minimize the labor required to review your commit, we run a relatively strict suite of formatting and linting programs.
We highly recommend that you run both `just format` and `just precommit` before submitting a pull request.
If those scripts don't work in your environment, we run `just precommit` through GitHub Actions inside of pull requests, so you may make modifications and push until the checks pass.

If this sounds intimidating, don't worry.
We are entirely willing to work with you to make sure your code can make it into Harper, just know it might take a little longer.



================================================
FILE: packages/web/src/routes/docs/contributors/dictionary/+page.md
================================================
---
title: Updating the Curated Dictionary
---

The curated dictionary is the English dictionary Harper uses as reference internally when analyzing or modifying English text.
It is common, especially with technical language, to come across words that are not in this dictionary.
If this happens to you, please open a PR to get them in.

PR [#343](https://github.com/Automattic/harper/pull/343) is a practical example of the ideas described here.

There are two files you need to worry about.
[`harper-core/dictionary.dict`](https://github.com/Automattic/harper/blob/master/harper-core/dictionary.dict) and [`harper-core/annotations.json`](https://github.com/Automattic/harper/blob/master/harper-core/annotations.json) (formerly `affixes.json`).
The first is a list of words, tagged with modifiers defined in the second.

For example, all words, such as "move", tagged with `L`, will be expanded to two dictionary entries, "move" and "movement".
In `annotations.json`, this expansion rule looks like this:

```js title=annotations.json
{
	"L": {
		// A description of the rule.
		"#": "'-ment' suffix",
        // Denotes that the area of interest is at the _end_ of the base word.
		"kind": "suffix",
        // Declare that it is OK to use the result of the expansion with other expansions.
		"cross_product": true,
        // The actual replacement rules that result in an expansion.
		"replacements": [
			{
                // If present, remove this text from the area of interest before expansion.
				"remove": "",
				"add": "ment",
                // A simplified regex-like pattern that describes what the area of interest must look like in order for this particular replacement to be applied.
				"condition": "."
			}
		],
        // The metadata that should be applied to the expanded word.
		"target": {},
        // The metadata that should be applied to the base word.
		"base_metadata": {}
	}
}
```

Those familiar with `hunspell` might notice some similarities with their dictionary format.
The main differences are the [metadata fields.](https://docs.rs/harper-core/latest/harper_core/lexeme_metadata/struct.LexemeMetadata.html)

There is a separate section, `properties` that is specifically for special rules that add only metadata to the words they're applied to.

## Adding Nouns

You don't need to know any of the nitty-gritty details to add nouns to the dictionary.
Use the tool we have in the repo:

```bash
just addnoun <YOUR NOUN HERE>
```

If this command doesn't look familiar, [read our setup documentation for contributors](./environment).



================================================
FILE: packages/web/src/routes/docs/contributors/environment/+page.md
================================================
---
title: Set Up Your Environment
---

Depending on what you're wanting to work on within the Harper repo, you may not need to set up every aspect of the environment described on this page.
For example, if you only intend to work on the core grammar engine, `harper-ls`, or `harper-cli`, you only need `cargo` installed.
In that case, Harper follows all of the standard conventions for Rust projects, so any existing Rust knowledge will apply.

If you intend to work on the Chrome extension, Obsidian plugin, or certain other projects, you'll need the full environment set up.

To use _all_ the tooling we use to build and debug Harper, you'll need the following programs available in your `$PATH`.
Please read the manuals for each tool for instructions on how to install it.
For Nix users, we provide a [Nix development shell](#Nix-development-shell) to setup all the necessary tooling automatically.

- [`just`](https://github.com/casey/just)
- `bash`
- [`cargo`](https://www.rust-lang.org/) (we develop against the latest version of Rust)
- `pnpm`
- `node`
- `grep`
- [`wasm-pack`](https://drager.github.io/wasm-pack/installer/)
- `zip`
- [`cargo-hack`](https://github.com/taiki-e/cargo-hack?tab=readme-ov-file#installation)

To run integration tests, you may also need `libnss3` and/or `libasound3`.
These are installable in Ubuntu using `apt-get`.

```bash
sudo apt-get install libnss3
sudo apt-get install libasound2
```

We develop a set of tools, accessible via `just`, to build and debug Harper's algorithm (otherwise known as `harper-core`) and its various integrations.
The source code is in the `justfile` [at the root of the repository](https://github.com/Automattic/harper/blob/master/justfile).
To see all the tools in the toolbox, run:

```bash
just --list
```

> Please note that `just build-web` _only_ builds the website for production, while `just dev-web` also spins up a development server.

Before making any modifications, we highly recommend that you run `just setup` to populate your build caches and download all dependencies.
If you see a Visual Studio code window pop open, don't worry! That's just a part of our integration tests.

## Nix development shell

If you use [nix-direnv](https://github.com/nix-community/nix-direnv), the shell will be loaded automatically when you change into the project directory.

Otherwise, run:

```bash
nix develop
```

This will start a bash shell that provides the build environment with everything you need to start contributing!



================================================
FILE: packages/web/src/routes/docs/contributors/faq/+page.md
================================================
---
title: Frequently Asked Questions
---

This page will be composed of frequently asked questions for contributors.

## What's the Difference Between a `Linter` and a `PatternLinter`?

![A diagram that shows the relationship between a `Linter` and a `PatternLinter`](/images/linter_diagram.png)

A [`Linter`](https://docs.rs/harper-core/latest/harper_core/linting/trait.Linter.html) is a Rust trait for a type that queries a [`Document`](https://docs.rs/harper-core/latest/harper_core/struct.Document.html) to identify grammatical errors, returning a human-readable list of errors, optionally with suggestions that could resolve them.

A [`PatternLinter`](https://docs.rs/harper-core/latest/harper_core/linting/trait.PatternLinter.html) is another Rust trait for a type that can hook into the `PatternLinter` framework.
The `PatternLinter` provides a pattern, which the framework locates inside of documents.
When a sequence of tokens is matched, they are provided to `match_to_lint` to map the match to a human-readable error.

All types that implement `PatternLinter` also implement `Linter` thanks to a [blanket implementation](https://doc.rust-lang.org/reference/glossary.html?highlight=blanket#blanket-implementation) of the latter upon the former.



================================================
FILE: packages/web/src/routes/docs/contributors/introduction/+page.md
================================================
---
title: Introduction to Contributing
---

Harper is completely open to outside contributions of any kind.

If you have a feature request or bug to report, please [create an issue](https://github.com/automattic/harper/issues) or ask us [a question on Discord](https://discord.gg/JBqcAaKrzQ) and we'll get back to you as soon as we can.

If you're interested in making a change to the code, we have documentation on [setting up your environment](./environment) and [getting your changes merged in](./committing).

## Other Resources

- [Why you should open a draft pull request as soon as possible.](https://elijahpotter.dev/articles/never_wait)
- [LLM-Assisted Fuzzing](https://elijahpotter.dev/articles/LLM_assisted_fuzzing)



================================================
FILE: packages/web/src/routes/docs/contributors/local-stats/+page.md
================================================
---
title: Local Statistics
---

Harper keeps track of certain aspects of your writing.
Things like:

- What words are misspelled most often?
- How often do you accept Harper's suggestions?
- How much do you write?

Harper does this to help _you_ improve _your_ writing.
In the interest of maintaining our user's data sovereignty, Harper aims to do all this processing __on the device__.
None of this data is sent anywhere without your explicit permission.

This document seeks to detail how Harper's statistics logging works under the hood.

## The `stats.txt` File.

The `stats.txt` file (whose name is subject to change) is a log of actions taken by Harper or the user.
It records specific events, along with some contextual information (like which word was misspelled).

The `stats.txt` file is formatted into lines (so it is easy to open in append-mode), each containing a JSON object.

```
{"kind":{"Lint":{"kind":"Spelling","context":[{"content":"mispelled","kind":{"kind":"Word","value":null}}]}},"when":1743696274,"uuid":"39d29bd0-5eb1-4bad-89ee-5a48531a4cbe"}
{"kind":{"Lint":{"kind":"Spelling","context":[{"content":"isnt","kind":{"kind":"Word","value":null}}]}},"when":1743696281,"uuid":"22e1ca15-e583-49c5-9da3-bc7e625d9682"}
{"kind":{"Lint":{"kind":"Spelling","context":[{"content":"Teasting","kind":{"kind":"Word","value":null}}]}},"when":1743696288,"uuid":"bd955190-a4d9-4f3e-b7df-d4bf6f12a415"}
```

In `harper-ls` it is written to the Harper `data` directory. (On Linux `~/.local/share/harper-ls/stats.txt`, on macOS `~/Library/Application Support/harper-ls/stats.txt`, on Windows `%FOLDERID_LocalAppData%/harper-ls/stats.txt`)
In `harper.js` it is available through methods of objects that implement the [`Linter`](/docs/harperjs/ref/harper.js.linter.html) interface.

A simple dashboard to view a summary of these statistics is available [on our website](/stats).



================================================
FILE: packages/web/src/routes/docs/contributors/obsidian/+page.md
================================================
---
title: Contributor's Guide to the Obsidian Plugin
---

This page will outline the most important bits of information needed to work on the Harper Obsidian plugin.
In addition to that outlined in [environment set up page](./environment), you'll also need a working [Obsidian installation](https://obsidian.md/) and vault prepared.

All the code for the Obsidian plugin lies in the `packages/obsidian-plugin` directory of our [monorepo](https://github.com/automattic/harper).

## Obsidian's Quirks

Obsidian, in the interest of relieving their development team of any overhead, imposes some restrictions on our plugins that make the build and deploy process unusual.

### Plugins Must Be a Single File

All the executable code for an Obsidian plugin must be contained within a single file.
That includes both JavaScript and—in our case—WebAssembly.

This is why the only artifact of the Harper Obsidian plugin build process is a single, [heavily minimized](https://www.cloudflare.com/learning/performance/why-minify-javascript-code/) `main.js` file.

### Plugins Are Loaded from a GitHub Repository

All Obsidian plugins are downloaded and installed from the latest release in a dedicated GitHub repository.
Since Harper uses a monorepo, our [dedicated GitHub repository](https://github.com/Automattic/harper-obsidian-plugin) is just a skeleton, containing barely more than a plugin manifest and `README.md`.

PRs for the Obsidian plugin should be __submitted to the monorepo__.
When a release is necessary, Harper maintainers will increment the version in the [skeletal repository](https://github.com/Automattic/harper-obsidian-plugin) and create a release.

## Developing the Harper Obsidian Plugin

Obsidian loads its plugins from the dedicated plugin directory inside your vault:

```
<vault dir>/.obsidian/plugins/<plugin name>
```

For Harper, this looks exactly as you'd expect:

```
<vault dir>/.obsidian/plugins/harper
```

The workflow for quickly iterating on the plugin looks something like this:

1. Compile and start watching for changes with `just setup && cd packages/obsidian-plugin && pnpm dev`.
   This will continously rebuild `main.js` anytime you make a change to a file in the `packages/obsidian-plugin` directory.
2. Copy the `manifest.json` from the skeletal repo to the dedicated plugin directory shown above.
3. Create a symbolic link to the `main.js` produced by step 1 in the dedicated plugin directory above.
4. Anytime you make a change, run the `Reload app without saving` command inside of Obsidian.

If you've done everything right, the dedicated plugin directory should contain three files:

1. `main.js`
2. `manifest.json`
3. `data.json` 

`data.json` is a configuration file created and modified by the Harper plugin to persist settings, the user's dictionary and other miscellaneous things.



================================================
FILE: packages/web/src/routes/docs/contributors/review/+page.md
================================================
---
title: Reviewing Pull Requests
---

There are a lot of individual components and artifacts that make up Harper.
How a patch gets reviewed depends significantly on which component or artifact it affects.
This page seeks to document the tooling available for downloading and testing patches on a local machine.

## Patches to `harper-core`

If a patch only affects a grammar rule, it should only be touching `harper-core`.
This means you can test the change using any Harper frontend (of which there are many).

### Using GitHub Actions Artifacts

We run builds for a variety of platforms whenever a Pull Request is pushed to.
You can use these to review changes to various aspects of Harper, including `harper-ls`, `harper-cli`, and the Visual Studio Code plugin.

![How to download the Windows Visual Studio Code plugin from the GitHub Actions run.](/images/download_artifact.gif)

### Testing Using Cargo and `harper-cli`

Most of our build tooling exists for Harper's various integrations.
If you are testing `harper-core`, you can skip all the fluff and compile the patch using [Cargo](https://doc.rust-lang.org/cargo/) directly.

```bash
cargo install --git https://github.com/automattic/harper --branch <branch-name> <binary-artifact> --locked
```

For example, for [PR #445](https://github.com/Automattic/harper/pull/455), we can install the patched version of the `harper-cli` debug tool with the following command:

```bash
cargo install --git https://github.com/automattic/harper --branch somewhat-something harper-cli --locked
```

From there, you can run the tool on any file with `harper-cli lint <path>`.

### Testing Via the Docker Image

We build our web documentation in a Docker image.
This documentation includes a [demo](/), so you can also use this image to review changes to linting rules and other aspects of the core algorithm.

```bash
git clone https://github.com/automattic/harper
cd harper
git switch <branch from PR>
IMAGE_HASH=$(docker build . -q)
docker run -p 3000:3000 -it $IMAGE_HASH
```

From there, open up `http://localhost:3000` in your web browser of choice and use the text area to test the change.



================================================
FILE: packages/web/src/routes/docs/contributors/tests/+page.md
================================================
---
title: About Harper's Test Suite
---

Harper's goal is to deliver top-tier grammar checking fast, without compromising privacy.
How do we maintain quality while also iterating quickly on our core engine?

As you know, Harper's core engine is written in Rust.
As a corollary to that, we use Cargo to pull dependencies, build, and test the system.
While we do take advantage of snapshot and integration tests, we tend to focus our efforts on unit tests.

## Performance

In the interest of maintaining fast iteration cycles, we run our tests with `opt-level = 1`.
These optimizations are known to cause issues with debuggers. 
If you plan to use one, you may want to comment them out.

@code(../../../../../../../Cargo.toml)

## Other Reading

- [3 Traits of Good Test Suites](https://elijahpotter.dev/articles/3_traits_of_good_test_suites)



================================================
FILE: packages/web/src/routes/docs/contributors/visual-studio-code/+page.md
================================================
---
title: Visual Studio Code
---

This document details how to develop the Visual Studio Code extension locally. If you're interested in how it's packaged and distributed, you can check out the [Release VS Code Plugin](https://github.com/Automattic/harper/blob/master/.github/workflows/release_vscode_plugin.yml) workflow.

## Notes

- The extension code and its tests live in the `packages/vscode-plugin/src` directory. Most changes you'll need to make will be there.
- VS Code can only pick up the tasks and launch configurations set in `packages/vscode-plugin/.vscode` if `packages/vscode-plugin`, not the root of the Harper repository, is open.
- You can look at the project's [`justfile`](https://github.com/Automattic/harper/blob/master/justfile) to see exactly what running the `just` recipes below does.

## Prerequisites

- Make sure to [set up your environment](./environment). Be sure to run `just setup` as the guide recommends to make sure the extension's dependencies are installed.
- Install the [recommended extension](https://github.com/Automattic/harper/blob/master/packages/vscode-plugin/.vscode/extensions.json), [`connor4312.esbuild-problem-matchers`](https://marketplace.visualstudio.com/items?itemName=connor4312.esbuild-problem-matchers), so VS Code can understand and run esbuild tasks.
- Before running or testing the extension using VS Code's Debugger, make sure you have `harper-ls` in `packages/vscode-plugin/bin`. You can either manually create the directory, compile `harper-ls`, and put it there or you can run `just test-vscode` or `just package-vscode` which will do that for you.

## Running the Extension

Following these steps will open the extension in a new Extension Development Host window, so you can view your changes.

1. Open the Run and Debug view by selecting it from the Activity Bar or by pressing `Ctrl+Shift+D`.
2. Choose `Run Extension`, if not chosen already.
3. Click the play (Start Debugging) button or press `F5`.

## Running the Tests

### Using the Command Line

You may run the following command to run the tests, this is the recommended way.

```bash
just test-vscode
```

### Using VS Code's Debugger

Remember: VS Code can only pick up the tasks and launch configurations set in `packages/vscode-plugin/.vscode` if `packages/vscode-plugin`, not the root of the Harper repository, is open.
That means you need to manually open VS Code in the `vscode-plugin` directory yourself.

You may also follow these steps to run the tests through your VS Code installation.

1. Open the Run and Debug view by selecting it from the Activity Bar or by pressing `Ctrl+Shift+D`.
2. Choose `Test Extension`, if not chosen already.
3. Click the play (Start Debugging) button or press `F5`.

## Packaging and Installing the Extension

1. Package the extension:

   ```bash
   just package-vscode
   ```

2. Install the extension:

   ```bash
   code --install-extension path/to/created/.vsix
   ```



================================================
FILE: packages/web/src/routes/docs/contributors/wordpress/+page.md
================================================
---
title: WordPress Plugin
---

This page will describe most of what you need to know to build and develop the WordPress plugin locally.
You do NOT need to have a WordPress installation on your machine (or hosted on a server, for that matter) to work on the Harper plugin.

Make sure you read the [introduction to contributing](./introduction) before opening a pull request.

## Notes

- The plugin does not have any kind of automated testing.
- You can look at the project's [`justfile`](https://github.com/Automattic/harper/blob/master/justfile) to see exactly what running the `just` recipes below do.

## Prerequisites

Make sure to [set up your environment](./environment).

## Running the Plugin on Your Machine

You should have already run `just setup` to prepare your environment.
All you need to do from here is run `just dev-wp`. This will:

- Download a local copy of the WordPress Playground to your machine
- Build and start watching for changes to the plugin code.
- Run WordPress, mounting the build directory to the Playground instance.

When you make changes to the plugin code, it will be rebuild and you will be able to reload the WordPress page to see your change.

:::info[Remember]
The Harper WordPress plugin only works on the Gutenberg editor.
You will need to draft or edit a post to see the option to open the sidebar.
:::

![Open the Harper Sidebar](/images/harper_wp_sidebar_button.png)



================================================
FILE: packages/web/src/routes/docs/harperjs/CDN/+page.md
================================================
---
title: Using a CDN
---

You can consume Harper from the [unpkg](https://unpkg.com/) CDN using native ECMAScript module syntax which is supported by all modern browsers.

[A simple example is provided below.](./CDN/example)

@code(../../../../../../harper.js/examples/raw-web/index.html)



================================================
FILE: packages/web/src/routes/docs/harperjs/CDN/example/+server.ts
================================================
import pageHtml from '../../../../../../../harper.js/examples/raw-web/index.html?raw';

export async function GET() {
	return new Response(pageHtml, {
		headers: {
			'Content-Type': 'text/html',
		},
	});
}



================================================
FILE: packages/web/src/routes/docs/harperjs/configurerules/+page.md
================================================
---
title: Configure Rules
---

We add new [rules](/docs/rules) to Harper on a daily basis.
As such, it is not recommended for consumers of `harper.js` to rely on any rule to exist.
Further, consumers should allow space (in their UI, database, etc.) for additional rules to be added whenever a new version of `harper.js` is published.

To make this easier, `harper.js` exposes a [`LintConfig`](/docs/harperjs/ref/harper.js.lintconfig.html) type, which can be obtained via `Linter.getLintConfig` and written using `Linter.setLintConfig`.

Each key refers to a specific rule. Each rule can be disabled (set the value to `false`), enabled (set the value to `true`), or to the default (set the value to `undefined`).
For example, the following code disables `SpellCheck`, enables `ExplanationMarks`, and sets `SameAs` to assume the default value.

```javascript
let linter = new WorkerLinter();

await linter.setLintConfig({
    SpellCheck: false,
    ExplanationMarks: true,
});
```



================================================
FILE: packages/web/src/routes/docs/harperjs/introduction/+page.md
================================================
---
title: Introduction to harper.js
---

## The Mission

If you're a developer, odds are that you are using JavaScript or TypeScript on a daily basis.
Your project probably has at least a little bit of either.

Furthermore, a plurality of focused authorship happens inside either a web browser or an [Electron-based app](https://www.electronjs.org/).
Given this, we wanted to create an environment where it would be trivial to integrate fantastic grammar checking into web applications.
That's why we created `harper.js`.

Today, it serves as the foundation for our [Obsidian plugin](/docs/integrations/obsidian) and our [website](/).

## Installation

`harper.js` is an ECMAScript module designed to be easy to import into any project.
On the inside, it uses a copy of Harper's core algorithm compiled to [WebAssembly](https://webassembly.org/).

It can be imported [natively in a browser](./CDN) or through [npm](https://www.npmjs.com/package/harper.js) and [consumed in Node.js](./node).

@install-pkg(harper.js)

Notice that the `harper.js` package is currently in early access.
This means that the API is not yet stable and we are still working out the kinks.



================================================
FILE: packages/web/src/routes/docs/harperjs/linting/+page.md
================================================
---
title: Linting With harper.js
---

[Linting](<https://en.wikipedia.org/wiki/Lint_(software)>) is the process of consuming, analyzing, and finding faults in text.
This is the principle task Harper tries to do.
When possible, Harper also tries to automatically generate fixes for any issues it finds.

In `harper.js`, there's just one interface you need to worry about: the `Linter`.

## Linters

The `Linter` type is relatively straightforward and has two implementations: the `LocalLinter` and the `WorkerLinter`.
Notice how every method returns a `Promise<...>`.

@code(../../../../../../harper.js/src/Linter.ts)

A `LocalLinter` will instantiate and prepare Harper's WebAssembly module asynchronously, but **in the same event loop**.
This can result in high [LCP](https://developer.mozilla.org/en-US/docs/Glossary/Largest_contentful_paint), so this implementation is only recommended in situations where the event loop will not be doing other latency-sensitive things.
In other words: `LocalLinter`s are not for the web.

A `WorkerLinter`, on the other hand, will instantiate and prepare Harper's WebAssembly module inside a [Web Worker](https://developer.mozilla.org/en-US/docs/Web/API/Web_Workers_API), which means it will **not** block the event loop.
This is recommended for interactive web applications.

[Visit our page about CDNs](./CDN) to see an example of a `WorkerLinter` in action, or [the page about Node.js](./node) for a `LocalLinter`.



================================================
FILE: packages/web/src/routes/docs/harperjs/node/+page.md
================================================
---
title: Using Harper in Node.js
---

Harper.js can run in Node.js.
There is just one consideration: as described in [more detailed here](./linting), we cannot use the `WorkerLinter`.
That means we must use the `LocalLinter`.

Additionally, since `harper.js` is an ECMAScript module, it must be imported in a relatively recent version of Node.js.

## Example Code

The example below can be found in [the Harper monorepo.](https://github.com/Automattic/harper/tree/master/packages/harper.js/examples/commonjs-simple)

@code(../../../../../../harper.js/examples/commonjs-simple/index.js)



================================================
FILE: packages/web/src/routes/docs/harperjs/spans/+page.md
================================================
---
title: Spans
---

When you lint a document using `harper.js`, you'll get back a series of `Lint` objects, each with a `span` method available.
There are a number of questions that come up about this method.

## What is a span?

A span is a struct that contains a start index and an end index.
The Rust code looks something like this:

```rust
struct Span {
    start: usize,
    end: usize
}
```

For the uninitiated, a `usize` is an unsigned integer.
Most commonly (and always in the context of a `Lint`), spans are referring to character windows.
More precisely, spans are windows or slices into an array of [unicode scalar values](https://www.unicode.org/glossary/#unicode_scalar_value).
This is less relevant to JavaScript consumers.
Some get confused and believe these are indices into byte arrays (C-style strings).

##  Why do I need to obtain the span through a method call?

The actual span for a `Lint` is stored inside WebAssembly memory.
In order to access that data from JavaScript, a tiny bit of WebAssembly code must be run to serialize it and convert its indices to JavaScript [number types](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Number).

## What can I use it for?

In a `Lint`, the span represents two things:

1. The location of the problematic text.
1. The text that would be edited by the relevant suggestions.

In other words, you use the span to underline the problem, then again to solve it.



================================================
FILE: packages/web/src/routes/docs/integrations/chrome-extension/+page.md
================================================
---
title: The Harper Chrome Extension
---

Harper is free to use for the > 3.6 billion people out there using Chrome.
Unlike other grammar checking plugins out there, Harper's Chrome extension does all of its work offline.
We help improve the prose and grammar of your emails, messages, and documents, all while respecting your privacy.

![A screenshot of the Chrome extension at work.](/images/chrome_extension_github.png)

To install it, visit the [Chrome Web Store](https://chromewebstore.google.com/detail/private-grammar-checking/lodbfhdipoipcjmlebjbgmmgekckhpfb) and click 'Add to Chrome'.

For our nerdy friends out there, you'll be happy to hear the Chrome extension is powered by [`harper.js`](/docs/harperjs/introduction).



================================================
FILE: packages/web/src/routes/docs/integrations/emacs/+page.md
================================================
---
title: Emacs
---

Our Emacs integration is powered by [`harper-ls`](./language-server).

## Required Setup

Make sure you have [`harper-ls` installed](./language-server#Installation) on your system and available in your `PATH`.

Since version 29, Emacs has had native support for the Language Server Protocol through [Eglot](https://www.gnu.org/software/emacs/manual/html_mono/eglot.html), so all you have to do is configure it to use `harper-ls` in your `init.el`:

```elisp title=init.el
(with-eval-after-load 'eglot
  (add-to-list 'eglot-server-programs
               '(text-mode . ("harper-ls" "--stdio"))))
```

where `text-mode` can be set to any, some, or all major modes that correspond to the [languages `harper-ls` supports](./language-server#Supported-Languages). Typically, if you want to use `harper-ls` to edit Markdown files and you have [`markdown-mode`](https://jblevins.org/projects/markdown-mode) installed, you can configure it like this:

```elisp title=init.el
(with-eval-after-load 'eglot
  (add-to-list 'eglot-server-programs
               '(markdown-mode . ("harper-ls" "--stdio"))))
```

:::note

A possible gotcha you may be encountering if you don't see any diagnostics is when Eglot automatically deduces the language ID being sent to `harper-ls` based on the major mode you used. In which case, you can set the language ID to one that is supported:

```elisp title=init.el
(with-eval-after-load 'eglot
  (add-to-list 'eglot-server-programs
               '((english-prose-mode :language-id "plaintext") . ("harper-ls" "--stdio"))
```

:::

## Optional Configuration

Additionally, you can also configure things like which linters to use or how you want code actions to appear. Below is an example config where everything is set to their default values:

```elisp title=init.el
(setq-default eglot-workspace-configuration
              '(:harper-ls (:userDictPath ""
                            :workspaceDictPath ""
                            :fileDictPath ""
                            :linters (:SpellCheck t
                                      :SpelledNumbers :json-false
                                      :AnA t
                                      :SentenceCapitalization t
                                      :UnclosedQuotes t
                                      :WrongQuotes :json-false
                                      :LongSentences t
                                      :RepeatedWords t
                                      :Spaces t
                                      :Matcher t
                                      :CorrectNumberSuffix t)
                            :codeActions (:ForceStable :json-false)
                            :markdown (:IgnoreLinkTitle :json-false)
                            :diagnosticSeverity "hint"
                            :isolateEnglish :json-false
                            :dialect "American"
                            :maxFileLength 120000
                            :ignoredLintsPath ""
                            :excludePatterns [])))
```

:::note
This example only contains some of the available linters, check out our [rules page](../rules) to view the full list.
:::

For more information on what each of these configs do, you can head over to the [configuration section](./language-server#Configuration) of our `harper-ls` documentation.

## Common Config Changes

Programmers often find certain rules have too much of a hair-trigger.
The below config is a simple cut-and-paste that gives you much fewer false-positives.

```elisp title=init.el
(setq-default eglot-workspace-configuration
              '(:harper-ls (:linters (:SpellCheck :json-false
                                      :SentenceCapitalization :json-false))))
```

## Additional Links

- [Community discussion on configuring `harper-ls` for Emacs](https://github.com/Automattic/harper/discussions/150)



================================================
FILE: packages/web/src/routes/docs/integrations/firefox-extension/+page.md
================================================
---
title: The Harper Firefox Extension
---

Harper is available for the millions who rely on Firefox for fast, private, and independent browsing.
Unlike most grammar tools, Harper's Firefox extension performs all analysis locally—never sending your text to the cloud.
Emails, chat messages, blog posts, and comments benefit from real-time grammar improvements, with your privacy intact.

![A screenshot of the Firefox extension in use.](/images/chrome_extension_github.png)

To install, head to the [Firefox Add-ons site](https://addons.mozilla.org/en-US/firefox/addon/private-grammar-checker-harper/) and select 'Add to Firefox'.

Curious how it works? The Firefox extension runs entirely on [`harper.js`](/docs/harperjs/introduction), our open-source JavaScript library.



================================================
FILE: packages/web/src/routes/docs/integrations/helix/+page.md
================================================
---
title: Helix
---

Our Helix integration is powered by [`harper-ls`](./language-server).

## Required Setup

Make sure you have [`harper-ls` installed](./language-server#Installation) on your system and available in your `PATH`.

Helix supports language servers [out-of-the-box](https://docs.helix-editor.com/languages.html), but you'll still need to configure it to use `harper-ls`. First, you need to tell Helix how it should run `harper-ls`:

```toml title=languages.toml
[language-server.harper-ls]
command = "harper-ls"
args = ["--stdio"]
```

Then, for all the [languages `harper-ls` supports](./language-server#Supported-Languages) that you want it to be enabled for, you need to declare the following in your `languages.toml`:

```toml title=languages.toml
[[language]]
name = "language-id"
language-servers = ["default-servers", "harper-ls"]
```

where `language-id` is the language ID of the language you want `harper-ls` to be used for and `default-servers` are any of the [default language servers](https://docs.helix-editor.com/lang-support.html) supported by Helix that you use for that language. For example, if you want to configure it for Markdown and you use both Marksman and Markdown-Oxide, you'd end up with this:

```toml title=languages.toml
[[language]]
name = "markdown"
language-servers = ["marksman", "markdown-oxide", "harper-ls"]
```

You need to include the default language servers since there currently isn't a way to append a language server to the default `language-servers` list. Of course, you can also add other language servers you use before or after `harper-ls`.

## Optional Configuration

Additionally, you can also configure things like which linters to use or how you want code actions to appear. Below is an example config where everything is set to their default values:

```toml title=languages.toml
[language-server.harper-ls.config.harper-ls]
userDictPath = ""
workspaceDictPath = ""
fileDictPath = ""
diagnosticSeverity = "hint"
isolateEnglish = false
dialect = "American"
maxFileLength = 120000
ignoredLintsPath = ""
excludePatterns = []

[language-server.harper-ls.config.harper-ls.linters]
SpellCheck = true
SpelledNumbers = false
AnA = true
SentenceCapitalization = true
UnclosedQuotes = true
WrongQuotes = false
LongSentences = true
RepeatedWords = true
Spaces = true
Matcher = true
CorrectNumberSuffix = true

[language-server.harper-ls.config.harper-ls.codeActions]
ForceStable = false

[language-server.harper-ls.config.harper-ls.markdown]
IgnoreLinkTitle = false
```

:::note
This example only contains some of the available linters, check out our [rules page](../rules) to view the full list.
:::

For more information on what each of these configs do, you can head over to the [configuration section](./language-server#Configuration) of our `harper-ls` documentation.

## Common Config Changes

Programmers often find certain rules have too much of a hair-trigger.
The below config is a simple cut-and-paste that gives you much fewer false-positives.

```toml title=languages.toml
[language-server.harper-ls.config.harper-ls.linters]
SpellCheck = false
SentenceCapitalization = false
```

## Additional Links

- [Helix's official documentation on `harper-ls`](https://github.com/helix-editor/helix/wiki/Language-Server-Configurations#harper-ls)
- [Community discussion on configuring `harper-ls` for Helix](https://github.com/Automattic/harper/discussions/135)



================================================
FILE: packages/web/src/routes/docs/integrations/language-server/+page.md
================================================
---
title: Language Server
---

`harper-ls` is the [Language Server Protocol](https://microsoft.github.io/language-server-protocol/) frontend for Harper.
Out of the box, it has built-in support for parsing the comments of most programming languages, as well as any and all Markdown files.

## Installation

### Scoop

You can install Harper on Windows through [Scoop](https://scoop.sh/#/apps?q=harper).

```bash
scoop install harper
```

### Homebrew

You can install Harper on macOS and Linux through [Homebrew](https://formulae.brew.sh/formula/harper).

```bash
brew install harper
```

### Arch Linux

#### Stable Release

The latest stable release is available through the [`extra` repo](https://archlinux.org/packages/extra/x86_64/harper):

```bash
sudo pacman -S harper
```

#### Bleeding-Edge

If you want the latest bleeding-edge, you can install `harper-git` from the [Arch User Repository](https://aur.archlinux.org/packages/harper-git) with your favorite AUR helper:

```bash
paru -S harper-git
# or yay -S harper-git, etc.
```

### Nixpkgs/NixOS

You may install Harper via
[Nixpkgs](https://search.nixos.org/packages?channel=unstable&show=harper&from=0&size=50&sort=relevance&type=packages&query=harper).
You can install the `harper` package via any of the normal methods such as
adding it to `environment.systemPackages`. You can try Harper within an
ephemeral shell using:

```bash
nix-shell -p harper
```

or if you have the `nix-command` and `flakes` experimental features enabled:

```bash
nix shell 'nixpkgs#harper'
```

### Cargo

If you have Rust installed, `harper-ls` is on [crates.io](https://crates.io/crates/harper-ls), so you can simply run:

```bash
cargo install harper-ls --locked
```

For this to work, make sure that `~/.cargo/bin` is in your system `$PATH`. If you are on a Debian-based Linux distribution, you may need to install `build-essential`.

### GitHub Releases

If none of the previous installation methods are available to you, we also provide [portable pre-built binaries on GitHub](https://github.com/Automattic/harper/releases).

## Dictionaries

`harper-ls` has four kinds of dictionaries: user, workspace, file-local, and static dictionaries. All four dictionaries are combined and used together when spell checking files.

### User Dictionary

Each user of `harper-ls` has their own dictionary, created on-demand the first time that a word is added to it, which by default, is located at the following paths on each operating system:

| Operating System |                                                                                Location |
| :--------------- | --------------------------------------------------------------------------------------: |
| Linux            | `$XDG_CONFIG_HOME/harper-ls/dictionary.txt` or `$HOME/.config/harper-ls/dictionary.txt` |
| macOS            |                            `$HOME/Library/Application Support/harper-ls/dictionary.txt` |
| Windows          |                                    `%FOLDERID_RoamingAppData%/harper-ls/dictionary.txt` |

This dictionary is a simple line-separated word list in plaintext. You can add and remove words at will. Code actions on misspelled words allow you to add elements to this list. Additionally, [its location is configurable](#Directories).

### Workspace Dictionary

Each workspace in which you use `harper-ls` has its own dictionary, which by default is located at `.harper-dictionary.txt` in the root of the workspace.

This dictionary is a simple line-separated word list in plaintext. You can add and remove words at will. Code actions on misspelled words allow you to add elements to this list. Additionally, [its location is configurable](#Directories).

### File-Local Dictionary

Sometimes, you'll encounter a word (or name) that is only valid within the context of a specific file. In this case, you can add this file-specific word to a file-local dictionary using code actions. Any words added to this dictionary will only be included in the combined dictionary when spell checking a file at that specific path.

You can find the file-local dictionaries in the following directories by default on each operation system:

| Operating System |                                                                                         Location |
| :--------------- | -----------------------------------------------------------------------------------------------: |
| Linux            | `$XDG_DATA_HOME/harper-ls/file_dictionaries` or `$HOME/.local/share/harper-ls/file_dictionaries` |
| macOS            |                                  `$HOME/Library/Application Support/harper-ls/file_dictionaries` |
| Windows          |                                            `%FOLDERID_LocalAppData%/harper-ls/file_dictionaries` |

The format of these files is identical to user dictionaries and [their location can also be configured](#Directories).

### Static Dictionary

The static dictionary is built into the binary and is (as of now) immutable. It contains almost all words you could possibly encounter.

We _do_ take pull requests or issues for adding words to the static dictionary. [Read the documentation on the matter before you do](../contributors/dictionary).

## Code Actions

`harper-ls` has code actions that help in quickly dealing with spelling or grammar errors you encounter. The examples below assume that you have misspelled "contained" as "containes" and have selected it to apply a code action to it.

| Code Action or Command | Description                                                | Example                                        |
| ---------------------- | ---------------------------------------------------------- | ---------------------------------------------- |
| Quick Fixes            | Suggests fixes for the selected error                      | `Replace with: "contained"`                    |
| `HarperIgnoreLint`     | Ignores the selected error for the duration of the session | `Ignore Harper error.`                         |
| `HarperAddToUserDict`  | Adds the selected word to the user dictionary              | `Add "containes" to the user dictionary.`      |
| `HarperAddToWSDict`    | Adds the selected word to the workspace dictionary         | `Add "containes" to the workspace dictionary.` |
| `HarperAddToFileDict`  | Adds the selected word to a file-local dictionary          | `Add "containes" to the file dictionary.`      |

## Ignore Comments

`harper-ls` supports skipping comment blocks that contain any of following:

- `harper:ignore`
- `harper: ignore`
- `spellcheck:ignore`
- `spellcheck: ignore`
- `spell-checker:ignore`
- `spell-checker: ignore`
- `spellchecker:ignore`
- `spellchecker: ignore`

You may notice that the last four ignore comments are the same with some of CSpell's ignore comments. That is intentional in case users wish to use Harper and CSpell together.

Here's an example of how these comments can be used:

```js
// harper:ignore this line will not be spellcheckd
function sample() {
	// harper: ignore
	// This line and any other line after it
	// will also not be spellcheckd

	// including this this one
}
```

In the above example, "spellcheckd", "this this", and other spelling or grammar errors will not be flagged.

## Configuration

`harper-ls` expects a JSON object with a `harper-ls` key that contains your configs:

```json
{
	"harper-ls": {
		// Your config goes here...
	}
}
```

### Directories

| Config              | Type     | Default Value | Description                                                     |
| ------------------- | -------- | ------------- | --------------------------------------------------------------- |
| `userDictPath`      | `string` | `""`          | Set the file path where the user dictionary is located          |
| `workspaceDictPath` | `string` | `""`          | Set the file path where the workspace dictionary is located     |
| `fileDictPath`      | `string` | `""`          | Set the directory where the file-local dictionaries are located |
| `ignoredLintsPath`  | `string` | `""`          | Set the directory where the ignored lint lists are located      |

These paths are always resolved relative to the root of the workspace in which `harper-ls` was invoked.

### Linters

These configs are under the `linters` key:

```json
{
	"harper-ls": {
		"linters": {
			// Your linter configs go here...
		}
	}
}
```

The list of linters together with their descriptions can be found at our [rules page](../rules). All linters are of `boolean` type. Here's an example config with some of them and their default values:

```json
{
	"harper-ls": {
		"linters": {
			"SpellCheck": true,
			"SpelledNumbers": false,
			"AnA": true,
			"SentenceCapitalization": true,
			"UnclosedQuotes": true,
			"WrongQuotes": false,
			"LongSentences": true,
			"RepeatedWords": true,
			"Spaces": true,
			"Matcher": true,
			"CorrectNumberSuffix": true
		}
	}
}
```

### Code Actions

These configs are under the `codeActions` key:

```json
{
	"harper-ls": {
		"codeActions": {
			// Your code action configs go here...
		}
	}
}
```

| Config        | Type      | Default Value | Description                                                                                                                                                    |
| ------------- | --------- | ------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `ForceStable` | `boolean` | `false`       | Make code actions appear in "stable" positions by placing code actions that should always be available, like adding misspelled words in the dictionary, first. |

### Markdown

These configs are under the `markdown` key:

```json
{
	"harper-ls": {
		"markdown": {
			// Your Markdown configs go here...
		}
	}
}
```

| Config            | Type      | Default Value | Description              |
| ----------------- | --------- | ------------- | ------------------------ |
| `IgnoreLinkTitle` | `boolean` | `false`       | Skip linting link titles |

### Other Configs

| Config               | Type                                                                | Default Value | Description                                                                                                                                                               |
| -------------------- | ------------------------------------------------------------------- | ------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `diagnosticSeverity` | `"error"`, `"hint"`, `"information"`, `"warning"`                   | `"hint"`      | Configures how severe diagnostics appear in your editor                                                                                                                   |
| `isolateEnglish`     | `boolean`                                                           | `false`       | In documents that are a mixture of English and another language, only lint English text. This feature is incredibly new and unstable. Do not expect it to work perfectly. |
| `dialect`            | `"American"`, `"British"`, `"Australian"`, `"Canadian"`, `"Indian"` | `"American"`  | Set the dialect of English Harper should expect.                                                                                                                          |
| `maxFileLength`      | `number`                                                            | `120000`      | Maximum length of file to be linted (in bytes). If a file is larger/longer than this, it will not be linted.                                                              |
| `excludePatterns`    | `array`                                                             | `[]`          | A set of globs to ignore. If a file matches any of the globs, it will not be linted.                                                                                      |

## Supported Languages

`harper-ls` supports a wide variety of programming and markup languages.

| Language            |          Language ID          | Comments Only |
| :------------------ | :---------------------------: | ------------: |
| C                   |              `c`              |            ✅ |
| Clojure             |           `clojure`           |            ✅ |
| CMake               |            `cmake`            |            ✅ |
| C++                 |             `cpp`             |            ✅ |
| C#                  |           `csharp`            |            ✅ |
| DAML                |            `daml`             |            ✅ |
| Dart                |            `dart`             |            ✅ |
| Git Commit          |   `git-commit`/`gitcommit`    |               |
| Go                  |             `go`              |            ✅ |
| Haskell             |           `haskell`           |            ✅ |
| HTML                |            `html`             |               |
| Ink                 |             `ink`             |               |
| Java                |            `java`             |            ✅ |
| JavaScript          |         `javascript`          |            ✅ |
| JavaScript React    |       `javascriptreact`       |            ✅ |
| Jujutsu Description |  `jj-commit`/`jjdescription`  |               |
| Kotlin              |           `kotlin`            |            ✅ |
| Literate Haskell    | `lhaskell`/`literate haskell` |               |
| Lua                 |             `lua`             |            ✅ |
| Email               |            `mail`             |               |
| Markdown            |          `markdown`           |               |
| Nix                 |             `nix`             |            ✅ |
| Org Mode            |             `org`             |               |
| PHP                 |             `php`             |            ✅ |
| Plain Text          |      `plaintext`/`text`       |               |
| Python              |           `python`            |            ✅ |
| Ruby                |            `ruby`             |            ✅ |
| Rust                |            `rust`             |            ✅ |
| Scala               |            `scala`            |            ✅ |
| Shell/Bash Script   |         `shellscript`         |            ✅ |
| Solidity            |          `solidity`           |            ✅ |
| Swift               |            `swift`            |            ✅ |
| TOML                |            `toml`             |            ✅ |
| TypeScript          |         `typescript`          |            ✅ |
| TypeScript React    |       `typescriptreact`       |            ✅ |
| Typst               |            `typst`            |               |

Want your language added?
Let us know by [commenting on this issue](https://github.com/Automattic/harper/issues/79).



================================================
FILE: packages/web/src/routes/docs/integrations/neovim/+page.md
================================================
---
title: Neovim
---

Our Neovim integration is powered by [`harper-ls`](./language-server).

## Required Setup

Make sure you have `harper-ls` installed and available on your global or Neovim's `PATH`. You can do this using [`mason.nvim`](https://mason-registry.dev/registry/list?search=harper-ls) or via any of our other [supported installation methods](./language-server#Installation).

Though Neovim supports language servers [out-of-the-box](https://neovim.io/doc/user/lsp.html), for ease of use, we suggest using `harper-ls` through [nvim-lspconfig](https://github.com/neovim/nvim-lspconfig).

Once you have `harper-ls` and nvim-lspconfig installed, you need to add this to your `init.lua`:

```lua title=init.lua
require('lspconfig').harper_ls.setup {}
```

## Optional Configuration

Additionally, you can also configure things like which linters to use or how you want code actions to appear. Below is an example config where everything is set to their default values:

```lua title=init.lua
require('lspconfig').harper_ls.setup {
  settings = {
    ["harper-ls"] = {
      userDictPath = "",
      workspaceDictPath = "",
      fileDictPath = "",
      linters = {
        SpellCheck = true,
        SpelledNumbers = false,
        AnA = true,
        SentenceCapitalization = true,
        UnclosedQuotes = true,
        WrongQuotes = false,
        LongSentences = true,
        RepeatedWords = true,
        Spaces = true,
        Matcher = true,
        CorrectNumberSuffix = true
      },
      codeActions = {
        ForceStable = false
      },
      markdown = {
        IgnoreLinkTitle = false
      },
      diagnosticSeverity = "hint",
      isolateEnglish = false,
      dialect = "American",
      maxFileLength = 120000,
      ignoredLintsPath = "",
      excludePatterns = {}
    }
  }
}
```

:::note
This example only contains some of the available linters, check out our [rules page](../rules) to view the full list.
:::

For more information on what each of these configs do, you can head over to the [configuration section](./language-server#Configuration) of our `harper-ls` documentation.

## Common Config Changes

Programmers often find certain rules have too much of a hair-trigger.
The below config is a simple cut-and-paste that gives you much fewer false-positives.

```lua title=init.lua
require('lspconfig').harper_ls.setup {
  settings = {
    ["harper-ls"] = {
      linters = {
        SentenceCapitalization = false,
        SpellCheck = false
      }
    }
  }
}
```

## Additional Links

- [nvim-lspconfig's documentation on `harper-ls`](https://github.com/neovim/nvim-lspconfig/blob/master/doc/configs.md#harper_ls)



================================================
FILE: packages/web/src/routes/docs/integrations/obsidian/+page.md
================================================
---
title: Harper for Obsidian
---

Put simply, [Harper](https://writewithharper.com/) is a grammar checking plugin that doesn't violate your privacy.
Other systems, like LanguageTool, ship your writing over the internet to centralized servers, where it's used for god-knows-what.
Harper isn't like that.

Instead, Harper runs its grammar checking engine directly _inside Obsidian_.
That means your data doesn't go anywhere you don't want it to.
Your Obsidian vault should be just what you expect: locked down and private.

![A screenshot of Obsidian with Harper installed](/images/obsidian_screenshot.webp)

Unlike other offerings (like Grammarly) Harper also explicitly ignores the contents of code fences and inline code blocks.
Since it runs entirely on-device, Harper also ends up being noticeably faster than alternatives, partly because there is no network latency.

### Open Source

- Harper is fully open source, allowing transparency and community contributions to improve its functionality.
- Developers can review the codebase or contribute directly via the [GitHub repository](https://github.com/automattic/harper).

## How It Compares to Other Plugins

| Feature                | Harper                        | LanguageTool                      |
| ---------------------- | ----------------------------- | --------------------------------- |
| **Privacy**            | 100% offline                  | Requires self-hosting for privacy |
| **Real-Time Checking** | Yes                           | Yes                               |
| **Language Support**   | English (extensible) | 30+ languages                     |
| **Open Source**        | Yes                           | Partially                         |
| **Ease of Use**        | Simple setup                  | Requires API/self-hosting setup   |
| **Performance**        | Fast and lightweight          | Resource-intensive                |

## Installation Guide

1. Open Obsidian and navigate to **Settings → Community Plugins → Browse**.
2. Search for "Harper" in the plugin library.
3. Click "Install" and then "Enable."
4. Start typing in your notes—Harper will automatically highlight errors as you go!

> **Warning**
> Harper expects an up-to-date version of the Obsidian installer. If you have issues, [reinstall Obsidian](https://obsidian.md/download) or otherwise update your installer version.

## Where's all the code?

All the code for the Harper Obsidian plugin lives [in the main Harper monorepo](https://github.com/automattic/harper/tree/master/packages/obsidian-plugin).
This repository exists to satisfy the [requirements](https://docs.obsidian.md/Plugins/Releasing/Submit+your+plugin) laid out by the Obsidian team for their plugins.

## I have a problem or feature request...

Let me know if you have any problems, feature requests, or feedback of any kind by filling out an [issue on the main repository](https://github.com/automattic/harper/issues/new).



================================================
FILE: packages/web/src/routes/docs/integrations/sublime-text/+page.md
================================================
---
title: Sublime Text
---

Our [Sublime Text](https://www.sublimetext.com/) integration is powered by [`harper-ls`](./language-server).

## Required Setup

Make sure you have `harper-ls` installed and available on your global or Sublime Text's `PATH`. You can do this using the [supported installation methods](./language-server#Installation).

Ensure you have [LSP for Sublime Text](https://lsp.sublimetext.io/) installed.

## Optional Configuration

Open `Preferences > Package Settings > LSP > Settings` and add the `harper-ls` client configuration to the "clients" section:

```json title=LSP.sublime-settings
{
  "clients": {
    "harper-ls": {
      "enabled": true,
      "command": [
        "harper-ls",
        "--stdio"
      ],
      "selector": "source.markdown | text.html.markdown | text.plain",
      "settings": {
        "harper-ls": {
          "userDictPath": "",
          "workspaceDictPath": "",
          "fileDictPath": "",
          "linters": {
            "SpellCheck": true,
            "SpelledNumbers": false,
            "AnA": true,
            "SentenceCapitalization": true,
            "UnclosedQuotes": true,
            "WrongQuotes": false,
            "LongSentences": true,
            "RepeatedWords": true,
            "Spaces": true,
            "Matcher": true,
            "CorrectNumberSuffix": true
          },
          "codeActions": {
            "ForceStable": false
          },
          "markdown": {
            "IgnoreLinkTitle": false
          },
          "diagnosticSeverity": "hint",
          "isolateEnglish": false,
          "dialect": "American",
          "maxFileLength": 120000,
          "ignoredLintsPath": "",
          "excludePatterns": []
        }
      }
    }
  }
}
```

For more information on what each of these configs do, you can head over to the [configuration section](./language-server#Configuration) of our `harper-ls` documentation.



================================================
FILE: packages/web/src/routes/docs/integrations/visual-studio-code/+page.md
================================================
---
title: Visual Studio Code
---

For our Visual Studio Code integration, we provide an extension powered by [`harper-ls`](./language-server), which also works for VS Code forks like VSCodium and Windsurf. It's available in the [Visual Studio Marketplace](https://marketplace.visualstudio.com/items?itemName=elijah-potter.harper) as well as the [Open VSX Registry](https://open-vsx.org/extension/elijah-potter/harper).

## Installation

Open the Extensions view in your editor by selecting the Extensions icon in the Activity Bar or by using the `Ctrl+Shift+X` keyboard shortcut, then search for "Harper" and click "Install".

If you prefer to use the command line, you can use the following command:

```bash
code --install-extension elijah-potter.harper
```

## Commands

| Command                         | ID                              | Description          |
| ------------------------------- | ------------------------------- | -------------------- |
| Harper: Restart Language Server | `harper.languageserver.restart` | Restarts `harper-ls` |

## Settings

The settings below are VS Code specific. There are other settings that `harper-ls` supports such as which linters to use or how code actions should appear that you can configure. You can view them in your editor's Settings UI under "Harper" or peruse through them in the [configuration section](./language-server#Configuration) of our `harper-ls` documentation.

| Setting       | Type     | Default Value | Description                                                                                                                                                 |
| ------------- | -------- | ------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `harper.path` | `string` | `""`          | Optional path to a `harper-ls` executable to use. Primarily useful if the bundled binary doesn't work in your system like in immutable Linux distributions. |

## Other Features

Since the extension is powered by `harper-ls`, it also supports [dictionaries](./language-server#Dictionaries), [code actions](./language-server#Code-Actions), and [ignore comments](./language-server#Ignore-Comments).



================================================
FILE: packages/web/src/routes/docs/integrations/wordpress/+page.md
================================================
---
title: Harper for WordPress
---

<script>
    import {Button} from "components"
</script>

Harper still works great with WordPress, but the recommended way to use it today is the
[Chrome extension](https://chromewebstore.google.com/detail/private-grammar-checking/lodbfhdipoipcjmlebjbgmmgekckhpfb).<br/>
Read the announcement: [The Chrome Extension Supersedes the WordPress Plugin](https://elijahpotter.dev/articles/the_chrome_extension_supersedes_the_wordpress_plugin).

The extension is faster to iterate on than the WordPress.com plugin review process, which means you get new
features and fixes right away. It also offers a more holistic experience by keeping your Harper preferences in
sync across the sites where you write.

![A screenshot of the Harper WordPress Demo](/images/harper_wp_playground_screenshot.png)

<Button href='https://chromewebstore.google.com/detail/private-grammar-checking/lodbfhdipoipcjmlebjbgmmgekckhpfb' target="_blank">Install the Chrome Extension</Button>

Want to explore the classic workflow? Visit our online demo that runs inside the WordPress Playground.

<Button href='/wpdemo' target="_blank">Go to the Demo</Button>

## Still using the plugin?

The existing Harper WordPress plugin will stick around, but it no longer receives regular updates and is already a
few months behind the Chrome extension. If you need a manual copy, you can still download `harper.zip` from
[GitHub releases](https://github.com/Automattic/harper/releases/latest) and upload it to your site.



================================================
FILE: packages/web/src/routes/docs/integrations/zed/+page.md
================================================
---
title: Zed
---

For our Zed integration, we have an [extension](https://github.com/zed-extensions/harper) that automatically downloads and runs [`harper-ls`](./language-server). For more information on how to install it and how it works, you can head over to the [extension's README](https://github.com/zed-extensions/harper/blob/main/README.md).



================================================
FILE: packages/web/src/routes/docs/rules/+page.svelte
================================================
<script module lang="ts">
import {
	Table,
	TableBody,
	TableBodyCell,
	TableBodyRow,
	TableHead,
	TableHeadCell,
} from 'components';
import { binary, type LintConfig, LocalLinter } from 'harper.js';

export const frontmatter = {
	title: 'Rules',
};

let descriptions: Record<string, string> = $state({});
let default_config: LintConfig = $state({});

let linter = new LocalLinter({ binary });
linter.getLintDescriptionsHTML().then(async (v) => {
	descriptions = v;
});
linter.getDefaultLintConfig().then(async (v) => {
	default_config = v;
});
</script>

<p>This page is an incomplete list of the various grammatical rules Harper checks for.</p>

<Table>
	<TableHead>
		<TableHeadCell>Name</TableHeadCell>
		<TableHeadCell>Enabled by Default</TableHeadCell>
		<TableHeadCell>Description</TableHeadCell>
	</TableHead>
	<TableBody>
		{#each Object.entries(descriptions) as [name, description]}
			<TableBodyRow>
				<TableBodyCell>{name}</TableBodyCell>
				<TableBodyCell>{default_config[name] ? '✔️' : '❌'}</TableBodyCell>
				<TableBodyCell tdClass="px-6 py-4 font-medium">{@html description.replaceAll('<p>', "").replaceAll('<p />', "")}</TableBodyCell>
			</TableBodyRow>
		{/each}
	</TableBody>
</Table>



================================================
FILE: packages/web/src/routes/docs/weir/+page.md
================================================
# The Weir Language

Most large organizations have a style guide.
A document that decides which versions of a linguistic rule to use.
That could be whether to use the Oxford comma, or if contractions are allowed.
It could declare that a certain word should be capitalized in a specific context.

Harper can cover *most* of the rules in *most* style guides, but there will always be outliers that we can't support (or simply don't know about).
That is why it is critical that Harper allow individuals and organizations to define rules and conventions for Harper to enforce.

## Introducing Weir

The heart of Weir is an expression language that mimics the pseudocode Harper contributors tend to use when describing the Rust code they intend to write.

Imagine you work at Google. You've just rebranded the "G Suite" collection of apps and services to the new name "Google Workspace".
Before that, they were collectively named "Google Apps for Work".
Moving forward, you don't want you or your coworkers to accidentally write "G Suite" on public documentation, because doing so might confuse users.
To solve this, you use the following Weir rule:

```plaintext
expr main [(G [Suite, Suit]), (Google Apps for Work)]

let message "Use the updated brand."
let description "`G Suite` or `Google Apps for Work` is now called `Google Workspace`"
let kind "Miscellaneous"
let becomes "Google Workspace"
```

The first line describes the pattern of the problematic text.
There are two cases here:

1. The letter "G" followed by "Suite" or its misspelling "Suit"
1. The literal phrase "Google Apps for Work"

Here is a semantically equivalent example that you may find a bit easier to read:

```plaintext
 [(G Suite), (G Suit), (Google Apps for Work)]
```

The remaining lines describe:

1. The message to be shown to the user when the error in encountered.
1. A description of the rule itself, explaining why it exists.
1. What kind of rule it is. 
1. What corrections to provide to the user.

## Comments

Comments are written using a single pound sign (`#`), like so:

```plaintext
# This is a comment and has no effect on the rest of the file.
 [(G Suite), (G Suit), (Google Apps for Work)]
```

## The Various Kinds of Expressions

As previously stated, Weir's expression language is the heart of the system.
There are a few key bits of notation you should know when writing a rule.

### Words

A word is the simplest kind of expression.
It is exactly what it sounds like: if a document contains a specific word, it will match.
Note that these matches are case-insensitive.

Here's an example:

```plaintext
expr main teh

let message "Did you mean the definite article?"
let description "Fixes especially common misspellings of the word `the`"
let kind "Typo"
let becomes "the"

test "I adore teh light of the moon." "I adore the light of the moon."
test "I adore TEH LIGHT OF THE MOON." "I adore THE LIGHT OF THE MOON."
```

When Harper encounters the literal word "teh", it will correct it directly to "the".
We'll get to the test notation later in this document.

### Sequences

A sequence, notated with round braces `()`, is exactly what it sounds like.
It is a sequence of other expressions. 
In order for a portion of a document to match against a sequence, all child expressions must match, in the sequence they are declared.

It's common to see expressions that string words together in a sequence to match against specific phrases.

```plaintext
expr main (gong to)

let message "Did you mean `going to`?"
let description "Corrects `gong to` to the intended phrase `going to`."
let kind "Typo"
let becomes "going to"
```

If the above rule is enabled, when Harper encounters the words `gong` and `to`, separated by whitespace, Harper will replace them with "going to".
The top-level expression assumed to be a sequence, so the first line can be replaced with this without changing the rule's behavior:

```plaintext
expr main gong to
```

### Alternatives

Alternatives in Weir, notated with `[]`, allow Harper to search for multiple potential options at a time.
For a document to match, it only needs to fulfill one of the options in the alternative array.

This syntax should look familiar from the first example we looked at in the introduction.
We have multiple specific phrases we want to look for, and change all of them, should they exist, to the same thing.

```plaintext
expr main [(low hanging fruit), (low hanging fruits), (low-hanging fruits)]

let message "The standard form is `low-hanging fruit` with a hyphen and singular form."
let description "Corrects nonstandard variants of `low-hanging fruit`."
let kind "Usage"
let becomes "low-hanging fruit"
```

Importantly, we can refactor this into just two sequences, by moving the arrays further into the expression.

```plaintext
expr main [(low[-, ( )]hanging fruits), (low hanging fruit)]
```

### Filters

Filters in Weir allow you to locate an expression, then narrow down the search to a shorter segment of that same expression.
This can be done as many times as you like.
The example below uses the filter syntax (the `<>`) to first select the broader phrase, then another to select the whitespace in between (that's the `( )` part).

```plaintext
expr main <([right, middle, left] $click), ( )>
let message "Hyphenate this mouse command"
let description "Hyphenates right-click style mouse commands."
let kind "Punctuation"
let becomes "-"

test "Right click the icon." "Right-click the icon."
test "Please right click on the link." "Please right-click on the link."
test "They right clicked the submit button." "They right-clicked the submit button."
test "Right clicking the item highlights it." "Right-clicking the item highlights it."
test "Right clicks are tracked in the log." "Right-clicks are tracked in the log."
test "He RIGHT CLICKED the file." "He RIGHT-CLICKED the file."
test "Left click the checkbox." "Left-click the checkbox."
test "Middle click to open in a new tab." "Middle-click to open in a new tab."
```

This is extremely useful for identifying exceptions to a rule, since you can include the exceptions in the first layer of the filter, then slowly become more specific.

See the testing section of this document for a more detailed description of the `test` syntax.

### UPOS

Weir allows you to require that certain words assume a specific role in the sentence by writing the [Universal Part-Of-Speech tag](https://universaldependencies.org/u/pos/index.html), literally, in the position you wish to require it..
For example, if you wanted to locate phrases that start with a determiner and are succeeded by a noun, you can write:

```plaintext
expr main DET NOUN
```

This will match against "the word", "a banana", "an apple", among others.

### Progressive Verbs

You can require that a token be a progressive verb with the keyword PROG.
For example:

```plaintext
expr main PROG
```

### Exceptions

You can add exceptions to expressions by throwing an exclamation mark in front of any other expression.
This is useful for excluding certain contexts from a match.
For example, if we wanted to locate all determiners when they are not followed by a noun, we can do this:

```
expr main DET !NOUN
```

Similarly, we can do the same with arrays or sequences of words:

```
expr main DET ![break, braking]
```

### Wildcards

If you need to allow a token between two others, or otherwise want to include an unknown and unrestricted token in the expression, you can use a wildcard.
Although they look like the single-character wildcard from regex (Weir borrows the `*` syntax), Weir wildcards match over entire tokens, including words, punctuation, and whitespace.

Example:

```plaintext
# To match any token that is preceded by a noun and succeeded by a noun.
expr main NOUN * NOUN
```

### Punctuation

Any punctuation that does not otherwise hold semantic meaning in Weir (like wildcards, etc.) is an expression that matches itself.
That means you can match a period with `.` or a question mark with `?`.

```
# Looks for all doubled hyphens.
expr main --

let message "The second mark is redundant."
let description "Looks for redundant doubling of hyphens."
let kind "Punctuation"
let becomes "-"
```

## Replacement Strategies

You can dictate how Harper will suggest a replacement using the `strategy` tag.
This allows rule authors to describe which strategy Harper will use when applying the replacements.
Right now, the only two options are `Exact` or `MatchCase`, which apply either the exact text, or the exact text but matching the capitalization of the text it replaces.
In the below example, we use `Exact` because we want to correct the capitalization of a proper noun, and it doesn't matter what the original text looked like.

```plaintext
expr main [(G [Suite, Suit]), (Google Apps for Work)]
let message "Use the updated brand."
let description "`G Suite` or `Google Apps for Work` is now called `Google Workspace`"
let kind "Miscellaneous"
let becomes "Google Workspace"
let strategy "Exact"
```

## Adding Tests

The Weir language supports the inclusion of tests directly in the file.
You can imagine these to be a lot like assertions.
It is a way of saying, "I expect this rule to transform this text into this other text."

It is pretty much always a good idea to include tests, just to make sure your rule does what you expect.

The syntax is pretty simple:

```plaintext
# I expect A to become B
test "A" "B"
```

You can also assert that the rule _will not_ change anything.

```plaintext
# I don't expect the rule to change anything
allows "A"
```

In the future, expect new types of tests to become available.

If you have `harper-cli` available, you can run the tests in a given Weir file by running `harper-cli test <path to the Weir file>`.

## See Also:

- [Building the Weir Language](https://elijahpotter.dev/articles/building-the-weir-language)
- [Updates on the Weir Language](https://elijahpotter.dev/articles/updates-on-the-weir-language)

## Additional Examples

```plaintext
expr main (like as if)

let message "Avoid redundancy. Use either `like` or `as if`."
let description "Corrects redundant `like as if` to `like` or `as if`."
let becomes ["like", "as if"]

test "And looks like as if linux-personality hasn't got any changes for 8 years." "And looks as if linux-personality hasn't got any changes for 8 years."
```

```plaintext
expr main (w/o)

let message "Use `without` instead of `w/o`"
let description "Expands the abbreviation `w/o` to the full word `without` for clarity."
let kind "Style"
let becomes "without"
```



================================================
FILE: packages/web/src/routes/editor/+page.svelte
================================================
<script>
/// This page exists to be embedded via an `iframe`.

import { page } from '$app/stores';
import Editor from '$lib/components/Editor.svelte';
import Isolate from '$lib/components/Isolate.svelte';

let content = $page.url.searchParams.get('initialText') ?? '';
</script>

<Isolate>
	<Editor {content}></Editor>
</Isolate>



================================================
FILE: packages/web/src/routes/editor/+page.ts
================================================
export const ssr = false;



================================================
FILE: packages/web/src/routes/install-browser-extension/+page.svelte
================================================
<script lang="ts">
import { Link, Textarea } from 'components';

let demoText =
	'Ths is an text box you can type in.\n\nany other site on the web will work the the same!';
</script>

<div class="fixed left-0 top-0 w-screen h-screen bg-white dark:bg-black z-1000">
  <div class="max-w-6xl mx-auto shadow-md border-gray-300 dark:border-x h-full overflow-y-auto">
    <section class="px-6 sm:px-10 py-16 sm:py-24">
      <h1 class="text-center font-bold text-primary text-4xl sm:text-6xl mb-6">
        Thanks for Installing Harper!
      </h1>

      <p class="text-center text-lg sm:text-xl mb-4 max-w-3xl mx-auto">
        Writing is hard. Writing well is harder. Now that Harper is available on most websites you visit, it should be a little easier.
      </p>

      <h2 class="text-center text-3xl mb-4 font-bold max-w-3xl mx-auto">
        Here's How It Works:
      </h2>

      <div class="grid grid-cols-3 gap-4 mb-2">
        <div class="p-4 border rounded-xl shadow-md">
          <p class="font-semibold py-0">1. Launch Any Site</p>
          <p>Harper plugs right into the page of any site you visit.</p>
        </div>
        <div class="p-4 border rounded-xl shadow-md">
          <p class="font-semibold py-0">2. Type Naturally</p>
          <p>When Harper notices an error in your work, it'll underline it.</p>
        </div>
        <div class="p-4 border rounded-xl shadow-md">
          <p class="font-semibold py-0">3. Review & Accept</p>
          <p>Tap the underline to fix the problem.</p>
        </div>
      </div>


      <h2 class="text-center text-3xl mb-4 font-bold max-w-3xl mx-auto">
        Give It a Whirl!
      </h2>

      <h3 class="text-center text-xl mb-4 max-w-xl mx-auto">
        It may take a moment for the engine to start...
      </h3>

      <div class="md:col-span-2 relative">
        <Textarea
          rows={10}
          bind:value={demoText}
          class="w-full rounded-lg border border-base-300 focus:ring-4 focus:ring-primary/30 transition text-xl! dark:text-white"
        />
      </div>


      <h2 class="text-center text-3xl mb-4 font-bold max-w-3xl mx-auto">
        Nothing is Happening?
      </h2>


    <div class="flex flex-row">
      <p class="text-left text-lg sm:text-xl mb-4 max-w-3xl mx-auto">
        Harper will only enable itself automatically on sites we've tested before. 
        <br/>
        <br/>
        If you work somewhere that isn't on our list of supported sites, you can enable the extension anyway by opening the Harper extension popup and clicking the power button.
        <br/>
        <br/>
        Alternatively, <Link href="/request-browser-support">let us know</Link> which sites you want us to support and we'll add it as soon as we can.
      </p>

      <img
        src="/images/chrome_extension_popup.png"
        alt="The Chrome extension’s popup page"
        class="max-w-full h-auto object-contain"
      />
    <div>

    </section>
  </div>
</div>



================================================
FILE: packages/web/src/routes/languagedetection/+page.svelte
================================================
<script lang="ts">
import { Select, Textarea } from 'components';
import { binary, WorkerLinter } from 'harper.js';
import demoText from '../../../../../demo.md?raw';

let isEnglish: boolean | null = null;
let text = '';
let strippedText = '';

let linter = new WorkerLinter({ binary });
linter.setup();

$: linter.isLikelyEnglish(text).then((v) => {
	isEnglish = v;
});
$: linter.isolateEnglish(text).then((t) => {
	strippedText = t;
});

$: color = isEnglish == null ? '' : isEnglish ? 'bg-green-100' : 'bg-red-100';

let templates = [
	{
		name: 'Java Code',
		value: `public class Main {
  public static void main(String[] args) {
    System.out.println("Hello World");
  }
}`,
	},
	{ name: 'Poor Grammar', value: demoText },
	{
		name: 'Chinese Lorem Ipsum',
		value:
			'食棵支每躲種。奶象打星爪子二細喜才記行在發像原斤！頁固點子衣點豆看身蝴看苗急午公何足，筆娘經色蝶行元香也要。麻了綠尼固世，色北書目登功；因告黑。',
	},
	{
		name: 'Spanish English Mix',
		value: 'En la mañana, como a dish de los huevos, un poquito of tocino, y a lot of leche.',
	},
	{
		name: 'Polish English Chunked',
		value: 'I have a simple motto in life: jeśli jesteś spragniony, napij się wody.',
	},
];

function selectChange(e: Event) {
	text = (e.target as HTMLSelectElement).value;
}
</script>

<div class="[&>*]:mt-12 p-4 dark:[&>*]:text-white">
	<h1 class="text-2xl">Language Detection Demo</h1>
	<p>
		This is demonstration of Harper's ability to quickly (under 1 ms for large documents) determine
		whether a provided document is intended to be English. The algorithm is flexible to bad grammar.
		<br />
		Since this is used to redact commented-out code, it airs on the side of producing false-positives.
	</p>

	<Select items={templates} on:change={selectChange} />

	<Textarea
		rows={8}
		class={color}
		bind:value={text}
		placeholder="Is your text supposed to be English?"
	/>

	<p>This lower area will show the chunks of the provided text that are marked as English.</p>

	<Textarea rows={8} value={strippedText} readonly />
</div>



================================================
FILE: packages/web/src/routes/latestversion/+server.ts
================================================
import { GithubClient } from '$lib/GitHubClient';

export async function GET() {
	const latestVersion = await GithubClient.getLatestReleaseFromCache('automattic', 'harper');

	if (latestVersion == null) {
		throw new Error('Unable to get latest version.');
	}

	console.log(`Received request for latest version. Responding with ${latestVersion}`);

	return new Response(latestVersion, {
		headers: {
			'Access-Control-Allow-Origin': 'app://obsidian.md',
			'Cache-Control': 'no-cache',
		},
	});
}

export async function OPTIONS() {
	return new Response(null, {
		headers: {
			'Access-Control-Allow-Origin': 'app://obsidian.md',
			'Access-Control-Allow-Methods': 'GET',
			'Access-Control-Allow-Headers': 'Harper-Version',
		},
	});
}



================================================
FILE: packages/web/src/routes/presentation/+page.svelte
================================================
<script lang="ts">
import 'reveal.js/dist/reveal.css';
import 'reveal.js/dist/theme/serif.css';
import { Link } from 'components';
import Reveal from 'reveal.js';
import { onMount } from 'svelte';
import Logo from '$lib/components/Logo.svelte';

onMount(() => {
	let deck = new Reveal();
	deck.initialize();
});
</script>

<div class="reveal">
	<div class="slides">
		<section>
			<Logo width="50%" />
			<h1>Harper</h1>
			<h2>The Grammar Checker for Developers</h2>
		</section>
		<section>
			<h1>Context</h1>
			<h3>I was bored</h3>
		</section>
		<section>
			<h2>
				That became
				<img
					src="https://thrax.elijahpotter.dev/logo.svg"
					alt="The Thrax Logo"
					class="w-1/2 inline rounded-lg"
				/>
			</h2>
		</section>
		<section>
			<h2>The language wasn't great, but the parser was fast.</h2>
		</section>
		<section>
			<h1>The Problem:</h1>
			<h1 class="fragment fade-in"><strong>Grammarly</strong></h1>
		</section>
		<section>
			<h3>It is a privacy nightmare.</h3>
			<p class="fragment fade-in">
				Every request gets sent to their servers and stored <strong>forever.</strong>
			</p>
		</section>
		<section>
			<h3>It is <i>slow.</i></h3>
			<p class="fragment fade-in">Grammarly requests can take as many as 4000ms to resolve.*</p>
		</section>
		<section>
			<h3>LanguageTool</h3>
			<p class="fragment fade-in">You can self-host it, but...</p>
			<p class="fragment fade-in">there are memory issues.</p>
		</section>
		<section>
			<Logo width="40%" />
			<h2>Let me introduce:</h2>
			<h1>Harper</h1>
		</section>
		<section>
			<h2>The mission:</h2>
			<p>Create a grammar checker of the same caliber as Grammarly and LanguageTool.</p>
			<p class="fragment fade-in"><strong>Without the cruft.</strong></p>
		</section>
		<section>
			<h2>That means:</h2>
			<ul>
				<li class="fragment fade-in">It must be completely private.</li>
				<li class="fragment fade-in">It must encourage painless revision <i>by a human</i>.</li>
				<li class="fragment fade-in">It has to get out of the way.</li>
			</ul>
		</section>
		<section>
			<h2>Harper (right now)</h2>
			<ul>
				<li class="fragment fade-in">Runs on-device.</li>
				<li class="fragment fade-in">
					The entire grammar checker fits under 500kb (including datasets).
				</li>
				<li class="fragment fade-in">Completes checking on large documents in under 10-20ms.</li>
			</ul>
		</section>
		<section>
			<h2>Linters</h2>
			<ul>
				<li>"a" v.s. "an" usage.</li>
				<li>Spell-checking.</li>
				<li>Accidental word repetition (e.x. "We ate at <i>the the</i> cafe").</li>
				<li>Extraneous spaces.</li>
				<li>More than 100 curated patterns.</li>
				<li>Run-on sentences.</li>
			</ul>
		</section>
		<section>
			<h2>Availability</h2>
			<h3>Full Support:</h3>
			<ul>
				<li>Neovim (LSP)</li>
				<li>Web (WebAssembly)</li>
			</ul>
			<h3>Early Access (talk to me)</h3>
			<ul><li>Obsidian (CodeMirror + WebAssembly)</li></ul>
			<h3>Planned:</h3>
			<ul>
				<li>JetBrains products (LSP)</li>
				<li>Visual Studio Code (LSP)</li>
			</ul>
		</section>
		<section>
			<h2>Try It!</h2>
			<p>
				Go to <Link href="https://writewithharper.com">https://writewithharper.com</Link> on a laptop.
				<img
					alt="The QR code for the website."
					src=" https://api.qrserver.com/v1/create-qr-code/?size=300x300&data=https://writewithharper.com"
				/>
			</p>
		</section>
	</div>
</div>

<style>
	.reveal * {
		text-align: left;
	}
</style>



================================================
FILE: packages/web/src/routes/report-problematic-lint/+page.svelte
================================================
<script lang="ts">
import { Button, Card, Checkbox, Input, Label, Radio } from 'components';
import Isolate from '$lib/components/Isolate.svelte';
</script>

<Isolate>
  <div class="flex flex-row justify-center items-center h-screen"> 
    <Card> 
      <h1 class="text-3xl font-semibold">Report Problematic Lint</h1> 
      <p class="text-sm text-gray-600">If you've encountered an example of Harper producing an incorrect result, we'd love to know about it.</p>
      <form method="POST" class="mt-4 space-y-6" action="/api/problematic-lints">
        <div class="space-y-3">
          <div class="flex items-baseline gap-2">
            <Label>What text caused (or should cause) feedback from Harper?</Label>
          </div>
          <Input name="example" placeholder="Give us an example." />

          <Checkbox name="is_false_positive">Is it a false positive? Otherwise, leave unchecked.</Checkbox>

          <div class="flex items-baseline gap-2">
            <Label>What rule caused (or should cause) feedback from Harper?</Label>
          </div>
          <Input name="rule_id" placeholder="We'd appreciate the specific rule ID, if applicable." />


          <div class="flex items-baseline gap-2">
            <Label>Additional Feedback</Label>
          </div>
          <Input name="feedback" placeholder="Anything you want to add?" />

          <div class="flex items-center justify-between pt-2">
            <Button type="submit">Submit</Button>
          </div>
        </div>
      </form>
    </Card> 
  </div>
</Isolate>



================================================
FILE: packages/web/src/routes/request-browser-support/+page.svelte
================================================
<div class="fixed left-0 top-0 w-screen h-screen bg-white dark:bg-black z-1000">
	<div class="max-w-4xl mx-auto shadow-md border-gray-300 dark:border-x h-full">
    <iframe src="https://docs.google.com/forms/d/e/1FAIpQLScaWQWtnszKS_oQ8DYEAt1Ei5ORIQFViaoImjZ06pXntbCarA/viewform?embedded=true" width="100%" height="100%" frameborder="0" marginheight="0" marginwidth="0" title="A form to request support for a specific website.">Loading…</iframe>
	</div>
</div>



================================================
FILE: packages/web/src/routes/stats/+page.svelte
================================================
<script lang="ts">
import {
	Fileupload,
	Table,
	TableBody,
	TableBodyCell,
	TableBodyRow,
	TableHead,
	TableHeadCell,
} from 'components';
import { binary, type Summary, WorkerLinter } from 'harper.js';
import LintKindChart from '$lib/components/LintKindChart.svelte';

let linter = new WorkerLinter({ binary: binary });
let files = $state<FileList | undefined>();
let summary: Summary | undefined = $state();

$effect(() => {
	(async () => {
		if (files && files.length >= 1) {
			let file = files.item(0);

			let t = await file?.text();

			if (!t) {
				throw new Error('Unable to get text content.');
			}

			await linter.importStatsFile(t);
			summary = await linter.summarizeStats();
		}
	})();
});
</script>

{#if summary}
  <h1>Harper Statistics</h1>

  {#if summary.lint_counts}
    <h2>Most Common Kinds of Corrections</h2>
    <LintKindChart lintCounts={summary.lint_counts}/>
  {/if}

  {#if summary.total_applied}
    <p>In total, {summary.total_applied} corrections were applied.</p>
  {/if}

  {#if summary.misspelled}
    <h2>Most Misspelled Words</h2>
    <Table>
    	<TableHead>
    		<TableHeadCell>Word</TableHeadCell>
    		<TableHeadCell># of Times Misspelled</TableHeadCell>
    	</TableHead>
    	<TableBody>
    		{#each Object.entries(summary.misspelled) as [word, count]}
    			<TableBodyRow>
    				<TableBodyCell>{word}</TableBodyCell>
    				<TableBodyCell>{count}</TableBodyCell>
    			</TableBodyRow>
    		{/each}
    	</TableBody>
    </Table>
    {/if}
{:else}
  <p> Upload your `stats.txt` file to start reflecting on your authorship. </p>
  <Fileupload bind:files={files}/>
{/if}



================================================
FILE: packages/web/src/routes/titlecase/+page.svelte
================================================
<script lang="ts">
import { Link, Textarea } from 'components';
import type { WorkerLinter } from 'harper.js';
import { onMount } from 'svelte';
import Typed from 'typed.js';

let linter: WorkerLinter | null = null;
let text = '';
let titlecaseRun = 0;

onMount(() => {
	(async () => {
		if (typeof Worker !== 'undefined') {
			const { WorkerLinter, binary } = await import('harper.js');
			const newLinter = new WorkerLinter({ binary });

			newLinter.setup();
			linter = newLinter;
		}
	})();

	const typed = new Typed('#titleCaseInputField', {
		strings: [
			'Click Here to Write an Article Title',
			'Click Here to Write a Blog Title',
			'Click Here to Write a Social Media Post Title',
			'Click Here to Write a Newsletter Title',
			'Click Here to Write a Video Script Title',
			'Click Here to Write a Press Release Title',
			'Click Here to Brainstorm a New Ebook Title',
		],
		typeSpeed: 50,
		showCursor: false,
		attr: 'placeholder',
	});

	return () => typed.destroy();
});

$: if (linter) {
	const requestId = ++titlecaseRun;
	const currentText = text;

	linter.toTitleCase(currentText).then((converted) => {
		if (requestId !== titlecaseRun) return;
		if (converted !== currentText) {
			text = converted;
		}
	});
}
</script>

<h1>Title Case Converter</h1>

<div class="fixed left-0 top-0 w-screen h-screen bg-white dark:bg-black z-1000">
	<div class="max-w-4xl mx-auto shadow-md border-gray-300 dark:border-x h-full">
		<!-- Header -->
		<header class="border-b border-gray-300 p-4">
			<div class="flex justify-between items-center">
				<h1 class="text-3xl font-serif font-bold">The News, Written by You</h1>
				<span class="text-sm">July 4th 1776</span>
			</div>
			<div class="flex justify-between mt-2">
				<div class="text-xs">Vol. 123, No. 45</div>
				<div class="text-xs">Your trusted news source</div>
			</div>
		</header>

		<main class="p-4 md:p-6">
			<article class="mb-8">
				<Textarea
					bind:value={text}
					rows="1"
					class="heading-textarea w-full font-serif text-2xl md:text-3xl font-bold border-none focus:ring-2 focus:ring-blue-200 bg-transparent p-0 resize-none overflow-hidden"
					id="titleCaseInputField"
				/>
				<div class="text-sm mb-3">By John Doe, Staff Writer</div>

				<p class="leading-relaxed">
					<Link href="/">Harper</Link> ships out-of-the box with everything you need to perform complex operations
					on English text at the edge. That includes converting text to title-case.
				</p>

				<p class="leading-relaxed">
					Just enter your text in the heading above and it'll be converted to title case following
					the <Link href="https://www.chicagomanualofstyle.org/home.html">Chicago Style</Link>. Your
					privacy means something. Keep your data where you want it: in your hands and on your
					device.
				</p>
			</article>
		</main>
	</div>
</div>



================================================
FILE: packages/web/src/routes/uninstall-browser-extension/+page.svelte
================================================
<script lang="ts">
import { Button, Card, Input, Label, Radio } from 'components';
import Isolate from '$lib/components/Isolate.svelte';

const reasons = {
	confused: 'I was confused by how it worked',
	'unsupported-language': "It doesn't support my language",
	'slowed-down-browser': 'It slowed down my browser',
	'false-positive': 'It incorrectly flagged my text as an error',
	'false-negative': "It didn't identify enough errors in my text",
	'no-positives': "It didn't identify any errors in my text",
};

let otherSelected: string | number | undefined;
let otherText = '';

function handleFormData(e: FormDataEvent) {
	const fd = e.formData;
	if (fd.get('feedback') === 'other') {
		const v = (fd.get('other') || '').toString().trim();
		if (v) fd.set('feedback', v);
	}
}
</script>

<Isolate>
  <div class="flex flex-row justify-center items-center h-screen"> 
    <Card> 
      <h1 class="text-3xl font-semibold">Uninstalling Harper</h1> <p class="text-sm text-gray-600">We’re sorry to see you go. If you have a minute, would you mind telling us why you uninstalled our browser extension?</p>
      <form method="POST" class="mt-4 space-y-6" action="/api/uninstall-feedback" on:formdata={handleFormData}>
        <div class="space-y-3">
          <div class="flex items-baseline gap-2">
            <Label>Why did you uninstall Harper?</Label>
          </div>
      
          <div class="space-y-3">
            {#each Object.entries(reasons) as [k, r], i}
              <Radio value={k} name="feedback">{r}</Radio>
            {/each}
      
            <Radio name="feedback" value="other" bind:group={otherSelected}>Other</Radio>
            {#if otherSelected}
              <Input name="other" bind:value={otherText} placeholder="Your answer" />
            {/if}
        </div>
      
        <div class="flex items-center justify-between pt-2">
          <Button type="submit">Submit</Button>
        </div>
      </form>
    </Card> 
  </div>
</Isolate>



================================================
FILE: packages/web/src/routes/wpdemo/+page.server.ts
================================================
import { redirect } from '@sveltejs/kit';
import blueprint from '../../../demo_wp_blueprint.json?raw';

const base64Blueprint = btoa(blueprint);
const playgroundUrl = `https://playground.wordpress.net/?mode=seamless#${base64Blueprint}`;

export function load() {
	redirect(302, playgroundUrl);
}



================================================
FILE: packages/web/static/browserconfig.xml
================================================
<?xml version="1.0" encoding="utf-8"?>
<browserconfig>
    <msapplication>
        <tile>
            <square150x150logo src="/mstile-150x150.png"/>
            <TileColor>#da532c</TileColor>
        </tile>
    </msapplication>
</browserconfig>



================================================
FILE: packages/web/static/site.webmanifest
================================================
{
	"name": "",
	"short_name": "",
	"icons": [
		{
			"src": "/android-chrome-192x192.png",
			"sizes": "192x192",
			"type": "image/png"
		},
		{
			"src": "/android-chrome-512x512.png",
			"sizes": "512x512",
			"type": "image/png"
		}
	],
	"theme_color": "#ffffff",
	"background_color": "#ffffff",
	"display": "standalone"
}



================================================
FILE: packages/web/static/images/obsidian_screenshot.webp
================================================
[Binary file]


================================================
FILE: packages/web/static/images/vscode_harper_path.webp
================================================
[Binary file]


================================================
FILE: packages/wordpress-plugin/README.md
================================================
# Harper for WordPress

![The early prototype version of the plugin](./screenshot.png)

This repository contains the WordPress plugin for [Harper](https://writewithharper.com).
It is a work-in-progress. Here be dragons!

## Contributing

Refer to [the online documentation](https://writewithharper.com/docs/contributors/wordpress) for instruction to contribute to the plugin.



================================================
FILE: packages/wordpress-plugin/harper.php
================================================
<?php
/**
 * Plugin Name:       Harper
 * Plugin URI:        https://writewithharper.com
 * Description:       Harper is the grammar checker that respects your privacy
 * Version:           0.0.1
 * Requires at least: 6.7
 * Requires PHP:      7.4
 * Author:            Elijah Potter
 * License:           GPL-2.0-or-later
 * License URI:       https://www.gnu.org/licenses/gpl-2.0.html
 * Text Domain:       harper
 *
 * @package Harper
 */

declare( strict_types = 1 );

if ( ! defined( 'ABSPATH' ) ) {
	exit; // Exit if accessed directly.
}

/**
 * Registers the block using the metadata loaded from the `block.json` file.
 * Behind the scenes, it registers also all assets so they can be enqueued
 * through the block editor in the corresponding context.
 *
 * @see https://developer.wordpress.org/reference/functions/register_block_type/
 */
function create_harper_block_init() {
	register_block_type( __DIR__ . '/build/harper' );
}
add_action( 'init', 'create_harper_block_init' );



================================================
FILE: packages/wordpress-plugin/package.json
================================================
{
	"name": "wordpress-plugin",
	"private": true,
	"version": "0.0.1",
	"description": "The grammar checker that respects your privacy.",
	"main": "build/index.js",
	"scripts": {
		"build": "wp-scripts build --webpack-copy-php",
		"packages-update": "wp-scripts packages-update",
		"plugin-zip": "zip harper.zip build harper.php screenshot.png -r",
		"start": "wp-scripts start --webpack-copy-php"
	},
	"devDependencies": {
		"@wordpress/scripts": "^30.9.0",
		"@wp-now/wp-now": "^0.1.74",
		"typescript": "catalog:"
	},
	"dependencies": {
		"@wordpress/components": "^29.2.0",
		"@wordpress/data": "^10.15.1",
		"@wordpress/edit-post": "^8.16.0",
		"@wordpress/editor": "^14.20.0",
		"@wordpress/preferences-persistence": "^2.17.0",
		"harper.js": "workspace:*",
		"lodash-es": "^4.17.21",
		"react": "^18.0.0",
		"react-dom": "^18.0.0"
	}
}



================================================
FILE: packages/wordpress-plugin/.editorconfig
================================================
# This file is for unifying the coding style for different editors and IDEs
# editorconfig.org

# WordPress Coding Standards
# https://make.wordpress.org/core/handbook/coding-standards/

root = true

[*]
charset = utf-8
end_of_line = lf
insert_final_newline = true
trim_trailing_whitespace = true
indent_style = tab

[*.{yml,yaml}]
indent_style = space
indent_size = 2



================================================
FILE: packages/wordpress-plugin/src/harper/block.json
================================================
{
	"$schema": "https://schemas.wp.org/trunk/block.json",
	"apiVersion": 3,
	"name": "harper/harper",
	"version": "0.0.1",
	"title": "Harper",
	"category": "text",
	"icon": "smiley",
	"description": "Harper is the grammar checker that respects your privacy",
	"example": {},
	"supports": {
		"html": false
	},
	"textdomain": "harper",
	"editorScript": "file:./index.js",
	"editorStyle": "file:./index.css"
}



================================================
FILE: packages/wordpress-plugin/src/harper/Box.ts
================================================
import type { Lint, Suggestion } from 'harper.js';

export type Box = {
	/** Horizontal position in pixels */
	x: number;
	/** Vertical position in pixels */
	y: number;
	/** Width in pixels */
	width: number;
	/** Height in pixels */
	height: number;
};

export type LintBox = Box & {
	lint: Lint;
	applySuggestion: (sug: Suggestion) => void;
};

export type IgnorableLintBox = LintBox & {
	ignoreLint: () => Promise<void>;
};

export function isPointInBox(point: [number, number], box: Box) {
	const [x, y] = point;

	return x > box.x && x < box.x + box.width && y > box.y && y < box.y + box.height;
}



================================================
FILE: packages/wordpress-plugin/src/harper/DataBlock.ts
================================================
import { dispatch } from '@wordpress/data';
import { getNodesFromQuerySelector, getRichTextContainers } from './domUtils';
import RichText from './RichText';

/**
 * Represents a Gutenberg block on-screen.
 * So named because all of these blocks have a `data-block` attribute.
 */
export default class DataBlock {
	public readonly targetElement: Element;

	constructor(targetElement: Element) {
		this.targetElement = targetElement;
	}

	private getClientId(): string {
		return this.targetElement.getAttribute('data-block')!;
	}

	public getAllRichText(): RichText[] {
		const containers = getRichTextContainers(this.targetElement);

		return containers.map(
			(cont) =>
				new RichText(cont, this, async (newContent: string) => {
					const { updateBlockAttributes } = dispatch('core/block-editor');

					const attributeName = cont.getAttribute('data-wp-block-attribute-key') ?? 'content';

					await updateBlockAttributes(this.getClientId(), {
						[attributeName]: newContent,
					});
				}),
		);
	}

	public static getAllDataBlocks(): DataBlock[] {
		const container = this.getContainer();

		const targetNodes = [...getNodesFromQuerySelector(container, '[data-block]')];

		return targetNodes.map((node) => new DataBlock(node));
	}

	/** Get all DataBlocks in the document, then remove any that have other DataBlocks as children. */
	public static getTerminalDataBlocks(): DataBlock[] {
		const blocks = this.getAllDataBlocks();

		return blocks.filter((block) => {
			for (const otherBlock of blocks) {
				if (otherBlock === block) {
					continue;
				}

				if (block.targetElement.contains(otherBlock.targetElement)) {
					return false;
				}
			}

			return true;
		});
	}

	public static getContainer(): Element {
		const iframe = document.querySelector('iframe[name="editor-canvas"]');
		const iframeDocument = iframe?.contentDocument || iframe?.contentWindow.document;
		const container =
			iframeDocument?.body || document.querySelector('.edit-post-visual-editor > div');
		return container;
	}
}



================================================
FILE: packages/wordpress-plugin/src/harper/DialectSelectRow.tsx
================================================
import { SelectControl } from '@wordpress/components';
import { Dialect } from 'harper.js';
import useDialect from './useDialect';

export default function DialectSelectRow() {
	const [dialect, setDialect] = useDialect();

	return (
		<div>
			<h3>Dialect</h3>
			<p>Choose which English dialect Harper should expect.</p>
			<SelectControl
				label="Dialect"
				value={dialect.toString()}
				options={[
					{
						label: 'American',
						value: Dialect.American.toString(),
					},
					{
						label: 'Canadian',
						value: Dialect.Canadian.toString(),
					},
					{
						label: 'Australian',
						value: Dialect.Australian.toString(),
					},
					{
						label: 'British',
						value: Dialect.British.toString(),
					},
					{
						label: 'Indian',
						value: Dialect.Indian.toString(),
					},
				]}
				onChange={(value) => setDialect(Number.parseInt(value, 10))}
			/>
		</div>
	);
}



================================================
FILE: packages/wordpress-plugin/src/harper/domUtils.ts
================================================
import type { Span } from 'harper.js';

/**
 * Turn a `NodeList` into a normal JavaScript array.
 * @param collection
 */
export function extractFromHTMLCollection(collection: HTMLCollection): Element[] {
	const elements: Element[] = [];

	for (const el of collection) {
		elements.push(el);
	}

	return elements;
}

/**
 * Turn a `NodeList` into a normal JavaScript array.
 * @param list
 */
export function extractFromNodeList<T extends Node>(list: NodeListOf<T>): T[] {
	const elements: T[] = [];

	for (let i = 0; i < list.length; i++) {
		const item = list[i];
		elements.push(item);
	}

	return elements;
}

export function getNodesFromQuerySelector(element: Element, query: string) {
	return extractFromNodeList(element.querySelectorAll(query));
}

/**
 * Flatten a provided node, and its children into a single array.
 * @param node
 */
export function leafNodes(node: Node): Node[] {
	const out: Node[] = [];

	const children = extractFromNodeList(node.childNodes);

	if (children.length === 0) {
		return [node];
	}

	for (const child of children) {
		const sub = leafNodes(child);
		sub.forEach((v) => {
			out.push(v);
		});
	}

	return out;
}

/**
 * Given an element and a Span of text inside it, compute the Range that represents the region of the DOM represented.
 * @param target
 * @param span
 */
export function getRangeForTextSpan(target: Element, span: Span): Range | null {
	const children = leafNodes(target);

	const range = document.createRange();
	let traversed = 0;

	let startFound = false;

	for (let i = 0; i < children.length; i++) {
		const child = children[i] as HTMLElement;
		const childText = child.textContent ?? '';

		if (traversed + childText.length > span.start && !startFound) {
			range.setStart(child, span.start - traversed);
			startFound = true;
		}

		if (startFound && traversed + childText.length >= span.end) {
			range.setEnd(child, span.end - traversed);
			return range;
		}

		traversed += childText?.length ?? 0;
	}

	return null;
}

/**
 * Locate the rich text containers inside a given element.
 * Notice: this function may return the provided element.
 * @param target
 */
export function getRichTextContainers(target: Element): Element[] {
	const elms: Element[] = [];

	if (target.classList.contains('rich-text')) {
		elms.push(target);
	}

	elms.push(...extractFromHTMLCollection(target.getElementsByClassName('rich-text')));

	return elms;
}



================================================
FILE: packages/wordpress-plugin/src/harper/Highlighter.tsx
================================================
import { useEffect } from 'react';
import type { LintBox } from './Box';
import type RichText from './RichText';
import SuggestionControl from './SuggestionControl';

/**
 * Renders controls to the user around the errors.
 * @param root0
 * @param root0.lintBoxes
 * @param root0.richText
 */
export default function Highlighter({
	lintBoxes,
	richText,
}: {
	lintBoxes: LintBox[];
	richText: RichText;
}) {
	// Disable browser spellchecking in favor of ours
	useEffect(() => {
		richText.getTargetElement().spellcheck = false;

		return () => {
			richText.getTargetElement().spellcheck = true;
		};
	}, [richText]);

	const visible = richText.getTargetElement().checkVisibility();

	return (
		<>{visible && lintBoxes.map((b, index) => <SuggestionControl lintBox={b} key={index} />)}</>
	);
}



================================================
FILE: packages/wordpress-plugin/src/harper/index.css
================================================
.harper-popover > div {
	width: 300px;
	z-index: 100;
	padding: 10px;
}

.harper-solved-cont {
	padding: 35px;
	width: 100%;
	display: flex;
	flex-direction: row;
	justify-content: center;
}

.harper-solved-cont h2 {
	font-size: 20px;
	font-weight: bold;
}

.harper-solved-cont p {
	font-size: 16px;
}

.harper-lint-card {
	margin: 4px;
}

.harper-lint-card h2 {
	font-weight: bold;
	font-size: large;
}

.harper-lint-card button {
	width: 100%;
	margin-top: 6px;
}

.harper-lint-config-cont {
	overflow-x: hidden;
}

.harper-lint-config-row {
	padding: 6px;
}

.harper-lint-config-row > h3 {
	font-weight: bold;
}

.harper-popover > div > button {
	width: 100%;
	margin-top: 6px;
}

.harper-underline-Spelling {
	border-bottom: 3px solid #ee4266;
}

.harper-underline-Capitalization {
	border-bottom: 3px solid #540d6e;
}

.harper-underline-Style {
	border-bottom: 3px solid #ffd23f;
}

.harper-underline-Formatting {
	border-bottom: 3px solid #540d6e;
}

.harper-underline-Repetition {
	border-bottom: 3px solid #3bceac;
}

.harper-underline-Enhancement {
	border-bottom: 3px solid #0ead69;
}

.harper-underline-Readability {
	border-bottom: 3px solid #0ead69;
}

.harper-underline-WordChoice {
	border-bottom: 3px solid #0ead69;
}

.harper-underline-Miscellaneous {
	border-bottom: 3px solid #3bceac;
}



================================================
FILE: packages/wordpress-plugin/src/harper/index.tsx
================================================
import { PluginSidebar, PluginSidebarMoreMenuItem } from '@wordpress/edit-post';
import { registerPlugin } from '@wordpress/plugins';
import Logo from './Logo';
import SidebarControl from './SidebarControl';
import './index.css';
import LinterProvider from './LinterProvider';

function Sidebar() {
	return (
		<>
			<PluginSidebarMoreMenuItem target="harper-sidebar" icon={Logo()}>
				Harper
			</PluginSidebarMoreMenuItem>
			<PluginSidebar name="harper-sidebar" title="Harper" icon={Logo}>
				<LinterProvider>
					<SidebarControl />
				</LinterProvider>
			</PluginSidebar>
		</>
	);
}

// @ts-expect-error
if (!window.__harperSidebarRegistered) {
	registerPlugin('harper-sidebar', { render: Sidebar });
	// @ts-expect-error
	window.__harperSidebarRegistered = true;
}



================================================
FILE: packages/wordpress-plugin/src/harper/LinterProvider.tsx
================================================
import { binaryInlined, type Linter, WorkerLinter } from 'harper.js';
import { createContext, type ReactNode, useContext, useEffect, useRef, useState } from 'react';

const linterContext = createContext<Linter>(new WorkerLinter({ binary: binaryInlined }));

export default function LinterProvider({ children }: { children: ReactNode | ReactNode[] }) {
	const linter = useRef(new WorkerLinter({ binary: binaryInlined }));

	return <linterContext.Provider value={linter.current}>{children}</linterContext.Provider>;
}

export function useLinter(): Linter {
	return useContext(linterContext);
}

export function useLintDescriptions(): Record<string, string> {
	const linter = useLinter();
	const [descriptions, setDescriptions] = useState({});

	useEffect(() => {
		linter.getLintDescriptions().then(setDescriptions);
	}, [linter]);

	return descriptions;
}



================================================
FILE: packages/wordpress-plugin/src/harper/LintList.tsx
================================================
import { Animate, Spinner } from '@wordpress/components';
import type { IgnorableLintBox } from './Box';
import LintListItem from './LintListItem';

export default function LintList({
	lintBoxes,
	loading,
}: {
	lintBoxes: IgnorableLintBox[];
	loading: boolean;
}) {
	if (lintBoxes.length === 0) {
		return (
			<div className="harper-solved-cont">
				<Animate type="appear" options={{ origin: 'middle' }}>
					{({ className }) => (
						<div className={className ?? ''}>
							{loading ? (
								<Spinner
									style={{
										height: 'calc(4px * 20)',
										width: 'calc(4px * 20)',
									}}
								/>
							) : (
								<>
									<h2>LGTM 👍</h2>
									<p>Harper could not find any problems with your work.</p>
								</>
							)}
						</div>
					)}
				</Animate>
			</div>
		);
	}

	return (
		<>
			{lintBoxes
				.filter((box) => box.lint.suggestion_count() > 0)
				.map((box, index) => (
					<LintListItem key={index} box={box} />
				))}
		</>
	);
}



================================================
FILE: packages/wordpress-plugin/src/harper/LintListItem.tsx
================================================
import { Button, Card, CardBody } from '@wordpress/components';
import type { IgnorableLintBox } from './Box';
import { suggestionText } from './lintUtils';
import { useAddToDictionary } from './usePersonalDictionary';

export default function LintListItem({ box }: { box: IgnorableLintBox }) {
	const addToDictionary = useAddToDictionary();

	return (
		<Card size="small" className="harper-lint-card">
			<CardBody>
				<h2 className={`harper-underline-${box.lint.lint_kind()}`}>
					{box.lint.lint_kind_pretty()}
				</h2>
				<p>{box.lint.message()}</p>

				{box.lint.suggestions().map((sug, index) => (
					<Button variant="primary" key={index} onClick={() => box.applySuggestion(sug)}>
						{suggestionText(sug.kind(), box.lint.get_problem_text(), sug.get_replacement_text())}
					</Button>
				))}

				{box.lint.lint_kind() === 'Spelling' ? (
					<Button onClick={() => addToDictionary(box.lint.get_problem_text())} variant="primary">
						Add “{box.lint.get_problem_text()}” to the dictionary
					</Button>
				) : (
					<></>
				)}

				<Button variant="link" onClick={box.ignoreLint}>
					Ignore
				</Button>
			</CardBody>
		</Card>
	);
}



================================================
FILE: packages/wordpress-plugin/src/harper/LintSettingList.tsx
================================================
import { SearchControl } from '@wordpress/components';
import { useState } from 'react';
import { useLintDescriptions } from './LinterProvider';
import LintSettingRow from './LintSettingRow';
import useLintConfig, { useDefaultLintConfig } from './useLintConfig';

export default function LintSettingList() {
	const [lintConfig, setLintConfig] = useLintConfig();
	const defaultConfig = useDefaultLintConfig();
	const descriptions = useLintDescriptions();
	const [query, setQuery] = useState('');

	return (
		<div className="harper-lint-config-cont">
			<SearchControl value={query} onChange={setQuery} placeholder="Search for a rule..." />

			{Object.entries(lintConfig)
				.filter(([key]) => key.includes(query) || descriptions[key]?.includes(query))
				.map(([key, value]) => (
					<LintSettingRow
						key={key}
						name={key}
						description={descriptions[key]}
						value={value}
						defaultValue={defaultConfig[key]!}
						setValue={(newValue) => setLintConfig({ ...lintConfig, [key]: newValue })}
					/>
				))}
		</div>
	);
}



================================================
FILE: packages/wordpress-plugin/src/harper/LintSettingRow.tsx
================================================
import { Animate, CheckboxControl } from '@wordpress/components';
import { useEffect, useState } from 'react';
import { useLinter } from './LinterProvider';

export default function LintSettingRow({
	name,
	value,
	defaultValue,
	setValue,
	description,
}: {
	name: string;
	description: string;
	value: boolean | undefined;
	defaultValue: boolean;
	setValue: (newValue: boolean | undefined) => void;
}) {
	const linter = useLinter();

	const [title, setTitle] = useState<string | null>(null);

	useEffect(() => {
		linter.toTitleCase(name.replace(/_/g, ' ')).then(setTitle);
	}, [linter, name]);

	return title && description ? (
		<Animate type={title === null ? undefined : 'slide-in'}>
			{({ className }) => (
				<div className={`${className} harper-lint-config-row`}>
					<h3>{title}</h3>
					<p>{description}</p>

					<CheckboxControl
						label={
							value == null
								? `Default (${defaultValue ? 'Enabled' : 'Disabled'})`
								: value
									? 'Enabled'
									: 'Disabled'
						}
						onChange={(val) => setValue(val)}
						checked={value ?? defaultValue}
					/>
				</div>
			)}
		</Animate>
	) : (
		<></>
	);
}



================================================
FILE: packages/wordpress-plugin/src/harper/lintUtils.ts
================================================
import { SuggestionKind } from 'harper.js';

/**
 * Produce the UI text shown inside suggestion buttons.
 * @param kind
 * @param problemText
 * @param replacementText
 */
export function suggestionText(
	kind: SuggestionKind,
	problemText: string,
	replacementText: string,
): string {
	if (kind === SuggestionKind.Remove) {
		return `Remove “${problemText}”`;
	} else if (kind === SuggestionKind.Replace) {
		return `Replace with “${replacementText}”`;
	}
	return `Insert “${replacementText}”`;
}



================================================
FILE: packages/wordpress-plugin/src/harper/Logo.jsx
================================================
export default function Logo() {
	return (
		<svg
			width="100%"
			height="100%"
			viewBox="0 0 695 411"
			xmlns="http://www.w3.org/2000/svg"
			xmlnsXlink="http://www.w3.org/1999/xlink"
			xmlSpace="preserve"
			style={{
				fillRule: 'evenodd',
				clipRule: 'evenodd',
				strokeLinecap: 'round',
				strokeLinejoin: 'round',
				strokeMiterlimit: 1.5,
			}}
		>
			<g transform="matrix(1,0,0,1,-5,-1720)">
				<g id="Artboard1" transform="matrix(0.824576,0,0,0.749254,0.365685,430.856)">
					<g transform="matrix(1.21274,0,0,1.33466,-2183.71,393.157)">
						<g transform="matrix(1,0,0,1,-22.3927,1.08043)">
							<path
								d="M1930.93,1121.75C1930.93,1121.75 1974.66,1080.73 2041.34,1094.1C2086.61,1103.18 2122.83,1145.4 2122.83,1145.4"
								style={{
									fill: 'none',
									stroke: 'currentColor',
									strokeWidth: '22.92px',
								}}
							/>
						</g>
						<g transform="matrix(1,0,0,1,-47.3485,12.3935)">
							<path
								d="M2250.3,1107.1C2250.3,1107.1 2261.8,1065.58 2311.59,1047.05C2361.62,1028.44 2422.42,1051.13 2422.42,1051.13"
								style={{
									fill: 'none',
									stroke: 'currentColor',
									strokeWidth: '22.92px',
								}}
							/>
						</g>
						<g transform="matrix(1.10085,0,0,1.10085,-212.096,-122.054)">
							<g transform="matrix(1,0,0,1,14.3186,-0.853887)">
								<ellipse
									cx={1981.62}
									cy={1247.49}
									rx={87.401}
									ry={87.881}
									style={{
										fill: 'none',
										stroke: 'currentColor',
										strokeWidth: '20.82px',
									}}
								/>
							</g>
							<rect
								x={2083.34}
								y={1231.11}
								width={66.702}
								height={15.521}
								style={{
									fill: 'none',
									stroke: 'currentColor',
									strokeWidth: '20.82px',
								}}
							/>
							<rect
								x={1892.23}
								y={1208.69}
								width={16.306}
								height={30.182}
								style={{
									fill: 'none',
									stroke: 'currentColor',
									strokeWidth: '20.82px',
								}}
							/>
							<g transform="matrix(-1,0,0,1,4281.79,-0.853887)">
								<ellipse
									cx={1981.62}
									cy={1247.49}
									rx={87.401}
									ry={87.881}
									style={{
										fill: 'none',
										stroke: 'currentColor',
										strokeWidth: '20.82px',
									}}
								/>
							</g>
							<g transform="matrix(-1,0,0,1,4296.11,0)">
								<rect
									x={2083.34}
									y={1231.11}
									width={66.702}
									height={15.521}
									style={{
										fill: 'none',
										stroke: 'currentColor',
										strokeWidth: '20.82px',
									}}
								/>
							</g>
							<g transform="matrix(-1,0,0,1,4296.11,0)">
								<rect
									x={1892.23}
									y={1208.69}
									width={16.306}
									height={30.182}
									style={{
										fill: 'none',
										stroke: 'currentColor',
										strokeWidth: '20.82px',
									}}
								/>
							</g>
						</g>
					</g>
				</g>
			</g>
		</svg>
	);
}



================================================
FILE: packages/wordpress-plugin/src/harper/RichText.ts
================================================
import { binaryInlined, type Lint, LocalLinter, type Suggestion } from 'harper.js';
import type { LintBox } from './Box';
import DataBlock from './DataBlock';
import { getRangeForTextSpan } from './domUtils';

export type EditContentCallback = (newContent: string) => void;

/**
 * Represents a rich text element on-screen.
 * It can either be a child element of a `DataBlock` or be the `DataBlock` itself.
 */
export default class RichText {
	private targetElement: Element;
	private parent: DataBlock;
	private editContent: EditContentCallback;

	constructor(targetElement: Element, parent: DataBlock, editContent: EditContentCallback) {
		this.targetElement = targetElement;
		this.parent = parent;
		this.editContent = editContent;
	}

	public getTargetElement(): Element {
		return this.targetElement;
	}

	public getTextContent(): string {
		return this.targetElement.textContent ?? '';
	}

	public computeLintBox(lint: Lint): LintBox[] {
		const text = this.targetElement.textContent;
		const span = lint.span();
		const range = getRangeForTextSpan(this.targetElement, span);
		// Use a local linter because we won't be doing any expensive operations with it.
		const linter = new LocalLinter({ binary: binaryInlined });

		if (range === null || text === null) {
			console.log('Could not locate range.');
			return [];
		}

		const targetRects = range.getClientRects();
		const container = DataBlock.getContainer();
		const contRect = container.getBoundingClientRect();

		const boxes: LintBox[] = [];

		for (const targetRect of targetRects) {
			boxes.push({
				x: targetRect.x - contRect.x,
				y: targetRect.y - contRect.y,
				width: targetRect.width,
				height: targetRect.height,
				lint,
				applySuggestion: async (sug: Suggestion) => {
					const fixed = await linter.applySuggestion(text, lint, sug);

					this.editContent(fixed);
				},
			});
		}

		return boxes;
	}
}



================================================
FILE: packages/wordpress-plugin/src/harper/SidebarControl.tsx
================================================
import { useCallback, useEffect, useMemo, useState } from 'react';
import { createPortal } from 'react-dom';
import DataBlock from './DataBlock';
import Highlighter from './Highlighter';
import SidebarTabContainer from './SidebarTabContainer';
import useLintBoxes from './useLintBoxes';

export default function SidebarControl() {
	const documentContainer = useMemo<Element>(() => DataBlock.getContainer(), []);

	const [blocks, setBlocks] = useState<DataBlock[]>(DataBlock.getTerminalDataBlocks());

	const updateBlocks = useCallback(() => setBlocks(DataBlock.getTerminalDataBlocks()), []);

	useEffect(updateBlocks, [updateBlocks]);

	useEffect(() => {
		const observer = new MutationObserver(updateBlocks);

		observer.observe(documentContainer, {
			subtree: true,
			childList: true,
		});

		return () => observer.disconnect();
	}, [documentContainer, updateBlocks]);

	const richTexts = useMemo(() => blocks.flatMap((block) => block.getAllRichText()), [blocks]);

	const [lintBoxes, loadingLints] = useLintBoxes(richTexts);

	const highlights =
		documentContainer &&
		richTexts.map((richText, index) => {
			const boxes = lintBoxes[index] ?? [];
			return createPortal(
				<Highlighter richText={richText} key={richText.getTextContent()} lintBoxes={boxes} />,
				documentContainer,
			);
		});

	return (
		<>
			{highlights}
			<SidebarTabContainer lintBoxes={lintBoxes.flat()} loading={loadingLints} />
		</>
	);
}



================================================
FILE: packages/wordpress-plugin/src/harper/SidebarTabContainer.tsx
================================================
import { Panel, PanelBody, TabPanel } from '@wordpress/components';
import type { IgnorableLintBox } from './Box';
import DialectSelectRow from './DialectSelectRow';
import LintList from './LintList';
import LintSettingList from './LintSettingList';

export default function SidebarTabContainer({
	lintBoxes,
	loading,
}: {
	lintBoxes: IgnorableLintBox[];
	loading: boolean;
}) {
	return (
		<TabPanel
			tabs={[
				{ name: 'errors', title: 'Errors' },
				{ name: 'settings', title: 'Settings' },
			]}
		>
			{(tab) => {
				switch (tab.name) {
					case 'errors':
						return <LintList lintBoxes={lintBoxes} loading={loading} />;
					case 'settings':
						return (
							<Panel>
								<PanelBody title="Rules">
									<DialectSelectRow />
									<LintSettingList />
								</PanelBody>
							</Panel>
						);
				}
			}}
		</TabPanel>
	);
}



================================================
FILE: packages/wordpress-plugin/src/harper/SuggestionControl.tsx
================================================
import { Button, Popover } from '@wordpress/components';
import { useEffect, useMemo, useRef, useState } from 'react';
import { type IgnorableLintBox, isPointInBox } from './Box';
import { suggestionText } from './lintUtils';
import { useAddToDictionary } from './usePersonalDictionary';

/**
 * A control for an individual suggestion shown on the screen.
 * This includes both the underline to be shown, and the control that appears when you hover over it.
 * @param root0
 * @param root0.lintBox
 */
export default function SuggestionControl({ lintBox }: { lintBox: IgnorableLintBox }) {
	const { x, y, width, height, lint, applySuggestion, ignoreLint } = lintBox;
	const addToDictionary = useAddToDictionary();

	const underlineRef = useRef<HTMLDivElement | null>(null);
	const popoverRef = useRef<HTMLDivElement | null>(null);

	const suggestions = useMemo(() => lint.suggestions(), [lint]);
	const [showPopover, setShowPopover] = useState(false);

	useEffect(() => {
		const effectTarget = underlineRef.current;
		const popover = popoverRef.current;

		function mouseUp(e: MouseEvent) {
			if (effectTarget === null) {
				return;
			}

			const underlineRect = effectTarget.getBoundingClientRect();
			const popoverRect = popover?.getBoundingClientRect();

			if (
				isPointInBox([e.clientX, e.clientY], underlineRect) ||
				(popoverRect && isPointInBox([e.clientX, e.clientY], popoverRect))
			) {
				setShowPopover(() => true);
			} else {
				setShowPopover(false);
			}
		}

		effectTarget?.parentElement?.addEventListener('mouseup', mouseUp);

		return () => {
			effectTarget?.parentElement?.removeEventListener('mouseup', mouseUp);
		};
	}, [underlineRef.current, popoverRef.current]);

	return (
		<>
			<div
				ref={underlineRef}
				className={`harper-underline-${lint.lint_kind()}`}
				style={{
					position: 'absolute',
					top: `${y}px`,
					left: ` ${x}px`,
					width: `${width}px`,
					height: `${height}px`,
					pointerEvents: 'none',
					zIndex: 1,
				}}
			/>
			{showPopover ? (
				<Popover ref={popoverRef} anchor={underlineRef.current} className="harper-popover">
					<h2 className={`harper-underline-${lint.lint_kind()}`}>{lint.lint_kind_pretty()}</h2>
					<p>{lint.message()}</p>
					{suggestions.map((sug, index) => (
						<Button key={index} onClick={() => applySuggestion(sug)} variant="primary">
							{suggestionText(sug.kind(), lint.get_problem_text(), sug.get_replacement_text())}
						</Button>
					))}

					{lint.lint_kind() === 'Spelling' ? (
						<Button onClick={() => addToDictionary(lint.get_problem_text())} variant="primary">
							Add “{lint.get_problem_text()}” to the dictionary
						</Button>
					) : (
						<></>
					)}

					<Button variant="link" onClick={ignoreLint}>
						Ignore
					</Button>
				</Popover>
			) : (
				<></>
			)}
		</>
	);
}



================================================
FILE: packages/wordpress-plugin/src/harper/useDialect.ts
================================================
import { useDispatch, useSelect } from '@wordpress/data';
import { Dialect } from 'harper.js';
import { useCallback, useMemo } from 'react';

const KEY = 'dialect';

export default function useDialect(): [Dialect, (newState: Dialect) => void] {
	const dialect = useSelect((select) => select('core/preferences').get('harper-wp', KEY), []);

	const { set } = useDispatch('core/preferences');

	const setConfig = useCallback((newValue) => {
		set('harper-wp', KEY, newValue);
	}, []);

	const nonNull = useMemo(() => {
		if (dialect == null) {
			return Dialect.American;
		}
		return dialect;
	}, [dialect]);

	return [nonNull, setConfig];
}



================================================
FILE: packages/wordpress-plugin/src/harper/useIgnoredLintState.ts
================================================
import { useDispatch, useSelect } from '@wordpress/data';
import type { Lint } from 'harper.js';
import { useCallback } from 'react';
import { useLinter } from './LinterProvider';

const KEY = 'ignoredLints';

export default function useIgnoredLintState(): [string | undefined, (newState: string) => void] {
	const ignoredLintState = useSelect(
		(select) => select('core/preferences').get('harper-wp', KEY),
		[],
	);

	const { set } = useDispatch('core/preferences');

	const updateState = useCallback((newValue: string) => set('harper-wp', KEY, newValue), [set]);

	return [ignoredLintState, updateState];
}

/** Get a callback that adds a lint to the global ignored lint state. */
export function useIgnoreLint(): (lint: Lint) => Promise<void> {
	const linter = useLinter();
	const [ignoredLintState, setIgnoredLintState] = useIgnoredLintState();

	return async (lint) => {
		await linter.clearIgnoredLints();

		if (ignoredLintState) {
			await linter.importIgnoredLints(ignoredLintState);
		}

		await linter.ignoreLint(lint);
		setIgnoredLintState(await linter.exportIgnoredLints());
	};
}



================================================
FILE: packages/wordpress-plugin/src/harper/useLintBoxes.ts
================================================
import type { Lint } from 'harper.js';
import { useCallback, useEffect, useState } from 'react';
import type { IgnorableLintBox } from './Box';
import { useLinter } from './LinterProvider';
import type RichText from './RichText';
import useDialect from './useDialect';
import useIgnoredLintState, { useIgnoreLint } from './useIgnoredLintState';
import useLintConfig from './useLintConfig';
import usePersonalDictionary from './usePersonalDictionary';

/**
 * Lint given elements and return the resulting error targets.
 * Provides a loading state as well.
 * @param richTexts
 */
export default function useLintBoxes(richTexts: RichText[]): [IgnorableLintBox[][], boolean] {
	const linter = useLinter();
	const [config] = useLintConfig();
	const [dialect] = useDialect();
	const [ignoreState] = useIgnoredLintState();
	const [personalDictionary] = usePersonalDictionary();
	const ignoreLint = useIgnoreLint();

	const [targetBoxes, setTargetBoxes] = useState<IgnorableLintBox[][]>([]);
	const [lints, setLints] = useState<Lint[][]>([]);
	const [loading, setLoading] = useState(true);

	const updateLints = useCallback(async () => {
		if ((await linter.exportIgnoredLints()) !== ignoreState) {
			await linter.clearIgnoredLints();
		}

		console.log(dialect);

		await linter.setDialect(dialect);

		if (personalDictionary) {
			await linter.importWords(personalDictionary);
		}

		if (JSON.stringify(await linter.getLintConfig()) !== JSON.stringify(config)) {
			await linter.setLintConfig(config);
		}

		if (ignoreState) {
			await linter.importIgnoredLints(ignoreState);
		}

		// We assume that a given index always refers to the same rich text field.
		const newLints = await Promise.all(
			richTexts.map(async (richText) => {
				const contents = richText.getTextContent();

				return await linter.lint(contents);
			}),
		);

		setLoading(false);
		setLints(newLints);
	}, [richTexts, linter, config, ignoreState, personalDictionary, dialect]);

	useEffect(() => {
		updateLints();

		const observers = richTexts.map((richText) => {
			const observer = new MutationObserver(updateLints);
			observer.observe(richText.getTargetElement(), {
				childList: true,
				characterData: true,
				subtree: true,
			});
			return observer;
		});

		return () => {
			observers.forEach((observer) => {
				observer.disconnect();
			});
		};
	}, [richTexts, updateLints]);

	// Update the lint boxes each frame.
	// Probably overkill.
	//
	// TODO: revisit this to do more lazily.
	// Maybe `onLayoutEffect`?
	useEffect(() => {
		let running = true;

		function onFrame() {
			const lintBoxes = lints.map((lintForText, index) => {
				const richText = richTexts[index];
				return lintForText
					.flatMap((lint) => richText.computeLintBox(lint))
					.map((box) => {
						return {
							...box,
							ignoreLint: () => ignoreLint(box.lint),
						};
					});
			});

			setTargetBoxes(lintBoxes);

			if (running) {
				requestAnimationFrame(onFrame);
			}
		}

		requestAnimationFrame(onFrame);

		return () => {
			running = false;
		};
	}, [lints, richTexts, ignoreLint]);

	return [targetBoxes, loading];
}



================================================
FILE: packages/wordpress-plugin/src/harper/useLintConfig.ts
================================================
import { useDispatch, useSelect } from '@wordpress/data';
import type { LintConfig } from 'harper.js';
import { merge } from 'lodash-es';
import { useCallback, useEffect, useMemo, useState } from 'react';
import { useLinter } from './LinterProvider';

const KEY = 'lintConfig';

export default function useLintConfig(): [LintConfig, (newState: LintConfig) => void] {
	const defaultConfig = useDefaultLintConfig();
	const lintConfig = useSelect((select) => select('core/preferences').get('harper-wp', KEY), []);

	const { set } = useDispatch('core/preferences');

	const setConfig = useCallback((newValue) => {
		set('harper-wp', KEY, newValue);
	}, []);

	useEffect(() => {
		if (
			lintConfig == null ||
			Object.entries(lintConfig).length < Object.entries(defaultConfig).length
		) {
			merge(lintConfig, defaultConfig);
			setConfig({ ...lintConfig });
		}
	}, [defaultConfig, setConfig]);

	const nonNull = useMemo(() => {
		if (lintConfig == null) {
			return defaultConfig;
		}
		return lintConfig;
	}, [lintConfig]);

	return [nonNull, setConfig];
}

export function useDefaultLintConfig(): LintConfig {
	const linter = useLinter();
	const [defaultConfig, setDefaultConfig] = useState({});

	useEffect(() => {
		linter.getDefaultLintConfig().then(setDefaultConfig);
	}, [linter]);

	return defaultConfig;
}



================================================
FILE: packages/wordpress-plugin/src/harper/usePersonalDictionary.ts
================================================
import { useDispatch, useSelect } from '@wordpress/data';
import { useCallback } from 'react';

const KEY = 'personalDictionary';

/** Read and add to the user's personal dictionary. */
export default function usePersonalDictionary(): [
	string[] | undefined,
	(updatedDictionary: string[]) => void,
] {
	const personalDictionary = useSelect(
		(select) => select('core/preferences').get('harper-wp', KEY),
		[],
	);

	const { set } = useDispatch('core/preferences');

	const updateState = useCallback(
		(updatedDictionary: string[]) => set('harper-wp', KEY, updatedDictionary),
		[set],
	);

	return [personalDictionary, updateState];
}

/** Get a callback that adds a word to the personal dictionary. */
export function useAddToDictionary(): (word: string) => void {
	const [dict, setDict] = usePersonalDictionary();

	return useCallback(
		(word: string) => {
			if (!dict?.includes(word)) {
				setDict([...(dict ?? []), word]);
			}
		},
		[dict, setDict],
	);
}



================================================
FILE: packages/wordpress-plugin/src/harper/useToggle.ts
================================================
import { useState } from 'react';

export default function useToggle(): [boolean, () => void] {
	const [value, setValue] = useState(false);

	return [value, () => setValue(!value)];
}



================================================
FILE: .github/dependabot.yml
================================================
version: 2
updates:
  - package-ecosystem: "cargo"
    directory: "/"
    schedule:
      interval: "weekly"
  - package-ecosystem: "npm"
    directory: "/"
    schedule:
      interval: "weekly"



================================================
FILE: .github/pull_request_template.md
================================================
# Issues 
<!-- Link any relevant GitHub issues here. -->
<!-- If this PR resolves the issue(s), write closes/fixes/resolves before the issue number(s) (e.g. Fixes #____, closes #____). -->

# Description
<!-- Please include a summary of the change. -->
<!-- Any details that you think are important to review this PR? -->
<!-- Are there other PRs related to this one? -->

# Demo
<!-- Add a screenshot or a video demonstration when possible and necessary. -->

# How Has This Been Tested?
<!-- Please describe how you tested your changes. -->

# Checklist
<!-- Go over all the following points, and put an `x` in all the boxes that apply -->

- [ ] I have performed a self-review of my own code
- [ ] I have added tests to cover my changes



================================================
FILE: .github/ISSUE_TEMPLATE/bug_report.md
================================================
---
name: Bug report
about: Create a report to help us improve
title: ''
labels: bug
assignees: ''

---

**Describe the bug**
A clear and concise description of what the bug is.

**To Reproduce**
Steps to reproduce the behavior:
1. Go to '...'
2. Click on '....'
3. Scroll down to '....'
4. See error

**Expected behavior**
A clear and concise description of what you expected to happen.

**Screenshots**
If applicable, add screenshots to help explain your problem.

**Platform**
What platform has the issue? Is it in Obsidian, Neovim, Visual Studio Code, Chrome, or Firefox? Something else?

**Additional context**
Add any other context about the problem here.



================================================
FILE: .github/ISSUE_TEMPLATE/report-false-positive.md
================================================
---
name: Report False Positive
about: Harper flagged something that's actually correct
title: ''
labels: bug, harper-core, linting, false-positive
---
**What got flagged?**
The text that was incorrectly flagged.

**Why is this incorrect?**
Brief explanation.

**Example of correct usage:**
[Your example here]


================================================
FILE: .github/ISSUE_TEMPLATE/report-grammatical-error.md
================================================
---
name: Report Grammatical Error
about: Harper missed a grammatical error
title: ''
labels: enhancement, harper-core, linting
---
**The Error**
Description of the error.

**Examples (2-3):**
1. 
2. 

**References**
Any grammar rules or resources that support this.

**Potential Edge Cases**
When might this not apply?


================================================
FILE: .github/ISSUE_TEMPLATE/suggest-a-feature.md
================================================
---
name: Suggest a Feature
about: Propose a new feature
title: ''
labels: enhancement
---
**What problem does this solve?**
Brief description.

**Proposed Solution**
How should it work?

**Examples**
Show, don't tell.

**Component**
- [ ] Core engine
- [ ] Plugin/Extension
- [ ] Other: _____

**Additional Context**
Any other relevant info.


================================================
FILE: .github/workflows/binaries.yml
================================================
name: Binaries

on:
  push:
    branches: ["master"]
    tags: ["v*"]
  merge_group:

jobs:
  binaries:
    name: ${{ matrix.platform.project }} - ${{ matrix.platform.release_for }}
    if: github.event.pull_request.draft == false
    strategy:
      matrix:
        platform:
          - release_for: Windows-x86_64
            os: windows-latest
            target: x86_64-pc-windows-msvc
            project: harper-ls
            bin: harper-ls.exe
            name: harper-ls-x86_64-pc-windows-msvc.zip
            command: build
          - release_for: macOS-x86_64
            os: macOS-latest
            target: x86_64-apple-darwin
            project: harper-ls
            bin: harper-ls
            name: harper-ls-x86_64-apple-darwin.tar.gz
            command: build
          - release_for: macOS-aarch64
            os: macOS-latest
            target: aarch64-apple-darwin
            project: harper-ls
            bin: harper-ls
            name: harper-ls-aarch64-apple-darwin.tar.gz
            command: build
          - release_for: Linux-x86_64-GNU
            os: ubuntu-latest
            target: x86_64-unknown-linux-gnu
            project: harper-ls
            bin: harper-ls
            name: harper-ls-x86_64-unknown-linux-gnu.tar.gz
            command: build
          - release_for: Linux-aarch64-GNU
            os: ubuntu-latest
            target: aarch64-unknown-linux-gnu
            project: harper-ls
            bin: harper-ls
            name: harper-ls-aarch64-unknown-linux-gnu.tar.gz
            command: build
          - release_for: Linux-x86_64-musl
            os: ubuntu-latest
            target: x86_64-unknown-linux-musl
            project: harper-ls
            bin: harper-ls
            name: harper-ls-x86_64-unknown-linux-musl.tar.gz
            command: build
          - release_for: Linux-aarch64-musl
            os: ubuntu-latest
            target: aarch64-unknown-linux-musl
            project: harper-ls
            bin: harper-ls
            name: harper-ls-aarch64-unknown-linux-musl.tar.gz
            command: build

          - release_for: Windows-x86_64
            os: windows-latest
            target: x86_64-pc-windows-msvc
            project: harper-cli
            bin: harper-cli.exe
            name: harper-cli-x86_64-pc-windows-msvc.zip
            command: build
          - release_for: macOS-x86_64
            os: macOS-latest
            target: x86_64-apple-darwin
            project: harper-cli
            bin: harper-cli
            name: harper-cli-x86_64-apple-darwin.tar.gz
            command: build
          - release_for: macOS-aarch64
            os: macOS-latest
            target: aarch64-apple-darwin
            project: harper-cli
            bin: harper-cli
            name: harper-cli-aarch64-apple-darwin.tar.gz
            command: build
          - release_for: Linux-x86_64-GNU
            os: ubuntu-latest
            target: x86_64-unknown-linux-gnu
            project: harper-cli
            bin: harper-cli
            name: harper-cli-x86_64-unknown-linux-gnu.tar.gz
            command: build
          - release_for: Linux-aarch64-GNU
            os: ubuntu-latest
            target: aarch64-unknown-linux-gnu
            project: harper-cli
            bin: harper-cli
            name: harper-cli-aarch64-unknown-linux-gnu.tar.gz
            command: build
          - release_for: Linux-x86_64-musl
            os: ubuntu-latest
            target: x86_64-unknown-linux-musl
            project: harper-cli
            bin: harper-cli
            name: harper-cli-x86_64-unknown-linux-musl.tar.gz
            command: build
          - release_for: Linux-aarch64-musl
            os: ubuntu-latest
            target: aarch64-unknown-linux-musl
            project: harper-cli
            bin: harper-cli
            name: harper-cli-aarch64-unknown-linux-musl.tar.gz
            command: build

    runs-on: ${{ matrix.platform.os }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4
      - name: Rust Cache
        uses: Swatinem/rust-cache@v2.7.8
      - name: Build binary
        uses: houseabsolute/actions-rust-cross@v1
        with:
          command: ${{ matrix.platform.command }}
          target: ${{ matrix.platform.target }}
          args: "--locked --release --bin ${{ matrix.platform.project }}"
          force-use-cross: ${{ matrix.platform.os == 'ubuntu-latest' }}
          strip: true
      - name: Package as archive
        shell: bash
        run: |
          cd target/${{ matrix.platform.target }}/release
          if [[ "${{ matrix.platform.os }}" == "windows-latest" ]]; then
            7z a ../../../${{ matrix.platform.name }} ${{ matrix.platform.bin }}
          else
            tar czvf ../../../${{ matrix.platform.name }} ${{ matrix.platform.bin }}
          fi
          cd -
      - name: Upload Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: ${{ matrix.platform.bin }}-${{ matrix.platform.target }}
          path: ${{ matrix.platform.name }}

      - name: Release artifacts
        if: startsWith(github.ref, 'refs/tags/v')
        uses: ncipollo/release-action@v1
        with:
          artifacts: ${{ matrix.platform.name }}
          allowUpdates: true
          draft: true



================================================
FILE: .github/workflows/build_web.yml
================================================
name: Build Web

on:
  push:
    branches: ["master", "web-prod"]
  pull_request:
    branches: ["master"]
  merge_group:

jobs:
  build-web:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Setup node
        uses: actions/setup-node@v4
        with:
          node-version-file: ".node-version"
      - name: Retrieve version after install
        id: nodenv
        run: echo "node-version=$(node -v | sed 's/^v//')" >> $GITHUB_OUTPUT
      - uses: redhat-actions/buildah-build@v2
        with:
          image: web
          containerfiles: |
            Dockerfile
          build-args: |
            NODE_VERSION=${{ steps.nodenv.outputs.node-version }}-slim
          extra-args: |
            --ulimit nofile=65536:65536



================================================
FILE: .github/workflows/chrome_plugin.yml
================================================
name: Chrome Plugin

on:
  push:
    branches: ["master"]
    tags: ["v*"]
  pull_request:
    branches: ["master"]
  merge_group:

env:
  CARGO_TERM_COLOR: always

jobs:
  chrome-plugin:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: extractions/setup-just@v2
      - uses: actions/setup-node@v4
        with:
          node-version-file: ".node-version"
      - name: Enable Corepack
        run: corepack enable
      - uses: cargo-bins/cargo-binstall@main
      - name: Install `wasm-pack`
        run: cargo binstall wasm-pack --force --no-confirm
      - name: Build Chrome Plugin
        run: just build-chrome-plugin
      - name: Build Firefox Plugin
        run: just build-firefox-plugin
      - name: Upload Chrome extension
        uses: actions/upload-artifact@v4
        with:
          name: harper-chrome-plugin.zip
          path: "packages/chrome-plugin/package/harper-chrome-plugin.zip"
      - name: Upload Firefox extension
        uses: actions/upload-artifact@v4
        with:
          name: harper-firefox-plugin.zip
          path: "packages/chrome-plugin/package/harper-firefox-plugin.zip"
      - name: Release artifacts
        uses: ncipollo/release-action@v1
        if: startsWith(github.ref, 'refs/tags/v')
        with:
          artifacts: "packages/chrome-plugin/package/*.zip"
          allowUpdates: true
          draft: true



================================================
FILE: .github/workflows/just_checks.yml
================================================
name: Just Checks

on:
  push:
    branches: ["master", "web-prod"]
  pull_request:
    branches: ["master"]
  merge_group:

env:
  CARGO_TERM_COLOR: always

jobs:
  just-checks:
    runs-on: ubuntu-latest
    name: just ${{ matrix.task }}
    strategy:
      matrix:
        task:
          [
            check-rust,
            check-js,
            test-rust,
            test-harperjs,
            test-vscode,
            test-chrome-plugin,
            test-firefox-plugin,
            test-obsidian,
          ]
    steps:
      - uses: actions/checkout@v4
      - uses: extractions/setup-just@v2
      - name: Install pnpm
        uses: pnpm/action-setup@v4
      - uses: actions-rust-lang/setup-rust-toolchain@v1
        with:
          components: rustfmt,clippy
      - name: Install Node.js
        uses: actions/setup-node@v4
        with:
          node-version-file: ".node-version"
      - name: Enable Corepack
        run: corepack enable
      - name: Rust Cache
        uses: Swatinem/rust-cache@v2.7.8
      - uses: cargo-bins/cargo-binstall@main
      - name: Install `wasm-pack`
        run: cargo binstall wasm-pack --force --no-confirm
      - name: Install `cargo hack`
        run: cargo binstall cargo-hack --force --no-confirm
      - name: Run `${{ matrix.task }}`
        run: just ${{ matrix.task }}



================================================
FILE: .github/workflows/stale.yml
================================================
# Adapted from [Jeff Geerling's Stale Workflow](https://github.com/geerlingguy/mac-dev-playbook/blob/719de3569804fcf4974fc3a14f46f3ebb92989b2/.github/workflows/stale.yml)

---
name: Close inactive issues
"on":
  schedule:
    - cron: "0 2 * * *"

jobs:
  close-issues:
    runs-on: ubuntu-latest
    permissions:
      issues: write
      pull-requests: write
    steps:
      - uses: actions/stale@v10
        with:
          days-before-stale: 60
          days-before-close: 14
          exempt-issue-labels: bug,pinned,security,planned
          exempt-pr-labels: bug,pinned,security,planned
          stale-issue-label: "stale"
          stale-pr-label: "stale"
          stale-issue-message: |
            This issue has been marked 'stale' due to lack of recent activity. If there is no further activity, the issue will be closed in another 14 days. Thank you for your contribution!
          close-issue-message: |
            This issue has been closed due to inactivity. If you feel this is in error, please reopen the issue or file a new issue with the relevant details.
          stale-pr-message: |
            This pr has been marked 'stale' due to lack of recent activity. If there is no further activity, the issue will be closed in another 14 days. Thank you for your contribution!
          close-pr-message: |
            This pr has been closed due to inactivity. If you feel this is in error, please reopen the issue or file a new issue with the relevant details.
          repo-token: ${{ secrets.GITHUB_TOKEN }}



================================================
FILE: .github/workflows/vscode_plugin.yml
================================================
name: VS Code Plugin

on:
  push:
    branches: ["master"]
    tags: ["v*"]
  merge_group:

jobs:
  vscode-plugin:
    name: ${{ matrix.platform.code_target }}
    if: github.event.pull_request.draft == false
    strategy:
      matrix:
        platform:
          - os: windows-latest
            rust_target: x86_64-pc-windows-msvc
            code_target: win32-x64
          - os: windows-latest
            rust_target: aarch64-pc-windows-msvc
            code_target: win32-arm64
          - os: macOS-latest
            rust_target: x86_64-apple-darwin
            code_target: darwin-x64
          - os: macOS-latest
            rust_target: aarch64-apple-darwin
            code_target: darwin-arm64
          - os: ubuntu-latest
            rust_target: x86_64-unknown-linux-gnu
            code_target: linux-x64
          - os: ubuntu-latest
            rust_target: aarch64-unknown-linux-gnu
            code_target: linux-arm64
          - os: ubuntu-latest
            rust_target: armv7-unknown-linux-gnueabihf
            code_target: linux-armhf
          - os: ubuntu-latest
            rust_target: x86_64-unknown-linux-musl
            code_target: alpine-x64
          - os: ubuntu-latest
            rust_target: aarch64-unknown-linux-musl
            code_target: alpine-arm64
    runs-on: ${{ matrix.platform.os }}
    steps:
      - uses: actions/checkout@v4
      - uses: extractions/setup-just@v2
      - uses: actions/setup-node@v4
        with:
          node-version-file: ".node-version"
      - name: Enable Corepack
        run: corepack enable
      - name: Build harper-ls
        uses: houseabsolute/actions-rust-cross@v1
        with:
          target: ${{ matrix.platform.rust_target }}
          args: "--locked --release --bin harper-ls"
          force-use-cross: ${{ matrix.platform.os == 'ubuntu-latest' }}
          strip: true
      - name: Package extension
        id: package_extension
        shell: bash
        run: |
          bin_dir="packages/vscode-plugin/bin"
          release_dir="target/${{ matrix.platform.rust_target }}/release"

          mkdir "$bin_dir"

          if [[ "${{ matrix.platform.os }}" == "windows-latest" ]]; then
            cp "${release_dir}/harper-ls.exe" "$bin_dir"
          else
            cp "${release_dir}/harper-ls" "$bin_dir"
          fi

          just package-vscode ${{ matrix.platform.code_target }}
          echo artifact=$(echo packages/vscode-plugin/*.vsix) >> $GITHUB_OUTPUT
      - name: Release artifacts
        if: startsWith(github.ref, 'refs/tags/v')
        uses: ncipollo/release-action@v1
        with:
          artifacts: "./packages/vscode-plugin/*.vsix"
          allowUpdates: true
          draft: true
      - name: Publish to OpenVSX
        if: startsWith(github.ref, 'refs/tags/v')
        uses: HaaLeo/publish-vscode-extension@v1
        with:
          pat: ${{ secrets.OPEN_VSX_TOKEN }}
          packagePath: "./packages/vscode-plugin/"
          extensionFile: ${{ steps.package_extension.outputs.artifact }}
          skipDuplicate: true
      - name: Publish to the Visual Studio Marketplace
        if: startsWith(github.ref, 'refs/tags/v')
        uses: HaaLeo/publish-vscode-extension@v1
        with:
          pat: ${{ secrets.VS_MARKETPLACE_TOKEN }}
          packagePath: "./packages/vscode-plugin/"
          extensionFile: ${{ steps.package_extension.outputs.artifact }}
          registryUrl: https://marketplace.visualstudio.com



================================================
FILE: .github/workflows/wp_plugin.yml
================================================
name: WordPress Plugin

on:
  push:
    branches: ["master"]
    tags: ["v*"]
  pull_request:
    branches: ["master"]
  merge_group:

env:
  CARGO_TERM_COLOR: always

jobs:
  wp-plugin:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: extractions/setup-just@v2
      - uses: actions/setup-node@v4
        with:
          node-version-file: ".node-version"
      - name: Enable Corepack
        run: corepack enable
      - uses: cargo-bins/cargo-binstall@main
      - name: Install wasm-pack
        run: cargo binstall wasm-pack --force --no-confirm
      - name: Build
        run: just build-wp
      - name: Upload artifact
        uses: actions/upload-artifact@v4
        with:
          name: harper.zip
          path: packages/wordpress-plugin/harper.zip
      - name: Draft GitHub release
        if: startsWith(github.ref, 'refs/tags/v')
        uses: ncipollo/release-action@v1
        with:
          artifacts: packages/wordpress-plugin/harper.zip
          allowUpdates: true
          draft: true



Directory structure:
└── zlwaterfield-scramble/
    ├── README.md
    ├── build.js
    ├── LICENSE
    ├── package.json
    ├── privacy.md
    ├── tailwind.config.js
    ├── manifests/
    │   ├── manifest_v2.json
    │   └── manifest_v3.json
    └── src/
        ├── background.js
        ├── content.js
        ├── options.html
        ├── options.js
        ├── popup.html
        ├── popup.js
        └── libs/
            ├── tw-input.css
            └── tw-output.css

================================================
FILE: README.md
================================================
# Scramble - Open-Source Grammarly Alternative

> Note: this project has lots of users but I'm not actively developing it so if you'd like to be a maintainer on this project let me know!

Scramble is an open-source Chrome extension that leverages AI to enhance your writing directly in your browser. It's designed to be a more customizable alternative to Grammarly by using specific prompts and allowing you to configure the LLM provider, model, and endpoint.

## Extensions

- Chrome: https://chromewebstore.google.com/detail/scramble/mkaljgnigabhmjfookbokejhfghmkffo
- Firefox: coming soon

## Installation

#### Chrome Installation

- Clone this repository
- Run `npm install`
- Run `npm run build`
- Open Chrome and go to chrome://extensions/
- Enable "Developer mode" in the top right
- Click "Load unpacked" and select the extension directory (dist/chrome)

#### Firefox Installation

- Clone this repository
- Run `npm install`
- Run `npm run build`
- Open Firefox and go to about:debugging#/runtime/this-firefox
- Click "Load Temporary Add-on"
- Navigate to the extension directory (dist/firefox) and select manifest.json

## Development

When developing you'll need to run `npx tailwindcss -i src/libs/tw-input.css -o src/libs/tw-output.css --minify --watch` in order to build the css on the fly. The runs automatically when you run `npm run build`.

## Usage

1. Highlight text on any webpage
2. Right-click to open the context menu
3. Select "Scramble" and choose a text enhancement option
4. Wait for the AI to process and enhance your text

Screenshot:

<img width="600" alt="Screenshot 2024-09-17 at 10 14 30 PM" src="https://github.com/user-attachments/assets/7a8685e5-94dd-47be-a141-f84bcbf1321f">

## Supported LLMs

- OpenAI
- Anthropic
- Groq
- OpenRouter
- Ollama
- LM Studio

## Default Prompts

Scramble comes with several pre-configured text enhancement options:

1. Fix spelling and grammar
2. Improve writing
3. Make more professional
4. Simplify text
5. Summarize text
6. Expand text
7. Convert to bullet points

## Custom Prompts

You can also create your own custom prompts. They will show up in the list of prompts as soon as you save.

<img width="755" alt="Screenshot 2024-11-02 at 10 00 47 AM" src="https://github.com/user-attachments/assets/add93ae6-0018-4845-91cc-a43a1d95077c">


## Future Features

Planned features include:

- Support for additional language models (LLMs)
- Multiple LLM configurations at the same time
- Enhanced context awareness
- View diff between original and improved text
- Underline grammar / spelling issues

## Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## License

[MIT License](LICENSE)




================================================
FILE: build.js
================================================
const fs = require('fs-extra');
const path = require('path');

async function build() {
  // Base extension files
  const commonFiles = [
    'popup.html',
    'popup.js',
    'styles.css',
    'icons'
  ];

  // Build for Chrome (MV3)
  await fs.ensureDir('dist/chrome');
  await fs.copy('src', 'dist/chrome');
  await fs.copy('manifests/manifest_v3.json', 'dist/chrome/manifest.json');

  // Build for Firefox (MV2)
  await fs.ensureDir('dist/firefox');
  await fs.copy('src', 'dist/firefox');
  await fs.copy('manifests/manifest_v2.json', 'dist/firefox/manifest.json');
}

build();


================================================
FILE: LICENSE
================================================
MIT License

Copyright (c) 2024 Zach Waterfield

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.



================================================
FILE: package.json
================================================
{
  "name": "scramble",
  "version": "1.3",
  "scripts": {
    "css:watch": "npx tailwindcss -i src/libs/tw-input.css -o src/libs/tw-output.css --minify --watch",
    "css:build": "npx tailwindcss -i src/libs/tw-input.css -o src/libs/tw-output.css --minify",
    "build": "npm run css:build && node build.js"
  },
  "dependencies": {
    "fs-extra": "^11.2.0"
  }
}


================================================
FILE: privacy.md
================================================
# Privacy Policy for Scramble

## Data Collection and Usage

Scramble is designed with your privacy in mind. We collect and process only the minimum amount of data necessary for the extension to function:

1. **Selected Text**: When you highlight text and use Scramble's features, the selected text is temporarily processed to provide the requested enhancements.

2. **API Key**: Your LLM API key is stored locally in your browser's storage and is never transmitted to our servers.

## Data Transmission

- Selected text is sent directly to the LLM provider's servers for processing using your personal API key.
- We do not store, retain, or have access to the text you process or the results returned by OpenAI.

## Third-Party Services

Scramble uses the LLM provider's API to process text. Please refer to the LLM provider's privacy policy for information on how they handle data.

## Data Security

We implement reasonable security measures to protect your API key and ensure that your data is transmitted securely to OpenAI.

## Changes to This Policy

We may update this privacy policy from time to time. We will notify you of any changes by posting the new privacy policy on this page.

## Contact Us

If you have any questions about this privacy policy, please contact us at [your contact information].

Last updated: 2024-10-26



================================================
FILE: tailwind.config.js
================================================
/** @type {import('tailwindcss').Config} */
module.exports = {
  content: [
    "./src/**/*.{html,js}",
  ],
  theme: {
    extend: {},
  },
  plugins: [],
}



================================================
FILE: manifests/manifest_v2.json
================================================
{
  "manifest_version": 2,
  "name": "Scramble",
  "version": "1.3",
  "description": "An Open-Source Grammarly alternative",
  "icons": {
    "256": "assets/logo256.png"
  },
  "permissions": [
    "activeTab",
    "storage",
    "contextMenus",
    "<all_urls>"
  ],
  "browser_specific_settings": {
    "gecko": {
      "id": "me@zlwaterfield.com"
    }
  },
  "background": {
    "scripts": ["background.js"]
  },
  "content_scripts": [
    {
      "matches": ["<all_urls>"],
      "js": ["content.js"]
    }
  ],
  "options_ui": {
    "page": "options.html",
    "open_in_tab": true
  },
  "browser_action": {
    "default_popup": "popup.html"
  },
  "web_accessible_resources": [
    "tailwind.css"
  ]
}


================================================
FILE: manifests/manifest_v3.json
================================================
{
  "manifest_version": 3,
  "name": "Scramble",
  "version": "1.3",
  "description": "An Open-Source Grammarly alternative",
  "icons": {
    "256": "assets/logo256.png"
  },
  "permissions": [
    "activeTab",
    "storage",
    "contextMenus",
    "scripting"
  ],
  "host_permissions": [
    "<all_urls>"
  ],
  "background": {
    "service_worker": "background.js"
  },
  "content_scripts": [
    {
      "matches": ["<all_urls>"],
      "js": ["content.js"]
    }
  ],
  "options_ui": {
    "page": "options.html",
    "open_in_tab": true
  },
  "action": {
    "default_popup": "popup.html"
  },
  "web_accessible_resources": [
    {
      "resources": ["tailwind.css"],
      "matches": ["<all_urls>"]
    }
  ]
}



================================================
FILE: src/background.js
================================================
const browserAPI = (typeof browser !== 'undefined' ? browser : chrome);

const DEFAULT_PROMPTS = [
  { id: 'fix_grammar', title: 'Fix spelling and grammar', prompt: 'Fix the spelling and grammar. Return only the corrected text without quotes, explanations, or additional text:' },
  { id: 'improve_writing', title: 'Improve writing', prompt: 'Enhance the following text to improve clarity and flow. Return only the improved text without quotes, explanations, or additional text:' },
  { id: 'make_professional', title: 'Make more professional', prompt: 'Rewrite the text in a formal, professional tone. Return only the rewritten text without quotes, explanations, or additional text:' },
  { id: 'simplify', title: 'Simplify text', prompt: 'Simplify this text using simpler words and shorter sentences. Return only the simplified text without quotes, explanations, or additional text:' },
  { id: 'summarize', title: 'Summarize text', prompt: 'Provide a concise summary. Return only the summary without quotes, explanations, or additional text:' },
  { id: 'expand', title: 'Expand text', prompt: 'Elaborate on this text with more details and examples. Return only the expanded text without quotes, explanations, or additional text:' },
  { id: 'bullet_points', title: 'Convert to bullet points', prompt: 'Convert this text into bullet points. Return only the bullet-point list without quotes, explanations, or additional text:' },
];

if (typeof importScripts === 'function') {
  browserAPI.runtime.onInstalled.addListener(handleInstall);
} else {
  handleInstall({ reason: 'install' });
}

async function handleInstall(details) {
  if (details.reason === 'update') {
    log(`Extension updated from version ${details.previousVersion} to ${browserAPI.runtime.getManifest().version}`);
  }
  await updateContextMenu();
}

async function injectContentScript(tabId) {
  try {
    if (browserAPI === chrome) {
      await chrome.scripting.executeScript({
        target: { tabId },
        files: ['content.js']
      });
    } else {
      await browser.tabs.executeScript(tabId, {
        file: 'content.js'
      });
    }
  } catch (error) {
    console.error('Failed to inject content script:', error);
    throw error;
  }
}

browserAPI.contextMenus.onClicked.addListener((info, tab) => {
  browserAPI.storage.sync.get('customPrompts', async ({ customPrompts = [] }) => {
    const allPrompts = [...DEFAULT_PROMPTS, ...customPrompts];
    if (allPrompts.some(prompt => prompt.id === info.menuItemId)) {
      try {
        try {
          await browserAPI.tabs.sendMessage(tab.id, { action: 'ping' });
          await sendEnhanceTextMessage(tab.id, info.menuItemId, info.selectionText);
        } catch (error) {
          await injectContentScript(tab.id);
          await sendEnhanceTextMessage(tab.id, info.menuItemId, info.selectionText);
        }
      } catch (error) {
        console.error('Error handling context menu click:', error);
      }
    }
  });
});

async function sendEnhanceTextMessage(tabId, promptId, selectedText) {
  try {
    await browserAPI.tabs.sendMessage(tabId, {
      action: 'enhanceText',
      promptId: promptId,
      selectedText: selectedText,
    });
  } catch (error) {
    console.error('Error sending message:', error);
    throw error;
  }
}

browserAPI.runtime.onMessage.addListener((request, sender, sendResponse) => {
  if (request.action === 'enhanceText') {
    enhanceTextWithRateLimit(request.promptId, request.selectedText)
      .then(enhancedText => {
        sendResponse({ success: true, enhancedText });
      })
      .catch(error => {
        log(`Error enhancing text: ${error.message}`, 'error');
        sendResponse({ success: false, error: error.message });
      });
    return true;
  }
  return false;
});

async function enhanceTextWithLLM(promptId, text) {
  const config = await getConfig();
  const llmProvider = config.llmProvider;
  const customPrompts = config.customPrompts || [];
  if (!llmProvider) {
    throw new Error('LLM provider not set. Please set it in the extension options.');
  }
  
  const allPrompts = [...DEFAULT_PROMPTS, ...customPrompts];
  const prompt = allPrompts.find(p => p.id === promptId)?.prompt;
  if (!prompt) {
    throw new Error('Invalid prompt ID');
  }
  const fullPrompt = `${prompt}:\n\n${text}`;

  const enhanceFunctions = {
    openai: enhanceWithOpenAI,
    anthropic: enhanceWithAnthropic,
    ollama: enhanceWithOllama,
    lmstudio: enhanceWithLMStudio,
    groq: enhanceWithGroq,
    openrouter: enhanceWithOpenRouter,
  };

  const enhanceFunction = enhanceFunctions[llmProvider];
  if (!enhanceFunction) {
    throw new Error('Invalid LLM provider selected');
  }

  return await enhanceFunction(fullPrompt);
}

async function enhanceWithOpenAI(prompt) {
  const config = await getConfig();
  if (!config.apiKey) {
    throw new Error('OpenAI API key not set. Please set it in the extension options.');
  }

  const endpoint = config.customEndpoint || 'https://api.openai.com/v1/chat/completions';

  try {
    const response = await fetch(endpoint, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${encodeURIComponent(config.apiKey)}`,
      },
      body: JSON.stringify({
        model: config.llmModel || 'gpt-3.5-turbo',
        messages: [
          { role: 'system', content: 'You are a helpful assistant.' },
          { role: 'user', content: prompt }
        ],
        max_tokens: 1000,
        temperature: 0.7,
      }),
    });

    if (!response.ok) {
      const errorData = await response.json();
      throw new Error(`OpenAI API request failed: ${errorData.error.message}`);
    }

    const data = await response.json();
    return data.choices[0].message.content.trim();
  } catch (error) {
    throw new Error(`Failed to enhance text with OpenAI. Error: ${error.message}`);
  }
}

async function enhanceWithAnthropic(prompt) {
  const { apiKey, llmModel, customEndpoint } = await browserAPI.storage.sync.get(['apiKey', 'llmModel', 'customEndpoint']);

  if (!apiKey) {
    throw new Error('Anthropic API key not set. Please set it in the extension options.');
  }

  if (!llmModel) {
    throw new Error('LLM model not set for Anthropic. Please set it in the extension options.');
  }

  const endpoint = customEndpoint || 'https://api.anthropic.com/v1/complete';

  try {
    const response = await fetch(endpoint, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'X-API-Key': apiKey,
      },
      body: JSON.stringify({
        prompt: `Human: ${prompt}\n\nAssistant:`,
        model: llmModel,
        max_tokens_to_sample: 1000,
        temperature: 0.7,
      }),
    });

    if (!response.ok) {
      const errorData = await response.json();
      throw new Error(`Anthropic API request failed: ${errorData.error || 'Unknown error'}`);
    }

    const data = await response.json();
    return data.completion.trim();
  } catch (error) {
    throw new Error(`Failed to enhance text with Anthropic. Error: ${error.message}`);
  }
}

async function enhanceWithOllama(prompt) {
  const { llmModel, customEndpoint, apiKey } = await browserAPI.storage.sync.get(['llmModel', 'customEndpoint', 'apiKey']);

  if (!llmModel) {
    throw new Error('LLM model not set for Ollama. Please set it in the extension options.');
  }

  const endpoint = customEndpoint || 'http://localhost:11434/api/generate';

  try {
    const headers = {
      'Content-Type': 'application/json',
    };

    // Add authorization header if API key is provided (for remote Ollama instances)
    if (apiKey) {
      headers['Authorization'] = `Bearer ${apiKey}`;
    }

    const response = await fetch(endpoint, {
      method: 'POST',
      headers: headers,
      body: JSON.stringify({
        model: llmModel || 'llama2',
        prompt: prompt,
        stream: false,
        options: {
          temperature: 0.7,
          top_p: 0.9,
          top_k: 40,
        }
      }),
    });

    if (!response.ok) {
      const errorText = await response.text();
      throw new Error(`Ollama API request failed: ${response.status} ${response.statusText}. ${errorText}`);
    }

    const data = await response.json();
    
    if (!data.response) {
      throw new Error('Invalid response from Ollama API: missing response field');
    }

    return data.response.trim();
  } catch (error) {
    if (error.message.includes('fetch')) {
      throw new Error(`Failed to connect to Ollama. Make sure Ollama is running on ${endpoint.split('/api')[0]}. Error: ${error.message}`);
    }
    throw new Error(`Failed to enhance text with Ollama. Error: ${error.message}`);
  }
}

// NEW: Add LM Studio support
async function enhanceWithLMStudio(prompt) {
  const { llmModel, customEndpoint, apiKey } = await browserAPI.storage.sync.get(['llmModel', 'customEndpoint', 'apiKey']);

  if (!llmModel) {
    throw new Error('LLM model not set for LM Studio. Please set it in the extension options.');
  }

  const endpoint = customEndpoint || 'http://localhost:1234/v1/chat/completions';

  try {
    const headers = {
      'Content-Type': 'application/json',
    };

    // Add authorization header if API key is provided
    if (apiKey) {
      headers['Authorization'] = `Bearer ${apiKey}`;
    }

    const response = await fetch(endpoint, {
      method: 'POST',
      headers: headers,
      body: JSON.stringify({
        model: llmModel,
        messages: [
          { role: 'system', content: 'You are a helpful assistant.' },
          { role: 'user', content: prompt }
        ],
        max_tokens: 1000,
        temperature: 0.7,
        stream: false
      }),
    });

    if (!response.ok) {
      const errorText = await response.text();
      throw new Error(`LM Studio API request failed: ${response.status} ${response.statusText}. ${errorText}`);
    }

    const data = await response.json();
    
    if (!data.choices || !data.choices[0] || !data.choices[0].message) {
      throw new Error('Invalid response from LM Studio API: missing choices or message');
    }

    return data.choices[0].message.content.trim();
  } catch (error) {
    if (error.message.includes('fetch')) {
      throw new Error(`Failed to connect to LM Studio. Make sure LM Studio server is running on ${endpoint.split('/v1')[0]}. Error: ${error.message}`);
    }
    throw new Error(`Failed to enhance text with LM Studio. Error: ${error.message}`);
  }
}

async function enhanceWithGroq(prompt) {
  const config = await getConfig();

  if (!config.apiKey) {
    throw new Error('Groq API key not set. Please set it in the extension options.');
  }

  if (!config.llmModel) {
    throw new Error('LLM model not set for Groq. Please set it in the extension options.');
  }

  const endpoint = config.customEndpoint || 'https://api.groq.com/v1/chat/completions';

  try {
    const response = await fetch(endpoint, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${encodeURIComponent(config.apiKey)}`,
      },
      body: JSON.stringify({
        model: config.llmModel || 'llama3-8b-8192',
        messages: [
          { role: 'system', content: 'You are a helpful assistant.' },
          { role: 'user', content: prompt }
        ],
        max_tokens: 1000,
        temperature: 0.7,
      }),
    });

    if (!response.ok) {
      const errorData = await response.json();
      throw new Error(`Groq API request failed: ${errorData.error?.message || 'Unknown error'}`);
    }

    const data = await response.json();
    return data.choices[0].message.content.trim();
  } catch (error) {
    console.error('Groq API error:', error);
    throw new Error(`Failed to enhance text with Groq. Error: ${error.message}`);
  }
}

async function enhanceWithOpenRouter(prompt) {
  const config = await getConfig();
  if (!config.apiKey) {
    throw new Error('OpenRouter API key not set. Please set it in the extension options.');
  }

  const endpoint = 'https://openrouter.ai/api/v1/chat/completions';

  try {
    const response = await fetch(endpoint, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${encodeURIComponent(config.apiKey)}`,
        'X-Title': 'Scramble Browser Extension',
      },
      body: JSON.stringify({
        model: config.llmModel || 'openai/gpt-3.5-turbo',
        messages: [
          { role: 'system', content: 'You are a helpful assistant.' },
          { role: 'user', content: prompt }
        ],
        max_tokens: 1000,
        temperature: 0.7,
      }),
    });

    if (!response.ok) {
      const errorData = await response.json();
      throw new Error(`OpenRouter API request failed: ${errorData.error || 'Unknown error'}`);
    }

    const data = await response.json();
    return data.choices[0].message.content.trim();
  } catch (error) {
    console.error('OpenRouter API error:', error);
    throw new Error(`Failed to enhance text with OpenRouter. Error: ${error.message}`);
  }
}

const MAX_REQUESTS_PER_MINUTE = 10;
const RATE_LIMIT_RESET_INTERVAL = 60000;

const rateLimiter = (() => {
  let requestCount = 0;
  let lastResetTime = Date.now();
  const queue = [];

  const resetRateLimit = () => {
    const now = Date.now();
    if (now - lastResetTime > RATE_LIMIT_RESET_INTERVAL) {
      requestCount = 0;
      lastResetTime = now;
    }
  };

  const executeNext = () => {
    if (queue.length > 0) {
      resetRateLimit();
      if (requestCount < MAX_REQUESTS_PER_MINUTE) {
        const next = queue.shift();
        requestCount++;
        next.resolve(next.fn());
        if (queue.length > 0) {
          setTimeout(executeNext, RATE_LIMIT_RESET_INTERVAL / MAX_REQUESTS_PER_MINUTE);
        }
      } else {
        setTimeout(executeNext, RATE_LIMIT_RESET_INTERVAL - (Date.now() - lastResetTime));
      }
    }
  };

  return (fn) => {
    return new Promise((resolve, reject) => {
      queue.push({ fn, resolve, reject });
      if (queue.length === 1) {
        executeNext();
      }
    });
  };
})();

const enhanceTextWithRateLimit = (promptId, text) => {
  return rateLimiter(() => enhanceTextWithLLM(promptId, text));
};

async function getConfig() {
  const defaults = {
    apiKey: '',
    llmProvider: 'openai',
    llmModel: 'gpt-3.5-turbo',
    customEndpoint: '',
    customPrompts: []
  };
  const config = await browserAPI.storage.sync.get(defaults);
  return {
    apiKey: config.apiKey,
    llmModel: config.llmModel,
    customEndpoint: config.customEndpoint,
    llmProvider: config.llmProvider,
    customPrompts: config.customPrompts
  };
}

function log(message, level = 'info') {
  const timestamp = new Date().toISOString();
  console[level](`[${timestamp}] ${message}`);
}

async function updateContextMenu() {
  try {
    await browserAPI.contextMenus.removeAll();
    const config = await getConfig();
    const customPrompts = config.customPrompts || [];
    const allPrompts = [...DEFAULT_PROMPTS, ...customPrompts];

    await browserAPI.contextMenus.create({
      id: 'scramble',
      title: 'Scramble',
      contexts: ['selection'],
    });

    for (const prompt of allPrompts) {
      await browserAPI.contextMenus.create({
        id: prompt.id,
        parentId: 'scramble',
        title: prompt.title,
        contexts: ['selection'],
      });
    }
  } catch (error) {
    console.error('Error updating context menu:', error);
  }
}

browserAPI.storage.onChanged.addListener((changes, area) => {
  if (area === 'sync' && changes.customPrompts) {
    updateContextMenu();
  }
});



================================================
FILE: src/content.js
================================================
const browserAPI = (typeof browser !== 'undefined' ? browser : chrome);

// Listen for messages from the background script
browserAPI.runtime.onMessage.addListener((request, sender, sendResponse) => {
  console.log('[SCRAMBLE] Received message:', request);
  
  // Add support for ping message
  if (request.action === 'ping') {
    sendResponse({ success: true });
    return;
  }
  
  if (request.action === 'enhanceText') {
    enhanceSelectedText(request.promptId, request.selectedText)
      .then(enhancedText => {
        replaceSelectedText(enhancedText);
        sendResponse({ success: true });
      })
      .catch(error => {
        console.error('Error enhancing text:', error);
        showErrorNotification(error.message);
        sendResponse({ success: false, error: error.message });
      });
    return true; // Indicates that the response is asynchronous
  }
});

// Function to enhance selected text
async function enhanceSelectedText(promptId, selectedText) {
  console.log('[SCRAMBLE] Selected text:', promptId, selectedText);
  try {
    const response = await browserAPI.runtime.sendMessage({
      action: 'enhanceText',
      promptId: promptId,
      selectedText: selectedText,
    });
    console.log('[SCRAMBLE] Response:', response);

    if (response.success) {
      return response.enhancedText;
    } else {
      throw new Error(response.error || 'Unknown error occurred');
    }
  } catch (error) {
    console.error('Error in enhanceSelectedText:', error);
    throw error;
  }
}

// Function to replace the selected text with enhanced text
function replaceSelectedText(enhancedText) {
  const selection = window.getSelection();
  if (selection.rangeCount > 0) {
    const range = selection.getRangeAt(0);

    // Handle text inputs and textareas
    const activeElement = document.activeElement;
    if (activeElement && (activeElement.tagName === 'TEXTAREA' || (activeElement.tagName === 'INPUT' && activeElement.type === 'text'))) {
      const start = activeElement.selectionStart;
      const end = activeElement.selectionEnd;
      const text = activeElement.value;
      activeElement.value = text.substring(0, start) + enhancedText + text.substring(end);
      
      // Trigger input event for compatibility with reactive frameworks
      const inputEvent = new Event('input', { bubbles: true });
      activeElement.dispatchEvent(inputEvent);
      
      // Trigger change event
      const changeEvent = new Event('change', { bubbles: true });
      activeElement.dispatchEvent(changeEvent);
    } else {
      range.deleteContents();
      range.insertNode(document.createTextNode(enhancedText));
    }

    selection.removeAllRanges();
  }
}

// Function to show error notification
function showErrorNotification(message) {
  const notification = document.createElement('div');
  notification.textContent = `Error: ${message}`;
  notification.style.cssText = `
    position: fixed;
    top: 20px;
    right: 20px;
    background-color: #ff4444;
    color: white;
    padding: 10px;
    border-radius: 5px;
    z-index: 9999;
    box-shadow: 0 2px 5px rgba(0,0,0,0.2);
  `;
  document.body.appendChild(notification);
  setTimeout(() => {
    notification.remove();
  }, 5000);
}


================================================
FILE: src/options.html
================================================
<!DOCTYPE html>
<html lang="en" class="bg-gray-100">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Scramble Options</title>
    <link href="./libs/tw-output.css" rel="stylesheet">
</head>
<body class="font-sans text-gray-900 antialiased">
    <div class="max-w-3xl mx-auto p-6 bg-white shadow-lg rounded-lg mt-10">
        <h1 class="text-3xl font-bold text-gray-900 mb-4">Scramble settings</h1>
        <p class="text-gray-700 mb-8">
            Scramble is an open-source Chrome extension that leverages AI to enhance your writing directly in your browser. It's designed to be a more customizable and privacy-respecting alternative to Grammarly.
        </p>

        <h2 class="text-2xl font-semibold text-gray-800 mt-8 mb-4">LLM configuration</h2>
        <div class="space-y-4">
            <label class="block">
                <span class="text-gray-700">LLM Provider:</span>
                <select id="llmProvider" class="mt-1 block w-full rounded-md border border-gray-300 bg-white px-3 py-2 shadow-sm focus:border-indigo-500 focus:ring focus:ring-indigo-200 focus:ring-opacity-50">
                    <option value="openai">OpenAI</option>
                    <option value="anthropic">Anthropic</option>
                    <option value="ollama">Ollama (Local)</option>
                    <option value="lmstudio">LM Studio (Local)</option>
                    <option value="groq">Groq</option>
                    <option value="openrouter">OpenRouter</option>
                </select>
            </label>
            <label class="block">
                <span class="text-gray-700">API Key:</span>
                <input type="text" id="apiKey" placeholder="Enter your API key" class="mt-1 block w-full rounded-md border border-gray-300 bg-white px-3 py-2 shadow-sm focus:border-indigo-500 focus:ring focus:ring-indigo-200 focus:ring-opacity-50">
                <small id="apiKeyHelp" class="text-gray-500 text-sm mt-1 block"></small>
            </label>
            <label class="block">
                <span class="text-gray-700">LLM Model:</span>
                <div class="flex gap-2">
                    <input type="text" id="llmModel" placeholder="Enter the LLM model (e.g., gpt-3.5-turbo)" class="mt-1 flex-1 rounded-md border border-gray-300 bg-white px-3 py-2 shadow-sm focus:border-indigo-500 focus:ring focus:ring-indigo-200 focus:ring-opacity-50">
                    <button id="fetchModels" type="button" class="mt-1 px-4 py-2 bg-indigo-600 text-white rounded-md hover:bg-indigo-700 focus:outline-none focus:ring-2 focus:ring-indigo-500 focus:ring-offset-2 disabled:bg-gray-400 disabled:cursor-not-allowed">
                        <span id="fetchModelsText">Fetch Models</span>
                        <span id="fetchModelsSpinner" class="hidden">⟳</span>
                    </button>
                </div>
                <small id="modelHelp" class="text-gray-500 text-sm mt-1 block"></small>
                <select id="availableModels" class="mt-2 block w-full rounded-md border border-gray-300 bg-white px-3 py-2 shadow-sm focus:border-indigo-500 focus:ring focus:ring-indigo-200 focus:ring-opacity-50 hidden">
                    <option value="">Select a model...</option>
                </select>
            </label>
            <label class="block">
                <span class="text-gray-700">Custom Endpoint (optional):</span>
                <input type="text" id="customEndpoint" placeholder="Enter custom API endpoint URL" class="mt-1 block w-full rounded-md border border-gray-300 bg-white px-3 py-2 shadow-sm focus:border-indigo-500 focus:ring focus:ring-indigo-200 focus:ring-opacity-50">
                <small id="endpointHelp" class="text-gray-500 text-sm mt-1 block"></small>
            </label>
        </div>
        
        <h2 class="text-2xl font-semibold text-gray-800 mt-8 mb-4">Custom prompts</h2>
        <div id="prompts-container" class="space-y-4"></div>
        <button id="add-prompt" class="mt-4 px-4 py-2 bg-indigo-600 text-white rounded-md hover:bg-indigo-700 focus:outline-none focus:ring-2 focus:ring-indigo-500 focus:ring-offset-2 font-bold">Add prompt</button>

        <div id="status" class="mt-6 text-sm text-gray-700"></div>
        <div class="flex justify-center">
            <button id="save" class="mx-auto mt-6 px-4 py-2 bg-indigo-600 text-white font-bold rounded-md hover:bg-blue-700 focus:outline-none focus:ring-2 focus:ring-blue-500 focus:ring-offset-2">Save changes</button>
        </div>
    </div>
    
    <script src="options.js"></script>

    <template id="prompt-template">
        <div class="prompt-container bg-gray-100 p-4 rounded-lg border border-gray-300">
            <label class="block mb-2">
                <span class="text-gray-700">Prompt Title:</span>
                <input type="text" class="prompt-title mt-1 block w-full rounded-md border border-gray-300 bg-white px-3 py-2 shadow-sm focus:border-indigo-500 focus:ring focus:ring-indigo-200 focus:ring-opacity-50" placeholder="Enter prompt title">
            </label>
            <label class="block mb-2">
                <span class="text-gray-700">Prompt:</span>
                <textarea class="prompt-text mt-1 block w-full rounded-md border border-gray-300 bg-white px-3 py-2 shadow-sm focus:border-indigo-500 focus:ring focus:ring-indigo-200 focus:ring-opacity-50" placeholder="Enter your prompt here" rows="3"></textarea>
            </label>
            <div class="prompt-actions mt-2">
                <button class="delete-prompt px-4 py-2 bg-red-600 text-white font-bold rounded-md hover:bg-red-700 focus:outline-none focus:ring-2 focus:ring-red-500 focus:ring-offset-2">Delete</button>
            </div>
        </div>
    </template>
</body>
</html>


================================================
FILE: src/options.js
================================================
const browserAPI = (typeof browser !== 'undefined' ? browser : chrome);

// Saves options to browserAPI.storage
async function saveOptions() {
  try {
    const options = {
      llmProvider: document.getElementById('llmProvider').value,
      apiKey: document.getElementById('apiKey').value,
      llmModel: document.getElementById('llmModel').value,
      customEndpoint: document.getElementById('customEndpoint').value,
      customPrompts: getCustomPrompts()
    };

    await new Promise((resolve, reject) => {
      browserAPI.storage.sync.set(options, () => {
        if (browserAPI.runtime.lastError) {
          reject(browserAPI.runtime.lastError);
        } else {
          resolve();
        }
      });
    });

    const status = document.getElementById('status');
    status.textContent = 'Options saved.';
    status.style.color = '#4CAF50';
    setTimeout(() => {
      status.textContent = '';
    }, 750);
  } catch (error) {
    console.error('Error saving options:', error);
    const status = document.getElementById('status');
    status.textContent = 'Error saving options.';
    status.style.color = '#f44336';
  }
}

function getCustomPrompts() {
  try {
    const promptContainers = document.querySelectorAll('.prompt-container');
    return Array.from(promptContainers).map(container => ({
      id: snakeCase(container.querySelector('.prompt-title').value || ''),
      title: container.querySelector('.prompt-title').value || '',
      prompt: container.querySelector('.prompt-text').value || ''
    })).filter(prompt => prompt.title && prompt.prompt); // Filter out empty prompts
  } catch (error) {
    console.error('Error getting custom prompts:', error);
    return [];
  }
}

function snakeCase(str) {
  return str.toLowerCase().replace(/[^a-zA-Z0-9]+/g, '_').replace(/^_|_$/g, '');
}

async function restoreOptions() {
  try {
    const defaults = {
      llmProvider: 'openai',
      apiKey: '',
      llmModel: 'gpt-3.5-turbo',
      customEndpoint: '',
      customPrompts: []
    };

    const items = await new Promise(resolve => {
      browserAPI.storage.sync.get(defaults, resolve);
    });

    const elementIds = ['llmProvider', 'apiKey', 'llmModel', 'customEndpoint'];

    elementIds.forEach(id => {
      const element = document.getElementById(id);
      if (element) {
        element.value = items[id] || defaults[id];
      } else {
        console.warn(`Element with id '${id}' not found`);
      }
    });

    // Clear existing prompts before restoring
    const promptsContainer = document.getElementById('prompts-container');
    while (promptsContainer.firstChild) {
      promptsContainer.removeChild(promptsContainer.firstChild);
    }

    // Restore custom prompts
    items.customPrompts.forEach(prompt => {
      addPromptToUI(prompt.title, prompt.prompt, prompt.id);
    });

    updateUIForProvider(items.llmProvider);
  } catch (error) {
    console.error('Error restoring options:', error);
    showErrorMessage('Error restoring options. Please try reloading the page.');
  }
}

function updateUIForProvider(provider) {
  try {
    const labels = document.querySelectorAll('label span');
    const apiKeySpan = Array.from(labels).find(span => span.textContent.includes('API Key'));
    const modelSpan = Array.from(labels).find(span => span.textContent.includes('Model'));
    const endpointSpan = Array.from(labels).find(span => span.textContent.includes('Endpoint'));
    
    const apiKeyInput = document.getElementById('apiKey');
    const apiKeyHelp = document.getElementById('apiKeyHelp');
    const llmModelInput = document.getElementById('llmModel');
    const modelHelp = document.getElementById('modelHelp');
    const customEndpointInput = document.getElementById('customEndpoint');
    const customEndpointContainer = customEndpointInput.parentElement;
    const endpointHelp = document.getElementById('endpointHelp');
    const fetchModelsButton = document.getElementById('fetchModels');
    const availableModelsSelect = document.getElementById('availableModels');

    if (!apiKeySpan || !modelSpan || !endpointSpan) {
      console.warn('Could not find required UI labels');
      return;
    }

    // Reset visibility
    customEndpointContainer.style.display = 'block';
    apiKeyInput.parentElement.style.display = 'block';
    if (availableModelsSelect) {
      availableModelsSelect.classList.add('hidden');
      availableModelsSelect.innerHTML = '<option value="">Select a model...</option>';
    }

    // Show/hide fetch models button based on provider capability
    const canFetchModels = ['openai', 'lmstudio', 'ollama', 'openrouter', 'groq'].includes(provider);
    if (fetchModelsButton) {
      fetchModelsButton.style.display = canFetchModels ? 'block' : 'none';
    }

    switch (provider) {
      case 'openai':
        apiKeySpan.textContent = 'OpenAI API Key:';
        apiKeyInput.placeholder = 'sk-...';
        if (apiKeyHelp) apiKeyHelp.textContent = 'Get your API key from https://platform.openai.com/api-keys';
        llmModelInput.placeholder = 'gpt-3.5-turbo, gpt-4, gpt-4-turbo, etc.';
        if (modelHelp) modelHelp.textContent = 'Common models: gpt-3.5-turbo, gpt-4, gpt-4-turbo';
        customEndpointInput.placeholder = 'https://api.openai.com/v1/chat/completions (default)';
        if (endpointHelp) endpointHelp.textContent = 'Leave empty to use default OpenAI endpoint';
        break;

      case 'anthropic':
        apiKeySpan.textContent = 'Anthropic API Key:';
        apiKeyInput.placeholder = 'sk-ant-...';
        if (apiKeyHelp) apiKeyHelp.textContent = 'Get your API key from https://console.anthropic.com/';
        llmModelInput.placeholder = 'claude-3-haiku-20240307, claude-3-sonnet-20240229, etc.';
        if (modelHelp) modelHelp.textContent = 'Common models: claude-3-haiku-20240307, claude-3-sonnet-20240229';
        customEndpointInput.placeholder = 'https://api.anthropic.com/v1/complete (default)';
        if (endpointHelp) endpointHelp.textContent = 'Leave empty to use default Anthropic endpoint';
        break;

      case 'ollama':
        apiKeySpan.textContent = 'API Key (Optional):';
        apiKeyInput.placeholder = 'Leave empty for local Ollama';
        if (apiKeyHelp) apiKeyHelp.textContent = 'Ollama typically runs without API keys. Only needed for remote instances.';
        llmModelInput.placeholder = 'llama2, llama3, mistral, codellama, etc.';
        if (modelHelp) modelHelp.textContent = 'Use "ollama list" to see available models on your system';
        customEndpointInput.placeholder = 'http://localhost:11434/api/generate (default)';
        if (endpointHelp) endpointHelp.textContent = 'Default: http://localhost:11434/api/generate. Make sure Ollama is running.';
        break;

      case 'lmstudio':
        apiKeySpan.textContent = 'API Key (Optional):';
        apiKeyInput.placeholder = 'Leave empty for local LM Studio';
        if (apiKeyHelp) apiKeyHelp.textContent = 'LM Studio typically runs without API keys for local use.';
        llmModelInput.placeholder = 'Model name as shown in LM Studio';
        if (modelHelp) modelHelp.textContent = 'Use the exact model name from your LM Studio models list';
        customEndpointInput.placeholder = 'http://localhost:1234/v1/chat/completions (default)';
        if (endpointHelp) endpointHelp.textContent = 'Default: http://localhost:1234/v1/chat/completions. Ensure LM Studio server is running.';
        break;

      case 'groq':
        apiKeySpan.textContent = 'Groq API Key:';
        apiKeyInput.placeholder = 'gsk_...';
        if (apiKeyHelp) apiKeyHelp.textContent = 'Get your API key from https://console.groq.com/keys';
        llmModelInput.placeholder = 'llama3-8b-8192, llama3-70b-8192, mixtral-8x7b-32768, etc.';
        if (modelHelp) modelHelp.textContent = 'Common models: llama3-8b-8192, llama3-70b-8192, mixtral-8x7b-32768';
        customEndpointInput.placeholder = 'https://api.groq.com/v1/chat/completions (default)';
        if (endpointHelp) endpointHelp.textContent = 'Leave empty to use default Groq endpoint';
        break;

      case 'openrouter':
        apiKeySpan.textContent = 'OpenRouter API Key:';
        apiKeyInput.placeholder = 'sk-or-...';
        if (apiKeyHelp) apiKeyHelp.textContent = 'Get your API key from https://openrouter.ai/keys';
        llmModelInput.placeholder = 'openai/gpt-3.5-turbo, anthropic/claude-3-haiku, etc.';
        if (modelHelp) modelHelp.textContent = 'Format: provider/model-name (e.g., openai/gpt-4, anthropic/claude-3-sonnet)';
        customEndpointInput.placeholder = 'https://openrouter.ai/api/v1/chat/completions (default)';
        if (endpointHelp) endpointHelp.textContent = 'Leave empty to use default OpenRouter endpoint';
        break;

      default:
        console.warn(`Unknown provider: ${provider}`);
        break;
    }
  } catch (error) {
    console.error('Error updating UI for provider:', error);
    showErrorMessage('Error updating provider settings.');
  }
}

async function fetchAvailableModels() {
  const provider = document.getElementById('llmProvider').value;
  const apiKey = document.getElementById('apiKey').value;
  const customEndpoint = document.getElementById('customEndpoint').value;
  const fetchButton = document.getElementById('fetchModels');
  const fetchText = document.getElementById('fetchModelsText');
  const fetchSpinner = document.getElementById('fetchModelsSpinner');
  const availableModelsSelect = document.getElementById('availableModels');

  // Show loading state
  fetchButton.disabled = true;
  if (fetchText) fetchText.classList.add('hidden');
  if (fetchSpinner) fetchSpinner.classList.remove('hidden');

  try {
    let endpoint, headers = {};
    
    switch (provider) {
      case 'openai':
        endpoint = customEndpoint ? customEndpoint.replace('/chat/completions', '/models') : 'https://api.openai.com/v1/models';
        if (apiKey) headers['Authorization'] = `Bearer ${apiKey}`;
        break;
        
      case 'lmstudio':
        const baseUrl = customEndpoint ? customEndpoint.split('/v1')[0] : 'http://localhost:1234';
        endpoint = `${baseUrl}/v1/models`;
        if (apiKey) headers['Authorization'] = `Bearer ${apiKey}`;
        break;
        
      case 'ollama':
        const ollamaBaseUrl = customEndpoint ? customEndpoint.split('/api')[0] : 'http://localhost:11434';
        endpoint = `${ollamaBaseUrl}/api/tags`;
        if (apiKey) headers['Authorization'] = `Bearer ${apiKey}`;
        break;
        
      case 'openrouter':
        endpoint = 'https://openrouter.ai/api/v1/models';
        if (apiKey) headers['Authorization'] = `Bearer ${apiKey}`;
        break;
        
      case 'groq':
        endpoint = customEndpoint ? customEndpoint.replace('/chat/completions', '/models') : 'https://api.groq.com/openai/v1/models';
        if (apiKey) headers['Authorization'] = `Bearer ${apiKey}`;
        break;
        
      default:
        throw new Error(`Model fetching not supported for ${provider}`);
    }

    const response = await fetch(endpoint, { headers });
    
    if (!response.ok) {
      throw new Error(`HTTP ${response.status}: ${response.statusText}`);
    }

    const data = await response.json();
    let models = [];

    // Parse models based on provider format
    switch (provider) {
      case 'ollama':
        models = data.models ? data.models.map(m => ({ id: m.name, name: m.name })) : [];
        break;
      case 'openrouter':
        models = data.data ? data.data.map(m => ({ id: m.id, name: m.name || m.id })) : [];
        break;
      default: // OpenAI, LM Studio, Groq
        models = data.data ? data.data.map(m => ({ id: m.id, name: m.id })) : [];
        break;
    }

    // Populate dropdown
    availableModelsSelect.innerHTML = '<option value="">Select a model...</option>';
    models.forEach(model => {
      const option = document.createElement('option');
      option.value = model.id;
      option.textContent = model.name;
      availableModelsSelect.appendChild(option);
    });

    availableModelsSelect.classList.remove('hidden');
    showSuccessMessage(`Found ${models.length} models`);

  } catch (error) {
    console.error('Error fetching models:', error);
    showErrorMessage(`Failed to fetch models: ${error.message}`);
  } finally {
    // Reset loading state
    fetchButton.disabled = false;
    if (fetchText) fetchText.classList.remove('hidden');
    if (fetchSpinner) fetchSpinner.classList.add('hidden');
  }
}

function addPromptToUI(title = '', prompt = '', id = '') {
  try {
    const promptsContainer = document.getElementById('prompts-container');
    const template = document.getElementById('prompt-template');
    
    if (!promptsContainer || !template) {
      throw new Error('Required elements not found');
    }

    const promptElement = template.content.cloneNode(true);

    const titleInput = promptElement.querySelector('.prompt-title');
    const textInput = promptElement.querySelector('.prompt-text');
    
    if (titleInput && textInput) {
      titleInput.value = title;
      textInput.value = prompt;
    }

    // Add a hidden input for the ID
    const idInput = document.createElement('input');
    idInput.type = 'hidden';
    idInput.className = 'prompt-id';
    idInput.value = id || snakeCase(title);
    
    const container = promptElement.querySelector('.prompt-container');
    if (container) {
      container.appendChild(idInput);
      
      const deleteButton = container.querySelector('.delete-prompt');
      if (deleteButton) {
        deleteButton.addEventListener('click', function() {
          container.remove();
          saveOptions(); // Auto-save when removing a prompt
        });
      }
    }

    promptsContainer.appendChild(promptElement);
  } catch (error) {
    console.error('Error adding prompt to UI:', error);
    showErrorMessage('Error adding new prompt.');
  }
}

function showErrorMessage(message) {
  const status = document.getElementById('status');
  if (status) {
    status.textContent = message;
    status.style.color = '#f44336';
    setTimeout(() => {
      status.textContent = '';
    }, 3000);
  }
}

function showSuccessMessage(message) {
  const status = document.getElementById('status');
  if (status) {
    status.textContent = message;
    status.style.color = '#4CAF50';
    setTimeout(() => {
      status.textContent = '';
    }, 2000);
  }
}

// Initialize event listeners
document.addEventListener('DOMContentLoaded', () => {
  console.log('DOMContentLoaded event fired');
  restoreOptions();

  const saveButton = document.getElementById('save');
  const providerSelect = document.getElementById('llmProvider');
  const addPromptButton = document.getElementById('add-prompt');
  const fetchModelsButton = document.getElementById('fetchModels');
  const availableModelsSelect = document.getElementById('availableModels');

  if (saveButton) {
    saveButton.addEventListener('click', saveOptions);
  }

  if (providerSelect) {
    providerSelect.addEventListener('change', (e) => updateUIForProvider(e.target.value));
  }

  if (addPromptButton) {
    addPromptButton.addEventListener('click', () => addPromptToUI());
  }

  if (fetchModelsButton) {
    fetchModelsButton.addEventListener('click', fetchAvailableModels);
  }

  if (availableModelsSelect) {
    availableModelsSelect.addEventListener('change', (e) => {
      if (e.target.value) {
        document.getElementById('llmModel').value = e.target.value;
      }
    });
  }
});

// Autosave function for custom prompts
async function saveCustomPrompts(customPrompts) {
  try {
    await new Promise((resolve, reject) => {
      browserAPI.storage.sync.set({ customPrompts }, () => {
        if (browserAPI.runtime.lastError) {
          reject(browserAPI.runtime.lastError);
        } else {
          resolve();
        }
      });
    });
    console.log('Custom prompts saved');
  } catch (error) {
    console.error('Error saving custom prompts:', error);
    showErrorMessage('Error saving custom prompts.');
  }
}


================================================
FILE: src/popup.html
================================================
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Scramble</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            width: 300px;
            padding: 15px;
        }
        h1 {
            font-size: 18px;
            color: #333;
            margin-bottom: 15px;
        }
        #status {
            margin-bottom: 15px;
            padding: 10px;
            background-color: #f1f1f1;
            border-radius: 8px;
        }
        button {
            width: 100%;
            padding: 10px;
            background-color: #2DD4BF;
            color: white;
            border: none;
            border-radius: 8px;
            cursor: pointer;
        }
        button:hover {
            opacity: 0.8;
        }
    </style>
</head>
<body>
    <h1>Scramble</h1>
    <div id="status">Checking status...</div>
    <button id="optionsButton">Open Options</button>
    <script src="popup.js"></script>
</body>
</html>


================================================
FILE: src/popup.js
================================================
const browserAPI = (typeof browser !== 'undefined' ? browser : chrome);

document.addEventListener('DOMContentLoaded', async function() {
    const statusElement = document.getElementById('status');
    const optionsButton = document.getElementById('optionsButton');
  
    try {
        // Use async/await and proper error handling
        const result = await new Promise((resolve) => {
            browserAPI.storage.sync.get({
                llmProvider: 'openai', // default value
                apiKey: ''
            }, resolve);
        });

        if (result.apiKey) {
            statusElement.textContent = `Extension is ready to use with ${result.llmProvider} provider.`;
            statusElement.style.color = '#4CAF50'; // Success color
        } else {
            statusElement.textContent = 'API key not set. Please set it in the options.';
            statusElement.style.color = '#f44336'; // Error color
        }
    } catch (error) {
        console.error('Error checking storage:', error);
        statusElement.textContent = 'Error checking extension status.';
        statusElement.style.color = '#f44336';
    }

    // Open options page when button is clicked
    optionsButton.addEventListener('click', function() {
        try {
            if (browserAPI.runtime.openOptionsPage) {
                // Chrome & Firefox support
                browserAPI.runtime.openOptionsPage();
            } else {
                // Fallback for older Firefox versions
                window.open(browserAPI.runtime.getURL('options.html'));
            }
        } catch (error) {
            console.error('Error opening options page:', error);
            // Fallback method
            window.open(browserAPI.runtime.getURL('options.html'));
        }
    });
});


================================================
FILE: src/libs/tw-input.css
================================================
@tailwind base;
@tailwind components;
@tailwind utilities;



================================================
FILE: src/libs/tw-output.css
================================================
*,:after,:before{--tw-border-spacing-x:0;--tw-border-spacing-y:0;--tw-translate-x:0;--tw-translate-y:0;--tw-rotate:0;--tw-skew-x:0;--tw-skew-y:0;--tw-scale-x:1;--tw-scale-y:1;--tw-pan-x: ;--tw-pan-y: ;--tw-pinch-zoom: ;--tw-scroll-snap-strictness:proximity;--tw-gradient-from-position: ;--tw-gradient-via-position: ;--tw-gradient-to-position: ;--tw-ordinal: ;--tw-slashed-zero: ;--tw-numeric-figure: ;--tw-numeric-spacing: ;--tw-numeric-fraction: ;--tw-ring-inset: ;--tw-ring-offset-width:0px;--tw-ring-offset-color:#fff;--tw-ring-color:rgba(59,130,246,.5);--tw-ring-offset-shadow:0 0 #0000;--tw-ring-shadow:0 0 #0000;--tw-shadow:0 0 #0000;--tw-shadow-colored:0 0 #0000;--tw-blur: ;--tw-brightness: ;--tw-contrast: ;--tw-grayscale: ;--tw-hue-rotate: ;--tw-invert: ;--tw-saturate: ;--tw-sepia: ;--tw-drop-shadow: ;--tw-backdrop-blur: ;--tw-backdrop-brightness: ;--tw-backdrop-contrast: ;--tw-backdrop-grayscale: ;--tw-backdrop-hue-rotate: ;--tw-backdrop-invert: ;--tw-backdrop-opacity: ;--tw-backdrop-saturate: ;--tw-backdrop-sepia: ;--tw-contain-size: ;--tw-contain-layout: ;--tw-contain-paint: ;--tw-contain-style: }::backdrop{--tw-border-spacing-x:0;--tw-border-spacing-y:0;--tw-translate-x:0;--tw-translate-y:0;--tw-rotate:0;--tw-skew-x:0;--tw-skew-y:0;--tw-scale-x:1;--tw-scale-y:1;--tw-pan-x: ;--tw-pan-y: ;--tw-pinch-zoom: ;--tw-scroll-snap-strictness:proximity;--tw-gradient-from-position: ;--tw-gradient-via-position: ;--tw-gradient-to-position: ;--tw-ordinal: ;--tw-slashed-zero: ;--tw-numeric-figure: ;--tw-numeric-spacing: ;--tw-numeric-fraction: ;--tw-ring-inset: ;--tw-ring-offset-width:0px;--tw-ring-offset-color:#fff;--tw-ring-color:rgba(59,130,246,.5);--tw-ring-offset-shadow:0 0 #0000;--tw-ring-shadow:0 0 #0000;--tw-shadow:0 0 #0000;--tw-shadow-colored:0 0 #0000;--tw-blur: ;--tw-brightness: ;--tw-contrast: ;--tw-grayscale: ;--tw-hue-rotate: ;--tw-invert: ;--tw-saturate: ;--tw-sepia: ;--tw-drop-shadow: ;--tw-backdrop-blur: ;--tw-backdrop-brightness: ;--tw-backdrop-contrast: ;--tw-backdrop-grayscale: ;--tw-backdrop-hue-rotate: ;--tw-backdrop-invert: ;--tw-backdrop-opacity: ;--tw-backdrop-saturate: ;--tw-backdrop-sepia: ;--tw-contain-size: ;--tw-contain-layout: ;--tw-contain-paint: ;--tw-contain-style: }/*! tailwindcss v3.4.14 | MIT License | https://tailwindcss.com*/*,:after,:before{box-sizing:border-box;border:0 solid #e5e7eb}:after,:before{--tw-content:""}:host,html{line-height:1.5;-webkit-text-size-adjust:100%;-moz-tab-size:4;-o-tab-size:4;tab-size:4;font-family:ui-sans-serif,system-ui,sans-serif,Apple Color Emoji,Segoe UI Emoji,Segoe UI Symbol,Noto Color Emoji;font-feature-settings:normal;font-variation-settings:normal;-webkit-tap-highlight-color:transparent}body{margin:0;line-height:inherit}hr{height:0;color:inherit;border-top-width:1px}abbr:where([title]){-webkit-text-decoration:underline dotted;text-decoration:underline dotted}h1,h2,h3,h4,h5,h6{font-size:inherit;font-weight:inherit}a{color:inherit;text-decoration:inherit}b,strong{font-weight:bolder}code,kbd,pre,samp{font-family:ui-monospace,SFMono-Regular,Menlo,Monaco,Consolas,Liberation Mono,Courier New,monospace;font-feature-settings:normal;font-variation-settings:normal;font-size:1em}small{font-size:80%}sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}sub{bottom:-.25em}sup{top:-.5em}table{text-indent:0;border-color:inherit;border-collapse:collapse}button,input,optgroup,select,textarea{font-family:inherit;font-feature-settings:inherit;font-variation-settings:inherit;font-size:100%;font-weight:inherit;line-height:inherit;letter-spacing:inherit;color:inherit;margin:0;padding:0}button,select{text-transform:none}button,input:where([type=button]),input:where([type=reset]),input:where([type=submit]){-webkit-appearance:button;background-color:transparent;background-image:none}:-moz-focusring{outline:auto}:-moz-ui-invalid{box-shadow:none}progress{vertical-align:baseline}::-webkit-inner-spin-button,::-webkit-outer-spin-button{height:auto}[type=search]{-webkit-appearance:textfield;outline-offset:-2px}::-webkit-search-decoration{-webkit-appearance:none}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}summary{display:list-item}blockquote,dd,dl,figure,h1,h2,h3,h4,h5,h6,hr,p,pre{margin:0}fieldset{margin:0}fieldset,legend{padding:0}menu,ol,ul{list-style:none;margin:0;padding:0}dialog{padding:0}textarea{resize:vertical}input::-moz-placeholder,textarea::-moz-placeholder{opacity:1;color:#9ca3af}input::placeholder,textarea::placeholder{opacity:1;color:#9ca3af}[role=button],button{cursor:pointer}:disabled{cursor:default}audio,canvas,embed,iframe,img,object,svg,video{display:block;vertical-align:middle}img,video{max-width:100%;height:auto}[hidden]:where(:not([hidden=until-found])){display:none}.container{width:100%}@media (min-width:640px){.container{max-width:640px}}@media (min-width:768px){.container{max-width:768px}}@media (min-width:1024px){.container{max-width:1024px}}@media (min-width:1280px){.container{max-width:1280px}}@media (min-width:1536px){.container{max-width:1536px}}.fixed{position:fixed}.mx-auto{margin-left:auto;margin-right:auto}.mb-2{margin-bottom:.5rem}.mb-4{margin-bottom:1rem}.mb-8{margin-bottom:2rem}.mt-1{margin-top:.25rem}.mt-10{margin-top:2.5rem}.mt-2{margin-top:.5rem}.mt-4{margin-top:1rem}.mt-6{margin-top:1.5rem}.mt-8{margin-top:2rem}.block{display:block}.flex{display:flex}.hidden{display:none}.w-full{width:100%}.max-w-3xl{max-width:48rem}.justify-center{justify-content:center}.space-y-4>:not([hidden])~:not([hidden]){--tw-space-y-reverse:0;margin-top:calc(1rem*(1 - var(--tw-space-y-reverse)));margin-bottom:calc(1rem*var(--tw-space-y-reverse))}.rounded-lg{border-radius:.5rem}.rounded-md{border-radius:.375rem}.border{border-width:1px}.border-gray-300{--tw-border-opacity:1;border-color:rgb(209 213 219/var(--tw-border-opacity))}.bg-gray-100{--tw-bg-opacity:1;background-color:rgb(243 244 246/var(--tw-bg-opacity))}.bg-indigo-600{--tw-bg-opacity:1;background-color:rgb(79 70 229/var(--tw-bg-opacity))}.bg-red-600{--tw-bg-opacity:1;background-color:rgb(220 38 38/var(--tw-bg-opacity))}.bg-white{--tw-bg-opacity:1;background-color:rgb(255 255 255/var(--tw-bg-opacity))}.p-4{padding:1rem}.p-6{padding:1.5rem}.px-3{padding-left:.75rem;padding-right:.75rem}.px-4{padding-left:1rem;padding-right:1rem}.py-2{padding-top:.5rem;padding-bottom:.5rem}.font-sans{font-family:ui-sans-serif,system-ui,sans-serif,Apple Color Emoji,Segoe UI Emoji,Segoe UI Symbol,Noto Color Emoji}.text-2xl{font-size:1.5rem;line-height:2rem}.text-3xl{font-size:1.875rem;line-height:2.25rem}.text-sm{font-size:.875rem;line-height:1.25rem}.font-bold{font-weight:700}.font-semibold{font-weight:600}.text-gray-700{--tw-text-opacity:1;color:rgb(55 65 81/var(--tw-text-opacity))}.text-gray-800{--tw-text-opacity:1;color:rgb(31 41 55/var(--tw-text-opacity))}.text-gray-900{--tw-text-opacity:1;color:rgb(17 24 39/var(--tw-text-opacity))}.text-white{--tw-text-opacity:1;color:rgb(255 255 255/var(--tw-text-opacity))}.antialiased{-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale}.shadow-lg{--tw-shadow:0 10px 15px -3px rgba(0,0,0,.1),0 4px 6px -4px rgba(0,0,0,.1);--tw-shadow-colored:0 10px 15px -3px var(--tw-shadow-color),0 4px 6px -4px var(--tw-shadow-color)}.shadow-lg,.shadow-sm{box-shadow:var(--tw-ring-offset-shadow,0 0 #0000),var(--tw-ring-shadow,0 0 #0000),var(--tw-shadow)}.shadow-sm{--tw-shadow:0 1px 2px 0 rgba(0,0,0,.05);--tw-shadow-colored:0 1px 2px 0 var(--tw-shadow-color)}.filter{filter:var(--tw-blur) var(--tw-brightness) var(--tw-contrast) var(--tw-grayscale) var(--tw-hue-rotate) var(--tw-invert) var(--tw-saturate) var(--tw-sepia) var(--tw-drop-shadow)}.hover\:bg-blue-700:hover{--tw-bg-opacity:1;background-color:rgb(29 78 216/var(--tw-bg-opacity))}.hover\:bg-indigo-700:hover{--tw-bg-opacity:1;background-color:rgb(67 56 202/var(--tw-bg-opacity))}.hover\:bg-red-700:hover{--tw-bg-opacity:1;background-color:rgb(185 28 28/var(--tw-bg-opacity))}.focus\:border-indigo-500:focus{--tw-border-opacity:1;border-color:rgb(99 102 241/var(--tw-border-opacity))}.focus\:outline-none:focus{outline:2px solid transparent;outline-offset:2px}.focus\:ring:focus{--tw-ring-offset-shadow:var(--tw-ring-inset) 0 0 0 var(--tw-ring-offset-width) var(--tw-ring-offset-color);--tw-ring-shadow:var(--tw-ring-inset) 0 0 0 calc(3px + var(--tw-ring-offset-width)) var(--tw-ring-color)}.focus\:ring-2:focus,.focus\:ring:focus{box-shadow:var(--tw-ring-offset-shadow),var(--tw-ring-shadow),var(--tw-shadow,0 0 #0000)}.focus\:ring-2:focus{--tw-ring-offset-shadow:var(--tw-ring-inset) 0 0 0 var(--tw-ring-offset-width) var(--tw-ring-offset-color);--tw-ring-shadow:var(--tw-ring-inset) 0 0 0 calc(2px + var(--tw-ring-offset-width)) var(--tw-ring-color)}.focus\:ring-blue-500:focus{--tw-ring-opacity:1;--tw-ring-color:rgb(59 130 246/var(--tw-ring-opacity))}.focus\:ring-indigo-200:focus{--tw-ring-opacity:1;--tw-ring-color:rgb(199 210 254/var(--tw-ring-opacity))}.focus\:ring-indigo-500:focus{--tw-ring-opacity:1;--tw-ring-color:rgb(99 102 241/var(--tw-ring-opacity))}.focus\:ring-red-500:focus{--tw-ring-opacity:1;--tw-ring-color:rgb(239 68 68/var(--tw-ring-opacity))}.focus\:ring-opacity-50:focus{--tw-ring-opacity:0.5}.focus\:ring-offset-2:focus{--tw-ring-offset-width:2px}

